<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>ML Wiki</sitename>
    <dbname>stolzen_mlwiki49</dbname>
    <base>http://mlwiki.org/index.php/Main_Page</base>
    <generator>MediaWiki 1.25.3</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">ML Wiki</namespace>
      <namespace key="5" case="first-letter">ML Wiki talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Main Page</title>
    <ns>0</ns>
    <id>1</id>
    <revision>
      <id>1</id>
      <timestamp>2015-11-07T00:32:15Z</timestamp>
      <contributor>
        <username>MediaWiki default</username>
        <id>0</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="592">&lt;strong&gt;MediaWiki has been successfully installed.&lt;/strong&gt;

Consult the [//meta.wikimedia.org/wiki/Help:Contents User's Guide] for information on using the wiki software.

== Getting started ==
* [//www.mediawiki.org/wiki/Special:MyLanguage/Manual:Configuration_settings Configuration settings list]
* [//www.mediawiki.org/wiki/Special:MyLanguage/Manual:FAQ MediaWiki FAQ]
* [https://lists.wikimedia.org/mailman/listinfo/mediawiki-announce MediaWiki release mailing list]
* [//www.mediawiki.org/wiki/Special:MyLanguage/Localisation#Translation_resources Localise MediaWiki for your language]</text>
      <sha1>glba3g2evzm40dqnqxegze66eqibkvb</sha1>
    </revision>
    <revision>
      <id>2</id>
      <parentid>1</parentid>
      <timestamp>2015-05-31T15:53:45Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="376">== О вики ==
Меня зовут Алексей Григорьев, это моя персональная вики

== Основные категории ==
Все категории: [[Служебная:Категории]]
* Недоработанные страницы: [[:Category:Special]]


=== Обучение ===
* [[Courses]]
* [[Books]]
* [[Sources Index]]</text>
      <sha1>devketdziz78ys715xdxulnxtd5wxq0</sha1>
    </revision>
    <revision>
      <id>275</id>
      <parentid>1</parentid>
      <timestamp>2015-11-07T00:51:56Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="68">Here I keep my notes: 

* [[Courses]]
* [[Books]]
* [[Source Index]]</text>
      <sha1>cziu4ymq61gpwnuzpfzyfurd5nztms7</sha1>
    </revision>
    <revision>
      <id>662</id>
      <parentid>275</parentid>
      <timestamp>2015-11-07T00:55:15Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="69">Here I keep my notes: 

* [[Courses]]
* [[Books]]
* [[Sources Index]]</text>
      <sha1>1gcy54yye7ity937zfh98fir2bz97s9</sha1>
    </revision>
    <revision>
      <id>704</id>
      <parentid>662</parentid>
      <timestamp>2015-11-23T14:33:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="365">Here I keep my notes: 

* [[Courses]]
* [[Books]]
* [[Sources Index]]

&lt;hr&gt;

&lt;center&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;width: 50%;&quot;&gt;
&lt;DynamicArticleList&gt;
  title=Newest Articles
  type=new
  count=10
&lt;/DynamicArticleList&gt;
&lt;/td&gt;
&lt;td class=&quot;width: 50%;&quot;&gt;
&lt;DynamicArticleList&gt;
  title=Latest Updated
  type=update
  count=10
&lt;/DynamicArticleList&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/center&gt;</text>
      <sha1>ne5u9f1z4g2d0lbr6lex4myzbqvk6ky</sha1>
    </revision>
    <revision>
      <id>707</id>
      <parentid>704</parentid>
      <timestamp>2015-11-23T14:41:11Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="459">&lt;center&gt;
&lt;table&gt;
&lt;tr valign=&quot;top&quot;&gt;
&lt;td class=&quot;width: 50%;&quot;&gt;
&lt;h3&gt;Menu&lt;/h3&gt;
{{MainPage Menu}}
&lt;/td&gt;
&lt;td class=&quot;width: 50%;&quot;&gt;
&lt;h3&gt;Featured&lt;/h3&gt;
{{MainPage Featured}}
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr valign=&quot;top&quot;&gt;
&lt;td class=&quot;width: 50%;&quot;&gt;
&lt;DynamicArticleList&gt;
  title=Newest Articles
  type=new
  count=10
&lt;/DynamicArticleList&gt;
&lt;/td&gt;
&lt;td class=&quot;width: 50%;&quot;&gt;
&lt;DynamicArticleList&gt;
  title=Latest Updated
  type=update
  count=10
&lt;/DynamicArticleList&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/center&gt;</text>
      <sha1>0wndzajmyt0xqdkwpum0l7cwgf1jus2</sha1>
    </revision>
    <revision>
      <id>709</id>
      <parentid>707</parentid>
      <timestamp>2015-11-23T14:58:21Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="441">
&lt;table&gt;
&lt;tr valign=&quot;top&quot;&gt;
&lt;td class=&quot;width: 50%;&quot;&gt;
&lt;h3&gt;Menu&lt;/h3&gt;
{{MainPage Menu}}
&lt;/td&gt;
&lt;td class=&quot;width: 50%;&quot;&gt;
&lt;h3&gt;Featured&lt;/h3&gt;
{{MainPage Featured}}
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr valign=&quot;top&quot;&gt;
&lt;td class=&quot;width: 50%;&quot;&gt;
&lt;DynamicArticleList&gt;
  title=Newest Articles
  type=new
  count=10
&lt;/DynamicArticleList&gt;
&lt;/td&gt;
&lt;td class=&quot;width: 50%;&quot;&gt;
&lt;DynamicArticleList&gt;
  title=Latest Updated
  type=update
  count=10
&lt;/DynamicArticleList&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;</text>
      <sha1>cl5k17rvwxy472j686b0olgarwze5d4</sha1>
    </revision>
    <revision>
      <id>746</id>
      <parentid>709</parentid>
      <timestamp>2015-12-25T21:13:36Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="428">
&lt;div class=&quot;row&quot;&gt;
  &lt;div class=&quot;col-md-6&quot;&gt;&lt;h3&gt;Menu&lt;/h3&gt;{{MainPage Menu}}&lt;/div&gt;
  &lt;div class=&quot;col-md-6&quot;&gt;&lt;h3&gt;Featured&lt;/h3&gt;{{MainPage Featured}}&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
  &lt;div class=&quot;col-md-6&quot;&gt;
&lt;DynamicArticleList&gt;
  title=Newest Articles
  type=new
  count=10
&lt;/DynamicArticleList&gt;
  &lt;/div&gt;
  &lt;div class=&quot;col-md-6&quot;&gt;
&lt;DynamicArticleList&gt;
  title=Latest Updated
  type=update
  count=10
&lt;/DynamicArticleList&gt;
  &lt;/div&gt;
&lt;/div&gt;</text>
      <sha1>cumx2j6pf4kihl59wxep3wi8zxcy6nk</sha1>
    </revision>
    <revision>
      <id>827</id>
      <parentid>746</parentid>
      <timestamp>2020-05-25T20:26:19Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="613">
&lt;div class=&quot;row&quot;&gt;
  &lt;div class=&quot;col-md-6&quot;&gt;&lt;h3&gt;Menu&lt;/h3&gt;{{MainPage Menu}}&lt;/div&gt;
  &lt;div class=&quot;col-md-6&quot;&gt;&lt;h3&gt;Links&lt;/h3&gt;

* Follow [https://twitter.com/Al_Grigor @Al_Grigor] on Twitter
* My book &quot;[http://bit.ly/mlbookcamp Machine Learning Bookcamp]&quot;: learn machine learning by doing projects (use &quot;grigorevpc&quot; to get 40% off)

&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;row&quot;&gt;
  &lt;div class=&quot;col-md-6&quot;&gt;
&lt;DynamicArticleList&gt;
  title=Newest Articles
  type=new
  count=10
&lt;/DynamicArticleList&gt;
  &lt;/div&gt;

  &lt;div class=&quot;col-md-6&quot;&gt;
&lt;DynamicArticleList&gt;
  title=Latest Updated
  type=update
  count=10
&lt;/DynamicArticleList&gt;
  &lt;/div&gt;
&lt;/div&gt;</text>
      <sha1>qz9bd43i7kbmeqdgkhydaj0qhhg574v</sha1>
    </revision>
    <revision>
      <id>828</id>
      <parentid>827</parentid>
      <timestamp>2020-11-16T20:06:19Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="712">
&lt;div class=&quot;row&quot;&gt;
  &lt;div class=&quot;col-md-6&quot;&gt;&lt;h3&gt;Menu&lt;/h3&gt;{{MainPage Menu}}&lt;/div&gt;
  &lt;div class=&quot;col-md-6&quot;&gt;&lt;h3&gt;Links&lt;/h3&gt;

* Follow [https://twitter.com/Al_Grigor @Al_Grigor] on Twitter
* [http://DataTalks.Club DataTalks.Club] - the place to talk about data. Join our Slack community!
* My book &quot;[http://bit.ly/mlbookcamp Machine Learning Bookcamp]&quot;: learn machine learning by doing projects (use &quot;grigorevpc&quot; to get 40% off)

&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;row&quot;&gt;
  &lt;div class=&quot;col-md-6&quot;&gt;
&lt;DynamicArticleList&gt;
  title=Newest Articles
  type=new
  count=10
&lt;/DynamicArticleList&gt;
  &lt;/div&gt;

  &lt;div class=&quot;col-md-6&quot;&gt;
&lt;DynamicArticleList&gt;
  title=Latest Updated
  type=update
  count=10
&lt;/DynamicArticleList&gt;
  &lt;/div&gt;
&lt;/div&gt;</text>
      <sha1>ce7h8noj271bkg92syg43om4ua6q8pq</sha1>
    </revision>
  </page>
  <page>
    <title>Computing for Data Analysis (coursera)</title>
    <ns>0</ns>
    <id>2</id>
    <revision>
      <id>3</id>
      <timestamp>2014-02-08T15:17:59Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14399">{{draft}}

Курс [https://www.coursera.org/course/compdata Computing for Data Analysis] об основах языка программирования R

* svn директория [http://code.google.com/p/stolzen/source/browse/trunk/courses/coursera/Computing+for+Data+Analysis/]
* mindmap [http://stolzen.googlecode.com/svn/trunk/courses/coursera/Computing%20for%20Data%20Analysis/summary.xmind]
* конспекты
** неделя 1 [http://stolzen.googlecode.com/svn/trunk/courses/coursera/Computing%20for%20Data%20Analysis/week1/week1%20summary.pdf]
** неделя 2 [http://stolzen.googlecode.com/svn/trunk/courses/coursera/Computing%20for%20Data%20Analysis/week2/week2_summary.pdf]
** неделя 3 [http://stolzen.googlecode.com/svn/trunk/courses/coursera/Computing%20for%20Data%20Analysis/week3/week3_notes.pdf]
** неделя 4 [http://stolzen.googlecode.com/svn/trunk/courses/coursera/Computing%20for%20Data%20Analysis/week4/week4_notes.pdf]


== Week1 ==

=== Syntax ===
  x &lt;- assigment
  # comment
  x &lt;- 1:20 - sequence

=== Data types ===
==== atomic classes ====
*logic
*characters
*numeric
*integer
*complex
==== numbers ====
*doubles by default
*if integer is needed - use L
*Inf = 1/ 0
*-Inf
*NaN - not a number
==== vector ====
*everything of the same class
*creating a vector
**vector() creates a new vector
**x &lt;- vector(&quot;numeric&quot;, length = 10)
***creates a vector filled with NA
**c() concatenate - other function for creating vector
**c(0.5, 0.6) numeric
**c(TRUE, FALSE); c(T, F) logical
**c(&quot;a&quot;, &quot;b&quot;) character
**9:29 integer
**c(1+0i, 2+4i) complex
==== matrix ====
*vector with dimension attributes
**nrow
**ncol
*creating
**m &lt;- matrix(nrow = 2, ncol = 3)
**m &lt;- matrix(1:6, nrow = 2, ncol = 3)
***from upper left down
***1 3 5
2 4 6
**column-binding
***x &lt;- 1:3; y &lt;- 10:12
***cbind(x, y)
****1 10
2 11
3 12
***rbind(x, y)
****1   2   3
10 11 12
==== list ====
*may contain different types
*x &lt;- list(1, &quot;a&quot;, T, 1+4i)
==== attributes ====
*names (dimnames)
*dimensions
*class
*length
*other user defined data
*attributes() - general function
==== factor ====
*categorical data vector
**ordered
**unordered
*integer vector with each integer having a label
*self-describing
*x &lt;- factor(c(&quot;yes&quot;, &quot;yes&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;no&quot;) 
*table(x) =&gt; frequency
*unclass(x)
**2 2 1 2 2 1 #(2=yes, 1=no)
*gl - generate factors
**f = gl(3, 10) # 1..1 x10, 2..2 x10, 3..3 x10
==== data frame ====
*for storing tabular data
*special type of list
*special attribute: row.names
*read.table() read.csv() return data frame
*can be converted to matrix
**but it will be coerced
*x &lt;- data.frame(foo = 1:4, bar = c(T, T, F, F))
*nrow(x)
*ncol(x)
==== convertion ====
*coercion
**finds &quot;last common denom&quot;
**y &lt;- c(1.7, &quot;a&quot;): 1.7 -&gt; &quot;1.7&quot;, &quot;a&quot; (character)
**c(T, 2) -&gt; 1, 2 (TRUE becomes 1)
**c(&quot;a&quot;, TRUE) -&gt; &quot;a&quot;, &quot;TRUE&quot; (T becomes &quot;TRUE&quot;)
*explicit
**as.* functions
**as.numeric()
**as.logical()
**as.character()
**as.complex()
**if no convertion possible, returns NA
==== missing values ====
*NaN
*NA
*is.na()
**is.na(NA) =&gt; T
**is.na(NaN) =&gt; T
*is.nan()
**is.nan(NA) =&gt; F
**is.nan(NaN) = T
*is.na(c(1, NA, 2)) =&gt; F T F
==== naming ====
*if named, will be printed with names
*vectors
**x &lt;- 1:3
names(x) =&gt; NULL
names(x) &lt;- c(&quot;foo&quot;, &quot;bar&quot;, &quot;n&quot;)
names(x) =&gt; given names
*lists
**x &lt;- list(a=1, b=2, c=3)
*matrices
**m &lt;- matrix(1:4, nrow=2, ncol=2)
dimnames(m) &lt;- list(c(&quot;a&quot;, &quot;b&quot;), c(&quot;c&quot;, &quot;d&quot;))
**m =&gt;
        c  d
a  1  3
b  2  4

=== Read/Write ===
==== tabular ====
*read
**read.table
***arguments:
****file*
****header
*****logical - variable names in the first row?
****sep
*****separator (&quot;,&quot; etc)
****colClasses
*****types of classes in each column
*****is not specified, R figures out the types
****nrows
*****number of rows to read
*****default is all the file
****comment
*****char, after which nothing is read
*****default is #
****skip
*****number of lines to skip
***data &lt;- read.table(&quot;foo.txt&quot;)
**read.csv
***same as read.table, but default separator is &quot;,&quot;
**for large files
***RTFM!
***make a rough calculation of RAM needed
****1.5 mln rows * 120 cols of numeric data
****1.5 mln * 120 * 8 bytes = 1.34 GB
****consider overhead! 1.43 * 2 ~ 2.7 GB
***comment.char = &quot;&quot; - faster
***colClasses set explicitly - much faster
****initial &lt;- read.table(&quot;db.txt&quot;, nrows=100)
classes &lt;- sapply(initial, class) #automatically figured out classes
head(initial) #just shows the fist 6 lines
tabAll &lt;- read.table(&quot;db.txt&quot;, colClasses=classes)
*write
**write.table
**write.csv
==== R objects ====
*metadata, as R source
**editable!
**good for VCS
**but not very space efficient
*read
**source
**dget
*write
**dump
**dput
*# for one variable
y &lt;- data.frame(a=1, b=&quot;a&quot;)
dput(y) =&gt; to the console
dput(y, file=&quot;y.R&quot;)
new.y &lt;- dget(&quot;y.R&quot;)
*# for several variables
x &lt;- smth, y &lt;- smth
dump(c(&quot;x&quot;, &quot;y&quot;), file=&quot;data.R&quot;)
rm(x, y) # removes x y
source(&quot;data.R&quot;) 
*Subtopic 5
==== character ====
*readLines
*writeLines
==== serialize/unserialize ====
==== File connections ====
*file
**plain file
*gzfile
**gzip
*bzfile
**bzip2
*url
**to a web page
*con &lt;- file(&quot;foo.txt&quot;, &quot;r&quot;)
data &lt;- read.csv(con)
close(con)
# the same as read.csv(&quot;foo.txt&quot;)
*con &lt;- gzfile(&quot;w.gz&quot;)
x &lt;- readLines(con, 10) #first 10 lines
*con &lt;- url(&quot;http://...&quot;, &quot;r&quot;)
x &lt;- readLines(con)

=== Accessing subsets ===
==== [ ====
*returns the same type
*starts from 1
==== [[ ====
*for lists and data frames
==== $ ====
*from lists and data frames, but using name
==== vectors ====
*x &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;c&quot;, &quot;d&quot;, &quot;a&quot;)
x[1] =&gt; a
x[1:4] =&gt; a b c d
x[x &gt; &quot;a&quot;] =&gt; b c c d
# the same:
u &lt;- x &gt; &quot;a&quot; =&gt; F T T T T F
x[u] =&gt; b c c d
#only trues
==== matrix ====
*m[row, col]
*x &lt;- matrix(1:6, 2, 3)
x[1, 2] =&gt; 3
x[2, 1] =&gt; 2
*m[1, ] =&gt; first row
*m[, 2] =&gt; secod col
*return VECTOR!
**x[1, 2, drop=F] =&gt; matrix of one element
**x[1, ,drop=F] =&gt; a matrix of one row
==== lists ====
*x &lt;- list(foo=1:4, bar=0.6)
*x[1] =&gt; sublist
$foo
[1] 1 2 3 4
*x[[1]] =&gt; (element) 1 2 3 4
*x$bar &lt;=&gt; x[[&quot;bar&quot;]] =&gt; 0.6
*x[&quot;bar&quot;] =&gt; sublist
$bar
[1] 0.6
*x[c(1, 3)] returns several cols
*name &lt;- &quot;bar&quot;
x[name] =&gt; smth
x$name =&gt; NULL! (&quot;name&quot; doesn't exist)
*x[[c(1, 3)]] =&gt; 1st list, 3th el
**the same: x[[1]][[3]]
*partial matching
**x &lt;- list(longname=1:5)
x$lo =&gt; returns $longname
x[[&quot;lo&quot;]] =&gt; NULL
x[[&quot;lo&quot;, exact=F]] =&gt; $longname
==== removing NAs ====
*bad &lt;- is.na(x)
x[!bad] #note the inversion!
*good &lt;- complete.cases(x, y)
x[good]; y[good]
*r &lt;- matrix
good &lt;- complete.cases(r)
r[good, ]
==== vectorized operations ====
*vector
**no need for looping!
**x &lt;- 1:4; y &lt;- 6:9
**x + y
**x &gt; 2
**x &gt;= 2
**y == 8
**x * y
**x / y
*matrix
**x &lt;- matrix(1:4, 2, 2)
y &lt;- matrix(rep(10, 4)), 2, 2)
**x * y =&gt; element-wise
**x / y =&gt; element-wise
**x %*% y - true matrix multiplication


== Week2 ==

=== Control Structures ===
==== conditions ====
*if (condition) {
  # smth
} else if (cond2) {
  # smth
} else {
  # smth
}
==== blocks return result ====
*y = if (x &gt; 3) {
  10
} else {
  0
}
==== loops ====
*while
**while (condition) {
  #do smth
}
*repeat
**infinite loop
**repeat {
  # smth
  if (smth) {
    break;
  }
}
*for
**for (i in 1:10) { print(i) }
**for (i in seq_lenght(nrow(x))) {
  print(x[i])
}
*next
**like continue
*break

=== Functions ===
==== high-level objects ====
*may take function as parameters, or return functions
==== declaration ====
*f = function(arg.x, arg.y, def.val = NULL) {
  4 # no need for return
}
*f = function(arg.x, ...) {
  # ... - any other arguments
  another.function(10, 20, ...)
}
==== scoping ====
*lexical scoping
*environments
**env - name-value pairs
**env can have a parent and multiple children
**env of a function - its closure
**global env
***seach() - list of packages
**local function environment
***consider make.power function
****make.power = function(n) {
  pow = function(x) {
    x ^ n 
  }
}
***cube = make.power(3)
***ls(environment(cube)) #lists variables
***get(&quot;n&quot;, environment(cube)) #returns variable n
*look up
**local env
**if not in the function env, look up in the parental
**until the top one reached
**global
==== args(f) returns list of arguments ====

=== Loop function ===
==== lapply ====
*lapply(X, FUN, ...)
*X -list, returns a list
*if X not a list, it will be coerced
*x = list(a = 1:5, b=rnorm(10))
lapply(x, mean)
==== sapply ====
*same as lapply, but simplifies the result
*if each el contains one element, result coerced to vector
*if each el of the same len, result coerced to matrix
*otherwise a list is returned
==== apply ====
*evaluates the function over the margin of array
*apply(X, MARGIN, FUN, ...)
*MARGIN: 1 for row, 2 for col
**rowSum = apply(x, 1, sum)
**rowMean = apply(x, 1, mean)
**colSum = apply(x, 2, sum)
**colMean = apply(x, 2, mean)
*apply(x, 1, quantile, probs=c(0.25, 0.75))
**apply for each row: qualtile(row, probs=c(0.25, 0.75)
==== tapply ====
*appliers for a group
*tapply(X, INDEX, FUN, ...)
*example
**x = c(rnorm(10), runif(10), rnorm(10, 1))
**f = gl(3, 10) # 1x10, 2x10, 3x10
**tapply(x, f, mean) - returns 3 means
==== split ====
*takes a vector and a factor
*splits it into groups determined by factors
*apply(X, F, ...)
*example
**x = c(rnorm(10), runif(10), rnorm(10, 1))
**f = gl(3, 10) # 1x10, 2x10, 3x10
**will return 3 groups
==== mapply ====
*multivariable apply
*mapply(FUN, ...)
*mapply(rep, 1:4, 4:1)
**rep(1, 4)
**rep(2, 3)
**rep(3, 2)
**rep(4, 1)

=== Debugging ===
==== traceback ====
*prints out stacktrace
==== debug ====
*you can step through
==== browser ====
*suspends execution for debugging
==== trace ====
*allows to insert debug code into existent functions
==== recover ====
*gets the control back


== Week3 ==

=== Simulations ===
==== generating random numbers ====
==== common prefixes ====
*d - density
*r - random number
*p - cumulative distribution
*q - quantile
==== normal ====
*rnorm
*dnorm
==== unified ====
*runif
*dunif
==== set.seed(n) ====
*ensures reproducibility
==== examples ====
*linear model
**y = B_0 + B_1 * X + E
**E ~ N(0, 4), X ~ N(0, 1), 
B_0=0.5, B_1=2
**set.seed(20)
**x = rnorm(100)
**e = rnorm(100, 0, 2)
**y = 0.5 + 2 * x + e
**plot(x, y)
==== sampling ====
*sample(1:10, 4) # 4 random numbers from 1:10
*sample(1:10) # permutation
*sample(letters, 5)
*sample(1:10, replace=TRUE) # el can be used multiple times

=== Plotting ===
==== base ====
*plot(x, y)
*params
**global
***par - global parameters (?par)
***example (margins)
****x = rnorm(100)
****y = rnorm(100)
****par(mar=c(2, 2, 2, 2))
****plot(x, y)
**plot(x, y, pch=20) # solid circles
*adding
**title(&quot;name&quot;) adds a title
**legend(&quot;topleft&quot;, legend=&quot;Data&quot;, pch=20)
**adding a line
***fit = lm(y ~ x)
***abline(fit)
***abline(fit, lwd=3, color=&quot;blue&quot;) # thick
*example(points) - built-in demos
*example
**plot(x, y, xlab=&quot;weight&quot;, ylab=&quot;height&quot;, 
main=&quot;Scatterplot&quot;, pch=20)
**several plots
***par(mfraw=c(2, 1))
***plot(x, y, pch=20)
***plot(x, z, pch=19)
*annotations
**expression
***plot(0, 0, main=expression(theta==0), 
ylab=expression(hat(gamma)==0),
xlab=expression(sum(x[i]*y[i], i==1,n))
**substitute
***xlab=substitute(bar(X)==k, list(k=mean(x))
***replaces x in the exp onto mean
==== lattice ====
*generally tale a formula
*y ~ x | f * g
**y ~ x - variables
**f * g - conditional variables
*returns an object
*example
**x = rnorm(100)
**y = x + rnorm(100, sd=0.5)
**f = gl(2, 50, labels=c(&quot;g1&quot;, &quot;g2&quot;))
**xyplot(x ~ y | f) # x vs y, split conditioned on f

=== Sorting ===
==== sort(read) ====
*returns a sorted array
==== order(read) ====
*sorts and returns a vector with ordered indexes 
**read[order(read)] == sort(read)
*order(read, prog) # 2 variables
*order(prog, -read) # reverse order
*order(prog, na.last=F) #na goes first
*order(prog, la.last=NA) # na omitted


== Week4 ==

=== Dates and time ===
==== Date class - only dates ====
==== Time ====
*POSIXct
**based on integer
*POSIXlt
**based on list
*x = Sys.time()
*p = as.POSIXlt(x)
*p$sec
==== Convertion ====
*strptime
**dates = c(&quot;January 10, 2012 10:40&quot;, &quot;December 9, 2011 10:50&quot;)
**x = strptime(dates, &quot;%B %d, %Y %H:%M&quot;)
==== Operations ====
*many operations are allowed: &lt; &gt; + - etc
*leap years, seconds etc are considered
**y = as.Date(&quot;2012-03-01&quot;)
**x = as.Date(&quot;2012-02-28&quot;)
**y - x # returns 2
*and time zones
**x = as.POSIXct(&quot;2012-10-25 01:00:00&quot;)
**y = as.POSIXct(&quot;2012-10-25 06:00:00&quot;, tz=&quot;GMT&quot;)
**x - y = 1 hour

=== Reg exps ===
==== grep ====
*grep
**returns indexes of matches
*grepl
**returns T/F vector
==== regexpr ====
*index where match begins, only first
*gregexpr - all matches
==== replacing ====
*sub
**sub(pattern, replacement)
**replaces found pattern on given string
**only first occurence
*gsub
**replaces everything
==== regmatches function ====
*for extracting results returned by regexpr
*r = regexpr(pattern, h)
*regexpr(h, r)
==== regexec ====
*regexec(pattern, d)
*returns list with matches
*if groups are used, also returned
==== example ====
*r = regexec(&quot;&lt;dd&gt;[Ff]ound on (.*?)&lt;/dd&gt;&quot;, homicides)
*m = regmatches(homicides, r)
*dates = sapply(m, function(x) x[2])
*dates = as.Date(dates, &quot;%B %d, %Y&quot;)
*hist(dates, &quot;year&quot;, freq=TRUE)

=== Classes and methods ===
==== class - description ====
==== object - instance of a class ====
==== method - operates on a certain class ====
==== generic function - for all objets ====
*don't do anything 
*only dispatches to appropriate function
==== more information ====
*?Classes, ?Methods, ?setClass, ?setMethod
==== S3 classes ====
*&quot;old-style&quot;
*mean
**UseMethod(&quot;mean&quot;)
**methods(&quot;mean&quot;) lists methods for mean
==== S4 classes ====
*&quot;new-style&quot;
*show
**StandartGeneric(&quot;show&quot;)
**ShowMethod(&quot;show&quot;)
==== dispatching ====
*gets the class
*searches for appropriate method
*if method exists, it's called
*otherwise default is called
*if no default, exception is thrown
==== example (S4) ====
*setClass - creates a new class
*slots - data stored there
**accessed via @
*setClass(&quot;polygon&quot;, representation(x=&quot;numeric&quot;, y=&quot;numeric&quot;))
*setMethod(&quot;plot&quot;, &quot;polygon&quot;,
	function(x, y, ...) {
		plot(x@x, x@y, type=n, ...)
		xp = c(x@x, x@x[1])
		yp = x(x@y, x@y[1])
		lines(xp, yp)
	}
})
*p = new(&quot;polygon&quot;, x=c(1, 2, 3, 4), y=c(1, 2, 3, 1))
*plot(p)


== Misc ==

=== Errors ===
  if (condition) {
    stop(&quot;error message&quot;)
  }

=== Proxy ===
  Sys.setenv(http_proxy=&quot;http://username:password@proxyaddress:8080&quot;)

=== Sets operations ===
  setdiff(i, j) - elements present in i, not present in j



[[Category:Coursera]]
[[Category:Programming]]
[[Category:Notes]]</text>
      <sha1>e9pwpasg1149p9rwbbmk9l8tkuj9a0x</sha1>
    </revision>
  </page>
  <page>
    <title>Refactor your Wetware</title>
    <ns>0</ns>
    <id>3</id>
    <revision>
      <id>4</id>
      <timestamp>2013-02-04T09:06:25Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15458">

Pragmatic Thinking and Learning: Refactor Your Wetware, Andy Hunt
[http://www.amazon.com/Pragmatic-Thinking-Learning-Refactor-Programmers/dp/1934356050]

* Ссылка на mind map: [http://yadi.sk/d/aJp8iwsM2Dt3O]
* Ссылка на конспект: [http://yadi.sk/d/SR1KDu7N2Dt5k]


== Dreufus model ==

=== Stages ===
* Novices
** want to know exactly how smth is done
** little/no experience
** not sure of the outcome
** don't want to learn
** want to accomplish an immediate goal
* Advanced beginners
** no holistic understanding
** little context
* Competent
** develop conceptual model
** plan deliberately
** base on past experience
** have troubles to decide what to focus on
* Proficient
** need big picture
** learn on expertise of others 
** learn on how they've done and revise
** know where to stop following rules
* Experts
** primary source of knowledge
** apply it in the right context
** work from intuituion
** have problems to articulate expertise
** rules ruin them

=== Become an expert ===
* Deliberate practice
** 10 years
** challenging but doable tasks
** with feedback
** with ability to repeat and correct errors
* 3 phases of learning
** Imitate (Shu)
*** without modification
** Assimilate (Ha)
*** reflect
** Innovate (Ri)
*** transcend


== Brain ==

=== L-mode ===
* what like
** von Neumann-like
** linear
** slow
* characteristics
** verbal
** analytic
** symbolic
** abstract
** temporal
** rational
** digital
** logical
** linear
* for
** working through details
** for white-collar information-based workers

=== R-mode ===
* what like
** non-linear
** fast
** pattern-matching
* characteristics
** needs whole picture
** intuitive
** makes insights
** non-verbal
** non-rational
** synthetic
** analogic
** intuitive
** hollistic
** non-linear
* for
** intuition
** problem solving
** creativity
** long term memory
** relating things together
* not controllable directly
* stores everything, but not everything is indexed
** you can recall when needed
* works asynchronously
* needed for becoming an expert


  only one has the access to the CPU (brain)


== Right Mind ==

=== Capture insights ===
* capture all ideas to get more of them
* how
** pen and notepad
** index cards 
** smartphones
** voice memos

=== add sensory activities ===
* activates more neural pathways
* engages more of your brain
* use cross-sensory feedback
** write down in usual form
** draw a visual metaphor
** describe it verbally
* your mind is hungry for these stimuli

=== R-to-L flow ===
* ideas
** R-mode - source of ideas
** L-mode - verification
* Metaphor
** act of creating analogies
** where L and R meet
** links abstract notions to concrete
** random juxtaposition
*** take a word and connect it to unrelated one
*** the further ideas are, the harder to join them
** cultivate humor
*** have you seen my fishbowl?
*** yes, it's just got a strike!

=== learn to be comfortable with uncertainty ===
* perfectionism may be dangerous

Think outside the box


== Harvest R-mode clues ==

=== ideas from R-mode are hard to verbalize ===

=== Image Streaming ===
* pose a problem/ask a question
* close your eyes ~10 mins
* for each image that you see
** try to see as many details as you can
** describe it out loud

=== Free-Form Journalism ===
* write as much as possible
* blog posts/letters/everything

=== [[Утренние страницы|The morning pages technique]] ===

* first thing in the morning
* while L is still sleeping
** unguarded brain dump
* write 3 pages
* by hand, no computer
* do not censor it
* do not skip a day

=== Fieldstone Method ===
* don't plan ahead
* just walk around and pick up good-looking stones
* eventually you'll collect a pile
* when it's time, find in the pile ones you like
* and use them
* once you have a pile, it's easy to build a wall

=== Harvesting by Walking ===
* do something that bores L-mode
* so R-mode frees up
* dump everything on paper
* free up your mind
* walk and don't think
** as soon as you focus, L-mode dominates
** you don't want it
* so, step away from the keyboard to solve hard problems

=== change your viewpoint ===
* look at smth in reverse
* turn the problem around
** instead of debugging for problems
** try to cause the bug
* exaggerate

=== reconcile unlike patterns ===
* 100 oblique strategies
** statements that force you to draw analogies
** &quot;what else is this like?&quot;
* Shakespeare's Brain Teaser
** new words, phrases
** unusual context for words
** unusual part of speech
** fundamental shift - makes you think


== Debug ==

=== cognitive biases ===
* anchoring
* fundamental attribution error
** &quot;rarely&quot; doesn't mean never
** Black Swans
* need for closure
** closure: we need to eliminate uncertainty
** defer closure
** the more you know - the better
** be comfortable with uncertainty
* confirmation bias
* exposure effect
* hawthorne effect
* false memory
** memory is unreliable

=== general affinity ===
* types
** risk taker vs rick adverse
** individualism vs teamwork
** stability vs freedom
** family vs work
* Mayer Briggs Type Indicator (MBTI)
** Extravert (E) vs Introvert (I)
** Sensing (S) vs Intuition (N)
*** how do you obtain information?
*** S - based on the details at the moment
*** N - imagination, intuition
** Thinking (T) vs Feeling (F)
*** how do you make decisions?
*** T - based on rules
*** F - base on emotional impact
** Judging (J) vs Perceiving (P)
*** J - early closure
*** P - don't like making decisions
** The combination defines your temperament

=== personal tendencies ===
* trust intuition, but verify
* if you feel smth, prove it
** create a prototype
** run unit tests
** benchmarks
** get the feedback!
* unittest your intuition
** how do you know?
** says who?
** how specifically?
** how does what I'm doing cause you to ... ?
** compared to what/whom?
** does it always happen? are there exceptions?
** what would happen if I did (didn't) ...?
** what stops you from ... ?
* get statistics
* expect better
* &quot;it's by logic we prove, it's by intuition we discover&quot;

=== hardware bugs ===
* most of out brain is primitive
* knee-jerk reaction - faster than brain
* let yourself think before act


== Learn ==

=== Learning ===
* ability to learn - most important element of success
* random approach without goals and feedbacks tends to random results 
* &quot;the body of knowledge&quot; isn't the most important part
* more relevant
** models you build
** questions you ask
** your experience and practice

=== Setting goals ===
* &quot;I want to be fit&quot; - vision, not a goal
* a goal needs a series of objectives
* goal - desired state
* objective - smth you do to get closer to your goal

=== SMART ===
* (S)pecific
** narrow down to something concrete
** &quot;I want to be able to write a webserver in Erlang that dynamically generates content&quot;
* (M)easurable
** how do you know when you done?
** take small bites and measure steady, incremental progress
** you have to see only 2/3 feet ahead
* (A)chievable
** need to be realistic
** attainable from where you are _now_
* (R)elevant
** are you passionate about it?
** it needs to matter
* (T)ime-boxed
** needs a deadline

=== [[Pragmatic Investment Plan]] ===
* knowledge portfolio - your skills and talents
* manage it as you would manage your financial portfolio
* relating learning to &quot;free&quot; time is a recipe for failure
* be deliberate about it
* allocate appropriate time
* use this time wisely
* be more effective in learning
* PIP
** have a concrete plan
*** be SMART
*** different goals over time
**** now
***** buy a book
**** next year
***** be proficient
**** 3 years
***** write a book
*** planning is important
**** &quot;The planning is more important than the plan. The plan will change.&quot; Eisenhower.
** diversify
*** don't put all eggs into one basket
*** consider risk vs return value
**** eg. .NET - low risk (mainstream technology), but low return on investment
**** Haskell - high risk (not mainstream), but may be the next language, and may go nowhere
*** always valuable
**** but knowledge investment always brings value
**** it may impact the way you think
**** how you solve problems
**** so everything you learn is valuable
** make active (not passive) investments
*** have feedback
*** ensure you can evaluate your plan
*** you may want to revise your plan as you go
** make regular investments
*** dollar-cost averaging
**** sometimes you pay too much
**** sometimes you get a great deal
**** it smoothes over time
*** invest a minimal amount or time
*** on regular basis
*** on average it will bring good results
* reevaluate your plan periodically
** what changed?
** what doesn't work?
** what will you do?

=== Learning modes ===
* how _you_ can learn?
* types of perception
** Visual
*** need to see material
*** picture, graphs
** Auditory
*** have to hear
*** lectures, seminars, podcasts
** Kinesthic
*** learn by moving and touching
*** need to physically experience the material
* Three-part mind
** meta-level component
*** manages thought process
** performance-based component
*** for making associations
** knowledge-acquisition component
*** assimilating new information
** each component is independent
* Frames of Mind
** Intelligence is a combination of
** Kinesthetic
*** sports
*** do-it-yourself projects
** Linguistic
*** storytelling
*** reading
*** writing
** Logical/Mathematical
*** math
*** numbers
*** science
** Visual/Spatial
*** diagrams
*** plans
*** sketching
*** paintings
** Musical
** Interpersonal
*** motivation of others
** Intrapersonal
*** self-reflectoin
*** dreams
*** relationships with others

=== Enhance ===
* Study groups
** informal
*** just agree to read through a book
*** and discuss
** formal
*** deliberate steps:
*** select a proposal and its leader
*** buy books
*** schedule meetings
* SQ3R
** Survey
*** scan the table of contents
*** see for overview
** Question
*** note every question you have
*** will I learn technology X?
** Read
*** read entirely
** Recite
*** summarize
*** take notes
*** rephrase
*** invent acronyms to help you remember
** Review
*** reread
*** expand notes
*** discuss with colleagues 
* Mind maps
** diagrams that shows topics and how they are connected
** notetaking
*** raw notes - while listening
*** then transfer to &quot;official&quot; notes
** should be hand-written
*** start with messy mind-map
*** then reorganize and redraw
** exercise
*** take 4-5 items bullet list
*** draw a mind map
*** wait a day
*** enhance it with colors
*** review a week later
** good for 
*** brainstorming
*** exploring
*** collaboration
* Documentation
** documenting may be more important than documentation
** mental preparation
*** turns on your attention
*** gets insight
** you may take time to create a screen cast
* Learn by teaching
** clarifies your own understanding
** try to explain it to smb
** even if it's an yellow rubber duck
** constant retrieval of information is very effective for learning
** preparation is also very important (see documentation)


== Experience ==

you have to learn by doing

=== play in order to learn ===
* explore and build mental models
* constructivism
** we build to learn
** not learn to build
* don't be afraid of mistakes
** they provide feedback
* make a game out of learning
** flashcards
** lego blocks

=== problem? ===
* can you break it down into smaller meaningful parts?
* is it like others?
* can you adapt other situations to match it?
** i.e. leverage existent knowledge
** danger: beware of differences

=== failures ===
* after a failure
** we study what happened
** what went wrong
** learn how to fix it
* it's important to get it right _last_ time (first is not that important)
* ensure safety
** freedom to experiment
** ability to backtrack to a stable state
** ability to demonstrate progress
* 2 types of failures
** we can learn from them
** we cannot learn from them
* allow failures
** pressure shuts your mind down
** your vision narrows
** so give yourself permission to fail
** you don't necessarily have to make errors
** create &quot;failure permitted&quot; zones

=== Imagination overrides senses ===
* that can improve your perfomance
* always be the worst
** be in the company with smarter people
** you'll mimic others
* groove your mind for success
* scaffolding
** make smth help you do smth
*** swimmers + rope
** you'll adjust to higher speed/etc
** unscaffolding
*** then it'll be easier to handle under usual circumstances
*** work in C++ after ruby and then get back


== Focus ==

=== focus and attention ===
* attention - act of focusing in
* your attention - a short supply
* when we say &quot;we don't have time&quot; we mean &quot;we're running out of attention&quot;
* meditation
** allocates attention
** Vipassana meditaion
*** you're aware
*** but don't render judgements
*** and don't making responses
** technique
*** find a quiet spot
*** sit in a comfortable posture, with a straight back
*** become aware of any tension and let it go
*** close eyes and focus on breath
*** be aware of the rhythm of your breath
**** don't try to change it
*** focus on nothing else but breath
*** if you wander off, let thoughts go and focus back
* learn to pay attention

=== knowledge ===
* information - raw data
* knowledge - meaning for the information
* manage your knowledge
** input (raw data)
*** ideas
*** insights
** processing
** output
*** processed and transcended
* you need to work with the material
** organize 
** develop
** coalesce disparate
** refine
** from general to specific
* exocortex (external support)
** book collection
** notes
** etc
* personal wiki
** knowledge and information management
** good wiki feels like a mind map
** by organizing your ideas you'll get more of them
** wiki gardening
*** rearranging/refactoring your wiki

=== optimizing the context ===
* context - things you're focusing on at the moment
* context switching is very expensive!
** 20-40% of productivity eaten by switching contexts
* manage interruptions deliberately
** use virtual desktops


== To do ==

=== Effective change ===
* convince your brain that it's important and do it
* you have to care
* practice makes permanent
* keep a beginner's brain

=== Possible actions ===
* Keep something with you for notetaking
* Make more metaphors
** how can you describe your current project?
* See connections between unconnected things
** 100 oblique strategies
* Do morning pages (at least for 2 weeks) [[Утренние страницы]]
* Write down concrete goals, long-term and short-term
* Add 2 new areas into your portfolio, diversify
* Experiment with different learning models
* Next time you read, use mind maps
* Start a study group
* Experiment with meditation, 20 mins a day
* Use virtual desktops

=== approach ===
* start with a plan
* keep track on what's done
* retrospect
* take some steps
* cultivate new habbits
* just start!

=== Books ===
* Tools of critical thinking: Metathoughts for Psychology
* Dan Pink, A whole new mind
* Drawing on the right side of the brain, B. Edwards
* The Einstein Factor: A proven new method for increasing you intelligence
* Process Patterns for Personal Practice: How to succeed in developing without really trying
* Relating Work and Education, VF72
* Knowledge and Competence, BW90
* Knowledge Hydrant: a pattern language for study groups
* Effective Study, Rob70
* Beyond Closed Doors: Secrets of Great Management
* How to Solve It: a new aspect of mathematical method; How to solve problems
* Consciousness explained: David Dennett</text>
      <sha1>4vvsjwylo5k5zqu8uf009unnmid6cw9</sha1>
    </revision>
  </page>
  <page>
    <title>Learn More Study Less (book notes)</title>
    <ns>0</ns>
    <id>4</id>
    <revision>
      <id>5</id>
      <timestamp>2013-03-15T12:32:45Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9462">Learn More, Study Less [http://www.scotthyoung.com/learnmorestudyless/]

* Ссылка на mindmap: [http://yadi.sk/d/ql-NYWYr2DuDw]
* Ссылка на конспект: [http://yadi.sk/d/bjnCnPtW2DuGk]

== Main concepts ==

=== Constructs ===
* set of interlinked understandments
* when building constructs, you need to create as many links as possible

=== Models ===
* simplified contructs
* compresses information
* visualization

=== Highways ===
* linking between isolated constructs
* creativity, thinking &quot;outside of the box&quot;


== Sequence of Learning ==

=== Acquire ===
* information enters
** reading
** taking notes
** personal exprerimes
* goals
** simplicity
*** lowest amount of redundancy
** volume
*** the more the better
** speed
*** works against simplicity and volume
* Test: Have I seen this idea before?

=== Understand ===
* comprehension
* taking the raw information and giving it context
* most basic interlinking
* Test: Do I get what it means?

=== Explore ===
* linking what you just learned to other concepts
* forming models to simplify and expand your constructs
* highways
* making well defined constructs
* types
** Depth exploration
*** links into the information
*** where does it come from?
*** how it was made?
*** not just understand the formula - understand the proof
*** disadvantage: requires lots of researching
** Lateral exploration
*** links around the information
*** What formulas are similar to?
*** What discoveries were made at the same time?
*** What other facts surrounding it?
*** requires less research but needs more creativity
** Vertical exploration
*** finding patters
*** Can I compare it to a natural event?
* Techniques
** Metaphor
** Visceralization
** Diagramms
* Test
** Do I understand where it comes from?
** What it's related to? 
** What outside ideas can be connected to?

=== Debug ===
* looking for errors in models and highways
* adding exceptions
* finding faults and contradictions
* how
** seek information in other soursces
*** better in ones which oppose your views
** testing it in the real world
* the only way to debug - is to practice
* Test
** Have I removed bad links between the idea and other ideas?
** Have I removed false conclusion?

=== Apply ===
* how this operation operates in reality
* here the learning becomes complete
* Test: Have I used this idea in my practical life?

=== Test ===
* continuous testing
* all the steps to be accompanied by testing
* allow to track your weaknesses
* you can improve on them


== Information Structure ==

=== Arbitrary ===
* lots of facts, dates, definitions
* have no logical (obvious) grouping
* the hardest to remember
* dealing
** make it less arbitrary - find a pattern
** linking
** pedding
** compression

=== Opinion ===
* essays/presentations at school
* look for patterns
* dealing
** speed reading
** diagramming

=== Process ===
* based on some background
* eg
** writing a program
** builing a house
** designing a protptype
* practice is the most important element
* dealing
** visceralization
** metaphor
** diagramming
** model debugging

=== Concrete ===
* tangible
* easy to visualize
* have practical usage

=== Abstract ===
* lacks the obvious connection to the real world
* eg
** Maths
** Physics
** CS
* Complete opposite of Arbitrary
** difficult to understand
** patters are logical
* dealing
** Visceralization
** metaphor


== Techniques ==

=== Aquiring ===

==== Speed Reading ====
* use a pointer
* practice reading
* measures
** wpm - words per minute
** comprehension
*** read for 3 minutes
*** write down every major idea/fact
**** without looking back at the book
*** go through it again and make a second list of ideas
*** c = (correct - incorrect) / (total number of facts)

==== Active reading ====
* write heading and subheadings for the chapter
* after each section make a few notes
** major points
** how can I remember them?
** how I can extend and apply them?
* forces you to create links
** metaphor
** visualization
* makes you go beyond it and apply this in different context
* so it forces you to move each major point through
** understanding
** exploring
** application
* example: classical conditioning
** Major Points
*** discovered by Ivan Pavlov
*** connects a stimulus with a response
** I remember it by
*** picturing Pavlov's dogs droding at the sound of bell
** I extend it by
*** remembering how I feel compelled to answer the phone when hearing the same ringtone

==== Flow-Based Notetaking ====
* goal - build a surface for connecting ideas as they're reaching you
* uses fluid formar
* major ideas are written in several words
** not entire sentence
* connect them using arrows
* hybrids
** Flow-Based Afternotes
*** take regular notes
*** afterwards reform them into flow-based
*** gives readability and understanding
*** but requires more time
** Flow-Based Commenting
*** for dense information flow
*** writing down the key info
*** inserting notes when there's a break

=== Linking Ideas ===

==== Metaphor ====
* for abstract
* describing an object by linking it to smth irrelevant
* bridge between familiar topic and unfamiliar
* how
** indentify the information
** find smth in your experience that matches a part of this idea
*** couple of imperfect matches would do
** repeat and check for circumstances where it doesn't applu
* improve
** ask yourself for a metaphor
** pick the first thing that comes to mind
** refine and test your metaphors
** repeat
** collect multiple metaphors that explore ideas from different angles

==== Visceralization ====
* process of creating a mental image
* connects ideas with emotions
* works best for concrete information
* experimental
* how
** identify the concept
** pick a mental image to base this idea from 
*** make a draft on paper
** Static/Dynamic?
*** visualize it moving
** add other sences
** refine and repeat until you can bring it just in a few seconds of thinking

==== Diagramming ====
* a simpler form of visceralization
* a diagram - picture, connecting several ideas together
* Flow-Based Diagrams
** sequence of steps, events; a system
** how
*** start with a single element
*** draw connection arrow to different ideas
*** for understanding - not for picture
**** less than 2 minutes!
* Concept-Based Diagrams
** start with the most important with branch off into details
* Image Diagrams
** not a diagram
** rather a doodle
** to represent idea, association to others
** 10-20 seconds

=== Arbitrary ===

==== Linking ====
* close to rote memorization
* links a series like a linked list
* Step1. Create you sequence
** write it down
** or beak it down into a sequence
* Step2. Symbolize each in the list
** create a symbol to associate with each element
*** a in a formula =&gt; apple
** the symbol helps conjure the original concept
* Step3. Create the links
** vivid and exaggerating image that connects two adjacent items
** banana and cow =&gt; big banana with cow spots
* Imagination is needed!

==== Pegging ====
* no need to be in sequence
* link each element to a specific slot
** 0 - hero
** 1 - gun
** 2 - shoe
** 3 - tree
** 4 - door
** 5 - hive
** 6 - sticks
** 7 - heaven
** 8 - plate
** 9 - wine
** 10 - pen
** 11 - ribbon
** 12 (dozen) - oven
** note the rhyming
* eg
** a bottle of wine is fighting with a knige
** a knife is a symbol of labor
** the 9th principle is the division of labor

==== Information Compression ====
* reduces size, so it can be associated together in a logical way
* Mnemonics
** storing several ideas together by using a phrase/word
** RED (first aid)
*** R - Rest the injured area
*** E - Elevate the injured ared
*** D - apply the direct pressure
* Picture linkung
** link several ideas by representing them in one picture
** done on paper
* Notes compression
** take a lot of information
** reduce it to just a few pages of notes
** organizes large amounts of data
** easier to connect ideas by looking at the entire sctructure
** how
*** take several sheets of paper
*** write down major ideas
*** next to it write relevant formulas/concepts etc
*** continue until you've written down all the major ideas
*** you may rewrite it for better organization

=== Extending ===
* Practice
** apply everything you learned in your life
** if you don't know how - do brainstorm
* Model Debugging
** practice regularly
** look for potential errors
** make it timed
*** split practice into daily intervals
* Project-Based Learning
** have a 1-3 month project
** it forces you to learn
** keep it small
** write it down
*** commit to your project on paper
** set a goal
*** objective outcome

== Final ==

=== Productivity Websites ===
* ScottHYoung.com - My website devoted to productivity, learning and habits.
* ZenHabits.net - Productivity through simplicity.
* Lifehack.org - One of the largest productivity websites.
* PickTheBrain.com - Productivity and motivation.
* StudyHacks – Productivity for the student
* StevePavlina.com – Personal development for smart people.

=== Productivity Books ===
* Getting Things Done - The classic by David Allen.
* The Power of Full Engagement - Energy management.
* Zen To Done - A spin off of Getting Things Done, this one focuses on slowly building productive habits.
* How to Be a Straight-A Student &amp; How to Win at College – Both classic books that can help you become more productive and handle the challenges of learning. Definitely worth reading!


[[Category:Books]]
[[Category:Notes]]
[[Category:Productivity]]</text>
      <sha1>iri3mhzf7s4rylzd64qipkgpsexgk6x</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Notes</title>
    <ns>14</ns>
    <id>5</id>
    <revision>
      <id>6</id>
      <timestamp>2013-01-30T10:36:52Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="30">Notes from books, classes, etc</text>
      <sha1>e76n9feheu0xf126nznrjcfm50uyaha</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Coursera</title>
    <ns>14</ns>
    <id>6</id>
    <revision>
      <id>7</id>
      <timestamp>2015-06-26T08:23:01Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="62">Courses с coursera

[[Category:Education]]
[[Category:Notes]]</text>
      <sha1>siv0oktwarxt95yuym09fzqgnghkntd</sha1>
    </revision>
  </page>
  <page>
    <title>Semantic Web</title>
    <ns>0</ns>
    <id>7</id>
    <revision>
      <id>8</id>
      <timestamp>2014-05-02T17:07:01Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6063">== Semantic Web ==
Semantic Web is a web that is used to represent knowledge
* Semantic Webs - part of Knowledge Representation, AI
* principles: be able to describe things in document in machine-processable way
* [[RDF]] is the main tool for representing knowledge in Semantic Web

What we currently have in WWW:
* mostly have links of the form $a \ \text{href} \ b$
* what we want: $A \ \text{dependsOn} \ a$, $a \ \text{isDescribedBy} \ b$, etc -
** i.e. we want links to have some meaning behind
** so we can use semantic web and [[Ontologies]] for that


=== DIKW ===
DIKW [http://en.wikipedia.org/wiki/DIKW_Pyramid]: data $\to$ information $\to$ knowledge $\to$ wisdom $\Rightarrow$ decision 
* D - just collecting data, smb enters data into a web app - just values
* I - databases (RDBs, XML, etc) - now you have some structure
** but also know when it was collected, by whom, etc - i.e. with some metadata
* K - reports, analysis - to facilitate decision making
* W - to increase effectiveness 
* see also [http://semanticabyss.blogspot.fr/2009/03/dikw-hierarchy-data-information.html]

http://upload.wikimedia.org/wikipedia/en/9/93/DIKW.png


== Smart Web of Linked Data ==
So the goal is to have machine-readable linked data. We want to have &quot;Smart Web&quot; - linked and consistent.
* fundamental issue of the web: how to manage distributed data 


=== Motivation: Integration === 
Data integration and distribution
* suppose that two servers share the same tables
* but tables have different schemas 
* how do we know that one columns in first db corresponds to another one in second?
* so we need some coordination between the servers, like global reference
* so represent each cell of these tables with 3 values
** global reference for row
** global reference for column
** global reference for the value in the cell 
* such cells can be stored on any of these servers 
* this is the basic idea of [[RDF]]
* and global references are URIs


Smart Managing of Data
* rows are &quot;things&quot; (or entities or individuals)
* columns specify properties of these things
* if a cell references some other &quot;thing&quot;, the meaning of this relation can be understood from the name of the column
* can express this in a more meaningful form - with reference where this meaning is described
* so the &quot;things&quot; are resources that can relate to other resources
* to describe these things and relations, use URIs 


=== Linked Data ===
Linked Open Data: a giant graph 
* all these sources provide RDF data
* every circle - a source of data, the bigger - the more articles it has 
* the bigger the arrow - the more links from one source to another
* http://lod-cloud.net/versions/2011-09-19/lod-cloud_colored_300px.png
* http://dbpedia.org - the main hub in LOD
** gets data from wikipedia:
** http://en.wikipedia.org/wiki/Birmingham $\to$  http://dbpedia.org/resource/Birmingham


Other Sources:
* Freebase, UMBEL, YAGO2, OpenCyc
* Geography: Geonames, LinkedGeoData; EuroStat, World Factbook, US Census, Ordnance
Survey
* Media: BBC (/programmes, /music), WildlifeFinder, New York Times, Thomson Reuters: Open Calais (Named Entities extracted from text)
* Social Media: Open Graph Protocol (Facebook), Internet Movie Database
* Libraries American Lib. of Congress, GermanNational Lib. of Economics, LIBRIS, SwedishNat. Union Catalogue, OpenLibrary
* Scholarly articles (journal, conferences): DBLP, ACM, RKBexplorer, SemanticWeb, DogfoodServer
* Many others - see http://linkeddata.org and http://lod-cloud.net/


==== Linked data principles ====
These principles are recommendation - best practices 
* use URIs to talk about things 
* HTTP URIs are better so people can access them 
* when somebody uses this URI, make use of standards ([[RDF]], [[SPARQL]]) to describe things
* include links to other resources 

Links
* relationship links - point to related links (inside/outside)
* identity links - point to other resources that describe the same concept (in OWL: owl:sameAs)
* vocabulary links - definition of used terms 


=== Main Assumptions ===
==== AAA Slogan ====
Main slogan for the web and the semantic web:
* AAA - Anyone can say Anything about Any topic 
* consequence: there always can be something else that somebody can say 

==== Open World Assumption ====
Open World assumption
* a consequence of the AAA slogan
* at any time some new information can appear


== Semantic Modeling  ==
How to model data in such a way so it's good for the web scale 
* need to explain things in understandable way
* and then be able to reuse it 
* need to be formal so machines can understand it, and '''logical inference''' is possible
* Result of modeling: [[Ontologies]]


Semantic Web provides a number of modeling languages with different degree of expressivity:
* [[RDF]] - resource definition framework
** the basic mechanism to make basic statements about anything
* [[RDFS]] - schema for RDF, expresses classes, subclasses and properties
* [[RDFS-Plus]] - a subset of OWL, more expressive than RDFS, less complex than OWL
* [[OWL]] - logics of Semantic Web, models detailed constraints between classes, properties and entities

Formal foundation for RDFS and OWL:
* [[First Order Logic]]
* [[Description Logic]]


=== Logical Inference ===
{{ main | Inference in Semantic Web }}

[[RDFS]] and [[OWL]] allow new tuples to be created from facts asserted in the database


== [[Semantic Web/Application Architecture]] ==
How to use the SW in your applications?
* tools, storage, parsers/serializers, etc


== Links ==
* [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.121.6980&amp;rep=rep1&amp;type=pdf Data Semantics: Data Integration and the Semantic Web]
* http://www.cambridgesemantics.com/semantic-university/what-makes-a-good-semantic-web-application
* [http://www.few.vu.nl/~jui200/papers/ISWC09-Urbani.pdf Scalable Distributed Reasoning using MapReduce]
* [http://www.cs.cf.ac.uk/Dave/AI2/node102.html Distributed Reasoning]


== Sources ==
* [[Semantic Web for the Working Ontologist (book)]]
* [[XML and Web Technologies (UFRT)]]

[[Category:Semantic Web]]</text>
      <sha1>q42x7ub7bfvaiin2l426e0yq2p673ny</sha1>
    </revision>
  </page>
  <page>
    <title>Pragmatic Investment Plan</title>
    <ns>0</ns>
    <id>8</id>
    <revision>
      <id>9</id>
      <timestamp>2013-02-01T14:55:32Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1539">

* knowledge portfolio - your skills and talents
* manage it as you would manage your financial portfolio
* relating learning to &quot;free&quot; time is a recipe for failure
* be deliberate about it
* allocate appropriate time
* use this time wisely
* be more effective in learning


== Have a concrete plan ==
* be [[Refactor your Wetware#SMART|SMART]]
* different goals over time
** now
*** buy a book
** next year
*** be proficient
** 3 years
*** write a book
* planning is important
** &quot;The planning is more important than the plan. The plan will change.&quot; Eisenhower.
 
== Diversify ==
* don't put all eggs into one basket
* consider risk vs return value
** eg. .NET - low risk (mainstream technology), but low return on investment
** Haskell - high risk (not mainstream), but may be the next language, and may go nowhere
* always valuable
** but knowledge investment always brings value
** it may impact the way you think
** how you solve problems
** so everything you learn is valuable

== Active investments ==
* have feedback
* ensure you can evaluate your plan
* you may want to revise your plan as you go

== Regular investments ==
* dollar-cost averaging
** sometimes you pay too much
** sometimes you get a great deal
** it smoothes over time
* invest a minimal amount or time
* on regular basis
* on average it will bring good results

== Reevaluate your plan periodically ==
* what changed?
* what doesn't work?
* what will you do?



== Ссылки ==
[[Refactor your Wetware#Pragmatic Investment Plan]]


[[Category:Productivity]]</text>
      <sha1>5dy12xe8wlwbkovd4pp1rkjr93ac0vy</sha1>
    </revision>
  </page>
  <page>
    <title>Personal Knowledge Management</title>
    <ns>0</ns>
    <id>9</id>
    <revision>
      <id>10</id>
      <timestamp>2013-02-03T16:34:24Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4499">Personal Knowledge

Mind map: [http://yadi.sk/d/f1pfNItl2KXsR]

== Knowledge ==

* derived from information
* distilled
* extracted from sources
* what one has learned 

data/information is not knowledge until we dig the value out of it


== Information Literacy ==

=== definition ===
* ability to know when there's a need for information
* to be able to identify, locate, evaluate and effectively use that information
* for the problem at hand

=== schemata (Big6) ===
* locating
** basic questions
*** what is known about the topic?
*** what information is needed?
*** where can it be found?
** finding sources of information
* selecting/analyzing
** examining the resources
** separating useful from not useful
* organizing/synthesizing
** selected information is organized
** knowledge and solutions are developed
** facts vs opinions
** comparisons
** organizing ideas logically
* creating/presenting
** presentation to an appropriate audience
** a paper
* evaluating
** critical evaluation of completion
** was it solved?
** was the knowledge found?
** could I do it differently?
** what was well?

=== standards ===
* information literacy
** asses information effectively and efficiently
** evaluate critically and completely
** use information accurately and creatively
* independent learner
** information literate
** peruses information related to personal interests
** excellent in information seeking and knowledge generating
* social responsibility
** contribute to learning community
** participates in groups to peruse information and generate knowledge


== Knowledge management ==

KM - making the best use of knowledge

=== processes ===
* acquiring
* creating
* sharing

=== KM ===
* cognitive science
* expert systems, AI
* knowledge base management systems
* groupware
* document managing
* etc

=== objectives ===
* enhance collaboration
* capture and store best practices
* e-learning
* web-publishing

=== goals ===
* identify
* create
* represent
* distribute
* enable adoption of
* insights and experiences
* and transform it into knowledge

=== knowledge ===
* tacit
** internal
* explicit
** in form that can be communicated to others

* KM converts knowledge from tacit to explicit

=== strategies ===
* push
** people publish their note into repository, for further access
* pull
** publish per request


== Personal Information Management ==

=== goal: to ease the process of ===
* acquire
* organize
* maintain
* retrieve
* use

=== sources ===
* documents
* web pages
* emails

=== main idea ===
* we always have needed information at hand


== Personal Knowledge Management ==

* bottom-up approach to Knowledge Management
* PKM integrates KM and PIM (personal information management)
* for expanding cognitive capabilities of individuals


=== process of ===
* gather
* classify
* store
* search
* retrieve
* share
* information

=== Wright's Model ===
* analytical
** interpretation
** envisioning
** application
** creation
** contextualization
* information
** sourcing
** assessment
** organization
** aggregation
** communication
* social
** collaboration with people
** development networks
* learning
** pattern recognition
** reflection
** development of new knowledge

=== Skills ===
* reflection
* continuous improvement
* manage learning
** how to learn
* informational literacy
** what is important
** how to find it
* organizational
** categorization
** taxomonies
* communication and interaction
* creativity


== Personal Knowledge Base ==

=== PKB ===
* personal
** for a particular individual, others should not care
* knowledge
** consists of knowledge, not information
* base
** consolidated knowledge store
** easy to access

=== knowledge capture tools ===
* mind mapping
** diagrams to visually outline information
** major categories radiate from central node
** free form
** spatial layout
** a tree
** guidelines - see @ wiki
** uses
*** generate, visualize, classify ideas
*** aids for students
*** problem solving
*** summarizing
* concept mapping
** based on assimilation theory of knowledge
*** newly encountered knowledge must be related to prior knowledge
** CM depicts these connections graphically
** links are labeled
*** typically with a verb phrase
* hyperlink systems
** non-linear dynamic hyperdocument
** piece of text linked together
* note-taking

=== benefits ===
* knowledge generation of formulation
* knowledge capture
* knowledge management and retrieval
* integration heterogenous sources


[[Category:Productivity]]</text>
      <sha1>sb3emcdw04f49it3vjjcxa7sixk0hr4</sha1>
    </revision>
  </page>
  <page>
    <title>Lateral Thinking</title>
    <ns>0</ns>
    <id>10</id>
    <revision>
      <id>11</id>
      <timestamp>2013-03-01T14:12:03Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1502">
Topic: Lateral Thinking

solving problems through an indirect and creative approach


== types of thinking tools ==
* idea generating tools
** to break current thinking patterns
* focus tools
** to broaden where to search for ideas
* harvest tools
** to receive more output from idea generation
* treatment tools
** to consider real-world constraints, resources, etc

== idea generating tools ==
=== Random entry ===
* a thinker chooses an object at random
* eg. an entry from a dictionary
* and tries to link it to the current problem
=== Provocation ===
* provocation techniques
** wishful thinking
** exaggerating
** reversal
* the thinker makes a list of provocations
* then uses the most outlandish ones
* to move thinking forward
=== Challenge ===
* &quot;why?&quot;
* answer leads to fresh ideas
* goal: be able to challenge absolutely everything
=== Concept fan ===
* expand the range and number of concepts
* end up with a very broad range of ideas to consider
=== Disproving ===
* &quot;majority is always wrong&quot;
* take the opposite view, try to disprove it

== 6 thinking hats of de Bono ==

== further reading ==

* De Bono Edward, &quot;Lateral thinking: creativity step by step&quot;, http://books.google.com/books?id=H-ROAAAAMAAJ
* De Bono Edward, &quot;Po: Beyond Yes and No&quot;
* De Bono Edward, &quot;Serious creativity: using the power of lateral thinking to create new ideas&quot;, http://books.google.com/books?id=NbB9AAAAMAAJ

== Ссылки ==

* http://en.wikipedia.org/wiki/Lateral_thinking


[[Category:Productivity]]</text>
      <sha1>0c14my70dgk9o5ky5tikd5ixiub0e7b</sha1>
    </revision>
  </page>
  <page>
    <title>Conditional Probability</title>
    <ns>0</ns>
    <id>11</id>
    <revision>
      <id>12</id>
      <timestamp>2015-07-05T16:32:11Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2663">== Conditional Probability ==
''Conditional Probability'' $P(B \mid A)$ (or $P_A (B)$) is the probability that $B$ happens provided that $A$ has already happen.

The conditional probability is calculated by the following formula:
* $P(B  \mid  A) = \cfrac{P(A \land B)}{P(A)}$


=== Intuition ===
Suppose that there are two events $A$ and $B$ 
* $A$ and $B$ are not independent 
* $A$ may happen before $B$ or $B$ may happen before $A$ 
* what the probability that both $A$ and $B$ happen? 

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/ru/bayesian-formula.png
* $P(A \land B) = P(A) \cdot P(B \mid A) = P(B) \cdot P(A \mid B)$
* it's either $A$ happens first and then $B$ happens (given that $A$ has happened)
* or $B$ happens first and then $A$ happens (given that $B$ has happened)
* these probabilities are equal
* thus we can calculate $P(A \mid B)$ as 
** $P(A \mid B) = \cfrac{P(A) \cdot P(B \mid A)}{P(B)}$
* how to calculate $P(B)$ if we only have the information from the left?
* $P(B) = P(A) \cdot P(B \mid A) + P(\overline{A}) \cdot P(B  \mid  \overline{A})$


== Examples ==
=== Example 1 ===
В урне находятся три красных и три синих шара. Вытащим два шара. Какая вероятность появления красного шара, если при первом извлечении выл вытащен синий?

* Пусть событие &lt;math&gt;A&lt;/math&gt; - извлечение синего шара, а &lt;math&gt;B&lt;/math&gt; - красного.
* Тогда найдем &lt;math&gt;P(B \mid A) = \frac{P(AB)}{P(A)}&lt;/math&gt;
* &lt;math&gt;P(AB)&lt;/math&gt; - вероятность вытащить красный и синий. Общее число исходов - это число [[Partial Permutations|размещений]] 2 по 6, т.е. &lt;math&gt;A^2_6 = 6 \cdot 5 = 30&lt;/math&gt;. Из 30 событию &lt;math&gt;AB&lt;/math&gt; благоприятствуют 9, поэтому &lt;math&gt;P(AB)=\frac{9}{30}&lt;/math&gt;
* &lt;math&gt;P(A)&lt;/math&gt; - вероятность вытащить синий шар, &lt;math&gt;P(A) = 1 / 2&lt;/math&gt;
* &lt;math&gt;P(B \mid A) = \frac{P(AB)}{P(A)} = \frac{9 / 30}{1 / 2} = \frac{3}{5}&lt;/math&gt;


== See Also ==
* [[Law of Total Probability]] 
* [[Bayes Rule]]

== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.
* [https://www.dropbox.com/s/j9yxtvkd0ns5eot/Probability_and_Statistics_exams_c.pdf#9 Конспект по теории вероятности и математической статистике]

[[Category:Russian]]
[[Category:Probability]]</text>
      <sha1>837w8eh55zl49i4dsbqp3eqb22sp804</sha1>
    </revision>
  </page>
  <page>
    <title>Law of Total Probability</title>
    <ns>0</ns>
    <id>12</id>
    <revision>
      <id>13</id>
      <timestamp>2013-08-01T10:09:44Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3288">== Law of Total Probability ==

Пусть &lt;math&gt;A&lt;/math&gt; может наступить при условии появления одного из событий &lt;math&gt;B_1, B_2, ..., B_n&lt;/math&gt;, образующих полную группу событий. Пусть известны вероятности этих событий &lt;math&gt;P(B_1), P(B_2), ..., P(B_n)&lt;/math&gt; а так же условные вероятности &lt;math&gt;P(A|B_1), P(A|B_2), ..., P(A|B_n)&lt;/math&gt; наступления события &lt;math&gt;A&lt;/math&gt; после каждого из &lt;math&gt;B_1, ..., B_n&lt;/math&gt;. 


'''Теорема.''' Probability события &lt;math&gt;A&lt;/math&gt;, которое может произойти лишь при появлении одного из несовместных событий &lt;math&gt;B_1, B_2, ..., B_n&lt;/math&gt;, образующих полную группу, есть

&lt;math&gt;P(A) = P(B_1) P(A|B_1) + P(B_2) P(A|B_2) + ... + P(B_n) P(A|B_n)&lt;/math&gt;


Эту формулу называют ''формулой полной вероятности'' (следует из [[Условная вероятность|определения условной вероятности]]).


=== Доказательство ===
Т.к. &lt;math&gt;B_1, B_2, ..., B_n&lt;/math&gt; несовместные, то появление &lt;math&gt;A&lt;/math&gt; означает появление одного из &lt;math&gt;B_1 A, B_2 A ..., B_n A&lt;/math&gt;. 

По теореме сложения получим 
: &lt;math&gt;P(A) = P(B_1 A) + P(B_2 A) + ... + P(B_n A)&lt;/math&gt;

И, применяя теорему умножения к каждому из членов суммы, получим
: &lt;math&gt;P(A) = P(B_1) P(A|B_1) + P(B_2) P(A|B_2) + ... + P(B_n) P(A|B_n)&lt;/math&gt;.


=== Пример ===
В магазин поступают продукты с трех предприятий в соотношении 20%, 30%, 50%. С первого предприятия приходит 10% продуктов высшего сорта, со второго - 5%, с третьего - 20%. Какая вероятность того, что случайно купленный продукт высшего сорта?

* Пусть событие &lt;math&gt;B_i&lt;/math&gt; - покупка продукта с предприятия &lt;math&gt;i&lt;/math&gt;. 
* Тогда &lt;math&gt;P(B_1) = 0.2&lt;/math&gt;, &lt;math&gt;P(B_2) = 0.3&lt;/math&gt; и &lt;math&gt;P(B_3) = 0.5&lt;/math&gt;. 
* &lt;math&gt;A&lt;/math&gt; - покупка продукта высшего сорта. 
* Тогда &lt;math&gt;P(A|B_1) = 0.1&lt;/math&gt;, &lt;math&gt;P(A|B_2) = 0.05&lt;/math&gt; и &lt;math&gt;P(A|B_3) = 0.2&lt;/math&gt;. 
* По формуле полной вероятности получаем
: &lt;math&gt;P(A) = \sum_{i = 1}^{3} P(B_i) P(A|B_i) = 0.135&lt;/math&gt;


== See also ==
* [[Conditional Probability]]
* [[Bayes Rule]]


== Источники и ссылки ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.
* [https://www.dropbox.com/s/j9yxtvkd0ns5eot/Probability_and_Statistics_exams_c.pdf#13 Конспект по теории вероятности и математической статистике]

[[Category:Russian]]
[[Category:Probability]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>1jdolbzqz15sezecqgnxcmgwd9gt1mj</sha1>
    </revision>
  </page>
  <page>
    <title>Eclipse settings</title>
    <ns>0</ns>
    <id>13</id>
    <revision>
      <id>14</id>
      <timestamp>2014-02-05T13:16:04Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="153">== eclipse.ini ==

 -Duser.name=Grigorev Alexey
 -Xms512m
 -Xmx1024m
 -XX:MaxPermSize=256m


[[Category:Java]]
[[Category:Eclipse]]
[[Category:Snippets]]</text>
      <sha1>6qfk8pn8zib31z6agzeopu8qcxbtibs</sha1>
    </revision>
  </page>
  <page>
    <title>Sublime Tricks</title>
    <ns>0</ns>
    <id>14</id>
    <revision>
      <id>15</id>
      <timestamp>2013-02-27T11:29:35Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="552">

== Новые горячии клавиши ==

Например, 

=== оборачивание тегом math ===

preferences - key binding (user)

 [
  { &quot;keys&quot;: [&quot;alt+shift+m&quot;], &quot;command&quot;: &quot;insert_snippet&quot;, &quot;args&quot;: { &quot;name&quot;: &quot;Packages/mediawiki/math-tag.sublime-snippet&quot; } }
 ]

Packages/mediawiki/math-tag.sublime-snippet:

 &amp;lt;snippet&amp;gt;
     &amp;lt;content&amp;gt;&amp;lt;![CDATA[&amp;lt;math&amp;gt;${2:$SELECTION}&amp;lt;/math&amp;gt;]]&amp;gt;&amp;lt;/content&amp;gt;
     &amp;lt;scope&amp;gt;math&amp;lt;/scope&amp;gt;
     &amp;lt;description&amp;gt;Math Tag&amp;lt;/description&amp;gt;
 &amp;lt;/snippet&amp;gt;</text>
      <sha1>iwna5i2iq6cx571hl6y1tc7xlhmfw0o</sha1>
    </revision>
    <revision>
      <id>669</id>
      <parentid>15</parentid>
      <timestamp>2015-11-16T10:44:47Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="924">== Hotkeys Binding ==
=== Tag Wrapping ===
Go to &quot;preferences -&gt; key binding (user)&quot;

 [
  { &quot;keys&quot;: [&quot;alt+shift+m&quot;], &quot;command&quot;: &quot;insert_snippet&quot;, &quot;args&quot;: { &quot;name&quot;: &quot;Packages/mediawiki/math-tag.sublime-snippet&quot; } }
 ]

Create `Packages/mediawiki/math-tag.sublime-snippet`:

 &amp;lt;snippet&amp;gt;
     &amp;lt;content&amp;gt;&amp;lt;![CDATA[&amp;lt;math&amp;gt;${2:$SELECTION}&amp;lt;/math&amp;gt;]]&amp;gt;&amp;lt;/content&amp;gt;
     &amp;lt;scope&amp;gt;math&amp;lt;/scope&amp;gt;
     &amp;lt;description&amp;gt;Math Tag&amp;lt;/description&amp;gt;
 &amp;lt;/snippet&amp;gt;


You don't need to create an XML file, and can pass arguments directly to snippets: [https://www.sublimetext.com/forum/viewtopic.php?f=6&amp;t=2314]

&lt;pre&gt;
[
  {&quot;keys&quot;: [&quot;alt+q&quot;], &quot;command&quot;: &quot;insert_snippet&quot;, &quot;args&quot;: {&quot;contents&quot;: &quot;&amp;lt;code&gt;${0:$TM_SELECTED_TEXT}&amp;lt;/code&amp;gt;&quot;}},
  {&quot;keys&quot;: [&quot;alt+w&quot;], &quot;command&quot;: &quot;insert_snippet&quot;, &quot;args&quot;: {&quot;contents&quot;: &quot;&amp;lt;pre&gt;${0:$TM_SELECTED_TEXT}&amp;lt;/pre&amp;gt;&quot;}}
]
&lt;/pre&gt;




[[Category:Snippets]]</text>
      <sha1>jqmh7gmw79saz2m6mn0icur40pp900x</sha1>
    </revision>
    <revision>
      <id>670</id>
      <parentid>669</parentid>
      <timestamp>2015-11-16T11:54:50Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1168">== Hotkeys Binding ==
=== Tag Wrapping ===
Go to &quot;preferences -&gt; key binding (user)&quot;

 [
  { &quot;keys&quot;: [&quot;alt+shift+m&quot;], &quot;command&quot;: &quot;insert_snippet&quot;, &quot;args&quot;: { &quot;name&quot;: &quot;Packages/mediawiki/math-tag.sublime-snippet&quot; } }
 ]

Create `Packages/mediawiki/math-tag.sublime-snippet`:

 &amp;lt;snippet&amp;gt;
     &amp;lt;content&amp;gt;&amp;lt;![CDATA[&amp;lt;math&amp;gt;${2:$SELECTION}&amp;lt;/math&amp;gt;]]&amp;gt;&amp;lt;/content&amp;gt;
     &amp;lt;scope&amp;gt;math&amp;lt;/scope&amp;gt;
     &amp;lt;description&amp;gt;Math Tag&amp;lt;/description&amp;gt;
 &amp;lt;/snippet&amp;gt;


You don't need to create an XML file, and can pass arguments directly to snippets: [https://www.sublimetext.com/forum/viewtopic.php?f=6&amp;t=2314]

&lt;pre&gt;
[
  {&quot;keys&quot;: [&quot;alt+q&quot;], &quot;command&quot;: &quot;insert_snippet&quot;, &quot;args&quot;: {&quot;contents&quot;: &quot;&amp;lt;code&gt;${0:$TM_SELECTED_TEXT}&amp;lt;/code&amp;gt;&quot;}},
  {&quot;keys&quot;: [&quot;alt+w&quot;], &quot;command&quot;: &quot;insert_snippet&quot;, &quot;args&quot;: {&quot;contents&quot;: &quot;&amp;lt;pre&gt;${0:$TM_SELECTED_TEXT}&amp;lt;/pre&amp;gt;&quot;}}
]
&lt;/pre&gt;

== Spell Checking ==

Add this to &quot;settings -&gt; user&quot; to enable spell checking for English [https://www.sublimetext.com/docs/2/spell_checking.html]

&lt;pre&gt;
{
  &quot;spell_check&quot;: true,
  &quot;dictionary&quot;: &quot;Packages/Language - English/en_US.dic&quot;
}
&lt;/pre&gt;



[[Category:Snippets]]</text>
      <sha1>2765z7ik5nsvkqcu8u6agum7r8mkbnu</sha1>
    </revision>
  </page>
  <page>
    <title>Game Theory (coursera)</title>
    <ns>0</ns>
    <id>15</id>
    <revision>
      <id>16</id>
      <timestamp>2014-01-16T07:03:51Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="795">{{draft}}

Курс [https://www.coursera.org/course/gametheory Game Theory] об основах теории игр


== [[Game Theory]] == 
=== Games by Form ===
* [[Normal Form Game]]
* [[Extensive Form Game]]
* [[Mixed-Strategy Game]]
* [[Repeated Game]]
* [[Coalitional Game]]
* [[Bayesian Game]]

=== By Type ===
* [[Pure Competition Game]]
* [[Cooperation Game]]


== Info ==
* Ссылка на svn директорию [http://stolzen.googlecode.com/svn/trunk/courses/coursera/Game%20Theory/]
* Отсканированный конспект [https://www.dropbox.com/s/vo6nbmhdvzs2947/Game%20Theory%20coursera.pdf]
* mindmap [http://stolzen.googlecode.com/svn/trunk/courses/coursera/Game%20Theory/Game%20Theory.xmind]


[[Category:Game Theory]]
[[Category:Coursera]]
[[Category:Notes]]</text>
      <sha1>oy108jtz2sdx35jc1rhyasmf0lg6qzk</sha1>
    </revision>
  </page>
  <page>
    <title>Game Theory</title>
    <ns>0</ns>
    <id>16</id>
    <revision>
      <id>17</id>
      <timestamp>2014-01-16T07:38:16Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2568">== Game Theory ==
In Game Theory the decision of a decision maker and its consequences are based on somebody else's decisions


=== Game ===
A ''game'' is a ''strategic interaction'' (in economics, social studies, networking, etc) between two or more ''self-interested agents''

Each agent has his/her own opinions and preferences

The ''outcome'' of a game depends on what all agents do
* what actions a game player takes?
* all users act in the same way?
* is there a global behavior pattern?
* if players can communicate, what effect it will have?
* repetitions?
* does it matter if opponents are rational?


Example:
* Suppose we have two airline companies $P_1$ and $P_2$
* They are both thinking about about opening a new destination 
* Both consider two options: either make tickets cheap or make them expensive 
* Clearly if $p_1$ decides to sell cheap tickets while $p_2$ - to sell expensive tickets, everybody will buy from $p_1$

So we can depict it with the following pay-off matrix
* a cell represents consequences of the decision that both players take

{| class=&quot;wikitable&quot;
! $p_2 \leftarrow$ &lt;br/&gt; $p_1 \downarrow$ || 500 || 200 
|-
! 500 
| (50, 100) || (-100, 200)
|-
! 200 
| (150, -200) || (-10, -10)
|}

We see that:
* if both agree on cheap tickets - both will have profits
* if $p_2$ sells expensive tickets and $p_1$ cheap ones, all go to $p_1$ and $p_2$ will have losses
* the same with $p_1$ and $p_1$
* if both decide on expensive tickets - nobody will buy them and they both will experience losses

This is a variation of the [[Prisoner's Dilemma]], an example of [[Normal Form Game]]


=== Types of Games ===
There are many types of games:
* [[Normal Form Game]] (also Strategic Game)
* [[Extensive Form Game]]
* [[Mixed-Strategy Game]]
* [[Repeated Game]]
* [[Coalitional Game]]
* [[Bayesian Game]]


=== Rationality ===
It is often assumed that agents behave rationally:
* a ''rational agent'' wants to maximize the consequence (utility, etc)
* There are some important principles:
* The [[Dominance]] principle (same as [[Unanimity]]) [[Iterative Removal]]
* [[Nash Equilibrium]]


=== Examples ===
Paradoxes
* [[Prisoner's Dilemma]]

[[Pure Competition Game]]s
* [[Matching Pennies]] (also &quot;Head or Tail&quot; game)

[[Cooperation Game]]s
* [[Coordination Game]]

General Games
* [[Battle of the Sexes]]

Other
* [[Cournot Duopoly Model]]
* [[Bertrand Duopoly Model]]
* [[Median Voter Theorem]] (also known as the [[Allocation Problem]])

== Sources ==
* [[Decision Engineering (ULB)]]
* [[Game Theory (coursera)]]

[[Category:Game Theory]]</text>
      <sha1>lrtowq2vv35j1ib1g9sw92btq0qo146</sha1>
    </revision>
  </page>
  <page>
    <title>Computing for Data Analysis</title>
    <ns>0</ns>
    <id>17</id>
    <revision>
      <id>18</id>
      <timestamp>2013-03-14T09:07:42Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="74">#перенаправление [[Computing for Data Analysis (coursera)]]</text>
      <sha1>9uln0mdn8xg42n0zuk3lpdcjn8d4tjd</sha1>
    </revision>
  </page>
  <page>
    <title>Algorithms Design and Analysis Part 1 (coursera)</title>
    <ns>0</ns>
    <id>18</id>
    <revision>
      <id>19</id>
      <timestamp>2013-12-10T20:53:24Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="746">
== Analysis ==
* [[Big O]]

== [[Divide and Conquer]] ==
* [[Divide and Conquer#Multiplication|Gauss Multiplication Algorithm]]
* [[Divide and Conquer#The Master Method|Master Method]]
* [[Merge Sort]]
* [[Quick Sort]]

== [[Graphs]] ==
* [[Graphs]]
* [[Minimal Cut Problem]]


=== [[Graph Search]] ===
* [[Breadth-First Search]] 
* [[Depth-First Search]]
** [[Topological Ordering]]
** [[Strongly Connected Components]]
* [[Dijkstra's Shortest Path]]


== Data Structures ==
* [[Heap]]
* [[Binary Search Trees]]
** [[Red-Black Trees]]
* [[Hash Tables]]
* [[Bloom Filters]]


== Links ==
* [https://www.dropbox.com/s/ai43yfm1jwcoog2/Algorithms%201%20coursera.pdf  Lecture Notes]


[[Category:Coursera]]
[[Category:Algorithms]]
[[Category:Notes]]</text>
      <sha1>l7h5687puseru547ofgdzrjjagckf6d</sha1>
    </revision>
  </page>
  <page>
    <title>Greatest Common Divisor</title>
    <ns>0</ns>
    <id>19</id>
    <revision>
      <id>20</id>
      <timestamp>2013-07-23T13:47:23Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3804">== Greatest Common Divisor ==

''Общий делитель'' чисел &lt;math&gt;a_1, a_2, ..., a_n&lt;/math&gt; - число, делящее все числа &lt;math&gt;a_1, a_2, ..., a_n&lt;/math&gt; без остатка.

=== Алгоритм ===

# Представим каждое число, как произведение его простых множителей и запишем их ввиде степеней
# Выпишем делители, общие для всех чисел
# Выберем наименьшую степень каждого из них
# Посчитаем результат

=== Пример ===

&lt;math&gt;168 = 2^3 \cdot 3^1 \cdot 7^1&lt;/math&gt;

&lt;math&gt;180 = 2^2 \cdot 3^7 \cdot 5^1&lt;/math&gt;

&lt;math&gt;3014 = 2^4 \cdot 3^3 \cdot 7^1&lt;/math&gt;

&lt;math&gt;GCD(168, 180, 3014) = 2^3 \cdot 3^1 = 12&lt;/math&gt;

== Алгоритм Евклида ==

Дано: числа &lt;math&gt;m&lt;/math&gt; и &lt;math&gt;n&lt;/math&gt;. Найти: наибольший общий делитель этих чисел

=== Алгоритм ===

# разделим &lt;math&gt;m&lt;/math&gt; на &lt;math&gt;n&lt;/math&gt;, &lt;math&gt;r&lt;/math&gt; - остаток от деления
# если &lt;math&gt;r = 0&lt;/math&gt;, то n - искомое значение
# если &lt;math&gt;r \neq 0&lt;/math&gt;, то &lt;math&gt;m = n&lt;/math&gt;, &lt;math&gt;n = r&lt;/math&gt; и пока &lt;math&gt;r&lt;/math&gt; не станет равной нулю

=== Доказательство ===

'''Во первых''', алгоритм всегда сходится.
'''Во вторых''', на каждой из итераций имеем:

1. &lt;math&gt;m = n \cdot q_1 + r_1&lt;/math&gt;

2. &lt;math&gt;n = r_1 \cdot q_2 + r_2&lt;/math&gt;

3. &lt;math&gt;r_1 = r_2 \cdot q_3 + r_3&lt;/math&gt;

...

k+1. &lt;math&gt;r_{k-1} = r_k \cdot q_{k+1} + r_{k+1}&lt;/math&gt;

k+2. &lt;math&gt;r_k = r_{k+1} \cdot q_{k+2} + 0&lt;/math&gt;


'''На первом шаге''': 

Допустим, что &lt;math&gt;c = GCD(m, n)&lt;/math&gt;.

Тогда 
&lt;math&gt;m = c \cdot d_m&lt;/math&gt;,
&lt;math&gt;n = c \cdot d_n&lt;/math&gt;,
где &lt;math&gt;d_m&lt;/math&gt; и &lt;math&gt;d_n &lt;/math&gt;- некоторые целые числа.

Значит, &lt;math&gt;r_1 = m - n q_1 = c \cdot (d_m - d_n \cdot q_1&lt;/math&gt;)

Т.е. &lt;math&gt;r_1&lt;/math&gt; тоже делится на &lt;math&gt;c&lt;/math&gt;


'''На &lt;math&gt;i&lt;/math&gt;-том шаге''': точно так же, &lt;math&gt;r_i&lt;/math&gt; делится на &lt;math&gt;c&lt;/math&gt;.


'''Последний шаг''': 
Т.к. остаток от деления на этом шаге 0, то &lt;math&gt;r_k = c = GCD(m, n)&lt;/math&gt;

'''Q.E.D.'''

== Greatest Common Divisor вычитанием ==

=== Алгоритм ===

# из большего числа вычитаем меньшее
# если получается 0, то числа равны - возвращаем одно из них


Вычетание &lt;math&gt;q&lt;/math&gt; раз - это то же самое, что взять остаток от деления на &lt;math&gt;q&lt;/math&gt;.


== Обобщенный алгоритм Евклида (Соотношения Безу) ==

Дано: числа &lt;math&gt;m&lt;/math&gt; и &lt;math&gt;n&lt;/math&gt;

Найти: НОД для &lt;math&gt;m&lt;/math&gt; и &lt;math&gt;n&lt;/math&gt; &lt;math&gt;d = GCD(m, n)&lt;/math&gt; и два числа &lt;math&gt;a&lt;/math&gt; и &lt;math&gt;b&lt;/math&gt; таких, что &lt;math&gt;am + bn = d&lt;/math&gt;

=== Алгоритм ===

# Инициализация:
#: $a' = 1$, $b = 1$
#: $a = 0$, $b' = 0$
#: $c = m$, $d = n$
# $c = qd + r$
#: $q$ - частное, $r$ - остаток от деления $c$ на $d$.
# $r = 0$? имеем $am + bn = d$
# $r \neq 0$?
#: повторяем итерацию
#: $c = d$, $d = r$
#: $t = a$', $a' = a$, $a = t - qa$
#: $t = b$', $b' = b$, $b = t - qb$


Доказательство: см. Кнут, т.1 стр. 33

== Sources ==
* Д. Кнут &quot;Искусство Программирования&quot;, т. 1


[[Category:Russian]]
[[Category:Algorithms]]
[[Category:Discrete Mathematics]]</text>
      <sha1>5muuisqixzekgarx4ko5l0bjbkkn2nh</sha1>
    </revision>
  </page>
  <page>
    <title>Программа поступления в ШАД</title>
    <ns>0</ns>
    <id>21</id>
    <revision>
      <id>22</id>
      <timestamp>2013-04-27T20:43:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10681">Программа для поступления в Школу анализа данных

== Алгебра ==

# [[Подстановки]]. Определение подстановки, четность подстановок. Произведение подстановок, разложение подстановок в произведение транспозиций и независимых циклов. 
# [[Комплексные числа]]. Геометрическое изображение, алгебраическая и тригонометрическая форма записи, извлечение корней, корни из единицы.
# [[Системы линейных уравнений]]. Прямоугольные матрицы. Приведение матриц и систем линейных уравнений к ступенчатому виду. Метод Гаусса.
# Линейная зависимость и ранг. Линейная зависимость строк (столбцов). Основная лемма о линейной зависимости, базис и ранг системы строк (столбцов). Ранг матрицы. Критерий совместности и определенности системы линейных уравнений в терминах рангов матриц. Фундаментальная система решений однородной системы линейных уравнений.
# [[Определители|Определитель]]. Определитель квадратной матрицы, его основные свойства. Критерий равенства определителя нулю. Формула разложения определителя матрицы по строке (столбцу).
# Операции над матрицами. Операции над матрицами и их свойства. Теорема о ранге произведения двух матриц. Определитель произведения квадратных матриц. Обратная матрица, ее явный вид (формула), способ выражения с помощью элементарных преобразований строк.
# Векторные пространства; базис. Векторное пространство, его базис и размерность. Преобразования координат в векторном пространстве. Подпространства как множества решений систем однородных линейных уравнений. Связь между размерностями суммы и пересечения двух подпространств. Линейная независимость подпространств. Базис и размерность прямой суммы подпространств.
# Линейные отображения и линейные операторы. Линейные отображения, их запись в координатах. Образ и ядро линейного отображения, связь между их размерностями. Сопряженное пространство и сопряженные базисы. Изменение матрицы линейного оператора при переходе к другому базису.
# Билинейные и квадратичные функции. Билинейные функции, их запись в координатах. Изменение матрицы билинейной функции при переходе к другому базису. Ортогональное дополнение к подпространству относительно симметрической билинейной функции. Связь между симметрическими билинейными и квадратичными функциями. Существование ортогонального базиса для симметрической билинейной функции. Нормальный вид вещественной квадратичной функции. Закон инерции.
# Собственные векторы и собственные значения. Собственные векторы и собственные значения линейного оператора. Собственные подпространства линейного оператора, их линейная независимость. Условие диагонализируемости оператора.



== Математический анализ ==
# [[Пределы и непрерывность]]. Пределы последовательностей и функций. Непрерывные функции.
# [[Ряды]]. Числовые и функциональные ряды. Признаки сходимости (Даламбера, Коши, интегральный, Лейбница). Абсолютно и условно сходящиеся ряды.
# [[Дифференцирование]]. Дифференцирование функций. Применение производной для нахождения экстремумов функций. Формула Тейлора.
# [[Интегрирование]]. Определенный и неопределенный интегралы. Методы интегрирования функций. Первообразные различных элементарных функций.



== Комбинаторика ==
# Основные правила комбинаторики. [[Правила суммы и произведения|Правило подсчета количества комбинаторных объектов]]. [[Pigeonhole Principle]]. Примеры.
# [[Sets]]. Круги Эйлера, операции на множествах. Формула включений и исключений. Примеры.
# [[Combinations]]. [[Partial Permutations]], [[Permutations|перестановки]] и [[Combinations|сочетания]]. [[Binomial Theorem]]. [[Combinations#Треугольник Паскаля|Треугольник Паскаля]]. [[Combinations#Combinations с повторениями|Combinations с повторениями]].

== Теория вероятностей ==
# [[Probability|Основные понятия теории вероятностей]]. Определение вероятностного пространства, простейшие дискретные случаи (выборки с порядком и без него, упорядоченные и неупорядоченные), [[Probability#Классическое определение вероятности|классическая вероятностная модель]]. [[Случайная величина]], [[Случайная величина#Закон распределения|функция распределения]].
# [[Условная вероятность|Условные вероятности]]. Определение условной вероятности, [[Law of Total Probability]], [[Bayes Theorem|формула Байеса]].
# [[Математическое ожидание]], [[Дисперсия|дисперсия]], [[Корреляция|корреляция]]. Определение математического ожидания, дисперсии, ковариации и корреляции, их свойства.
# [[Independence]]. Попарная независимость и независимость в совокупности. ([[Chain and Sum Rules in Probability]].)
# Основные теоремы теории вероятностей. [[Chebyshev's Inequality]]. [[Laws of Large Numbers]]. [[Центральная предельная теорема]].
# Распределения. Стандартные дискретные и непрерывные распределения, их математические ожидания, дисперсии и свойства:
#* [[Биномиальное распределение|биномиальное]];
#* [[Равномерное распределение|равномерное]];
#* [[Нормальное распределение|нормальное]];
#* [[Poisson Distribution|пуассоновское]];
#* [[Exponential Distribution|показательное]];
#* [[Геометрическое распределение|геометрическое]].

== Программирование, алгоритмы и структуры данных ==

(предполагается владение одним из основных языков программирования, предпочтительным является C/C++)

# Простейшие конструкции языка программирования. Циклы, ветвления, рекурсия.
# Анализ алгоритмов. Понятие о сложности по времени и по памяти. Асимптотика, О-символика. Инварианты, пред- и пост- условия. Доказательство корректности алгоритмов.
# Простейшие структуры данных. Массивы, стеки, очереди, связные списки. Сравнение временных затрат при различных типах операций.
# Строки и операции над ними. Представление строк. Вычисление длины, конкатенация, быстрый поиск подстрок.
# Сортировки. Нижняя теоретико-информационная оценка сложности задачи сортировки. Алгоритмы сортировки вставками, пузырьком, быстрая сортировка, сортировка слиянием. Оценка сложности.
# Указатели. Указатели и динамическое управление памятью.


== Ссылки ==

* [http://shad.yandex.ru/admission/ Как поступить в Школу Яндекса]
* [http://download.yandex.ru/company/schad_programm.pdf Программа для поступления]


[[Category:Russian]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>kfo7zec3taxfqx1a2feg44xjrfnw2yb</sha1>
    </revision>
  </page>
  <page>
    <title>Pigeonhole Principle</title>
    <ns>0</ns>
    <id>22</id>
    <revision>
      <id>23</id>
      <timestamp>2013-08-01T10:07:29Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4447">== Принцип кроликов и клеток ==

Если в &lt;math&gt;N&lt;/math&gt; клетках сидят не менее &lt;math&gt;N + 1&lt;/math&gt; кроликов, то в какой-то из клеток сидит не менее 2-х кроликов. 

Данное утверждение носит называние ''принцип Дирихле''. Доказывается методом от противного: если бы в каждой клетке сидело не более одного кролика, то в N клетках сидело бы не более &lt;math&gt;N&lt;/math&gt; кроликов -- противоречие. 

Более общая формулировка принципа:

Если в &lt;math&gt;n&lt;/math&gt; коробок положить &lt;math&gt;k&lt;/math&gt; предметов и &lt;math&gt;k &gt; n&lt;/math&gt;, то существует хотя бы одна коробка, в которой находится не менее 2-х предметов. 

== Обобщённый принцип Дирихле ==
Если &lt;math&gt;pn + 1&lt;/math&gt; предметов поместить в n коробок, то хотя бы одна из них будет содержать &lt;math&gt;p + 1&lt;/math&gt; предметов.

== Задачи ==

=== Задача 1 ===
В лесу растёт 1 млн ёлок и известно, что на каждой из них не более 600 тыс иголок. Доказать, что в лесу найдутся хотя бы две ёлки с одинаковым количеством иголок.

* 1 000 000 ёлок (предметов)
* 600 001 ящиков - на каждой из ёлок &lt;math&gt;0 \leqslant k \leqslant 600 000&lt;/math&gt; иголок
* Т.к. предметов больше, чем ящиков, то в каком-то ящике находится более одного предмета. 

=== Задача 2 ===
Доказать, что среди 6-ти целых чисел найдутся два числа, разность которых делится на 5. 

* 5 коробок: { 0, 1, 2, 3, 4, 5 } - остатки от деления на 5,
* Если распределить числа по коробкам, то в одной коробке окажется два числа,
* Следовательно, существует как минимум два числа с одинаковым остатком от деления на 5, 
* Тогда разность этих чисел делится на 5.

=== Задача 3 ===
Доказать, что для любого &lt;math&gt;n \in \mathbb{N}&lt;/math&gt;, &lt;math&gt;n \geqslant 1&lt;/math&gt; существует &lt;math&gt;k \in \mathbb{N}&lt;/math&gt;, состоящее только из чисел 0 и 5, такое, что оно делится на &lt;math&gt;n&lt;/math&gt;.

* &lt;math&gt;a_1 = 50, a_2 = 5050, a_n = \underbrace{5050..50}&lt;/math&gt; (&lt;math&gt;n&lt;/math&gt; раз)
* Распределим эти предметы по коробкам &lt;math&gt;s_i \in \{0, 1, ..., n-1\}&lt;/math&gt;
* В коробку &lt;math&gt;s_i&lt;/math&gt; помещаем число &lt;math&gt;a_k&lt;/math&gt; если оно имеет остаток от деления равный &lt;math&gt;i&lt;/math&gt;
* Если в &lt;math&gt;s_0&lt;/math&gt; находится 1 предмет - то задача решена.
* Иначе, &lt;math&gt;n - 1&lt;/math&gt; коробке находится &lt;math&gt;n&lt;/math&gt; предметов, следовательно существует два числа, имеющих одинаковы остаток от деления на &lt;math&gt;n&lt;/math&gt;
* Т.к. разность двух чисел, состоящих их 5 и 0 тоже состоит из 5 и 0, то разность этих двух чисел и есть ответ.

=== Задача 4 ===
В доме 40 человек. Существует ли такой месяц, когда хотя бы 4 ученика празднует свои дни рождения?

* Коробки - месяцы (12 шт)
* Предметы - люди (40 = 12 * 3 + 4)
* Существует коробка по крайней мере с 3 + 1 предметами

== Sources ==
* Генкин С.А., Итенберг И.В., Фомин Д.В. Ленинградские математические кружки, 1994.
* Pigeonhole Principle, http://bars-minsk.narod.ru/teachers/dirichle.html

[[Category:Russian]]
[[Category:Combinatorics]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>spzk4uo0m7aha5oqdw8brh9r9nfktp7</sha1>
    </revision>
  </page>
  <page>
    <title>The Rules of Sums and Products (Combinatorics)</title>
    <ns>0</ns>
    <id>23</id>
    <revision>
      <id>24</id>
      <timestamp>2013-08-01T10:07:04Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3505">== Правило суммы ==
Если элемент &lt;math&gt;a&lt;/math&gt; можно выбрать &lt;math&gt;m&lt;/math&gt; способами, и элемент &lt;math&gt;b&lt;/math&gt; - &lt;math&gt;n&lt;/math&gt; способами, то выбор &quot;или &lt;math&gt;a&lt;/math&gt; или &lt;math&gt;b&lt;/math&gt;&quot; можно произвести &lt;math&gt;m + n&lt;/math&gt; способами.

=== Обобщенное правило суммы ===
Если некоторое способы выборки элемента &lt;math&gt;a&lt;/math&gt; совпадают со способами выбора элемента &lt;math&gt;b&lt;/math&gt;, то такую выборку можно совершить &lt;math&gt;m + n - k&lt;/math&gt; способами, где &lt;math&gt;k&lt;/math&gt; - число совпадающих способов для &lt;math&gt;a&lt;/math&gt; и &lt;math&gt;b&lt;/math&gt;.

== Правило произведения ==
Если элемент &lt;math&gt;a&lt;/math&gt; можно выбрать &lt;math&gt;m&lt;/math&gt; способами, и элемент &lt;math&gt;b&lt;/math&gt; - &lt;math&gt;n&lt;/math&gt; способами, то пару &lt;math&gt;(a, b)&lt;/math&gt; можно выбрать &lt;math&gt;m \cdot n&lt;/math&gt; способами. (Пара &lt;math&gt;(a, b)&lt;/math&gt; отличается от пары &lt;math&gt;(b, a)&lt;/math&gt;).


== Задачи ==

=== Задача 1 ===
В алфавите 33 буквы. Сколько слов, содержащих 5 букв можно составить так, чтобы не было двух идущих подряд одинаковых букв?

* Первую букву можно выбрать 33 способами
* Остальные можно выбрать только 32 способами, т.к. не может быть двух одинаковых букв, идущих подряд.
* Ответ: 33 * 32 * 32 * 32 * 32

=== Задача 2 ===
Сколькими способами можно поставить на шахматную доску размера 8 * 8 белую и черную ладьи так, чтобы они не били друг друга?

* 64 - 1-ю ладью можно поставить на любую клетку
* 49 - ладья 1 бьёт 14 полей и на одном стоит, поэтому остается 64 - 15 полей
* Ответ: 64 * 49

=== Задача 3 ===
Сколькими способами можно поставить 2х королей на шахматную доску 8 * 8?

Рассмотрим несколько случаев
* Если король стоит в углу, то он бьёт 3 поля и стоит на одном - остается 60 клеток для второго;
* Если король стоит на краю доски, но не в углу (24 поля), то он бьёт 5 полей и стоит на одном - остается 58 клеток;
* Если не на краю доски (36 полей), то он бьёт 8 полей и стоит на одном - остается 55 клеток. 

Ответ: 4 * 60 + 24 * 58 + 36 * 55

== Sources ==

* Виленкин Н.Я. Комбинаторика. М., Наука, 1969.
* Генкин С.А., Итенберг И.В., Фомин Д.В. Ленинградские математические кружки, 1994.
* Виленкин Н.Я., Комбинаторика. Статья в журнале &quot;Квант&quot;, 1 номер 1971 год.  http://kvant.mccme.ru/1971/01/kombinatorika.htm 

[[Category:Russian]]
[[Category:Combinatorics]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>aaspktf0jcwtmk7ohmnqfl8rt8xwuj7</sha1>
    </revision>
  </page>
  <page>
    <title>Sets</title>
    <ns>0</ns>
    <id>24</id>
    <revision>
      <id>25</id>
      <timestamp>2013-08-01T10:06:54Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11464">== Sets ==

''Множество'' - совокупность различных предметов объединённых в одно целое по некоторому признаку.

Объекты, из которых состоит множество, называют ''элементами'' множества. Во множестве не может быть более одного одинакового элемента.

* &lt;math&gt;a \in A&lt;/math&gt; - элемент a принадлежит множеству $A$
* &lt;math&gt;a \notin A&lt;/math&gt; - элемент a не принадлежит множеству $A$


''Пустое множество'' - множество, не содержащее ни одного элемента. Обозначается &lt;math&gt;\varnothing&lt;/math&gt;

Sets делят на ''конечные'' множества (например, число жителей города Биробиджана) и на ''бесконечные'' (число точек на отрезке).

=== Способы задания ===

* Перечисление:
: $A = \{a_1, a_2, ..., a_n\}$

* Характеристические свойства:
: $A = \{ x | P(x) \}$, где &lt;math&gt;P(x)&lt;/math&gt; - свойство, которым обладают элементы &lt;math&gt;x \in A&lt;/math&gt; и не обладают &lt;math&gt;x \notin A&lt;/math&gt;. 
: Например, &lt;math&gt;X = \{x | x^2 - 3x + 2 = 0\}&lt;/math&gt;

=== Подмножества ===
Если каждый элемент множества &lt;math&gt;A&lt;/math&gt; является так же и элементом множества &lt;math&gt;B&lt;/math&gt;, то &lt;math&gt;A&lt;/math&gt; - ''подмножество'' &lt;math&gt;B&lt;/math&gt;. Обозначается &lt;math&gt;A \subset B&lt;/math&gt;. 

Каждое непустое множество &lt;math&gt;A&lt;/math&gt; имеет хотя бы два подмножества: само &lt;math&gt;A&lt;/math&gt; и &lt;math&gt;\varnothing&lt;/math&gt;. Эти множества являются ''несобственными'' подмножествами &lt;math&gt;A&lt;/math&gt;, а все остальные подмножества (если существуют) - ''собственными''. 

Если &lt;math&gt;A \subset B&lt;/math&gt; и &lt;math&gt;B \subset C&lt;/math&gt;, то &lt;math&gt;A \subset C&lt;/math&gt;. Т.е. свойство быть подмножеством удовлетворяет условию ''транзитивности''. 

Если &lt;math&gt;A \subset B&lt;/math&gt; и &lt;math&gt;B \subset A&lt;/math&gt;, то &lt;math&gt;A&lt;/math&gt; и &lt;math&gt;B&lt;/math&gt; ''равны''.

''Универсальное множество'' &lt;math&gt;U&lt;/math&gt; - множество, включающее все возможные элементы. Т.е. для любого множества &lt;math&gt;A&lt;/math&gt;, &lt;math&gt;A \subset U&lt;/math&gt;.

== Круги Эйлера ==
''Круги Эйлера'' - геометрическая схема для наглядного изображения отношения между подмножествами.


== Операции ==

=== Пересечение ===
''Пересечением'' (произведением) множеств &lt;math&gt;A&lt;/math&gt; и &lt;math&gt;B&lt;/math&gt; называется множество, состоящее из элементов, принадлежащих одновременно и &lt;math&gt;A&lt;/math&gt; и &lt;math&gt;B&lt;/math&gt;. 

&lt;math&gt;A \cap B = \{ x | x \in A \mbox{~and~} x \in B\}&lt;/math&gt;

=== Объединение ===
''Объединением'' (сложением) &lt;math&gt;A&lt;/math&gt; и &lt;math&gt;B&lt;/math&gt; является множество всех элементов, принадлежащих хотя бы &lt;math&gt;A&lt;/math&gt; или &lt;math&gt;B&lt;/math&gt;. 

&lt;math&gt;A \cup B = \{ x | x \in A \mbox{~and~} x \in B\}&lt;/math&gt;

=== Разность ===
''Разностью'' &lt;math&gt;A&lt;/math&gt; и &lt;math&gt;B&lt;/math&gt; называют множество, состоящее из всех элементов, не принаджежащих &lt;math&gt;B&lt;/math&gt; и принадлежащих &lt;math&gt;A&lt;/math&gt;. 

&lt;math&gt;A \backslash B = \{ x | x \in A \mbox{~or~} x \notin B\}&lt;/math&gt;

''Симметричной разностью'' &lt;math&gt;A&lt;/math&gt; и &lt;math&gt;B&lt;/math&gt; называют множество, принадлежащее либо &lt;math&gt;A&lt;/math&gt;, либо &lt;math&gt;B&lt;/math&gt;, но не сразу и &lt;math&gt;A&lt;/math&gt; и &lt;math&gt;B&lt;/math&gt;.

''Дополнением'' множества А до универсального множества U называют множество всех элементов не принадлежащих множеству A и обозначается &lt;math&gt;\bar{A}&lt;/math&gt;.

&lt;math&gt;\bar{A} = U \backslash A = \{ x | x \in A \mbox{~and~} x \notin U \}&lt;/math&gt;

=== Декартово произведение ===
Декартовым произведением множеств &lt;math&gt;A&lt;/math&gt; и &lt;math&gt;B&lt;/math&gt; называют множество таких упорядоченных пар &lt;math&gt;(a, b)&lt;/math&gt;, что &lt;math&gt;x \in A, y \in B&lt;/math&gt;:

&lt;math&gt;A \times B = \{ (x, y) | x \in A, y \in B \}&lt;/math&gt;

Пусть задано &lt;math&gt;n&lt;/math&gt; множеств &lt;math&gt;X_1, X_2, ..., X_n&lt;/math&gt;. Декартовым произведением &lt;math&gt;X_1 \times X_2 \times ... \times X_n&lt;/math&gt; называют множество возможных упорядоченных наборов &lt;math&gt;\alpha = (x_1, x_2, ..., x_n)&lt;/math&gt;, таких, что &lt;math&gt;x_1 \in X_1, x_2 \in X_2, ..., x_n \in X_n&lt;/math&gt;:

&lt;math&gt;X_1, X_2, ..., X_n = \{ (x_1, x_2, ..., x_n) | x_i \in X_i, i = 1, ..., n \}&lt;/math&gt;

Каждый набор &lt;math&gt;\alpha = (x_1, x_2, ..., x_n)&lt;/math&gt; называется кортежем длины &lt;math&gt;n&lt;/math&gt;, составленный из элементов множества &lt;math&gt;X^n = X \times X \times ... \times X&lt;/math&gt;. Элемент &lt;math&gt;x_i&lt;/math&gt; называется &lt;math&gt;i&lt;/math&gt;-ой компонентой кортежа.

Отличия кортежа от множества:
* во множестве порядок не имеет значения, а в кортеже имеет;
* во множестве все элементы различны а в кортеже могут повторяться


== Алгебра множеств ==

* Объединения и пересечения коммутативны
: &lt;math&gt;A \cup B = B \cup A&lt;/math&gt;
: &lt;math&gt;A \cap B = B \cap A&lt;/math&gt;
* Объединения и пересечения ассоциативны
: &lt;math&gt;(A \cup B) \cup C = A \cup (B \cup C)&lt;/math&gt;
: &lt;math&gt;(A \cap B) \cap C = A \cap (B \cap C)&lt;/math&gt;
* Свойства дистрибутивности объединения относительно пересечения и дистрибутивности пересечения отностительно объединения
: &lt;math&gt;(A \cap B) \cup C = (A \cup C) \cap (D \cup C)&lt;/math&gt;
: &lt;math&gt;(A \cup B) \cap C = (A \cap C) \cup (B \cap C)&lt;/math&gt;
* &lt;math&gt;A \cup A = A&lt;/math&gt;
* &lt;math&gt;A \cup U = U&lt;/math&gt; и &lt;math&gt;A \cap U = A&lt;/math&gt;
* &lt;math&gt;A \cup \varnothing = A&lt;/math&gt; и &lt;math&gt;A \cap \varnothing = \varnothing&lt;/math&gt;
* &lt;math&gt;\Bar{\Bar{A}} = A&lt;/math&gt;
* &lt;math&gt;\bar{U} = \varnothing&lt;/math&gt; и &lt;math&gt;\bar{\varnothing} = U&lt;/math&gt;
* Законы де-Моргана
: &lt;math&gt;\overline{A \cup B} = \overline{A} \cap \overline{B}&lt;/math&gt; и 
: &lt;math&gt;\overline{A \cap B} = \overline{A} \cup \overline{B}&lt;/math&gt;





== Формула включений и исключений ==

Дано &lt;math&gt;m&lt;/math&gt; предметов &lt;math&gt;x_1, x_2, ..., x_m&lt;/math&gt; и &lt;math&gt;n&lt;/math&gt; множеств &lt;math&gt;\alpha_1, \alpha_2, ..., \alpha_n&lt;/math&gt;. При этом элементы &lt;math&gt;x_i&lt;/math&gt; могут принадлежать любому произвольному &lt;math&gt;\alpha_i&lt;/math&gt;, а могут не принадлежать.

Введём обозначения
* &lt;math&gt;N&lt;/math&gt; - число всех предметов, &lt;math&gt;N = m&lt;/math&gt;
* &lt;math&gt;N(\alpha_i \alpha_j ... \alpha_k)&lt;/math&gt; - количество элементов, принадлежащих множеству &lt;math&gt;\alpha_i \cup \alpha_j \cup ... \cup \alpha_k&lt;/math&gt;, 
* &lt;math&gt;N(\overline{\alpha_i \alpha_j ... \alpha_k})&lt;/math&gt; - количество не принадлежащих ни одному из &lt;math&gt;\alpha_i \alpha_j ... \alpha_k&lt;/math&gt; (т.е. не принадлежащих &lt;math&gt;\alpha_i \cap \alpha_j \cap ... \cap \alpha_k&lt;/math&gt;).


Вычислим &lt;math&gt;N(\overline{\alpha_1 \alpha_2 ... \alpha_n})&lt;/math&gt; - т.е. посчитаем число элементов, не принадлежащих ни одному из множеств. 


&lt;math&gt;N(\overline{\alpha_1 \alpha_2 ... \alpha_n}) = N - N(\alpha_1) - N(\alpha_2) - ... - N(\alpha_n) + N(\alpha_1 \alpha_2) + N(\alpha_1 \alpha_3) + N(\alpha_1 \alpha_4) + ... N(\alpha_1 \alpha_n) + ... + N(\alpha_{n-1} \alpha_n) - N(\alpha_1 \alpha_2 \alpha_3) - ... + (-1)^n N(\alpha_1 \alpha_2 ... \alpha_n)&lt;/math&gt;


Причем слагаемое &lt;math&gt;N(...)&lt;/math&gt; имеет знак &quot;+&quot;&quot; если число множеств чётно, и &quot;-&quot;, если нечётно. 

Эту формулу можно записать схематично, как &lt;math&gt;N(\overline{\alpha \beta ... \omega})&lt;/math&gt; = &lt;math&gt;N(1 - \alpha)(1 - \beta)...(1 - \omega)&lt;/math&gt;, а после раскрытия скобок заменить &lt;math&gt;N\alpha\beta...\omega&lt;/math&gt; на &lt;math&gt;N(\alpha\beta...\omega)&lt;/math&gt;.

=== Доказательство ===

По индукции:

1 шаг: для 1

&lt;math&gt;N(\overline{\alpha_1}) = N - N(\alpha_1})&lt;/math&gt;

2 шаг: для &lt;math&gt;n - 1&lt;/math&gt;

&lt;math&gt;N(\overline{\alpha_1 \alpha_2 ... \alpha_{n - 1}}) = N - N(\alpha_1) - ... + N(\alpha_1 \alpha_2) + ... - N(\alpha_1 \alpha_2 \alpha_3) - ... + (-1)^{n-1} N(\alpha_1 \alpha_2 ... \alpha_{n-1})&lt;/math&gt;

3 шаг: для &lt;math&gt;n&lt;/math&gt;

Рассмотрим группу элементов, принадлежащих &lt;math&gt;\alpha_n&lt;/math&gt;

&lt;math&gt;N(\overline{\alpha_1 \alpha_2 ... \alpha_{n - 1}} \alpha_n) = N(\alpha_n) - N(\alpha_1 \alpha_n) - ... + N(\alpha_1 \alpha_2 \alpha_n) + ... - N(\alpha_1 \alpha_2 \alpha_3 \alpha_n) - ... + (-1)^{n-1} N(\alpha_1 \alpha_2 ... \alpha_{n-1} \alpha_n)&lt;/math&gt;

Вычтем &lt;math&gt;N(\overline{\alpha_1 \alpha_2 ... \alpha_{n - 1}} \alpha_n)&lt;/math&gt; из &lt;math&gt;N(\overline{\alpha_1 \alpha_2 ... \alpha_{n - 1}})&lt;/math&gt;

* &lt;math&gt;N(\overline{\alpha_1 \alpha_2 ... \alpha_{n - 1}})&lt;/math&gt; - число элементов, которые могут принадлежать \alpha_n, а могут и не принадлежать
* &lt;math&gt;N(\overline{\alpha_1 \alpha_2 ... \alpha_{n - 1}} \alpha_n)&lt;/math&gt; - число элементов, которые наверняка принадлежат \alpha_n
* Т.е. их разность как раз равна числу элементов, не принадлежащих ни одному из &lt;math&gt;\alpha_1 \alpha_2 ... \alpha_n&lt;/math&gt;


Таким образом, 
&lt;math&gt;N(\overline{\alpha_1 \alpha_2 ... \alpha_n}) = N(\overline{\alpha_1 \alpha_2 ... \alpha_{n - 1}}) -  N(\overline{\alpha_1 \alpha_2 ... \alpha_{n - 1}} \alpha_n)&lt;/math&gt;. 

'''Q.E.D.'''


== Sources ==
* Киреенко С.Г., Гриншпон И.Э. Элементы теории множеств (учебное пособие). Томск, 2003. http://portal.tpu.ru/lyceum/innovacion/workroom/sets.pdf
* Виленкин Н.Я. Комбинаторика. М., Наука, 1969.

[[Category:Russian]]
[[Category:Combinatorics]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>g82o7xd5vs50pp4sombi9e27ioq7y9y</sha1>
    </revision>
  </page>
  <page>
    <title>Partial Permutations</title>
    <ns>0</ns>
    <id>25</id>
    <revision>
      <id>26</id>
      <timestamp>2013-08-01T10:07:47Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1835">== Partial Permutations ==
Имеется &lt;math&gt;n&lt;/math&gt; различных предметов. Сколько из них можно составить расстановок длины &lt;math&gt;k&lt;/math&gt;? При этом две расстановки считаются различными, если они различаются либо хотя бы одним элементом, либо состоят из одних и тех же элементов, но расположенных в разном порядке.

Такие расстановки называются ''размещениями без повторений'' и обозначаются &lt;math&gt;A_n^k&lt;/math&gt;


При составлении нужно сделать &lt;math&gt;k&lt;/math&gt; выборов 

* на первом шаге нужно выбрать из n предметов
* на втором шаге - из &lt;math&gt;n - 1&lt;/math&gt; предметов (повторно выбрать нельзя)
* на &lt;math&gt;k&lt;/math&gt;-ом шаге - из &lt;math&gt;n - k + 1&lt;/math&gt; предметов

Таким образом, &lt;math&gt;A_n^k = n \cdot (n - 1) \cdot ... \cdot (n - k + 1) = \frac{n!}{(n - k)!}&lt;/math&gt;

=== Задача ===
Научное сообщество состоит из 25 человек. Надо выбрать президента, вице-президента, учёного секретаря и казначея. Сколькими способами можно сделать выбор?

&lt;math&gt;A_{25}^4 = 25 \cdot 24 \cdot 23 \cdot 22 = 303 \ 600&lt;/math&gt;

== Partial Permutations с повторениями ==

'''TODO'''


== See also == 
* [[Permutations]]

== Sources ==
* Виленкин Н.Я. Комбинаторика. М., Наука, 1969.

[[Category:Russian]]
[[Category:Combinatorics]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>dadnpyshq2b80fz2114z072z4liqoj4</sha1>
    </revision>
  </page>
  <page>
    <title>Permutations</title>
    <ns>0</ns>
    <id>26</id>
    <revision>
      <id>27</id>
      <timestamp>2014-12-12T14:12:19Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3896">== Permutations ==
Если брать [[Partial Permutations|размещения]], в которые входят все &lt;math&gt;n&lt;/math&gt; предметов, то они могут различаться только порядком.

''Перестановками из &lt;math&gt;n&lt;/math&gt; элементов'' называют размещения без повторений из &lt;math&gt;n&lt;/math&gt; элементов, в которые входят все элементы.

Обозначаются &lt;math&gt;P_n = A_n^n = n \cdot (n - 1) \cdot ... \cdot 2 \cdot 1 = n!&lt;/math&gt;

=== Задачи ===
Сколькими способами можно расположить на шахматной доске 8 ладей так, чтобы они не били друг друга?

При таком расположении на каждой горизонтали и вертикали стоит по одной ладье
* &lt;math&gt;a_1&lt;/math&gt; - номер поля на первой горизонтали
* &lt;math&gt;a_2&lt;/math&gt; - номер поля на второй горизонтали
* ...
* &lt;math&gt;a_8&lt;/math&gt; - номер поля на восьмой горизонтали

* &lt;math&gt;(a_1, ..., a_8)&lt;/math&gt; - некоторая перестановка &lt;math&gt;(1, ..., 8)&lt;/math&gt;
* &lt;math&gt;P_8 = 8! = 40320&lt;/math&gt;


== Permutations с повторениями ==
В перестановках мы переставляли предметы, которые попарно различны. Если же некоторые переставляемые предметы одинаковы, то получается меньше перестановок - некоторые перестановки совпадают друг с другом. 

Пусть имеется &lt;math&gt;n&lt;/math&gt; предметов &lt;math&gt;k&lt;/math&gt; различных типов. Сколько перестановок можно сделать из &lt;math&gt;n_1&lt;/math&gt; элементов первого типа, &lt;math&gt;n_2&lt;/math&gt; элементов второго типа, ..., &lt;math&gt;n_k&lt;/math&gt; элементов &lt;math&gt;k&lt;/math&gt;-того типа?

Число элементов в каждой перестановке равно &lt;math&gt;n = n_1 + n_2 + ... + n_k&lt;/math&gt;
Если бы все элементы были разными, то у нас было бы &lt;math&gt;n!&lt;/math&gt; перестановок.

Но из-за того, что элементы совпадают, получается меньшее количество перестановок.


Рассмотрим перестановку 

&lt;math&gt;\underbrace{aa \ .. \ a}_{n_1} \ \underbrace{bb \ .. \ b}_{n_2} \ ... \ \underbrace{xx \ .. \ x}_{n_k}&lt;/math&gt;

* Элементы первого типа можно переставить друг с другом &lt;math&gt;n_1!&lt;/math&gt; способами, но т.к. эти элементы одинаковы, то это не изменит перестановку. 
* Permutations первого, второго, &lt;math&gt;k&lt;/math&gt;-того типов можно делать независимо друг от друга. Поэтому по правилу произведения элементы этой перестановки можно переставить друг с другом &lt;math&gt;n_1! \cdot n_2! \cdot ... \cdot n_k!&lt;/math&gt; способами так, что она останется неизменной. 

* Следовательно, &lt;math&gt;P(n_1, n_2, ..., n_k) = \frac{n!}{n_1! n_2! ... n_k!}&lt;/math&gt;

=== Задача ===

Сколько перестановок можно сделать из букв слова &quot;Миссисипи&quot;?

&lt;math&gt;P(4, 3, 1, 1) = \frac{9!}{4! \cdot 3! \cdot 1! \cdot 1!} = 2520&lt;/math&gt;

== Sources ==
* Виленкин Н.Я. Комбинаторика. М., Наука, 1969.

[[Category:Russian]]
[[Category:Combinatorics]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>nek8ysjksfxq3wwb8c5zzoofko32iqn</sha1>
    </revision>
  </page>
  <page>
    <title>Combinations</title>
    <ns>0</ns>
    <id>27</id>
    <revision>
      <id>28</id>
      <timestamp>2013-08-01T10:08:11Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12545">== Combinations ==
Не всегда нас интересует порядок, в котором располагаются элементы - а интересует лишь состав.

Combinationsми размера &lt;math&gt;k&lt;/math&gt; из &lt;math&gt;n&lt;/math&gt; элементов называют всевозможные расстановки длины &lt;math&gt;k&lt;/math&gt;, составленных из этих элементов и отличающихся лишь составом, а не порядком элементов. 

&lt;math&gt;C_n^k&lt;/math&gt; - число сочетаний размера &lt;math&gt;k&lt;/math&gt;, которые можно составить из &lt;math&gt;n&lt;/math&gt; элементов.

Сначала составим все сочетания размера &lt;math&gt;k&lt;/math&gt; из &lt;math&gt;n&lt;/math&gt; элементов, а потом переставим элементы в них всеми возможными способами - и получим все возможные размещения размера &lt;math&gt;k&lt;/math&gt; из &lt;math&gt;n&lt;/math&gt; элементов. Из каждого сочетания можно сделать &lt;math&gt;k!&lt;/math&gt; [[Permutations|перестановок]], значит, 

&lt;math&gt;k! \cdot C_n^k = A_n^k, C_n^k = \frac{A_n^k}{k!} = \frac{n!}{(n - k)! \cdot k!}&lt;/math&gt;

Эта функция совпадает с формулой для числа перестановок из &lt;math&gt;k&lt;/math&gt; элементов одного типа и &lt;math&gt;(n-k)&lt;/math&gt; элементов второго типа

&lt;math&gt;P(n, n-k) = \frac{n!}{k! \cdot (n - k)!} = C_n^k&lt;/math&gt;

Расставим по порядку все &lt;math&gt;n&lt;/math&gt; элементов и зашифруем каждое сочетание расстановкой размера &lt;math&gt;n&lt;/math&gt;, состоящей из нулей и единиц. Если элемент входит, запишем 1, иначе 0.
При этом каждому сочетанию будет соответствовать расстановка из &lt;math&gt;k&lt;/math&gt; единиц и &lt;math&gt;(n - k)&lt;/math&gt; нулей. 

=== Задача ===
Сколькими способами можно поставить 8 ладей на поле 8 &lt;math&gt;\times&lt;/math&gt; 8? (Так, что они могут бить друг друга, а могут и не бить.)

* Нам нужно выбрать из 64 клеток любые 8. 
* Следовательно, &lt;math&gt;C_{64}^8 = \frac{64!}{8! \cdot 56!}&lt;/math&gt;


== Combinations с повторениями ==
Имеется &lt;math&gt;n&lt;/math&gt; различных типов предметов. Сколько комбинаций размера &lt;math&gt;k&lt;/math&gt; можно сделать из них, если не принимать во внимание порядок элементов в комбинациях?

=== Мотивирующий пример === 
В кондитерском магазине продают 4 типа пирожных: наполеон, эклеры, песочные и слоёные. Сколькими типами можно купить 7 пирожных? 

==== Способ 1 ====
* Зашифруем каждую покупку с помощью единиц и нулей. 
* Сначала запишем сколько было куплено наполеонов, затем ноль, затем количество эклеров, ноль, песочных, ноль, и, наконец, слоёных.
* Получим &lt;math&gt;\underbrace{111} 0 \underbrace{1} 0 \underbrace{11} 0 \underbrace{1}&lt;/math&gt;
* Разным покупкам при этом соответствуют различные перестановки с повторениями 

&lt;math&gt;P(7, 3) = \frac{10!}{7! \cdot 3!} = 120&lt;/math&gt;

==== Способ 2 ====
* Расположим в каждой покупке пирожные по порядку (наполеоны, эклеры, песочные, слоёные)
* Затем пронумеруем их, при этом к номерам наполеонов прибавляя 0, к номерам эклеров 1, песочных 2, слоёных - 3.
* Самый большой номер - 7 + 3 = 10 для слоёного пирожного
* Самый маленький номер - 1 + 0 = 1 для наполеона
* Ни один номер при этом не будет повторятся и каждой возрастающей последовательности из 7 чисел будет соответствовать некоторая покупка 

Например, имеем последовательность (2, 3, 4, 5, 7, 8, 9). Отнимем (1, 2, 3, 4, 5, 6, 7) и получим (1, 1, 1, 1, 2, 2, 2).
Т.е. имеем 4 эклера (к эклерам мы прибавляли 1) и 3 песочных (к их номерам прибавляли 2).

* Таким образом, число способов купить 7 пирожных равно числу способов выбрать 7 предметов из 10:
* Ответ &lt;math&gt;C_{10}^7 = 120&lt;/math&gt;



В общем случае задачи на сочетания с повторениями решаются так же. 

Зашифруем каждую комбинацию нулями и единицами 
* для каждого типа единицами запишем сколько предметов входит в комбинацию 
* и разделим типы предметов между собой нулями


При этом получится столько единиц, сколько предметов нам нужно выбрать, т.е. &lt;math&gt;k&lt;/math&gt;, и &lt;math&gt;(n - 1)&lt;/math&gt; нулей
* &lt;math&gt;\bar{C_n^k} = P(k, n - 1) = \frac{(k + n - 1)!}{k! \cdot (n - 1)!}&lt;/math&gt;
* Следовательно, &lt;math&gt;\bar{C}_n^k} = C_{n + k - 1}^k&lt;/math&gt;.


Аналогично можно прийти к этой формуле и вторым способом.


=== Разновидность ===
Встречаются задачи, в которые обязательно нужно включить элементы &lt;math&gt;r&lt;/math&gt; фиксированных типов, &lt;math&gt;r \leqslant n&lt;/math&gt;

Для этого 
* возьмем &lt;math&gt;r&lt;/math&gt; элементов нужного типа
* оставшиеся &lt;math&gt;k - r&lt;/math&gt; мест заполним остальными элементами, принадлежащими всем &lt;math&gt;n&lt;/math&gt; типам.

Итого, имеем формулу &lt;math&gt;\bar{C}_n^{k - r}} = C_{n + k - r - 1}^{k - r}&lt;/math&gt;


== Свойства сочетаний ==
=== Свойство 1 ===
&lt;math&gt;C_n^k = C_n^{n - k}&lt;/math&gt;
* Очевидно из формулы &lt;math&gt;C_n^k = \frac{n!}{(n - k)! \cdot k!}&lt;/math&gt;
* Если в формуле заменить &lt;math&gt;k&lt;/math&gt; на &lt;math&gt;(n - k)&lt;/math&gt;, то &lt;math&gt;n - k&lt;/math&gt; заменится на &lt;math&gt;n - (n - k) = k&lt;/math&gt; - и множители просто поменяются местами

=== Свойство 2 ===
&lt;math&gt;C_n^k = C_{n - 1}^{k - 1} + C^k_{n - 1}&lt;/math&gt;

* Составим все сочетания размера &lt;math&gt;k&lt;/math&gt; из &lt;math&gt;n&lt;/math&gt; элементов &lt;math&gt;a_1, a_2, ..., a_n&lt;/math&gt; и разобъем на две группы:
** в первых будут элементы, содержащие &lt;math&gt;a_n&lt;/math&gt;
** во второй не будет элементов, содержащих &lt;math&gt;a_n&lt;/math&gt;
* если в первой группе откинуть &lt;math&gt;a_n&lt;/math&gt; (т.к. оно есть везде, то на количество сочетаний это не повлияет), то получится сочетания размера &lt;math&gt;k - 1&lt;/math&gt;, составленные из элементов &lt;math&gt;a_1, a_2, ..., a_{n - 1}&lt;/math&gt; (всего &lt;math&gt;n - 1&lt;/math&gt; элементов) .
** Число сочетаний в первой группе равно &lt;math&gt;C_{n - 1}^{k - 1}&lt;/math&gt;
* сочетания второй группы являются сочетаниями размера &lt;math&gt;k&lt;/math&gt;, составленные из &lt;math&gt;n - 1&lt;/math&gt; элементов &lt;math&gt;a_1, a_2, ..., a_{n - 1}&lt;/math&gt;
** Число сочетаний во второй группе равно &lt;math&gt;C_{n - 1}^k&lt;/math&gt;
* По [[Правила суммы и произведения|правилу суммы]], общее число сочетаний равняется &lt;math&gt;C_{n - 1}^k + C_{n - 1}^{k - 1} = C_n^k&lt;/math&gt;

=== Свойство 3 ===
&lt;math&gt;\sum_{k = 0}^n C_n^k = 2^n&lt;/math&gt;

* &lt;math&gt;2^n&lt;/math&gt; - число всех [[Partial Permutations|размещений с повторениями]] из элементов ''двух типов''.
* Разобьём эти размещения на &lt;math&gt;k&lt;/math&gt; групп
* в &lt;math&gt;k&lt;/math&gt;-ю группу отнесем те элементы, в которые входят &lt;math&gt;k&lt;/math&gt; элементов первого типа и (&lt;math&gt;n - k&lt;/math&gt;) элементов второго типа
* размещения, входящие в &lt;math&gt;k&lt;/math&gt;-ю группу - всевозможные [[Permutations|перестановки]] из &lt;math&gt;k&lt;/math&gt; элементов первого типа и &lt;math&gt;n - k&lt;/math&gt; второго 
* число таких перестановок равно &lt;math&gt;P(k, n - k)&lt;/math&gt;, а &lt;math&gt;P(k, n - k) = C_n^k&lt;/math&gt;

В общем виде эту формулу можно записать так:

&lt;math&gt;\sum_{n_1 + ... + n_k = n} P(n_1, ..., n_k) = k^n&lt;/math&gt;



(свойства 4 и 5 опущены - см. Виленкина)

=== Свойство 6 === 
&lt;math&gt;C_n^0 - C_n^1 + ... + (-1)^n C_n^k = 0&lt;/math&gt;

* &lt;math&gt;C_n^0 = C_{n - 1}^0 = 1&lt;/math&gt;
* т.к. &lt;math&gt;C_n^1 = C_{n - 1}^0 + C_{n - 1}^1&lt;/math&gt;, то &lt;math&gt;C_{n - 1}^0 - C_n^{1} = -C_{n - 1}^2&lt;/math&gt;
* далее, имеем &lt;math&gt;-C_{n - 1}^2 + C_n^2 = C_{n - 1}^2&lt;/math&gt;
* В конце концов все слагаемые взаимоуничтожаются


Некоторые свойства (особенно 3 и 6) очень легко доказываются с помощью [[Binomial Theorem|бинома Ньютона]]


== Треугольник Паскаля ==
Биномиальные коэффициенты можно вычислять с помощью свойства 2: &lt;math&gt;C_n^k = C_{n - 1}^{k - 1} + C^k_{n - 1}&lt;/math&gt;.
Если расположить &lt;math&gt;C_n^k&lt;/math&gt; по середине под &lt;math&gt;C_{n - 1}^{k - 1}&lt;/math&gt; и &lt;math&gt;C^k_{n - 1}&lt;/math&gt;, то числа выстроятся в треугольник

&lt;img src=&quot;http://allmatematika.ru/images/kombib8.GIF&quot; /&gt;


=== Задача ===
&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/pascal-triangle-problem.png&quot; /&gt;

Сколькими способами можно добраться из вершины &lt;math&gt;A&lt;/math&gt; в вершину &lt;math&gt;B&lt;/math&gt;, если двигаться можно только &quot;вправо&quot; и &quot;вверх&quot;?

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/pascal-triangle-problem-solution.png&quot; /&gt;

* Если записать число способов, которыми можно попасть в определенный узел, то мы увидим треугольник Паскаля.
* Действительно, в &lt;math&gt;k&lt;/math&gt;-й узел &lt;math&gt;n&lt;/math&gt;-й строки можно попасть либо из &lt;math&gt;(k-1)&lt;/math&gt;-того, либо из &lt;math&gt;k&lt;/math&gt;-го узла
* Поэтому число путей, ведущих в этот узел есть &lt;math&gt;C_n^k = C_{n - 1}^{k - 1} + C^k_{n - 1}&lt;/math&gt;

Таким образом мы можем сформулировать одно из свойств треугольника Паскаля: 
Каждое число в треугольнике равно количеству способов добраться до него из вершины, перемещаясь либо вправо-вниз, либо влево-вниз.


== See also ==
* [[Permutations]]
* [[Binomial Theorem]]

== Sources ==
* Виленкин Н.Я. Комбинаторика. М., Наука, 1969.
* Генкин С.А., Итенберг И.В., Фомин Д.В. Ленинградские математические кружки, 1994.

[[Category:Russian]]
[[Category:Combinatorics]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>asfgog5y0u0n7vvovxy1t1dv3nuucd0</sha1>
    </revision>
  </page>
  <page>
    <title>Binomial Theorem</title>
    <ns>0</ns>
    <id>28</id>
    <revision>
      <id>29</id>
      <timestamp>2013-08-01T10:06:38Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2678">== Binomial Theorem ==
Рассмотрим степень &lt;math&gt;(a + x)^n&lt;/math&gt; 
* &lt;math&gt;(a + x)^2 = a^2 + 2xa + x^2 = aa + ax + xa + xx&lt;/math&gt;
* &lt;math&gt;(a + x)^3 = aaa + aax + axa + axx + xaa + xax + xxa + xxx&lt;/math&gt;

В эти формулы входят все [[Permutations|перестановки с повторениями]], составленные из символов &lt;math&gt;x&lt;/math&gt; и &lt;math&gt;a&lt;/math&gt;
* &lt;math&gt;(a + x)^n&lt;/math&gt; - то же самое, содержит всевозможные перестановки из &lt;math&gt;a&lt;/math&gt; и &lt;math&gt;x&lt;/math&gt; длины &lt;math&gt;n&lt;/math&gt;


Найдем, сколько будет членов, в которые входит &lt;math&gt;k&lt;/math&gt; символов &lt;math&gt;x&lt;/math&gt; и &lt;math&gt;n - k&lt;/math&gt; символов &lt;math&gt;a&lt;/math&gt;
* &lt;math&gt;P(k, n - k) = C_n^k = \frac{n!}{k! \cdot (n - k)!}&lt;/math&gt; (число перестановок с повторениями для двух групп равняется числу [[Combinations|сочетаний]] размера k из n)
* Т.е. член &lt;math&gt;x^k \cdot a^{n - k}&lt;/math&gt; возьмём с коэффициентом &lt;math&gt;C_n^k&lt;/math&gt; и получим 
* &lt;math&gt;(a + x)^n = C_n^0 a^n + C_n^1 a^{n-1} x + ... + C_n^k a^{n-k} x^k + ... + C_n^n x^n&lt;/math&gt;

Эта формула носит название ''Binomial Theorem''


=== Общий случай  ===
Для &lt;math&gt;(x_1 + ... + x_m)^n&lt;/math&gt; коэффициент при &lt;math&gt;x_1^{k_1} \cdot x_2^{k_2} \cdot ... \cdot x_m^{k_m}&lt;/math&gt; будет &lt;math&gt;P(k_1, k_2, ..., k_m)&lt;/math&gt;.


== Доказательство [[Combinations#Свойства сочетаний|свойств сочетаний]] ==
Назовём функцию вида &lt;math&gt;(1 + x)^n&lt;/math&gt; ''производящей''

&lt;math&gt;(1 + x)^n = C_n^0 + C_n^1 x + ... + C_n^k x^k + ... + C_n^n x^n&lt;/math&gt;.

С помощью этой формулы легко доказывать свойства сочетаний, в частности [[Combinations#Свойство 3|свойство 3]] и [[Combinations#Свойство 6|свойство 6]]

Свойство 3: &lt;math&gt;\sum_{k = 0}^n C_n^k = 2^n&lt;/math&gt;
* Пусть x в производящей функции равно 1. Тогда
* &lt;math&gt;2^n = C_n^0 + C_n^1 + ... + C_n^k + ... + C_n^n&lt;/math&gt;.


Свойство 6: &lt;math&gt;C_n^0 - C_n^1 + ... + (-1)^n C_n^k = 0&lt;/math&gt;
* Пусть &lt;math&gt;x = -1&lt;/math&gt;. Тогда
* &lt;math&gt;0 = C_n^0 - C_n^1 + ... + (-1)^n C_n^k&lt;/math&gt;.


== See also ==
* [[Combinations]]

== Sources ==
* Виленкин Н.Я. Комбинаторика. М., Наука, 1969.


[[Category:Combinatorics]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>82gfh3qtwzm5sf76tppvzc9uozlcnlj</sha1>
    </revision>
  </page>
  <page>
    <title>Probability</title>
    <ns>0</ns>
    <id>29</id>
    <revision>
      <id>30</id>
      <timestamp>2013-08-01T10:04:24Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5702">== События и испытания ==

''Событие'' называется ''случайным'', если при осуществлении определённой совокупности условий &lt;math&gt;S&lt;/math&gt; оно может либо произойти, либо не произойти.

Событие - результат ''испытания''.

Пример
* Стрелок стреляет по мишени. Выстрел - испытание. Попадание или непопадание - событие



События являются ''несовместными'', если появление одного из них исключает появления других событий в одном и том же испытании

Пример
* Из ящика вынут шар. &quot;Вынут красный шар&quot; и &quot;Вынут синий шар&quot; - несовместные события;
* Выпадание орла и решки - несовместные события.


Несколько событий образуют ''полную группу'', если в результате испытания появится хотя бы одно из этих событий. Полная группа событий обозначается буквой &lt;math&gt;\Omega&lt;/math&gt;.

Если события, образующие полную группу, попарно несовместны, то появиться может только одно из них.

Пример
* Орел и решка - полная группа событий


''Противоположными'' называют два единственно возможных события, образующие полную группу событий. Событие, противоположное событию &lt;math&gt;A&lt;/math&gt; обозначают &lt;math&gt;\bar{A}&lt;/math&gt;


Два события называют ''совместными'', если появление одного не исключает появление другого в одном и том же испытании.

Пример
*  Брошена игральная кость. Событие &lt;math&gt;A&lt;/math&gt; - выпало 4 очка, и событие &lt;math&gt;B&lt;/math&gt; - выпало четное количество очков. События &lt;math&gt;A&lt;/math&gt; и &lt;math&gt;B&lt;/math&gt; совместные.

== Классическое определение вероятности ==

''Probability'' - число, характерезующее степень возможности появления события.

Каждый возможный результат испытания - ''элементарный исход''.

''Probability события &lt;math&gt;A&lt;/math&gt;'' - отношение числа благоприятствующих событию &lt;math&gt;A&lt;/math&gt; элементарных исходов к общему их числу, обозначается &lt;math&gt;P(A)&lt;/math&gt;. 

&lt;math&gt;P(A) = \frac{m}{n}&lt;/math&gt;, где &lt;math&gt;m&lt;/math&gt; - число благоприятствующих исходов, &lt;math&gt;n&lt;/math&gt; - общее число исходов.


'''Пример'''

* Всевозможные элементарные исходы
:* &lt;math&gt;\omega_1&lt;/math&gt; - белый шар
:* &lt;math&gt;\omega_2&lt;/math&gt; - белый шар
:* &lt;math&gt;\omega_3&lt;/math&gt; - чёрный шар

* События
: &lt;math&gt;A&lt;/math&gt; - вынут белый шар
: &lt;math&gt;B&lt;/math&gt; - вынут чёрный шар

* Вероятности
: &lt;math&gt;P(A) = \frac{2}{3}&lt;/math&gt; 
: &lt;math&gt;P(B) = \frac{1}{3}&lt;/math&gt;

=== Свойства вероятности ===

#. Probability достоверного события &lt;math&gt;A&lt;/math&gt;: &lt;math&gt;P(A) = 1&lt;/math&gt;
#. Probability невозможного события &lt;math&gt;A&lt;/math&gt;: &lt;math&gt;P(A) = 0&lt;/math&gt;
#. Probability случайного события &lt;math&gt;A&lt;/math&gt;: &lt;math&gt;0 &lt; P(A) &lt; 1&lt;/math&gt;

Таким образом, &lt;math&gt;0 \leqslant p \leqslant 1&lt;/math&gt;


== Статистическое определение вероятности ==

Классическое определение вероятности подразумевает конечность числа элементарных исходов. На практике же это число может быть бесконечно. Так же часто невозможно представить результат в виде совокупности элементарных событий.

''Статистическое определение вероятности'' - в качестве вероятности принимается относительная частота &lt;math&gt;\frac{m}{n}&lt;/math&gt;.

При этом все свойства вероятности выполняются: &lt;math&gt;0 \leqslant p = \frac{m}{n} \leqslant 1&lt;/math&gt;


== Принцип практической невозможности маловероятных событий ==

Если случайное событие имеет очень маленькую вероятность, то практически можно считать, что в единичном испытание это событие не произойдет.

''Уровень значимости'' - достаточно малая вероятность, при которой событие можно считать невозможным. 

== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.

[[Category:Russian]]
[[Category:Probability]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>k9k3rf589pzh0rofngn196i4a6q7y64</sha1>
    </revision>
  </page>
  <page>
    <title>Random Variable</title>
    <ns>0</ns>
    <id>30</id>
    <revision>
      <id>31</id>
      <timestamp>2014-05-09T20:25:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1585">== Random Variable ==
Random Variables (RV)
* A variable is ''random'' if it can take some value with certain probability


== Types of Random Variables ==
=== Discrete Random Variables ===
A RV is ''discrete'' if it takes certain isolated values.
* the # of possible values can be finite or infinite
* example: the number of born boys


=== Continuous Random Variables  ===
A RV is continuous if it can take all values from some interval


=== Statistics ===
In [[Statistics]] and [[Data Analysis]], there are different names for the same thing:
* [[Types of Variables]]
* [[Quantitative Variables]] 
* [[Categorical Variables]] 


== [[Distributions]] ==
A distribution of an RV is a mapping from possible values of RV to probabilities 
* it can be a table (for discrete RVs) or a function (for continuous RVs)
* the sum of all probabilities must be 1

A distribution of an RV can be specified by 
* [[Distribution Function]]
* [[Probability Density Function]]


== Parameters ==
Most important parameters for an RV $X$ are:
* $E[X]$ or sometimes $M[X]$ - [[Expected Value]], the mean value 
* $\text{Var}[X]$ - [[Variance]], how the variable is &quot;spread out&quot;, measured in (units of $X$)${}^2$
* $\text{sd}[X] = \sqrt{\text{Var}[X]}$ - [[Standard Deviation]], also a measure of variance, but in the same units as $X$



== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.
* http://en.wikipedia.org/wiki/Probability_distribution


[[Category:Probability]]</text>
      <sha1>okno02a6wp11p724alqguax3x4xwvfq</sha1>
    </revision>
  </page>
  <page>
    <title>Chain and Sum Rules in Probability</title>
    <ns>0</ns>
    <id>31</id>
    <revision>
      <id>32</id>
      <timestamp>2014-01-17T10:25:59Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4528">== Теорема сложения вероятностей == 

''Суммой'' &lt;math&gt;A + B&lt;/math&gt; двух событий &lt;math&gt;A&lt;/math&gt; и &lt;math&gt;B&lt;/math&gt; является событие, состоящее в появлении события &lt;math&gt;A&lt;/math&gt; или события &lt;math&gt;B&lt;/math&gt; 

'''Теорема'''. Probability появления одного из двух несовместных событий равна сумме этих событий:

&lt;math&gt;P(A + B) = P(A) + P(B)&lt;/math&gt;

Доказательство:
&lt;math&gt;n&lt;/math&gt; - общее число исходов, &lt;math&gt;m_a&lt;/math&gt; - благоприятных &lt;math&gt;A&lt;/math&gt;, &lt;math&gt;m_b&lt;/math&gt; - благоприятных &lt;math&gt;b&lt;/math&gt;

&lt;math&gt;P(A + B) = \frac{m_a + m_b}{n} = \frac{m_a}{n} + \frac{m_b}{n} = P(A) + P(B)&lt;/math&gt;


=== Следствия ===
* Сумма вероятностей всех событий &lt;math&gt;A_i \in \Omega&lt;/math&gt;, составляющих [[Probability#События и испытания|полную группу событий]], равна единице.
: &lt;math&gt;P(A_1) + ... + P(A_n) = 1&lt;/math&gt;
* Сумма вероятности появления события &lt;math&gt;A&lt;/math&gt; или противоположного ему события &lt;math&gt;\bar{A}&lt;/math&gt; равна единице, т.к. &lt;math&gt;A&lt;/math&gt; и &lt;math&gt;\bar{A}&lt;/math&gt; образуют полную группу событий
: &lt;math&gt;P(A) + P(\bar{A}) = 1&lt;/math&gt;


== Теорема сложения вероятностей совместных событий ==
Два события называют ''совместными'', если появление одного не исключает появление другого в одном и том же испытании.


'''Теорема.''' Probability появления хотя бы одного из двух совместных событий равна сумме вероятностей этих событий без вероятности их совместного появления 

&lt;math&gt;P(A + B) = P(A) + P(B) - P(AB)&lt;/math&gt;

Доказательство
* &lt;math&gt;A + B&lt;/math&gt; наступит, если произойдёт &lt;math&gt;A\bar{B}&lt;/math&gt;, &lt;math&gt;\bar{A}B&lt;/math&gt; или &lt;math&gt;AB&lt;/math&gt;. Так как эти события несовместы, то по теореме сложения имеем
: &lt;math&gt;P(A + B) = P(A\bar{B}) + P(\bar{A}B) + P(AB)&lt;/math&gt; ('''*''')
* &lt;math&gt;A&lt;/math&gt; наступит, если произойдёт или &lt;math&gt;AB&lt;/math&gt; или &lt;math&gt;A\bar{B}&lt;/math&gt;. По теореме сложения, 
: &lt;math&gt;P(A) = P(A\bar{B}) + P(AB)&lt;/math&gt; или
: &lt;math&gt;P(A\bar{B}) = P(A) - P(AB)&lt;/math&gt; ('''**''')
* Аналогично, &lt;math&gt;B&lt;/math&gt; наступит, если произойдёт или &lt;math&gt;AB&lt;/math&gt; или &lt;math&gt;\bar{A}B&lt;/math&gt;. Т.е.
: &lt;math&gt;P(B) = P(\bar{A}B) + P(AB)&lt;/math&gt; или
: &lt;math&gt;P(\bar{A}B) = P(B) - P(AB)&lt;/math&gt; ('''***''')
* Подставив ('''**''') и ('''***''') в ('''*'''), получим 
: &lt;math&gt;P(A + B) = P(A) + P(B) - P(AB)&lt;/math&gt;

== Теорема произведения вероятностей == 
''Произведением'' событий &lt;math&gt;A&lt;/math&gt; и &lt;math&gt;B&lt;/math&gt; называется событие &lt;math&gt;A \cdot B&lt;/math&gt;, состоящее в совместном появлении этих событий. 

Пример:
* &lt;math&gt;A&lt;/math&gt; - деталь годная
* &lt;math&gt;B&lt;/math&gt; - деталь окрашена
* &lt;math&gt;A \cdot B&lt;/math&gt; - деталь годна и окрашена

'''Теорема'''. Рассмотрим два события &lt;math&gt;A&lt;/math&gt; и &lt;math&gt;B&lt;/math&gt;. Нам известны &lt;math&gt;P(A)&lt;/math&gt; и &lt;math&gt;P(B|A)&lt;/math&gt;. Как найти вероятность появления и &lt;math&gt;A&lt;/math&gt; и &lt;math&gt;B&lt;/math&gt;? 

&lt;math&gt;P(A \cdot B) = P(A) \cdot P(B | A)&lt;/math&gt; - по определению [[Условная вероятность|условной вероятности]]. 

Для [[Independence|независимых событий]] теорема умножения принимает вид 

&lt;math&gt;P(A \cdot B) = P(A) \cdot P(B)&lt;/math&gt;

== See also ==
* [[Правила суммы и произведения]] (Комбинаторика)

== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.

[[Category:Russian]]
[[Category:Probability]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>cv1g3py6yu7pnw3n2c66w53sk3ryqrl</sha1>
    </revision>
  </page>
  <page>
    <title>Independence</title>
    <ns>0</ns>
    <id>32</id>
    <revision>
      <id>33</id>
      <timestamp>2013-08-01T10:06:16Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3319">== Независимые события ==
Событие B называют ''независимым'' от события &lt;math&gt;A&lt;/math&gt;, если появление события &lt;math&gt;A&lt;/math&gt; не изменяет вероятность события &lt;math&gt;B&lt;/math&gt;, т.е. 

&lt;math&gt;P(B | A) = P(B)&lt;/math&gt; и &lt;math&gt;P(A | B) = P(A)&lt;/math&gt;

Или, по-другому, два события являются независимыми, если вероятность их совместного появления равна произведению вероятностей этих событий:

&lt;math&gt;P(A \cdot B) = P(A) \cdot P(B)&lt;/math&gt;

Иначе, такие события называются ''зависимыми''. 

== Попарная независимость и независимость в совокупности ==
Несколько событий называют ''попарно-независимыми'', если каждые два из них независимы. 

События называют ''независмыми в совокупности'', если они попарно независимы, а так же независимы со всеми возможными произведениями.

Для таких событий &lt;math&gt;P(A_1 \cdot ... \cdot A_n) = P(A_1) \cdot ... \cdot P(A_n) &lt;/math&gt;


== Появление хотя бы одного события == 
'''Теорема'''. Probability появления хотя бы одного из  независимых в совокупности событий &lt;math&gt;A_1, ..., A_n&lt;/math&gt; есть

&lt;math&gt;P(A) = 1 - P(\bar{A}_1 \bar{A}_2 ... \bar{A}_n)&lt;/math&gt; 

или, иначе,

&lt;math&gt;P(A) = 1 - q_1 q_2 ... q_n&lt;/math&gt;

Так как события &lt;math&gt;A&lt;/math&gt; и &lt;math&gt;\bar{A}_1 \bar{A}_2 ... \bar{A}_n&lt;/math&gt; - противоположные. 

=== Пример ===
Probability того, что первое орудие попадёт в цель 0.7 (событие &lt;math&gt;A&lt;/math&gt;). Для второго орудия - 0.8 (событие &lt;math&gt;B&lt;/math&gt;). Найти вероятность попадания в одном залпе хотя бы одного орудия. 

* Оба орудия попадут в цель: &lt;math&gt;P(AB) = 0.7 + 0.8 = 0.56&lt;/math&gt;
* Одно из орудий попадёт в цель: &lt;math&gt;P(A + B) = 0.7 + 0.8 - 0.56 = 0.94&lt;/math&gt; (по [[Chain and Sum Rules in Probability#Теорема сложения вероятностей совместных событий|теореме сложения вероятностей совместных событий]])

* Если же воспользоваться формулой, то &lt;math&gt;p = 1 - q_1 q_2 = 1 - 0.3 \cdot 0.2 = 0.94&lt;/math&gt;

=== Пример 2 ===
Probability того, что генератор случайных чисел сгенерирует заданное наперёд слово 
* http://forum.vingrad.ru/forum/topic-365451/anchor-entry2556737/0.html

== See also ==
* [[Conditional Probability]]

== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.

[[Category:Russian]]
[[Category:Probability]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>6n8cz560u1tb9or74mbnjhscppr7yab</sha1>
    </revision>
  </page>
  <page>
    <title>Bayes Theorem</title>
    <ns>0</ns>
    <id>33</id>
    <revision>
      <id>34</id>
      <timestamp>2013-08-01T10:09:07Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4832">== Bayes Theorem ==

Пусть &lt;math&gt;H = \{H_1, H_2, ..., H_n\}&lt;/math&gt; образуют полную группу событий и &lt;math&gt;A&lt;/math&gt; может выполняться только при выполнении одного из &lt;math&gt;\{ H_i \}&lt;/math&gt;.

Назовём события &lt;math&gt;H_1, H_2, ..., H_n&lt;/math&gt; ''гипотезами'', поскольку заранее не известно, какое из них наступит.

''Bayes Theorem'' позволяет переоценить вероятность гипотез после того, как становится известным результат испытания, после которого появилось &lt;math&gt;A&lt;/math&gt;.

&lt;math&gt;P(H_i | A) = \frac{P(H_i) P(A | H_i)}{P(H_1) P(A|H_1) + P(H_2) P(A|H_2) + ... + P(H_n) P(A|H_n)}&lt;/math&gt;


&lt;math&gt;P(H_i)&lt;/math&gt; называется ''априорной вероятностью'', &lt;math&gt;P(H_i|A)&lt;/math&gt; - ''апостериорной''.

=== Вывод формулы ===
* Допустим, что произведено испытание, в результате которого появилось событие &lt;math&gt;A&lt;/math&gt;. 
* Найдем условные вероятности &lt;math&gt;P(H_1|A), P(H_2|A), ..., P(H_n|A)&lt;/math&gt; 
: Т.е. вероятности гипотез, при условии, что событие &lt;math&gt;A&lt;/math&gt; уже наступило. 

* Для &lt;math&gt;P(H_1|A) &lt;/math&gt;по теореме умножения имеем 
: &lt;math&gt;P(A H_1) = P(A) P(H_1 A) = P(H_1) P(A | H_1)&lt;/math&gt;
: Т.е. &lt;math&gt;P(H_1 | A) = \frac{P(H_1) P(A | H_1)}{P(A)}&lt;/math&gt;
* Если заменить все &lt;math&gt;P(A)&lt;/math&gt; на формулу полной вероятности, то получим 
: &lt;math&gt;P(H_1 | A) = \frac{P(H_1) P(A | H_1)}{P(H_1) P(A|H_1) + P(H_2) P(A|H_2) + ... + P(H_n) P(A|H_n)}&lt;/math&gt;
* Аналогично и для других гипотез. Т.е. 
: &lt;math&gt;P(H_i | A) = \frac{P(H_i) P(A | H_i)}{P(H_1) P(A|H_1) + P(H_2) P(A|H_2) + ... + P(H_n) P(A|H_n)}&lt;/math&gt;


=== Пример 1 ===
Каждый из трех стрелков может сделать два выстрела. Probability попаданий: &lt;math&gt;P(A_1) = 0.3&lt;/math&gt;, &lt;math&gt;P(A_2) = 0.5&lt;/math&gt; и &lt;math&gt;P(A_3) = 0.8&lt;/math&gt;. Один из стрелков выстрелил два раза и ни разу не попал. Какая вероятность, что стрелком был первый?

* Пусть гипотеза &lt;math&gt;H_1&lt;/math&gt; - стрелял первый, &lt;math&gt;H_2&lt;/math&gt; - стрелял второй и &lt;math&gt;H_3&lt;/math&gt; - стрелял третий. 
* &lt;math&gt;P(H_1) = P(H_2) = P(H_3) = \frac{1}{3}&lt;/math&gt;. 
* &lt;math&gt;D&lt;/math&gt; - стрелок промахивается два раза.
* &lt;math&gt;P(D|H_1) = 0.7 * 0.7 = 0.49&lt;/math&gt;
* &lt;math&gt;P(D|H_2) = 0.25&lt;/math&gt;
* &lt;math&gt;P(D|H_3) = 0.04&lt;/math&gt;

Тогда по формуле Байеса
* &lt;math&gt;P(H_1|D) = 0.628&lt;/math&gt;

=== Пример 2 ===
В первом ящике лежит 2 золотых монеты, во втором одна золотая, одна серебряная, а в третьем - две серебряных. Случайным образом выбирается монета, которая оказывается золотой. Какая вероятность того, что вторая монета в том же ящике тоже золотая?

Золотой вторая монета может быть только в первом ящике, поэтому нужно найти вероятность того, что монета извлечена из первого ящика.

Пусть &lt;math&gt;H_1&lt;/math&gt; - монета извлечена из первого ящика, &lt;math&gt;H_2&lt;/math&gt; - из второго и &lt;math&gt;H_3&lt;/math&gt; - из третьего. Очевидно, что &lt;math&gt;P(H_1) = P(H_2) = P(H_3) = \fraq{1}{3}&lt;/math&gt;.

&lt;math&gt;D&lt;/math&gt; - вытащенная монета является золотой. Тогда &lt;math&gt;P(D|H_1) = 1&lt;/math&gt;, &lt;math&gt;P(D|H_2) = 0.5&lt;/math&gt; и &lt;math&gt;P(D|H_3) = 0&lt;/math&gt;. 

Вычислим &lt;math&gt;P(H_1|D)&lt;/math&gt; по формуле &lt;math&gt;P(H_1|D) = \frac{ P(H_1) P(A|H_1) }{ \sum_{i=1}^{3} P(H_i) P(D|H_i) }&lt;/math&gt;


== See also ==
* [[Conditional Probability]]
* [[Law of Total Probability]]

== Источники и ссылки ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.
* [https://www.dropbox.com/s/j9yxtvkd0ns5eot/Probability_and_Statistics_exams_c.pdf#13 Конспект по теории вероятности и математической статистике]

[[Category:Russian]]
[[Category:Probability]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>h38edqo0ym36bmfax9g7ot2gfy483ud</sha1>
    </revision>
  </page>
  <page>
    <title>Variance</title>
    <ns>0</ns>
    <id>34</id>
    <revision>
      <id>35</id>
      <timestamp>2014-07-15T20:21:26Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3171">== Motivation ==
[[Expected Value]] (Математическое ожидание) can't describe a possible range of values for a [[Random Variable]]

Consider the following two RVs

&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;
{| class=&quot;wikitable&quot; 
! $X$ !! -0.1 || 0.1
|-
! $p$ !!  0.5 || 0.5
|}
&lt;/td&gt;
&lt;td&gt;
{| class=&quot;wikitable&quot; 
! $Y$ !! -100 || 100
|-
! $p$ !!  0.5 || 0.5
|}
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

In both cases $M(X) = M(Y) = 0$
* but values for $X$ are close to the expected value, and values of $Y$ are far


=== Deviation ===
''Deviation of a Random Variable'' (''Отклонение случайной величины'') - absolute difference between the value of an RV and its expected value

Отклонение иногда называют центрированной величиной и обозначают $\dot{X}$

Since $E\big[X - E[X] \big] = 0$, we need another way to describe the spread of some RV


== Variance ==
''Variance of a Random Variable'' (''Дисперсиия (разброс) случайной величины'') is a measure of spread that describes how far away values get from the expected value

$\text{Var}[X] = E \big[X - E[X] \big]^2 = \big[x_1 - E[X] \big]^2 \cdot p_1 + \big[x_2 - E[X] v]^2 \cdot p_2 + ... + \big[x_n - E[X] \big]^2 \cdot p_n$


=== Формула для вычисления дисперсии ===
'''Теорема.''' Дисперсия равна разности между мат. ожиданием квадрата случайной величины и квадрата её мат. ожидания:

$\text{Var}[X] = E[X^2] - E^2[X]$ (meaning $E[X^2] - (E[X])^2$)

Доказательство: 
* $\text{Var} [X] = E\big[X - E[X]\big]^2 = ... $
* $... = E\big[X^2 - 2X \cdot E[X] + E^2 [X]\big] = ...$
* $... = E[X^2] - 2E[X] \cdot E[X] + E^2(X) = ...$
* $... = E[X^2] - 2E^2[X] + E^2[X] = E[X^2] - E^2[X]$


=== Properties ===
# $\text{Var}(C) = 0$
# $\text{Var}(C \cdot X) = C^2 \cdot \text{Var}(X)$
# $\text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y) + 2[E(XY) - E(X)E(Y)]$
#: If $X$ and $Y$ are independent, then $E(XY) = E(X)E(Y)$ and $\text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y)$
#: $E(XY) - E(X)E(Y)$ is also called [[Корреляция#Ковариация|covariation]]
# for independent $X$ and $Y$ $\text{Var}(X - Y) = \text{Var}(X) + \text{Var}(Y)$ ($\text{Var}(X - Y) = \text{Var}(X + (-1) Y) = \text{Var}(X) + (-1)^2 \text{Var}(Y)$)


== Standard Deviation ==
$\sigma(X) = \sqrt{ \text{Var} [X] }$


Дисперсия имеет размерность, равную квадрату размерности случайной величины, а среднеквадратичное отклонение совпадает с ней. 

* $\text{Var}(x) = \cfrac{1}{n - 1} \sum (x_i - \bar{x})^2$
* $s(x) = \text{std}(x) = \sqrt{\text{Var}(x)}$

($n - 1$ gives &quot;unbiased&quot; estimate of the variance {{{ TODO | add link }}})

in R: 
&lt;pre&gt;
st.dev = sd(data)
&lt;/pre&gt;


== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.

[[Category:Russian]]
[[Category:Probability]]</text>
      <sha1>jr2vkmqitz7n4bhhro8bswc8dgeq7ln</sha1>
    </revision>
  </page>
  <page>
    <title>Expected Value</title>
    <ns>0</ns>
    <id>35</id>
    <revision>
      <id>36</id>
      <timestamp>2014-05-09T10:43:34Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1096">== Expected Value ==
''Expected Value'' (''Математическое ожидание'') of a [[Random Variable]] X
* is a sum of all possible values from $x_i \in \text{Dom}(X)$ multiplied by their probabilities $p_i$
* denoted $E[X]$ or $M[X]$
* it's often called the center of a [[Distribution]]

For discrete random values the formula is 
* $E[X] = \sum_{i = 1}^{\infty} x_i p_i$


=== Mean ===
Expected Value of $X$ is approximately equal to the mean value of $X$
* $E[X] \approx \bar{X}$

$\bar{X} = x_1 \cfrac{m_1}{n} + x_2 \cfrac{m_2}{n} + ... + x_k \cfrac{m_k}{n}$ where
* $\cfrac{m_i}{n} \approx p_i$ relative frequency of $x_i$


== Properties ==
* $E[C] = C$
* $E[C \cdot X] = C \cdot E[X]$
* $E[X \cdot Y] = E[X] \cdot E[Y]$, if $X$ and $Y$ are independent (proof?)
* and $E[XYZ] = E[X] E[Y] E[Z]$, also if $X$, $Y$ and $Z$ are independent


== See Also ==
* [[Variance]]

== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.

[[Category:Probability]]</text>
      <sha1>eqkpw3ux8jtsoltwr96b8844et7mkl6</sha1>
    </revision>
  </page>
  <page>
    <title>Correlation</title>
    <ns>0</ns>
    <id>36</id>
    <revision>
      <id>37</id>
      <timestamp>2014-05-09T20:32:30Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4273">== Независимые случайные величины ==
Если $X$ и $Y$ независисые, то распределение одной не влияет на значение второй. Иначе случайные величины называют зависимыми.


== Ковариация ==
Ковариация - мера линейной зависимости двух случайных величин. 

$\text{cov}(X, Y) = M[(X - M(X)) \cdot (Y - M(Y))] = M(XY) - M(X)M(Y)$


=== Ограниченность ковариации ===
'''Теорема.'''
Абсолютная величина коэффициента ковариации двух случайных величин $X$ и $Y$ не превышает $\sigma(X) \sigma(Y)$

$|\text{cov}(X, Y)| \leqslant \sigma(X) \sigma(Y)$


'''Доказательство.''' Рассмотрим две случайные величины $Z_1 = \sigma(Y) X - \sigma(X) Y$ и $Z_2 = \sigma(Y) X + \sigma(X) Y$


{{Hider|
  title = Вывод $D(Z_1) = 2\sigma^2(X)\sigma^2(Y) - 2\sigma(X)\sigma(Y) \text{cov}(X, Y)$ |
  content =
* $D(Z_1) = M(Z_1)^2 - M^2(Z_1) = M[\sigma(Y) X - \sigma(X) Y]^2 - M^2[\sigma(Y) X - \sigma(X) Y] = $
* $M[\sigma^2(Y) X^2 - 2\sigma(X)\sigma(Y)XY + \sigma^2(X) Y^2] + [\sigma(Y) M(X) - \sigma(X) M(Y)]^2 = $
* $\sigma^2(Y) M(X^2) - 2\sigma(X)\sigma(Y) M(XY) + \sigma^2(X) M(Y^2)$ $ - \sigma^2(Y) M^2(X) - \sigma(X)\sigma(Y) M(X)M(Y) + \sigma^2(X) M^2(Y) = $ 
* $\sigma^2(Y)(M[X^2] - M^2[X]) - $ $ 2\sigma(X)\sigma(Y) (M[XY] - M[X]M[Y]) + \sigma^2(X)(M[Y^2] - M^2[Y]) =$ 
* $2\sigma^2(X)\sigma^2(Y) - 2\sigma(X)\sigma(Y) \text{cov}(X, Y)$
}}


Аналогично, $D(Z_2) = 2\sigma^2(X)\sigma^2(Y) + 2\sigma(X)\sigma(Y) \text{cov}(X, Y)$


Т.к. любая дисперсия неотрицательна, получим,
* $D(Z_1) \geqslant 0$
* $2\sigma^2(X)\sigma^2(Y) - 2\sigma(X)\sigma(Y) \text{cov}(X, Y) \geqslant 0$
* $2\sigma^2(X)\sigma^2(Y) \geqslant 2\sigma(X)\sigma(Y) \text{cov}(X, Y)$
* $\text{cov}(X, Y) \leqslant \sigma(X)\sigma(Y)$

Аналогично, для $D(Z_2)$
* $2\sigma^2(X)\sigma^2(Y) + 2\sigma(X)\sigma($Y) \text{cov}(X, Y) \geqslant 0
* $\text{cov}(X, Y)  \geqslant -\sigma(X)\sigma(Y)$

Или, $|\text{cov}(X, Y)| \leqslant \sigma(X)\sigma(Y)$.

'''Q.E.D'''


=== Свойства ковариации === 
* Ковариация симметрична
: $\text{cov}(X, Y) = \text{cov}(Y, X)$
* Ковариация ограничена (см. теорему)
: $|\text{cov}(X, Y)| \leqslant \sigma(X)\sigma(Y)$
* Ковариация переменной самой с собой - ее дисперсия
: $\text{cov}(X, X) = M(X^2) - M^2(X) = D(X)$
* $\text{cov}(100 \cdot X, Y) = 100 \cdot \text{cov}(X, Y)$
* Если $X$ и $Y$ независимы, то $\text{cov}(X, Y) = 0$


=== Интерпретация ===
* Если ковариация положительна, то с ростом одной С.В. значения второй С.В. имеют тенденцию возрастать, а если ковариация отрицательна - то убывать.


== Корреляция ==
По абсолютному значению ковариации нельзя судить о том, насколько сильно величины взаимосвязаны, т.к. её масштаб зависит от дисперсий. 

Однако масштаб можно отнормировать, поделив на $\sigma(X) \sigma(Y)$ и получив при этом ''линейный коэффициент корреляции'' (так же называемый коэффициентом корреляции Пирсона).

$r(X, Y) = r = \cfrac{\text{cov}(X, Y)}{\sigma(X) \sigma(Y)}$


Так как $|\text{cov}(X, Y)| \leqslant \sigma(X)\sigma(Y)$, то $-1 \leqslant r \leqslant 1$


== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.
* http://ru.wikipedia.org/wiki/Ковариация
* http://ru.wikipedia.org/wiki/Корреляция

[[Category:Russian]]
[[Category:Probability]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>r4ai3pj8tamgoz5szx06rq1z72j2h8x</sha1>
    </revision>
  </page>
  <page>
    <title>Chebyshev's Inequality</title>
    <ns>0</ns>
    <id>37</id>
    <revision>
      <id>38</id>
      <timestamp>2013-08-01T10:06:10Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3156">== Chebyshev's Inequality ==
Probability того, что отклонение [[Случайная величина|случайной величины]] X от её [[Математическое ожидание|математического ожидания]] по абсолютной величине меньше положительного числа &lt;math&gt;\epsilon&lt;/math&gt;, не меньше, чем &lt;math&gt;1 - \frac{D(X)}{\epsilon^2}&lt;/math&gt;:

&lt;math&gt;P(|X - M(X)| &lt; \epsilon) \geqslant 1 - \frac{D(X)}{\epsilon^2}&lt;/math&gt;

== Доказательство ==

* Рассмотрим событие, обратное &lt;math&gt;|X - M(X)| &lt; \epsilon&lt;/math&gt; - это будет событие, что отклонение принимает значение, большее &lt;math&gt;\epsilon&lt;/math&gt;: &lt;math&gt;|X - M(X)| \geqslant \epsilon&lt;/math&gt;
: Эти два события противоположные: &lt;math&gt;P(|X - M(X)| &lt; \epsilon) + P(|X - M(X)| \geqslant \epsilon) = 1&lt;/math&gt;
: вычислим &lt;math&gt;P(|X - M(X)| \geqslant \epsilon)&lt;/math&gt;

* &lt;math&gt;D(X) = \sum_{i = 1}^n (x_i - M(X))^2 p_i&lt;/math&gt; (*)
: все слагаемые этой суммы больше нуля
* Отбросим все &lt;math&gt;(x_i - M(X))^2 p_i&lt;/math&gt;, у которых &lt;math&gt;|x_i - M(X)| &lt; \epsilon&lt;/math&gt;
: После этого сумма (*) только уменьшится
* Условно будем считать, что отброшено первые &lt;math&gt;k&lt;/math&gt; слагаемых 
: &lt;math&gt;D(X) \geqslant \sum_{j = k + 1}^n (x_j - M(X))^2 p_j&lt;/math&gt;
* &lt;math&gt;|x_j - M(X)| \geqslant \epsilon, j = k + 1, ..., n&lt;/math&gt; (по предположению)
: обе части неравенства положительны, поэтому &lt;math&gt;|x_j - M(X)|^2 \geqslant \epsilon^2&lt;/math&gt;
* Воспользуемся этим и заменим каждый из множителей на &lt;math&gt;\epsilon^2&lt;/math&gt;, и при этом неравенство только усилится. Получим
: &lt;math&gt;D(X) \geqslant \epsilon^2 \cdot (p_{k+1} + ... + p_n) = \epsilon^2 \sum_{j = k + 1}^n p_j&lt;/math&gt;
* По [[Chain and Sum Rules in Probability#Теорема сложения вероятностей|теореме сложения вероятностей]], сумма &lt;math&gt;\sum_{j = k + 1}^n p_j&lt;/math&gt; - вероятности того, что &lt;math&gt;X&lt;/math&gt; примет одно из значений &lt;math&gt;{x_j}, j = k+1, ..., n&lt;/math&gt;
: При любом &lt;math&gt;x_j&lt;/math&gt; удовлетворяется &lt;math&gt;|x_j - M(X)| \geqslant \epsilon&lt;/math&gt;
: т.е. &lt;math&gt;\sum_{j = k + 1}^n p_j&lt;/math&gt; выражает вероятность &lt;math&gt;P(|X - M(X)| \geqslant \epsilon)&lt;/math&gt;
* Поэтому имеем
: &lt;math&gt;D(X) \geqslant \epsilon^2 \cdot P(|X - M(X)| \geqslant \epsilon)&lt;/math&gt;
: или &lt;math&gt;P(|X - M(X)| &lt; \epsilon) \geqslant 1 - \frac{D(X)}{\epsilon^2}&lt;/math&gt;



== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.

[[Category:Russian]]
[[Category:Probability]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>83g34gmiktaohc9gycobubm1b5ddlzl</sha1>
    </revision>
  </page>
  <page>
    <title>Laws of Large Numbers</title>
    <ns>0</ns>
    <id>38</id>
    <revision>
      <id>39</id>
      <timestamp>2013-08-01T10:05:21Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1297">== Закон больших чисел ==
Общий смысл законов больших чисел - совместное действие большого числа одинаковых и независимых случайных факторов.

Последовательность случайных величин &lt;math&gt;X_1, X_2, ..., X_n&lt;/math&gt; удовлетворяет закону больших чисел, если 

&lt;math&gt;\cfrac{X_1, X_2, ..., X_n}{n} - \cfrac{M(X_1), M(X_2), ..., M(X_n)}{n} \rightarrow_{p} 0&lt;/math&gt; при &lt;math&gt;n \rightarrow \infty&lt;/math&gt;


Разновидности законов больших чисел:
* [[Weak Law of Large Numbers]] - наиболее общий закон больших чисел
* [[Bernoulli Theorem]] - простейший закон больших чисел
* [[Центральная предельная теорема]]


== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.
* [http://www.exponenta.ru/educat/class/courses/tv/theme0/10.asp Закон больших чисел на exponenta.ru]

[[Category:Russian]]
[[Category:Probability]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>kw5a993lalbarkyfl8epm8ylhx0zpld</sha1>
    </revision>
  </page>
  <page>
    <title>Weak Law of Large Numbers</title>
    <ns>0</ns>
    <id>39</id>
    <revision>
      <id>40</id>
      <timestamp>2013-08-01T10:08:49Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4334">== Weak Law of Large Numbers ==

(Chebyshev's Theorem)

'''Теорема.''' Если &lt;math&gt;X_1, ..., X_n&lt;/math&gt; - попарно независимые случайные величины, причём их дисперсии равномерно ограничены (т.е. не превышают некоторого постоянного числа &lt;math&gt;C&lt;/math&gt;), то, как бы мало не было число &lt;math&gt;\epsilon&lt;/math&gt;, вероятность того, что

&lt;math&gt;\left| \frac{X_1 + ... + X_n}{n} - \frac{M(X_1) + ... + M(X_n)}{n} \right| &lt; \epsilon&lt;/math&gt;

будет как угодно близко к единице, если число случайных событий достаточно велико.

Или, 

&lt;math&gt;\lim_{n \rightarrow \infty} P\left(\left| \frac{X_1 + ... + X_n}{n} - \frac{M(X_1) + ... + M(X_n)}{n} \right| &lt; \epsilon\right) = 1&lt;/math&gt;


=== Доказательство ===

* Рассмотрим случайную величину &lt;math&gt;\bar{X} = \frac{X_1 + ... + X_n}{n}&lt;/math&gt;
* Найдем &lt;math&gt;M(\bar{X}) = M\left(\frac{X_1 + ... + X_n}{n}\right) = \frac{M(X_1) + ... + M(X_n)}{n}&lt;/math&gt;
* Применяя к &lt;math&gt;\bar{X}&lt;/math&gt; [[Chebyshev's Inequality|неравенство Чебышева]], получим
: &lt;math&gt;P\left(\left| \frac{X_1 + ... + X_n}{n} - \frac{M(X_1) + ... + M(X_n)}{n} \right| &lt; \epsilon\right) \geqslant 1 - \frac{D(\frac{X_1 + ... + X_n}{n})}{\epsilon^2}&lt;/math&gt;
* Т.к. &lt;math&gt;X_1 + ... + X_n&lt;/math&gt; независимые, то 
: &lt;math&gt;D\left(\frac{X_1 + ... + X_n}{n}\right) = \frac{D(X_1) + ... + D(X_n)}{n^2}&lt;/math&gt;
* Все дисперсии &lt;math&gt;D(X_i)&lt;/math&gt; ограничены постоянным числом &lt;math&gt;C&lt;/math&gt;: &lt;math&gt;D(X_i) \leqslant C&lt;/math&gt;, поэтому 
: &lt;math&gt;\frac{D(X_1) + ... + D(X_n)}{n^2} \leqslant \frac{C + ... + C}{n^2} = \frac{nC}{n^2} = \frac{C}{n}&lt;/math&gt;
: т.е. &lt;math&gt;D\left(\frac{X_1 + ... + X_n}{n}\right) \leqslant \frac{C}{n}&lt;/math&gt;
* Подставляя в неравенство, имеем
: &lt;math&gt;P\left(\left| \frac{X_1 + ... + X_n}{n} - \frac{M(X_1) + ... + M(X_n)}{n} \right| &lt; \epsilon\right) \geqslant 1 - \frac{C}{n \epsilon^2}&lt;/math&gt;
* переходя к пределу при &lt;math&gt;n \rightarrow \infty&lt;/math&gt; получим
: &lt;math&gt;\lim_{n \rightarrow \infty} P\left(\left| \frac{X_1 + ... + X_n}{n} - \frac{M(X_1) + ... + M(X_n)}{n} \right| &lt; \epsilon\right) \geqslant 1&lt;/math&gt;
: т.к. вероятность не может быть больше единицы, получаем равенство 
: &lt;math&gt;\lim_{n \rightarrow \infty} P\left(\left| \frac{X_1 + ... + X_n}{n} - \frac{M(X_1) + ... + M(X_n)}{n} \right| &lt; \epsilon\right) = 1&lt;/math&gt;

'''Q.E.D.'''



Если все случайные величины &lt;math&gt;X_i&lt;/math&gt; имеют одно и то же математическое ожидание &lt;math&gt;a&lt;/math&gt;, то формула принимает вид 
&lt;math&gt;\lim_{n \rightarrow \infty} P\left(\left| \frac{X_1 + ... + X_n}{n} - a \right| &lt; \epsilon\right) = 1&lt;/math&gt;


== Значение ==
Отдельные случайные величины могут иметь значительнй разброс, но их среднее арифметическое рассеяно мало, и можно предвидеть, какое значение оно (ср. ар.) примет. 

Или, среднее арифметическое достаточно большого количества независимых случайных величин утрачивает характер случайной величины. Объясняется это тем, что что отклонения каждой из случайных величин от своих мат. ожиданий могут быть как положительными, так и отрицательными, а в среднем арифметическом они взаимно погашаются. 


== See also ==
* [[Chebyshev's Inequality]]
* [[Laws of Large Numbers]]

== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.

[[Category:Russian]]
[[Category:Probability]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>d46ot2w3bnp7i9nnwerblc3t3n6ukx5</sha1>
    </revision>
  </page>
  <page>
    <title>Bernoulli Theorem</title>
    <ns>0</ns>
    <id>40</id>
    <revision>
      <id>41</id>
      <timestamp>2013-08-01T10:08:43Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2559">== Bernoulli Theorem ==
'''Теорема.''' Если в каждом из n независимых испытаний вероятность &lt;math&gt;p&lt;/math&gt; появления события &lt;math&gt;A&lt;/math&gt; постоянна, то как угодно близка к единицы вероятность того, что отклонение относительной частоты от вероятности &lt;math&gt;p&lt;/math&gt; будет сколь угодно малым, если число испытаний достаточно велико.

&lt;math&gt;\lim_{n \rightarrow \infty} P\left(\left|\frac{m}{n} - p\right| &lt; \epsilon\right) = 1&lt;/math&gt;


=== Доказательство ===
* &lt;math&gt;X_i&lt;/math&gt; - число появлений события в испытании &lt;math&gt;i&lt;/math&gt;. Принимает два значения:
** 1: событие наступило
** 0: событие не наступило
: &lt;math&gt;P(X_i = 1) = p, P(X_i = 0) = q = 1 - p&lt;/math&gt;
* Все величины попарно-независимы (т.к. испытания независимы)
* Их дисперисии ограничены
: &lt;math&gt;D(X_i) = pq&lt;/math&gt; (т.к. число испытаний &lt;math&gt;n = 1&lt;/math&gt;) ('''TODO''': линк)
: и не превышает 1/4
: (произведение 2-х сомножителей максимально при их равенстве, т.е. &lt;math&gt;p = q = 0.5&lt;/math&gt;)
: &lt;math&gt;D \leqslant \frac{1}{4}&lt;/math&gt;, следовательно, дисперсии ограничены числом &lt;math&gt;C = \frac{1}{4}&lt;/math&gt;
* Все условия для применения [[Weak Law of Large Numbers|теоремы Чебышева]] соблюдены, поэтому
: &lt;math&gt;\lim_{n \rightarrow \infty} P\left(\left| \frac{X_1 + ... + X_n}{n} - p \right| &lt; \epsilon\right) = 1&lt;/math&gt; (т.к. для всех &lt;math&gt;M(X_i)&lt;/math&gt; мат. ожидание есть &lt;math&gt;M(X_i) = p&lt;/math&gt;)
* &lt;math&gt;\frac{1}{n} \sum X_i = \frac{m}{n}&lt;/math&gt; - относительная частота появления события &lt;math&gt;A&lt;/math&gt;. т.е
: &lt;math&gt;\lim_{n \rightarrow \infty} P\left(\left| \frac{m}{n} - p \right| &lt; \epsilon\right) = 1&lt;/math&gt;

'''Q.E.D.'''


== See also ==
* [[Laws of Large Numbers]]
* [[Weak Law of Large Numbers]]

== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.

[[Category:Russian]]
[[Category:Probability]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>7h1gfodq4gp0tagcmyv3slkuzeoy85j</sha1>
    </revision>
  </page>
  <page>
    <title>Central Limit Theorem</title>
    <ns>0</ns>
    <id>41</id>
    <revision>
      <id>42</id>
      <timestamp>2014-07-27T19:30:50Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5375">== Central Limit Theorem ==
C.L.T. explains why [[Normal Distribution]] is so widespread 
* when values of a [[Random Variable]] are the results of a big number of independent Random Variables with limited [[Variance]]s
* then the [[Distribution]] of this RV is [[Normal Distribution]]





== Experiments ==
=== Sampling Distribution ===
C.L.T. allows us to assume that [[Sampling Distribution]]s approach Normal as the sample size grows 
* we want to show that experimentally for the SD of Mean 


Assume we want to sample from 3 distributions:
* http://habrastorage.org/files/e99/d4c/a20/e99d4ca2047b4969a9bc366507a63f8a.png
* [[Uniform Distribution]] (blue line)
* [[Lognormal Distribution]] (orange line)
* [[Exponential Distribution]] (red line)


There are 3 various degrees of skewness in these distributions

Uniform:
* http://habrastorage.org/files/15f/4dd/ff4/15f4ddff472a4335a686cfdfa5e83ead.gif
* http://habrastorage.org/files/737/4d8/03c/7374d803c1fd448d9c393b907886e05f.png

Lognormal:
* http://habrastorage.org/files/14a/549/77d/14a54977dcb84e5eb39f0f5868380665.gif
* http://habrastorage.org/files/7cf/90d/f36/7cf90df361da48bda3ea90d1d3803421.png

Exponential
* http://habrastorage.org/files/e30/f3b/352/e30f3b35268f4d61bc6f2e560430e35c.gif
* http://habrastorage.org/files/42f/406/6fb/42f4066fba924f5396986fb4d23d4356.png


{{ Hider |
   title=R code of the experiment |
   content=
&lt;pre&gt;
default.par = par()

set.seed(18213)

x = seq(-0.1, 4.1, 0.1)
yn = dlnorm(x, meanlog=0.1, sdlog=0.5)
yu = dunif(x, min=0, max=4)
ye = dexp(x)

plot(x, yn, type='l', ylim=c(0, 1), col=&quot;orange&quot;, lwd=2,
     main='the distributions from which we sample')
lines(x, yu, col=&quot;blue&quot;, lwd=2)
lines(x, ye, col=&quot;red&quot;, lwd=2)

m = 3000

generate = function(m, FUN, main, xlim, ylim, breaks=13) {
  sd.x = replicate(m, mean(FUN()))
  par(mfcol=c(1,2))
  
  hist(sd.x, breaks=breaks, prob=T, main='', xlim=xlim, ylim=ylim)
  x = seq(min(sd.x), max(sd.x), 0.01)
  y = dnorm(x=x, mean=mean(sd.x), sd=sd(sd.x))
  lines(x=x, y=y, col=&quot;blue&quot;, lwd=2)
  
  dens = density(sd.x, adjust=2)
  lines(dens, col=&quot;red&quot;, lwd=2)

  qqnorm(sd.x, col=&quot;orange&quot;, pch=19, main='')
  qqline(sd.x, lwd=2)

  mtext(main, side=3, outer=TRUE, line=-3) 
  par(mfcol=c(1,1))
}

gen.uniform = function(n) {
  function() { runif(n, min=0, max=4) }
}

gen.lnorm = function(n) {
  function() { rlnorm(n, meanlog=0.1, sdlog=0.5) }
}

gen.exp = function(n) {
  function() { rexp(n) }
}

require(animation)

n.vec = c(1:20, 50)
saveGIF({
  for (n in n.vec) {
    generate(m, gen.uniform(n), 
             xlim=c(0,4), ylim=c(0, 1.4),
             paste('Uniform Distribution, sample size = ', n))
  }
}, interval=0.3)


n.vec = c(1:40, 100)
saveGIF({
  for (n in n.vec) {
    generate(m, gen.lnorm(n), 
             xlim=c(0,3), ylim=c(0, 1.8),
             paste('Lognormal Distribution, sample size = ', n))
  }
}, interval=0.3)

n.vec = c(1:50, 100)
saveGIF({ 
  for (n in n.vec) {
    generate(m, gen.exp(n), 
             xlim=c(0,3), ylim=c(0, 1.8),
             paste('Exponential Distribution, sample size = ', n))
  }
}, interval=0.3)

generate(m, gen.uniform(n), 
         xlim=c(1.5,2.5), ylim=c(0, 4),
         paste('Uniform Distribution, sample size = ', n))
generate(m, gen.lnorm(n), 
         xlim=c(1,1.5), ylim=c(0, 6),
         paste('Lognormal Distribution, sample size = ', n))
generate(m, gen.exp(n), 
         xlim=c(0.5,1.5), ylim=c(0, 4),
         paste('Exponential Distribution, sample size = ', n))

par(default.par)
&lt;/pre&gt;
}}


[https://yadi.sk/i/-4wm3y_0XzkKN See also here]
* this is taken from [[OpenIntro Statistics (book)|OpenIntro]], figure 4.20



== Теорема (Ляпунов) ==
Если случайная величина $X$ представляет собой сумму очень большого количества взаимно-независимых случайных величин, влияние каждой из них на всю сумму ничтожно мало, то X имеет распределение, близкое к нормальному. 

'''TODO''': доказательство

=== Применение ===
Пусть &lt;math&gt;X_i&lt;/math&gt; - последовательность независимых случайных величин, каждая из которых имеет мат. ожидание и дисперсию:

&lt;math&gt;M(X_i) = a_i, D(X_i) = b_i^2&lt;/math&gt;

* Введём обозначения 
: &lt;math&gt;S_n = X_1 + ... + X_n&lt;/math&gt;
: &lt;math&gt;A_n = \sum_{i = 1}^{n} a_i&lt;/math&gt;
: &lt;math&gt;B^2 = \sum_{i = 1}^{n} b_i^2&lt;/math&gt;
* Тогда &lt;math&gt;F_n(X) = P\left(\frac{S_n - A_n}{B_n} &lt; x\right)&lt;/math&gt; - функция распределения нормированной суммы



К последовательности &lt;math&gt;X_i&lt;/math&gt; применима центральная предельная теорема, если 

&lt;math&gt;\lim_{n \rightarrow \infty} P\left(\frac{S_n - A_n}{B_n} &lt; x\right) = \frac{1}{\sqrt{2\Pi}} \int_{-\infty}^{x} e^{-z^2/2} dz
&lt;/math&gt;


== See Also ==
* [[Laws of Large Numbers]]
* [[Normal Distribution]]
* [[Weak Law of Large Numbers]]

== Sources ==
* [http://www.exponenta.ru/educat/class/courses/tv/theme0/10.asp Закон больших чисел на exponenta.ru]
* [[OpenIntro Statistics (book)]]

[[Category:Russian]]
[[Category:Probability]]
[[Category:Statistics]]
[[Category:R]]</text>
      <sha1>qtafhzfoivvdkn0pp87n9kpqa98hg7o</sha1>
    </revision>
  </page>
  <page>
    <title>Binomial Distribution</title>
    <ns>0</ns>
    <id>42</id>
    <revision>
      <id>43</id>
      <timestamp>2014-07-25T16:05:54Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7041">== Binomial Distribution ==
A binomial distribution is a Discrete [[Distribution]] of [[Random Variable]]s

=== Intuition ===
Assume there are $n$ independent experiments
* an event $A$ can either appear with probability $p$ or not appear with probability $q = 1 -p$
* an RV $X$ is the number of experiments in which $A$ appeared
* such experiments are called &quot;Bernoulli Trials&quot;


Using [[Bernoulli Formula]], can calculate that
* the probability of $A$ happening $k$ times out of $n$ trials is 
* $P_n(k) = C_n^k \ p^k q^{n-k}$, $0 \leqslant k \leqslant n$


=== Example ===
$X \sim \text{Bin}(10, 0.5)$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/binomial-distr-ex.png


== Main Properties ==
=== [[Expected Value]] ===
$E[X] = np$

* let $X$ be the # of independent experiments in which $A$ appeared 
** $X = X_1 + X_2 + ... + X_n$,
** where $X_i = 1$ if $A$ happened in experiment $i$, and $X_i = 0$ otherwise
* $E[X_i] = 1^2 \cdot p + 0^2 \cdot q = P(A)$
* $E[X] = E \left[ \sum X_i \right] = \sum E[X_i] = np$


=== [[Variance]] ===
'''Thm''' $\text{Var}[X] = npq$

'''Proof''' 
* let $X$ be the # of independent experiments in which $A$ appeared, 
** $X = X_1 + X_2 + ... + X_n$
* $X_i$ are pair-wise independent, i.e. the outcome of one experiment doesn't depend on the outcome of any other experiment
* thus,
** $\text{Var}[X] = \sum_{i = 1}^n \text{Var}(X_i)$
** $E[X_i] = P(A)$
** $\text{Var}[X_i] = E[X_i^2] - E^2[X_i] = p - p^2 = p(1 - p) = pq$
* since there are $n$  $\text{Var}[X_i]$ then we multiply it by $n$:
* $\text{Var}[X] = npq$


We say that $X$ follows the Binomial Distribution


== Examples ==
=== Example 1 ===
Произведено 10 независимых испытаний, в каждом из которых вероятность появления события равна 0.6. Найти дисперсию С.В. $X$ - числа появления события в этих испытаниях
* $n = 10, p = 0.6, q = 1 - 0.6 = 0.4 $
* $\text{Var}[X] = npq = 10 \cdot 0.6 \cdot 0.4 = 2.4$


=== Example 2 ===
Монета брошена два раза. Написать в виде таблицы закон распределения случайной величины $X$ - число выпаданий герба. 

$p = 0.5, q = 0.5$

Возможные значения: $x_0 = 0, x_1 = 1, x_2 = 2$
* $P_2(2) = C_2^2 p^2 = 0.25$
* $P_2(1) = C_2^1 pq = 0.5$
* $P_2(0) = C_2^0 q^2 = 0.25$



== Normal Approximation ==
The Bernoulli formula is cumbersome when $n$ is large 
* in some cases, the [[Normal Distribution]] is a fast way of estimating the binomial probabilities 



=== Binomial Coin Experiment ===
Link: http://socr.stat.ucla.edu/htmls/SOCR_Experiments.html
* go to the applet page and select &quot;Binomial Coin Experiment&quot;
* set # of trials to 20 and prob of success to 0.13
** we see the theoretical shape
** the applet allows to simulate coin flips and we see that the empirical distribution approaches the theoretical 
* what's the $n$ when we can obtain a unimodal and symmetric distribution?

http://habrastorage.org/files/d05/00d/a7a/d0500da7a9a54694940d278ee9b2878c.gif

{{ Hider |
   title=R code to produce the figure |
   content=
&lt;pre&gt;
require(animation)

p = 0.13
max.n = 30

saveGIF({
  for (n in 2:130) {
    x = seq(1, min(n, max.n))
    fx = dbinom(x=x, size=n, prob=p)  
    plot(x=NULL, y=NULL, xlim=c(0, max.n), ylim=c(0, 0.2),
         main=paste(&quot;binomomial distribution with n =&quot;, n),
         ylab=&quot;probability&quot;, xlab=&quot;outcome&quot;, axes=F)
    
    axis(side=1); axis(side=2)
    
    bar.width = 0.4
    par(xpd=NA)
    rect(xleft=x-bar.width, xright=x+bar.width,
         ybottom=0, ytop=fx, col='skyblue')
  }
}, interval=0.1)
&lt;/pre&gt;
}}

We see that around $n = $ 50-60 it becomes quite symmetric 
* http://habrastorage.org/files/09d/d1b/c35/09dd1bc35cbe4f8280804f6e1eb1939e.png


It's reasonable to use the Normal Distribution to approximate Binomial
* parameters: $\mu = np, \sigma = \sqrt{npq}$
* note: the sample size should be sufficiently large:
** both $n \cdot p$ and $n \cdot q$ should be at least 10
* here's the same distribution ($p=0.13$, and $n$ increasing) plus $N(np, \sqrt{npq})$

http://habrastorage.org/files/ad7/d13/3a5/ad7d133a5b254d62a83fe4c8f0d349d8.gif



{{ Hider |
   title=R code to produce the figure |
   content=
&lt;pre&gt;
saveGIF({
  for (n in 2:130) {
    x = seq(1, min(n, max.n))
    fx = dbinom(x=x, size=n, prob=p)
    
    plot(x=NULL, y=NULL, xlim=c(0, max.n), ylim=c(0, 0.2),
         main=paste(&quot;binomomial distribution with n =&quot;, n),
         ylab=&quot;probability&quot;, xlab=&quot;outcome&quot;, axes=F)
    
    par(xpd=FALSE)
    abline(v=0:30, col='grey', lty=2)
    axis(side=1); axis(side=2)

    par(xpd=NA)
    bar.width = 0.4
    rect(xleft=x-bar.width, xright=x+bar.width,
         ybottom=0, ytop=fx, col='skyblue')
    
    fn = dnorm(x=c(-1, 0, 1, x), mean=n*p, sd=sqrt(n*p*(1-p)))
    xspline(x=c(-1, 0, 1, x), y=fn, lwd=2, shape=1, border=&quot;blue&quot;)
  }
}, interval=0.1)
&lt;/pre&gt;
}}


=== Example ===
* We want to estimate the prob of observing 59 or fewer smokers in a sample of 400
* the true proportion of smokers is $p=0.20$
* Normal approximation: $\mu = np = 80$, and $\sigma = \sqrt{npq} = 8$
** so use the normal model N(80, 8) to approximate 

Compute
* $Z$ score first: $Z = \cfrac{59 - 80}{8} = -2.63$
* The corresponding left tail area is 0.0043.
* the solution with the formula (using the Binomial Distribution) is 0.0041 - approximately equal 



=== Small Intervals ===
Caution: The normal approximation may fail on small intervals
* Even when the conditions are met, the approximation can still perform poorly
* it's the case when the range of counts is small

Example:
* want to compute probabilities of observing 69, 70, 71 smokers in 400 people with $p=0.2$
* Binom: 0.0703
* Norm: 0.0476


Reason why: 
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/b/openintrostat/binom-normal-approx.png
* (source: Figure 3.19 from [[OpenIntro Statistics (book)|OpenIntro]])
* normal curve + ares between 69 and 71 is shaded
* outlined area - exact binomial probability
* Normal approx is too fine-grained (area for ND is too slim)
* solution in this case is to add extra areas on both sides (-+0.5 and ) - this is called &quot;Continuity Correction&quot; [http://en.wikipedia.org/wiki/Continuity_correction]


== Usage ==
A [[Sampling Distribution]] for a population mean follows this distribution
* see also [[Binomial Proportion Confidence Intervals]]
* and [[Binomial Proportion Test]]



== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.
* [[Data Analysis (coursera)]]
* [[OpenIntro Statistics (book)]]
* http://stat.duke.edu/courses/Spring13/sta101.001/slides/unit2lec4H.pdf
* https://en.wikipedia.org/wiki/Binomial_distribution#Normal_approximation

[[Category:Russian]]
[[Category:Probability]]
[[Category:Distributions]]
[[Category:R]]</text>
      <sha1>jmviqxj9uhk1b3p29n020toajz8h0s0</sha1>
    </revision>
  </page>
  <page>
    <title>Poisson Limit Theorem</title>
    <ns>0</ns>
    <id>43</id>
    <revision>
      <id>44</id>
      <timestamp>2013-08-01T10:09:13Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2851">== Poisson Limit Theorem ==

Пусть производятся &lt;math&gt;n&lt;/math&gt; независимых испытаний, в каждом из которых вероятность появления события &lt;math&gt;A&lt;/math&gt; равна &lt;math&gt;p&lt;/math&gt;. 

Для определения вероятности &lt;math&gt;k&lt;/math&gt; появлений события в этих испытаниях используют [[Формула Бернулли|формулу Бернулли]]. Если &lt;math&gt;p&lt;/math&gt; велико, то используют [[Ассимптотическая формула Лапласса|ассимптотическую формулу Лапласса]]. Однако и она непригодна, если &lt;math&gt;p \leqslant 0.1&lt;/math&gt;.

Если &lt;math&gt;n&lt;/math&gt; велико, то можно использовать формулу Пуассона.

Итак, найдем вероятность того, что при большом количестве испытаний событие наступит ровно &lt;math&gt;k&lt;/math&gt; раз.


* Т.к. произведение &lt;math&gt;np&lt;/math&gt; сохраняет постоянное значение, то пусть &lt;math&gt;np = \lambda&lt;/math&gt;
* По формуле Бернулли &lt;math&gt;P_n(k) = C_n^k p^k (1-p)^{n-k} &lt;/math&gt;
* Т.к. &lt;math&gt;np = \lambda&lt;/math&gt;, то &lt;math&gt;p = \frac{\lambda}{n}&lt;/math&gt;
* &lt;math&gt;P_n(k) = C_n^k \left(\frac{\lambda}{n}\right)^k \left(1 - \frac{\lambda}{n}\right)^{n - k}&lt;/math&gt;
* Т.к. &lt;math&gt;n&lt;/math&gt; большое, то найдем &lt;math&gt;\lim_{k \rightarrow \infty} P_n(k)&lt;/math&gt; [опущено - см. Гмурман, с. 68]
* Получаем &lt;math&gt;P_n(k) = \frac{\lambda^k}{k!} e^{-\lambda}&lt;/math&gt;


Эта формула выражает закон распределения Пуассона вероятности массовых (&lt;math&gt;n&lt;/math&gt; велико) и редких (&lt;math&gt;p&lt;/math&gt; мала) событий.



== Пример ==
Завод отправил 5000 изделий. Probability того, что изделие повредится - 0.0002. Найти вероятность того, что прибудут 3 негодных изделия

* &lt;math&gt;n = 5000, p = 0.0002, k = 3&lt;/math&gt;
* &lt;math&gt;\lambda = np = 5000 \cdot 0.0002 = 1&lt;/math&gt;
* По формуле Пуассона, искомая вероятность приблизительно равна 
: &lt;math&gt;P_{5000}(3) = \lambda^k \frac{e^{-\lambda}}{k!} = \frac{e^{-1}}{3!} = \frac{1}{6e} \approx 0.06&lt;/math&gt;


== See also ==
* [[Формула Бернулли]]
* [[Poisson Process]]
* [[Poisson Distribution]]

== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.

[[Category:Russian]]
[[Category:Probability]]</text>
      <sha1>l2af0bfjqaqbec9bjktgyqzovux1m5h</sha1>
    </revision>
  </page>
  <page>
    <title>Poisson Process</title>
    <ns>0</ns>
    <id>44</id>
    <revision>
      <id>45</id>
      <timestamp>2013-08-01T10:07:36Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4155">== Poisson Process ==
Рассмотрим события, наступающие в случайные моменты времени.

Потоком событий называют последовательность событий, которые наступают в случайные моменты времени. 

Примеры 
* вызовы на АТС,
* прибытие самолётов в аэропорт,
* прибытие клиентов на предприятие,
* последовательность отказов элементов.


== Свойства простейшего потока ==
Простейшим потоком называется поток, обладающий следующими свойствами:

=== Свойство стационарности ===
Probability появления &lt;math&gt;k&lt;/math&gt; событий на любом промежутке зависит только от &lt;math&gt;k&lt;/math&gt; и длины &lt;math&gt;t&lt;/math&gt; промежутка, и не зависит от начала отчёта. При этом различные промежутки времени предполагаются не пересекающимися.

=== Свойство отсутствия последствия ===
Probability появления &lt;math&gt;k&lt;/math&gt; событий на любом промежутке времени не зависит от того, появлялись или не появлялись события до этого. Т.е. предыстория потока не сказывается на вероятности появления события в ближайшем будущем. 

=== Свойство одинарности ===
За бесконечно малый промежуток времени может появится не более одного события.


Если поток представляет собой сумму очень большого числа независимых событий, влияние каждого из которых на всю сумму ничтожно мало, то суммарный поток (при условии его одинарности) близок к простейшему.


== Интенсивность потока ==
Интенсивностью потока &lt;math&gt;\lambda&lt;/math&gt; называют среднее число событий, которые появляются в единицу времени. 

Если &lt;math&gt;\lambda&lt;/math&gt; известно, то вероятность появления k событий простейшего потока определяется [[Poisson Limit Theorem|формулой Пуассона]]

&lt;math&gt;P_t(k) = (\lambda t)^k \frac{e^{-\lambda t}}{k!}&lt;/math&gt;

Эта формула удовлетворяет всем трем свойствам.

== Пример ==
В течение одной минуты на АТС в среднем поступает 2 вызова. Найти вероятность того, что за 5 минут наступит
# 2 вызова
# менее 2-х вызовов
# не менее 2-х вызовов



* Т.к. поток событий простейший, то &lt;math&gt;\lambda = 2, t = 5, k = 2&lt;/math&gt; 
* &lt;math&gt;P_t(k) = (\lambda t)^k \frac{e^{-\lambda t}}{k!}&lt;/math&gt;
:
* 1. за 5 минут наступит 2 вызова
: &lt;math&gt;P_5(2) = 10^2 \frac{e^{-10}}{2!} \approx 0.00225&lt;/math&gt;
* 2. наступит менее 2-х вызовов
: по теореме сложения,
: &lt;math&gt;P_5(k &lt; 2) = P_5(0) + P_5(1) = e^{-10} + \frac{10 e^{-10}}{1!} \approx 0.000495&lt;/math&gt;
* 3. не менее 2-х событий
: обратное событие - &quot;наступило менее 2-х событий&quot;
: &lt;math&gt;P_5(k \geqslant 2) = 1 - P_5(k &lt; 2) \approx 0.999505&lt;/math&gt;


== See also ==
* [[Poisson Limit Theorem]]
* [[Poisson Distribution]]

== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.

[[Category:Russian]]
[[Category:Probability]]</text>
      <sha1>izdj7cvv7mkandi1acpap7qih5fcumo</sha1>
    </revision>
  </page>
  <page>
    <title>Template:Hider</title>
    <ns>10</ns>
    <id>45</id>
    <revision>
      <id>46</id>
      <timestamp>2013-06-05T11:00:00Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="298">&lt;div class=&quot;mw-collapsible mw-collapsed&quot;&gt;
	&lt;div style=&quot;text-align: left;background-color: #CCCCFF;padding: 2px;&quot;&gt;{{{title|Hidden content}}}&amp;nbsp;&amp;nbsp;&lt;/div&gt;
	&lt;div class=&quot;mw-collapsible-content&quot;&gt;
		{{{content}}}
	&lt;/div&gt;
&lt;/div&gt;
&lt;noinclude&gt;
== Usage ==
Hides the content behind a spoiler
&lt;/noinclude&gt;</text>
      <sha1>3h371lc55m3apyj9tbccf71adkgdvq4</sha1>
    </revision>
  </page>
  <page>
    <title>Geometric Distribution</title>
    <ns>0</ns>
    <id>46</id>
    <revision>
      <id>47</id>
      <timestamp>2014-07-22T19:20:14Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2036">== Geometric Distribution ==
A geometric distribution is a Discrete [[Distribution]] of [[Random Variable]]s


Assume we run a series of [[Bernoulli Trial]]s where the probability of seing the event $A$ is $p$, and, therefore, the probability of not seing $A$ is $q = 1 - p$

The trials stop once $A$ occures, i.e. if $A$ occures at $k$-th trial, it didn't occur in previous $k -1$ trials

[[Random Variable]] $X$ is the number of trials we should run until we see $A$ 
* the distribution of $X$ is called ''Geomentric''

Formally, Geometric Distribution describes the waiting time until a success for indepented and identically distributed Bernoulli Random Variables



Typical questions:
* How long should we flip a coin until we get head? 
* How many times we roll a dice until we get 1?


== [[Cumulative Distribution Function]] ==
Пусть в $k-1$-ом испытании событие не появилось, а в $k$-ом появилось. Тогда по [[Chain and Sum Rules in Probability#Теорема произведения вероятностей|теореме умножения вероятностей независимых событий]] имеем следующую функцию распределения:

$P(X = k) = q^{k - 1} p$

Таким образом, для каждого $k = 0, 1, 2, ...$ получим геометрическую прогрессию, в которой p - первый член прогрессии, q - знаменатель:

$p, qp, q^2 p, ..., q^{k - 1} p, ...$

== Moments ==
* $E[X] = \cfrac{p}{1 - p}$
* $\text{Var}[X] = \cfrac{q}{p^2}$


== See Also ==
* [[Hypergeometric Distribution]]
* [[Negative Binomial Distribution]] - general case of Geometric distribution

== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.
* [[OpenIntro Statistics (book)]]

[[Category:Russian]]
[[Category:Probability]]
[[Category:Distributions]]</text>
      <sha1>dba2vlqzivmdh3mgmc7edc7vhx2o8oc</sha1>
    </revision>
  </page>
  <page>
    <title>Hypergeometric Distribution</title>
    <ns>0</ns>
    <id>47</id>
    <revision>
      <id>48</id>
      <timestamp>2013-08-02T09:46:58Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1867">== Hypergeometric Distribution ==

Пусть в партии из &lt;math&gt;N&lt;/math&gt; изделий &lt;math&gt;M&lt;/math&gt; стандартных (&lt;math&gt;M &lt; N&lt;/math&gt;). Из партии отбирают n изделий, причём изделия обратно не возвращаются. 

$X$ - случайная величина, число m стандартных изделий среди n отобранных. Возможные значения &lt;math&gt;X: 0, 1, ..., \min(M, n)&lt;/math&gt;


Probability того, что &lt;math&gt;X = m&lt;/math&gt;:
* Общее число исходов &lt;math&gt;C_N^n&lt;/math&gt;
* Число благоприятствующих исходов &lt;math&gt;X = m&lt;/math&gt;:

&lt;math&gt;C_M^m \cdot C_{N - M}^{m - n}&lt;/math&gt;

(число способов извлечь &lt;math&gt;m&lt;/math&gt; из &lt;math&gt;M&lt;/math&gt; умножить на число способов извлечь оставшиеся нестандартные детели)


Таким образом, 

&lt;math&gt;P(X = m) = \frac{C_M^m \cdot C_{N - M}^{m - n}}{C_N^n}&lt;/math&gt;

Эта формула определяет ''гипергеометрическое распределение''.


=== Пример ===
Среди 50 изделий 20 окрашеных. Найти вероятность того, что из 5 извлёченных изделий 3 будут окрашенными. 

* &lt;math&gt;N = 50, M = 20, n = 5, m = 3&lt;/math&gt;
* &lt;math&gt;P(X = 3) = \frac{C_{20}^3 \cdot C_{30}^2}{C_{50}^5} = 0.234&lt;/math&gt;

== See also ==
* [[Геометрическое распределение]]

== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.

[[Category:Russian]]
[[Category:Probability]]
[[Category:Probability Distributions]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>3cozwk7dakacvzq9n2xtrogvdto40i5</sha1>
    </revision>
  </page>
  <page>
    <title>Exponential Distribution</title>
    <ns>0</ns>
    <id>48</id>
    <revision>
      <id>49</id>
      <timestamp>2013-08-02T09:47:16Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="645">== Exponential Distribution ==

Плотность вероятности:
* &lt;math&gt;f(x) = \left\{ \begin{array}{lll} 0 &amp; \mbox{if} &amp; x &lt; 0 \\ \lambda e^{-\lambda x} &amp; \mbox{if} &amp; x \geqslant 0 \end{array} \right.&lt;/math&gt;

* &lt;math&gt;F(X) = \int_{-\infty}^{x} f(x) dx = \int_{-\infty}^{0} 0 dx + \lambda \int_{0}^{x} e^{-\lambda x} dx = 1 - e^{-\lambda x}&lt;/math&gt;

=== Моменты ===
* &lt;math&gt;M(X) = \frac{1}{\lambda}&lt;/math&gt;
* &lt;math&gt;D(X) = \frac{1}{\lambda^2}&lt;/math&gt;
* &lt;math&gt;M(X) = \sigma(X) = \frac{1}{\lambda}&lt;/math&gt;

[[Category:Russian]]
[[Category:Probability]]
[[Category:Probability Distributions]]
[[Category:Подготовка к ШАД]]</text>
      <sha1>90mlup93b31adovwrkcsg1mme5bjgrq</sha1>
    </revision>
  </page>
  <page>
    <title>Functional Programming</title>
    <ns>0</ns>
    <id>49</id>
    <revision>
      <id>50</id>
      <timestamp>2013-11-06T13:53:17Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3833">== Functional Programming  ==

Основные идеи
* Одного или нескольких типов данных
* Операциях на этих данных
* Законы, которые описывают отношения между значениями и операциями
* Никаких мутаций! (Изменений состояний)

Цель: 
* Сконцентрироваться на основных идеях
* Избежать изменения состояния
* Иметь возможность использовать абстракцию для составление сложных функций из простых


''Functional Programming'' 
* В узком смысле - программирование без изменения состояния, циклов, присваивания и других структур, присущих императивному программированию
* В широком смысле - фокусирование на функциях
* Функции как основная единица абстракции
** Функции могут быть определены где угодно, в том числе внутри других функций,
** Функции могут создаваться, возвращаться как результат, и передаваться в качестве параметров другим функциям
** Из простых функций можно составлять более сложные функции


Функции, которые принимают другие функции в качестве аргументов или возвращают в качестве результата, называют ''функциями высшего порядка''. 

=== Преимущества ===
* Легко понимать и писать
* Модульность
* Легко параллелить


== Вычисление выражений ==
Так как в функциональных языках нет никаких побочных эффектов (т.к. нет изменений состояния), то для вычисления выражения можно использовать the Substitution Model [http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-10.html#%_sec_1.1.5] 
* Основная идея: постепенно приводить выражение к некоторому значению
* Это называется ''&lt;math&gt;\lambda&lt;/math&gt;-calculus (лямбда-вычисление)'' - основа функционального программирование

''Побочный эффект (side-effect)'' изменение в однажды заданных определениях. Функции с побочным эффектом не могут быть выражены с помощью этой модели.

=== Алгоритм ===
* Вычислить все значения аргументов функции слева направо
* В коде заменить вызов функции на тело этой функции
* Заменить формальные аргументы в теле функции на значения

== Функциональные языки ==
* [[Scala]] ([[Functional Programming Principles in Scala (coursera)]])
* [[Haskell]]

== Литература ==
* Structure and Interpretation of Computer Programs [http://mitpress.mit.edu/sicp/full-text/book/book.html] [http://newstar.rinet.ru/~goga/sicp/sicp.pdf]
* А. Филд, П. Харрисон, Functional Programming.

== Sources ==
* [[Functional Programming Principles in Scala (coursera)]]

[[Category:Russian]]
[[Category:Programming]]
[[Category:Functional Programming]]</text>
      <sha1>a6y2cope6vps2d3s6l92qidca95l2q9</sha1>
    </revision>
  </page>
  <page>
    <title>Functional Programming Principles in Scala (coursera)</title>
    <ns>0</ns>
    <id>50</id>
    <revision>
      <id>51</id>
      <timestamp>2014-02-02T10:02:40Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="73205">Конспект курса &quot;Functional Programming Principles in Scala&quot;

Ссылки:
* [https://www.coursera.org/course/progfun Описание курса]
* [http://rutracker.org/forum/viewtopic.php?t=4434746 Все лекции для скачивания]
* [https://www.dropbox.com/s/kc0rc2s91f6erd8/Functional%20Programming%20Principles%20in%20Scala%20coursera.pdf Конспект лекций]


== Функции и их вычисление ==
=== Определения ===
Как только значения были определены, их больше нельзя изменить. Выражение присваивания некоторому идентификатору значения называется ''определением''.
&lt;pre&gt;
def radius = 10
def pi = 3.14159
&lt;/pre&gt;


Определения могут иметь как параметры, так и тип возвращаемого значения - в этом случае их следует называть ''функциями''.

&lt;pre&gt;
def square(x: Double) = x * x
square(2) =&gt; 4

def sumOfSquares(x: Double, y: Double) = square(x) * square(y)
def power(x: Double, y: Int): Double = ...
&lt;/pre&gt;

=== Стратегии вычисления функций ===
Для вычисления значений функции используется [[Functional Programming#Вычисление выражений|the Substitution Model]])

==== call-by-value (&lt;code&gt;CBV&lt;/code&gt;) ====
Сначала вычисляются значения аргументов, а затем вычисленные значения передаются функции

&lt;pre&gt;
* square(2 + 2)
* square(4)
* 4 * 4
* 16
&lt;/pre&gt;

Плюсы:
* выражение вычисляется только раз - с самого начала

==== call-by-name (&lt;code&gt;CBN&lt;/code&gt;) ====
Выражения передаются в качестве аргументов, которые вычисляются только при вызове внутри тела функции

&lt;pre&gt;
* square(2 + 2)
* (2 + 2) * (2 + 2)
* 4 * 4
* 16
&lt;/pre&gt;

Плюсы:
* не вычисляется, если параметры потом не используются 


Если &lt;code&gt;CBV&lt;/code&gt; заканчивает выполнение (т.е. не зацикливается и завершается), то &lt;code&gt;CBE&lt;/code&gt; так же заканчивает, но обратное не всегда верно. 

&lt;pre&gt;
def loop = loop
def first(x: Int, y: Int) = x

first(1, loop)
&lt;/pre&gt;

При &lt;code&gt;CBN&lt;/code&gt; выполнится только один раз и завершиться, а при &lt;code&gt;CBV&lt;/code&gt; зациклиться и будет выполняться бесконечно. 
По умолчанию в Scala используется &lt;code&gt;CBV&lt;/code&gt;, но, когда нужно, можно использовать &lt;code&gt;CBN&lt;/code&gt;.

&lt;pre&gt;def countOne(x: Int, y: =&gt; Int) = 1&lt;/pre&gt;

&lt;code&gt;x&lt;/code&gt; вычисляется как &lt;code&gt;CBV&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt; как &lt;code&gt;CBN&lt;/code&gt;


==== Определения ====
Определения так же могут быть &lt;code&gt;CBN&lt;/code&gt; и &lt;code&gt;CBV&lt;/code&gt;

Ключевое слово &lt;code&gt;def&lt;/code&gt; задаёт &lt;code&gt;CBN&lt;/code&gt; определение, &lt;code&gt;val&lt;/code&gt; - &lt;code&gt;CBV&lt;/code&gt;

&lt;pre&gt;
val x = 2
val y = square(2)
val z = square(x)
&lt;/pre&gt;

Для &lt;code&gt;val&lt;/code&gt; правая часть вычисляется сразу же и используется впоследствии (т.е. &lt;code&gt;y&lt;/code&gt; ссылается на &lt;code&gt;4&lt;/code&gt;, а не на &lt;code&gt;square(2)&lt;/code&gt;)

&lt;pre&gt;
def x = loop // OK
val x = loop // виснет
&lt;/pre&gt;


=== Условия ===
''Условное выражение'' &lt;code&gt;if else&lt;/code&gt; используется для выбора между двумя альтернативами

&lt;pre&gt;def abs(x: Int) = if (x &gt;= 0) x else -x&lt;/pre&gt;


=== Блоки и лексикографический контекст ===
Считается хорошим стилем программирования разбивать сложные функции на много маленьких, однако многие функции имеют значение только для какой-то конкретной реализации какого-либо алгоритма, и не предназначены для использования извне.

Например, дан алгоритм вычисления квадратного корня с помощью метода Ньютона [http://ru.wikipedia.org/wiki/Метод_Ньютона] (см. также [http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-10.html#%_sec_1.1.7])
&lt;pre&gt;
def sqrt(x: Double): Double = 
  sqrtIter(1.0, x)

def sqrtIter(guess: Double, x: Double): Double = 
  if (isGoodEnough(guess, x)) guess
  else sqrtIter(improve(guess, x), x)

def isGoodEnough(guess: Double, x: Double) = 
  abs(guess * guess - x) / x &lt; 0.001

def improve(guess: Double, x: Double) = 
  (guess + x / guess) / 2
&lt;/pre&gt;

Для того, чтобы избежать &quot;namespace pollution&quot;, можно поместить все второстепенные функции внутрь sqrt:
&lt;pre&gt;
def sqrt(x: Double): Double = {
  def sqrtIter(guess: Double, x: Double): Double = 
    if (isGoodEnough(guess, x)) guess
    else sqrtIter(improve(guess, x), x)

  def isGoodEnough(guess: Double, x: Double) = 
    abs(guess * guess - x) / x &lt; 0.001

  def improve(guess: Double, x: Double) = 
    (guess + x / guess) / 2

  sqrtIter(1.0, x)
}
&lt;/pre&gt;

В данном случае фигурные скобки определяют ''блок кода'', который так же является выражением (и, следовательно, возвращает какое-либо значение). Это называется ''лексикографическим контекстом блока''.

Область видимости:
* Все определения внутри блока кода не видимы за его пределами (локальный контекст)
* Определения снаружи блока видимы внутри блока (родительский контекст)
* Определения внутри блока (в локальном контексте) перекрывают определения за пределами этого блока (т.е. родительского контекста)

&lt;pre&gt;
val x = 0
val res = {
  val x = f(3)
  x * x
} + x
&lt;/pre&gt;

В этом примере в блоке переменная &lt;code&gt;x&lt;/code&gt; перекрывается значением, которое возвращает функция &lt;code&gt;f&lt;/code&gt;, затем блок возвращает значение, которое затем прибавляется к изначальному &lt;code&gt;x&lt;/code&gt;. 


== Функции высшего порядка ==
Функции в Scala являются полноправными объектами. То есть функцию можно передать как параметр или вернуть, как значение. Функции, которые это делают, называются ''функциями высшего порядка''. 

&lt;pre&gt;
def sum(f: Int =&gt; Int, a: Int, b: Int): Int = 
  if (a &gt; b) 0
  else f(a) + sum(f, a + 1, b)

def sumInts(a: Int, b: Int) = sum(id, a, b)
def sumCubes(a: Int, b: Int) = sum(cube, a, b)
def sumFactorials(a: Int, b: Int) = sum(fact, a, b)

def id(x: Int): Int = x
def cube(x: Int): Int = x * x * x
def fact(x: Int): Int = if (x == 0) 1 else fact(x - 1)
&lt;/pre&gt;

Тип &lt;code&gt;A =&gt; B&lt;/code&gt; описывает функцию, принимающую в аргумент типа &lt;code&gt;A&lt;/code&gt; и возвращающую результат типа &lt;code&gt;B&lt;/code&gt;. &lt;code&gt;Int =&gt; Int&lt;/code&gt; -  принимает &lt;code&gt;Int&lt;/code&gt;, возвращает &lt;code&gt;Int&lt;/code&gt;. 

Функцию без имени называют ''анонимной функцией''

&lt;pre&gt;
(x: Int) =&gt; x * x * x
(x: Int, y: Int) =&gt; x + y
&lt;/pre&gt;

В левой части функции перечисляются параметры, а правая часть называется ''телом'' анонимной функции. 

Параметры функции можно опустить, если компилятор может их вычислить сам.

&lt;pre&gt;
def sumInts(a: Int, b: Int) = sum(x =&gt; x, a, b)
def sumCubes(a: Int, b: Int) = sum(x =&gt; x * x * x, a, b)
&lt;/pre&gt;

=== Каррирование ===
Рассмотрим пример 

&lt;pre&gt;def sumInts(a: Int, b: Int) = sum(x =&gt; x, a, b)&lt;/pre&gt;

Аргументы &lt;code&gt;a&lt;/code&gt; и &lt;code&gt;b&lt;/code&gt; просто передаются без изменений, поэтому возможно эту функцию возможно сделать еще короче

&lt;pre&gt;
def sum(f: Int =&gt; Int): (Int, Int) = {
  def sumF(a: Int, b: Int): Int =
    if (a &gt; b) 0
    else f(a) + sum(a + 1, b)

  sumF
}
&lt;/pre&gt;

&lt;code&gt;sum&lt;/code&gt; - это функция, которая возвращает другую функцию, которая &quot;помнит&quot; &lt;code&gt;f&lt;/code&gt; и знает, как нужно вычислять значение. Далее можно написать

&lt;pre&gt;
def sumInts = sum(x =&gt; x)
def sumCubes = sum(x =&gt; x * x * x)
def sumFactorials = sum(fact)
&lt;/pre&gt;

Т.е. 
&lt;pre&gt;sumCubes(1, 10) == (sum(cube))(1, 10)&lt;/pre&gt;

&lt;code&gt;sum(cube)&lt;/code&gt; возвращает функцию, которая тут же применяется к аргументам 1 и 10.

В Scala для таких функций существует специальный синтаксис:
&lt;pre&gt;
def sum(f: Int =&gt; Int)(a: Int, b: Int): Int = 
  if (a &gt; b) 0 else f(a) + sum(f)(a + 1, b)
&lt;/pre&gt;

Это называется [[Functional Programming#Карринг|''каррингом'']].


=== Пример: Нахождение неподвижной точки ===
Нахождение неподвижной точки (Fixed Point) [http://ru.wikipedia.org/wiki/Неподвижная_точка] [http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-12.html#%_sec_Temp_106]

&lt;math&gt;x&lt;/math&gt; называется ''неподвижной точкой'' функции &lt;math&gt;f&lt;/math&gt; если &lt;math&gt;f(x) = x&lt;/math&gt;

Для некоторых функций мы можем найти неподвижную точку, применив функцию к некоторому начальному значению, затем применив эту же функцию к полученному результату, затем опять и т.п.

&lt;math&gt;x, f(x), f(f(x)), f(f(f(x))), ...&lt;/math&gt;

до тех пор, пока два соседних члена такой последовательности отличаются незначительно. 


&lt;pre&gt;
val tolerance = 0.0001

def isCloseEnough(x: Double, y: Double) =
  abs((x - y) / x) / x &lt; tolerace

def fixedPoint(f: Double =&gt; Double)(firstGuess: Double) = {
  def iterate(guess: Double): Double = {
    val next = f(guess)
    if (isCloseEnough(guess, next)) next
    else iterate(next)
  }
  iterate(firstGuess)
}
&lt;/pre&gt;

Функция &lt;math&gt;f = \sqrt{x}&lt;/math&gt; возвращает число y такое, что &lt;math&gt;y \cdot y = x&lt;/math&gt;, или, если разделить на &lt;math&gt;y&lt;/math&gt;, &lt;math&gt;y = \frac{x}{y}&lt;/math&gt;

Следовательно,  &lt;math&gt;f = \sqrt{x}&lt;/math&gt; - это неподвижная точка функции &lt;math&gt;y = \frac{x}{y}&lt;/math&gt;

&lt;pre&gt;def sqrt(x: Double) = fixedPoint(y =&gt; x / y)(1.0)&lt;/pre&gt;

Однако, такая функция не сойдётся, а будет колебаться: 1.0, 2.0, 1.0, 2.0, ...

Этого можно избежать с помощью нахождения среднего между двумя последними значениями:

&lt;pre&gt;def sqrt(x: Double) = fixedPoint(y =&gt; (x + x / y) / 2)(1.0)&lt;/pre&gt;

Эта техника стабилизации колеблющейся функции называется ''average damp'', и она достаточно общая для того, чтобы вынести эту логику в отдельную функцию:

&lt;pre&gt;def averageDamp(f: Double =&gt; Double)(x: Double) = (x + f(x)) / 2&lt;/pre&gt;

В итоге получаем
&lt;pre&gt;def sqrt(x: Double) = fixedPoint(averageDamp(x =&gt; x / y))(1.0)&lt;/pre&gt;


=== Пример: Sets ===
''Синонимом'' (type alias) называют новый идентификатор для уже существующего типа.

Для множеств мы можем определить следующий синоним:
&lt;pre&gt;type Set = Int =&gt; Boolean&lt;/pre&gt;

Т.е. множество можно представить как функцию, которая принимает число и возвращает &lt;code&gt;true&lt;/code&gt;, если это число входит в множество, и &lt;code&gt;false&lt;/code&gt; в противном случае.

Например, чтобы представить множество всех отрицательных чисел, можно написать следующие
&lt;pre&gt;(x: Int) =&gt; x &lt; 0&lt;/pre&gt;

Соответственно, функция &lt;code&gt;contains&lt;/code&gt; принимает следующий вид:
&lt;pre&gt;def contains(s: Set, elem: Int): Boolean = s(elem)&lt;/pre&gt;


== Функции и структуры данных ==
Как с помощью функций создавать и инкапсулировать структуры данных.

=== Пример: Вещественные числа ===
Мы хотим спроектировать пакет, позволяющий выполнять арифметические операции над вещественными числами.

Вещественное число можно представить в виде двух чисел &lt;math&gt;x&lt;/math&gt; и &lt;math&gt;y&lt;/math&gt;: числитель &lt;math&gt;x&lt;/math&gt; и знаменатель &lt;math&gt;y&lt;/math&gt;

&lt;pre&gt;
class Rational(x: Int, y: Int) {
  def numer = x
  def denom = y
}
&lt;/pre&gt;

В этом определении &lt;code&gt;Rational&lt;/code&gt; в код добавляется
* новый тип - &lt;code&gt;Rational&lt;/code&gt;
* конструктор, с помощью которого можно создавать элементы типа &lt;code&gt;Rational&lt;/code&gt;

&lt;pre&gt;new Rantional(1, 2) // конструктор&lt;/pre&gt;

Определения &lt;code&gt;numer&lt;/code&gt; и &lt;code&gt;denum&lt;/code&gt; называются членами класса. Доступ к членам класса производится с помощью инфиксного оператора &lt;code&gt;.&lt;/code&gt; (точка):

&lt;pre&gt;
x.numer 
x.denum
&lt;/pre&gt;

Над вещественными числами можно совершать следующие операции:
* &lt;math&gt;\cfrac{n_1}{d_1} + \cfrac{n_2}{d_2} = \cfrac{n_1 d_2 + n_2 d_1}{d_1 d_2}&lt;/math&gt;
* &lt;math&gt;\cfrac{n_1}{d_1} - \cfrac{n_2}{d_2} = \cfrac{n_1 d_2 - n_2 d_1}{d_1 d_2}&lt;/math&gt;
* &lt;math&gt;\cfrac{n_1}{d_1} \cdot \cfrac{n_2}{d_2} = \cfrac{n_1 n_2}{d_1 d_2}&lt;/math&gt;
* &lt;math&gt;\cfrac{n_1}{d_1} / \cfrac{n_2}{d_2} = \cfrac{n_1 d_2}{d_1 n_2}&lt;/math&gt;
* &lt;math&gt;\cfrac{n_1}{d_1} = \cfrac{n_2}{d_2} \iff n_1 d_2 = d_1 n_2&lt;/math&gt;

Для каждой из этих операций мы можем создать функцию

&lt;pre&gt;
def addRational(r: Rational, s: Rational): Rational = 
  new Rational(r.numer * s.denom + s.numer * r.denom, r.denom * s.denom)

//...

def makeString(r: Rational) = 
  r.numer + &quot;/&quot; + r.denom
&lt;/pre&gt;

Но эти функции можно поместить внутрь абстракции &lt;code&gt;Rational&lt;/code&gt; - тогда такие фукнции будут называться ''методами''. 


&lt;pre&gt;
class Rational(x: Int, y: Int) {
  def numer = x
  def denom = y

  def add(r: Rational) = 
    new Rational(numer * r.denom + r.numer * denom, denom * r.denom)

  //...

  def override toString = numer + &quot;/&quot; + denom
}
&lt;/pre&gt;

(Ключевое слово &lt;code&gt;override&lt;/code&gt; говорит о том, что метод &lt;code&gt;toString&lt;/code&gt; уже существует)

&lt;pre&gt;
val x = new Rational(1, 3)
val y = new Rational(5, 7)
val z = new Rational(9, 11)

x.add(y).mul(z)
&lt;/pre&gt;

Можно заметить, что в некоторых случаях дробь можно упростить (сократить)

&lt;pre&gt;
class Rational(x: Int, y: Int) {
  private def gcd(a: Int, b: Int): Int = 
    if (b == 0) a else gcd(b, a % b)

  private val g = gcd(x, y)

  def numer = x / g
  def denom = y / g

  //...
}
&lt;/pre&gt;

Ключевое слово &lt;code&gt;private&lt;/code&gt; используется в случаях, когда члены класса должны быть видимы только внутри определения класса и не должны быть видимы снаружи (т.е. к ним можно получить доступ только внутри класса &lt;code&gt;Rational&lt;/code&gt;).


=== Конструкторы ===
Определения класса неявно объявляет и его конструктор. Такой конструктор называется главным конструктором. 

Главный конструктор 
* принимает параметры класса 
* выполняет все выражения в теле класса

Мы так же можем объявить вспомогательные конструкторы - они объявляются с помощью метода с называнием &lt;code&gt;this&lt;/code&gt;:

&lt;pre&gt;
class Rational(x: Int, y: Int) {
  //...

  def this(x: Int) = this(x, 1)
}

new Rational(2) // -&gt; 2/1
&lt;/pre&gt;


=== Идентификаторы и Операторы ===
В Scala возможно написать 

&lt;pre&gt;
r add s
r mul s
&lt;/pre&gt;

вместо

&lt;pre&gt;
r.add(s)
r.mul(s)
&lt;/pre&gt;

И оператор может быть использован, как идентификатор.

Правила наименования идентификаторов
* идентификатор может начинаться с буквы и состоять из букв и цифр
* идентификатор может начинаться с операторного символа и состоять из других операторных символов 
* &lt;code&gt;_&lt;/code&gt; (нижнее подчеркивание) считается буквой
* буквенно-цифровые идентификаторы могут оканчиваться подчёркиванием, за которым следуют операторные символы

Например, &lt;code&gt;x1&lt;/code&gt;, &lt;code&gt;*&lt;/code&gt;, &lt;code&gt;+?%&amp;&lt;/code&gt;, &lt;code&gt;vector_++&lt;/code&gt;, &lt;code&gt;counter_=&lt;/code&gt;.

Таким образом, мы можем определить следующие методы:

&lt;pre&gt;
class Rational(x: Int, y: Int) {
  def numer = x
  def denom = y

  def +(r: Rational) = //...
  def -(r: Rational) = //...
  def *(r: Rational) = //...

  //...
}

val x = new Rational ...
val y = new Rational ...

x * x + y * y
// тоже самое, что 
(x * x) + (y * y)
&lt;/pre&gt;


Приоритеты у операторов определяются первым символом их имени. Приоритет:
* буквы
* &lt;code&gt;|&lt;/code&gt;
* &lt;code&gt;^&lt;/code&gt;
* &lt;code&gt;&amp;&lt;/code&gt;
* &lt;code&gt;&lt; &gt;&lt;/code&gt;
* &lt;code&gt;= !&lt;/code&gt;
* &lt;code&gt;:&lt;/code&gt;
* &lt;code&gt;+ -&lt;/code&gt;
* &lt;code&gt;* / %&lt;/code&gt;
* все остальные специальные символы

Пример:

&lt;pre&gt;
a + b ^? c ^? d less a ==&gt; b | c
((a + b) ^? (c ^? d)) less ((a ==&gt; b) | c)
&lt;/pre&gt;


=== Создание иерархий классов ===
''Абстрактным классом'' называется класс, который может содержать методы, которые ещё не реализованы. 

Рассмотрим пример - множество целых чисел.
&lt;pre&gt;
abstract class IntSet {
  def incl(x: Int): IntSet
  def contains(x: Int): Boolean
}
&lt;/pre&gt;

Оператор &lt;code&gt;new&lt;/code&gt; неприменим к абстрактным классам - т.е. нельзя создать объект такого класса. 

''Расширением'' называется отношение между классами, в котором один из классов является ''базовым'' или ''суперклассом'' (superclass) для второго класса - ''подкласса'' (subclass). Базовый класс предоставляет свои методы для использования подклассу, который, в свою очередь, может добавлять новые методы (т.е. ''расширять'' базовый класс).

Если класс расширяет абстрактный класс, то он должен реализовать его абстрактные методы.

&lt;pre&gt;
class Empty extends IntSet {
  def contains(x: Int): Boolean = false
  def incl(x: Int): IntSet = new NonEmpty(x, new Empty, new Empty)
}

class NonEmpty(elem: Int, left: IntSet, right: IntSet) extends IntSet {
  def contains(x: Int): Boolean = 
    if (x &lt; elem) left contains x
    else if (x &gt; else) right contains x
    else true

  def incl(x: Int): IntSet = 
    if (x &lt; elem)
      new NonEmpty(elem, left incl x, right)
    else if (x &gt; elem)
      new NonEmpty(elem, left, right incl x)
    else this
}
&lt;/pre&gt;

Оба класса &lt;code&gt;Empty&lt;/code&gt; и &lt;code&gt;NonEmpty&lt;/code&gt; расширяют &lt;code&gt;IntSet&lt;/code&gt; и оба соответствуют одному и тому же типу &lt;code&gt;IntSet&lt;/code&gt; - объект типа &lt;code&gt;Empty&lt;/code&gt; или &lt;code&gt;NonEmpty&lt;/code&gt; может быть использован везде, где требуется объект типа &lt;code&gt;IntSet&lt;/code&gt;.

&lt;code&gt;IntSet&lt;/code&gt; является базовым классом для &lt;code&gt;Empty&lt;/code&gt; и &lt;code&gt;NonEmpty&lt;/code&gt;, а &lt;code&gt;Empty&lt;/code&gt; и &lt;code&gt;NonEmpty&lt;/code&gt; являются подклассами класса &lt;code&gt;IntSet&lt;/code&gt;.

Классы &lt;code&gt;Empty&lt;/code&gt; и &lt;code&gt;NonEmpty&lt;/code&gt; реализуют абстрактные определения incl и contains из &lt;code&gt;IntSet&lt;/code&gt;. Так же возможно переопределить существующие неабстрактные определения родительского класса в подклассе с помощью ключевого слова override.

&lt;pre&gt;
abstract class Base {
  def foo = 1
  def bar: Int
}

class Sub extends Base {
  override def foo = 2
  def bar = 3
}
&lt;/pre&gt;

==== Value parameters ====
Для определения полей класса можно в конструкторе использовать ключевое слово val

&lt;pre&gt;
class Cons(val head: Int, val tail: IntList) extends IntList {
  // ...
}
&lt;/pre&gt;

Эта запись эквивалентна следующему:

&lt;pre&gt;
class Cons(_head: Int, _tail: IntList) extends IntList {
  val head = _head
  val tail = _tail
  // ...
}
&lt;/pre&gt;

==== Синглтоны ====
В этом примере нужен только один EmptySet, и нет необходимости каждый раз создавать новый объект, и мы можем определить один ''объект-синглтон''. Существует только один объект-синглтон и нельзя создать больше.

&lt;pre&gt;
object Empty extends IntSet {
  def contains(x: Int): Boolean = false
  def incl(x: Int): IntSet = new NonEmpty(x, new Empty, new Empty)
}
&lt;/pre&gt;


==== Traits ====
Как в Java, так и в Scala, класс может иметь только один суперкласс. Для того, чтобы иметь возможность переиспользования кода из нескольких суперклассов, используются ''trait-ы'' (или ''типажи'' [http://ru.wikipedia.org/wiki/Типаж_(абстрактный_тип)])

Объявление trait-а похоже на объявление абстрактного класса, однако подкласс может использовать несколько trait-ов с помощью ключевого слова with

&lt;pre&gt;
trait Planar {
  def height
  def width
  def surface = heigh * width
}

class Square extends Shape with Planar with Movable {
  // ...
}
&lt;/pre&gt;


Trait-ы похожи на интерфейсы в Java, но 
* они могут содержать поля и
* конкретные методы


=== Организация кода ===
==== Точка входа в приложение ====
Точкой входа в приложение называется место, с которого начинает выполняться программа. В Scala этим местом является метод main:

&lt;pre&gt;
object Hello {
  def main(args: Array[String]) = println(&quot;hw!&quot;)
}
&lt;/pre&gt;


Для того, чтобы запустить приложение, нужно написать

&lt;pre&gt;scala Hello&lt;/pre&gt;

==== Пакеты ====
Пакеты используются для организации классов и объектов

&lt;pre&gt;
package progfun.exmaple

object Hello {
  def main(args: Array[String]) = println(&quot;hw!&quot;)
}
&lt;/pre&gt;

''Полное имя класса'' ('fully-qualified name') состоит из названия пакета и имени класса, например, &lt;code&gt;progfun.example.Hello&lt;/code&gt;

Для старта приложения нужно указывать полное имя класса:
&lt;pre&gt;scala progfun.example.Hello&lt;/pre&gt;

==== Импорты ====
Мы можем ссылаться на класс/объект с помощью его полного имени

&lt;pre&gt;val r = new week3.Rational(1, 2)&lt;/pre&gt;

Но это неудобно, и поэтому можно сделать импорт из другого пакета и затем использовать только короткое имя класса

&lt;pre&gt;
import week3.Rational
val r = new Rational(1, 2)
&lt;/pre&gt;

Так же можно перечислить, какие именно классы нужно импортировать из пакета, или импортировать все
&lt;pre&gt;
import week3.{Rational, Hello}
import week3._ // wildcard import
&lt;/pre&gt;

Импортировать можно не только из пакетов, но и из объектов

Некоторые классы и объекты импортируются автоматически. К их числу относится содержимое следующих пакетов
* java.lang
* scala
* scala.predef


== Типы ==
=== Иерархии типов в Scala ===
* Базовым типом для всех типов в Scala является тип &lt;code&gt;Any&lt;/code&gt;, который содержит базовые методы типа &lt;code&gt;==&lt;/code&gt;, &lt;code&gt;!=&lt;/code&gt; и т.п.
* Для всех классов базовым классом является &lt;code&gt;AnyRef&lt;/code&gt; (который является синонимом для &lt;code&gt;java.lang.Object&lt;/code&gt;)
* Для примитивов базовым типом является тип &lt;code&gt;AnyVal&lt;/code&gt;

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/class-hierarchy.png&quot; /&gt;


* Тип &lt;code&gt;Nothing&lt;/code&gt; находится в самом низу иерархии и является подтипом для всех типов. 
* Так же в Scala существует тип &lt;code&gt;Null&lt;/code&gt;, который является типом для значения &lt;code&gt;null&lt;/code&gt;. &lt;code&gt;Null&lt;/code&gt; является подклассом для всех подклассов &lt;code&gt;AnyRef&lt;/code&gt;

&lt;pre&gt;
val x = null // x: Null
val y: String = null // y: String
val z: Int = null // error: type mismatch (не подкласс AnyRef)
&lt;/pre&gt;


=== Параметризованные типы ===
Рассмотрим ''Cons-список'' - неизменяемый связный список, который строится из следующих элементов
* &lt;code&gt;Cons&lt;/code&gt; - ячейка, содержащая элемент и ссылку на следующую часть списка
* &lt;code&gt;Nil&lt;/code&gt; - пустой список 

&lt;pre&gt;
trait IntList ...
class Cons(val head: Int, val tail: IntList) extends IntList ...
class Nil extends IntList ...
&lt;/pre&gt;

Однако это определение слишком узко: такой список можно использовать лишь с типом Int. Но мы можем обобщить определение нашего списка с помощью ''параметров типа''

&lt;pre&gt;
trait List[T] ...
class Cons(val head: T, val tail: List[T]) extends List[T] ...
class Nil extends List[T] ...
&lt;/pre&gt;

Функции, как и классы, так же могут иметь такие параметры
&lt;pre&gt;
def signleton[T](elem: T) = new Cons[T](elem, new Nil[T])
signleton[Int](1)
signleton[Boolean](true)
&lt;/pre&gt;

Однако Scala может выводить нужный тип, и поэтому параметр можно опустить
&lt;pre&gt;
signleton(1)
signleton(true)
&lt;/pre&gt;

=== Функции как объекты ===
Функции в Scala являются объектами
Функциональный тип A =&gt; B на самом деле является сокращением от scala.Function[A, B], который определён как

&lt;pre&gt;
package scala 
trait Function1[A, B] {
  def apply(x: A): B
}
&lt;/pre&gt;

То есть, функции - это объекты, у которых есть метод &lt;code&gt;apply&lt;/code&gt;

Объявление анонимной функции можно записать с помощью класса следующим образом:

&lt;pre&gt;
// anonimous
(x: Int) =&gt; x * x

{ 
  class AnonFunc extends Function1[Int, Int] {
    def apply(x: Int) = x * x
  }

  new AnonFunc
} 
&lt;/pre&gt;

Или, используя синтаксис для объявления анонимных классов

&lt;pre&gt;
new Function1[Int, Int] {
  def apply(x: Int) = x * x
}
&lt;/pre&gt;

Например,

&lt;pre&gt;
val f = (x: Int) =&gt; x * x
f(7)
&lt;/pre&gt;

Превращается в

&lt;pre&gt;
val f = new Function1[Int, Int] {
  def apply(x: Int) = x * x
}
f.apply(7)
&lt;/pre&gt;

Методы не являются функциями, но их так же можно использовать, как функции - и они конвертируются в функции автоматически следующим образом

&lt;pre&gt;(x: Int) =&gt; f(x)&lt;/pre&gt;


=== Подтипы и генерики ===
==== Граничные типы (Type Bounds) ====
Рассмотрим метод &lt;code&gt;assertAllPos&lt;/code&gt;, который
* Принимает &lt;code&gt;IntSet&lt;/code&gt;
* Возвращает полученный &lt;code&gt;IntSet&lt;/code&gt;, если все его элементы положительные
* Выбрасывает исключение в противном случае

Какой тип лучше всего подходит для параметра этого метода?

&lt;pre&gt;def assertAllPos(s: IntSet): IntSet&lt;/pre&gt;

Но
* &lt;code&gt;assertAllPos(Empty)&lt;/code&gt; должен вернуть &lt;code&gt;Empty&lt;/code&gt;
* &lt;code&gt;assertAllPos(NonEmpty)&lt;/code&gt; должен вернуть &lt;code&gt;NonEmpty&lt;/code&gt;

Это можно сделать с помощью ''верхней границы'' (''upper bound'') параметризованного типа

&lt;pre&gt;def assertAllPos[S &lt;: IntSet](r: S): S = ...&lt;/pre&gt;

Это определение означает, что параметр &lt;code&gt;S&lt;/code&gt; может принимать значения только типов, соответствующих &lt;code&gt;IntSet&lt;/code&gt; (т.е. являющихся либо объектами этого класса, либо любого из его подклассов).

В общем случае используются следующие обозначения:
* &lt;code&gt;S &lt;: T&lt;/code&gt; - верхняя граница (ограничение сверху), &lt;code&gt;S&lt;/code&gt; является подтипом &lt;code&gt;T&lt;/code&gt;
* &lt;code&gt;S &gt;: T&lt;/code&gt; - нижняя граница (ограничение снизу), &lt;code&gt;S&lt;/code&gt; является базовым типом (супертипом) для &lt;code&gt;T&lt;/code&gt;, или &lt;code&gt;T&lt;/code&gt; является подтипом для &lt;code&gt;S&lt;/code&gt;

Так же возможно одновременно ограничивать тип как сверху, так и снизу. 
Например, &lt;code&gt;[S &gt;: NonEmpty &lt;: IntSet]&lt;/code&gt; ограничивает &lt;code&gt;S&lt;/code&gt; между &lt;code&gt;IntSet&lt;/code&gt; и &lt;code&gt;NonEmpty&lt;/code&gt;.

=== Ковариация (Covariance) ===
Если &lt;code&gt;NonEmpty &lt;: IntSet&lt;/code&gt;, выполняется ли &lt;code&gt;List[NonEmpty] &lt;: List[IntSet]&lt;/code&gt;?

Такое отношение называется ''ковариацией'', а типы, которые поддерживают это, называются ''ковариантными''. 

Однако ковариация не во всех случаях имеет смысл. Например, массивы в Java ковариантны, но это вызывает ряд проблем. Рассмотрим следующий код:

&lt;pre&gt;
NonEmpty[] a = new NonEmpty[] { new NonEmpty(...) }
IntSet[] b = a

b[0] = Empty
NonEmpty s = a[0] // ArrayStoreException
&lt;/pre&gt;

==== Принцип подстановки Лисков ====
Если &lt;code&gt;A &lt;: B&lt;/code&gt;, то тогда всё, что можно сделать со значением типа &lt;code&gt;B&lt;/code&gt;, должно выполняться и для значений типа &lt;code&gt;A&lt;/code&gt;. 


Как видно из примера, ковариация не всегда приносит пользу. Некоторые типы должны быть ковариантными, а некоторые не должны. 
Однако, если соблюсти некоторые условия, то неизменяемые типы могут быть ковариантными. Например, &lt;code&gt;List&lt;/code&gt; может быть ковариантным.

Допустим, &lt;code&gt;C[T]&lt;/code&gt; - параметризованный тип, а &lt;code&gt;A&lt;/code&gt; и &lt;code&gt;B&lt;/code&gt; типы, такие, что &lt;code&gt;A &lt;: B&lt;/code&gt;. Существуют три возможных отношения между C[A] и C[B]:

* C[A] &lt;: C[B], т.е. тип C[A] является подтипом C[B]. Данное отношение называют ''ковариантным'' (covariant)
* C[A] &gt;: C[B], т.е. тип C[B] является подтипом C[A]. Данное отношение называют ''контравариантным'' (contravariant)
* ни C[A], ни C[B] не являются подтипом друг друга. Такое отношение называют ''невариантным'' (non-variant)

В Scala используют следующие обозначения:
&lt;pre&gt;
class C[+A] {...} // covariant
class C[-A] {...} // contravariant
class C[A] {...}  // non-variant
&lt;/pre&gt;

==== Типы для функций ====
* Если &lt;code&gt;A2 &lt;: A1&lt;/code&gt; и &lt;code&gt;B1 &lt;: B2&lt;/code&gt;,
* &lt;code&gt;то A1 =&gt; B1 &lt;: A2 =&gt; B2&lt;/code&gt;

Т.е. функции контраварианты в типах их аргументах и ковариантны в типах их результатах. 

Таким образом, имеем следующее определение для функций:
&lt;pre&gt;
package scala 

trait Function1[-T, +U] {
  def apply(x: T): U
}
&lt;/pre&gt;

В примере с массивом проблемной операцией была операция обновления массива. Если представить массив в виде класса, то получим 
&lt;pre&gt;
class Array[+T] {
  def update(x: T)
}
&lt;/pre&gt;

В этом классе проблема вызвана
* Ковариантным параметром типа &lt;code&gt;T&lt;/code&gt;
* Который используется для параметра в методе &lt;code&gt;update&lt;/code&gt;

Компилятор Scala проверяет, что в коде нет таких проблемных комбинаций. 

Итого,
* Ковариантные типы могут быть использованы только в результатах методов
* Контравариантные типы только в параметрах методов
* Инвариантные методы могут использоваться везде

Мы можем сделать &lt;code&gt;List&lt;/code&gt; ковариантным
&lt;pre&gt;
trait List[+T] {...}
object EmptyList extends List[Nothing] {...}
&lt;/pre&gt;

Мы хотели бы иметь объект-синглтон для пустого списка, ведь для пустого списка разницы нет, что внутри, он всегда пуст. 


Рассмотрим метод &lt;code&gt;prepend&lt;/code&gt; который добавляет новый элемент и возвращает новый список 
&lt;pre&gt;
trait List[+T] {
  def prepend(elem: T): List[T] = new Cons(elem, this)
}
&lt;/pre&gt;

Такое определение не пройдет проверку на вариантность, так как ковариантный тип, использующийся в параметре метода. 

Более того, это нарушает принцип подстановки Лисков. Пусть у нас есть список &lt;code&gt;xs&lt;/code&gt; типа &lt;code&gt;List[IntSet]&lt;/code&gt;

&lt;pre&gt;
xs.prepend(Empty)
&lt;/pre&gt;

К такому списку пустое множество. Но если рассмотреть список &lt;code&gt;ys&lt;/code&gt; типа &lt;code&gt;List[NonEmpty]&lt;/code&gt;, то мы получим ошибку при попытке присоединить пустой список:

&lt;pre&gt;
ys.prepend(Empty) // type mismatch, required: NonEmpty, found: Empty
&lt;/pre&gt;

Т.е. &lt;code&gt;List[NonEmpty]&lt;/code&gt; не может быть подтипом &lt;code&gt;List[IntSet]&lt;/code&gt;

Каким образом можно исправить это?

Мы можем ограничить снизу параметр типа для метода &lt;code&gt;prepend&lt;/code&gt;

&lt;pre&gt;
def prepend[U &gt;: T](elem: U): List[U] = new Cons(elem, this)
&lt;/pre&gt;

Это проходит проверку на вариантность потому что
* ковариантные параметры типов могут использоваться в качестве нижней границы для типов в методах
* аналогично, контравариантные параметры типов могут использоваться в качестве верхней границы

И, наконец, рассмотрим следующую функцию

&lt;pre&gt;
def f(xs: List[NonEmpty], x: Empty) = xs prepend x
&lt;/pre&gt;

Типом возвращаемого значения этой функции будет &lt;code&gt;List[IntSet]&lt;/code&gt;



== Сопоставление с образцом (Pattern Matching) ==
В качестве примера рассмотрим небольшой интерпретатор для арифметических операций. Все выражения могут быть представлены в виде иерархии классов, с базовым trait-ом &lt;code&gt;Expr&lt;/code&gt; и подклассами &lt;code&gt;Number&lt;/code&gt; и &lt;code&gt;Sum&lt;/code&gt; (ограничимся только числами и операцией сложения).

Мы можем использовать ООП-подход 
&lt;pre&gt;
trait Expr {
  def eval: Int
}

class Number(n: Int) extends Expr {
  def eval: Int = n
}

class Sum(e1: Expr, e2: Expr) extends Expr {
  def eval: Int = e1.eval + e2.eval
}
&lt;/pre&gt;

Ограничение такого подхода:
* Что если мы захотим упростить выражения, используя некоторый набор правил? 
* Например &lt;math&gt;a \cdot b + a \cdot c = a \cdot (b + c)&lt;/math&gt;. 
* Проблема состоит в том, что это упрощение не локальное, т.е. его нельзя инкапсулировать в метод только одного объекта 
* Необходимо вносить изменения во все классы при добавлении нового метода

=== Case Classes ===
Рассмотрим следующее определение:
&lt;pre&gt;
trait Expr
case class Number(n: Int) extends Expr
case classs Sum(e1: Expr, e2: Expr) extends Expr

object Number {
  def apply(n: Int) = new Number(n)
}

object Sum {
  def apply(e1: Expr, e2: Expr) = new Sum(e1, e2)
}
&lt;/pre&gt;

Объекты &lt;code&gt;Number&lt;/code&gt; и &lt;code&gt;Sum&lt;/code&gt; нужны для того, чтобы можно было писать &lt;code&gt;Number(1)&lt;/code&gt; вместо &lt;code&gt;new Number(1)&lt;/code&gt; (такие объекты называются ''companion objects'').

''Сопоставление с образцом (pattern matching)'' - генерализация конструкции &lt;code&gt;switch&lt;/code&gt; из java для иерархий классов. Классы, помеченные ключевым словом &lt;code&gt;case&lt;/code&gt; могут использоваться в конструкциях сопоставления с образцом. 

&lt;pre&gt;
def eval(e: Expr): Int = e match {
  case Number =&gt; n
  case Sum(e1, e2) =&gt; eval(e1) + eval(e2)
}
&lt;/pre&gt;

Правила объявления:
* используется ключевое слово &lt;code&gt;match&lt;/code&gt; и
* последовательность вида &lt;code&gt;pattern =&gt; expression&lt;/code&gt; для каждого из ''случаев (case)''
* для каждого случая производится сопоставление выражения expression с образцом &lt;code&gt;pattern&lt;/code&gt;
* если ни один из образцом нельзя сопоставить с данным значением, выкидывается ошибка &lt;code&gt;MatchError&lt;/code&gt;

=== Формы образцов ===
Образцы можно составить из
* конструкторов (например, &lt;code&gt;Number&lt;/code&gt;, &lt;code&gt;Sum&lt;/code&gt;)
* переменных (&lt;code&gt;n&lt;/code&gt;, &lt;code&gt;e1&lt;/code&gt;, &lt;code&gt;e2&lt;/code&gt;)
* wildcard образцов (&lt;code&gt;_&lt;/code&gt;), которые сопоставляются с любым значением
* константы, например, &lt;code&gt;1&lt;/code&gt;, &lt;code&gt;true&lt;/code&gt; и т.п.

Например, конструктор &lt;code&gt;Sum(x, y)&lt;/code&gt; сопоставляется с объектом типа &lt;code&gt;Sum&lt;/code&gt;, а в переменные &lt;code&gt;x&lt;/code&gt; и &lt;code&gt;y&lt;/code&gt; записываются значения для левого и правого операнда.

Также, в качестве образцов можно использовать кортежи (пары и т.п.) и списки (подробнее см. ниже)
* &lt;code&gt;case (c, count)&lt;/code&gt; сопоставляется с парой, в &lt;code&gt;c&lt;/code&gt; записывается первое значение, в &lt;code&gt;count&lt;/code&gt; второе
* &lt;code&gt;x :: xs&lt;/code&gt; сопоставляется со списком, в &lt;code&gt;x&lt;/code&gt; записывается голова списка, в &lt;code&gt;xs&lt;/code&gt; - хвост


Примеры:
&lt;pre&gt;
def singleton(trees: List[CodeTree]): Boolean = trees match {
  case x :: Nil =&gt; true
  case _ =&gt; false
}
&lt;/pre&gt;

&lt;pre&gt;
def nextBranch(tree: Fork, bit: Bit): CodeTree = bit match {
  case 0 =&gt; tree.left
  case 1 =&gt; tree.right
  case _ =&gt; throw new IllegalArgumentException(&quot;unexpected value for bit: &quot; + bit)
}
&lt;/pre&gt;

&lt;pre&gt;
def decode1(currentBranch: CodeTree, bits: List[Bit]): List[Char] = (currentBranch, bits) match {
  case (Leaf(char, _), Nil) =&gt; List(char)
  case (fork: Fork, head :: tail) =&gt; decode1(nextBranch(fork, head), tail)
  case (Leaf(char, _), head :: tail) =&gt; char :: decode1(tree, bits)
  case (_: Fork, Nil) =&gt; throw new IllegalStateException(&quot;the sequence of bits ended abruptly&quot;)
  case _ =&gt; throw new IllegalStateException()
}
&lt;/pre&gt;


Также можно использовать для каждого из образцов ''граничное условие'', только при соблюдении которого будет выполняться выражение. Например, 
&lt;pre&gt;
def positiveSingleton(xs: List[Int]): Boolean = xs match {
  case x :: Nil if x &gt; 0 =&gt; true
  case _ =&gt; false
}
&lt;/pre&gt;


== Списки ==
Список, состоящий из элементов &lt;math&gt;x_1, ..., x_n&lt;/math&gt; в Scala записывается следующим образом:

&lt;pre&gt;
List(x1, ..., xn)
&lt;/pre&gt;

Основные характеристики списков:
* Списки неизменяемые
* Списки заданы рекурсивно (список состоит из элемента, называемого ''головой списка'', и списка, называемого ''хвостом списка'').
* Списки ''гомогенны'' - т.е. могут состоять только из элементов одного и того же типа

В Scala списки составляются при помощи 
* Пустого списка &lt;code&gt;Nil&lt;/code&gt;
* Оператора &lt;code&gt;::&lt;/code&gt; (он же &lt;code&gt;Cons&lt;/code&gt;) для присоединения нового элемента списка 

=== Операции со списками ===
&lt;pre&gt;
x :: xs
&lt;/pre&gt;
Присоединяет элемент &lt;math&gt;x&lt;/math&gt; к списку &lt;math&gt;xs&lt;/math&gt;

&lt;pre&gt;
fruit = &quot;apples&quot; :: (&quot;pears&quot; :: Nil)
nums = 1 :: (2 :: (3 :: Nil))
empty = Nil
&lt;/pre&gt;

Операция &lt;code&gt;::&lt;/code&gt; право-ассоциативная, поэтому скобки можно опустить
&lt;pre&gt;
fruit = &quot;apples&quot; :: &quot;pears&quot; :: Nil
nums = 1 :: 2 :: 3 :: Nil
&lt;/pre&gt;

Операция &lt;code&gt;::&lt;/code&gt; является методом, поэтому следующие две записи эквивалентны
&lt;pre&gt;
nums = 1 :: 2 :: 3 :: Nil
nums = Nil.::(3).::(2).::(1)
&lt;/pre&gt;

Cписки можно использовать в сопоставлениях с образцом
* &lt;code&gt;Nil&lt;/code&gt; или &lt;code&gt;List()&lt;/code&gt; сопоставляются с пустым списком 
* &lt;code&gt;x :: xs&lt;/code&gt; сопоставляется с головой списка &lt;code&gt;x&lt;/code&gt; и хвостом &lt;code&gt;xs&lt;/code&gt;
* &lt;code&gt;List(x1, x2, x3)&lt;/code&gt; сопоставляется со списком, состоящим из трех элементов 


Пример: сортировка вставками
&lt;pre&gt;
def sort(xs: List[Int]): List[Int] = xs match {
  case List() =&gt; List(x)
  case y :: ys =&gt; if (x &lt;= y) x :: xs else y :: insert(x, ys)
}
&lt;/pre&gt;

Помимо этого, у списков определены следующие методы
* &lt;code&gt;xs.head&lt;/code&gt; - возвращает первый элемент списка
* &lt;code&gt;xs.tail&lt;/code&gt; - возвращает все элементы, кроме первого
* &lt;code&gt;xs.isEmpty&lt;/code&gt; возвращает &lt;code&gt;true&lt;/code&gt;, если список пуст, &lt;code&gt;false&lt;/code&gt; в противном случае

Также:
* &lt;code&gt;xs.length&lt;/code&gt; - длина списка
* &lt;code&gt;xs.last&lt;/code&gt; - последний элемент
* &lt;code&gt;xs.init&lt;/code&gt; - все элементы, кроме последнего
* &lt;code&gt;xs take n&lt;/code&gt; - возвращает первые &lt;code&gt;n&lt;/code&gt; элементов списка (или сам &lt;code&gt;xs&lt;/code&gt;, если он содержит меньше, чем &lt;code&gt;n&lt;/code&gt; элементов)
* &lt;code&gt;xs drop n&lt;/code&gt; - возвращает список, полученный из данного путём отбрасывания первых &lt;code&gt;n&lt;/code&gt; элементов 
* &lt;code&gt;xs(i)&lt;/code&gt; или &lt;code&gt;xs.apply(i)&lt;/code&gt; - возвращает &lt;code&gt;i&lt;/code&gt;-тый элемент списка
* &lt;code&gt;xs ++ ys&lt;/code&gt; - соединяет два списка
* &lt;code&gt;xs.reverse&lt;/code&gt; - разворачивает список
* &lt;code&gt;xs.updated(n, x)&lt;/code&gt; - возвращает список, полученный из данного, в котором на позиции &lt;code&gt;n&lt;/code&gt; расположен элемент &lt;code&gt;x&lt;/code&gt;
* &lt;code&gt;xs.indexOf(x)&lt;/code&gt; - индекс элемента &lt;code&gt;x&lt;/code&gt; в списке
* &lt;code&gt;xs.contains(x)&lt;/code&gt; - &lt;code&gt;true&lt;/code&gt; если элемент содержится в списке

=== Функции высшего порядка для списков === 
При обработке списков следующие задачи встречаются наиболее часто
* Трансформация каждого элемента списка
* Фильтрация элементов 
* Компоновка всех значений списка в одно

==== Map ====
Применяет функцию к каждому элементу 

&lt;pre&gt;
class List[T] {

  def map[U](f: T =&gt; U): List[U] = this match {
    case Nil =&gt; this
    case x :: xs =&gt; f(x) :: xs.map(f)
  }

}

val scaled = xs.map(x =&gt; x * factor)
val squares = xs.map(x =&gt; x * x)
&lt;/pre&gt;

==== Filter ====
Фильтрует элементы, удовлетворяющие некоторому условию

&lt;pre&gt;
class List[T] {
  def filter(p: T =&gt; Boolean): List[T] = this match {
    case Nil =&gt; this
    case x :: xs =&gt; if (p(x))
                      x :: xs.filter(p)
                    else
                      xs.filter(p)
  }
}
&lt;/pre&gt;

Вариации функции &lt;code&gt;filter&lt;/code&gt;
* &lt;code&gt;xs filterNot&lt;/code&gt; - то же самое, что &lt;code&gt;xs filter (x =&gt; !p(x))&lt;/code&gt;
* &lt;code&gt;xs partition p&lt;/code&gt; - то же самое, что &lt;code&gt;(xs filter p, xs filterNot p)&lt;/code&gt;, но выполненное за один проход
* &lt;code&gt;xs takeWhile p&lt;/code&gt; - возвращает префикс списка, удовлетворяющие предикату
* &lt;code&gt;xs dropWhile p&lt;/code&gt; - остаток списка после удаления элементов, удовлетворяющие предикату
* &lt;code&gt;xs span p&lt;/code&gt; - то же самое, что &lt;code&gt;(xs takeWhile p, xs dropWhile p)&lt;/code&gt;, но выполненное за один проход

Пример:
Функция &lt;code&gt;pack&lt;/code&gt;, выполняющая следующее преобразование:

&lt;pre&gt;
&quot;a&quot;,&quot;a&quot;,&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;c&quot;,&quot;c&quot;,&quot;a&quot; =&gt; List(&quot;a&quot;,&quot;a&quot;,&quot;a&quot;), List(&quot;b&quot;), List(&quot;c&quot;,&quot;c&quot;,&quot;c&quot;), List(&quot;a&quot;)
&lt;/pre&gt;

&lt;pre&gt;
def pack[T](xs: List[T]): List[List[T]] = xs match {
  case Nil =&gt; Nil
  case x :: xs1 =&gt; {
    (l, r) = xs.span(el =&gt; x == el)
    List(l) :: pack(r)
  }
}
&lt;/pre&gt;

==== Reduce ====
Редуцирует список.

Часто используемая операция, например
* сумма: $0 + x_1 + x_2 + ... + x_n$
* произведение: $1 \cdot x_1 \cdot x_2 \cdot ... \cdot x_n$

&lt;code&gt;reduceLeft&lt;/code&gt;
&lt;pre&gt;
def sum(xs: List[Int]) = 
  (0 :: xs) reduceLeft((x, y) =&gt; x + y)

def product(xs: List[Int]) = 
  (1 :: xs) reduceLeft((x, y) =&gt; x * y)
&lt;/pre&gt;

Вместо того, чтобы писать &lt;code&gt;(x, y) =&gt; x + y&lt;/code&gt;, можно написать &lt;code&gt;(_ * _)&lt;/code&gt;
Каждый из &lt;code&gt;_&lt;/code&gt; представляет собой параметр, поэтому функции выше можно переписать следующим образом:

&lt;pre&gt;
def sum(xs: List[Int]) = 
  (0 :: xs) reduceLeft(_ + _)

def product(xs: List[Int]) = 
  (1 :: xs) reduceLeft(_ * _)
&lt;/pre&gt;


&lt;code&gt;reduceLeft&lt;/code&gt; определена с помощью более общей функции &lt;code&gt;foldLeft&lt;/code&gt;. &lt;code&gt;foldLeft&lt;/code&gt; работает примерно так же, как и &lt;code&gt;reduceLeft&lt;/code&gt;, но в качестве аргумента так же принимает аккумулятор - значение, которое будет возвращено, при применении функции к пустому списку.

Таким образом, сумма и произведение могут быть записаны как

&lt;pre&gt;
def sum(xs: List[Int]) = 
  (xs foldLeft 0) reduceLeft(_ + _)

def product(xs: List[Int]) = 
  (xs foldRight 1) reduceLeft(_ * _)
&lt;/pre&gt;


Реализовать эти две функции можно следующим образом:

&lt;pre&gt;
class List[T] {
  def reduceLeft(op: (T, T) =&gt; T): T = this match {
    case Nil =&gt; throw ...
    case x :: xs =&gt; (xs foldLeft x)(op)
  }

  def foldLeft[U](z: U)(op: (U, T) =&gt; U): U = this match {
    case Nil =&gt; z
    case x :: xs =&gt; (xs foldLeft op(z, x))(op)
  }
}
&lt;/pre&gt;


Помимо &lt;code&gt;foldLeft&lt;/code&gt; и &lt;code&gt;reduceLeft&lt;/code&gt; так же определены функции &lt;code&gt;foldRight&lt;/code&gt; и &lt;code&gt;reduceRight&lt;/code&gt;

&lt;pre&gt;
class List[T] {
  def reduceRight(op: (T, T) =&gt; T): T = this match {
    case Nil =&gt; throw ...
    case x :: Nil =&gt; x
    case x :: xs =&gt; op(x, xs.reduceRight(op))
  }

  def foldRight[U](z: U)(op: (T, U) =&gt; U): U = this match {
    case Nil =&gt; z
    case x :: xs =&gt; op(x, (xs foldRight z)(op))
  }
}
&lt;/pre&gt;

Для операций, которые ассоциативные и коммутативные, функции &lt;code&gt;foldLeft&lt;/code&gt; и &lt;code&gt;foldRight&lt;/code&gt; эквивалентны, однако одна из них может быть более эффективной. 


== Коллекции ==
=== Vector ===
Списки линейны, т.е. доступ к первому элементу списка очень быстрый, однако для того, чтобы получить элемент в середине или в конце, нужно пройти все предыдущие элементы. 

Однако в Scala существуют альтернативные реализации последовательностей (интерфейс &lt;code&gt;Seq&lt;/code&gt;), например, &lt;code&gt;Vector&lt;/code&gt;, который предоставляет более эффективные операции доступа к элементам.

&lt;pre&gt;
val nums = Vector(1, 2, 3)
val people = Vector(&quot;Bob&quot;, &quot;James&quot;, &quot;Peter&quot;)
&lt;/pre&gt;

Векторы поддерживают те же самые операции, что и списки, за исключением операции &lt;code&gt;::&lt;/code&gt;. Вместо неё определены следующие операции:

* &lt;code&gt;x +: xs&lt;/code&gt; - создаёт новый вектор с элементом x в начале 
* &lt;code&gt;xs :+ s&lt;/code&gt; - создаёт новый вектор с элементом x в конце

=== Range ===
Объекты типа &lt;code&gt;Range&lt;/code&gt; служат представлением равномерно распределённых целых чисел

Создаются с помощью трех операций:
* &lt;code&gt;to&lt;/code&gt; (включительно)
* &lt;code&gt;until&lt;/code&gt; (исключительно)
* &lt;code&gt;by&lt;/code&gt; (шаг)

&lt;pre&gt;
val r: Range = 1 until 5 // 1, 2, 3, 4
val s: Range = 1 to 5 // 1, 2, 3, 4, 5

1 to 10 by 3 // 1, 4, 7, 10
6 to 1 by -2 // 6, 4, 2
&lt;/pre&gt;

=== Seq ===
&lt;code&gt;Seq&lt;/code&gt; - общий базовый класс для классов &lt;code&gt;Vector&lt;/code&gt;, &lt;code&gt;List&lt;/code&gt; и &lt;code&gt;Range&lt;/code&gt;:

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/collections-hier.png&quot; /&gt;

Строки (тип &lt;code&gt;String&lt;/code&gt;) и массивы (тип &lt;code&gt;Array&lt;/code&gt;) поддерживают те же самые операции, что и Seq, и неявно конвертируюся в тип &lt;code&gt;Seq&lt;/code&gt; когда нужно (но они не могут быть подклассами последовательности, т.к. они из Java)

Для объектов класса Seq так же определяются следующие операции:
* &lt;code&gt;xs exists p&lt;/code&gt; - &lt;code&gt;true&lt;/code&gt; если хотя бы один элемент удовлетворяет &lt;code&gt;p&lt;/code&gt;
* &lt;code&gt;xs forall p&lt;/code&gt; - &lt;code&gt;true&lt;/code&gt; если все элементы удовлетворяют &lt;code&gt;p&lt;/code&gt;
* &lt;code&gt;xs zip ys&lt;/code&gt; - возвращает последовательность пар, составленных из соотвествующих элементов из xs и ys
* &lt;code&gt;xs unzip ys&lt;/code&gt; - операция, обратная &lt;code&gt;zip&lt;/code&gt;
* &lt;code&gt;xs flatMap f&lt;/code&gt; - для тех случаев, когда f возвращает коллекцию, flatMap &quot;склеивает&quot; общий результат в одну коллекцию

И так же
* &lt;code&gt;xs.sum&lt;/code&gt;
* &lt;code&gt;xs.product&lt;/code&gt;
* &lt;code&gt;xs.max&lt;/code&gt;
* &lt;code&gt;xs.min&lt;/code&gt;

&lt;code&gt;Примеры&lt;/code&gt;

Все комбинации для $x \in [1..M]$ и $y \in [1..N]$

&lt;pre&gt;
(1 to M) flatMap (x =&gt; (1 to N) map (y =&gt; (x, y)))
&lt;/pre&gt;


Скалярное произведение двух векторов:
&lt;pre&gt;
def scalarProduct(xs: Vector[Double], ys: Vector[Double]): Double = 
  (xs zip ys).map(xy =&gt; xy._1 * xy._2).sum
&lt;/pre&gt;

Что, используя сопоставление с образцом (pattern matching function value), можно записать следующим образом:

&lt;pre&gt;
(xs zip ys).map { case (x, y) = x * y }.sum
&lt;/pre&gt;


Проверка числа на простоту
&lt;pre&gt;
def isPrime(n: Int): Boolean =
  (2 until n) forall (d =&gt; u % d != 0)
&lt;/pre&gt;

=== For-Expressions ===
Из списка людей мы хотим вывести имена тех, кто старше 20:

&lt;pre&gt;
persons filter (p =&gt; p.age &gt; 20) map (p =&gt; p.name)
&lt;/pre&gt;

Анологичное мы можем сделать с помощью конструкции &lt;code&gt;for&lt;/code&gt;:

&lt;pre&gt;
for (p &lt;- persons if p.age &lt; 20) yield p.name
&lt;/pre&gt;

Синтакс:
&lt;pre&gt;
for (s) yield e
&lt;/pre&gt;

Где 
* &lt;code&gt;s&lt;/code&gt; - последовательность генераторов и фильтров
* &lt;code&gt;e&lt;/code&gt; - выражение, которое будет возвращено для каждого объекта

* генератор имеет вид &lt;code&gt;p &lt;- e&lt;/code&gt;
** &lt;code&gt;p&lt;/code&gt; - образец
** &lt;code&gt;e&lt;/code&gt; - выражение
* фильтр имеет вид &lt;code&gt;if f&lt;/code&gt;
** &lt;code&gt;f&lt;/code&gt; - выражение, возвращающее &lt;code&gt;Boolean&lt;/code&gt;

Последовательность должна начинаться с генератора. Если генераторов несколько, последний генератор изменяется быстрее, чем первый.

Вместо круглых скобок можно использовать &lt;code&gt;{}&lt;/code&gt;, и тогда генераторы можно записывать в несколько строк

&lt;pre&gt;
for {
  i &lt;- 1 until n
  j &lt;- i until i
  if isPrime(i + j)
} yield (i, j)
&lt;/pre&gt;

Таким образом, скалярное произведение можно записать так:
&lt;pre&gt;
(for ((x, y) &lt;- xs zip ys) yield y * x).sum
&lt;/pre&gt;

=== Set ===
Тип данных, представляющий множество - коллекцию, в которой элементы не повторяются.

&lt;pre&gt;
val fruit = Set(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;)
val s = (1 to 6).toSet
&lt;/pre&gt;

Большинство операций для последовательностей так же доступны и для множеств:

&lt;pre&gt;
s map (_ + 2)
fruit filter (_.startsWith(&quot;app&quot;))
&lt;/pre&gt;

=== Пример: 8 Queens ===
Проблема [http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-15.html#%_thm_2.42]: как расставить $N$ ферзей так, чтобы ни один не мог сбить другого. Т.е. требуется расставить ферзей так, чтобы ни один из них не был на одной горизонтали, вертикали или диагонали. 

Алгоритм:
* допустим, мы уже имеем решение для первых $k-1$ ферзей на доске размера $n$
* каждое решение - это список длины $k-1$, содержащий номера вертикалей, на которых стоят ферзи (от 0 до $n-1$)
* для того, чтобы поставить ферзя на $k$-ю вертикаль, мы генерируем все возможные позиции и отфильтровываем те, в которых условия нарушаются

&lt;pre&gt;
def queens(n: Int) = {
  def placeQueens(k: Int): Set[List[Int]] = {
    if (k == 0)
      Set(List())
    else
      for {
        queens &lt;- placeQueens(k - 1)
        col &lt;- 0 until n
        if isSafe(col, queens)
      } yield col :: queens
  }
  placeQueens(n)
}

def isSafe(col: Int, queens: List[Int]): Boolean = ...
&lt;/pre&gt;

=== Map (Структура данных) ===
Map[Key, Value] - ассоциативный контейнер для пар ключ-значение. 

&lt;pre&gt;
val roman = Map(&quot;I&quot; -&gt; 1, &quot;V&quot; -&gt; 5, &quot;X&quot; -&gt; 10)
val capitals = Map(&quot;US&quot; -&gt; &quot;Washington&quot;, &quot;Switzerland&quot; -&gt; &quot;Bern&quot;)
&lt;/pre&gt;

Класс Map[Key, Value] расширяет класс Iterable[(Key, Value)], так что с объектами этого типа можно делать всё, что угодно:

&lt;pre&gt;
val countries = capitals map { case (x, y) =&gt; (y, x) }
&lt;/pre&gt;

Для извлечения нужно просто применить мапу к ключу:

&lt;pre&gt;
capital(&quot;Andorra&quot;)
&lt;/pre&gt;

Однако если ключа не существует, будет выброшено &lt;code&gt;java.utils.NoSuchElement&lt;/code&gt;

Однако можно использовать метод get, который всегда возвращает значения типа Option

==== Option ====
Объекты типа &lt;code&gt;Option&lt;/code&gt; бывают двух типов: в одном содержится какое-то значение, а другое всегда пустое. 

&lt;pre&gt;
trait Option[+A]
case class Some[+A](value: A) extends Option[A]
object None extends Option[Nothing]
&lt;/pre&gt;

Метод &lt;code&gt;get&lt;/code&gt; возвращает
* &lt;code&gt;None&lt;/code&gt;, если мапа не содержит ключ
* &lt;code&gt;Some(x)&lt;/code&gt;, если содержит

&lt;pre&gt;
def showCapital(country: String) = capital.get(country) match {
  case Some(capital) =&gt; capital
  case None =&gt; &quot;missing data&quot;
}
&lt;/pre&gt;

==== Group By ====
Коллекцию превратить в &lt;code&gt;Map&lt;/code&gt; коллекций можно с помощью операции &lt;code&gt;groupBy&lt;/code&gt;:
&lt;pre&gt;
fruit groupBy(_.head)
&lt;/pre&gt;

Вернет
&lt;pre&gt;
Map(
  p -&gt; List(pear, pineapple),
  a -&gt; List(apple),
  o -&gt; List(orange)
)
&lt;/pre&gt;

Так же можно создать мапу со значением по умолчанию, которое будет использоваться в случаях, когда ключ не найден
&lt;pre&gt;
val cap1 = capitals withDefaultValue &quot;unknown&quot;
cap1(&quot;Andorra&quot;) // &quot;unknown&quot;
&lt;/pre&gt;

==== Параметры переменной длины ====
Допустим, у нас есть класс &lt;code&gt;Polynom&lt;/code&gt;:

&lt;pre&gt;
Polynom(Map(1 -&gt; 2.0, 3 -&gt; 4.0, 5 -&gt; 6.2))
&lt;/pre&gt;

Можно ли избежать передачи &lt;code&gt;Map&lt;/code&gt;? Мы можем использовать параметр с повторением (&quot;repeated parameter&quot;)

&lt;pre&gt;
def Polynom(bindings: (Int, Double)*) = 
  new Polynom(bindings.toMap withDefaultValue 0)
&lt;/pre&gt;

Теперь можно это использовать без &lt;code&gt;Map&lt;/code&gt;:

&lt;pre&gt;
Polynom(1 -&gt; 2.0, 3 -&gt; 4.0, 5 -&gt; 6.2)
&lt;/pre&gt;


== Ленивые вычисления ==
=== Stream ===
[http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-24.html#%_sec_3.5]. Дана задача: вычислить второе простое число в последовательности между 1000 и 10000.

&lt;pre&gt;
((1000 to 10000) filter isPrime)(1)
&lt;/pre&gt;

Но этот код находит _все_ простые числа в заданном промежутке, но использует только 2.

Мы могли бы снизить верхнюю границу промежутка, но при этом рискуя тем, что второго простого числа в интервале просто может не оказаться. 

Однако мы можем избежать вычисления хвоста последовательности до тех пор, пока он явно не понадобится. 

Структура данных Stream построена на этом принципе, и внутри очень похожа на список. Единственное отличие: хвост стрима вычисляется только тогда, когда нужно. 

&lt;pre&gt;
Stream.cons(1, Stream.cons(2, Stream.empty))
Stream(1, 2, 3)
&lt;/pre&gt;

Коллекции имеют специальный метод для получения Stream:

&lt;pre&gt;
(1 to 1000).toStream // &gt; Stream[Int] = Stream(1, ?)
&lt;/pre&gt;

Все операции для списков можно применять и для этой структуры данных. 

Например,

&lt;pre&gt;
((1000 to 10000).toStream filter isPrime)(1)
&lt;/pre&gt;

Однако &lt;code&gt;::&lt;/code&gt; всегда создает список, а не Stream, поэтому для них используется &lt;code&gt;#::&lt;/code&gt;:

&lt;pre&gt;
x #:: xs == Stream.cons(x, xs)
&lt;/pre&gt;

Реализация стрима очень похожа на реализацию списка. Однако есть одно существенное отличие:

&lt;pre&gt;
def cons[T](hd: T, tl: =&gt; Stream) = new Stream {
  def isEmpty = false
  def head = hd
  def tail = tl
}
&lt;/pre&gt;

Для параметра &lt;code&gt;tl&lt;/code&gt; используется передача по имени, а не по значению. Именно поэтому хвост вычисляется только тогда, когда необходимо. 

=== Lazy Evaluation ===
Однако предложенная выше реализация имеет недостаток, из-за которого существенно страдает производительность: eсли элемент списка затребован несколько раз, каждый раз будет вычисляться весь список. 

Этого можно избежать, если при первом вызове сохранять вычисленное значение и при втором запросе возвращать уже заранее посчитанные данные.

Этот приём называется ''ленивая инициализация'', и в Scala осуществляется с помощью ключевого слова &lt;code&gt;lazy&lt;/code&gt;:

&lt;pre&gt;
lazy val x = expression
&lt;/pre&gt;

Таким образом, Stream можно переписать так:

&lt;pre&gt;
def cons[T](hd: T, tl: =&gt; Stream) = new Stream {
  def isEmpty = false
  def head = hd
  lazy val tail = tl
}
&lt;/pre&gt;

=== Бесконечные последовательности ===
С помощью стримов можно создавать последовательности неограниченного размера [http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-24.html#%_sec_3.5.2]:

&lt;pre&gt;
def from(n: Int): Stream[Int] = n #:: from(n + 1)
val natural = from(0)
natural map (_ * 4)
&lt;/pre&gt;

При этом, если &lt;code&gt;for-expression&lt;/code&gt; применить к бесконечному списку, результат так же будет ленивым

&lt;pre&gt;
val legals = b.legalNeighbors.toStream
for ((nextBlock, move) &lt;- legals) yield (nextBlock, move :: history)
&lt;/pre&gt;

=== Пример: Решето Эратосфена ===
Для вычисления простых чисел:
* Начинаем с $i = 2$
* Убираем из результата все делители $i$
* Переходим к следующему элементу результата и повторяем

&lt;pre&gt;
def sieve(s: Stream[Int]): Stream[Int] =
  s.head #:: sieve(s.tail filter (_ % s.head != 0))

val primes = sieve(from(2))

(primes take N).toList
&lt;/pre&gt;


== Остальное ==
=== Кортежи и пары ===
Рассмотрим сортировку слиянием

Алгоритм:
* Разделить список пополам
* Отсортировать полученные подсписки
* Слить их в один отсортированный список

&lt;pre&gt;
def msort(xs: List[Int]): List[Int] = {
  val n = xs.length / 2
  if (n == 0) {
    xs
  } else {
    val (fst, snd) = xs splitAt n
    merge(msort(fst), msort(snd))
  }
}

def merge(xs: List[Int], ys: List[Int]) = xs match {
  case Nil =&gt; ys 
  case x :: xs1 =&gt;
    ys match {
      case Nil =&gt; xs
      case y :: ys1 =&gt;
        if (x &lt; y) x :: merge(xs1, ys)
        else y :: merge(xs, ys1)
    }
}
&lt;/pre&gt;

В этом примере функция &lt;code&gt;splitAt&lt;/code&gt; возвращает два подсписка, в виде ''пары''.

В Scala пара записывается в виде &lt;code&gt;(x1, x2)&lt;/code&gt;

&lt;pre&gt;
val pair = (&quot;answer&quot;, 12) // тип: (String, Int)
&lt;/pre&gt;

Пары могут быть использованы в сопоставлениях с образцом:

&lt;pre&gt;
val (label, value) = pair 
laber == &quot;answer&quot;
value == 12
&lt;/pre&gt;

Пара является кортежем из двух элементов, и для кортежей болей размерности все вышеперечисленное работает. 

Так как пары можно использовать в сопоставлениях с образцом, то функцию &lt;code&gt;merge&lt;/code&gt; можно переписать следующим образом:

&lt;pre&gt;
def merge(xs: List[Int], ys: List[Int]): List[Int] = (xs, ys) match {
  case (Nil, _) =&gt; ys
  case (_, Nil) =&gt; xs
  case (x :: xs1, y :: ys1) =&gt;
    if (x &lt; y) 
      x :: merge(xs1, ys)
    else 
      y :: merge(xs, ys1)
}
&lt;/pre&gt;

=== Неявные параметры ===
Функция &lt;code&gt;msort&lt;/code&gt; сортирует только числа. Как сделать её более общей? 

Например, можно передавать функцию для сравнения двух объектов 

&lt;pre&gt;
def msort[T](xs: List[T], ys: List[T])(lt: (T, T) =&gt; Boolean): List[T] = {
  ...

  def merge[T](xs: List[T], ys: List[T]): List[T] = (xs, ys) match {
    ...
    case (x :: xs1, y :: ys1) =&gt;
      if (ls(x, y)) 
        ...
  }

  merge(msort(fst)(lt), msort(snd)(lt))
}

msort(xs)((x, y) =&gt; x &lt; y)
msort(xs)((x, y) =&gt; x.compareTo(y) &lt; 0)
&lt;/pre&gt;

В Scala уже есть функции для сравнения, которые можно использовать:

&lt;pre&gt;
import math.Ordering
msort(nums)(Ordering.Int)
msort(fruits)(Ordering.String)
&lt;/pre&gt;

Однако в этой реализации есть проблема: необходимо постоянно передавать параметр ls. Однако можно этого избежать при помощи неявных параметров (implicit parameters)

&lt;pre&gt;
def msort[T](xs: List)(implicit ord: Ordering) = {
  ...

  def merge(xs: List[T], ys: List[T]) = {
    ...
    if (ls(x, y)) 
    ...
  }

  merge(msort(fst), msort(snd))
}
&lt;/pre&gt;

Теперь можно целиком избежать передачи последнего параметра, компилятор найдёт правильное значение нужного типа для неявно заданного параметра 

&lt;pre&gt;
import math.Ordering
msort(nums)
msort(fruits)
&lt;/pre&gt;

Для того, чтобы значения могли использоваться компилятором неявно, они должны удовлетворять следующим правилам
* должны быть помечены с помощью ключевого слова &lt;code&gt;implicit&lt;/code&gt;
* иметь соответствующий тип
* и быть видимыми

Во всех остальных случаях будет выброшено исключение

[[Category:Russian]]
[[Category:Functional Programming]]
[[Category:Coursera]]
[[Category:Scala]]</text>
      <sha1>6brfpsfrb3o3x4sqe5p0qgm207bapfr</sha1>
    </revision>
  </page>
  <page>
    <title>Downloading coursera previews</title>
    <ns>0</ns>
    <id>51</id>
    <revision>
      <id>52</id>
      <timestamp>2013-08-02T08:06:03Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1255">Скрипт выдёргивает все ссылки на видео из превью для курсеры и складывает их в файл

&lt;pre&gt;
import urllib
import re

outputhtml = open('course-download.html' ,'w')

mainpage = urllib.urlopen(&quot;https://class.coursera.org/algo2-2012-001/lecture/preview&quot;);
mainpage_contents = mainpage.read()

allvideos = re.findall('(&quot;.*?lecture_id.*?&quot;)', mainpage_contents)

for vid_each in allvideos:
    vid = vid_each[1:-1]
    vidcontent = urllib.urlopen(vid).read()

    vidtitle = re.findall('&lt;div id=&quot;lecture_title&quot; class=&quot;hidden&quot;&gt;(.*?)&lt;/div&gt;', vidcontent)
    if (len(vidtitle) &gt; 0):
        vidtitle = vidtitle[0]
    else:
        continue

    vidurl = re.findall('&quot;([^&quot;]*?\.mp4)&quot;', vidcontent)
    if (len(vidurl) &gt; 0):
        vidurl = vidurl[0]
    else:
        continue

    vidsub = re.findall('src=&quot;(.*?subtitles.*?_en)&quot;', vidcontent)
    if (len(vidsub) &gt; 0):
        vidsub = vidsub[0]
    else:
        vidsub = ''

    outputhtml.write(vidurl + ' ' + vidsub + '\n')
    print vidtitle

outputhtml.close()
&lt;/pre&gt;

Оригинал: [http://crossplatform.net/download-coursera-videos-with-your-favorite-download-manager/]

[[Category:Coursera]]
[[Category:Scripts]]
[[Category:Python]]</text>
      <sha1>ckddyjk22kh2ewleimr79997od1j35a</sha1>
    </revision>
  </page>
  <page>
    <title>Template:Code</title>
    <ns>10</ns>
    <id>52</id>
    <revision>
      <id>53</id>
      <timestamp>2013-06-05T11:29:41Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="222">{{#&lt;noinclude&gt;&lt;/noinclude&gt;tag:pre|{{{2}}}|class=brush: {{{1}}} }}
&lt;noinclude&gt;
== Использование ==
Оформляет код

{{code|scala|new Function1[Int, Int] {
  def apply(x: Int) = x * x
}
}}
&lt;/noinclude&gt;</text>
      <sha1>idf142m6yo29rwpmxhcnp8xbtfteb6v</sha1>
    </revision>
  </page>
  <page>
    <title>My bat file</title>
    <ns>0</ns>
    <id>53</id>
    <revision>
      <id>54</id>
      <timestamp>2014-02-05T13:15:24Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="866">
== Командная строка с PATH ==

command_line.bat:
&lt;pre&gt;
echo off
cls

cmd /K C:\Dev\bin\bootstrap.bat
&lt;/pre&gt;

bootstrap.bat:
&lt;pre&gt;
@echo off

set NODE_JS_PATH=C:\Program Files (x86)\nodejs
set PYTHON_PATH=C:\Users\Alexey Grigorev\Documents\Portable Python 2.7.3.1\App
set DOT=C:\Users\Alexey Grigorev\Documents\soft\graphviz-2.34\release\bin;C:\Program Files\gs9.06\bin
set UNIX=C:\cygwin\bin
set JAVA_HOME=C:\Program Files\Java\jdk1.7.0_25
set GRAILS_HOME=C:\Users\Alexey Grigorev\Documents\soft\grails-2.3.5
set GRAILS=%GRAILS_HOME%\bin
set PATH=%PATH%;%UNIX%;%NODE_JS_PATH%;%PYTHON_PATH%;%DOT%;%GRAILS%

cmd
cls
&lt;/pre&gt;

== Передаём параметры ==
&lt;pre&gt;
python C:\UBS\dev\portablepython\App\Scripts\uncompyle2 %*
&lt;/pre&gt;

%* передаёт все переданные параметры 


[[Category:Scripts]]
[[Category:Snippets]]</text>
      <sha1>it5wkslodp2c0b70rkq459t1t6ri9cy</sha1>
    </revision>
  </page>
  <page>
    <title>Excel Macro</title>
    <ns>0</ns>
    <id>54</id>
    <revision>
      <id>55</id>
      <timestamp>2014-02-05T13:13:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="888">
== Удаляет все пустые строки на всех листах ==

&lt;pre&gt;
Sub DeleteBlanks()

    Application.ScreenUpdating = False

    For Each s In Sheets
        TotalRows = s.UsedRange.Rows.Count
        For i = TotalRows To 1 Step -1
           If (s.Cells(i, 1) = &quot;&quot;) Then
                s.Rows(i).Delete
           End If
        Next i
    Next

    Application.ScreenUpdating = True

End Sub
&lt;/pre&gt;

== Удалить все строки, содержащие выражение ==

&lt;pre&gt;
Sub RemoveRowsWithSymbol()
    Application.ScreenUpdating = False

    Set r = ActiveSheet.UsedRange
    Set c = r.Find(&quot;}&quot;, LookIn:=xlValues)

    Do While Not c Is Nothing
        r.Rows(c.Row).Delete
        Set c = r.Find(&quot;}&quot;, LookIn:=xlValues)
    Loop

    Application.ScreenUpdating = True
End Sub
&lt;/pre&gt;

[[Category:Scripts]]
[[Category:VBA]]
[[Category:Snippets]]</text>
      <sha1>6vu5ksp234idkkr2x2jkh342wlj34ad</sha1>
    </revision>
  </page>
  <page>
    <title>Groovy Java in Maven</title>
    <ns>0</ns>
    <id>55</id>
    <revision>
      <id>56</id>
      <timestamp>2013-08-16T11:02:05Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6370">Смешанный проект с groovy и java используя maven и Groovy-Eclipse compiler

== Groovy-eclipse Compiler ==

&lt;pre&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
  xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;

  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

  &lt;groupId&gt;com.alexeygrigorev.groovyjavamix&lt;/groupId&gt;
  &lt;artifactId&gt;groovy-java-mix-project&lt;/artifactId&gt;
  &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;
  &lt;name&gt;Groovy and Java mixed project&lt;/name&gt;
  &lt;description&gt;Groovy and Java mixed project&lt;/description&gt;

  &lt;properties&gt;
    &lt;javaVersion&gt;1.6&lt;/javaVersion&gt;
  &lt;/properties&gt;

  &lt;dependencies&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.codehaus.groovy&lt;/groupId&gt;
      &lt;artifactId&gt;groovy-all&lt;/artifactId&gt;
      &lt;version&gt;2.0.4&lt;/version&gt;
    &lt;/dependency&gt;
  
 
    &lt;!-- Test --&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.hamcrest&lt;/groupId&gt;
      &lt;artifactId&gt;hamcrest-all&lt;/artifactId&gt;
      &lt;version&gt;1.3&lt;/version&gt;
      &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;junit&lt;/groupId&gt;
      &lt;artifactId&gt;junit-dep&lt;/artifactId&gt;
      &lt;version&gt;4.8.1&lt;/version&gt;
      &lt;scope&gt;test&lt;/scope&gt;
      &lt;exclusions&gt;
        &lt;exclusion&gt;
          &lt;groupId&gt;org.hamcrest&lt;/groupId&gt;
          &lt;artifactId&gt;hamcrest-core&lt;/artifactId&gt;
        &lt;/exclusion&gt;
      &lt;/exclusions&gt;
    &lt;/dependency&gt;

  &lt;/dependencies&gt;

  &lt;build&gt;
    &lt;plugins&gt;

      &lt;!-- Configuration needed for Groovy to work from Eclipse --&gt;
      &lt;plugin&gt;
        &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;
        &lt;artifactId&gt;build-helper-maven-plugin&lt;/artifactId&gt;
        &lt;version&gt;1.8&lt;/version&gt;
        &lt;executions&gt;
          &lt;execution&gt;
            &lt;id&gt;add-source&lt;/id&gt;
            &lt;phase&gt;generate-sources&lt;/phase&gt;
            &lt;goals&gt;
              &lt;goal&gt;add-source&lt;/goal&gt;
            &lt;/goals&gt;
            &lt;configuration&gt;
              &lt;sources&gt;
                &lt;source&gt;src/main/java&lt;/source&gt;
                &lt;source&gt;src/main/groovy&lt;/source&gt;
              &lt;/sources&gt;
               &lt;resources&gt;
                &lt;resource&gt;src/main/resources&lt;/resource&gt;
               &lt;/resources&gt;
            &lt;/configuration&gt;
          &lt;/execution&gt;
          &lt;execution&gt;
            &lt;id&gt;add-test-source&lt;/id&gt;
            &lt;phase&gt;generate-test-sources&lt;/phase&gt;
            &lt;goals&gt;
              &lt;goal&gt;add-test-source&lt;/goal&gt;
            &lt;/goals&gt;
            &lt;configuration&gt;
              &lt;sources&gt;
                &lt;source&gt;src/test/java&lt;/source&gt;
                &lt;source&gt;src/test/groovy&lt;/source&gt;
              &lt;/sources&gt;
               &lt;resources&gt;
                &lt;resource&gt;src/test/resources&lt;/resource&gt;
               &lt;/resources&gt;
            &lt;/configuration&gt;
          &lt;/execution&gt;
        &lt;/executions&gt;
      &lt;/plugin&gt;

      &lt;plugin&gt;
        &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
        &lt;version&gt;3.1&lt;/version&gt;
        &lt;configuration&gt;
          &lt;source&gt;${javaVersion}&lt;/source&gt;
          &lt;target&gt;${javaVersion}&lt;/target&gt;
          &lt;compilerId&gt;groovy-eclipse-compiler&lt;/compilerId&gt;
          &lt;compilerArgument&gt;nowarn&lt;/compilerArgument&gt;
        &lt;/configuration&gt;
        &lt;dependencies&gt;
          &lt;dependency&gt;
            &lt;groupId&gt;org.codehaus.groovy&lt;/groupId&gt;
            &lt;artifactId&gt;groovy-eclipse-compiler&lt;/artifactId&gt;
            &lt;version&gt;2.5.1-1&lt;/version&gt;
          &lt;/dependency&gt;
          &lt;dependency&gt;
            &lt;groupId&gt;org.codehaus.groovy&lt;/groupId&gt;
            &lt;artifactId&gt;groovy-eclipse-batch&lt;/artifactId&gt;
            &lt;version&gt;2.1.5-03&lt;/version&gt;
          &lt;/dependency&gt;
        &lt;/dependencies&gt;
      &lt;/plugin&gt;
      &lt;plugin&gt;
        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
        &lt;artifactId&gt;maven-eclipse-plugin&lt;/artifactId&gt;
        &lt;version&gt;2.8&lt;/version&gt;
        &lt;configuration&gt;
          &lt;additionalProjectnatures&gt;
            &lt;projectnature&gt;org.eclipse.jdt.groovy.core.groovyNature&lt;/projectnature&gt;
          &lt;/additionalProjectnatures&gt;
        &lt;/configuration&gt;
      &lt;/plugin&gt;

      &lt;plugin&gt;
        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
        &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt;
        &lt;executions&gt;
          &lt;execution&gt;
            &lt;id&gt;attach-sources&lt;/id&gt;
            &lt;goals&gt;
              &lt;goal&gt;jar&lt;/goal&gt;
            &lt;/goals&gt;
          &lt;/execution&gt;
        &lt;/executions&gt;
      &lt;/plugin&gt;
    &lt;/plugins&gt;

    &lt;pluginManagement&gt;
      &lt;plugins&gt;
        &lt;!-- Ignore/Execute plugin execution --&gt;
        &lt;plugin&gt;
          &lt;groupId&gt;org.eclipse.m2e&lt;/groupId&gt;
          &lt;artifactId&gt;lifecycle-mapping&lt;/artifactId&gt;
          &lt;version&gt;1.0.0&lt;/version&gt;
          &lt;configuration&gt;
            &lt;lifecycleMappingMetadata&gt;
              &lt;pluginExecutions&gt;
                &lt;!-- copy-dependency plugin --&gt;
                &lt;pluginExecution&gt;
                  &lt;pluginExecutionFilter&gt;
                    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                    &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;
                    &lt;versionRange&gt;[1.0.0,)&lt;/versionRange&gt;
                    &lt;goals&gt;
                      &lt;goal&gt;copy-dependencies&lt;/goal&gt;
                      &lt;goal&gt;unpack&lt;/goal&gt;
                    &lt;/goals&gt;
                  &lt;/pluginExecutionFilter&gt;
                  &lt;action&gt;
                    &lt;ignore /&gt;
                  &lt;/action&gt;
                &lt;/pluginExecution&gt;
              &lt;/pluginExecutions&gt;
            &lt;/lifecycleMappingMetadata&gt;
          &lt;/configuration&gt;
        &lt;/plugin&gt;
      &lt;/plugins&gt;
    &lt;/pluginManagement&gt;
  &lt;/build&gt;
&lt;/project&gt;
&lt;/pre&gt;

Для того, чтобы тесты, написанные на Groovy, можно было запускать из Maven, в Surefire нужно добавить следующее

&lt;pre&gt;
&lt;plugin&gt;
  &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
  &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;
  &lt;version&gt;${surefire.version}&lt;/version&gt;
  &lt;configuration&gt;
    &lt;jvm&gt;${jdk16}/bin/java&lt;/jvm&gt;
    &lt;argLine&gt;-Xmx512m&lt;/argLine&gt;
    &lt;forkMode&gt;once&lt;/forkMode&gt;
    &lt;redirectTestOutputToFile&gt;true&lt;/redirectTestOutputToFile&gt;
    &lt;includes&gt;
      &lt;include&gt;**/*Test.*&lt;/include&gt;
    &lt;/includes&gt;
  &lt;/configuration&gt;
&lt;/plugin&gt;
&lt;/pre&gt;

Таким образом Surefire будет запускать не только тесты на Java, а все классы, оканчивающиеся на Test

== GMaven ==


== Sources ==
* https://github.com/nickmcdowall/JavaAndGroovy


[[Category:Groovy]] 
[[Category:Java]] 
[[Category:Maven]]</text>
      <sha1>jgssqw4d9urifibq04q4pdi6lntkx68</sha1>
    </revision>
  </page>
  <page>
    <title>ANTLR4 Maven</title>
    <ns>0</ns>
    <id>56</id>
    <revision>
      <id>57</id>
      <timestamp>2013-07-19T07:43:07Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2656">
== pom.xml == 

&lt;pre&gt;
&lt;dependencies&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;org.antlr&lt;/groupId&gt;
    &lt;artifactId&gt;antlr4&lt;/artifactId&gt;
    &lt;version&gt;4.1&lt;/version&gt;
  &lt;/dependency&gt;
&lt;/dependencies&gt;  

&lt;build&gt;
  &lt;plugins&gt;
    &lt;plugin&gt;
      &lt;groupId&gt;org.antlr&lt;/groupId&gt;
      &lt;artifactId&gt;antlr4-maven-plugin&lt;/artifactId&gt;
      &lt;version&gt;4.1&lt;/version&gt;
      &lt;configuration&gt;
        &lt;visitor&gt;true&lt;/visitor&gt;
        &lt;sourceDirectory&gt;${basedir}/src/main/resources/&lt;/sourceDirectory&gt;
      &lt;/configuration&gt;
      &lt;executions&gt;
        &lt;execution&gt;
          &lt;goals&gt;
            &lt;goal&gt;antlr4&lt;/goal&gt;
          &lt;/goals&gt;
        &lt;/execution&gt;
      &lt;/executions&gt;
    &lt;/plugin&gt;

    &lt;plugin&gt;
      &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;
      &lt;artifactId&gt;build-helper-maven-plugin&lt;/artifactId&gt;
      &lt;version&gt;1.8&lt;/version&gt;
      &lt;executions&gt;
        &lt;execution&gt;
          &lt;id&gt;add-source&lt;/id&gt;
          &lt;phase&gt;generate-sources&lt;/phase&gt;
          &lt;goals&gt;
            &lt;goal&gt;add-source&lt;/goal&gt;
          &lt;/goals&gt;
          &lt;configuration&gt;
            &lt;sources&gt;
              &lt;source&gt;target/generated-sources/antlr4&lt;/source&gt;
            &lt;/sources&gt;
          &lt;/configuration&gt;
        &lt;/execution&gt;
      &lt;/executions&gt;
    &lt;/plugin&gt;
  &lt;/plugins&gt;
&lt;/build&gt;
&lt;pluginManagement&gt;
  &lt;plugins&gt;
    &lt;plugin&gt;
      &lt;groupId&gt;org.eclipse.m2e&lt;/groupId&gt;
      &lt;artifactId&gt;lifecycle-mapping&lt;/artifactId&gt;
      &lt;version&gt;1.0.0&lt;/version&gt;
      &lt;configuration&gt;
        &lt;lifecycleMappingMetadata&gt;
          &lt;pluginExecutions&gt;
            &lt;pluginExecution&gt;
              &lt;pluginExecutionFilter&gt;
                &lt;groupId&gt;org.antlr&lt;/groupId&gt;
                &lt;artifactId&gt;antlr4-maven-plugin&lt;/artifactId&gt;
                &lt;versionRange&gt;[4.0,)&lt;/versionRange&gt;
                &lt;goals&gt;
                  &lt;goal&gt;antlr4&lt;/goal&gt;
                &lt;/goals&gt;
              &lt;/pluginExecutionFilter&gt;
              &lt;action&gt;
                &lt;ignore&gt;&lt;/ignore&gt;
              &lt;/action&gt;
            &lt;/pluginExecution&gt;
          &lt;/pluginExecutions&gt;
        &lt;/lifecycleMappingMetadata&gt;
      &lt;/configuration&gt;
    &lt;/plugin&gt;
  &lt;/plugins&gt;
&lt;/pluginManagement&gt;
&lt;/pre&gt;


== Ссылки ==
* https://gist.github.com/sharwell/4979017

* https://github.com/miho/antlr-4-playground/blob/master/experiments/expr/src/eu/mihosoft/antlr/experiments
* https://github.com/miho/antlr-4-playground/blob/master/experiments/expr/src/eu/mihosoft/antlr/experiments/Main.java

* https://github.com/antlr/grammars-v4

* http://stackoverflow.com/questions/6487593/what-does-fragment-means-in-antlr
* http://stackoverflow.com/questions/17720608/curbing-antlr4-greediness-building-antlr4-grammar-for-existing-dsl


[[Category:Java]] [[Category:Maven]] [[Category:Programming]]</text>
      <sha1>0sm1z742cp0jqxlwayxy7ak6wckiy6z</sha1>
    </revision>
  </page>
  <page>
    <title>Scala interview questions</title>
    <ns>0</ns>
    <id>57</id>
    <revision>
      <id>58</id>
      <timestamp>2013-08-01T10:01:31Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="644">== Part 1 Theoretical ==
* Scala collections
* Pattern matching
* Scala type parameters
* Case classe
* Nested functions
* Polymorphic Methods
* Currying
* Higher-Order Functions
* Traits
* Unified Types
* Local Type Inference
* Call-by-name evaluation

== Coding tasks ==
=== Not solved ===
* https://gist.github.com/oxbowlakes/1958028
* https://gist.github.com/oxbowlakes/1958039

=== With Solution ===
* http://sujitpal.blogspot.co.uk/2009/01/scala-mock-interview-coding-questions.html

== Links ==
* http://programmers.stackexchange.com/questions/58145/how-scala-developers-are-being-interviewed


[[Category:Interviews]]
[[Category:Scala]]</text>
      <sha1>dzzd79vnd7m0r37hd60yojphn357ozp</sha1>
    </revision>
  </page>
  <page>
    <title>Design interview questions</title>
    <ns>0</ns>
    <id>58</id>
    <revision>
      <id>59</id>
      <timestamp>2014-01-26T08:38:02Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1514">== Design patterns ==
* [http://habrahabr.ru/post/210288/ Шпаргалка по шаблонам проектирования]
* What major patterns do the Java APIs utilize? 
* Pattern used in Java 
* Which patterns do you use in a daily basis. Explain their principles. 
* Give an insight into such patterns as Façade/Proxy/Decorator/Strategy/Observer (selectively) 
* Can you please explain “bridge”, &quot;singleton&quot; design pattern? 
* Can you please explain &quot;FlyWeight&quot; design pattern? 

== OOP ==
* Inheritance vs Composition 
* Coupling &amp; Cohesion (class &amp; method level) 
* SOLID 
* DRY 
* Law of Demeter 
* Feature Envy 
* CQRS: Command Query Responsibility Segregation 
* Principle of Least Astonishment/Surprise 


== Domain driven design ==
* Building blocks: Entity, Value Object, Aggregate, Service, Repository, Factory
* Ubiquitous Language
* Anticorruption Layer
* Bounded context


== Craftsmanship ==
* What is software craftsmanship?
* Books: Clean Code, GOOS, Working Effectively With Legacy Code, RSpec, etc
* How do you keep yourself up-to-date?
* Pet projects? Tell me more
* Katas? How do you practice?


== Code ==
* How do you identify good and bad code?
* Multiple return statements
* Average lines per method &amp; class
* What do you think about the “else” keyword. What are the alternatives?
* What is the problem with getters?
* why the switch statement is post-soviet construction?
* what is problem with comments in the code?


[[Category:Interviews]]
[[Category:Software Design]]</text>
      <sha1>3oi4nmcv6h54yuv2585hyo4ymjqcvny</sha1>
    </revision>
  </page>
  <page>
    <title>DB interview questions</title>
    <ns>0</ns>
    <id>59</id>
    <revision>
      <id>60</id>
      <timestamp>2013-10-10T03:33:10Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1216">== DB ==
* Czy kazdy system SQL implementuje standard SQL w jednakowy sposób? 
* Podaj róznice pomiedzy tabela a perspektywa 
* Jaka jest glówna róznica miedzy systemami SQL a NoSQL? 
* Czym jest transakcja?  
* Czym jest ACID? 
* What transaction isolation levels do you know? 
* Primary key vs unique key. Differences. 
* What types of constraints does one know? 
* What is a view/materialized view. 
* What kind of joins do you know? 
* What is the difference between inner join and outer join? 
* Types of tables (regular, temporary, index-organized etc) 
* Are database Indexes useful? What is the role of them? 
* Why many indexes are not good for performance 
* Views, why they are needed? 
* Which of SELECT, UPDATE, DELETE, ADD’s performance is mostly affected by performance of indexes? 
* What does it mean database de-normalization? 
* What are ways to increase performance of database 


== SQL (Oracle applied) ==
* What are DML and DDL
* Aggregate functions with examples
* What is a nested subquery?
* Types of indices in Oracle
* What is a hierarchical query? How to create it?
* What is a bitmap index
* Partitioning and methods of partitioning

[[Category:Databases]]
[[Category:Interviews]]</text>
      <sha1>h0d2nmccj98hudqzgdpalc1p07r3x3d</sha1>
    </revision>
  </page>
  <page>
    <title>Java interview questions</title>
    <ns>0</ns>
    <id>60</id>
    <revision>
      <id>61</id>
      <timestamp>2014-04-17T18:34:13Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4635">== Java basics ==
* Meaning of keywords: static, final, transient
* Contract between equals() and hashCode()
* Rules to create equals method (stability, transitivity, reflectivity etc)
* Access modifiers in Java
* Explain strictfp, volatile, transient?
* Purpose, types and creation of nested classes
* What does it mean that an object or a class is mutable or immutable?
* How to make class immutable?
* Besides “string” do you know any other immutable classes?
* How can we replace multi-inheritance pattern in Java
* Can interface inherit from different interface
* Regular vs. static initialization blocks

Also
* Length in bytes for primitive types
* '''this''' and '''super''' keywords
* What different between StringBuffer and StringBuilder? 
* Difference between overriding and overloading


== Exceptions ==
* Checked vs. unchecked exceptions. Why would one use former or later?
* Difference in handling of Error and Exception
* Could we have only try and finally withouth catch
* Cases when the finally block isn't executed
* What is exception handling mechanism
* Java Exceptions API
* How to avoid catch block?


== Collections ==
* General collection interfaces (Collection, Set, Map, List, Queue, SortedSet, SortedMap)
* Interfaces extending Collection. Is Map part of Collection interface?
* Difference between ArrayList and LinkedList
* Difference between Stack and Queue
* TreeSet vs LinkedHashSet
* Internal structure of HashMap/Hashtable
* Requirements for implementation of hashCode to achieve best performance
* Definition and ways of resolving collisions in hash tables
* Differences between Hashtable and ConcurrentHashMap
* Special versions of collections. EnumSet, EnumMap, WeakHaskMap, IdentityHashMap.
* Implementation details of about ConcurrentHashMap. Synchronization.
* Iterator and modification of a List. ConcurentModificationException. Collections with safe iterators (CopyOnWriteArrayList/CopyOnWriteArraySet)


== Java 5+ Specifics ==
* What is a parameterized or generic type?
* Can we use parameterized types in exception handling?
* Liskov substitution principle
* What is a wildcard parameterized type?
* What is Autoboxing and what are its advantages/pitfalls?
* Problems Enum type solves (comparing to &quot;public static int&quot; enum pattern)
* Can we add something to List&lt;?&gt; ?
* What are Annotations and which predefined by the language specification does one know (@Deprecated, @Override, @SuppressWarnings)



== Multithreading ==
* Thread vs Runnable, run() vs start()
* Synchronization of java blocks and methods
* Explain usage of the couple wait()/notify()
* Difference between sleep and wait
* Atomic operations
* What does it mean Volatile keyword?
* java.util.concurrent.*, what utils do you know?
* Thread local, what for are they needed?
* Does child thread see the value of parent thread local?
* Deadlock definition plus example
* Livelock definition plus example
* Starvation definition plus example
* Race condition definition plus example
* Garbage definition plus example
* Execution order
* Atomicity of long and double assignment operations
* Lock-free operations, how to create lock-free implementation of field reassignment


How to interrupt a thread
* http://javatalks.ru/topics/36538
* http://stackoverflow.com/questions/2020992/is-thread-interrupt-evil


== Java NIO ==
* What is NIO
* What is Channel
* What is Buffer
* What is Charset
* What is Selector
* How to lock file?
* what is NIO2 ?


== Memory &amp; GC ==
* Memory model in JVM
* How does virtual space divided in Java?
* What difference between float and BigDecimal. How they store the data?
* Java object references
* What is deep copy of a Java object?
* Disadvantages of setting heap size too high
* What are utilities for JVM monitoring? What is Jconsole?
* How to force GC be executed?
* Garbage collection principles
* What are memory leaks?
* Are memory leaks a problem in Java?
* What is variable shadowing
* How would you monitor JVM
* How would you monitor how GC behaves during program execution
* Name few GC implementations (Serial, Parallel, ParallelOld, ConcarentMarkAndSweep, G1) describe major  differences



== Unit testing ==
* Libraries that help to writing unit tests
* EasyMock and Mockito usage
* Junit. What is this tool for?
* What are features of Junit? Please explain Junit Theories


== Some Links ==
* http://www.itshared.org/2015/10/java-interview-questions.html
* [http://www.evernote.com/shard/s344/sh/0a9befd7-507d-4a9b-be08-fb5e39876219/2718ba3054cec6ef43edba0b19606277 115 Java Interview Questions and Answers – The ULTIMATE List]

[[Category:Interviews]]
[[Category:Java]]</text>
      <sha1>qlh9otadaokm08jrmxsqqa5nh2xcuf7</sha1>
    </revision>
  </page>
  <page>
    <title>Scrum interview questions</title>
    <ns>0</ns>
    <id>61</id>
    <revision>
      <id>62</id>
      <timestamp>2013-07-23T13:41:55Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="581">== Scrum ==
* How meeting in scrum looks like (three questions)
* What is team velocity and burn down chart
* What is poker game and what are story points
* What are different meauseres used during poker game ? (linear, prime, powers of two, fibonacci)
* What tools do you know supporting agile (IBM RTC, JIRA with Green Hopper, Redmine)
* What is role of scrum master
* What types of meetings scrum have (daily scrum, planning, review, retrospective, scrum of scrums)
* What artifacts scrum have (product backlog, sprint backlog)
* Disadvantages of scrum


[[Category:Interviews]]</text>
      <sha1>t41974jl5kv3fqa3qyfx1o53jzlpgeu</sha1>
    </revision>
  </page>
  <page>
    <title>Spring interview questions</title>
    <ns>0</ns>
    <id>62</id>
    <revision>
      <id>63</id>
      <timestamp>2013-08-01T10:00:42Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="648">== Spring ==
* Basic idea of IoC pattern. Benefits.
* What is Spring configuration file? How does it look like?
* Out of the box bean scopes (singleton, prototype, request, session, global session)
* What are the main bean scopes in web container?
* What are the types of Dependency Injection Spring supports?
* Autowiring. Types of autowiring.
* What are inner beans.
* What modules does Spring Framework have?
* Describe Test support in Spring (AbstractTransactionalSpringTests)
* Describe AOP integration in Spring
* How to integrate Spring and Hibernate using HibernateDaoSupport? 

[[Category:Interviews]]
[[Category:Java]]
[[Category:Spring]]</text>
      <sha1>im5r2gni9nlgvogkhg00dfhzl11bt6y</sha1>
    </revision>
  </page>
  <page>
    <title>Hibernate interview questions</title>
    <ns>0</ns>
    <id>63</id>
    <revision>
      <id>64</id>
      <timestamp>2013-08-02T08:09:10Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="595">== Hibernate ==
* Benefits and risks of using Hibernate
* What is a SessionFactory? Is it a thread-safe object?  
* What is the difference between merge and update
* What is Hibernate Query Language (HQL)?
* Lazy loading
* What do you mean by Named – SQL query and how to invoke it?
* What is the difference between sorted and ordered collection in hibernate?
* Difference between get() and load()
* What are the entity states in Hibernate
* Hierarchy-to-tables mapping strategies
* ORM incompatibility
* What are the Collection types in Hibernate ?


[[Category:Interviews]]
[[Category:Java]]</text>
      <sha1>a2v09qisngx0dmxg4rpd2hdsnh4bwys</sha1>
    </revision>
  </page>
  <page>
    <title>Algo interview questions</title>
    <ns>0</ns>
    <id>64</id>
    <revision>
      <id>65</id>
      <timestamp>2013-08-02T08:03:55Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="607">== Algorithms &amp; Data structures ==
* Data structures
* Boolean operations, short circuits in Boolean operations
* Recursion, tail recursion, mutual recursion
* Sorting algorithms
* Complexity of algorithms, big O notation
* Trees, graphs and ways to traverse graph
* Binary tree
* Self balanced trees (Red-black tree, AVL, Splay)
* Search in binary tree
* Linear-time sorting. (count sort)
* Sorting of linked list.
* Tries, prefix and suffix trees
* NP-complete algorithms
* Map/reduce and divide and conquer approach in solving tasks
* Dynamic programming


[[Category:Interviews]]
[[Category:Algorithms]]</text>
      <sha1>o6en6lx538oqaw5jolz6iqq2z4b97ch</sha1>
    </revision>
  </page>
  <page>
    <title>XML interview questions</title>
    <ns>0</ns>
    <id>65</id>
    <revision>
      <id>66</id>
      <timestamp>2013-08-01T10:02:08Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="327">== XML ==
* Overall experience with XML
* Experience with XPath
* Experience with XSLT
* SAX vs. DOM
* DTD vs. XMLSchema
* Difference between HTML and XML
* What is well formed HTML
* What are siblings
* What is XML Namespace
* What characters are disallowed from XML without escaping


[[Category:Interviews]]
[[Category:XML]]</text>
      <sha1>kvhje8loqz79nipnci4f3x8hs6o1uhe</sha1>
    </revision>
  </page>
  <page>
    <title>JMS interview questions</title>
    <ns>0</ns>
    <id>66</id>
    <revision>
      <id>67</id>
      <timestamp>2013-08-02T08:03:27Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="550">== JMS ==
* What is the purpose of JMS
* What are the different messaging paradigms JMS supports?
* Difference between topic and queue
* What is the basic difference between Publish Subscribe model and P2P model?
* Durability
* How JMS is different from RPC?
* What are the different types of messages available in the JMS API?
* Frameworks and libraries


== Integration ==
* Experience with ESB
* Could you please tell us about Apache Camel. What patterns does it use?
* Ways to integrate enterprise apps


[[Category:Interviews]]
[[Category:Java]]</text>
      <sha1>7hn9l7htqwp80upoww0noisyvgtzwz7</sha1>
    </revision>
  </page>
  <page>
    <title>Interview questions</title>
    <ns>0</ns>
    <id>67</id>
    <revision>
      <id>68</id>
      <timestamp>2015-09-16T18:57:04Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="687">== Java and related ==
* [[Java interview questions]]
* [[Spring interview questions]]
* [[Hibernate interview questions]]
* [[JMS interview questions]]
* [[Scala interview questions]]


== Other ==
* [[Data Science Interview Questions]]
* [[Algo interview questions]]: Algorithms and data structures
* [[Design interview questions]]: design principles, patterns, etc
* [[DB interview questions]]: Databases and SQL
* [[XML interview questions]]


== Non-technical ==
* [[Scrum interview questions]]


== Links ==
* [https://docs.google.com/spreadsheets/d/12uMQd_fRyhPMVmRHR5-DnPIwOR_Zw9CMxSdDiZK76QY/pubhtml Interview Template]


[[Category:Interview Questions]]
[[Category:Interviews]]</text>
      <sha1>idg51qvenyb8oh9rvglpculu2pf71d5</sha1>
    </revision>
  </page>
  <page>
    <title>Java Fork/Join</title>
    <ns>0</ns>
    <id>68</id>
    <revision>
      <id>69</id>
      <timestamp>2014-06-11T16:54:06Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2854">
== Использование Fork/Join для поиска файлов ==

&lt;pre&gt;
public class ForkJoinTest {

    @Test
    public void forkJoinSearch() {
        ForkJoinPool forkJoinPool = new ForkJoinPool();
        Stream&lt;File&gt; result = forkJoinPool.invoke(new DirWalker(new File(&quot;C:/&quot;), &quot;ubs&quot;));
        result.forEach(System.out::println);
        System.out.println(&quot;Done&quot;);
    }

    static class DirWalker extends RecursiveTask&lt;Stream&lt;File&gt;&gt; {
        private File dir;
        private String name;

        public DirWalker(File dir, String name) {
            if (!dir.isDirectory()) {
                throw new IllegalArgumentException(&quot;not a dir&quot;);
            }
            this.name = name;
            this.dir = dir;
        }

        @Override
        protected Stream&lt;File&gt; compute() {
            // System.out.println(&quot;looking into &quot; + dir);
            List&lt;File&gt; all = toList(dir.listFiles());

            List&lt;ForkJoinTask&lt;Stream&lt;File&gt;&gt;&gt; tasks = new LinkedList&lt;&gt;();
            tasks.add(new FileLooker(all.stream(), name).fork());

            Stream&lt;File&gt; dirs = all.stream().filter(f -&gt; f.isDirectory());
            Stream&lt;ForkJoinTask&lt;Stream&lt;File&gt;&gt;&gt; dirTasks = dirs.map(subdir -&gt; new DirWalker(subdir, name).fork());
            dirTasks.forEach(tasks::add);

            return tasks.stream().flatMap(t -&gt; t.join());
        }

        private static &lt;E&gt; List&lt;E&gt; toList(E[] a) {
            if (a == null) {
                return Collections.emptyList();
            } else {
                return Arrays.asList(a);
            }
        }
    }

    static class FileLooker extends RecursiveTask&lt;Stream&lt;File&gt;&gt; {
        private Stream&lt;File&gt; files;
        private String name;

        public FileLooker(Stream&lt;File&gt; files, String name) {
            this.files = files;
            this.name = name;
        }

        @Override
        protected Stream&lt;File&gt; compute() {
            return files.filter((File f) -&gt; f.getName().contains(name));
        }
    }

    @Test
    public void recursively() {
        parseAllFiles(&quot;C:/&quot;, &quot;ubs&quot;);
        System.out.println(&quot;Done&quot;);
    }

    public void parseAllFiles(String parentDirectory, String searchword) {
        File[] filesInDirectory = new File(parentDirectory).listFiles();
        if (filesInDirectory == null) {
            return;
        }

        for (File f : filesInDirectory) {
            if (f.isDirectory()) {
                parseAllFiles(f.getAbsolutePath(), searchword);
            } else if (f.getName().contains(searchword)) {
                System.out.println(f);
            }
        }

    }
}
&lt;/pre&gt;

В этом коде два теста: один использует Fork/Join, второй обычный рекурсивный обход.


[[Category:Java]]
[[Category:Java 8]]
[[Category:Snippets]]

[[Category:Concurrency]]</text>
      <sha1>rrj1o7hi2m7k8hnpirwqobzwj32uha7</sha1>
    </revision>
  </page>
  <page>
    <title>Graphs</title>
    <ns>0</ns>
    <id>69</id>
    <revision>
      <id>70</id>
      <timestamp>2013-12-23T19:11:03Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1969">== Graphs ==

Consist of:
* vertices aka nodes ($V$)
* $n$ = number of vertices
* edges ($E$) = pair of vertices
* $m$ - number of edges

* can be ''undirected'' &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/29btqo4e5smcg6v9l29a0k7i8u.png&quot; \&gt;
* or ''directed'' &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/37ijdgf2d7dri4jkv2fpbrouea.png&quot; \&gt;


== Directed Acyclic Graph ==
This is a special kind of graph where
* there are no cycles
* and it is directed

These graphs can be [[Topological Ordering|sorted topologically]]


== Representation ==
=== adjacency matrix ===
* &lt;math&gt;n \times n&lt;/math&gt; matrix where 
* &lt;math&gt;A_{i,j} = 1&lt;/math&gt; if $G$ has &lt;math&gt;(i, j)&lt;/math&gt; edge
* or $+1$/$-1$ if directed
* or weight if weighted
* space required &lt;math&gt;\Theta(n^2)&lt;/math&gt;

=== adjacency list ===
* array of vertices
* array of edges for each vertex
* space required &lt;math&gt;\Theta(n + m)&lt;/math&gt;

== Implementation ==
Adjacency list:
&lt;pre&gt;
public class Graph {
    private int n;
    private final List&lt;List&lt;Integer&gt;&gt; adj;

    public Graph(int n) {
        this.n = n;
        this.adj = createAdjacentList(n);
    }

    private static List&lt;List&lt;Integer&gt;&gt; createAdjacentList(int n) {
        List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;List&lt;Integer&gt;&gt;(n);

        int i = 0;
        while (i &lt; n) {
            res.add(new LinkedList&lt;Integer&gt;());
            i++;
        }

        return res;
    }

    public void addEdge(int v, int u) {
        adj.get(v).add(u);
    }

    public Iterable&lt;Integer&gt; adjacent(int v) {
        return adj.get(v);
    }

    public int getN() {
        return n;
    }
}
&lt;/pre&gt;


== See also ==
* [[Minimal Cut Problem]]
* [[Graph Search]] ([[Breadth-First Search]] и [[Depth-First Search]])
* [[Dijkstra's Shortest Path]]
* [[Topological Ordering]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]

[[Category:Algorithms]]
[[Category:Graphs]]</text>
      <sha1>74x4gi70yj340fm9wob3p3fhfn7gys8</sha1>
    </revision>
  </page>
  <page>
    <title>Minimal Cut Problem</title>
    <ns>0</ns>
    <id>70</id>
    <revision>
      <id>71</id>
      <timestamp>2013-08-01T09:53:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6323">== Minimal Cut Problem ==
A ''cut'' in a [[Graphs|graph]] is a partition of vertices $V$ into two non-empty subsets $A$ and $B$

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/31fvn7e3gpg82523n3cguh1sua.png&quot; \&gt;

A ''crossing edges'' is an edge that
* has one end point in each of &lt;math&gt;(A, B)&lt;/math&gt;
* has tail in &lt;math&gt;A&lt;/math&gt;, head in &lt;math&gt;B&lt;/math&gt; (directed)
* if head in &lt;math&gt;B&lt;/math&gt;, tail in &lt;math&gt;A&lt;/math&gt; - not a crossing edge

== The problem ==
* input: indirect [[Graphs|graph]] &lt;math&gt;G = (V, E)&lt;/math&gt; with parallel edges allowed
* goal: compute a cut with fewer number of crossing edges (the min cut)

Eg:

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/44dvh9gbo78ljnt0tmds5rv618.png&quot; \&gt;

== Applications ==
* identify weakness/bottlenecks
* detect communities
* image segregation

== Random Contraction Algorithm ==

MinCut algo:
* while there are more than 2 vertices
* pick a remaining edge $(u, v)$ at random
* merge (contract) $u$ and $v$ into a single vertex
* remove self-loogs
* return 2 final vertices


Example:
* step 1 &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/3lf26679cst0jm7hsug5h1hef2.png&quot; \&gt;
* step 2 &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/3rdg1jgvkna7mtb0gnu00vbkdg.png&quot; \&gt;
* step 3 &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/7j8r5op0949ctu5jmq03c1uf0m.png&quot; \&gt;
* result &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/5eoumts8f24v0ifjebqgjsumjr.png&quot; \&gt;

Example 2:
* &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/15f4s9iuk97l9qvnt171bqc904.png&quot; \&gt;

It can find something other than a minimal cut!
* the probability of success is just &lt;math&gt;\cfrac{1}{n^2}&lt;/math&gt;!
* solution: repeated trials
* try &lt;math&gt;N&lt;/math&gt; times and remember the smallest cut found


How many trials we need?
* probability that all trials fail is &lt;math&gt;(1 - \cfrac{1}{n^2}) ^ N&lt;/math&gt;
* if &lt;math&gt;N = n^2 \log n&lt;/math&gt;, &lt;math&gt;Pr[\text{all fail}] = \frac{1}{n}&lt;/math&gt;
* running time: $\Omega(n^2 m)$
* TODO: link to proof


=== Implementation ===
&lt;pre&gt;
public class MinCutProblem {
    private UndirectedGraph graph;
    private UndirectedGraph initialGraphCopy;
    private int best;

    public void run() {
        graph = readGraph();
        initialGraphCopy = graph.copy();
        best = Integer.MAX_VALUE;

        int trials = 25;

        while (trials &gt; 0) {
            iteration();
            graph = initialGraphCopy.copy();
            trials--;
        }

        out.println(best);
    }

    private void iteration() {
        while (graph.getN() &gt; 2) {
            Pair&lt;Integer, Integer&gt; randomVertex = graph.randomEdge();
            graph.contract(randomVertex.getLeft(), randomVertex.getRight());
        }

        Map&lt;Integer, List&lt;Integer&gt;&gt; adjacencyList = graph.adjacencyList();

        Iterator&lt;Entry&lt;Integer, List&lt;Integer&gt;&gt;&gt; iterator = adjacencyList.entrySet().iterator();
        List&lt;Integer&gt; first = iterator.next().getValue();
        List&lt;Integer&gt; second = iterator.next().getValue();

        if (best &gt; first.size()) {
            best = first.size();
        }
    }
}
&lt;/pre&gt;

&lt;pre&gt;
public class UndirectedGraph {
    private int n;
    private final Map&lt;Integer, List&lt;Integer&gt;&gt; adj;
    private final Random random = new Random();

    public UndirectedGraph(int n) {
        this.n = n;
        this.adj = createAdjacentList(n);
    }

    private static Map&lt;Integer, List&lt;Integer&gt;&gt; createAdjacentList(int n) {
        Map&lt;Integer, List&lt;Integer&gt;&gt; res = new LinkedHashMap&lt;Integer, List&lt;Integer&gt;&gt;();

        int i = 0;
        while (i &lt; n) {
            res.put(i, new ArrayList&lt;Integer&gt;());
            i++;
        }

        return res;
    }

    private UndirectedGraph(UndirectedGraph copy) {
        this.n = copy.n;
        this.adj = new LinkedHashMap&lt;Integer, List&lt;Integer&gt;&gt;();
        
        for (Entry&lt;Integer, List&lt;Integer&gt;&gt; entry : copy.adj.entrySet()) {
            adj.put(entry.getKey(), new ArrayList&lt;Integer&gt;(entry.getValue()));
        }
    }
    
    public UndirectedGraph copy() {
        return new UndirectedGraph(this);
    }

    public void contract(int v, int u) {
        List&lt;Integer&gt; newList = new ArrayList&lt;Integer&gt;();

        for (int fromFirst : adj.get(v)) {
            if (fromFirst != u) {
                newList.add(fromFirst);
            }
        }

        for (int fromSecond : adj.get(u)) {
            if (fromSecond != v) {
                newList.add(fromSecond);
            }
        }

        adj.remove(v);
        adj.remove(u);
        n--;

        // updating the graph so 'u' now will point to 'v'
        for (Entry&lt;Integer, List&lt;Integer&gt;&gt; entry : adj.entrySet()) {
            List&lt;Integer&gt; row = entry.getValue();
            for (int i = 0; i &lt; row.size(); i++) {
                if (row.get(i).intValue() == u) {
                    row.set(i, v);
                }
            }
        }

        // and keeping only 'v'
        adj.put(v, newList);
    }

    public void addEdge(int v, int u) {
        adj.get(v).add(u);
    }

    public Iterable&lt;Integer&gt; adjacentTo(int v) {
        if (!adj.containsKey(v)) {
            throw new IllegalArgumentException(v + &quot; is already removed&quot;);
        }
        return adj.get(v);
    }

    // TODO may be implemented more efficiently
    public Pair&lt;Integer, Integer&gt; randomEdge() {
        int[] available = new int[n];

        int j = 0;
        for (Entry&lt;Integer, List&lt;Integer&gt;&gt; entry : adj.entrySet()) {
            if (!entry.getValue().isEmpty()) {
                available[j] = entry.getKey();
                j++;
            }
        }

        int vertexU = available[random.nextInt(j)];
        List&lt;Integer&gt; edges = adj.get(vertexU);
        int vertexV = edges.get(random.nextInt(edges.size()));
        return Pair.of(vertexU, vertexV);
    }

    public Map&lt;Integer, List&lt;Integer&gt;&gt; adjacencyList() {
        return ImmutableMap.copyOf(adj);
    }
    
    public int getN() {
        return n;
    }
}
&lt;/pre&gt;

== See also ==
* [[Graphs]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]

[[Category:Algorithms]]
[[Category:Graphs]]</text>
      <sha1>7w7ugfen7eo0u2ol7kkn6lxndwl6a8h</sha1>
    </revision>
  </page>
  <page>
    <title>Graph Search</title>
    <ns>0</ns>
    <id>71</id>
    <revision>
      <id>72</id>
      <timestamp>2013-08-01T09:54:02Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="818">== Graph Search ==
Motivation: Given a [[Graphs|graph]]
* check if network is connected (get from &lt;math&gt;A&lt;/math&gt; to &lt;math&gt;B&lt;/math&gt;)
* find best driving directions (shortest path)
* etc etc

Search:
* find everything findable from a given vertex $s$
* don't explore anything twice
* goal: $O(n+m)$

== Algorithm ==
GenericAlgorithm(graph $G$, starting vertex $s$):
* initially only $s$ is explored
* while possible
** choose an edge $(u, v)$ with $u$ explored and $v$ unexplored
** mark $v$ explored
* if at the end $v$ is explored, there is a path from $s$ to $v$

== Concrete algorithms ==
* [[Breadth-First Search]] 
* [[Depth-First Search]]
* [[Dijkstra's Shortest Path]]

== See also ==
* [[Graphs]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]

[[Category:Algorithms]]
[[Category:Graphs]]</text>
      <sha1>lwva8dme7p0p2c1gkvmzu3v7its2gzr</sha1>
    </revision>
  </page>
  <page>
    <title>Breadth-First Search</title>
    <ns>0</ns>
    <id>72</id>
    <revision>
      <id>73</id>
      <timestamp>2013-08-01T09:54:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1307">== Breadth-First Search ==
A [[Graph Search]] algorithm:
* explores [[Graphs]] in &quot;layers&quot;
* uses FIFO (i.e. a queue)

== Basic Algorithm ==
BFS(graph $G$, start vertex $s$):
* [all nodes are initially unexplored]
* mark $s$ as explored
* $Q$ = queue, initialized with $s$
* while $Q$ is not empty
** remove $v$ from $Q$
** for each edge $(v, w)$
*** if $w$ unexplored
*** mark $w$ as explored
*** add $w$ to $Q$

running time $O(m + n)$

== Applications ==
=== Shortest Path ===
Goal: compute $\text{dist}(v)$ - the fewest number of edges on the path from $s$ to $v$ (in unweighted graph)

Extra code:
* in initialization:
** $\text{dist}(v)$:
*** $0$ if $v = s$
*** $\infty$ if $v \ne s$
* when considering edge(v, w):
** if $w$ unexplored
** set $\text{dist}(w) = \text{dist}(v) + 1$


=== Connected Components ===
Goal: compute all connected components of an undirected graph.

why?
* is network connected?
* graph visualization
* clustering (quick and dirty)

ConnectedComponents(graph $G$):
* for $i$ = 1 to $n$
* if $i$ not exploted
** BFS($G$, $i$)

Running time also $O(n + m)$

== See also ==
* [[Graphs]]
* [[Graph Search]] и [[Depth-First Search]]
* [[Dijkstra's Shortest Path]]


== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]

[[Category:Algorithms]]
[[Category:Graphs]]</text>
      <sha1>rt7jadqluqwnvp3nw3ved9yka23a4b9</sha1>
    </revision>
  </page>
  <page>
    <title>Depth-First Search</title>
    <ns>0</ns>
    <id>73</id>
    <revision>
      <id>74</id>
      <timestamp>2013-08-01T09:54:20Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="718">== Depth-First Search ==
A [[Graph Search]] algorithm:
* explore aggressively, backtrack only if needed
* uses FILO / recursion

== Algorithm ==
DFS(graph $G$, start vertex $s$):
* mark $s$ as explored
* for every edge $(s, v)$
** if $v$ is unexplored
** DFS($G$, $v$)

running time &lt;math&gt;O(n + m)&lt;/math&gt;

== DFS applications ==
* [[Breadth-First Search#Connected Components|Connected components]] like with [[Breadth-First Search]]
* [[Topological Ordering]]
* [[Strongly Connected Components]]

== See also ==
* [[Graphs]]
* [[Graph Search]] и [[Breadth-First Search]]
* [[Dijkstra's Shortest Path]]


== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]

[[Category:Algorithms]]
[[Category:Graphs]]</text>
      <sha1>q83ibngya8b5dhz8i5g3p56qwc4p33j</sha1>
    </revision>
  </page>
  <page>
    <title>Topological Ordering</title>
    <ns>0</ns>
    <id>74</id>
    <revision>
      <id>75</id>
      <timestamp>2013-12-19T14:40:35Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3317">== Topological Ordering ==
A ''topological ordering'' for a directed graph $G$ is a labelling $f$ of $G$'s nodes such that
* the $f(v)$'s are the set $\{1, 2, ..., n\}$
* $(u, v) \in G$ =&gt; $f(u) &lt; f(v)$
* all edges go forward

Example:
* graph &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/30n9ocu0akrqskcbbemhfamnld.png&quot; \&gt;
* possible orderings &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/1g0c9hkcn6db8rsd4somiag97q.png&quot; \&gt;

Motivation:
* sequence tasks while respecting all constains
** courses at uni with prerequisites

== Straightforward solution ==
* every directed graph has a ''sink'' vertex  &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/4ptua7u63ola9kq942q7f108s8.png&quot; \&gt;
* compute backwards, finding a sink on each iteration

Idea:
* let $v$ be sink of $G$
* set $f(v) = n$
* recurse on $G - \{v\}$

But it can be computed using [[Depth-First Search]] very quickly

== DFS solution ==
* dfs finds a sink
* and unfolds backwards numerating the vertices

Consists of 2 routines: DFS-loop and DFS

DFS-loop(graph $G$):
* mark all vertices not explored
* current label = $n$
* for each vertex $v$
** if $v$ not explored
** DFS($G$, $v$)


DFS(graph $G$, vertex $s$):
* for every edge $(s, v)$
** if $v$ not explored
** mark $v$ explored
** DFS($G$, $v$)
* set $f(s)$ = current label
* current label = current label - 1

== Cycles ==
if $G$ has a [directed] cycle, it has no topological ordering. It is possible to modify the algorithm so it will inform about cycles.

Idea: instead of marking the vertices as explored, mark them with two colors:
* one color means &quot;the vertex is being processed&quot;
* another color means &quot;the vertex has been processed&quot;

Modifications:
* check if vertex $s$ is already ''being proceed'' - and if so, report a cycle 
* mark the vertex as ''being processed''
* proceed as usually
* before leaving the routine, mark the vertex as ''done''


== Implementation ==
&lt;pre&gt;
public class TopologicalOrdering {
    private final List&lt;String&gt; vertices;
    private final Graph graph;
    private final Map&lt;String, Status&gt; visitedVertices;
    private final List&lt;String&gt; result = Lists.newLinkedList();

    // some initialization

    private static enum Status {
        STARTED, DONE;
    }

    public List&lt;Rule&gt; run() {
        for (String vertex : vertices) {
            if (!visitedVertices.containsKey(vertex)) {
                dfs(graph, vertex);
            }
        }

        return result;
    }

    private void dfs(Graph graph, String vertex) {
        Status status = visitedVertices.get(vertex);
        if (status == Status.STARTED) {
            throw new IllegalStateException(&quot;Look ma I got a cycle!&quot;);
        }

        if (status == Status.DONE) {
            return;
        }

        visitedVertices.put(vertex, Status.STARTED);

        for (String to : graph.adjacent(vertex)) {
            dfs(graph, to);
        }

        visitedVertices.put(vertex, Status.DONE);
        result.add(vertex);
    }
}
&lt;/pre&gt;

== See also ==
* [[Depth-First Search]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]
* http://en.wikipedia.org/wiki/Topological_sorting

[[Category:Algorithms]]
[[Category:Graphs]]
[[Category:Sorting]]</text>
      <sha1>lnmw0rsspndeudobzp1mkzyh2t5beof</sha1>
    </revision>
  </page>
  <page>
    <title>Strongly Connected Components</title>
    <ns>0</ns>
    <id>75</id>
    <revision>
      <id>76</id>
      <timestamp>2013-08-01T09:54:38Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4295">== Computing Strong Components ==
''strongly connected'':
* you can get to any point to any point within component
* example &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/0b4o3ktommo3j25jinji8tla29.png&quot; \&gt;

idea:
* use DFS and mark &quot;leaders&quot;
* leaders - points where DFS starts
* nodes with the same leader are SCCs

where to start?
* it depends on the starting point
* with good starting point we may discover a SCC
* with bad - the whole graph


== Kosaraju's Two-Pass algorithm ==
This is a randomized algorithm for finding strongly connected components, consists of 2 DFS passes of the graph.

=== First pass ===
* compute the &quot;magical&quot; ordering: the finishing times
* reverse the graph and run DFS 

Example
* graph (already reversed) &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/5vusfd6dc62fo3e58d567np03j.png&quot; \&gt;

* t = [7, 3, 1, 8, 2, 5, 9, 4, 6]
* order &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/5j38otlp5foorh6v5rmqeojmj8.png&quot; \&gt;

=== Second pass ===
* now we replace ordinal node names with finishing times
* and it's run on the original graph (not the reversed)

Example
* second pass &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/01l0gvo7sq1aqgkpkj9kea0gv4.png&quot; \&gt;


=== Algorithm ===
It consists of 3 routines: Kosaraju's, DFS-loop and DFS


Kosaraju's:
* let $G_{\text{rev}}$ be $G$ with all arcs reversed
* run DFS-loop on $G_{\text{rev}}$ to compute magic ordering of nodes
* let $f(v)$ = &quot;finishing time&quot;
* run DFS-loop on $G$ and process nodes in decreasing order of their finishing time


DFS-loop(graph $G$):
* global $t$ = 0: number of nodes processed so far
* global $s$ = NULL: most recent node from which DFS initiated
* for $i$ = $n$ downto $1$
** if $i$ not explored
** $s$ = $i$
** DFS($G$, $i$)


DFS(graph $G$, node $i$):
* mark $i$ explored
* leader($i$) = node $s$ (where DFS started)
* for each $(i, j) \in G$
** if $j$ not explored
** DFS($G$, $j$)
* $t$ = $t$ + $1$: finishing time
* set $f(i)$ = $t$


Running time: 2DFS = &lt;math&gt;O(n + m)&lt;/math&gt;


=== Correctness===
idea of the correctness:
* maximal finishing time is a sink
* if we replace each SCC with just a node
* the sink won't have outgoing edges
* first pass finds the sink SCC
* second pass &quot;peels off&quot; SCCs one-by-one


=== Implementation ===
&lt;pre&gt;
public class StronglyConnectedComponents {
    private Graph graph;

    private int counter = 0;
    private int currentLeaderVertex = -1;

    private boolean visited[];
    private int leaders[];
    private int finishingTime[];
    private int finishingTimeReversed[];

    public void run() {
        graph = readGraph();
        dfs1Loop();
        dfs2Loop();
    }

    public void dfs1Loop() {
        visited = new boolean[graph.getN()];
        finishingTime = new int[graph.getN()];
        Arrays.fill(finishingTime, -1);
        finishingTimeReversed = new int[graph.getN()];
        Arrays.fill(finishingTimeReversed, -1);

        for (int i = graph.getN() - 1; i &gt;= 0; i--) {
            if (!visited[i]) {
                currentLeaderVertex = i;
                dfs1(i);
            }
        }
    }

    private void dfs1(int u) {
        visited[u] = true;

        for (int v : graph.reverse(u)) {
            if (!visited[v]) {
                dfs1(v);
            }
        }

        finishingTime[u] = counter;
        finishingTimeReversed[counter] = u;
        counter++;
    }

    public void dfs2Loop() {
        visited = new boolean[graph.getN()];
        leaders = new int[graph.getN()];
        Arrays.fill(leaders, -1);

        for (int i = graph.getN() - 1; i &gt;= 0; i--) {
            int ft = finishingTimeReversed[i];
            if (!visited[ft]) {
                currentLeaderVertex = ft;
                dfs2(ft);
            }
        }
    }

    private void dfs2(int u) {
        visited[u] = true;
        leaders[u] = currentLeaderVertex;

        for (int v : graph.adjacent(u)) {
            if (!visited[v]) {
                dfs2(v);
            }
        }
    }
}
&lt;/pre&gt;


== See also ==
* [[Depth-First Search]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]

[[Category:Algorithms]]
[[Category:Graphs]]</text>
      <sha1>cnfz293t9xljdjoueozos8c3sx9brow</sha1>
    </revision>
  </page>
  <page>
    <title>Dijkstra's Shortest Path</title>
    <ns>0</ns>
    <id>76</id>
    <revision>
      <id>77</id>
      <timestamp>2013-08-01T09:54:48Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4433">== Dijkstra's Shortest Path ==
Goal: to find the shortest path in a graph from a single-source s

input
* directed graph &lt;math&gt;G = (V, E)&lt;/math&gt;
* each edge has non-negative length
* source vertex &lt;math&gt;s&lt;/math&gt;

output
* for each &lt;math&gt;v \in V&lt;/math&gt; complete
* &lt;math&gt;L(v)&lt;/math&gt; = length of the shortest path from $s$ to $v$ in &lt;math&gt;G&lt;/math&gt;

== Algorithm ==
Dijkstra's(graph &lt;math&gt;G&lt;/math&gt;, vertex &lt;math&gt;s&lt;/math&gt;)

Initialization:
* &lt;math&gt;X = \{s\}&lt;/math&gt;: vertices we've processed so far
* &lt;math&gt;A[s] = 0&lt;/math&gt;: at the end, it'll be populated with the shortest paths
* &lt;math&gt;B[s] = \varnothing&lt;/math&gt; (empty path): computed shortest path, or explanation only

Main loop: 
* we examine all edges that came from &lt;math&gt;X&lt;/math&gt; to &lt;math&gt;V - X&lt;/math&gt;
* and among all vertices we pick one which gives the minimal score in Dijkstra's greedy criterion $A[v] + l_{vw}$: we call it ''minimizing edge''


while $X \neq V$:
* for all $(v, w) \in E$
* with $v \in X$ and $w \notin X$
* pick a pair that minimizes $A[v] + l_{vw}$ ($A[v]$ is already computed in earlier iterations)
* let the minimizing edge be &lt;math&gt;(v^*, w^*)&lt;/math&gt;
* add &lt;math&gt;w^*&lt;/math&gt; to &lt;math&gt;X&lt;/math&gt;
* &lt;math&gt;A[w^*] = A[v] + l_{v^*w^*}&lt;/math&gt;: shortest path from &lt;math&gt;s&lt;/math&gt; to &lt;math&gt;w^*&lt;/math&gt;
* &lt;math&gt;B[w^*] = B[v^*] + (v^*, w^*)&lt;/math&gt;


Example 
* $s$ - starting vertex 
* &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/2b7gkb7r01nl56v8o3l1pgpchd.png&quot; \&gt;


Non-example 
* won't compute the shortest path for non-negative edges!
* &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/1ivblqfc6cju4p352nbq9mmad2.png&quot; \&gt;


== Implementation notes ==
* don't need the $B$ array
* $\Theta(mn)$ - naive implementation of Dijkstra's
* with [[Heap|heaps]] - better speed

=== Heaps to speed up Dijkstra ===
invariants to keep with heaps
* elements in heap: vertices in $V - X$ (not processed)
* for $v \notin X$
** $\text{key}[v]$ = smallest Dijkstra's greedy score of $(u, v) \in E$ with $v \in X$
** $\text{key}[v] = +\infty$ if an edge doesn't exist

if maintain 2nd invariants
* extract-min returns vertex &lt;math&gt;w^*&lt;/math&gt; to add to &lt;math&gt;X&lt;/math&gt; next

to maintain 2nd invariant
* when we extract $w$ from heap (added to $X$)
* for each edge &lt;math&gt;(w, v) \in E&lt;/math&gt;
* if &lt;math&gt;v \in V - X&lt;/math&gt; (i.e. already in the heap)
* we update the key
** delete &lt;math&gt;v&lt;/math&gt; from heap
** recompute &lt;math&gt;\text{key}[x] = \min(\text{key}[u], A[w] + l_{wv})&lt;/math&gt;
** re-insert &lt;math&gt;v&lt;/math&gt; into heap


running time with heaps: $O(m \log_2 n)$


== Implementation ==
&lt;pre&gt;
public static final int INFINITY = 1000000;

public static int[] dijkstra(UndirectedWeightedGraph graph, int s) {
    int dist[] = new int[graph.getN()];
    Arrays.fill(dist, INFINITY);

    List&lt;HeapNode&lt;Integer, Integer&gt;&gt; heapNodesList = prepareHeapNodesList(graph.getN());

    Heap&lt;Integer, Integer&gt; heap = Heap.naturalMin();
    HeapNode&lt;Integer, Integer&gt; sourceHeapNode = heap.insert(s, 0);
    heapNodesList.set(s, sourceHeapNode);

    for (int i = 0; i &lt; graph.getN(); i++) {
        if (i != s) {
            HeapNode&lt;Integer, Integer&gt; result = heap.insert(i, INFINITY);
            heapNodesList.set(i, result);
        }
    }

    int n = graph.getN();

    while (n &gt; 0) {
        HeapNode&lt;Integer, Integer&gt; node = heap.extractFirst();
        int distance = node.getKey();
        int nodeNumber = node.getValue();
        dist[nodeNumber] = distance;

        for (Edge edge : graph.adjacent(nodeNumber)) {
            int to = edge.getTo();
            HeapNode&lt;Integer, Integer&gt; toNode = heapNodesList.get(to);
            int newDistance = distance + edge.getWeight();
            if (newDistance &lt; toNode.getKey()) {
                heap.decreaseKey(toNode, newDistance);
            }
        }

        n--;
    }

    return dist;
}

@SuppressWarnings(&quot;unchecked&quot;)
private static List&lt;HeapNode&lt;Integer, Integer&gt;&gt; prepareHeapNodesList(int n) {
    List&lt;?&gt; list = Arrays.asList(new HeapNode[n]);
    return (List&lt;HeapNode&lt;Integer, Integer&gt;&gt;) list;
}
&lt;/pre&gt;

Heap implementation can be found here: [[Heap#Implementation]]


== See also ==
* [[Graphs]]
* [[Graph Search]]: [[Breadth-First Search]] and [[Depth-First Search]]


== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]
* http://algorithms.soc.srcf.net/notes/dijkstra_with_heaps.pdf

[[Category:Algorithms]]
[[Category:Graphs]]</text>
      <sha1>tjwe6u740tnzsg7rptfuftcjv0r5iom</sha1>
    </revision>
  </page>
  <page>
    <title>Heap</title>
    <ns>0</ns>
    <id>77</id>
    <revision>
      <id>78</id>
      <timestamp>2013-09-10T13:20:37Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2379">== Heap ==
a container that have keys

key property: at every node $x$
* key[x] $\leqslant$ (or $\geqslant$) all keys of $x$'s children
* therefore, the object at root must have min (max) value

== operations ==
insert
* adds new object
* $O(\log n)$


extract-min(max)
* extracts min (max) from heap
* ties broken arbitrarily
* $O(\log n)$


heapify
* initialization: builds a heap


delete
* $O(\log n)$ time


== Implementation ==
* it's a tree with &lt;math&gt;\approx \log_2 n&lt;/math&gt; levels
* backed by array

Traversing the tree:
* &lt;math&gt;\text{parent}(i) = i / 2&lt;/math&gt;
* &lt;math&gt;\text{left}(i) = 2i&lt;/math&gt;
* &lt;math&gt;\text{right}(i) = 2i + 1&lt;/math&gt;

insert(key $k$):
* stick $k$ at the end of last level
* bubble-up $k$ until heap property is restored

extract-min():
* delete root
* move last leaf to be new root
* bubble-down until heap property is restored
* (always swap with the smallest child)

Java implementation: 
* [https://code.google.com/p/codeforces-solutions-java/source/browse/trunk/codeforces-java/src/main/java/coursera/algo1/week5/Heap.java Heap.java]

== Applications ==
* general: fast way to do repeated minimum (maximum) computations
* priority queues, &quot;event manager&quot;

=== Heap sort ===
* put everythin into heap
* repeatedly extract-min until the heap is empty


=== Median maintenance ===
* given: a sequence of numbers $x_1, ..., x_n$, one-by-one
* goal: at each time step $i$, compute the median of $\{x_1, ..., x_i\}$
* solution: 
** create two heaps: 
*** $H_\text{low}$ (with extract-max operation), 
*** $H_\text{high}$ (extract-min)

* key idea: maintain invariant that $\approx \cfrac{i}{2}$ smallest (largest) numbers are in $H_\text{low}$ ($H_\text{high}$)
* so on $20$th step, in $H_\text{low}$ would be $10$th order statistics, and in $H_\text{high}$ - $11$th
* keep the heaps balanced! (so they have the same number of elements)


Implementation: [http://code.google.com/p/codeforces-solutions-java/source/browse/trunk/codeforces-java/src/main/java/coursera/algo1/week6/NextMedian.java]


=== Speeding up the [[Dijkstra's Shortest Path|Dijkstra's algorithm]] ===
* naive $\Theta(nm)$
* with heaps $O(m \log n)$


== See also ==
* [[Dijkstra's Shortest Path]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]
* http://algorithms.soc.srcf.net/notes/dijkstra_with_heaps.pdf

[[Category:Algorithms]]
[[Category:Data Structures]]</text>
      <sha1>3mhvwmff1debxoq3lysee46uiha5kdp</sha1>
    </revision>
  </page>
  <page>
    <title>Courses</title>
    <ns>0</ns>
    <id>78</id>
    <revision>
      <id>79</id>
      <timestamp>2015-06-26T08:20:57Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1811">== [[:Category:IT4BI]] ==
=== ULB ===
* [[Advanced Databases (ULB)]]
* [[Business Process Management (ULB)]]
* [[Data Warehousing (ULB)]]
* [[Database Systems Architecture (ULB)]]
* [[Decision Engineering (ULB)]]

=== UFRT ===
* [[Advanced Data Warehousing (UFRT)]]
* [[Data Mining (UFRT)]]
* [[XML and Web Technologies (UFRT)]]
* [[Information Retrieval (UFRT)]]
* [[Business Intelligence Seminar (UFRT)]]

=== TUB ===
* [[Scalable Data Analytics and Data Mining AIM3 (TUB)]]
* [[Python for Machine Learning (TUB)]]
* [[Machine Learning 1 (TUB)]]
* [[Machine Learning 2 (TUB)]]
* [[Seminar Hot Topics in Information Management IMSEM (TUB)]]


== Online Courses ==
=== [[:Category:Coursera]] ===
* [[Computing for Data Analysis (coursera)]]
* [[Game Theory (coursera)]]
* [[Data Analysis (coursera)]]
* [[Algorithms Design and Analysis Part 1 (coursera)]]
* [[Functional Programming Principles in Scala (coursera)]]
* [[Statistics: Making Sense of Data (coursera)]]
* [[Web Intelligence and Big Data (coursera)]]
* [[Machine Learning (coursera)]]
* [[Introduction to Data Science (coursera)]]
* [[Cryptography I (coursera)]]
* [[Discrete Optimization (coursera)]]
* [[Automata (coursera)]]
* [[Mining Massive Datasets (coursera)]]
* [[Coding the Matrix (coursera)]]
* [[Calculus Single Variable (coursera)]]
* [[Information Theory (coursera)]]

=== [[:Category:edX]] ===
* [[Introduction to Probability - The Science of Uncertainty 6.041x (edX)]]
* [[Learning From Data CS1156x (edX)]]
* [[Introduction to Linear Models and Matrix Algebra (edX)]] 
* [[Linear Algebra Foundations to Frontiers (edX)]]
* [[The Analytics Edge (edX)]] 

=== Misc ===
* [[Linear Algebra MIT 18.06 (OCW)]]
* [[Statistical Learning (Stanford Lagunita)]]



[[Category:Coursera]]
[[Category:IT4BI]]
[[Category:Notes]]
[[Category:Notes]]</text>
      <sha1>9k2gr95id6pmhtbkf6yl2iw2jrxn9v6</sha1>
    </revision>
    <revision>
      <id>720</id>
      <parentid>79</parentid>
      <timestamp>2015-12-06T16:36:26Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1950">== [[:Category:IT4BI]] ==
=== ULB ===
* [[Advanced Databases (ULB)]]
* [[Business Process Management (ULB)]]
* [[Data Warehousing (ULB)]]
* [[Database Systems Architecture (ULB)]]
* [[Decision Engineering (ULB)]]

=== UFRT ===
* [[Advanced Data Warehousing (UFRT)]]
* [[Data Mining (UFRT)]]
* [[XML and Web Technologies (UFRT)]]
* [[Information Retrieval (UFRT)]]
* [[Business Intelligence Seminar (UFRT)]]

=== TUB ===
1st Semester
* [[Seminar Hot Topics in Information Management IMSEM (TUB)]]
* [[Database Implementation (TUB)]]
* [[Scalable Data Analytics and Data Mining AIM3 (TUB)]]
* [[Python for Machine Learning (TUB)]]
* [[Machine Learning 1 (TUB)]]

2nd Semester
* [[Machine Learning 2 (TUB)]]
* [[Scalable Machine Learning (TUB)]]


== Online Courses ==
=== [[:Category:Coursera]] ===
* [[Computing for Data Analysis (coursera)]]
* [[Game Theory (coursera)]]
* [[Data Analysis (coursera)]]
* [[Algorithms Design and Analysis Part 1 (coursera)]]
* [[Functional Programming Principles in Scala (coursera)]]
* [[Statistics: Making Sense of Data (coursera)]]
* [[Web Intelligence and Big Data (coursera)]]
* [[Machine Learning (coursera)]]
* [[Introduction to Data Science (coursera)]]
* [[Cryptography I (coursera)]]
* [[Discrete Optimization (coursera)]]
* [[Automata (coursera)]]
* [[Mining Massive Datasets (coursera)]]
* [[Coding the Matrix (coursera)]]
* [[Calculus Single Variable (coursera)]]
* [[Information Theory (coursera)]]
* [[Econometrics: Methods and Applications (coursera)]]

=== [[:Category:edX]] ===
* [[Introduction to Probability - The Science of Uncertainty (edX)]]
* [[Learning From Data (edX)]]
* [[Introduction to Linear Models and Matrix Algebra (edX)]] 
* [[Linear Algebra Foundations to Frontiers (edX)]]
* [[The Analytics Edge (edX)]] 

=== Misc ===
* [[Linear Algebra MIT 18.06 (OCW)]]
* [[Statistical Learning (Stanford Lagunita)]]


[[Category:edX]]
[[Category:Coursera]]
[[Category:IT4BI]]
[[Category:Notes]]</text>
      <sha1>kkwu22zzuxc9de5f8zd8tvbcwuvpr3w</sha1>
    </revision>
    <revision>
      <id>726</id>
      <parentid>720</parentid>
      <timestamp>2015-12-06T19:59:50Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1951">== [[:Category:IT4BI]] ==
=== ULB ===
* [[Advanced Databases (ULB)]]
* [[Business Process Management (ULB)]]
* [[Data Warehousing (ULB)]]
* [[Database Systems Architecture (ULB)]]
* [[Decision Engineering (ULB)]]

=== UFRT ===
* [[Advanced Data Warehousing (UFRT)]]
* [[Data Mining (UFRT)]]
* [[XML and Web Technologies (UFRT)]]
* [[Information Retrieval (UFRT)]]
* [[Business Intelligence Seminar (UFRT)]]

=== TUB ===
1st Semester
* [[Seminar Hot Topics in Information Management IMSEM (TUB)]]
* [[Database Implementation (TUB)]]
* [[Scalable Data Analytics and Data Mining AIM3 (TUB)]]
* [[Python for Machine Learning (TUB)]]
* [[Machine Learning 1 (TUB)]]

2nd Semester
* [[Machine Learning 2 (TUB)]]
* [[Scalable Machine Learning (TUB)]]


== Online Courses ==
=== [[:Category:Coursera]] ===
* [[Computing for Data Analysis (coursera)]]
* [[Game Theory (coursera)]]
* [[Data Analysis (coursera)]]
* [[Algorithms Design and Analysis Part 1 (coursera)]]
* [[Functional Programming Principles in Scala (coursera)]]
* [[Statistics: Making Sense of Data (coursera)]]
* [[Web Intelligence and Big Data (coursera)]]
* [[Machine Learning (coursera)]]
* [[Introduction to Data Science (coursera)]]
* [[Cryptography I (coursera)]]
* [[Discrete Optimization (coursera)]]
* [[Automata (coursera)]]
* [[Mining Massive Datasets (coursera)]]
* [[Coding the Matrix (coursera)]]
* [[Calculus: Single Variable (coursera)]]
* [[Information Theory (coursera)]]
* [[Econometrics: Methods and Applications (coursera)]]

=== [[:Category:edX]] ===
* [[Introduction to Probability - The Science of Uncertainty (edX)]]
* [[Learning From Data (edX)]]
* [[Introduction to Linear Models and Matrix Algebra (edX)]] 
* [[Linear Algebra Foundations to Frontiers (edX)]]
* [[The Analytics Edge (edX)]] 

=== Misc ===
* [[Linear Algebra MIT 18.06 (OCW)]]
* [[Statistical Learning (Stanford Lagunita)]]


[[Category:edX]]
[[Category:Coursera]]
[[Category:IT4BI]]
[[Category:Notes]]</text>
      <sha1>et48o4pcaa0txnh1ho1j97fagiq98vz</sha1>
    </revision>
  </page>
  <page>
    <title>Books</title>
    <ns>0</ns>
    <id>79</id>
    <revision>
      <id>80</id>
      <timestamp>2015-05-05T14:00:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="267">== Books ==

=== Read ===
* [[Refactor your Wetware]]
* [[Learn More Study Less]]
* [[Semantic Web for the Working Ontologist (book)]]
* [[OpenIntro Statistics (book)]]
* [[Semantic Domains in Computational Linguistics (book)]]


[[Category:Books]]
[[Category:Notes]]</text>
      <sha1>0jtv08t02lbdofyo3o03n3h64l6f5um</sha1>
    </revision>
    <revision>
      <id>683</id>
      <parentid>80</parentid>
      <timestamp>2015-11-23T12:12:34Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="322">== Books ==

=== Read ===
* [[Refactor your Wetware]]
* [[Learn More Study Less (book notes)]]
* [[Semantic Web for the Working Ontologist (book)]]
* [[OpenIntro Statistics (book)]]
* [[Semantic Domains in Computational Linguistics (book)]]
* [[Hadoop: The Definitive Guide (book)]]


[[Category:Books]]
[[Category:Notes]]</text>
      <sha1>2em65eiv9vlku0wqlwskniq6iiocmxw</sha1>
    </revision>
    <revision>
      <id>684</id>
      <parentid>683</parentid>
      <timestamp>2015-11-23T12:25:20Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="355">== Books ==

=== Read ===
* [[Refactor your Wetware]]
* [[Learn More Study Less (book notes)]]
* [[Semantic Web for the Working Ontologist (book)]]
* [[Web Data Management (book)]]
* [[OpenIntro Statistics (book)]]
* [[Semantic Domains in Computational Linguistics (book)]]
* [[Hadoop: The Definitive Guide (book)]]


[[Category:Books]]
[[Category:Notes]]</text>
      <sha1>dd2j268kmj91fw8dhfub34zadx5gc3o</sha1>
    </revision>
    <revision>
      <id>810</id>
      <parentid>684</parentid>
      <timestamp>2017-08-06T19:31:44Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="388">== Books ==

=== Read ===
* [[Refactor your Wetware]]
* [[Learn More Study Less (book notes)]]
* [[Semantic Web for the Working Ontologist (book)]]
* [[Web Data Management (book)]]
* [[OpenIntro Statistics (book)]]
* [[Semantic Domains in Computational Linguistics (book)]]
* [[Hadoop: The Definitive Guide (book)]]
* [[Matrix Computations (book)]]


[[Category:Books]]
[[Category:Notes]]</text>
      <sha1>pwa5lmzgx927xbdup9ccile65e4ktn0</sha1>
    </revision>
  </page>
  <page>
    <title>Divide and Conquer</title>
    <ns>0</ns>
    <id>80</id>
    <revision>
      <id>81</id>
      <timestamp>2013-08-14T14:38:14Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2505">== Divide and Conquer ==
A computational paradigm, the main idea of which is to split a problem into subproblems until they are small enough to solve them easily

Idea:
* Divide into small subproblems
* Conquer using recursion
* Combine

== Examples ==
=== Sorting ===
This paradigm is used in 2 quite popular sorting algorithms:
* [[Merge Sort]]
* [[Quick Sort]]

=== Multiplication ===
grade-school multiplication method
* $\Theta(n^2)$

recursive way:
* $x \times y = 10^n ac + 10^{\frac{n}{2}} (ab + bc) + bd$
* $T(n)$ - max number of operations
* base case: $T(1) \leqslant c$ - constant
* general case: $T(n) \leqslant 4T(\frac{n}{2}) + O(n)$
* 4 recursive calls, $O(n)$ - addition

Gauss recursive algorithm:
* (1) $ac$, (2) $bd$, $(a+b)(c+d)$ (3)
* $ad + bc = (a+b)(c+d) - ac - bd$
* base case: $T(1) \leqslant c$
* gen case: $T(n) \leqslant 3T(\frac{n}{2}) + O(n)$
* 3 recursive calls instead of 4



== The Master Method ==
The way of estimating running time of D&amp;Q algorithms

* $T(n) = aT(\frac{n}{b}) + O(n^d)$
** $a$ - number of recursive calls ($&gt;= 1$)
** $b$ - shrinkage factor ($&gt; 1$)
** $d$ - running time done outside of recursive calls
* $T =$ 
** $O(n^d \log n)$ if $a = b^d$ (case 1)
** $O(n^d)$ if $a &lt; b^d$ (case 2)
** $O(n ^ {\log_b a})$ if $a &gt; b^d$ (case 3)

=== Examples ===
[[Merge Sort]]
* $a = 2$, $b = 2$, $d = 1$
* $b^d = 2$; case 1
* $T(n) \leqslant O(n^d \log n) = O(n \log n)$


Binary Search
* $a = 1$, $b = 2$, $d = 0$; case 1
* $ T(n) = O(log n)$


Recursive integer multiplication
* $a = 4$, $b = 2$, $d = 1$
* $b^d = 2 &lt; a$, case 3
* $T(n) = O(n ^ {\log_b a}) = O(n^2)$
* same as a grade-school algo


Gauss recursive integer multiplication
* $a = 3$, $b = 2$, $c = 1$
* $a &gt; b^d$; case 3
* $T(n) = O(n ^ {\log_2 3}) \approx O(n^{1.59})$
* better than $O(n^2)$

=== Idea behind proof ===
Suppose
* $a$ - rate of subproblem proliferation (&quot;force of Evil&quot;) - $\text{RSP}$
* $b^d$ - rate of work shrinkage (&quot;force of Good&quot;) - $\text{RWS}$

Then if
* $\text{RSP} &lt; \text{RWS}$
** the amount of work decreases with the recursion level j
** of the same magnitude
** expect $O(n^d \log n)$
* $\text{RSP} &gt; \text{RWS}$
** amount of work increases at level j
** RSP outdoes PWS, most of the work is at the root
** expect $O(n^d)$
* $\text{RSP} = \text{RWS}$
** amount of work is the same at every level
** $O(\# \text{leaves})$


== See also ==
* [[Merge Sort]]
* [[Quick Sort]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]

[[Category:Algorithms]]</text>
      <sha1>j7lokqt2g72ohy68qr1yxikc4vl5haq</sha1>
    </revision>
  </page>
  <page>
    <title>Merge Sort</title>
    <ns>0</ns>
    <id>81</id>
    <revision>
      <id>82</id>
      <timestamp>2015-10-16T14:35:28Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6169">== Merge Sort ==
Sorting algorithm based on [[Divide and Conquer]] computational paradigm

== Algorithm ==
MergeSort(array $a$):
* split $a$ into 2 halves
* sort them recursively
* merge the result

== Implementation ==
=== Java ===
&lt;pre&gt;
public int[] mergeSort(int[] input) {
    int n = input.length;
    if (n &lt;= 1) {
        return input;
    }

    int middle = n / 2;
    int leftUnsorted[] = Arrays.copyOfRange(input, 0, middle);
    int rightUnsorted[] = Arrays.copyOfRange(input, middle, n);

    int left[] = mergeSort(leftUnsorted);
    int right[] = mergeSort(rightUnsorted);

    return merge(left, right);
}

public int[] merge(int[] left, int[] right) {
    int leftLen = left.length, rightLen = right.length;
    int res[] = new int[leftLen + rightLen];

    int leftIndex = 0, rightIndex = 0, resIndex = 0;

    while (leftIndex &lt; leftLen &amp;&amp; rightIndex &lt; rightLen) {
        if (left[leftIndex] &lt;= right[rightIndex]) {
            res[resIndex] = left[leftIndex];
            leftIndex++;
            resIndex++;
        } else {
            res[resIndex] = right[rightIndex];
            rightIndex++;
            resIndex++;
        }
    }

    while (leftIndex &lt; leftLen) {
        res[resIndex] = left[leftIndex];
        leftIndex++;
        resIndex++;
    }

    while (rightIndex &lt; rightLen) {
        res[resIndex] = right[rightIndex];
        rightIndex++;
        resIndex++;
    }

    return res;
}
&lt;/pre&gt;

=== Scala ===
&lt;pre&gt;
def msort(xs: List[Int]): List[Int] = {
  val n = xs.length / 2
  if (n == 0) {
    xs
  } else {
    val (fst, snd) = xs splitAt n
    merge(msort(fst), msort(snd))
  }
}
 
def merge(xs: List[Int], ys: List[Int]) = xs match {
  case Nil =&gt; ys 
  case x :: xs1 =&gt;
    ys match {
      case Nil =&gt; xs
      case y :: ys1 =&gt;
        if (x &lt; y) x :: merge(xs1, ys)
        else y :: merge(xs, ys1)
    }
}
&lt;/pre&gt;

== Applications ==
=== Counting Inversions ===
With little modification the merge sort algorithm can be turned in the counting inversions algorithm.

Goal
* Input: array $A$ containing $1..n$ in some arbitrary order
* Output: number of inversions
** i.e. number of pairs $(i, j)$ of array indices with $i &lt; j$ and $A[i] &gt; A[j]$


Motivation
* how close are the two ranked lists?
* i.e. of 2 friends with movies


Example
* 1 3 5 2 4 6
* &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/4sejvio5u5q0jbvvq4ig4lpleg.png&quot; \&gt;
* if we write the sorted input and the given input, number of crosses would be number of inversions
* &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/6p2a0utmd4bi6kjp6tigf1pqfi.png&quot; \&gt;
* inversions are $(3,2)$, $(5,2)$, $(5,4)$

Brute force is not an option: $\Theta(n^2)$ time

Basic idea:
* insertion $c(i, j)$ is
** '''left''', if $i, j \leqslant \frac{n}{2}$
** '''right''', if $i, j &gt; \frac{n}{2}$
** '''split''' if $i \leqslant \frac{n}{2} &lt; j$


==== Algorithm ====
count(array $A$, length $n$): [idea]
* if $n$ = 1 return 0
* $X$ = count(1st half of $A$, $n / 2$)
* $Y$ = count(2nd part of $A$, $n / 2$)
* $Z$ = count-split($A$, $n$)
* return $X + Y + Z$

Count split should be linear to get $O(n \log n)$ running time. So we may modify merge sort and get:


count-and-sort(array $A$, length $n$):
* // B - sorted version of 1st half, C - of 2nd, D - (A, B) merged
* if $n$ = 1 return 0
* $(B, X)$ = count-and-sort(1st half of $A$, $n/2$)
* $(C, Y)$ = count-and-sort(2nd half of $A$, $n/2$)
* $(D, Z)$ = count-split($A$, $n$)
* return $(D, X + Y + Z)$


merge-count-split:
* while merging the two sorted subarrays, count the number of split inversions
* when element of 2nd array C is copied to output D
** increment total by number of elements remaining in 1st array B


Example
* consider merging (1, 2, 3) {L} with (2, 4, 6) {R}
* when 2 is copied to the output, it discovers the split inversions (3, 2) and (5, 2)
* when 4 is copied, it finds (5, 4)
* when in R element is less than in L - that's an inversion!


==== Implementation ====
&lt;pre&gt;
public Pair&lt;int[], Long&gt; countAndSort(int[] input) {
    int n = input.length;
    if (n == 1) {
        return Pair.of(input, 0L);
    }

    int middle = n / 2;
    int leftUnsorted[] = Arrays.copyOfRange(input, 0, middle);
    int rightUnsorted[] = Arrays.copyOfRange(input, middle, n);

    Pair&lt;int[], Long&gt; left = countAndSort(leftUnsorted);
    Pair&lt;int[], Long&gt; right = countAndSort(rightUnsorted);
    Pair&lt;int[], Long&gt; split = countSplitAndMerge(left.getLeft(), right.getLeft());

    return Pair.of(split.getLeft(), left.getRight() + right.getRight() + split.getRight());
}

public Pair&lt;int[], Long&gt; countSplitAndMerge(int[] left, int[] right) {
    int leftLen = left.length, rightLen = right.length;
    int sortedOutput[] = new int[leftLen + rightLen];

    int leftIndex = 0, rightIndex = 0, resIndex = 0;

    long inversions = 0;

    while (leftIndex &lt; leftLen &amp;&amp; rightIndex &lt; rightLen) {
        if (left[leftIndex] &lt;= right[rightIndex]) {
            sortedOutput[resIndex] = left[leftIndex];
            leftIndex++;
            resIndex++;
            // nothing
        } else {
            sortedOutput[resIndex] = right[rightIndex];
            rightIndex++;
            resIndex++;

            int remainedInLeft = leftLen - leftIndex;
            inversions = inversions + remainedInLeft;
        }
    }

    while (leftIndex &lt; leftLen) {
        sortedOutput[resIndex] = left[leftIndex];
        leftIndex++;
        resIndex++;
    }

    while (rightIndex &lt; rightLen) {
        sortedOutput[resIndex] = right[rightIndex];
        rightIndex++;
        resIndex++;
    }

    return Pair.of(sortedOutput, inversions);
}

@Override
public void run() {
    int[] input = readInput();
    Pair&lt;int[], Long&gt; result = countAndSort(input);
    out.print(result.getRight());
}
&lt;/pre&gt;

== [[External Merge Sort]] ==
The merge sort algorith is very easy to extend to sort large amounts of data that don't fit into memory - see [[External Merge Sort]]


== See Also ==
* [[Divide and Conquer]]
* [[Quick Sort]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]


[[Category:Algorithms]]
[[Category:Sorting]]</text>
      <sha1>tsvz0vz4r070tfj6vzpna54h8nmh2jb</sha1>
    </revision>
  </page>
  <page>
    <title>Quick Sort</title>
    <ns>0</ns>
    <id>82</id>
    <revision>
      <id>83</id>
      <timestamp>2013-08-01T09:53:01Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3096">== Quick Sort ==
Sorting algorithm based on [[Divide and Conquer]] computational paradigm

Advantages: 
* $O(n \log n)$
* operates at place

Main idea - partition around a pivot:
* pick an element
* rearrange array so
** left from pivot =&gt; less than pivot
** right from pivot =&gt; greater than pivot

done in $O(n)$ time

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/3qgfuh1sgn1v8jm90h0utise6h.png&quot; \&gt;

partition:

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/30s2g8fj552rlsrh1j0q2bjkn8.png&quot; \&gt;

== Algorithm ==
QuickSort(array $A$):
* if $n = 1$ return
* $p$ = ChosePivot($A$, $n$)
* partition $A$ around $p$
* QuickSort(left from $p$)
* QuickSort(right from $p$)


Partition($A$, $l$, $r$):
* // input: $A[l..r]$
* $p = A[l]$
* $i = i + 1$
* for $j = l + 1$ to $r$
** if $A[j] &lt; p$
*** swap $j$ and $i$
*** $i++$
** if $A[j] &gt; p$ - do nothing
* swap $l$ and $i - 1$

running time $O(n)$ where $n = r - l + 1$

== Pivot ==
quality
* Running time depends on the quality of pivot
* good quality - always divides into 2 equal halves (matches the median)
* i.e. leads to $\Theta(n)$
* Random pivot is good enough on average cases

So, possible pivots
* 1st element
* last element
* random

== Implementation ==
&lt;pre&gt;
public void qsort(int[] input, int left, int right) {
    int n = right - left;
    if (n &lt;= 1) {
        return;
    }

    int pivotIndex = partition(input, left, right);

    qsort(input, left, pivotIndex);
    qsort(input, pivotIndex + 1, right);
}

public int partition(int[] input, int left, int right) {
    int pivot = input[left];
    int i = left + 1;

    for (int j = left + 1; j &lt; right; j++) {
        if (input[j] &lt; pivot) {
            swap(input, j, i);
            i++;
        }
    }

    swap(input, left, i - 1);
    return i - 1;
}

public void swap(int[] input, int j, int i) {
    int tmp = input[j];
    input[j] = input[i];
    input[i] = tmp;
}
&lt;/pre&gt;

== Randomized Selection ($i$th order statistics) ==
problem
* input: given $i$th element and array $A$
* goal: find $i$th order statistics (i.e. $i$th smallest element)


Reduction to sorting
* $O(n \log n)$
* apply merge sort
* return $i$th element
* can we do better? yes!


modification for QuickSort:
* recall Partition procedure
* pivot is on its position!


how to find $i$th order?
* suppose need 5th element in $A$ of len 10
* after partition, pivot in on 3rd position
* so we need 2nd (5-3) statistics on the $R$ side


=== Algorithm ===
RSelect(array $A$, len $n$, order $i$)
* if $n = 1$ return $A[1]$
* choose pivot $p$ from $A$ at random
* partition $A$ around $p$
* $j$ = new index of $p$
* if $j = i$: return $p$ // lucky case
* if $j &gt; i$
** return RSelect($L$ side of $A$, $j-1$, $i$)
* if $j &lt; i$
** return RSelect($R$ side of $A$, $n-j$, $i-j$)


Best pivot - the median
* $T(n) \leqslant T(\frac{n}{2}) + O(n)$
* $T(n) = O(n)$


== See also ==
* [[Divide and Conquer]]
* [[Merge Sort]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]

[[Category:Algorithms]]
[[Category:Sorting]]</text>
      <sha1>agwh9posh9gxitgdapanw1xe0zwlf4a</sha1>
    </revision>
    <revision>
      <id>815</id>
      <parentid>83</parentid>
      <timestamp>2018-04-21T10:46:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5396">== Quick Sort ==
Sorting algorithm based on [[Divide and Conquer]] computational paradigm

Advantages: 
* $O(n \log n)$
* operates at place

Main idea - partition around a pivot:
* pick an element
* rearrange array so
** left from pivot =&gt; less than pivot
** right from pivot =&gt; greater than pivot

done in $O(n)$ time

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/3qgfuh1sgn1v8jm90h0utise6h.png&quot; \&gt;

partition:

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/30s2g8fj552rlsrh1j0q2bjkn8.png&quot; \&gt;

=== Algorithm ===
QuickSort(array $A$):
* $n = \text{len}(A)$
* if $n = 1$ return
* $p$ = ChosePivot($A$)
* partition $A$ around $p$
* QuickSort($A$ left from $p$)
* QuickSort($A$ right from $p$)

Partition($A$):
* // input: $A[l..r]$
* $p = A[l]$
* $i = i + 1$
* for $j = l + 1$ to $r$
** if $A[j] &lt; p$
*** swap $j$ and $i$
*** $i = i + 1$
* swap $l$ and $i - 1$

running time $O(n)$ where $n = r - l + 1$

=== Pivot ===
Quality
* Running time depends on the quality of pivot
* good quality - always divides into 2 equal halves (matches the median)
* i.e. leads to $\Theta(n)$
* Random pivot is good enough on average cases

So, possible pivots
* 1st element
* last element
* random

=== Implementation ===
==== Java ====
&lt;pre&gt;
public void qsort(int[] input, int left, int right) {
    int n = right - left;
    if (n &lt;= 1) {
        return;
    }

    int pivotIndex = partition(input, left, right);

    qsort(input, left, pivotIndex);
    qsort(input, pivotIndex + 1, right);
}

public int partition(int[] input, int left, int right) {
    int pivot = input[left];
    int i = left + 1;

    for (int j = left + 1; j &lt; right; j++) {
        if (input[j] &lt; pivot) {
            swap(input, j, i);
            i++;
        }
    }

    swap(input, left, i - 1);
    return i - 1;
}

public void swap(int[] input, int j, int i) {
    int tmp = input[j];
    input[j] = input[i];
    input[i] = tmp;
}
&lt;/pre&gt;

==== Python ====

 def pivot(A, l, r):
     return l
 
 def partition(A, l, r):
     pi = pivot(A, l, r)
     p = A[pi]
     A[l], A[pi] = A[pi], A[l]
 
     i = l
     
     for j in range(i + 1, r):
         if A[j] &lt; p:
             i = i + 1
             A[i], A[j] = A[j], A[i]
     
     A[l], A[i] = A[i], A[l]
     return i
 
 def qs(A, l, r):
     n = r - l
 
     if n &lt;= 1:
         return
 
     i = partition(A, l, r)
     
     qs(A, l, i)
     qs(A, i + 1, r)
 
 def quicksort(A):
     return qs(A, 0, len(A))

== Hoare Partition ==
QuickSort implementation from above does not behave well when there repeating elements. 

Hoare Partitioning scheme fixes it:
* Idea: for pivot $p$ split array $A$ into two parts: &quot;$\leqslant p$&quot; and &quot;$\geqslant p$&quot; (not &quot;$&gt;p$&quot; and &quot;$&lt;p$&quot; like previously)
* Previously we moved both indices $i$ and $j$ from left to right. Now move $i$ from left, and $j$ from right

HoarePartition($A$, $l$, $r$):
* choose pivot $p$ (e.g. $p = A[l]$)
* $i = l$, $j = r$
* repeat:
** while $A[i] &lt; p$, increment $i$ 
** while $A[j] &gt; p$, decrement $j$
** if $i \geqslant j$, stop and return $j$
** swap $A[i]$ and $A[j]$
** increment $i$, decrement $j$

The QuickSort procedure stays the same

=== Implementation ===

 def hoare_partition(A, l, r):
     pi = pivot(A, l, r)
     p = A[pi]
 
     i = l
     j = r
     
     while True:
         while A[i] &lt; p:
             i = i + 1
 
         while A[j] &gt; p:
             j = j - 1
         
         if i &gt;= j:
             return j
         
         A[i], A[j] = A[j], A[i]
         i = i + 1
         j = j - 1
 
 
 def qs(A, l, r):
     if l &gt;= r:
        return
     q = hoare_partition(A, l, r)
     qs(A, l, q)
     qs(A, q + 1, r)
 
 def quicksort(A):
     return qs(A, 0, len(A) - 1)


== $i$th order statistics ==
problem
* input: given $i$th element and array $A$
* goal: find $i$th order statistics (i.e. $i$th smallest element)


Reduction to sorting
* $O(n \log n)$
* apply merge sort
* return $i$th element
* can we do better? yes!


modification for QuickSort:
* recall Partition procedure
* pivot is on its position!


how to find $i$th order?
* suppose need 5th element in $A$ of len 10
* after partition, pivot in on 3rd position
* so we need 2nd (5-3) statistics on the $R$ side


=== Algorithm ===
RSelect(array $A$, len $n$, order $i$)
* if $n = 1$ return $A[1]$
* choose pivot $p$ from $A$ at random
* partition $A$ around $p$
* $j$ = new index of $p$
* if $j = i$: return $p$ // lucky case
* if $j &gt; i$
** return RSelect($L$ side of $A$, $j-1$, $i$)
* if $j &lt; i$
** return RSelect($R$ side of $A$, $n-j$, $i-j$)


Best pivot - the median
* $T(n) \leqslant T(\frac{n}{2}) + O(n)$
* $T(n) = O(n)$

=== Implementation ===

 def r_select(A, l, r, i):
     n = r - l
     if n == 0:
         return A[l]
 
     pi = partition(A, l, r)
 
     if i == pi:
         return A[pi]
     if pi &lt; i:
         return r_select(A, pi + 1, r, i)
     else:
         return r_select(A, l, pi, i)
 
 def ith_order_statistic(A, i):
     return r_select(A.copy(), 0, len(A), i)

If there are repeating elements, we need to use HoarePartition instead 

== See also ==
* [[Divide and Conquer]]
* [[Merge Sort]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]
* https://stackoverflow.com/questions/40368543/quicksort-hoares-partitioning-with-duplicate-values

[[Category:Algorithms]]
[[Category:Sorting]]</text>
      <sha1>fvxah5bidy516gl0muyla6gr2e5oqq0</sha1>
    </revision>
    <revision>
      <id>816</id>
      <parentid>815</parentid>
      <timestamp>2018-04-21T10:50:07Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5755">== Quick Sort ==
Sorting algorithm based on [[Divide and Conquer]] computational paradigm

Advantages: 
* $O(n \log n)$
* operates at place

Main idea - partition around a pivot:
* pick an element
* rearrange array so
** left from pivot =&gt; less than pivot
** right from pivot =&gt; greater than pivot

done in $O(n)$ time

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/3qgfuh1sgn1v8jm90h0utise6h.png&quot; \&gt;

partition:

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/30s2g8fj552rlsrh1j0q2bjkn8.png&quot; \&gt;

=== Algorithm ===
QuickSort(array $A$):
* $n = \text{len}(A)$
* if $n = 1$ return
* $p$ = ChosePivot($A$)
* partition $A$ around $p$
* QuickSort($A$ left from $p$)
* QuickSort($A$ right from $p$)

Partition($A$):
* // input: $A[l..r]$
* $p = A[l]$
* $i = i + 1$
* for $j = l + 1$ to $r$
** if $A[j] &lt; p$
*** swap $j$ and $i$
*** $i = i + 1$
* swap $l$ and $i - 1$

running time $O(n)$ where $n = r - l + 1$

=== Pivot ===
Quality
* Running time depends on the quality of pivot
* good quality - always divides into 2 equal halves (matches the median)
* i.e. leads to $\Theta(n)$
* Random pivot is good enough on average cases

So, possible pivots
* 1st element
* last element
* random

=== Implementation ===
==== Java ====
&lt;pre&gt;
public void qsort(int[] input, int left, int right) {
    int n = right - left;
    if (n &lt;= 1) {
        return;
    }

    int pivotIndex = partition(input, left, right);

    qsort(input, left, pivotIndex);
    qsort(input, pivotIndex + 1, right);
}

public int partition(int[] input, int left, int right) {
    int pivot = input[left];
    int i = left + 1;

    for (int j = left + 1; j &lt; right; j++) {
        if (input[j] &lt; pivot) {
            swap(input, j, i);
            i++;
        }
    }

    swap(input, left, i - 1);
    return i - 1;
}

public void swap(int[] input, int j, int i) {
    int tmp = input[j];
    input[j] = input[i];
    input[i] = tmp;
}
&lt;/pre&gt;

==== Python ====

 def pivot(A, l, r):
     return l
 
 def partition(A, l, r):
     pi = pivot(A, l, r)
     p = A[pi]
     A[l], A[pi] = A[pi], A[l]
 
     i = l
     
     for j in range(i + 1, r):
         if A[j] &lt; p:
             i = i + 1
             A[i], A[j] = A[j], A[i]
     
     A[l], A[i] = A[i], A[l]
     return i
 
 def qs(A, l, r):
     n = r - l
 
     if n &lt;= 1:
         return
 
     i = partition(A, l, r)
     
     qs(A, l, i)
     qs(A, i + 1, r)
 
 def quicksort(A):
     return qs(A, 0, len(A))

== Hoare Partition ==
QuickSort implementation from above does not behave well when there repeating elements. 

Hoare Partitioning scheme fixes it:
* Idea: for pivot $p$ split array $A$ into two parts: &quot;$\leqslant p$&quot; and &quot;$\geqslant p$&quot; (not &quot;$&gt;p$&quot; and &quot;$&lt;p$&quot; like previously)
* Previously we moved both indices $i$ and $j$ from left to right. Now move $i$ from left, and $j$ from right

HoarePartition($A$, $l$, $r$):
* choose pivot $p$ (e.g. $p = A[l]$)
* $i = l$, $j = r$
* repeat:
** while $A[i] &lt; p$, increment $i$ 
** while $A[j] &gt; p$, decrement $j$
** if $i \geqslant j$, stop and return $j$
** swap $A[i]$ and $A[j]$
** increment $i$, decrement $j$

The QuickSort procedure stays the same

=== Implementation ===

 def hoare_partition(A, l, r):
     pi = pivot(A, l, r)
     p = A[pi]
 
     i = l
     j = r
     
     while True:
         while A[i] &lt; p:
             i = i + 1
 
         while A[j] &gt; p:
             j = j - 1
         
         if i &gt;= j:
             return j
         
         A[i], A[j] = A[j], A[i]
         i = i + 1
         j = j - 1
 
 
 def qs(A, l, r):
     if l &gt;= r:
        return
     q = hoare_partition(A, l, r)
     qs(A, l, q)
     qs(A, q + 1, r)
 
 def quicksort(A):
     return qs(A, 0, len(A) - 1)


== $i$th order statistics ==
problem
* input: given $i$th element and array $A$
* goal: find $i$th order statistics (i.e. $i$th smallest element)


Reduction to sorting
* $O(n \log n)$
* apply merge sort
* return $i$th element
* can we do better? yes!


modification for QuickSort:
* recall Partition procedure
* pivot is on its position!


how to find $i$th order?
* suppose need 5th element in $A$ of len 10
* after partition, pivot in on 3rd position
* so we need 2nd (5-3) statistics on the $R$ side


=== Algorithm ===
RSelect(array $A$, len $n$, order $i$)
* if $n = 1$ return $A[1]$
* choose pivot $p$ from $A$ at random
* partition $A$ around $p$
* $j$ = new index of $p$
* if $j = i$: return $p$ // lucky case
* if $j &gt; i$
** return RSelect($L$ side of $A$, $j-1$, $i$)
* if $j &lt; i$
** return RSelect($R$ side of $A$, $n-j$, $i-j$)


Best pivot - the median
* $T(n) \leqslant T(\frac{n}{2}) + O(n)$
* $T(n) = O(n)$

=== Implementation ===

 def r_select(A, l, r, i):
     n = r - l
     if n == 0:
         return A[l]
 
     pi = partition(A, l, r)
 
     if i == pi:
         return A[pi]
     if pi &lt; i:
         return r_select(A, pi + 1, r, i)
     else:
         return r_select(A, l, pi, i)
 
 def ith_order_statistic(A, i):
     return r_select(A.copy(), 0, len(A), i)

If there are repeating elements, use HoarePartition instead:

 def hoare_r_select(A, l, r, i):
     n = r - l
     if n == 0:
         return A[l]
 
     pi = hoare_partition(A, l, r)
     if i == pi:
         return A[pi]
     if pi &lt; i:
         return hoare_r_select(A, pi + 1, r, i)
     else:
         return hoare_r_select(A, l, pi, i)
 
 def ith_order_statistic(A, i):
     return hoare_r_select(A.copy(), 0, len(A) - 1, i)

== See also ==
* [[Divide and Conquer]]
* [[Merge Sort]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]
* https://stackoverflow.com/questions/40368543/quicksort-hoares-partitioning-with-duplicate-values

[[Category:Algorithms]]
[[Category:Sorting]]</text>
      <sha1>oxsiemgxvqe0jy5nlcmbqqt017cyq10</sha1>
    </revision>
    <revision>
      <id>818</id>
      <parentid>816</parentid>
      <timestamp>2018-04-22T11:33:37Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6356">== Quick Sort ==
Sorting algorithm based on [[Divide and Conquer]] computational paradigm

Advantages: 
* $O(n \log n)$
* operates at place

Main idea - partition around a pivot:
* pick an element
* rearrange array so
** left from pivot =&gt; less than pivot
** right from pivot =&gt; greater than pivot

done in $O(n)$ time

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/3qgfuh1sgn1v8jm90h0utise6h.png&quot; \&gt;

partition:

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/30s2g8fj552rlsrh1j0q2bjkn8.png&quot; \&gt;

=== Algorithm ===
QuickSort(array $A$):
* $n = \text{len}(A)$
* if $n = 1$ return
* $p$ = ChosePivot($A$)
* partition $A$ around $p$
* QuickSort($A$ left from $p$)
* QuickSort($A$ right from $p$)

Partition($A$):
* // input: $A[l..r]$
* $p = A[l]$
* $i = i + 1$
* for $j = l + 1$ to $r$
** if $A[j] &lt; p$
*** swap $j$ and $i$
*** $i = i + 1$
* swap $l$ and $i - 1$

running time $O(n)$ where $n = r - l + 1$

=== Pivot ===
Quality
* Running time depends on the quality of pivot
* good quality - always divides into 2 equal halves (matches the median)
* i.e. leads to $\Theta(n)$
* Random pivot is good enough on average cases

So, possible pivots
* 1st element
* last element
* random

=== Implementation ===
==== Java ====
&lt;pre&gt;
public void qsort(int[] input, int left, int right) {
    int n = right - left;
    if (n &lt;= 1) {
        return;
    }

    int pivotIndex = partition(input, left, right);

    qsort(input, left, pivotIndex);
    qsort(input, pivotIndex + 1, right);
}

public int partition(int[] input, int left, int right) {
    int pivot = input[left];
    int i = left + 1;

    for (int j = left + 1; j &lt; right; j++) {
        if (input[j] &lt; pivot) {
            swap(input, j, i);
            i++;
        }
    }

    swap(input, left, i - 1);
    return i - 1;
}

public void swap(int[] input, int j, int i) {
    int tmp = input[j];
    input[j] = input[i];
    input[i] = tmp;
}
&lt;/pre&gt;

==== Python ====

 def pivot(A, l, r):
     return l
 
 def partition(A, l, r):
     pi = pivot(A, l, r)
     p = A[pi]
     A[l], A[pi] = A[pi], A[l]
 
     i = l
     
     for j in range(i + 1, r):
         if A[j] &lt; p:
             i = i + 1
             A[i], A[j] = A[j], A[i]
     
     A[l], A[i] = A[i], A[l]
     return i
 
 def qs(A, l, r):
     n = r - l
 
     if n &lt;= 1:
         return
 
     i = partition(A, l, r)
     
     qs(A, l, i)
     qs(A, i + 1, r)
 
 def quicksort(A):
     return qs(A, 0, len(A))

== Hoare Partition ==
QuickSort implementation from above does not behave well when there repeating elements. 

Hoare Partitioning scheme fixes it:
* Idea: for pivot $p$ split array $A$ into two parts: &quot;$\leqslant p$&quot; and &quot;$\geqslant p$&quot; (not &quot;$&gt;p$&quot; and &quot;$&lt;p$&quot; like previously)
* Previously we moved both indices $i$ and $j$ from left to right. Now move $i$ from left, and $j$ from right

HoarePartition($A$, $l$, $r$):
* choose pivot $p$ (e.g. $p = A[l]$)
* $i = l$, $j = r$
* repeat:
** while $A[i] &lt; p$, increment $i$ 
** while $A[j] &gt; p$, decrement $j$
** if $i \geqslant j$, stop and return $j$
** swap $A[i]$ and $A[j]$
** increment $i$, decrement $j$

The QuickSort procedure stays the same

=== Implementation ===

 def hoare_partition(A, l, r):
     pi = pivot(A, l, r)
     p = A[pi]
 
     i = l
     j = r
     
     while True:
         while A[i] &lt; p:
             i = i + 1
 
         while A[j] &gt; p:
             j = j - 1
         
         if i &gt;= j:
             return j
         
         A[i], A[j] = A[j], A[i]
         i = i + 1
         j = j - 1
 
 
 def qs(A, l, r):
     if l &gt;= r:
        return
     q = hoare_partition(A, l, r)
     qs(A, l, q)
     qs(A, q + 1, r)
 
 def quicksort(A):
     return qs(A, 0, len(A) - 1)


== Quick Select ==
Quickselect is an algorithm for computing $i$th order statistics

Problem
* input: given $i$th element and array $A$
* goal: find $i$th order statistics (i.e. $i$th smallest element)


Reduction to sorting
* $O(n \log n)$
* apply merge sort
* return $i$th element
* can we do better? yes!


modification for QuickSort:
* recall Partition procedure
* pivot is on its position!


how to find $i$th order?
* suppose need 5th element in $A$ of len 10
* after partition, pivot in on 3rd position
* so we need 2nd (5-3) statistics on the $R$ side


=== Algorithm ===
RSelect(array $A$, len $n$, order $i$)
* if $n = 1$ return $A[1]$
* choose pivot $p$ from $A$ at random
* partition $A$ around $p$
* $j$ = new index of $p$
* if $j = i$: return $p$ // lucky case
* if $j &gt; i$
** return RSelect($L$ side of $A$, $j-1$, $i$)
* if $j &lt; i$
** return RSelect($R$ side of $A$, $n-j$, $i-j$)

Best pivot - the median
* $T(n) \leqslant T(\frac{n}{2}) + O(n)$
* $T(n) = O(n)$


==== Implementation ====

 def r_select(A, l, r, i):
     n = r - l
     if n == 0:
         return A[l]
 
     pi = partition(A, l, r)
 
     if i == pi:
         return A[pi]
     if pi &lt; i:
         return r_select(A, pi + 1, r, i)
     else:
         return r_select(A, l, pi, i)
 
 def ith_order_statistic(A, i):
     return r_select(A.copy(), 0, len(A), i)


=== Repeating Elements ===
If there are repeating elements:
* the HoarePartition algorithm (as it is implemented above) does not work well with such RSelect:
* It does not place the pivot on its position, unlike the Partition algorithm
* It only ensures the invariant that left is $\leqslant p$ and right is $\geqslant p$.

Solution:
* We do &quot;partial QuickSort&quot;: sort only the part where $i$ is
* After the input is partially sorted, we know that the $i$th element is correctly placed
* So we just take it

==== Implementation ====

 def partial_quicksort(A, l, r, i):
     if l &gt;= r:
         return
     q = hoare_partition(A, l, r)
     if i &lt;= q:
         partial_quicksort(A, l, q, i)
     else:
         partial_quicksort(A, q + 1, r, i)
 
 def ith_order_statistic(A, i):
     A = A.copy()
     partial_quicksort(A, 0, len(A) - 1, i)
     return A[i]


== See also ==
* [[Divide and Conquer]]
* [[Merge Sort]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]
* https://stackoverflow.com/questions/40368543/quicksort-hoares-partitioning-with-duplicate-values
* https://en.wikipedia.org/wiki/Quickselect
* https://oneraynyday.github.io/algorithms/2016/06/16/QuickSelectSort/

[[Category:Algorithms]]
[[Category:Sorting]]</text>
      <sha1>g2qkok4ke54nn5642e64745520rlx65</sha1>
    </revision>
    <revision>
      <id>819</id>
      <parentid>818</parentid>
      <timestamp>2018-04-22T11:35:26Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6378">== Quick Sort ==
Sorting algorithm based on [[Divide and Conquer]] computational paradigm

Advantages: 
* $O(n \log n)$
* operates at place

Main idea - partition around a pivot:
* pick an element
* rearrange array so
** left from pivot =&gt; less than pivot
** right from pivot =&gt; greater than pivot

done in $O(n)$ time

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/3qgfuh1sgn1v8jm90h0utise6h.png&quot; \&gt;

partition:

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/30s2g8fj552rlsrh1j0q2bjkn8.png&quot; \&gt;

=== Algorithm ===
QuickSort(array $A$):
* $n = \text{len}(A)$
* if $n = 1$ return
* $p$ = ChosePivot($A$)
* partition $A$ around $p$
* QuickSort($A$ left from $p$)
* QuickSort($A$ right from $p$)

Partition($A$):
* // input: $A[l..r]$
* $p = A[l]$
* $i = i + 1$
* for $j = l + 1$ to $r$
** if $A[j] &lt; p$
*** swap $j$ and $i$
*** $i = i + 1$
* swap $l$ and $i - 1$

running time $O(n)$ where $n = r - l + 1$

=== Pivot ===
Quality
* Running time depends on the quality of pivot
* good quality - always divides into 2 equal halves (matches the median)
* i.e. leads to $\Theta(n)$
* Random pivot is good enough on average cases

So, possible pivots
* 1st element
* last element
* random

=== Implementation ===
==== Java ====
&lt;pre&gt;
public void qsort(int[] input, int left, int right) {
    int n = right - left;
    if (n &lt;= 1) {
        return;
    }

    int pivotIndex = partition(input, left, right);

    qsort(input, left, pivotIndex);
    qsort(input, pivotIndex + 1, right);
}

public int partition(int[] input, int left, int right) {
    int pivot = input[left];
    int i = left + 1;

    for (int j = left + 1; j &lt; right; j++) {
        if (input[j] &lt; pivot) {
            swap(input, j, i);
            i++;
        }
    }

    swap(input, left, i - 1);
    return i - 1;
}

public void swap(int[] input, int j, int i) {
    int tmp = input[j];
    input[j] = input[i];
    input[i] = tmp;
}
&lt;/pre&gt;

==== Python ====

 def pivot(A, l, r):
     return l
 
 def partition(A, l, r):
     pi = pivot(A, l, r)
     p = A[pi]
     A[l], A[pi] = A[pi], A[l]
 
     i = l
     
     for j in range(i + 1, r):
         if A[j] &lt; p:
             i = i + 1
             A[i], A[j] = A[j], A[i]
     
     A[l], A[i] = A[i], A[l]
     return i
 
 def qs(A, l, r):
     n = r - l
 
     if n &lt;= 1:
         return
 
     i = partition(A, l, r)
     
     qs(A, l, i)
     qs(A, i + 1, r)
 
 def quicksort(A):
     return qs(A, 0, len(A))

== Hoare Partition ==
QuickSort implementation from above does not behave well when there repeating elements. 

Hoare Partitioning scheme fixes it:
* Idea: for pivot $p$ split array $A$ into two parts: &quot;$\leqslant p$&quot; and &quot;$\geqslant p$&quot; (not &quot;$&gt;p$&quot; and &quot;$&lt;p$&quot; like previously)
* Previously we moved both indices $i$ and $j$ from left to right. Now move $i$ from left, and $j$ from right

HoarePartition($A$, $l$, $r$):
* choose pivot $p$ (e.g. $p = A[l]$)
* $i = l$, $j = r$
* repeat:
** while $A[i] &lt; p$, increment $i$ 
** while $A[j] &gt; p$, decrement $j$
** if $i \geqslant j$, stop and return $j$
** swap $A[i]$ and $A[j]$
** increment $i$, decrement $j$

The QuickSort procedure stays the same

=== Implementation ===

 def hoare_partition(A, l, r):
     pi = pivot(A, l, r)
     p = A[pi]
 
     i = l
     j = r
     
     while True:
         while A[i] &lt; p and i &lt;= j:
             i = i + 1
 
         while A[j] &gt; p and j &gt;= i:
             j = j - 1
         
         if i &gt;= j:
             return j
         
         A[i], A[j] = A[j], A[i]
         i = i + 1
         j = j - 1
 
 
 def qs(A, l, r):
     if l &gt;= r:
        return
     q = hoare_partition(A, l, r)
     qs(A, l, q)
     qs(A, q + 1, r)
 
 def quicksort(A):
     return qs(A, 0, len(A) - 1)


== Quick Select ==
Quickselect is an algorithm for computing $i$th order statistics

Problem
* input: given $i$th element and array $A$
* goal: find $i$th order statistics (i.e. $i$th smallest element)


Reduction to sorting
* $O(n \log n)$
* apply merge sort
* return $i$th element
* can we do better? yes!


modification for QuickSort:
* recall Partition procedure
* pivot is on its position!


how to find $i$th order?
* suppose need 5th element in $A$ of len 10
* after partition, pivot in on 3rd position
* so we need 2nd (5-3) statistics on the $R$ side


=== Algorithm ===
RSelect(array $A$, len $n$, order $i$)
* if $n = 1$ return $A[1]$
* choose pivot $p$ from $A$ at random
* partition $A$ around $p$
* $j$ = new index of $p$
* if $j = i$: return $p$ // lucky case
* if $j &gt; i$
** return RSelect($L$ side of $A$, $j-1$, $i$)
* if $j &lt; i$
** return RSelect($R$ side of $A$, $n-j$, $i-j$)

Best pivot - the median
* $T(n) \leqslant T(\frac{n}{2}) + O(n)$
* $T(n) = O(n)$


==== Implementation ====

 def r_select(A, l, r, i):
     n = r - l
     if n == 0:
         return A[l]
 
     pi = partition(A, l, r)
 
     if i == pi:
         return A[pi]
     if pi &lt; i:
         return r_select(A, pi + 1, r, i)
     else:
         return r_select(A, l, pi, i)
 
 def ith_order_statistic(A, i):
     return r_select(A.copy(), 0, len(A), i)


=== Repeating Elements ===
If there are repeating elements:
* the HoarePartition algorithm (as it is implemented above) does not work well with such RSelect:
* It does not place the pivot on its position, unlike the Partition algorithm
* It only ensures the invariant that left is $\leqslant p$ and right is $\geqslant p$.

Solution:
* We do &quot;partial QuickSort&quot;: sort only the part where $i$ is
* After the input is partially sorted, we know that the $i$th element is correctly placed
* So we just take it

==== Implementation ====

 def partial_quicksort(A, l, r, i):
     if l &gt;= r:
         return
     q = hoare_partition(A, l, r)
     if i &lt;= q:
         partial_quicksort(A, l, q, i)
     else:
         partial_quicksort(A, q + 1, r, i)
 
 def ith_order_statistic(A, i):
     A = A.copy()
     partial_quicksort(A, 0, len(A) - 1, i)
     return A[i]


== See also ==
* [[Divide and Conquer]]
* [[Merge Sort]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]
* https://stackoverflow.com/questions/40368543/quicksort-hoares-partitioning-with-duplicate-values
* https://en.wikipedia.org/wiki/Quickselect
* https://oneraynyday.github.io/algorithms/2016/06/16/QuickSelectSort/

[[Category:Algorithms]]
[[Category:Sorting]]</text>
      <sha1>jjensjai65wqtuk4dz8027bb538pdq7</sha1>
    </revision>
  </page>
  <page>
    <title>Binary Search Trees</title>
    <ns>0</ns>
    <id>83</id>
    <revision>
      <id>84</id>
      <timestamp>2014-05-03T08:47:32Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2951">== Binary search trees ==
Binary search trees are [[Tree]]s with rank = 2.

Operations on a sorted array
* Search $\Theta(\log n)$
* Select $O(1)$
* min/max $O(1)$
* pred/succ $O(1)$
* rank $O(\log n)$
* insertion/deletion $\Theta(n)$

Is there a data structure that allows better insertion and deletes? 

Balanced trees:
* operations like on sorted arrays
* but with fast (logarithmic) inserts and deletes

Basic version of node
* left child pointer
* right child pointer
* parent pointer

Search tree property: for a node with element $x$ 
* on the left - all elements are less than $x$
* on the right - all elements are greater than $x$


Height
* from $\approx \log_2 n$ to $\approx n$
* worst case - $\approx n$, like a chain
* to avoid the worst case we need trees that can rebalance themselves
** [[Red-Black Trees]]


== Operations ==
=== Search ===
Search($k$):
* start at the root
* if $k &lt; \text{key}$, go left
* if $k &gt; \text{key}$, go right
* return node with key $k$ or $\text{null}$


=== Insert ===
Insert($k$):
* search for $k$
* rewrite final $\text{null}$ pointer to point to new node with key $k$

worst-case running time $O(\text{height})$


=== Min (Max) ===
Min($k$)/Max($k$):
* start at root
* and follow left (right) child pointer


=== Pred ===
Pred should return next smallest element after given

Pred($k$):
* if $k$'s subtree is not empty, return the max key in the left subtree
* or follow parent pointer until you get a key less than $k$

=== In-Order Traversal ===
goal: to print out keys in increasing order

Traverse():
* recurse on the left tree
* print current node's key
* recurse on the right tree

running time $O(n)$


=== Deletion ===
Delete($k$):
* search for $k$
* if $k$ has no children
** just delete the node
* if $k$ has one child
** the child gets the pointer of $k$
* if $k$ has 2 children
** compute $k$'s predecessor $l$
*** traverse $k$'s non-NULL left child pointer
*** then right-child pointer
*** until no longer possible
** swap $k$ and $l$
** in a new position it's easy to delete $k$
*** it has no left child


=== Select ===
goal: to retrieve $i$th order statistics

Need to store additional information for that
* $\text{size}(x)$ - number of subtree nodes at subtree rooted at $x$
* $\text{size}(x) = \text{size}(l) + \text{size}(r) + 1$

Select($i$):
* start at root $x$ with left child $\text{lt}$ and right child $\text{rt}$
* $a = \text{size(lt)}$
* if $a = i - 1$
** return $x$'s key
* if $a \geqslant i$
** recursively compute $i$th order statistics on $\text{lt}$
* if $a \leqslant i - 1$
** recursively compute $(i - a - 1)$th order statistics on $r$

running time $\Theta(\text{height})$


=== Rank ===
Goal: to compute how many keys are less or equal to that value

Rank:
* $a$ = size(lt)
* return $a + 1$


== See also ==
* [[Heap]]
* [[Red-Black Trees]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]


[[Category:Algorithms]]
[[Category:Data Structures]]</text>
      <sha1>6ccjlene9x7dz8t1w0wt18dkdfyntdq</sha1>
    </revision>
  </page>
  <page>
    <title>Red-Black Trees</title>
    <ns>0</ns>
    <id>84</id>
    <revision>
      <id>85</id>
      <timestamp>2014-02-08T12:58:34Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="810">{{stub}}

== Red-Black trees ==
In [[Binary Search Trees]] the worst case running time depends on the height of a tree. How we can make sure the tree doesn't turn into a linked list - and is kept balanced? 

Idea
* the height is maintained at &lt;math&gt;O(\log n)&lt;/math&gt;
* therefore all operations are in &lt;math&gt;O(\log n)&lt;/math&gt;

== Red-Black invariants ==
* each node is red or black
* root is black
* not 2 reds in a row
** red node =&gt; only black children
* every path from the root to NULL-nodes passed the same amount of black nodes

== Operations ==
All the operations expect insert and delete are performed as usual in [[Binary Search Trees]]


== See also ==
* [[Binary Search Trees]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]


[[Category:Algorithms]]
[[Category:Data Structures]]</text>
      <sha1>dgc8jnvh8xnad0v3l9woz8us35xg2bh</sha1>
    </revision>
  </page>
  <page>
    <title>Hash Tables</title>
    <ns>0</ns>
    <id>85</id>
    <revision>
      <id>86</id>
      <timestamp>2013-12-11T18:14:21Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3758">== Hash tables ==
Purpose
* maintain a set of things with all operations in $O(1)$ time 
* $O(1)$ when data is not pathological
* need to use a [[Hash Function]] to do that


=== Operations ===
$O(1)$ operations:
* insert
* delete
* lookup


=== Details ===
* given: Universe $U$ - really really big
* goal: want to maintain set $S \subset U$

Solution:
* pick $n$ - number of buckets
* choose a [[Hash Function]] $h: U \mapsto \{0, 1, ..., n-1\}$
* use array $A$ of length $n$ to store $x$ in $A[h(x)]$


== Collisions ==
This approach leads to collisions ([[Birthday paradox]])

There are two ways to address collisions:
* Separate Chaining 
* Open Addressing


=== Separate Chaining ===
* keep a linked list in each bucket
* given a key $x$, perform insert/delete in the list in $A[h(x)]$
* $A[h(x)] $returns a list


=== Open Addressing ===
* hash function now specifies a succession $h_1(x), h_2(x), ...$
* keep trying until find an open slot


== Parameters ==
=== Number of buckets ===
* should be prime
* and not close to a power of 2 or 10

=== Load factor ===
* $\alpha$ = number of objects / number of buckets
* for good performance, need to control load


== Applications ==
=== De-duplication ===
* given: a &quot;stream&quot; of objects
* goal: ignore duplicates 

solution
* when a new object $x$ arrives
* look $x$ up in the hash table $H$
* if not found, insert $x$ into $H$


=== 2-sum problem ===
input
* unsorted array $A$ of $n$ integers
* target sum $t$

goal
* determine if there are two numbers $x, y \in A$
* such that $x + y = t$

solution
* insert elements of $A$ into hash table $H$ ($\Theta(n)$ time)
* for each $x \in A$ lookup $l - x$ ($\Theta(n)$ time)
 

=== Symbol tables in compilators ===
* historical application 
etc 



== Implementation ==
Simplest implementation in Java:

&lt;pre&gt;
public class HashTable {
    private final int buckets;
    private HashTableNode[] hashTable;

    public HashTable(int buckets) {
        this.buckets = buckets;
        this.hashTable = new HashTableNode[buckets];
    }

    public void add(int i) {
        if (!contains(i)) {
            int hash = h(i);
            HashTableNode oldNode = hashTable[hash];
            hashTable[hash] = new HashTableNode(oldNode, i);
        }
    }

    public void remove(int i) {
        if (!contains(i)) {
            return;
        }

        int hash = h(i);
        HashTableNode prevNode = hashTable[hash];

        if (prevNode.getValue() == i) {
            hashTable[hash] = prevNode.getNext();
            return;
        }

        HashTableNode node = prevNode.getNext();
        while (node != null) {
            if (node.getValue() == i) {
                prevNode.setNext(node.getNext());
                return;
            }

            prevNode = node;
            node = node.getNext();
        }
    }

    public boolean contains(int i) {
        HashTableNode node = hashTable[h(i)];
        while (node != null) {
            if (node.getValue() == i) {
                return true;
            }
            node = node.getNext();
        }
        return false;
    }

    private int h(int number) {
        return Math.abs(number) % buckets;
    }
}

public class HashTableNode {
    private int value;
    private HashTableNode next;

    public HashTableNode(HashTableNode next, int value) {
        this.next = next;
        this.value = value;
    }

    public int getValue() {
        return value;
    }

    public HashTableNode getNext() {
        return next;
    }

    public void setNext(HashTableNode next) {
        this.next = next;
    }
}
&lt;/pre&gt;


== See also ==
* [[Bloom Filters]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]


[[Category:Algorithms]]
[[Category:Data Structures]]</text>
      <sha1>g94z11t0ng464w9ymly4g0p62a3wyas</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Data Structures</title>
    <ns>14</ns>
    <id>86</id>
    <revision>
      <id>87</id>
      <timestamp>2013-08-01T07:30:47Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23">[[Category:Algorithms]]</text>
      <sha1>r76apkj24r65uprb4tc339y8073prph</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Graphs</title>
    <ns>14</ns>
    <id>87</id>
    <revision>
      <id>88</id>
      <timestamp>2013-08-01T07:31:37Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23">[[Category:Algorithms]]</text>
      <sha1>r76apkj24r65uprb4tc339y8073prph</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Java</title>
    <ns>14</ns>
    <id>88</id>
    <revision>
      <id>89</id>
      <timestamp>2013-08-01T07:33:16Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24">[[Category:Programming]]</text>
      <sha1>kf5psdimgr1sx9e80utmmehom1l3auk</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Algorithms</title>
    <ns>14</ns>
    <id>89</id>
    <revision>
      <id>90</id>
      <timestamp>2013-08-01T07:34:23Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24">[[Category:Programming]]</text>
      <sha1>kf5psdimgr1sx9e80utmmehom1l3auk</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Functional Programming</title>
    <ns>14</ns>
    <id>90</id>
    <revision>
      <id>91</id>
      <timestamp>2013-08-01T07:35:20Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24">[[Category:Programming]]</text>
      <sha1>kf5psdimgr1sx9e80utmmehom1l3auk</sha1>
    </revision>
  </page>
  <page>
    <title>Bloom Filters</title>
    <ns>0</ns>
    <id>91</id>
    <revision>
      <id>92</id>
      <timestamp>2013-08-01T09:55:49Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1017">== Bloom filters ==
Goal: fast inserts and lookups

Compared to [[Hash Tables]]
* pros
** more space efficient
* cons
** can't store associated object
** no deletions
** small false positive probability


== Applications ==
* early spell-checkers (original)
* list of forbidden passwords
* network routers
** limited memory
** need to be super-fast


== Implementation ==
Inside contains 
* array of $n$ bits
** $\frac{n}{|S|}$ - number of bits per object
** in data set $S$
* $h$ - hash function $h_1..h_k$
** $k$ - a small constant


== Operations ==
Insert($x$):
* for $i = 1..k$
* set $A[h_i(x)] = 1$

Lookup($x$)
* True if $A[h_i(x)] = 1$ for every $i = 1..k$


== False positives ==
if $x$ was inserted
* no false negatives - guaranteed to succeed

if $x$ wasn't inserted, false positives if
* all $k$ $h_i(x)$ are already set to 1 by other insertions


== See also ==
* [[Hash Tables]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]


[[Category:Algorithms]]
[[Category:Data Structures]]</text>
      <sha1>eo7jdl6rwcl8iko15uja63xoujhxk3d</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Cominatorics</title>
    <ns>14</ns>
    <id>92</id>
    <revision>
      <id>93</id>
      <timestamp>2013-08-01T07:44:49Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24">[[Category:Mathematics]]</text>
      <sha1>b9vk507szcbw6tn1xarrdf31jl1qtsn</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Java 8</title>
    <ns>14</ns>
    <id>93</id>
    <revision>
      <id>94</id>
      <timestamp>2013-08-01T07:51:21Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17">[[Category:Java]]</text>
      <sha1>9igx8un2j0lurpeyj8zj5vrkwfu22yr</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Sorting</title>
    <ns>14</ns>
    <id>94</id>
    <revision>
      <id>95</id>
      <timestamp>2013-08-01T09:53:17Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23">[[Category:Algorithms]]</text>
      <sha1>r76apkj24r65uprb4tc339y8073prph</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Spring</title>
    <ns>14</ns>
    <id>95</id>
    <revision>
      <id>96</id>
      <timestamp>2013-08-01T10:01:02Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17">[[Category:Java]]</text>
      <sha1>9igx8un2j0lurpeyj8zj5vrkwfu22yr</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Interviews</title>
    <ns>14</ns>
    <id>96</id>
    <revision>
      <id>97</id>
      <timestamp>2013-08-01T10:03:25Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27">See [[Interview questions]]</text>
      <sha1>lfdjqoe3p44k367m2i6b3eqrgv8ekyw</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Scripts</title>
    <ns>14</ns>
    <id>97</id>
    <revision>
      <id>98</id>
      <timestamp>2013-08-02T08:07:02Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24">[[Category:Programming]]</text>
      <sha1>kf5psdimgr1sx9e80utmmehom1l3auk</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Groovy</title>
    <ns>14</ns>
    <id>98</id>
    <revision>
      <id>99</id>
      <timestamp>2013-08-02T08:08:50Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24">[[Category:Programming]]</text>
      <sha1>kf5psdimgr1sx9e80utmmehom1l3auk</sha1>
    </revision>
  </page>
  <page>
    <title>Statistics: Making Sense of Data (coursera)</title>
    <ns>0</ns>
    <id>99</id>
    <revision>
      <id>100</id>
      <timestamp>2015-04-19T10:58:26Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1914">These are notes of an introductory course to [[Statistics]]
* https://www.coursera.org/account/records
* taken in spring 2013


== [[Statistics]] ==
''Statistics'' - the science of collecting, organizing, summarizing, analyzing and interpreting data

== Course Syllabus ==
=== First Look at Data (Weeks 1-2) === 
* [[Summary Statistics]]
* [[Distributions|The Shape of Data]]
* [[Types of Variables]] 
** [[Types of Variables#Quantitative Variables|Quantitative Variables]]
** [[Types of Variables#Relationships|Relationship Between Two Variables]]

=== [[Data Collection|Collecting Data]] (Week 2) ===
* [[Sampling]]
* [[Observational Studies]] and [[Experiments]]
** [[Confounding Variables]]

=== Probability (Week 3) ===
* [[Probability|Probability models]]
* [[Normal Distribution]]
* [[Weak Law of Large Numbers]] 
* [[Central Limit Theorem]]
* [[Sampling Distribution]]

=== [[Confidence Intervals]] (Week 4) ===
* [[Binomial Proportion Confidence Intervals|Confidence Intervals for Proportions]]
* [[Confidence Intervals for Means]]
* [[Sample Size Estimation]]

=== [[Hypothesis Testing|Statistical Tests]] (Week 5) ===
* [[Hypothesis Testing#Structure of Statistical Test|Structure of Statistical Test]]
* [[Binomial Proportion Tests#One-Sample Binomial Proportion Test|Tests For Proportions]]
* [[t-tests#One-Sample t-test|Tests For Means]]
* [[Statistical Power|The Power of a Test]]

=== [[Comparing Two Samples|Two Samples]] (Week 6) ===
* [[Binomial Proportion Tests#Two-Sample Binomial Proportion Test|Comparing Two Proportions]]
* [[t-tests#Paired t-test|Matched Pairs]]
* [[t-tests#Two Sample t-test|Comparing Two Means]]

=== [[Linear Regression|Simple Linear Regression]] (Week 7) ===
* [[Method of Least Squares]]
* [[Residual Analysis]]
* [[Linear Regression#Limitations|Limitations]]

=== Statistical Inquiry (Week 8) ===
* Capstone case study


[[Category:Statistics]]
[[Category:Coursera]]</text>
      <sha1>106goptl7mgs7izqygwdq5r6t18f7bz</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Discrete Mathematics</title>
    <ns>14</ns>
    <id>100</id>
    <revision>
      <id>101</id>
      <timestamp>2013-08-02T09:16:17Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24">[[Category:Mathematics]]</text>
      <sha1>b9vk507szcbw6tn1xarrdf31jl1qtsn</sha1>
    </revision>
  </page>
  <page>
    <title>Summary Statistics</title>
    <ns>0</ns>
    <id>101</id>
    <revision>
      <id>102</id>
      <timestamp>2014-05-10T18:31:11Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1591">== Five Number Summary ==
Consists of 
* ''Minimum'': the lowest point
* ''First quartile'': the ¼ point in data
* ''Median'': the center of data
* ''Third quartile'': the ¾ point in dat.
* ''Maximum'': the largest point


If a sample has even length, then the median is average of the two middle points:
* $\text{median} = \cfrac{a_{n/2} + a_{n/2 + 1}}{2}$


Same applies to 1st and 3rd quartiles 

In [[R]], command &lt;code&gt;summary&lt;/code&gt; returns the 5 number summary as well as the mean


== Visualization ==
=== [[Box Plot]] ===
A visual summary of all the 5 numbers is called a ''box plot''
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/boxplot.png

''Modified box plot''
* is a variation of the box plot
* it's used to explain data with unusual values - [[Outliers]]
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/boxplot-modified.png


== Measures of the Center ==
* Median is a measure of the center. 
* But there is another measure - [[Mean]] or average value
: $\text{mean} = \cfrac{1}{n} \sum x_i$
: Where $n$ - number of data values, and $x_i$ - each data value.


== The Spread ==
Mean and median don't show how spread the data is. There is another measure that address it: [[Variance]].
* $\text{var}(x) = \cfrac{1}{n - 1} \sum (x_i - \bar{x})^2$
* $s(x) = \text{std}(x) = \sqrt{\text{var}(x)}$
* ($n - 1$ gives &quot;unbiased&quot; estimate of the variance {{ TODO | add link}})

in R: 
&lt;pre&gt;
st.dev = sd(data)
&lt;/pre&gt;


== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]

[[Category:Statistics]]
[[Category:R]]</text>
      <sha1>4gighl4uiry7whjpr7tyhwvrcs4ks3v</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Probability Distributions</title>
    <ns>14</ns>
    <id>102</id>
    <revision>
      <id>103</id>
      <timestamp>2013-08-02T09:47:26Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24">[[Category:Probability]]</text>
      <sha1>evgda9svto3j5t4nendkuvs795wpu3w</sha1>
    </revision>
  </page>
  <page>
    <title>Distributions</title>
    <ns>0</ns>
    <id>103</id>
    <revision>
      <id>104</id>
      <timestamp>2014-07-28T18:41:33Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2015">== The Shape of Data ==
''Distribution'' - the pattern of values in the data, showing their frequency of occurrence relative to each other. 


== [[Plots]] ==
There are some plots that can be useful for showing the distribution of data

=== [[Histogram]]s ===
''Histogram'' is useful to show distribution of data
* Bins: the intervals used in a histogram. The data must be separated into mutually exclusive and exhaustive bins
* Cutpoints: the values that define the beginning and the end of the bins
* Frequency: the count of the number of the data values in each bin
* The peaks in the distribution are called ''modes''

We can group distributions according to the number of modes they have:
* ''unimodal'' - a distribution with one mode
* ''bimodal'' - with 2 peaks
* ''multimodal'' - more than 2 peaks

In R:
&lt;pre&gt;
hist(..., breaks=10, ...) // histogram
&lt;/pre&gt;


=== [[Density Plot]]s ===
Like a histogram, but smoothed

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/density-hist.png

== Types ==
There are many distributions:
* [[Uniform Distribution]] - equally spread without any mode
* symmetric
** the mean, median, and mode are all approximately the same.
** https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/dist-symmetric.png
* assymetric
** https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/dist-asymetric.png
* left-skewed
** the longer tail on the left side
** the mode is larger than the median which is larger than the mean
* right-skewed
** the longer tail on the right side
** the mode is less than the median which is less the mean
** https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/dist-left-right.png
* with gap
** https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/dist-gap.png


== See Also ==
* [[:Category:Distributions]]

== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]


[[Category:Statistics]]
[[Category:R]]
[[Category:Distributions]]</text>
      <sha1>k7xuu9exdb2r1589hh550trkmz8f29d</sha1>
    </revision>
  </page>
  <page>
    <title>Types of Variables</title>
    <ns>0</ns>
    <id>104</id>
    <revision>
      <id>105</id>
      <timestamp>2014-07-15T16:30:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2114">== Types of Variables ==
When we have a table with data, rows correspond to ''observation units'' (subjects, etc.) and columns are ''variables''. 
* NB: Don't confuse with [[Random Variable]]s from Probability Theory


There are several types of variables: 
* [[Categorical Variables]] - values that can be organized into categories (not numerical)
* [[Quantitative Variables]] -  with numerical values for which arithmetic operation make sense
* ''Ordinal Variables'' - with natural order


=== Problems with Variables ===
Also we may have
* [[Outliers]] - too large or too small values, sometimes they are errors, we have to find explanation for them
** use [[Anomaly Detection]] techniques to detect outliers
* ''Missing values'' - not present values, can bias the result
** need [[Handling Missing Values]] to avoid that 
* Noise - modification of the original value
** Looks like normal input, but it's faulty
** Very hard to detect 


== Relationships ==
Types of variables in the analysis: 
* outcome - the variables of our interest
* explanatory - the variables that are used to analyze and explain the outcome


=== Types of Relationships ===
The relationships between the explanatory variable and the outcome
* ''independent'': there is no association between the variables
* ''association'': the variables are dependent, but it's not clear what kind of relationship there is
** ''causes'': changes in the explanatory variables case the outcome to change 
** ''reverse causation'': changes in outcome cause the explanatory variable to change
** ''coincidence'': just pure chance
** ''common cause'': some other variable causes both the explanatory variables and the outcome to change - see [[Lurking Variables]] and [[Confounding Variables]]


=== Multivariate Analysis ===
To analyze relationships between variables there are following methods:
* [[Bivariate Analysis]]
* e.g. [[Correlation]], [[Regression Analysis]], [[ANOVA]], [[Statistical Test of Independence]]
* and many others 


== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]

[[Category:Statistics]]
[[Category:Data Analysis]]</text>
      <sha1>f7671chfdlas67mtiaqxnbj94g60qem</sha1>
    </revision>
  </page>
  <page>
    <title>Sampling</title>
    <ns>0</ns>
    <id>105</id>
    <revision>
      <id>106</id>
      <timestamp>2014-07-15T16:11:18Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4369">== Sampling ==
''Statistical Inference'' - making conclusions and decisions incomplete information in based on data. This is the main goal of [[Statistics]]
* ''Population'' - the group we're interested in making conclusions about.
* ''Census'' - collection of data from the entire population
** Census is almost impossible or very expensive to obtain
* ''Sample'' - a subset of the population, typically a small fraction


=== Goals ===
So, the goal of sampling (data collection): 
* based on a sample make conclusions about the population 
* this is done at the [[Data Collection]] step in the process of statistical investigation (see [[Statistics]])

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/sample-conclusion.png


For [[Machine Learning|ML]] models there are other goals
* how to reduce data to speed up computation? 
* select a subset of rows - a ''sample''



== Types of Sampling ==
We need a ''representative'' sample to be able to generalize from the statistics calculated on a sample to the population parameters
* For that we need to use randomization - and have [[#Random Sampling]]
* otherwise can have [[#Non-Random Sampling]]


== Random Sampling ==
Random sampling (especially SRS - simple random sampling) is very important 
* in [[Inferential Statistics]] - when making the independence assumption about the observations
* doesn't introduce bias


=== Replacements ===
* '''without replacement'''
** when item is selected for a sampling, it's taken out of the population
* sampling '''with replacement''' 
** an item can be sampled several times
** used in the [[Bootstrap]] method - for resampling
* also see [[Simulation Basics in R#Sampling]]


=== Simple Random Sampling ===
Randomly pick up items from the population
* the original [[distribution]] of data is not always kept


=== Stratified Sampling ===
Stratified Sampling 
* divide the population into non-overlapping groups (called ''strata'') 
* and use SRS within each stratum
* so the original distribution is kept

Also called 
* Sampling with proportional allocation
* Under-sampling of the majority class
* etc


=== Cluster Sampling ===
Cluster Sampling
* use [[Cluster Analysis]] to divide the population into clusters
* select a cluster at random and use all the items from that cluster
* Use then it's easer to select a group than an item


=== Examples ===
==== Example 1 ====
* 1 mln elements 
* 5% True, 95% False 
* want to sample 100 examples
* proportional (stratified): 5 True, 95 False
* without proportional (uniform): 50 True, 50 False

Reason to use proportional
* suppose you need to be good at detecting TRUE 
* but you'll have only 5 records to train your classified - not enough!
* so it's better to use stratified sampling


==== Stratified Sampling Example ====
Assume a company with the following allocation of staff 

{| class=&quot;wikitable&quot;
! || Full Time || Part Time
|-
! Male  
| 90 || 18
|-
! Female 
| 9 || 63
|}


How to build a sample of 40 staff? 
* Stratified with proportional allocation: according to the distribution
* total number: $N = 180$
* calculate the percentage in each group

{| class=&quot;wikitable&quot;
! || Full Time || Part Time
|-
! Male  
| 90 / 180 = 50%  || 18 / 180 = 10% 
|-
! Female 
| 9 / 180 = 5%  || 63 / 180 = 35% 
|}


So we know that 
* 50% in out sample of 40 should be males, full time

{| class=&quot;wikitable&quot;
! || Full Time || Part Time
|-
! Male  
| 20  || 4
|-
! Female 
| 2  || 14
|}



== Non-Random Sampling ==
* Systematic sampling
** every $n$th individual, non-representative is there's a structure
* Convenience / Volunteer sampling
** select first $n$ who are available or volunteer to participate. Also non-representative
* all these may introduce bias into the samples


== [[Bias]] ==
* A sample is biased if it's differs from a population in a systematic way
* That can result in a statistics that's consistently larger or smaller

=== Types of Biases === 
* Selection bias - when you systematically exclude or under-represent a part of population
* Measurement/Response bias - when data is collected with systematic error 
* Non-response bias - when responses aren't obtained from all individuals selected for inclusion in sampling


== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[Data Mining (UFRT)]]
* [[OpenIntro Statistics (book)]]

[[Category:Statistics]]</text>
      <sha1>mp5krezoyu7b4ifje6timdtd34g9d2e</sha1>
    </revision>
  </page>
  <page>
    <title>Variables in Observations</title>
    <ns>0</ns>
    <id>106</id>
    <revision>
      <id>107</id>
      <timestamp>2013-08-05T12:39:22Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2607">== Variables in Observations ==
A paradigm for Observation Studies
* 2 or more group
* response variables (''outcome'') to be compared between the groups
* ''an explanatory variable'' is an variable that can be used to explain the differences in the response 
* And we want to avoid ''confounding variables'' - variables that may affect the response variable


== Relationships ==
The relationships between the explanatory variable and the outcome
* ''causes'': changes in the explanatory variables case the outcome to change 
* ''reverse causation'': changes in outcome cause the explanatory variable to change
* ''coincidence'': just pure chance
* ''common cause'': some other variable causes both the explanatory variables and the outcome to change
* a ''confounding variable'' is associated with the explanatory variable and causes the outcome to change
: it's impossible to know whether to attribute changes in the outcome to changes in the explanatory variable or in the confounding variable


Confounding variables:
:&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/experiment-confounders.png&quot; /&gt;


=== Lurking variables ===
''Lurking variables'' are variables that are not considered in the analysis, but may affect the nature of the relationship between the explanatory variable and the outcome

E.g. smokers are less likely to die after 75+ years. This is not true when we consider it within age groups.

A lurking variable can be 
* a confounding variable, 
* or the source of the common response, 
* or another variable that, when considered, changes the nature of the association 


== Variables in Experiments ==
* ''Response variable'' (or ''dependent variable'') - the outcome of interest, measured on each subject or entry participating in the study
* ''Explanatory variable'' (or ''predictor'', or ''independent variable'') - a variable that we think may help to explain the value of the response variable.


* ''Experiment'' - when a researcher manipulates the explanatory variable to see the effect on the response. 


== Factors ==
* A categorical explanatory variable in an experiment is a ''factor''
* The values of a factor are its ''levels'' 
* A particular combination of values for the factors is called a ''treatment''

Example: 
* factor 1: $A$, $B$
* factor 2: $X$, $Y$
* 4 treatments: $A X$, $A Y$, $B X$, $X Y$

''Experimental unit'' - the smallest using to which a treatment is applied, and a ''block'' - is a group of similar experimental units


== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]


[[Category:Statistics]]</text>
      <sha1>9j00xd1samszlrrqd3ec28onc62ux96</sha1>
    </revision>
  </page>
  <page>
    <title>Observational Studies</title>
    <ns>0</ns>
    <id>107</id>
    <revision>
      <id>108</id>
      <timestamp>2014-07-28T08:14:45Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2484">== Observation Studies ==
There are two types of [[Data Collection]]
* Observation Studies and [[Statistical Experiment]]s

In ''Observation Studies'' we observe existing characteristics of a subset of individuals in a population
* typically done via surveys, by following smb, etc
* this method doesn't directly interfere with how the data appear (in contrast to [[Statistical Experiment]]s)


the goal is to
* draw conclusions about the population or 
* find differences between 2 or more groups or
* find out about the relationships between variables


=== Types ===
* Prospective Study 
** collect the data as an event unfolds
* Retrospective Study
** use the data of some event that already took place 


== Finding Relationships ==
Types of variables: 
* outcome - the variables of our interest
* explanatory - the variables that are used to analyze and explain the outcome


=== Types of Relationships ===
The relationships between the explanatory variable and the outcome
* ''independent'': there is no association between the variables
* ''association'': the variables are dependent, but it's not clear what kind of relationship there is
** ''causes'': changes in the explanatory variables case the outcome to change 
** ''reverse causation'': changes in outcome cause the explanatory variable to change
** ''coincidence'': just pure chance
** ''common cause'': some other variable causes both the explanatory variables and the outcome to change (see also [[Confounding Variables]])


=== Correlation and Causation ===
* with this type of studies it is possible to find association relationship between the variables
* but it's not possible to show the causation here - need to run a controlled [[Statistical Experiment]] for that 
* beware of [[Confounding Variables]]


Example
* Suppose we run a sunscreen study and collected some data
* We saw that the more sunscreen is used, the more chances to have skin cancer 
* does sunscreen causes the cancer? 
* cannot say it here because the study is observational - we didn't run a controlled [[Statistical Experiment]] to make sure there are no other variables that might have caused it
* e.g. in this case  we don't see the exposure to sun - it's correlated with both sunscreen and cancer variables
** this is a [[Confounding Variables|Confounding Variable]] that is likely to have caused the effect



== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[OpenIntro Statistics (book)]]

[[Category:Statistics]]</text>
      <sha1>to9m3o0zofnl2r78jfxyf4a7ogw74yi</sha1>
    </revision>
  </page>
  <page>
    <title>Statistical Experiment</title>
    <ns>0</ns>
    <id>108</id>
    <revision>
      <id>109</id>
      <timestamp>2014-07-15T17:13:23Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3458">== Statistical Experiments ==
There are two types of [[Data Collection]]
* [[Observation Studies]] and Statistical Experiments


=== Variables in Experiments ===
* ''Response variable'' (or ''dependent variable'') - the outcome of interest, measured on each subject or entry participating in the study
* ''Explanatory variable'' (or ''predictor'', or ''independent variable'') - a variable that we think may help to explain the value of the response variable.


=== Experiment ===
* ''Experiment'' - when a researcher manipulates the explanatory variable to see the effect on the response. 
* So they ''create'' the data


=== Correlation and Causation ===
* with this type of studies it is possible to show the causal relationship between the variables


Example
* Suppose we run a sunscreen study and collected some data
* We saw that the more sunscreen is used, the more chances to have skin cancer 
* does sunscreen causes the cancer? 
* cannot say it here because the study is [[Observational Studies|observational]]
* e.g. in this case  we don't see the exposure to sun - it's correlated with both sunscreen and cancer variables
** this is a [[Confounding Variables|Confounding Variable]] that is likely to have caused the effect
* but if we do a randomized experiment, we can see if there's any causal relationship 



== Randomized Experiments ==
Randomized Experiments
* individuals are assigned to groups
* researches assigns treatments to the groups
* typically assignment is done at random - which is why it's called &quot;Randomized Experiments&quot;


=== Principles of Experimental Design ===
* Controlling
* Randomization 
* Replication
* Blocking


=== Controlling ===
* We want to see if there's any causal relationship between the variables
* so do the best to control any other difference in the group
** to make sure there's nothing else that might interfere with the experiment (no [[Confounding Variables]])
** e.g. the exposure to sun in the previous example

Example
* specify that a pill must be taken with exactly 200ml glass of water 
* not with a sip or 1 liter 


=== Randomization ===
* Assign cases to treatment groups at random 
* This way accounting for variation that cannot be controlled by the researcher 
* it keeps uncontrolled differences even and prevents from adding accidental [[Bias]]


=== Replication ===
* Make sure the experiment may be run again and the findings can be replicated


=== Blocking ===
* Researchers sometimes may suspect that some variables (not only treatment) may influence the response
* in such a case, group individuals into blocks and then randomize within the blocks
* this way ensuring that there's equal number of patients within each group 

Example
* first divide patients into low-risk, mid-risk and high-risk groups
* then randomize within each risk group 


== Reducing [[Bias]] ==
To reduce the bias in the human experiments, split the patients into two groups: 
* treatment group - receives the medicine
* control group - receive placebo


=== Double-Blind Setup ===
* but if a doctor knows that this patient is going to receive a placebo, it may impose some emotional effect on the doctors - it's difficult to quantify 
* which is why both patients and the doctors are kept uninformed of what type of medicine they receive 
* it's called a ''double-blind setup''


== Sources ==
* [[OpenIntro Statistics (book)]]
* [[Statistics: Making Sense of Data (coursera)]]

[[Category:Statistics]]</text>
      <sha1>7yxud9cmx41s7v5bq4m2v0y85i9jafr</sha1>
    </revision>
  </page>
  <page>
    <title>Sampling Distribution</title>
    <ns>0</ns>
    <id>109</id>
    <revision>
      <id>110</id>
      <timestamp>2013-08-07T08:41:43Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3162">== Estimation ==
Our goal is to be able to estimate theoretical parameters with a data sample. 

Example:
* we want to estimate the probability of getting heads in coin flipping [[Experiments|experiment]]
* flip a coin 10 times, 
* count number of heads 

Experiment:
* Our parameter of interest is $p = p(\text{heads})$
* Data: result of 10 coin flips
* $\hat{p}$ - estimate of $p$
: $\hat{p} = \cfrac{\text{# of heads}}{\text{total # of flips}}$
: i.e. $\hat{p}$ is calculated from data


== Sampling Distribution ==
* if we repeat over and over again, each time we will probably have different estimates of $\hat{p}$
* so there is a ''variability'' in the estimate
* this is called ''sampling variability'', and it occurs because of the randomness in our data


The probability distribution of all the possible values of an estimator is it's ''sampling distribution''.


=== Unbiased estimation ===
In our coin flipping example
* a flip follows the [[Bernoulli Distribution]] with $p = 1/2$
: $X \sim \text{Bernoulli}(0.5)$
* and $E(X) = 0.5$


For the entire experiment:
* 10 coin flips = 10 Bernoulli experiments with outcomes $X_1, ..., X_{10}$
* so, $\hat{p} = \cfrac{X_1 + ... + X_{10}}{10} = \bar{X}$
* thus, $E(\hat{p}) = p$ since $E(X_i) = p$ and $E(\bar{X}) = \cfrac{10 p}{10}  = p$
* and $\hat{p}$ is called ''unbiased estimator''


A statistic used to estimate a parameter is ''unbiased'' if the expected value of its sampling distribution is equal to the value of the parameter being estimated


=== Variance estimation ===
* For one observation $X \sim \text{Bernoulli}(p)$, variance $\text{Var}(X)$ is:
: $\text{Var}(X) = \sum_{x} (x - E(X))^2 p(X) = (1 - p)^2 p + (0 - p)^2 (1 - p) = p - p^2 = p(1 - p)$
* For $n$ observations $X_1, ..., X_{n}$ with $\hat{p} = E(X)$
: since $\text{Var}(\bar{X}) = \cfrac{\sum X_i}{n}$,
: $\text{Var}(\hat{p}) = \cfrac{p(1 - p)}{n}$ and $\text{sd}(\hat{p}) = \sqrt{\cfrac{p(1-p)}{n}}$,
So we get more and more precise answers over time 


And by the [[Central Limit Theorem]], for large $n$ the sampling distribution is approximately 

$N\left(p, \cfrac{p(1-p)}{n}\right)$


== Theoretical World Model ==
In the [[Normal Distribution]] we have  $N(\mu, \sigma^2)$, and we're interested in $\mu$
* Say we have $n$ data values $X_1, ..., X_n$ from independent observations 
* Estimator of $\mu$ is $\bar{X} = \cfrac{X_1 + ... + X_n}{n}$
* So $E(\bar{X}) = \mu$, and $\bar{X}$ - unbiased estimator of $\mu$
* Variance of $\bar{X}$ is $\text{Var}(\bar{X}) = \cfrac{\sigma^2}{n}$ and $\text{sd}(\bar{X}) = \cfrac{\sigma}{\sqrt{n}}$
* And by the [[Центральная предельная теорема|Central Limit Theorem]] we have $\bar{X} \sim N(\mu, \cfrac{\sigma^2}{n})$


So, 
* distribution of $\hat{p} \sim N\left(p, \cfrac{p(1-p)}{n}\right)$
* distribution of $\bar{X} \sim N\left(\mu, \cfrac{\sigma^2}{n}\right)$


For data, unbiased variance is 
* $\text{Var}(X) = \cfrac{1}{n-1} \sum (X_i - \bar{X})^2$ (unbiased)
* not $\text{Var}(X) = \cfrac{1}{n} \sum (X_i - \bar{X})^2$ (biased)


== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]


[[Category:Statistics]]
[[Category:Probability]]</text>
      <sha1>1u63f2u2558db6gxrihgkb97dreswyt</sha1>
    </revision>
  </page>
  <page>
    <title>Confidence Intervals</title>
    <ns>0</ns>
    <id>110</id>
    <revision>
      <id>111</id>
      <timestamp>2014-08-06T20:00:07Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5060">== Confidence Intervals ==
In [[Inferential Statistics]] we estimate a parameter of the population based on sample
* [[Point Estimate]] is just one single plausible value
* it's a good idea to expand it a bit and build a confidence interval around the point estimate
* and use [[Standard Error]] as a measure of uncertainty in the Point Estimate to find this interval


Main idea - the CI should include the real parameter 


=== Confidence Level ===
The degree of confidence at which we're sure the interval will span the true parameter is ''Confidence level''
* e.g. 95% confidence interval contains the estimated parameter with probability 0.95 - i.e. in 1 case out of 20 it will miss the real parameter


The idea of [[Sampling Distribution]] is important here
* we use it to calculate percentiles of the possible values, if the SD was centered at our point estimate
* so the SI should span the true value


Example
* we want to estimate the mean
* suppose we happen to know the sampling distribution: it's $N(\mu = 10, \sigma = 3.3)$
** it's centered around the proportion mean $\mu$
** and the [[Standard Error]] is 3.3
* we draw a Point Estimate from the sampling distribution
** we get $\bar{X} = 5.5$
* Assuming that the SD is centered around 5.5, we compute 95% CI
** $z$-value is 1.96, so the interval is (-0.97 11.97)
* it includes the true value $\mu=10$


http://habrastorage.org/files/a76/ac7/b68/a76ac7b689e64323af65a6d4d0df5f9c.png

{{ Hider |
   title=R code |
   content=
&lt;pre&gt;
x = seq(-10, 25, 0.3)
m = 10
se = 3.3

plot(x, dnorm(x, mean=m, sd=se), type='l', bty='n', lty=2, ylab='')
abline(v=m, lty=2)

m.observed = 5.5
abline(v=m.observed, col='red')
dy = dnorm(x, mean=5.5, sd=se)
lines(x, y=dy, col='red')

lo = m.observed - 1.96 * se
hi = m.observed + 1.96 * se
c(lo, hi)

x1 = min(which(x &gt;= lo)); x2 = max(which(x &lt;= hi)) 

polygon(x[c(x1, x1:x2, x2)],
        c(0, dy[x1:x2], 0), col=adjustcolor('red', 0.4), border=NA)

par(xpd=NA)

text(m, 0.13, m)
text(m.observed, 0.13, m.observed)

arrows(x0=lo, y0=0.02, x1=hi, y1=0.02, code=3, length=0.15)
text(m.observed, 0.02-0.005, 'confidence interval', cex=0.7)

par(xpd=FALSE)
&lt;/pre&gt;
}} 


A confidence interval consists of two parts
* left part - ''lower bound''
* right part - ''upper bound ''


&quot;95% confident&quot; means that if we took many many samples from the SD and build a CI from each, then about 95% of these CIs should contain the actual parameter being estimated (e.g. $p$ for binom, $\mu$ for mean)


http://habrastorage.org/files/2ab/3aa/77c/2ab3aa77ce294aa691b07d98778052f1.png

So we see indeed that sometimes the CI doesn't include the true value
but we're 95% confident that a CI calculated from one sample will include it 



{{ Hider |
   title=R code to produce the figure |
   content=
&lt;pre&gt;
load(url('http://s3.amazonaws.com/assets.datacamp.com/course/dasi/ames.RData'))
population = ames$Gr.Liv.Area

set.seed(1237)
n = 50
sampl = replicate(51, sample(population, n))
sampl.sd = apply(sampl, MARGIN=2, sd)
sampl.m  = apply(sampl, MARGIN=2, mean)

me = 1.96 * sampl.sd / sqrt(n)

plot_ci(sampl.m - me, sampl.m + me, mean(population))
&lt;/pre&gt;
}}


=== Margin Of Error ===
If the [[Sampling Distribution]] is symmetric (e.g. [[Normal Distribution]] or [[t-Distribution]]) we can calculate the CI bounds by adding and subtracting the ''margin of error'' 
* '''margin of error''' is typically percentile ($z$ or $t$ score) multiplied by [[Standard Error]]


=== Critical Value ===
Critical Value shows the level of confidence in our interval
* for $\alpha = 0.025$ CI is 90%


=== Types ===
Main types:
* [[Binomial Proportion Confidence Intervals]]
* [[Confidence Intervals for Means]]


=== [[Statistical Simulation]] ===
Not always it's possible to calculate everything with traditional methods 
* but when we know the truth and can control it, we can simulate and build the [[Sampling Distribution]], this way getting the CIs
* also, [[Bootstrapping]] (a [[Resampling]] method) is a powerful strategy for calculating CIs 



== Extra Stuff ==
=== Robustness ===
A method  for constructing CIs is ''robust'' if
* the resulting CIs include the theoretical parameter approximately the percentage claimed by the confidence level
* even if not all necessary conditions for the CIs are satisfied

[[t-distribution|$t$-distribution]] is very robust and works well for the [[Normal Distribution]] as well as for skewed distributions


=== Relationship with [[Statistical Tests of Significance|Hypothesis Testing]] ===
{{Main | Confidence Intervals and Statistical Tests}}


=== Additional Resources ===
* [http://www.rossmanchance.com/applets/NewConfsim/Confsim.html applet] for simulating CIs 
* [http://www.utstat.utoronto.ca/alisong/moocapplets/ci_creation_applet another applet]


== See Also ==
* [[Sampling Distribution]]
* [[Inferential Statistics]]
* [[Hypothesis Testing]]

== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[OpenIntro Statistics (book)]]
* https://en.wikipedia.org/wiki/Confidence_interval



[[Category:Statistics]]
[[Category:R]]</text>
      <sha1>21sk4tvmzx7m9le3tppy7yscmbh7020</sha1>
    </revision>
  </page>
  <page>
    <title>Hypothesis Testing</title>
    <ns>0</ns>
    <id>111</id>
    <revision>
      <id>112</id>
      <timestamp>2014-07-28T18:53:55Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10456">== Hypothesis Testing ==
''Hypothesis Testing'' is a framework of testing some assumptions in [[Inferential Statistics]]
* a result is ''statistically significant'' if it's very unlikely to have happened due to chance alone 


=== Motivation ===
Suppose we have 2 groups and we observe the difference between them

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/tests-diff.png&quot; /&gt;

Question: 
* Is this difference significant?
* Could the difference be due to natural variability of the [[Sampling Distribution]]?
* Or we have something stronger?


''Statistical tests'' (often as well called &quot;Hypothesis tests&quot; or &quot;Tests of Significance&quot;) answer these questions.


== Structure of Statistical Test ==
=== Summary ===
# Determine the $H_0$ and $H_A$
# Collect data and calculate a ''test statistic''
# Calculate the $p$-value
# Make a conclusion based on it and on the context


=== Step 1: Null and Alternative Hypotheses ===
* Formulate a hypothesis what you want to test and specify its alternative

Court case analogy: Innocent until proven guilty 
* &quot;Innocent&quot; part
** null-Hypothesis $H_0$ (read as &quot;H-naught&quot;)
** it's a skeptical position or position of no difference
** example: no relationships, no difference, etc
** we assume it's true
* &quot;Guilty&quot; part:
** alternative hypothesis $H_A$ (or $H_a$ or $H_1$)
** it's a new perspective
** this is what a researcher wants to establish 
** example: relationship, change, difference

And we question we ask is do we have enough evidence to rule out any difference from the $H_0$ that are just due to chance?

Like in a court, we conclude that $H_A$ is true if we have evidence against $H_0$.


Alternatives could be 
* one-sided (greater than or less than)
* two-sided (not equal)


So the first step is
* '''clearly specify the null and alternative hypotheses'''


=== Step 2: Evidence  - Test Statistics ===
* ''The evidence'' is provided by our data
* We need to summarize the data into a ''test statistics'': a numerical summary of the data. 

A test statistic is made under assumption that $H_0$ is true


So the 2nd step is 
* '''Collect the data and calculate a test statistic assuming $H_0$ is true'''


=== Step 3: $P$-value ===
* Is the evidence (the test statistics) good enough to reject the $H_0$? 


''$p$-value'' 
* helps us to answer this question: it transforms the test statistic into a probabilistic scale:
* it's a number between 0 and 1 that quantifiers the strength of evidence against the $H_0$
* formally, $p$-value is a conditional probability of 
** observing data favorable to $H_A$ and to the current data set 
** given $H_0$ is true


It answers the following question
* Assuming $H_0$ is true, how likely it is to observe a test statistic of this magnitude just by chance?
* And the numerical answer is the $p$-value


The smaller the $p$-value the stronger the evidence against $H_0$


'''Note!'''
* $p$-value cannot be interpreted as how likely it is that the $H_0$ is true. 
* $p$-value tells you how unlikely the observed value of the test statistics (and more extreme value) is if the $H_0$ was true. 


So the 3rd step is 
* '''determine how unlikely the test statistic is if the $H_0$ is true''' (or, calculate the $p$-value)


=== Step 4: Verdict ===
Based on the $p$-value make a verdict: 
* $p$-value is not small
** $\Rightarrow$ conclude that the data is consistent with the $H_0$
* $p$-value is small
** $\Rightarrow$ then we have sufficient evidence against $H_0$ to reject it in favor of $H_A$
** we say &quot;we fail to reject $H_0$&quot;


Strength of the evidence: 
* $p &lt; 0.001$ - very strong
* $0.001 \leqslant p &lt; 0.01$ - strong
* $0.01 \leqslant p &lt; 0.05$ - moderate
* $0.05 \leqslant p &lt; 0.1$ - weak
* $p \geqslant 0.1$ - no evidence

The result is statistically significant if the evidence is strong.


The final step: 
* '''make a conclusion based on the $p$-value''' and on the context of the problem (important!)


== Common Test Statistics ==
* [[z-tests|$z$-tests]] - [[Normal Distribution|normal]], for comparing means
* [[Binomial Proportion Test]]s - for comparing proportions, typically approximated by $z$ statistics as well
* [[t-tests|$t$-tests]] - like $z$, but more relaxed (uses [[t Distribution|$t$-distribution]], for comparing means
* [[Chi-Squared Tests|$\chi^2$-tests]] - for normality, variance and goodness of fit 
* [[F-tests|$F$-tests]] ([[ANOVA]]) - for checking more than 2 samples for equality of means


== Terms ==
* Critical Value
* [[Statistical Power|Power of a test]]
* Significance level
* $p$-value
* Type I and II Errors (&quot;Decision Errors&quot;)


=== [[Hypothesis Testing Decision Errors|Decision Errors]] ===
{| class=&quot;wikitable&quot;
|+ Summary [http://en.wikipedia.org/wiki/Type_I_and_type_II_errors]
! || $H_0$ is true  || $H_0$ is false
|-
! Reject $H_0$
| align=&quot;center&quot;| Type&amp;nbsp;I error&lt;br /&gt;False positive
| align=&quot;center&quot;| Correct outcome&lt;br /&gt;True positive
|-
! Fail to reject $H_0$
| align=&quot;center&quot;| Correct outcome&lt;br /&gt;True negative
| align=&quot;center&quot;| Type&amp;nbsp;II error&lt;br /&gt;False negative
|}


=== Significance Level ===
* The ''significance level'' of a test gives a cut-off for how small is small for a $p$-value
* It's denoted by $\alpha$ and called &quot;desired level of significance&quot;
* $\alpha$ shows how the testing method would perform in repeated sampling
* If $H_0$ is true and you use $\alpha = 0.01$, and you carry out a test repeatedly, with the same size of a sample each time, you will reject $H_0$ 1% of the time, and not reject 99% of the time 
* If $\alpha$ is too small, you may never reject $H_0$, even if the true value is very different from the $H_0$


Choosing $\alpha$ 
* traditionally, $\alpha=0.05$
* if making [[Type I Errors]] is dangerous, or especially costly, choose small $\alpha$
** in this case we want very strong evidence to support $H_A$ before rejecting $H_0$
* if [[Type II Errors]] are more costly, then take higher $\alpha$, e.g. $\alpha=0.1$
** here we're careful about failing to reject $H_0$ when it's false 


=== Robustness ===
A statistical test is ''robust'' if the p-value is approximately correct even if some conditions aren't fully satisfied



== One-Sided vs Two-Sided ==
Alternative hypotheses $H_A$ could be one-sided or two-sided 
* if it's one-sided we look only at the corresponding tail of our [[Sampling Distribution]]
* otherwise we look at both tails


Consider the following one-sample [[z-test|$z$-test]] for means: 

=== One-Sided ===
* $H_0: \mu = \mu_0, H_A: \mu &gt; \mu_0$
* $\mu_0$ is called the &quot;null value&quot; because we assume it under $H_0$
* i.e. we want to check if population mean is larger than some value 
* under the [[Normal Distribution|Normal Model]] we calculate the $z$-score and corresponding $p$ value of the right tail
* http://habrastorage.org/files/ab5/ad1/a1f/ab5ad1a1f6054967aecca86243c4b433.png
** (source: [[OpenIntro Statistics (book)|OpenIntro]], figure 4.16)


Analogously, for 
* $H_0: \mu = \mu_0, H_A: \mu &lt; \mu_0$ 
* we calculate the $p$-value based on the left tail 
* http://habrastorage.org/files/bb4/edb/b53/bb4edbb5330e4c0c814a89d52c821690.png
** (source: [[OpenIntro Statistics (book)|OpenIntro]], figure 4.16. modified)


=== Two-Sided ===
Two-Sided alternative hypotheses looks at both left and right tails. E.g.
* $H_0: \mu = \mu_0, H_A: \mu \ne \mu_0$ 
* http://habrastorage.org/files/34a/68f/2b4/34a68f2b488c420fbc9ec0d522a9e906.png
** (source: [[OpenIntro Statistics (book)|OpenIntro]], figure 4.19, modified)
* if this case, we reject $H_0$ if the test statistics gets under any of the shaded tails 
** i.e. the $p$-value is (typically) twice bigger than for one-sided tests 



== Advice for Hypothesis Testing ==
=== $p$-values ===
* Don't misinterpret $p$-values  (see what p-values say and what don't)
* A $p$-value is a measure of the strength of the evidence - so don't forget to report it 


=== Data Collection ===
[[Data Collection]] matters 
* [[Sampling|Sample]] wisely:
* use randomization to avoid flaws and biases 


=== Two-Sided Tests ===
Always try to use 2-sided tests 
* Unless you're really sure you need one direction
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/tests-1vs2sides.png
* $p$-value for one-sided test is 0.5 of p-value of 2-sided 


One-sided hypotheses are allowed only &lt;u&gt;before&lt;/u&gt; seeing the data
* it's never good to change 2-sided to 1-sided after observing the data
* it can cause twice more [[Type I error]]s (False positives - i.e. rejecting $H_0$ when it's true)


=== Practical Significance ===
Statistical significance $\neq$ practical significance 
* the larger the $n$, the smaller $p$-value 
* A large $p$-value doesn't necessarily mean that the $H_0$ is true, there might be not enough power to reject it.


Small $p$-values can occur (in order of significance:)
* ''by chance''
* data collection is [[Bias|biased]]
* violations of the conditions
* $H_0$ is false (the last one! - so be more careful about those above!)


So 
* If multiple tests are carried out, some are likely to be significant by '''chance alone'''
* If $\alpha = 0.05$ we expect significant results 5% of the time, even when the $H_0$ is '''true'''
* $\Rightarrow$ be suspicious if you see only a few significant results when many tests have been carried out 


=== [[Data Snooping]] ===
* The test results are not reliable if the statements of the hypotheses are suggested by data.
* This is called ''data snooping'' - So hypotheses should be specified before any data is collected


=== General Advice ===
* Start with [[Explanatory Data Analysis]] e.g. using [[Plots]] and [[Summary Statistics]] 
* watch for [[Distributions|skewed distributions]], [[Outliers]], etc 
** before using some test statistics, make sure the corresponding assumptions about the data hold



== Relationship with [[Confidence Intervals]] ==
{{Main | Confidence Intervals and Statistical Tests}}

Some hypothesis can be checked with [[Confidence Intervals]]
* e.g. if the null value (the value under $H_0$) is included in the CI, then $p$-value is greater than $\alpha$ and we fail to reject $H_0$




== See Also ==
* [[Sampling Distribution]]
* [[Confidence Intervals]]
* [[Confidence Intervals and Statistical Tests]]


== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[OpenIntro Statistics (book)]]
* http://en.wikipedia.org/wiki/Statistical_hypothesis_testing


[[Category:Statistics]]
[[Category:Statistical Tests]]</text>
      <sha1>15rqrqc93lvkrlpai2nnxigncc6oe7v</sha1>
    </revision>
  </page>
  <page>
    <title>Confidence Intervals and Statistical Tests</title>
    <ns>0</ns>
    <id>112</id>
    <revision>
      <id>113</id>
      <timestamp>2013-08-09T10:57:44Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2013">== Relationship between Confidence Intervals and Tests ==
How to connect [[Statistical Tests of Significance|Hypothesis Testing]] and [[Confidence Intervals]]? 

== Example ==
* Remember [[Confidence Intervals#Beer Cap Flipping|the beer cap flipping experiment]]? 
* We test: $H_0: p = 0.5, H_A: p \neq 0.5$ (2-sided)
Observations:
* $n = 1000$
* $\hat{p} = 0.576$
* under $H_0$, is difference $| \hat{p} - p | = | \hat{p} - 0.5 | = 0.076$ too large to reject H_0?


We calculate $p$-value
: $P(|\hat{p} - 0.5| \geqslant 0.076) \approx P(|N(0, 1)| \geqslant 4.81 ) \approx 1 / 663000 \leqslant 0.05$

And reject the $H_0$ because the $p$-value is small


Now let's calculate 95% CI:
*  $\hat{p} \pm 1.96 \sqrt{p(1-p)/n} = [0.532, 0.620]$
* The CI misses 0.5 
* and this is '''not''' a coincidence! 


== General Test ==
Suppose we have a test of the following form
* $H_0: \mu = \mu_0, H_A: \mu \neq \mu_0$
* Our observations are: $n$, $\bar{X}$, $s$, 
* We're interested in the difference between observed mean and the true mean:
: $\Delta = |\bar{X} - \mu_0|$

So we reject $H_0$ if
* $P(|\bar{X} - \mu_0| \geqslant \Delta) \leqslant \alpha$
* $P\left(\left| \cfrac{\bar{X} - \mu_0}{\sqrt{s^2 / n}} \right| \geqslant \cfrac{\Delta}{\sqrt{s^2 / n}} \right) = P\left(\left| t_{n - 1} \right| \geqslant \cfrac{\Delta}{\sqrt{s^2 / n}} \right) \leqslant \alpha$


This will only happen if
* $\cfrac{\Delta}{\sqrt{s^2 / n}} \geqslant T_{\alpha/2, n-1}$
* where $T_{\alpha/2, n-1}$ is ''critical value'' s.t.
: $P(|t_{n-1}| \geqslant T_{\alpha/2, n-1} ) = \alpha$


And $(1 - \alpha)$ [[Confidence Intervals]] for $\mu$ is
* $\bar{X} \pm T_{\alpha/2, n-1} \cdot \sqrt{s^2 / n}$
* This misses $\mu_0$ when 
: $|\bar{X} - \mu_0 | \geqslant T_{\alpha/2, n-1} \cdot \sqrt{s^2 / n}$


So these are equivalent:
: Reject $H_0$ when C.I. misses $\mu_0$

== See also ==
* [[Confidence Intervals]]
* [[Statistical Tests of Significance]]

== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]


[[Category:Statistics]]</text>
      <sha1>2h43kc5zrseks54roru2u4kny3cetvg</sha1>
    </revision>
  </page>
  <page>
    <title>Category:R</title>
    <ns>14</ns>
    <id>113</id>
    <revision>
      <id>114</id>
      <timestamp>2014-07-15T16:14:47Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="48">[[Category:Programming]]
[[Category:Statistics]]</text>
      <sha1>6r41sb04m1rotsfxsh6ualpy2aygync</sha1>
    </revision>
  </page>
  <page>
    <title>Linear Regression</title>
    <ns>0</ns>
    <id>114</id>
    <revision>
      <id>115</id>
      <timestamp>2013-08-16T14:17:22Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6063">== Regression ==
How to understand the linear relationship between data? 
* dependent (response) variable - $Y$
* independent (explanatory) variable or predictor - $X$

To what extent $X$ can help us to predict $Y$? 


=== Regression Line ===
The line has the followoing form: 
* $y = b_0 + b_1 \cdot x$
* $b_0$ - intercept
* $b_1$ - slope 

Suppose we have $n$ observations
* for $i$th observation we have $y_i = b_0 + b_1 x_i$
* and difference $y_i - b_0 - b_1 x_i$ is called ''residual'' 
* We'd like to make these differences for all $i$ as small as possible


=== Method of Least Squares ===
{{Main | Method of Least Squares}}

To find the slope and the intercept parameters we may use the method of least squares


=== Interpretation ===
* Suppose we have $b_0 = -23.3, b_1 = 0.41$
* It means that
: When $X$ increases by 1, $Y$ increases by 0.41
* $b_0$ value the regression would give if $X = 0$
: or how much we have to shift the line 


=== Symmetry ===
Regression is not symmetric:
: regressing $X$ over $Y$ is not the same as regressing $Y$ over $X$


=== Example ===
This is an example of best linear fit:

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/regression-line.png&quot; /&gt;



== Correlation ==
For intercept we have:
* $b_0 = \cfrac{1}{n} (\sum y_i - b_1 \sum x_i) = \bar{y} - b_1 \bar{x}$

So the regression line takes the following form
* $b_0 + b_1 x_i = (\bar{y} - b_1 \bar{x}) + b_1 x_i = \bar{y} + b_1 (x_i - \bar{x})$

This means: 
* we start from mean of $y$
* and shift by how far we're from $\bar{x}$ multiplied by slope
* $(\bar{x}, \bar{y})$ is always on the line!


Let's manipulate it a bit the formula for the slope coefficient to get better understanding of what's going on
* $b_1 = \cfrac{n \sum x_i y_i - \sum x_i \sum y_i }{n \sum x_i^2 - (\sum x_i)^2} $ (divide top and bottom by $1/n^2$)
* $ = \cfrac{\frac{1}{n} \sum x_i y_i - \frac{1}{n} \sum x_i \cdot \frac{1}{n} \sum y_i}{\frac{1}{n} \sum x_i^2 - (\frac{1}{n} \sum x_i )^2 } $ 
* $= \cfrac{\frac{1}{n} \sum x_i y_i - \bar{x} \bar{y}}{\frac{1}{n} \sum x_i^2 - \bar{x}^2 } $
* $ = \cfrac{\frac{1}{n} (x_i - \bar{x})(y_i - \bar{y}) }{\frac{1}{n} \sum (x_i - \bar{x})^2 }$ (let's multiply top and bottom on $\sqrt{\sum (y_i - \bar{y}) }$)
* $ = \cfrac{(x_i - \bar{x})(y_i - \bar{y}) \cdot \sqrt{\sum (y_i - \bar{y})^2 } }{ \sqrt{\sum (x_i - \bar{x})^2 } \cdot \sqrt{\sum (x_i - \bar{x})^2 } \cdot \sqrt{\sum (y_i - \bar{y})^2 }} = R \cfrac{s_y}{s_x}$


So we get
: $b_1 = R \cfrac{s_y}{s_x}$

where
* $s_x = \sqrt{\cfrac{1}{n - 1} \sum (x_i - \bar{x}) }$ and
* $s_y = \sqrt{\cfrac{1}{n - 1} \sum (y_i - \bar{y}) }$
* $R = \cfrac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum (x_i - \bar{x})^2 \sum (y_i - \bar{y})^2 }}$ is the [[Корреляция|''correlation coefficient'']]


== Residuals ==
''Residuals'' is the difference between actual values and predicted values

$i$th residual is:
* $e_i = y_i - (b_0 + b_1 x_i) = y_i - b_0 - b_1 x_1 $

=== Residual Analysis ===
{{Main | Residual Analysis}}

[[Residual Analysis]] - is a powerful mechanism for estimating how good a regression is
* It gives us $R^2$, called [[Residual Analysis#Coefficient of Determination|Coefficient of Determination]], which is a measure of how much variance in the data was explained by our regression model


== Regression Inference ==
How much uncertainty is it there? Can we apply
* [[Confidence Intervals]]? 
* [[Statistical Tests of Significance|Hypothesis testing]]? 


We have a formula for slope $b_1$ and, let  $\beta_1$ be the true value of slope
* How close $b_1$ to $\beta_1$?


There's the following fact: 
* $\cfrac{b_1 - \beta_1}{\text{SE}(b_1)} \sim t_{n - 2}$
* where $\text{SE}$ is ''standard error'' 
* we loose one degree because we don't know the slope and the other because of the intercept 

And we calculate the standard error as
* $\text{SE}(b_1) = \cfrac{\sqrt{\sum e_i^2 }}{\sqrt{(n - 2) \sum (x_i - \bar{x})^2 } }$
* recall that $e_i = y_i - (b_0 + b_1 x_i)$


=== Confidence Intervals ===
So a $(1 - \alpha)$ CI for $\beta_1$ is
: $b_1 \pm T_{\alpha/2, n-2} \cdot \text{SE}(b_1)$

Example 
* $Y$ = age difference
* $X$ = bmi
* $n = 400$
* $b_1 = 0.41$
* $\sum e_i^2 = 78132$
* $\sum(x_i - \bar{x}) = 8992$


We're interested to calculate 95% CI:
* $0.41 \pm 1.97 \cdot \cfrac{\sqrt{78131}}{\sqrt{398 \cdot 8992}} = 0.41 \pm 0.29 = [0.12, 0.70]$


=== Hypothesis Testing ===
We may want to ask if there is any linear relationship.

So the following test gives an answer:
* $H_0: \beta_1 = 0, H_A: \beta_1 \neq 1$


For the example above we have
* $\cfrac{b_1 - \beta_1}{\text{SE}(b_1)} \sim t_{n - 2}$
* $b_1= 0.41, \text{SE}(b_1) = 0.148$

$p$-value (under $H_0$)
* $P( | b_1 - \beta_1 | \geqslant 0.41 ) = $
* $P \left( \left| \cfrac{b_1 - \beta_1}{\text{SE}(b_1)} \right| \geqslant \cfrac{0.41}{\text{SE}(b_1)} \right) \approx$
* $P( | t_{398} | \geqslant 2.77 ) \approx 0.0059$

Quite small, so we reject the $H_0$ and conclude that $\beta_1 \neq 0$, i.e. there is some linear relationship.


== Limitations ==
* linear! - fails to predict other kinds of relationships (quadratic etc)
* not robust to outliers (just one outlier can change the regression line rather significantly)


== [[Gradient Descent]] ==
Another way of finding the slope and intercept parameters is [[Gradient Descent|Gradient Descent Algorithm]], 
* which, usually, gives approximate solution,
* but works faster for [[Multivariate Linear Regression|Multivariate Linear Regressions]]


== [[Multivariate Linear Regression]] ==
{{Main | Multivariate Linear Regression}}

We can use the regression to fit a linear model for several variables.

== In R ==
&lt;pre&gt;
# lm - linear model 
lm1 = lm(diff ~ bmi)

plot(diff ~ bmi)
abline(lm1)

# summary of regression
summary(lm1)

# the residual difference for each observation
lm1$residuals 
&lt;/pre&gt;

Logarithmic transformation
&lt;pre&gt;
lm1 = lm(diff ~ log10(bmi))
&lt;/pre&gt;


== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]

[[Category:Statistics]]
[[Category:Machine Learning]]
[[Category:R]]</text>
      <sha1>4001d3m6u74whwf7vtbj4zqtieoyqnh</sha1>
    </revision>
  </page>
  <page>
    <title>Machine Learning (coursera)</title>
    <ns>0</ns>
    <id>115</id>
    <revision>
      <id>116</id>
      <timestamp>2015-04-19T11:34:24Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1557">== Overview ==
* Introduction to [[Machine Learning]]
* [https://share.coursera.org/wiki/index.php/ML:Octave_Tutorial Octave tutorial @ Coursera crowd wiki]


== Prediction: [[Supervised Learning]] ==
=== [[Linear Regression]] ===
* Univariate [[Linear Regression]]
** [[Gradient Descent]]
* [[Multivariate Linear Regression]]
** [[Gradient Descent#Gradient Descent for Multivariate Linear Regression|Gradient Descent for Multivariate Linear Regression]]
* [[Normal Equation]]


== Classification ==
=== [[Logistic Regression]] ===
* [[One-vs-All Classification]]
* [[Overfitting]] and [[Regularization]]


=== [[Neural Networks]] ===
* [[Neural Networks#Model Representation|Representation]]
* [[Neural Networks#Forward Propagation|Forward Propagation]]
* [[Neural Networks#Back Propagation|Back Propagation]]


=== [[Support Vector Machines]] ===
* Intuition behind SVM


== [[Unsupervised Learning]] ==
* [[Cluster Analysis|Clustering]]
** [[K-Means]]
* [[Dimensionality Reduction]]
* [[Anomaly Detection]]
* [[Recommender Systems]]


== Other ==
=== Model Debugging ===
* [[Machine Learning Diagnosis]]
* [[Learning Curves]]
* [[Model Selection]]
* [[Cross-Validation]]
* [[Error Analysis]] - also good for prioritizing 


=== [[Error Metrics]] ===
* [[Error Metrics#Precision|Precision]]
* [[Error Metrics#Recall|Recall]]
* [[Error Metrics#F1 Score|$F_1$-score]]


=== Practical Advice ===
* [[Large-Scale Machine Learning]]
* [[Photo OCR Application Example (Machine Learning)]]


[[Category:Machine Learning]]
[[Category:Coursera]]
[[Category:Notes]]</text>
      <sha1>pna02yjy0w544kxbbf4mwfbb4m73hwk</sha1>
    </revision>
  </page>
  <page>
    <title>Machine Learning</title>
    <ns>0</ns>
    <id>116</id>
    <revision>
      <id>117</id>
      <timestamp>2013-08-30T15:01:32Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2030">== Machine Learning ==
''Machine Learning'' - field of study that gives computers the ability to learn without being explicitly programmed

A computer is said to ''learn'' from experience $E$ with respect to some task $T$ and some performance measure $P$
* if it's performance of $T$,
* as measured by $P$,
* improves with experience $E$


E.g. email filtering:
* $T$: classifying email as spam/not spam
* $E$: watching you label as spam/not spam 
* $P$: the number of emails correctly classified as spam/not spam


Examples of Machine Learning: 
* db-mining
** web-data clicks, etc
* automation
** autonomous helicopter 
** NLP
** Computer Vision
* self-customizing software
** amazon, netflix, etc
* understanding human learning


== Supervised Learning ==
&quot;right answers&quot; are given 
* i.e. the algoritm takes a training set $\{(x^{(i)}, y^{(i)})\}$
* and then predicts a value for / classifies a data example $x$


=== Regression  ===
''Regression'' - predict: continuous values 

Examples:
* You have a large inventory of identical items 
* You want to predict how many of these items will sell over the next 3 months


Main tool
* [[Linear Regression]]


=== Classification  ===
''Classification'' - assigning to a group (0, 1) etc: discrete values

$y \in \{0, 1\}$ - ''binary classification problem'' 
* 0 - negative class, connected with absence of smth (not spam)
* 1 - positive class, connected with presence of smth (spam)

Tools:
* [[Logistic Regression]]
* [[Neural Networks]]
* [[Support Vector Machines]]


== Unsupervised Learning  ==
* just given the data, no labels 
* can we find a structure in the data? 
* we don't tell the algorithm what are the categories 

i.e. we're given only $\{x^{(i)}\}$, no $y^{(i)}$s

applications
* news segregation
* social network analysis
* clustering 
* market segregation

=== [[Clustering]] ===
The goal is to automatically group the data into coherent subsets (or ''clusters'')
* [[K-Means]]




== Sources ==
* [[Machine Learning (coursera)]]

[[Category:Machine Learning]]</text>
      <sha1>cz0thpyd00wwcplxzns0zv32ycg6i97</sha1>
    </revision>
  </page>
  <page>
    <title>Template:Main</title>
    <ns>10</ns>
    <id>117</id>
    <revision>
      <id>118</id>
      <timestamp>2013-08-16T13:42:59Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="31">: Main Article: ''[[{{{1}}}]]''</text>
      <sha1>e9732njodp8ojgiz44j73lo8a3fyz4h</sha1>
    </revision>
  </page>
  <page>
    <title>Gradient Descent</title>
    <ns>0</ns>
    <id>118</id>
    <revision>
      <id>119</id>
      <timestamp>2013-08-30T10:40:15Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5770">== Gradient Descent ==
Suppose we have a cost function $J$ and want to minimize it 
* say it takes 2 parameters $\theta_0$ and $\theta_1$
* So we have $J(\theta_0, \theta_1)$ and want to find $\min_{\theta_0, \theta_1} J(\theta_0, \theta_1)$


Idea: 
* start with some $(\theta_0, \theta_1)$ (say, $(0,0)$)
* keep changing $(\theta_0, \theta_1)$ to reduce $J(\theta_0, \theta_1)$ until we end up in minimum


In the pseudo code
* repeat until converges
** for $j = 0$ and $j = 1$
** $\theta_j = \theta_j - \alpha \cfrac{\partial}{\partial \theta_i} J(\theta_0, \theta_1)$

$\alpha$ is the learning rate, value that specifies how small are steps we take 


=== Simultaneous Update ===
Note that the update for $(\theta_0, \theta_1)$ has to be ''simultaneous''. That is 
* $\tau_0 = \theta_0 - \alpha \cfrac{\partial}{\partial \theta_0} J(\theta_0, \theta_1)$
* $\tau_1 = \theta_1 - \alpha \cfrac{\partial}{\partial \theta_1} J(\theta_0, \theta_1)$
* $\theta_0 = \tau_0$
* $\theta_1 = \tau_1$

As you see, $\theta_0$ is used to calculate new value for $\theta_1$, so we cannot update it before we calculate new value for $\theta_0$.

This is called ''simultaneous update''


== Intuition ==
Let's see how it works
* assuming that there's only one variable $\theta_1$ and $\theta_1 \in \mathbb{R}$

$\theta_1 = \theta_1 - \alpha \cfrac{d}{d \theta_1} J(\theta_1)$


let's have a look at the partial derivative: 
* $\beta = \alpha \cfrac{d}{d \theta_1} J(\theta_1)$

if the derivative is positive
* &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/gradient-descent-right-deriv.png&quot; /&gt;
* we're moving left: 
: $\theta_1 = \theta_1 - \beta$

if the derivative is negative
* &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/gradient-descent-left-deriv.png&quot; /&gt;
* we're moving right:
: $\theta_1 = \theta_1 + \beta$


For two variables the cost function would look like that:
: &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/gradient-descent-2vars.png&quot; /&gt;


=== Learning Rate ===
* when $\alpha$ is too small - we're taking very small steps - too slow
* when $\alpha$ is too large - we're taking too big steps and may miss the minimum 
: in this case not only may it fail to converge, but even diverge! 

Approaching the minimum
* As we're approaching the local minimum, it takes smaller and smaller steps 
* If $\theta_1$ is at the local minimum, then $\beta = 0$ and $\theta_1$ won't change 


=== Convex Function ===
The cost function $J$ has to be convex if we don't want to end up in a local minimum.


== Univarivate [[Linear Regression]] ==
* Given input data set $\{(x^{(i)}, y^{(i)}\}$ of size $m$
* We have our hypothesis $h(x) = \theta_0 + \theta_1 x$
* how to choose $\theta_0$ and $\theta_1$ so $h(x)$ is closest to the set of input data 

We need to minimize the cost function:
* $J(\theta_1, \theta_2) = \cfrac{1}{2 m} \sum_{i = 1}{m} (h_0 x^{(i)} - y^{(i)} )^2$
* This is the ''squared error cost function''

Let's simplify our expression:
: $\cfrac{\partial}{\partial \theta_j} J(\theta_0, \theta_1) =  \cfrac{\partial}{\partial \theta_j} \cfrac{1}{2m} \sum (h_{\theta}(x^{i}) - y^{(i)} )^2 = \cfrac{\partial}{\partial \theta_j} \cfrac{1}{2m} \sum (\theta_0 + \theta_1 x^{i} - y^{(i)} )^2 $


Now we calculate the derivatives and have: 
* for $\theta_0$:
: $\cfrac{\partial}{\partial \theta_0} J(\theta_0, \theta_1) = \cfrac{1}{m} \sum (h_{\theta} (x^{(i)}) - y^{(i)})$
* for $\theta_1$:
: $\cfrac{\partial}{\partial \theta_1} J(\theta_0, \theta_1) = \cfrac{1}{m} \sum (h_{\theta} (x^{(i)}) - y^{(i)}) \cdot x^{(i)}$


So for the [[Linear Regression|regression]] the algorithm is 
* repeat until converges
** $\theta_0 = \theta_0 - \alpha \cfrac{\partial}{\partial \theta_0} J(\theta_0, \theta_1) = \cfrac{1}{m} \sum (h_{\theta} (x^{(i)}) - y^{(i)})$
** $\theta_1 = \theta_1 - \alpha \cfrac{\partial}{\partial \theta_1} J(\theta_0, \theta_1) = \cfrac{1}{m} \sum (h_{\theta} (x^{(i)}) - y^{(i)}) \cdot x^{(i)}$
* (update simultaneously)


The square error cost function is convex, so we always converge to the global minimum.


== Gradient Descent for [[Multivariate Linear Regression]] ==
For Multivariate Linear Regression we have $x^{(i)} \in \mathbb{R}^{n + 1} $and $\theta = \in \mathbb{R}^{n+1}$, where 
* $n$ - is number of features 
* $m$ - number of training examples
* and $x_0^{(i)} = 1$ for all $i$ (the slope)

So out cost function takes the following form:
: $J(\theta) = J(\theta_0, ... , \theta_n) = \cfrac{1}{2m} \sum_{i = 1}^{m} (h_{\theta} (x^{(i)}) - y^{(i)} )^2$


The algorithm:
* repeat
** simultaneously for all $i$
** $\theta_j = \theta_j - \alpha \cfrac{\partial}{\partial \theta_j} J(\theta)$

or, having calculated the derivatives:   
* repeat
** simultaneously for all $i$
** $\theta_j = \theta_j - \alpha \cfrac{1}{m} \sum (h_{\theta}) (x^{(i)}) - y^{(i)} ) \cdot x_j^{(i)}$


== Gradient Descent in Practice ==
=== [[Feature Scaling]] ===
Use [[Feature Scaling]] to help GD converge faster 

=== Learning Rate ===
* How to choose $\alpha$?
* If GD works properly, cost function should decrease after each iteration 
* if $J$ decreases by less than $\epsilon = 10^{-3}$ in one iteration - declare ''convergence''
* If $J$ is increasing instead - need to make $\alpha$ smaller 

Choosing $\alpha$:
* But don't choose $\alpha$ too small - it'll take too long to converge 
* To choose $\alpha$ try
: $..., 0.001, 0.01, 0.1$, ... or increase it 3-fold 
* And see what is acceptable 


== Applications ==
Apart from [[Linear Regression]], Gradient Descent may also be used for 
* [[Logistic Regression]]
* [[Neural Networks]]
* and many others 


== Sources ==
* [[Machine Learning (coursera)]]

[[Category:Machine Learning]]</text>
      <sha1>ld70s2sq1qlkr4o3l1ml6mh70ct5j5d</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Machine Learning</title>
    <ns>14</ns>
    <id>119</id>
    <revision>
      <id>120</id>
      <timestamp>2015-05-01T19:45:32Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="103">[[Category:Mathematics]]
[[Category:Computer Science]]
[[Category:Statistics]]
[[Category:Programming]]</text>
      <sha1>bmorotcyhoe9t8f4k8as7bl22jolw8s</sha1>
    </revision>
  </page>
  <page>
    <title>Residual Analysis</title>
    <ns>0</ns>
    <id>120</id>
    <revision>
      <id>121</id>
      <timestamp>2013-08-16T13:52:01Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3994">== Residuals ==
''Residuals'' is the difference between actual values and predicted values

$i$th residual is:
* $e_i = y_i - (b_0 + b_1 x_i) = y_i - b_0 - b_1 x_1 $

Mean of $e$: 
* $\bar{e} = \bar{y} - b_0 - b_1 \bar{x} = \bar{y} - (\bar{y} - b_1 \bar{x}) - b_1 \bar{x} = 0$


What about $\text{Var}(e)$?
* $e_i = y_i - b_0 - b_1 x_i = y_i - (\bar{y} - b_1 \bar{x}) - b_1 x_i = (y_i - \bar{y}) - b_i (x_i - \bar{x}) = (y_i - \bar{y}) - R \cfrac{s_y}{s_x}(x_i - \bar{x})$
* so, 
: $(e_i - \bar{e})^2 = (y_i - \bar{y})^2 + (R \cfrac{s_y}{s_x})^2 (x_i - \bar{x})^2 - 2 (\bar{y} - b_1 \bar{x}) \cdot R \cfrac{s_y}{s_x}(x_i - \bar{x})$
* $\text{Var}(e) = \cfrac{1}{n - 1} \sum (e_i - \bar{e})^2 = s_y^2 + (R \cfrac{s_y}{s_x})^2 s_x^2 - 2R \cfrac{s_y}{s_x} \cfrac{1}{n - 1} \sum (x_0 - \bar{x})(y_i - \bar{y}) = $ (note the [[Корреляция|orrelation coefficient]] again!)
* $= s_y^2 + R^2 s_y^2 - 2R\cfrac{s_y}{s_x} s_x s_y R = s_y^2 + R^2 s_y^2 - 2R^2 s_y^2 = s_y^2 (1 - R^2)$

So 
: $\text{Var}(e) = \text{Var}(y)(1 - R^2)$


== Coefficient of Determination ==
The regression multiplies the variance of $y$ by $(1 - R^2)$
* Or, the regression line ''removes'' (or ''reduces'') a fraction of $R^2$ of the variance of $y$
* Or we say it &quot;explains a fraction of $R^2$ of the variation&quot;

$R^2$ is called ''coefficient of determination'' - and says what fraction of $\text{Var}(Y)$ has been explained by the linear relationship


Examples:
* $R^2 = 0$: the linear relationship explains nothing (so no linear relationship between $X$ and $Y$)
* $R^2 = 1$: the linear relationship explains everything - no left-overs, no uncertainty 
* $R^2 = 0.0186$: only 1.86% of variation was explained by   the linear model - so there hardly is a linear relation. The rest of the variance (98%) is due to something else


Let's take a look at the example again: 
* &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/regression-line.png&quot; /&gt;
* $R^2$ = 0.4033
* so it means quite a bit of variance there is explained by linear model
* but still it doesn't explain everything - indeed the real data doesn't seem to have linear relationship


== Residual Analysis ==
Are there any other kinds of relationships between $X$ and $Y$, not captured by regression? 

=== Ideal case ===
&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/regression-residuals-good2.png&quot; /&gt;

* This is a good case because after taking out linear relationship there's no particular pattern in residuals: only independent errors are left
* So overall there's no particular trend and that means that the regression really tells us something about the relationships between $X$ and $Y$


=== Another Example ===
&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/regression-residuals-quad2.png&quot; /&gt;

And the same here 

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/regression-residuals-pat2.png&quot; /&gt;

In both cases the linear relationship doesn't describe the whole story and we see there are apparent patterns in the residuals in both cases 


== Logarithmic Transformation ==
* To improve the situation we could try to transform the variables before applying regression.
* Most common transformation is logarithmic

So we have the following: 

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/regression-residuals-log1.png&quot; /&gt;

Recall that in this case $R^2 = 0.40$


If we calculate $\log_{10} x$ what we get is 

&lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/regression-residuals-log3.png&quot; /&gt;

Now we're able to fit a better regression line and in this case $R^2 = 0.6576$

Here we interpret a slope of 14.93 as
* if $\log_b x$ increases by $1$, $y$ increases by 14.93
* or if $x$ is multiplied by $b$, $y$ increases by 14.93


== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]

[[Category:Statistics]]</text>
      <sha1>3w2yfsccx2z8yhur631c4g7hjt132hh</sha1>
    </revision>
  </page>
  <page>
    <title>Method of Least Squares</title>
    <ns>0</ns>
    <id>121</id>
    <revision>
      <id>122</id>
      <timestamp>2014-02-09T21:05:04Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="982">== Method of Least Squares ==
=== [[Linear Regression]] ===
* Suppose we want to fit a [[Linear Regression|regression line]] to our data
* We want to find the slope and intercept parameters 
* And we want to find the best fit 


Optimization
* To do that we minimize the sum of squares for differences:
* $\text{ss} = \sum_{i = 1}^{n} (y_i - b_0 - b_1 x_i)^2 $
* We want to make $\text{ss}$ as small as possible 


We need to use calculus to do that
* we find partial derivatives to find the critical (minimal in our case) value 
* $\cfrac{\partial \text{ss}}{\partial b_0} = \cfrac{\partial \text{ss}}{\partial b_1} = 0$


So after calculating that we get:
* $b_0 = \cfrac{1}{n} (\sum y_i - b_0 \sum x_i)$ for intercept
* $b_1 = \cfrac{n \sum x_i y_i - \sum x_i \sum y_i }{n \sum x_i^2 - (\sum x_i)^2}$ for slope

These values minimize the sum of square differences 


== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]

[[Category:Regression]]
[[Category:Statistics]]</text>
      <sha1>7853g395n381iy4301huezsgacnymsx</sha1>
    </revision>
  </page>
  <page>
    <title>Multivariate Linear Regression</title>
    <ns>0</ns>
    <id>122</id>
    <revision>
      <id>123</id>
      <timestamp>2015-08-30T10:45:26Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3223">== [[Linear Regression]] ==
[[Linear Regression]] - main article about univariative linear regression

== Multiple Features ==
* suppose we have several features 
* and we want to use them all to predict $Y$


For example, we want to predict a house's price
* $y$ - price (dependent)
* $x_1$ - # of bedrooms
* $x_2$ - # of floors 
* $x_3$ - age
* $x_4$ - size


let's use the following notation 
* $n$ - number of features 
* $m$ - number of examples 
* $x^{(i)}$ - a vector all features of the $i$th training set, $x^{(i)} \in \mathbb{R}$
* $x_j^{(i)}$ - $j$th element of $i$th training example 

e.g. 
: $x^{(2)} = (x_1^{(2)}, x_2^{(2)}, x_3^{(2)}, x_4^{(2)})$ - vector of all features from the second row 


* Recall that for [[Linear Regression|one variable]] we have
: $h_{\theta}(x) = \theta_0 + \theta_1 x$
* now we have 
: $h_{\theta}(x) = \theta_0 + \theta_1 x_1 + ... + \theta_n x_n$


let $x_0 = 1$ (i.e. all $x_0^{(i)} = 1$) - so-called zeroth feature - always 1 (our slope)


So now we can view $x^{(i)}$ as $n+1$ vector: $x^{(i)} \in \mathbb{R}^{n + 1}$, 
$x = 
\left[
\begin{matrix}
x_0 \\ \vdots \\ x_n
\end{matrix}
\right]$
and 
$\theta = 
\left[
\begin{matrix}
\theta_0 \\ \vdots \\ \theta_n
\end{matrix}
\right] 
\in \mathbb{R}^{n+1}$

And $h_{\theta}(x) = \theta_0 x_0 + \theta_1 x_1 + ... + \theta_n x_n = \theta^{T} x$
(which is $[\theta_0 ... \theta_n] \cdot \left[
\begin{matrix}
x_0 \\ \vdots \\ x_n
\end{matrix}
\right]$ )

This is called ''multivariate linear regression''


== Polynomial Regression ==
* Suppose we want to fit not just features, but their combinations
* For example, we have two features: height and width, and we want to use them both to fit one parameter $\theta$
** So we write: 
** $h(x) = \theta_0 + \theta_1 x = \theta_0 + \theta_1 \cdot \text{height} \cdot \text{width}$
** ($x = \text{height} \cdot \text{width}$)

Next, suppose we have the following relationship between data 
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/regression-poly.png
* we may try to use 
* $\theta_0 + \theta_1 x + \theta_2 x^2 $
* or even 
* $\theta_0 + \theta_1 x + \theta_2 x^2 +  \theta_3 x^3 $
* So we have 3 features instead of one: $x$, $x^2$ and $x^3$! 
* Don't forget to normalize them - it's important because all these features have different scales


== Computing Coefficients ==
=== [[Gradient Descent]] for Multivariate Linear Regression ===
{{Main | Gradient Descent#Multivariate Linear Regression}}

=== [[Normal Equation]] ===
{{Main | Normal Equation}}
This is another way of computing coefficients for multivariate regression 


== Linear Regression Assumptions ==
* https://en.wikipedia.org/wiki/Ordinary_least_squares#Assumptions
* http://stats.stackexchange.com/questions/55113/where-do-the-assumptions-for-linear-regression-come-from
* http://people.duke.edu/~rnau/testing.htm
* http://www.statisticssolutions.com/assumptions-of-linear-regression/
* http://pareonline.net/getvn.asp?n=2&amp;v=8
* http://stats.stackexchange.com/questions/16381/what-is-a-complete-list-of-the-usual-assumptions-for-linear-regression


== Sources ==
* [[Machine Learning (coursera)]]

[[Category:Regression]]
[[Category:Statistics]]
[[Category:Machine Learning]]</text>
      <sha1>24huh25rg8wuy7qanntxh0uweuospt9</sha1>
    </revision>
  </page>
  <page>
    <title>Normal Equation</title>
    <ns>0</ns>
    <id>123</id>
    <revision>
      <id>124</id>
      <timestamp>2015-04-25T20:41:56Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13696">$\require{cancel}$

== Normal Equation ==
* This is a technique for computing coefficients for [[Multivariate Linear Regression]].
* the problem is also called [[OLS Regression]], and ''Normal Equation'' is an approach of solving it
* It finds the regression coefficients analytically
* It's ''an one-step learning'' algorithm (as opposed to [[Gradient Descent]])


== [[Multivariate Linear Regression]] Problem ==
Suppose we have
* $m$ training examples $(\mathbf x_i, y_i)$
* $n$ features, $\mathbf x_i = \big[x_{i1}, \ ... \ , x_{in} \big]^T \in \mathbb{R}^n$
* We can put all such $\mathbf x_i$ as rows of a matrix $X$ (sometimes called a ''design matrix'')
* $X = \begin{bmatrix}
- \ \mathbf x_1^T - \\ 
  \vdots  \\ 
- \ \mathbf x_m^T -   \\ 
\end{bmatrix} = \begin{bmatrix}
x_{11} &amp; \cdots &amp; x_{1n}  \\ 
 &amp;  \ddots &amp;  \\ 
x_{m1} &amp; \cdots &amp; x_{mn}  \\ 
\end{bmatrix}$
* the observed values: $\mathbf y = \begin{bmatrix}
y_1 \\ \vdots \\ y_m
\end{bmatrix} \in \mathbb{R}^{m}$
* Thus, we expressed our problem in the matrix form: $X \mathbf w = \mathbf y$
* Note that there's usually additional feature $x_{i0} = 1$ - the slope, 
** so $\mathbf x_i \in \mathbb{R}^{n+1}$ and $X = \begin{bmatrix}
- \ \mathbf x_1^T - \\ 
- \ \mathbf x_2^T - \\ 
 \vdots  \\ 
- \ \mathbf x_m^T -   \\ 
\end{bmatrix} = \begin{bmatrix}
x_{10} &amp; x_{11} &amp; \cdots &amp; x_{1n}  \\ 
x_{20} &amp; x_{21} &amp; \cdots &amp; x_{2n}  \\ 
 &amp; &amp;  \ddots &amp;  \\ 
x_{m0} &amp; x_{m1} &amp; \cdots &amp; x_{mn}  \\ 
\end{bmatrix} \in \mathbb R^{m \times n + 1}$


Thus we have a system 
* $X \mathbf w = \mathbf y$
* how do we solve it, and if there's no solution, how do we find the best possible $\mathbf w$?


== Least Squares ==
There's no solution to the system, so we try to fit the data as good as possible 
* Let $\mathbf w$ be the best fit solution to $X \mathbf w \approx \mathbf y$
* we'll try to minimize the error $\mathbf e = \mathbf y - X \mathbf w$ (also called [[Residual Analysis|residuals]])
* we take the square of this error, so the objective is 
* $J(\mathbf w) = \| \mathbf e \|^2 = \| \mathbf y - X \mathbf w \|^2$


=== Minimization ===
So our problem is 
* $\hat{\mathbf w} = \operatorname{arg \, max}\limits_{\mathbf w} J(\mathbf w) =  \operatorname{arg \, max}\limits_{\mathbf w} \| \mathbf y - X \mathbf w \|^2$
* let's expand $J(\mathbf w)$:
** $J(\mathbf w) = \| \mathbf y - X \mathbf w \|^2 = ( \mathbf y - X \mathbf w )^T ( \mathbf y - X \mathbf w ) = \mathbf y^T \mathbf y - (X \mathbf w)^T \mathbf y - \mathbf y^T (X \mathbf w) + (X \mathbf w)^T (X \mathbf w) = \ ...$
** $... \ = \mathbf y^T \mathbf y - 2 \mathbf w^T X^T \mathbf y + \mathbf w^T X^T X \mathbf w$
* now minimize $J(\mathbf w)$ w.r.t. $\mathbf w$:
** $\frac{\partial J(\mathbf w)}{\partial \mathbf w} = - 2 X^T \mathbf y + 2 X^T X \mathbf w \mathop{=}\limits^! \mathbf 0$
** $X^T X \mathbf w = X^T \mathbf y$ or
* the solution:
* $\mathbf w = (X^T X)^{-1} X^T \mathbf y = X^+ \mathbf y$ 
* where $X^+ = (X^T X)^{-1} X^T$ is the [[General Inverse|Pseudoinverse]] of $X$



== Linear Algebra Point of View ==
In Linear algebra we typically use different notation
* Instead of $X$ we use $A$ - it's a [[System of Linear Equations]] that is very tall and thin
* so we have an $m \times n$ matrix $A$ s.t. $m &gt; n$ - 
* http://habrastorage.org/files/618/d1c/dc2/618d1cdc2f5c4d2fb19a34eb118d5f5f.png
* we need to solve the system $A \mathbf x = \mathbf b$
* if $\mathbf b \not \in C(A)$ ([[Column Space]]) then there's no solution
* how to find an approximate solution? Project onto $C(A)$!
* it also gives the Normal Equation


=== Projection onto $C(A)$ ===
Suppose we have a matrix $A$ with out observations
* the system $A \mathbf x = \mathbf b$ has no solution
* We [[Projection onto Subspaces|project]] $\mathbf b$ on the [[Column Space]] $C(A)$
* how do we do it? $C(A)$ is all the combinations of columns in $A$, so they form a hyperplane in $\mathbb R^m$ 
* $\mathbf b$ is not on this hyperplane - otherwise we would not need to project on it


Normal Equation:
* so we have $A \mathbf x = \mathbf b$
* let's multiply both sides by $A^T$ - to find the best $\mathbf{\hat x}$ that approximates the solution $\mathbf x$ that doesn't exist
* $A^T A \mathbf{\hat x} = A^T \mathbf b$ - this one usually has the solution, and it's called the '''Normal Equation'''
* it projects $\mathbf b$ onto $C(A)$ and gives the solution $\mathbf{\hat x}$
* it also happens to be the best solution in terms of Least Squares error: the projection error $\| \mathbf e \|^2 = \| \mathbf b - A \mathbf{\hat x} \|^2$ is minimal


=== Invertability of $A^T A$ === 
When does $A^T A$ have no inverse? 

Consider this example: 

$A^T A = \begin{bmatrix}
1 &amp; 1 &amp; 1 \\
3 &amp; 3 &amp; 3
\end{bmatrix} \begin{bmatrix}
1 &amp; 3 \\ 
1 &amp; 3 \\
1 &amp; 3 
\end{bmatrix} = \begin{bmatrix}
3 &amp; 9 \\
9 &amp; 27
\end{bmatrix}$

In this case $\text{rank}(A) = 1$ and $\text{rank}(A^T A) = 1$   so $A^T A$ is not invertible
* $\text{rank}(A) = \text{rank}(A^T A)$


When it is invertible?
* $N(A^T A) = N(A)$ (see the theorem in [[Projection onto Subspaces]])
* so when $N(A) = \{ \; \mathbf 0 \; \}$ then it's invertible
* or, in other words, the columns of $A$ are linearly independent


$(A^T A)$ may be not invertible if
* some columns are linearly dependent (i.e. we have redundant features)
** solution: remove the linear dependency
* too many features ($m &lt; n$)
** solution: delete some features, there are too many features for the amount of data we have


=== $\mathbb R^2$ Case ===
* suppose that $\text{dim } C(A) = 2$, i.e. the basis made of columns of $A$: $\mathbf a_1$ and $\mathbf a_2$, $A = \Bigg[ \ \mathop{\mathbf a_1}\limits_|^| \ \mathop{\mathbf a_2}\limits_|^| \ \Bigg]$
* http://habrastorage.org/files/245/834/296/245834296b494b6a8f42522ff1feb119.png
* $\mathbf b$ is not on the plane $C(A)$, but we project on it to get $\mathbf p$ 
* $\mathbf e$ is our projection error




== Example ==
=== $\mathbb R^2$ Case ===
Suppose we have the following dataset: 
* ${\cal D} = \{ (1,1), (2,2), (3,2) \}$

so we have this system:
* $\left\{\begin{array}{l}
x_0 +   x_1 = 1\\ 
x_0 + 2 x_1 = 2\\
x_0 + 2 x_1 = 3\\
\end{array}\right.$
* first column is always 1 because it's our intercept term $x_0$, and $x_1$ is the slope
* the matrix form is $\begin{bmatrix}
1 &amp; 1\\ 
1 &amp; 2\\ 
1 &amp; 3\\
\end{bmatrix}
\begin{bmatrix}
x_0 \\ x_1
\end{bmatrix} = 
\begin{bmatrix} 
1 \\ 2 \\ 2
\end{bmatrix}$
* no line goes through these points at once
* so we solve $A^T A \mathbf{\hat x} = A^T \mathbf b$ 
* $\begin{bmatrix}
1 &amp; 1 &amp; 1 \\ 
1 &amp; 2 &amp; 3 \\ 
\end{bmatrix} \begin{bmatrix}
1 &amp; 1\\ 
1 &amp; 2\\ 
1 &amp; 3\\
\end{bmatrix} = \begin{bmatrix}
3 &amp; 6\\ 
6 &amp; 14\\
\end{bmatrix}$
* this system is invertible, so we solve it and get $\hat x_0 = 2/3, \hat x_1 = 1/2$
* thus the best line is $y = x_0 + x_1 t = 2/3 + 1/2 t$

http://habrastorage.org/files/9af/963/3b5/9af9633b58c04fc9b5ba4aa720e63a8f.png


Is this indeed the best straight line through these points? 
* we want to make the overall error as small as possible
* recall that $\mathbf e$ is our projection error - so we want to minimize it 
* usually we minimize the square: $\min \| \mathbf e \|^2 = \min \big\{ e_1^2 + e_2^2 + e_3^2 \big\} $ 
* so we minimize this: $\| \mathbf e \|^2 = \| A \mathbf x - \mathbf b \|^2$
* we claim that the solution to $A^T A \mathbf{\hat x} = A^T \mathbf b$ minimizes $\| A \mathbf x - \mathbf b \|^2$


http://habrastorage.org/files/ae0/b63/5a2/ae0b635a2e81493bb363d898b0e6369c.png


Let's check if $\mathbf p \; \bot \; \mathbf e$
* $\mathbf{\hat x} = \begin{bmatrix} \hat x_0 \\ \hat x_1 \end{bmatrix} = \begin{bmatrix} 2/3 \\ 1/2 \end{bmatrix}$
* thus $\mathbf p = A \mathbf{ \hat x } = \begin{bmatrix} p_1 \\ p_2 \\ p_3 \end{bmatrix} = \begin{bmatrix} 7/6 \\ 5/3 \\ 13/6 \end{bmatrix}$
* $\mathbf p + \mathbf e = \mathbf b$, so $\mathbf e = \mathbf b - \mathbf p = \begin{bmatrix} 1 - 7/6 \\ 2 - 5/3 \\ 2 - 13/6 \end{bmatrix} = \begin{bmatrix} - 1/6 \\ 2/3 \\ -1/6 \end{bmatrix} $
* $\mathbf p \; \bot \; \mathbf e$ $\Rightarrow$ $\mathbf p^T \mathbf e = 0$. 
* Check: $\begin{bmatrix} 7/6 &amp; 5/3 &amp; 13/6 \end{bmatrix} \begin{bmatrix} - 1/6 \\ 2/3 \\ -1/6 \end{bmatrix} = - 7/6 \cdot 1/6 + 5/3 \cdot 2/3 - 13/6 \cdot 1/6 = 0$


We can also verify that $\mathbf e \; \bot \; C(A)$ 
* let's take one vector from $C(A)$, e.g. $\mathbf 1 = [1, 1, 1]^T \in C(A)$,
* $\mathbf e^T \cdot \mathbf 1 = -1/6 + 2/6 - 1/6 = 0$  



{{ Hider | 
    title=Python code |
    content=
&lt;pre&gt;
import matplotlib.pylab as plt
import numpy as np

class Line:
    def __init__(self, slope, intercept):
        self.slope = slope
        self.intercept = intercept

    def calculate(self, x1):
        x2 = x1 * self.slope + self.intercept
        return x2

A = np.array([[1, 1], [1, 2], [1, 3]])
b = np.array([1, 2, 2])

x0, x1 = np.linalg.solve(A.T.dot(A), A.T.dot(b))
lsq = Line(x1, x0)

# figure
plt.scatter(A[:, 1], b, marker='x', color='black')

points = np.array([0.5, 3.5])
plt.plot(points, lsq.calculate(points))

plt.scatter(A[:, 1], lsq.calculate(A[:, 1]), marker='o', color='red')
plt.vlines(A[:, 1], b, lsq.calculate(A[:, 1]))

plt.show()

x = np.array([[x0], [x1]])
p = A.dot(x).reshape(-1)
e = p - b
print p.dot(e)
&lt;/pre&gt;
}}



== Normal Equation vs [[Gradient Descent]] ==
[[Gradient Descent]]:
* need to choose learning rate $\alpha$
* need to do many iterations
* works well with large $n$


Normal Equation:
* don't need to choose $\alpha$
* don't need to iterate - computed in one step
* slow if $n$ is large $(n \geqslant 10^4)$
* need to compute $(X^T X)^{-1}$ - very slow
* if $(X^T X)$ is not-invertible  - we have problems


== Additional ==
=== Orthogonalization ===
How to speed up computation of $(X^T X)^{-1}$?
* let's make the columns of $X$ orthonormal: orthogonal to each other and of length 1
* we can do the [[QR Factorization]] and obtain matrix $X = QR$ 
* $Q^T Q = I$, and it simplifies the calculation a lot!
* usual case: $\mathbf w = (X^T X)^{-1} X^T \mathbf y$
* with $X = QR$: $X^T X = R^T Q^T Q R = R^T R$
* so, 
** $X^T X \mathbf w = X^T \mathbf y$
** $\cancel{R^T} R \mathbf w = \cancel{R^T} Q^T \mathbf y$
** $\mathbf w = R^{-1} Q^T \mathbf y$
* so it becomes much simpler: no need to invert $X^T X$ directly


=== [[Singular Value Decomposition]] ===
Let's apply SVD to $X$:
* $X = U \Sigma V^T$, with $\text{dim } X = \text{dim } \Sigma$
* $\begin{align} 
X \mathbf w - \mathbf y &amp; = U \Sigma V^T \mathbf w - \mathbf y \\
&amp; =  U \Sigma V^T \mathbf w - U U^T \mathbf y \\
&amp; =  U (\Sigma V^T \mathbf w - U^T \mathbf y) \\
\end{align}$
* let $\mathbf v = V^T \mathbf w$ and $\mathbf z = U^T \mathbf y$
* then we have $U (\Sigma \mathbf v - \mathbf z)$


[[Orthogonal Matrices]] preserve the $L_2$-norm
* i.e. $\| U \mathbf x \| = \| \mathbf x \|$
* thus, $\| \mathbf e \| = \| X \mathbf w - \mathbf y \| = \| U (\Sigma \mathbf v - \mathbf z) \| = \| \Sigma \mathbf v - \mathbf z\|$. 
* $\| X \mathbf w - \mathbf y \| = \| \Sigma \mathbf v - \mathbf z\|$
* $\| \Sigma \mathbf v - \mathbf z\|$ is easier to minimize than $\| X \mathbf w - \mathbf y \|$

So we reduced OLS Regression problem to a diagonal form


Minimization $\| \Sigma \mathbf v - \mathbf z\|$:
* $\text{diag}(\Sigma) = (\sigma_1, \ ... \ , \sigma_r, 0, \ ... \ , 0)$
* $\Sigma \mathbf v = \begin{bmatrix} \sigma_1 \mathbf v_1 \\ \vdots \\ \sigma_r \mathbf v_r \\ 0 \\ \vdots \\ 0 \end{bmatrix}$ and therefore $\Sigma \mathbf v - \mathbf z = \begin{bmatrix} \sigma_1 v_1 - z_1 \\ \vdots \\ \sigma_r v_r - z_r \\ -z_{r+1} \\ \vdots \\ -z_{m} \end{bmatrix}$
* since we minimizing it w.r.t. $\mathbf v$, only first $r$ components of $\Sigma \mathbf v - \mathbf z$ matter
** we can make these $\sigma_i v_i - z_i$ as small as possible by using $v_i = z_i / \sigma_i$
** so first $r$ components become 0, and the rest are $-c_i$, thus, $\| \Sigma \mathbf v - \mathbf z \|^2 = \sum\limits_{i = r+1}^m c_i^2$
** when $r = m$, $\| \Sigma \mathbf v - \mathbf z \| = 0$, but in this case there's no need to Normal Equation


Summary:
* calculate $X = U \Sigma V^T$ and $\mathbf z = U^T \mathbf y$
* use $\mathbf v = \left( \cfrac{z_1}{\sigma_1}, \ ... \ , \cfrac{z_r}{\sigma_r}, 0, \ ... \ , 0  \right)$ to minimize $\| \Sigma \mathbf v - \mathbf z\|$
* since $\mathbf v = V^T \mathbf w$, we recover $\mathbf w$ as $\mathbf w = V \mathbf v$
* this gives solution $\mathbf w$ and residual error $\| \Sigma \mathbf v - \mathbf z\|$ 


Compact solution:
* if $X = U \Sigma V^T$, then $\mathbf w = V \Sigma^+ U^T \mathbf y$
* where $\Sigma^+ = \Big[ \text{diag}(\Sigma) \Big]^{-1}$ (invert only non-zero elements on the diagonal of $\Sigma$)



=== [[Regularization]] ===
We find $\mathbf w$ by calculating $\mathbf w = (X^T X + \lambda E^*)^{-1} \cdot X^T \cdot y$
* where $E^* \in \mathbb{R}^{(n + 1) \times (n + 1)}$
** and $E$ is almost identity matrix (1s on the main diagonal, the rest is 0s), except that the very first element is 0
** i.e. for $n = 2$ : $\left[\begin{matrix} 0 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0  \\ 0 &amp; 0 &amp; 1 \\  \end{matrix} \right]$
** because we don't regularize for the bias input $x_{i0} = 1$
* $(X^T X + \lambda E^*)$ is always invertible


This is called [[Ridge Regression]]
* it can also be solved by both Normal Equation and [[Gradient Descent]] 



=== Implementation ===
Implementation in Octave

&lt;pre&gt;pinv(X' * X) * X' * y&lt;/pre&gt;



== See Also ==
* [[Multivariate Linear Regression]]
* [[Gradient Descent]]

== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* [[Machine Learning (coursera)]]
* http://en.wikipedia.org/wiki/Linear_least_squares_%28mathematics%29
* http://www.seas.ucla.edu/~vandenbe/103/lectures/qr.pdf

[[Category:Machine Learning]]
[[Category:Regression]]
[[Category:Linear Algebra]]
[[Category:Statistics]]</text>
      <sha1>mmd9qyez1zrqxkz54r8f7go9j8wsgll</sha1>
    </revision>
    <revision>
      <id>813</id>
      <parentid>124</parentid>
      <timestamp>2017-08-16T07:51:26Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13832">$\require{cancel}$

== Normal Equation ==
* This is a technique for computing coefficients for [[Multivariate Linear Regression]].
* the problem is also called [[OLS Regression]], and ''Normal Equation'' is an approach of solving it
* It finds the regression coefficients analytically
* It's ''an one-step learning'' algorithm (as opposed to [[Gradient Descent]])


== [[Multivariate Linear Regression]] Problem ==
Suppose we have
* $m$ training examples $(\mathbf x_i, y_i)$
* $n$ features, $\mathbf x_i = \big[x_{i1}, \ ... \ , x_{in} \big]^T \in \mathbb{R}^n$
* We can put all such $\mathbf x_i$ as rows of a matrix $X$ (sometimes called a ''design matrix'')
* &lt;math&gt;X = \begin{bmatrix}
- \ \mathbf x_1^T - \\ 
  \vdots  \\ 
- \ \mathbf x_m^T -   \\ 
\end{bmatrix} = \begin{bmatrix}
x_{11} &amp; \cdots &amp; x_{1n}  \\ 
 &amp;  \ddots &amp;  \\ 
x_{m1} &amp; \cdots &amp; x_{mn}  \\ 
\end{bmatrix}&lt;/math&gt;
* the observed values: &lt;math&gt;\mathbf y = \begin{bmatrix}
y_1 \\ \vdots \\ y_m
\end{bmatrix} \in \mathbb{R}^{m}&lt;/math&gt;
* Thus, we expressed our problem in the matrix form: $X \mathbf w = \mathbf y$
* Note that there's usually additional feature $x_{i0} = 1$ - the slope, 
** so &lt;math&gt;\mathbf x_i \in \mathbb{R}^{n+1}&lt;/math&gt; and &lt;math&gt;X = \begin{bmatrix}
- \ \mathbf x_1^T - \\ 
- \ \mathbf x_2^T - \\ 
 \vdots  \\ 
- \ \mathbf x_m^T -   \\ 
\end{bmatrix} = \begin{bmatrix}
x_{10} &amp; x_{11} &amp; \cdots &amp; x_{1n}  \\ 
x_{20} &amp; x_{21} &amp; \cdots &amp; x_{2n}  \\ 
 &amp; &amp;  \ddots &amp;  \\ 
x_{m0} &amp; x_{m1} &amp; \cdots &amp; x_{mn}  \\ 
\end{bmatrix} \in \mathbb R^{m \times n + 1}&lt;/math&gt;


Thus we have a system 
* $X \mathbf w = \mathbf y$
* how do we solve it, and if there's no solution, how do we find the best possible $\mathbf w$?


== Least Squares ==
There's no solution to the system, so we try to fit the data as good as possible 
* Let $\mathbf w$ be the best fit solution to $X \mathbf w \approx \mathbf y$
* we'll try to minimize the error $\mathbf e = \mathbf y - X \mathbf w$ (also called [[Residual Analysis|residuals]])
* we take the square of this error, so the objective is 
* $J(\mathbf w) = \| \mathbf e \|^2 = \| \mathbf y - X \mathbf w \|^2$


=== Minimization ===
So our problem is 
* $\hat{\mathbf w} = \operatorname{arg \, max}\limits_{\mathbf w} J(\mathbf w) =  \operatorname{arg \, max}\limits_{\mathbf w} \| \mathbf y - X \mathbf w \|^2$
* let's expand $J(\mathbf w)$:
** $J(\mathbf w) = \| \mathbf y - X \mathbf w \|^2 = ( \mathbf y - X \mathbf w )^T ( \mathbf y - X \mathbf w ) = \mathbf y^T \mathbf y - (X \mathbf w)^T \mathbf y - \mathbf y^T (X \mathbf w) + (X \mathbf w)^T (X \mathbf w) = \ ...$
** $... \ = \mathbf y^T \mathbf y - 2 \mathbf w^T X^T \mathbf y + \mathbf w^T X^T X \mathbf w$
* now minimize $J(\mathbf w)$ w.r.t. $\mathbf w$:
** $\frac{\partial J(\mathbf w)}{\partial \mathbf w} = - 2 X^T \mathbf y + 2 X^T X \mathbf w \mathop{=}\limits^! \mathbf 0$
** $X^T X \mathbf w = X^T \mathbf y$ or
* the solution:
* $\mathbf w = (X^T X)^{-1} X^T \mathbf y = X^+ \mathbf y$ 
* where $X^+ = (X^T X)^{-1} X^T$ is the [[General Inverse|Pseudoinverse]] of $X$



== Linear Algebra Point of View ==
In Linear algebra we typically use different notation
* Instead of $X$ we use $A$ - it's a [[System of Linear Equations]] that is very tall and thin
* so we have an $m \times n$ matrix $A$ s.t. $m &gt; n$ - 
* http://habrastorage.org/files/618/d1c/dc2/618d1cdc2f5c4d2fb19a34eb118d5f5f.png
* we need to solve the system $A \mathbf x = \mathbf b$
* if $\mathbf b \not \in C(A)$ ([[Column Space]]) then there's no solution
* how to find an approximate solution? Project onto $C(A)$!
* it also gives the Normal Equation


=== Projection onto $C(A)$ ===
Suppose we have a matrix $A$ with out observations
* the system $A \mathbf x = \mathbf b$ has no solution
* We [[Projection onto Subspaces|project]] $\mathbf b$ on the [[Column Space]] $C(A)$
* how do we do it? $C(A)$ is all the combinations of columns in $A$, so they form a hyperplane in $\mathbb R^m$ 
* $\mathbf b$ is not on this hyperplane - otherwise we would not need to project on it


Normal Equation:
* so we have $A \mathbf x = \mathbf b$
* let's multiply both sides by $A^T$ - to find the best $\mathbf{\hat x}$ that approximates the solution $\mathbf x$ that doesn't exist
* $A^T A \mathbf{\hat x} = A^T \mathbf b$ - this one usually has the solution, and it's called the '''Normal Equation'''
* it projects $\mathbf b$ onto $C(A)$ and gives the solution $\mathbf{\hat x}$
* it also happens to be the best solution in terms of Least Squares error: the projection error $\| \mathbf e \|^2 = \| \mathbf b - A \mathbf{\hat x} \|^2$ is minimal


=== Invertability of $A^T A$ === 
When does $A^T A$ have no inverse? 

Consider this example: 

$A^T A = \begin{bmatrix}
1 &amp; 1 &amp; 1 \\
3 &amp; 3 &amp; 3
\end{bmatrix} \begin{bmatrix}
1 &amp; 3 \\ 
1 &amp; 3 \\
1 &amp; 3 
\end{bmatrix} = \begin{bmatrix}
3 &amp; 9 \\
9 &amp; 27
\end{bmatrix}$

In this case $\text{rank}(A) = 1$ and $\text{rank}(A^T A) = 1$   so $A^T A$ is not invertible
* $\text{rank}(A) = \text{rank}(A^T A)$


When it is invertible?
* $N(A^T A) = N(A)$ (see the theorem in [[Projection onto Subspaces]])
* so when $N(A) = \{ \; \mathbf 0 \; \}$ then it's invertible
* or, in other words, the columns of $A$ are linearly independent


$(A^T A)$ may be not invertible if
* some columns are linearly dependent (i.e. we have redundant features)
** solution: remove the linear dependency
* too many features ($m &lt; n$)
** solution: delete some features, there are too many features for the amount of data we have


=== $\mathbb R^2$ Case ===
* suppose that $\text{dim } C(A) = 2$, i.e. the basis made of columns of $A$: $\mathbf a_1$ and $\mathbf a_2$, $A = \Bigg[ \ \mathop{\mathbf a_1}\limits_|^| \ \mathop{\mathbf a_2}\limits_|^| \ \Bigg]$
* http://habrastorage.org/files/245/834/296/245834296b494b6a8f42522ff1feb119.png
* $\mathbf b$ is not on the plane $C(A)$, but we project on it to get $\mathbf p$ 
* $\mathbf e$ is our projection error




== Example ==
=== $\mathbb R^2$ Case ===
Suppose we have the following dataset: 
* ${\cal D} = \big\{ (1,1), (2,2), (3,2) \big\}$

so we have this system:
* &lt;math&gt;\left\{\begin{array}{l}
x_0 +   x_1 = 1\\ 
x_0 + 2 x_1 = 2\\
x_0 + 2 x_1 = 3\\
\end{array}\right.&lt;/math&gt;
* first column is always 1 because it's our intercept term $x_0$, and $x_1$ is the slope
* the matrix form is &lt;math&gt;\begin{bmatrix}
1 &amp; 1\\ 
1 &amp; 2\\ 
1 &amp; 3\\
\end{bmatrix}
\begin{bmatrix}
x_0 \\ x_1
\end{bmatrix} = 
\begin{bmatrix} 
1 \\ 2 \\ 2
\end{bmatrix}&lt;/math&gt;
* no line goes through these points at once
* so we solve &lt;math&gt;A^T A \mathbf{\hat x} = A^T \mathbf b&lt;/math&gt;
* &lt;math&gt;\begin{bmatrix}
1 &amp; 1 &amp; 1 \\ 
1 &amp; 2 &amp; 3 \\ 
\end{bmatrix} \begin{bmatrix}
1 &amp; 1\\ 
1 &amp; 2\\ 
1 &amp; 3\\
\end{bmatrix} = \begin{bmatrix}
3 &amp; 6\\ 
6 &amp; 14\\
\end{bmatrix}&lt;/math&gt;
* this system is invertible, so we solve it and get $\hat x_0 = 2/3, \hat x_1 = 1/2$
* thus the best line is $y = x_0 + x_1 t = 2/3 + 1/2 t$

http://habrastorage.org/files/9af/963/3b5/9af9633b58c04fc9b5ba4aa720e63a8f.png


Is this indeed the best straight line through these points? 
* we want to make the overall error as small as possible
* recall that $\mathbf e$ is our projection error - so we want to minimize it 
* usually we minimize the square: $\min \| \mathbf e \|^2 = \min \big[ e_1^2 + e_2^2 + e_3^2 \big]$ 
* so we minimize this: $\| \mathbf e \|^2 = \| A \mathbf x - \mathbf b \|^2$
* we claim that the solution to $A^T A \mathbf{\hat x} = A^T \mathbf b$ minimizes $\| A \mathbf x - \mathbf b \|^2$


http://habrastorage.org/files/ae0/b63/5a2/ae0b635a2e81493bb363d898b0e6369c.png


Let's check if $\mathbf p \; \bot \; \mathbf e$
* &lt;math&gt;\mathbf{\hat x} = \begin{bmatrix} \hat x_0 \\ \hat x_1 \end{bmatrix} = \begin{bmatrix} 2/3 \\ 1/2 \end{bmatrix}&lt;/math&gt;
* thus &lt;math&gt;\mathbf p = A \mathbf{ \hat x } = \begin{bmatrix} p_1 \\ p_2 \\ p_3 \end{bmatrix} = \begin{bmatrix} 7/6 \\ 5/3 \\ 13/6 \end{bmatrix}&lt;/math&gt;
* $\mathbf p + \mathbf e = \mathbf b$, so $\mathbf e = \mathbf b - \mathbf p = \begin{bmatrix} 1 - 7/6 \\ 2 - 5/3 \\ 2 - 13/6 \end{bmatrix} = \begin{bmatrix} - 1/6 \\ 2/3 \\ -1/6 \end{bmatrix} $
* $\mathbf p \; \bot \; \mathbf e$ $\Rightarrow$ $\mathbf p^T \mathbf e = 0$. 
* Check: &lt;math&gt;\begin{bmatrix} 7/6 &amp; 5/3 &amp; 13/6 \end{bmatrix} \begin{bmatrix} - 1/6 \\ 2/3 \\ -1/6 \end{bmatrix} = - 7/6 \cdot 1/6 + 5/3 \cdot 2/3 - 13/6 \cdot 1/6 = 0&lt;/math&gt;


We can also verify that $\mathbf e \; \bot \; C(A)$ 
* let's take one vector from $C(A)$, e.g. $\mathbf 1 = [1, 1, 1]^T \in C(A)$,
* $\mathbf e^T \cdot \mathbf 1 = -1/6 + 2/6 - 1/6 = 0$  



{{ Hider | 
    title=Python code |
    content=
&lt;pre&gt;
import matplotlib.pylab as plt
import numpy as np

class Line:
    def __init__(self, slope, intercept):
        self.slope = slope
        self.intercept = intercept

    def calculate(self, x1):
        x2 = x1 * self.slope + self.intercept
        return x2

A = np.array([[1, 1], [1, 2], [1, 3]])
b = np.array([1, 2, 2])

x0, x1 = np.linalg.solve(A.T.dot(A), A.T.dot(b))
lsq = Line(x1, x0)

# figure
plt.scatter(A[:, 1], b, marker='x', color='black')

points = np.array([0.5, 3.5])
plt.plot(points, lsq.calculate(points))

plt.scatter(A[:, 1], lsq.calculate(A[:, 1]), marker='o', color='red')
plt.vlines(A[:, 1], b, lsq.calculate(A[:, 1]))

plt.show()

x = np.array([[x0], [x1]])
p = A.dot(x).reshape(-1)
e = p - b
print p.dot(e)
&lt;/pre&gt;
}}



== Normal Equation vs [[Gradient Descent]] ==
[[Gradient Descent]]:
* need to choose learning rate $\alpha$
* need to do many iterations
* works well with large $n$


Normal Equation:
* don't need to choose $\alpha$
* don't need to iterate - computed in one step
* slow if $n$ is large $(n \geqslant 10^4)$
* need to compute $(X^T X)^{-1}$ - very slow
* if $(X^T X)$ is not-invertible  - we have problems


== Additional ==
=== Orthogonalization ===
How to speed up computation of $(X^T X)^{-1}$?
* let's make the columns of $X$ orthonormal: orthogonal to each other and of length 1
* we can do the [[QR Factorization]] and obtain matrix $X = QR$ 
* $Q^T Q = I$, and it simplifies the calculation a lot!
* usual case: $\mathbf w = (X^T X)^{-1} X^T \mathbf y$
* with $X = QR$: $X^T X = R^T Q^T Q R = R^T R$
* so, 
** $X^T X \mathbf w = X^T \mathbf y$
** $\cancel{R^T} R \mathbf w = \cancel{R^T} Q^T \mathbf y$
** $\mathbf w = R^{-1} Q^T \mathbf y$
* so it becomes much simpler: no need to invert $X^T X$ directly


=== [[Singular Value Decomposition]] ===
Let's apply SVD to $X$:
* $X = U \Sigma V^T$, with $\text{dim } X = \text{dim } \Sigma$
* &lt;math&gt;\begin{align} 
X \mathbf w - \mathbf y &amp; = U \Sigma V^T \mathbf w - \mathbf y \\
&amp; =  U \Sigma V^T \mathbf w - U U^T \mathbf y \\
&amp; =  U (\Sigma V^T \mathbf w - U^T \mathbf y) \\
\end{align}&lt;/math&gt;
* let $\mathbf v = V^T \mathbf w$ and $\mathbf z = U^T \mathbf y$
* then we have $U (\Sigma \mathbf v - \mathbf z)$


[[Orthogonal Matrices]] preserve the $L_2$-norm
* i.e. $\| U \mathbf x \| = \| \mathbf x \|$
* thus, $\| \mathbf e \| = \| X \mathbf w - \mathbf y \| = \| U (\Sigma \mathbf v - \mathbf z) \| = \| \Sigma \mathbf v - \mathbf z\|$. 
* $\| X \mathbf w - \mathbf y \| = \| \Sigma \mathbf v - \mathbf z\|$
* $\| \Sigma \mathbf v - \mathbf z\|$ is easier to minimize than $\| X \mathbf w - \mathbf y \|$

So we reduced OLS Regression problem to a diagonal form


Minimization $\| \Sigma \mathbf v - \mathbf z\|$:
* $\text{diag}(\Sigma) = (\sigma_1, \ ... \ , \sigma_r, 0, \ ... \ , 0)$
* $\Sigma \mathbf v = \begin{bmatrix} \sigma_1 \mathbf v_1 \\ \vdots \\ \sigma_r \mathbf v_r \\ 0 \\ \vdots \\ 0 \end{bmatrix}$ and therefore $\Sigma \mathbf v - \mathbf z = \begin{bmatrix} \sigma_1 v_1 - z_1 \\ \vdots \\ \sigma_r v_r - z_r \\ -z_{r+1} \\ \vdots \\ -z_{m} \end{bmatrix}$
* since we minimizing it w.r.t. $\mathbf v$, only first $r$ components of $\Sigma \mathbf v - \mathbf z$ matter
** we can make these $\sigma_i v_i - z_i$ as small as possible by using $v_i = z_i / \sigma_i$
** so first $r$ components become 0, and the rest are $-c_i$, thus, $\| \Sigma \mathbf v - \mathbf z \|^2 = \sum\limits_{i = r+1}^m c_i^2$
** when $r = m$, $\| \Sigma \mathbf v - \mathbf z \| = 0$, but in this case there's no need to Normal Equation


Summary:
* calculate $X = U \Sigma V^T$ and $\mathbf z = U^T \mathbf y$
* use $\mathbf v = \left( \cfrac{z_1}{\sigma_1}, \ ... \ , \cfrac{z_r}{\sigma_r}, 0, \ ... \ , 0  \right)$ to minimize $\| \Sigma \mathbf v - \mathbf z\|$
* since $\mathbf v = V^T \mathbf w$, we recover $\mathbf w$ as $\mathbf w = V \mathbf v$
* this gives solution $\mathbf w$ and residual error $\| \Sigma \mathbf v - \mathbf z\|$ 


Compact solution:
* if $X = U \Sigma V^T$, then $\mathbf w = V \Sigma^+ U^T \mathbf y$
* where $\Sigma^+ = \Big[ \text{diag}(\Sigma) \Big]^{-1}$ (invert only non-zero elements on the diagonal of $\Sigma$)



=== [[Regularization]] ===
We find $\mathbf w$ by calculating $\mathbf w = (X^T X + \lambda E^*)^{-1} \cdot X^T \cdot y$
* where $E^* \in \mathbb{R}^{(n + 1) \times (n + 1)}$
** and $E$ is almost identity matrix (1s on the main diagonal, the rest is 0s), except that the very first element is 0
** i.e. for $n = 2$ : $\left[\begin{matrix} 0 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0  \\ 0 &amp; 0 &amp; 1 \\  \end{matrix} \right]$
** because we don't regularize for the bias input $x_{i0} = 1$
* $(X^T X + \lambda E^*)$ is always invertible


This is called [[Ridge Regression]]
* it can also be solved by both Normal Equation and [[Gradient Descent]] 



=== Implementation ===
Implementation in Octave

&lt;pre&gt;pinv(X' * X) * X' * y&lt;/pre&gt;



== See Also ==
* [[Multivariate Linear Regression]]
* [[Gradient Descent]]

== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* [[Machine Learning (coursera)]]
* http://en.wikipedia.org/wiki/Linear_least_squares_%28mathematics%29
* http://www.seas.ucla.edu/~vandenbe/103/lectures/qr.pdf

[[Category:Machine Learning]]
[[Category:Regression]]
[[Category:Linear Algebra]]
[[Category:Statistics]]</text>
      <sha1>t8mv4huf7w7jzhvkuwrv00o7j1q7vwt</sha1>
    </revision>
    <revision>
      <id>826</id>
      <parentid>813</parentid>
      <timestamp>2020-03-02T12:36:34Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13832">$\require{cancel}$

== Normal Equation ==
* This is a technique for computing coefficients for [[Multivariate Linear Regression]].
* the problem is also called [[OLS Regression]], and ''Normal Equation'' is an approach of solving it
* It finds the regression coefficients analytically
* It's ''an one-step learning'' algorithm (as opposed to [[Gradient Descent]])


== [[Multivariate Linear Regression]] Problem ==
Suppose we have
* $m$ training examples $(\mathbf x_i, y_i)$
* $n$ features, $\mathbf x_i = \big[x_{i1}, \ ... \ , x_{in} \big]^T \in \mathbb{R}^n$
* We can put all such $\mathbf x_i$ as rows of a matrix $X$ (sometimes called a ''design matrix'')
* &lt;math&gt;X = \begin{bmatrix}
- \ \mathbf x_1^T - \\ 
  \vdots  \\ 
- \ \mathbf x_m^T -   \\ 
\end{bmatrix} = \begin{bmatrix}
x_{11} &amp; \cdots &amp; x_{1n}  \\ 
 &amp;  \ddots &amp;  \\ 
x_{m1} &amp; \cdots &amp; x_{mn}  \\ 
\end{bmatrix}&lt;/math&gt;
* the observed values: &lt;math&gt;\mathbf y = \begin{bmatrix}
y_1 \\ \vdots \\ y_m
\end{bmatrix} \in \mathbb{R}^{m}&lt;/math&gt;
* Thus, we expressed our problem in the matrix form: $X \mathbf w = \mathbf y$
* Note that there's usually additional feature $x_{i0} = 1$ - the slope, 
** so &lt;math&gt;\mathbf x_i \in \mathbb{R}^{n+1}&lt;/math&gt; and &lt;math&gt;X = \begin{bmatrix}
- \ \mathbf x_1^T - \\ 
- \ \mathbf x_2^T - \\ 
 \vdots  \\ 
- \ \mathbf x_m^T -   \\ 
\end{bmatrix} = \begin{bmatrix}
x_{10} &amp; x_{11} &amp; \cdots &amp; x_{1n}  \\ 
x_{20} &amp; x_{21} &amp; \cdots &amp; x_{2n}  \\ 
 &amp; &amp;  \ddots &amp;  \\ 
x_{m0} &amp; x_{m1} &amp; \cdots &amp; x_{mn}  \\ 
\end{bmatrix} \in \mathbb R^{m \times n + 1}&lt;/math&gt;


Thus we have a system 
* $X \mathbf w = \mathbf y$
* how do we solve it, and if there's no solution, how do we find the best possible $\mathbf w$?


== Least Squares ==
There's no solution to the system, so we try to fit the data as good as possible 
* Let $\mathbf w$ be the best fit solution to $X \mathbf w \approx \mathbf y$
* we'll try to minimize the error $\mathbf e = \mathbf y - X \mathbf w$ (also called [[Residual Analysis|residuals]])
* we take the square of this error, so the objective is 
* $J(\mathbf w) = \| \mathbf e \|^2 = \| \mathbf y - X \mathbf w \|^2$


=== Minimization ===
So our problem is 
* $\hat{\mathbf w} = \operatorname{arg \, max}\limits_{\mathbf w} J(\mathbf w) =  \operatorname{arg \, max}\limits_{\mathbf w} \| \mathbf y - X \mathbf w \|^2$
* let's expand $J(\mathbf w)$:
** $J(\mathbf w) = \| \mathbf y - X \mathbf w \|^2 = ( \mathbf y - X \mathbf w )^T ( \mathbf y - X \mathbf w ) = \mathbf y^T \mathbf y - (X \mathbf w)^T \mathbf y - \mathbf y^T (X \mathbf w) + (X \mathbf w)^T (X \mathbf w) = \ ...$
** $... \ = \mathbf y^T \mathbf y - 2 \mathbf w^T X^T \mathbf y + \mathbf w^T X^T X \mathbf w$
* now minimize $J(\mathbf w)$ w.r.t. $\mathbf w$:
** $\frac{\partial J(\mathbf w)}{\partial \mathbf w} = - 2 X^T \mathbf y + 2 X^T X \mathbf w \mathop{=}\limits^! \mathbf 0$
** $X^T X \mathbf w = X^T \mathbf y$ or
* the solution:
* $\mathbf w = (X^T X)^{-1} X^T \mathbf y = X^+ \mathbf y$ 
* where $X^+ = (X^T X)^{-1} X^T$ is the [[General Inverse|Pseudoinverse]] of $X$



== Linear Algebra Point of View ==
In Linear algebra we typically use different notation
* Instead of $X$ we use $A$ - it's a [[System of Linear Equations]] that is very tall and thin
* so we have an $m \times n$ matrix $A$ s.t. $m &gt; n$ - 
* http://habrastorage.org/files/618/d1c/dc2/618d1cdc2f5c4d2fb19a34eb118d5f5f.png
* we need to solve the system $A \mathbf x = \mathbf b$
* if $\mathbf b \not \in C(A)$ ([[Column Space]]) then there's no solution
* how to find an approximate solution? Project onto $C(A)$!
* it also gives the Normal Equation


=== Projection onto $C(A)$ ===
Suppose we have a matrix $A$ with out observations
* the system $A \mathbf x = \mathbf b$ has no solution
* We [[Projection onto Subspaces|project]] $\mathbf b$ on the [[Column Space]] $C(A)$
* how do we do it? $C(A)$ is all the combinations of columns in $A$, so they form a hyperplane in $\mathbb R^m$ 
* $\mathbf b$ is not on this hyperplane - otherwise we would not need to project on it


Normal Equation:
* so we have $A \mathbf x = \mathbf b$
* let's multiply both sides by $A^T$ - to find the best $\mathbf{\hat x}$ that approximates the solution $\mathbf x$ that doesn't exist
* $A^T A \mathbf{\hat x} = A^T \mathbf b$ - this one usually has the solution, and it's called the '''Normal Equation'''
* it projects $\mathbf b$ onto $C(A)$ and gives the solution $\mathbf{\hat x}$
* it also happens to be the best solution in terms of Least Squares error: the projection error $\| \mathbf e \|^2 = \| \mathbf b - A \mathbf{\hat x} \|^2$ is minimal


=== Invertability of $A^T A$ === 
When does $A^T A$ have no inverse? 

Consider this example: 

$A^T A = \begin{bmatrix}
1 &amp; 1 &amp; 1 \\
3 &amp; 3 &amp; 3
\end{bmatrix} \begin{bmatrix}
1 &amp; 3 \\ 
1 &amp; 3 \\
1 &amp; 3 
\end{bmatrix} = \begin{bmatrix}
3 &amp; 9 \\
9 &amp; 27
\end{bmatrix}$

In this case $\text{rank}(A) = 1$ and $\text{rank}(A^T A) = 1$   so $A^T A$ is not invertible
* $\text{rank}(A) = \text{rank}(A^T A)$


When it is invertible?
* $N(A^T A) = N(A)$ (see the theorem in [[Projection onto Subspaces]])
* so when $N(A) = \{ \; \mathbf 0 \; \}$ then it's invertible
* or, in other words, the columns of $A$ are linearly independent


$(A^T A)$ may be not invertible if
* some columns are linearly dependent (i.e. we have redundant features)
** solution: remove the linear dependency
* too many features ($m &lt; n$)
** solution: delete some features, there are too many features for the amount of data we have


=== $\mathbb R^2$ Case ===
* suppose that $\text{dim } C(A) = 2$, i.e. the basis made of columns of $A$: $\mathbf a_1$ and $\mathbf a_2$, $A = \Bigg[ \ \mathop{\mathbf a_1}\limits_|^| \ \mathop{\mathbf a_2}\limits_|^| \ \Bigg]$
* http://habrastorage.org/files/245/834/296/245834296b494b6a8f42522ff1feb119.png
* $\mathbf b$ is not on the plane $C(A)$, but we project on it to get $\mathbf p$ 
* $\mathbf e$ is our projection error




== Example ==
=== $\mathbb R^2$ Case ===
Suppose we have the following dataset: 
* ${\cal D} = \big\{ (1,1), (2,2), (3,2) \big\}$

so we have this system:
* &lt;math&gt;\left\{\begin{array}{l}
x_0 +   x_1 = 1\\ 
x_0 + 2 x_1 = 2\\
x_0 + 3 x_1 = 2\\
\end{array}\right.&lt;/math&gt;
* first column is always 1 because it's our intercept term $x_0$, and $x_1$ is the slope
* the matrix form is &lt;math&gt;\begin{bmatrix}
1 &amp; 1\\ 
1 &amp; 2\\ 
1 &amp; 3\\
\end{bmatrix}
\begin{bmatrix}
x_0 \\ x_1
\end{bmatrix} = 
\begin{bmatrix} 
1 \\ 2 \\ 2
\end{bmatrix}&lt;/math&gt;
* no line goes through these points at once
* so we solve &lt;math&gt;A^T A \mathbf{\hat x} = A^T \mathbf b&lt;/math&gt;
* &lt;math&gt;\begin{bmatrix}
1 &amp; 1 &amp; 1 \\ 
1 &amp; 2 &amp; 3 \\ 
\end{bmatrix} \begin{bmatrix}
1 &amp; 1\\ 
1 &amp; 2\\ 
1 &amp; 3\\
\end{bmatrix} = \begin{bmatrix}
3 &amp; 6\\ 
6 &amp; 14\\
\end{bmatrix}&lt;/math&gt;
* this system is invertible, so we solve it and get $\hat x_0 = 2/3, \hat x_1 = 1/2$
* thus the best line is $y = x_0 + x_1 t = 2/3 + 1/2 t$

http://habrastorage.org/files/9af/963/3b5/9af9633b58c04fc9b5ba4aa720e63a8f.png


Is this indeed the best straight line through these points? 
* we want to make the overall error as small as possible
* recall that $\mathbf e$ is our projection error - so we want to minimize it 
* usually we minimize the square: $\min \| \mathbf e \|^2 = \min \big[ e_1^2 + e_2^2 + e_3^2 \big]$ 
* so we minimize this: $\| \mathbf e \|^2 = \| A \mathbf x - \mathbf b \|^2$
* we claim that the solution to $A^T A \mathbf{\hat x} = A^T \mathbf b$ minimizes $\| A \mathbf x - \mathbf b \|^2$


http://habrastorage.org/files/ae0/b63/5a2/ae0b635a2e81493bb363d898b0e6369c.png


Let's check if $\mathbf p \; \bot \; \mathbf e$
* &lt;math&gt;\mathbf{\hat x} = \begin{bmatrix} \hat x_0 \\ \hat x_1 \end{bmatrix} = \begin{bmatrix} 2/3 \\ 1/2 \end{bmatrix}&lt;/math&gt;
* thus &lt;math&gt;\mathbf p = A \mathbf{ \hat x } = \begin{bmatrix} p_1 \\ p_2 \\ p_3 \end{bmatrix} = \begin{bmatrix} 7/6 \\ 5/3 \\ 13/6 \end{bmatrix}&lt;/math&gt;
* $\mathbf p + \mathbf e = \mathbf b$, so $\mathbf e = \mathbf b - \mathbf p = \begin{bmatrix} 1 - 7/6 \\ 2 - 5/3 \\ 2 - 13/6 \end{bmatrix} = \begin{bmatrix} - 1/6 \\ 2/3 \\ -1/6 \end{bmatrix} $
* $\mathbf p \; \bot \; \mathbf e$ $\Rightarrow$ $\mathbf p^T \mathbf e = 0$. 
* Check: &lt;math&gt;\begin{bmatrix} 7/6 &amp; 5/3 &amp; 13/6 \end{bmatrix} \begin{bmatrix} - 1/6 \\ 2/3 \\ -1/6 \end{bmatrix} = - 7/6 \cdot 1/6 + 5/3 \cdot 2/3 - 13/6 \cdot 1/6 = 0&lt;/math&gt;


We can also verify that $\mathbf e \; \bot \; C(A)$ 
* let's take one vector from $C(A)$, e.g. $\mathbf 1 = [1, 1, 1]^T \in C(A)$,
* $\mathbf e^T \cdot \mathbf 1 = -1/6 + 2/6 - 1/6 = 0$  



{{ Hider | 
    title=Python code |
    content=
&lt;pre&gt;
import matplotlib.pylab as plt
import numpy as np

class Line:
    def __init__(self, slope, intercept):
        self.slope = slope
        self.intercept = intercept

    def calculate(self, x1):
        x2 = x1 * self.slope + self.intercept
        return x2

A = np.array([[1, 1], [1, 2], [1, 3]])
b = np.array([1, 2, 2])

x0, x1 = np.linalg.solve(A.T.dot(A), A.T.dot(b))
lsq = Line(x1, x0)

# figure
plt.scatter(A[:, 1], b, marker='x', color='black')

points = np.array([0.5, 3.5])
plt.plot(points, lsq.calculate(points))

plt.scatter(A[:, 1], lsq.calculate(A[:, 1]), marker='o', color='red')
plt.vlines(A[:, 1], b, lsq.calculate(A[:, 1]))

plt.show()

x = np.array([[x0], [x1]])
p = A.dot(x).reshape(-1)
e = p - b
print p.dot(e)
&lt;/pre&gt;
}}



== Normal Equation vs [[Gradient Descent]] ==
[[Gradient Descent]]:
* need to choose learning rate $\alpha$
* need to do many iterations
* works well with large $n$


Normal Equation:
* don't need to choose $\alpha$
* don't need to iterate - computed in one step
* slow if $n$ is large $(n \geqslant 10^4)$
* need to compute $(X^T X)^{-1}$ - very slow
* if $(X^T X)$ is not-invertible  - we have problems


== Additional ==
=== Orthogonalization ===
How to speed up computation of $(X^T X)^{-1}$?
* let's make the columns of $X$ orthonormal: orthogonal to each other and of length 1
* we can do the [[QR Factorization]] and obtain matrix $X = QR$ 
* $Q^T Q = I$, and it simplifies the calculation a lot!
* usual case: $\mathbf w = (X^T X)^{-1} X^T \mathbf y$
* with $X = QR$: $X^T X = R^T Q^T Q R = R^T R$
* so, 
** $X^T X \mathbf w = X^T \mathbf y$
** $\cancel{R^T} R \mathbf w = \cancel{R^T} Q^T \mathbf y$
** $\mathbf w = R^{-1} Q^T \mathbf y$
* so it becomes much simpler: no need to invert $X^T X$ directly


=== [[Singular Value Decomposition]] ===
Let's apply SVD to $X$:
* $X = U \Sigma V^T$, with $\text{dim } X = \text{dim } \Sigma$
* &lt;math&gt;\begin{align} 
X \mathbf w - \mathbf y &amp; = U \Sigma V^T \mathbf w - \mathbf y \\
&amp; =  U \Sigma V^T \mathbf w - U U^T \mathbf y \\
&amp; =  U (\Sigma V^T \mathbf w - U^T \mathbf y) \\
\end{align}&lt;/math&gt;
* let $\mathbf v = V^T \mathbf w$ and $\mathbf z = U^T \mathbf y$
* then we have $U (\Sigma \mathbf v - \mathbf z)$


[[Orthogonal Matrices]] preserve the $L_2$-norm
* i.e. $\| U \mathbf x \| = \| \mathbf x \|$
* thus, $\| \mathbf e \| = \| X \mathbf w - \mathbf y \| = \| U (\Sigma \mathbf v - \mathbf z) \| = \| \Sigma \mathbf v - \mathbf z\|$. 
* $\| X \mathbf w - \mathbf y \| = \| \Sigma \mathbf v - \mathbf z\|$
* $\| \Sigma \mathbf v - \mathbf z\|$ is easier to minimize than $\| X \mathbf w - \mathbf y \|$

So we reduced OLS Regression problem to a diagonal form


Minimization $\| \Sigma \mathbf v - \mathbf z\|$:
* $\text{diag}(\Sigma) = (\sigma_1, \ ... \ , \sigma_r, 0, \ ... \ , 0)$
* $\Sigma \mathbf v = \begin{bmatrix} \sigma_1 \mathbf v_1 \\ \vdots \\ \sigma_r \mathbf v_r \\ 0 \\ \vdots \\ 0 \end{bmatrix}$ and therefore $\Sigma \mathbf v - \mathbf z = \begin{bmatrix} \sigma_1 v_1 - z_1 \\ \vdots \\ \sigma_r v_r - z_r \\ -z_{r+1} \\ \vdots \\ -z_{m} \end{bmatrix}$
* since we minimizing it w.r.t. $\mathbf v$, only first $r$ components of $\Sigma \mathbf v - \mathbf z$ matter
** we can make these $\sigma_i v_i - z_i$ as small as possible by using $v_i = z_i / \sigma_i$
** so first $r$ components become 0, and the rest are $-c_i$, thus, $\| \Sigma \mathbf v - \mathbf z \|^2 = \sum\limits_{i = r+1}^m c_i^2$
** when $r = m$, $\| \Sigma \mathbf v - \mathbf z \| = 0$, but in this case there's no need to Normal Equation


Summary:
* calculate $X = U \Sigma V^T$ and $\mathbf z = U^T \mathbf y$
* use $\mathbf v = \left( \cfrac{z_1}{\sigma_1}, \ ... \ , \cfrac{z_r}{\sigma_r}, 0, \ ... \ , 0  \right)$ to minimize $\| \Sigma \mathbf v - \mathbf z\|$
* since $\mathbf v = V^T \mathbf w$, we recover $\mathbf w$ as $\mathbf w = V \mathbf v$
* this gives solution $\mathbf w$ and residual error $\| \Sigma \mathbf v - \mathbf z\|$ 


Compact solution:
* if $X = U \Sigma V^T$, then $\mathbf w = V \Sigma^+ U^T \mathbf y$
* where $\Sigma^+ = \Big[ \text{diag}(\Sigma) \Big]^{-1}$ (invert only non-zero elements on the diagonal of $\Sigma$)



=== [[Regularization]] ===
We find $\mathbf w$ by calculating $\mathbf w = (X^T X + \lambda E^*)^{-1} \cdot X^T \cdot y$
* where $E^* \in \mathbb{R}^{(n + 1) \times (n + 1)}$
** and $E$ is almost identity matrix (1s on the main diagonal, the rest is 0s), except that the very first element is 0
** i.e. for $n = 2$ : $\left[\begin{matrix} 0 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0  \\ 0 &amp; 0 &amp; 1 \\  \end{matrix} \right]$
** because we don't regularize for the bias input $x_{i0} = 1$
* $(X^T X + \lambda E^*)$ is always invertible


This is called [[Ridge Regression]]
* it can also be solved by both Normal Equation and [[Gradient Descent]] 



=== Implementation ===
Implementation in Octave

&lt;pre&gt;pinv(X' * X) * X' * y&lt;/pre&gt;



== See Also ==
* [[Multivariate Linear Regression]]
* [[Gradient Descent]]

== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* [[Machine Learning (coursera)]]
* http://en.wikipedia.org/wiki/Linear_least_squares_%28mathematics%29
* http://www.seas.ucla.edu/~vandenbe/103/lectures/qr.pdf

[[Category:Machine Learning]]
[[Category:Regression]]
[[Category:Linear Algebra]]
[[Category:Statistics]]</text>
      <sha1>8scq91isvg0ch9ht1zlsugrpkoabp94</sha1>
    </revision>
  </page>
  <page>
    <title>Logistic Regression</title>
    <ns>0</ns>
    <id>124</id>
    <revision>
      <id>125</id>
      <timestamp>2014-02-14T21:06:06Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7361">== Motivation ==
Suppose we have a ''binary classification problem'':
* $y \in \{0, 1\}$ - 
* 0 - negative class, connected with absence of smth (not spam)
* 1 - positive class, connected with presence of smth (spam)


=== [[Linear Regression]] ===
We may try to use [[Linear Regression]] for that
* We fit a regression line 
: $h_{\theta}(x) = \theta^T x$
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/log-reg-linear-motivation.png
* And we set a &quot;threshold&quot; at 0.5
** if $h_{\theta}(x) \geqslant 0.5$ - we predict 1 
** if $h_{\theta}(x) &lt; 0.5$ - we predict 0

What's wrong with this approach?
* Linear regression is susceptible to outliers - a single outlier can break the classificator 
* $h_{\theta}(x)$ can be $&gt; 1$ or $&lt; 0$
* So linear regression is not a good idea


We need to develop something that outputs values from range $[0, 1]$ that we can treat as probabilities 


== Logistic Regression ==
Logistic Regression - is a classification algorithm


=== Hypothesis Representation ===
* we want - $0 \leqslant h_{\theta}(x) \leqslant 1$
* let $h_{\theta}(x) = g(\theta^T x)$
* where $g(z) = \cfrac{1}{1 + e^{-z}}$ - ''sigmoid (logistic) function''
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/log-reg-sigmoid.png
: it's always between 0 and 1


It inputs probability
* We interpret the output from $h_{\theta}(x) $as probability that $y = 1$ on input $x$, or
* $h_{\theta}(x) = P(y = 1 | x; \theta)$: probability that $y = 1$ given $x$ parametrized by $\theta$
* As $y = \{0, 1\}$, $P(y = 0| x; \theta) =  1 - P(y = 1 | x; \theta)$


For example, suppose $x = \left[\begin{matrix} x_0 \\ x_1 \end{matrix} \right] = \left[\begin{matrix} 1 \\ \text{tumor size} \end{matrix} \right]$
* if $h_{\theta}(x) = 0.7$, there's 70% chance of tumor being malignant 


== Decision Boundary ==
Suppose we predict 
* &quot;$y = 1$&quot; if $h_{\theta}(x) \geqslant 0.5$, and 
* &quot;$y = 0$&quot; if $h_{\theta}(x) &lt; 0.5$

* $g(z) \geqslant 0.5$ when $z \geqslant 0$
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/log-reg-sigmoid.png
* so $h_{\theta}(x) = g(\theta^T x) \geqslant 0.5$ when $\theta^T x \geqslant 0$


== Decision Boundary Line ==
* Assume that out model is $h_{\theta}(x) = g(\theta_0 + \theta_1 x_1 + \theta_2 x_2)$
* for $\theta = [-3, 1, 1]^T$
* $y = 1$ if $\theta^T x = -3 + x_1 + x_2 \geqslant 0$ (or $x_1 + x_2 \geqslant 3$)
* So we have the following decision boundary line
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/log-reg-decision-boundary.png
* this line separates two regions: one with &quot;$y = 1$&quot; and another with &quot;$y = 0$&quot;


We may fit as complex expressions as we like
* Suppose we want non-linear decision boundary
* we fit polynomial expression:
: $h_{\theta} = g(\theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_1^2 + \theta_4 x_2^2)$
* Assume $\theta = [-1, 0, 0, 1, 1]^T$
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/log-reg-decision-boundary-poly.png
* here we predict &quot;$y = 1$&quot; if $x_1^2 + x_2^2 \geqslant 1$


=== Examples ===
Suppose we fit $h_{\theta}(x) = g(\theta_0 + \theta_1 x_1 + \theta_2 x_2)$
* with parameters $\theta_0 = -6$, $\theta_1 = 0$  and $\theta_2 = 1$
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/log-reg-decision-boundary-ex1.png
: the transition from negative to positive occur when x_2 goes from below 6 to above 6
* if parameters are $\theta_0 = 6$, $\theta_1 = -1$  and $\theta_2 = 0$,
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/log-reg-decision-boundary-ex2.png
: the transition occurs when $x_1$ goes from above 6 to below 6 (note that $\theta_1 = -1$)


== Cost Function ==
We have:
* Training set $\{(x^{(i)}, y^{(i)})\}$ with $m$ examples
* each $x = [x_0, ..., x_n]^T \in \mathbb{R}^{n + 1}$ where $n$ is a number of features, 
* all $x_0 = 1 $
* and all $y \in \{0, 1\}$
* the model is $h_{\theta} = \cfrac{1}{1 - e^{-\theta^T x}}$
* How to choose parameters $\theta$? 


=== Non-Convex Cost Function ===
For [[Linear Regression]] the cost function was
* $J(\theta) = \cfrac{1}{m} \sum \text{cost}(h_{\theta}(x^{(i)}), y^{(i)})$
* where $\text{cost}(h_{\theta}(x), y) = \cfrac{1}{2} (h_{\theta}(x) - y)^2$


For logistic regression the problem with this approach is that with the sigmoid function g(z) it gives a non-convex function 
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/log-reg-convex-non-convex.png
* that is, 
* if $J(\theta)$ is non-convex, it has many local optima, and [[Gradient Descent]] is not guaranteed to converge to a global optimum
* if $J(\theta)$ is convex, [[Gradient Descent]] always converges to a global optimum
* So we need a different cost function that is convex and GD will work on it


=== Better Cost Function ===
We can use:
* $\text{cost}(h_{\theta}(x), y) = \left\{\begin{array}{l l} -\log(h_{\theta}(x)) &amp; \text{ if } y = 1 \\ - \log(1 - h_{\theta}(x)) &amp; \text{ if } y = 0 \end{array} \right. $
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/log-reg-cost.png
* for the first equation (the left side)
** $\text{cost} = 0$ if $h_{\theta}(x) = 1$ (and $y = 1$)
** as $h_{\theta}(x) \to 0$, $\text{cost} \to \infty$
** it captures the intuition that if $h_{\theta}(x) = 0$, but $y = 1$, we will penalize by a very large cost
* same for the 2nd equation (the right side)
** $\text{cost} \to \infty$ as $h_{\theta}(x) \to 1$


Because $y \in \{0, 1\}$, we can rewrite the cost function as 
* $\text{cost}(h_{\theta}(x), y) =  -y \cdot \log(h_{\theta}(x)) - (1 - y) \cdot \log(1 - h_{\theta}(x))$
* and the total cost is $J(\theta) = \cfrac{1}{m} \sum \text{cost}(h_{\theta}(x^{(i)}), y^{(i)}) = - \cfrac{1}{m} \sum \left[ y \cdot \log(h_{\theta}(x)) + (1 - y) \cdot \log(1 - h_{\theta}(x)) \right]$


=== Fitting $\theta$ ===
* To fit $\theta$ we use [[Gradient Descent]] or other optimization technique 
* The algorithm is identical to finding $\theta$ for [[Gradient Descent#Multivariate Linear Regression|Linear Regression]]


== Basic Algorithm ==
So the whole Logistic Regression algorithms is: 
* find $\min_{\theta} J(\theta)$
* get this $\theta$
* for a new $x$ output $h_{\theta}(x) = g(\theta^T x)$
* using given threshold decide if $y = 1$ or $y = 0$


== Additional Notes ==
=== Multi-Class Classification ===
For multi-class classification with Logistic Regression use [[One-vs-All Classification]]

=== Regularization ===
{{Main | Regularization}}

To prevent [[Overfitting|overfitting]] we reduce magnitude of some features with [[Regularization]]


=== Implementation ===
Matlab/Octave implementation:
* [https://code.google.com/p/stolzen/source/browse/trunk/courses/coursera/Machine%20Learning/week04/mlclass-ex3/lrCostFunction.m regularized cost function]
* [https://code.google.com/p/stolzen/source/browse/trunk/courses/coursera/Machine%20Learning/week04/mlclass-ex3/predict.m prediction]
* [https://code.google.com/p/stolzen/source/browse/trunk/courses/coursera/Machine%20Learning/week04/mlclass-ex3/predictOneVsAll.m one-vs-all prediction]


== See also ==
* [[Linear Regression]]
* [[One-vs-All Classification]]
* [[Regularization]]
* [[Neural Networks]]

== Sources ==
* [[Machine Learning (coursera)]]

[[Category:Classification]]
[[Category:Machine Learning]]</text>
      <sha1>oikqd1yyue299hfk253v82r6gxf2av4</sha1>
    </revision>
  </page>
  <page>
    <title>One-vs-All Classification</title>
    <ns>0</ns>
    <id>125</id>
    <revision>
      <id>126</id>
      <timestamp>2013-08-21T13:31:38Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1912">== One vs All Classifier ==
Suppose we have a classifier for sorting out input data into 3 categories: 
* class 1 ($\triangle$)
* class 2 ($\square$)
* class 3 ($\times$)

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/multiclass-one-vs-all-01.png

We may turn this problem into 3 binary classification problems (i.e. where we predict only $y \in \{0, 1\}$) to be able to use classifiers such as [[Logistic Regression]].
* We take values of one class and turn them into positive examples, and the rest of classes - into negatives

* Step 1
** triangles are positive, and the rest are negative - and we run a classifier  on them. 
** https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/multiclass-one-vs-all-02.png
** and we calculate $h_{\theta}^{(1)}(x)$ for it
* Step 2
** next we do same with squares: make them positive, and the rest - negative
** https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/multiclass-one-vs-all-03.png
** and we calculate $h_{\theta}^{(2)}(x)$
* Step 3
** finally, we make $\times$s as positive and the rest as negative and calculate $h_{\theta}^{(3)}(x)$
** https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/multiclass-one-vs-all-04.png


So we have fit 3 classifiers:
* $h_{\theta}^{(i)}(x) = P(y = i | x; \theta), i = 1, 2, 3$
* Now, having calculated the vector $h_{\theta}(x) = [h_{\theta}^{(1)}(x), h_{\theta}^{(2)}(x), h_{\theta}^{(3)}(x)]$ we just pick up the maximal value 
* i.e. we choose $\max_{i} h_{\theta}^{(i)}(x)$


== Implementation ==
The implementation is straightforward
* Matlab/Octave implementation can be found [https://code.google.com/p/stolzen/source/browse/trunk/courses/coursera/Machine%20Learning/week04/mlclass-ex3/predictOneVsAll.m here]


== Sources ==
* [[Machine Learning (coursera)]]

[[Category:Classification]]
[[Category:Machine Learning]]</text>
      <sha1>8r99otu5yq04kla13azykaje26nyhid</sha1>
    </revision>
  </page>
  <page>
    <title>Overfitting</title>
    <ns>0</ns>
    <id>126</id>
    <revision>
      <id>127</id>
      <timestamp>2014-06-08T19:55:38Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3944">== Overfitting ==
''Overfitting'' (or  ''high variance'') - if we have too many features, the learning hypothesis may 
* fit the training set very well (with cost function $J(\theta) \approx 0$), 
* but fail to generalize to new examples (predict for new data)


== Generalization Error ==
=== [[Cross-Validation]] ===
Best way to see if you overfit:
* split data in training and test set
* train the model on training set
* evaluate the model on the training set
* evaluate the model on the test set
* generalization error: difference between them, measures the ability to generalize


It's clear that a model overfits when we plot the generalization error
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/ds/overfitting.png
* we have low error on the training data, but high on the testing data
* may perform [[Machine Learning Diagnosis]] to see that


=== High Variance vs High Bias ===
Generalization error can be decomposed into bias and variance 
* bias: tendency to constantly learn the same wrong thing 
* variance: tendency to learn random things irrespective to the input data

Dart throwing illustration:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/ds/high-variance-bias.png


=== Underfitting ===
* high bias, low variance
* you're always missing in the same way

example:
* predict always the same
* very insensible to the data 
* the variance is very low! (0)
* but it has high bias - it's wrong



== Examples ==
=== [[Multivariate Linear Regression]] ===
Suppose we have a set of data 
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/overfit-dataset-lin.png
* We can fit the following [[Multivariate Linear Regression]] model
* linear: $\theta_0 + \theta_1 x$, likely to underfit (high bias)
* quadratic: $\theta_0 + \theta_1 x + \theta_2 x^2 $
* extreme: $\theta_0 + \theta_1 x + \theta_2 x^2 +  \theta_3 x^3 +  \theta_4 x^4 $
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/overfit-dataset-lin-ex.png


=== [[Logistic Regression]] ===
Same applies for [[Logistic Regression]]
* Suppose we have the following set
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/overfit-dataset.png
* We may underfit with just a line
** $g(\theta_0 + \theta_1 x_1 + \theta_2 x_2)$
* We may perform just right, but missing some positive examples
** $g(\theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_1^2 + \theta_4 x_2^2 + \theta_5 x_1 x_2)$
* Or we may overfit using high-polynomial model
** $g(\theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_1^2 + \theta_4 x_2^2 + \theta_5 x_1 x_2 + \theta_6 x_1^2 x_2 + \theta_7 x_1 x_2^2 + \theta_8 x_1^2 x_2^2 + \theta_9 x_1^3 + ...)$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/overfitting-logreg-ex.png


The problem with it
* overly high polynomial 
* it can fit anything!
* it overfits - results in high variance


== Diagnosing ==
=== How to Diagnose the Problem ===
To identify overfitting we can use [[Machine Learning Diagnosis]]:
* [[Cross-Validation]]
* and [[Learning Curves]]


=== How to Address the Problem ===
* plotting - doesn't work with many features
* reducing the number of features
** manually select features to keep 
** [[Model Selection]] algorithm (chooses good features by itself)
** but it may turn out that some of the features we want to throw away are significant
** [[Principal Component Analysis]]
* [[Regularization]]
** keep all the features but reduce the magnitude of parameters
* [[Cross-Validation]]
** test your hypotheses on cross-validation set 



== Sources ==
* [[Machine Learning (coursera)]]
* [[Data Mining (UFRT)]]
* [[Introduction to Data Science (coursera)]]
* Domingos, Pedro. &quot;A few useful things to know about machine learning.&quot; [http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf]

[[Category:Machine Learning]]
[[Category:Model Performance Evaluation]]</text>
      <sha1>hdvzpp5ci7vgkh605x3h1f57psrlpmn</sha1>
    </revision>
  </page>
  <page>
    <title>Regularization</title>
    <ns>0</ns>
    <id>127</id>
    <revision>
      <id>128</id>
      <timestamp>2013-08-28T08:09:18Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5398">== Regularization ==
* ''Regularization'' is a technique used to address [[Overfitting|overfitting]]
* Main idea of regularization is to keep all the features, but reduce magnitude of parameters $\theta$
* It works well when we have a lot of features, each of which contributes a bit to predicting $y$


=== Penalization ===
* Suppose we want to fit $\theta_0 + \theta_1 x_1 + \theta_2 x_2  + \theta_3 x_3 + \theta_4 x_4$
* We want to penalize $\theta_3$ and $\theta_4$ - and make them small 
* we modify out cost function $J$:
: $J(\theta) = \cfrac{1}{m} \left[ \sum_{i=1}^{m}  \text{cost}(h_{\theta}(x^{(i)}), y^{(i)}) + 1000 \cdot \theta_3^2 + 1000 \cdot \theta_4^2 \right]$
* where $1000 \cdot \theta_3^2$ and $1000 \cdot \theta_4^2$ - ''penalty'' for using $\theta_3$ and $\theta_4$ respectively
* As a result, we'll have $\theta_3 \approx 0$ and $\theta_4 \approx 0$


So, ''regularization'' ensures that values for $\theta_1 ... \theta_n$ are small 
* it makes the hypotheses simple
* and less prone to overfitting 


== Cost Function ==
* we have features $x_1, ..., x_m$ - they may be polynomials
* and parameters $\theta_0, \theta_1, ..., \theta_m$

We don't know which parameter to penalize. 


Here is our cost function $J$ with regularization:
* $J(\theta) = \cfrac{1}{m} \left[ \sum_{i=1}^{m} \text{cost}(h_{\theta}(x^{(i)}), y^{(i)}) + \lambda \sum_{j = 1}^{n} \theta_j^2 \right]$
* In the cost function we include the penalty for all $\theta$s  
** we typically don't penalize $\theta_0$, only $\theta_1, ..., \theta_n$
** $\lambda$ is called ''regularization parameter''


== Regularization Parameter $\lambda$ ==
When we find the optimum for our cost function $J$ we have two goals:
* we would like to fit the training data well
** 1st term of the expression reflects that:
** $\sum_{i=1}^{m} (\text{cost}(h_{\theta}(x^{(i)})), y^{(i)})$
* we want to keep the parameters small
** 2nd term ensures that:
** $\lambda \sum_{j = 1}^{n} \theta_j^2$


$\lambda$ is the paramenter that controls the trade-off between these two goals
* We need to choose $\lambda$ carefully
** large $\lambda$ will lead to underfitting (we'll end up with $h_{\theta}(x) \approx \theta_0$ )


Say we want to fit $h_{\theta}(x) = \theta_0 + \theta_1 x + ... + \theta_4 x^4$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/diagnosis-regularization.png
* (a) If $\lambda$ if large (say $\lambda = 10000$), all $\theta$ are penalized and $\theta_1 \approx \theta_2 \approx ... \approx 0$, $h_{\theta}(x) \approx \theta_0$
* (b) if $\lambda$ is intermediate, we fit well
* (c) if $\lambda$ is small (close to 0) we fit too well, i.e. we overfit

To find the best value for this parameter, [[Model Selection]] techniques can be used. For example, [[Cross-Validation#Cross-Validation for Regularization|Cross-Validation]]


== Usage ==
=== Regularized [[Multivariate Linear Regression|Linear Regression]] ===
==== [[Gradient Descent]] ====
When we use [[Gradient Descent]] (or other optimization technique), we have the following algorithm:
* repeat:
** for all $j$
** $\theta_j = \theta_j - \cfrac{\partial}{\partial \theta_j} J(\theta)$


Because we have changed the $J(\theta)$ by adding the regularization term, we need to change the partial derivatives of $J(\theta)$. So the algorithm now looks as follows:
* repeat 
** $\theta_0 = \theta_0 - \cfrac{\alpha}{m} \sum (h_{\theta}(x^{(i)}) - y^{(i)}) x_0^{(i)}$ // no change for $\theta_0$
** $\theta_j = \theta_j - \alpha \left[ \cfrac{1}{m} \sum (h_{\theta}(x^{(i)}) - y^{(i)}) x_0^{(i)}  + \cfrac{\lambda}{m} \theta_j \right]$

Or we can rewrite the last one as: 
$\theta_j = \theta_j \left(1 - \alpha \cfrac{\lambda}{m} \right) - \cfrac{\alpha}{m} \sum (h_{\theta}(x^{(i)}) - y^{(i)}) x_0^{(i)}$


==== [[Normal Equation]] ====
We have the following input:
* $X = \left[\begin{matrix} ... (x^{(1)})^T ... \\   ...   \\ ... (x^{(m)})^T ...  \end{matrix} \right] \in \mathbb{R}^{m \times (n + 1)}$
* $y = \left[\begin{matrix} y_1 \\ \vdots \\ y_m \end{matrix} \right] \in \mathbb{R}^{m}$

We find $\theta$ by calculating $\theta = (X^T X + \lambda E^*)^{-1} \cdot X^T \cdot y$
* where $E^* \in \mathbb{R}^{(n + 1) \times (n + 1)}$
** and $E$ is almost identity matrix (1s on the main diagonal, the rest is 0s), except that the very first element is 0
** i.e. for $n = 2$ : $\left[\begin{matrix} 0 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0  \\ 0 &amp; 0 &amp; 1 \\  \end{matrix} \right]$
* $(X^T X + \lambda E^*)$ is always invertible


=== Regularized [[Logistic Regression]] ===
* Old cost function for [[Logistic Regression]] (without regularization) is: 
: $J_{\text{old}}(\theta) = - \cfrac{1}{m} \sum \left[ y \cdot \log(h_{\theta}(x)) + (1 - y) \cdot \log(1 - h_{\theta}(x)) \right]$
* We need to modify it to penalize $\theta_1, ..., \theta_n$:
: $J(\theta) = J_{\text{old}}(\theta) + \cfrac{\lambda}{2m} \sum_{j = 1}^{n} \theta_j^2$


Similarly, for [[Gradient Descent]] we have
* repeat 
** $\theta_0 = \theta_0 - \cfrac{\alpha}{m} \sum (h_{\theta}(x^{(i)}) - y^{(i)}) x_0^{(i)}$ // no change for $\theta_0$
** $\theta_j = \theta_j - \alpha \left[ \cfrac{1}{m} \sum (h_{\theta}(x^{(i)}) - y^{(i)}) x_0^{(i)}  + \cfrac{\lambda}{m} \theta_j \right]$


== See also ==
* [[Overfitting]]
* [[Gradient Descent]]
* [[Multivariate Linear Regression]]
* [[Logistic Regression]]

== Sources ==
* [[Machine Learning (coursera)]]

[[Category:Machine Learning]]</text>
      <sha1>mglb6vmja1lsw206l4s6eoj85bhzii6</sha1>
    </revision>
  </page>
  <page>
    <title>Neural Networks</title>
    <ns>0</ns>
    <id>128</id>
    <revision>
      <id>129</id>
      <timestamp>2013-08-23T09:44:48Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16117">== Motivation ==
* Suppose we have a large number of features and a complex structure of data 
* For [[Logistic Regression]] we would probably need to fit a very high-order polynomial 


Say we have 100 features ($n = 100$) and we want to fit, a multiplication of each pair of features
* i.e. we will have $x_1^2, x_1 x_2, ..., x_1 x_{100}, ... x_2^2, x_2 x_3, ..., $
* this gives us $\approx$ 5000 features (it grows as $O(n)$)
* for combinations of triples we'll have $\approx$ 170 000 features!

Next, suppose we have a computer vision problem: car detection
* we show it cars, then show it not cars, and then test
* Say we have 50 x 50 pixels image, 2500 pixels in total (7500 if RGB). 
* If we want to fit polynomials, the number of features is too huge to do this!


So using [[Logistic Regression]] is certainly not a good way to handle lots of features, and here Neural Networks can help 


== Neural Networks ==
This technique is based on how our brain works - it tries to mimic its behavior. 


== Model Representation ==
* A NN model is built from many ''neurons'' - cells in the brain.
* the neuron, called ''activation unit'', takes features as input 
* A network consists of many activation units


=== Sigmoid Activation Unit ===
* the simplest activation unit is a [[Logistic Regression]] 
* i.e. it is equivalent to [[Logistic Regression]] model


it's called ''sigmoid (logistic) activation function'': 
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/nn-sigmoid.png


Bias unit
* $x_0$ is a bias unit, $x_0 = 1$ always 
* $x_0$ may be omitted from a picture, but it's usually assumed in these cases

Weights
* arrows are &quot;input wires&quot;
* so this unit takes $x = [x_0, x_1, x_2, x_3]^T$, 
* and the wires are out parameters $\theta = [\theta_0, \theta_1, \theta_2, \theta_3]^T$ - their are called ''weights''

Result
* it applies the sigmoid function to the input, and as the result, it returns 
* $h_{\theta} = g(\theta^T x) = \cfrac{1}{1 + e^{-\theta^T x}}$


=== Neural Network Model ===
Let's have a look at an actual neural network
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/nn-representation.png

* A NN model is a network of many sigmoid activation units, organized in ''layers'' 
** where the next layer's input is the current layer's output 
* the first layer is ''input layer'', called $x$ - it takes our feature vector $x = [x_1, ..., x_n]^T$
* the last layer (3rd on the picture) is an output layer, it gives us the final result
* all layers in between are called ''hidden layers ''
* (note that bias units $x_0$ and $a_0^{(2)}$ are omitted from the picture, but they are there)



=== Mathematical Representation ===
We'll have the following notation: 
* $a_i^{(j)}$ is an ''activation of unit $i$ in layer $j$''
* $\theta^{(j)}$ - matrix of ''weights'' that control mapping from layer $j$ to $j + 1$ (i.e. $\theta_1$ is the parameters of the 2nd layer and so on)
* Neural Networks are parametrized by $\theta$s 

Mathematical representation of a neural network is (where $g$ is the sigmoid function)
* $a_1^{(2)} = g(\theta_{10}^{(1)} x_0 + \theta_{11}^{(1)} x_1 + \theta_{12}^{(1)} x_2  + \theta_{13}^{(1)} x_3)$
* $a_2^{(2)} = g(\theta_{20}^{(1)} x_0 + \theta_{21}^{(1)} x_1 + \theta_{22}^{(1)} x_2  + \theta_{23}^{(1)} x_3)$
* $a_3^{(2)} = g(\theta_{30}^{(1)} x_0 + \theta_{31}^{(1)} x_1 + \theta_{32}^{(1)} x_2  + \theta_{33}^{(1)} x_3)$
* and  $h_{\theta}(x) = a_1^{(3)} = g(\theta_{10}^{(2)} a_0^{(2)} + \theta_{11}^{(2)} a_1^{(2)} + \theta_{12}^{(2)} a_2^{(2)} + \theta_{13}^{(2)} a_3^{(2)})$

so we have 
* 3 input units $x_1, x_2, x_3$ (plus bias $x_0 = 1$)
* 3 hidden units in 1 hidden layer $a_1^{(2)}, a_2^{(2)}, a_3^{(2)}$ in layer 2 (plus bias $a_0^{(2)} = 1$)


=== Dimension of $\theta$ ===
In this example the dimension of $\theta^{(1)}$ is $\theta^{(1)} \in \mathbb{R}^{3 \times 4}$

General rule
* if a network has $s_j$ units in layer $j$ and $s_{j + 1}$ units in layer $j + 1$ , then 
* $\theta^{(i)} \in \mathbb{R}^{s_{j + 1} \times (s_{j} + 1)}$ (i.e. it has dimension $s_{j + 1} \times (s_{j} + 1)$)



== Forward Propagation ==
=== Vectorized Form ===
For the first step we have 
* $a_1^{(2)} = g(z_1^{(2)})$ where $z_1^{(2)} = \theta_{10}^{(1)} x_0 + \theta_{11}^{(1)} x_1 + \theta_{12}^{(1)} x_2  + \theta_{13}^{(1)} x_3$
* $a_2^{(2)} = g(z_2^{(2)})$, and
* $a_3^{(2)} = g(z_3^{(2)})$
* ($z_1^{(2)}, z_2^{(2)}, z_3^{(2)}$ - are ''linear combinations'' of $x_1, x_2, x_3$)


So we have 3 vectors
* $\theta^{(0)} = [\theta_0^{(0)}, \theta_1^{(0)}, \theta_2^{(0)}, \theta_3^{(0)}]^T$, 
* $x = [x_0, x_1, x_2, x_3]^T$, 
* $z^{(2)} = [z_1^{(2)},  z_2^{(2)},  z_3^{(2)}]^T$


And can rewrite the first step in a vectorized form:
* instead of $z_1^{(2)} = \theta_{10}^{(1)} x_0 + \theta_{11}^{(1)} x_1 + \theta_{12}^{(1)} x_2  + \theta_{13}^{(1)} x_3$, we write $z_1^{(2)} = \theta_1^{(1)} \cdot x$


=== Algorithm ===
* 1st step
** $z^{(2)} = \theta^{(1)} \cdot x = \theta^{(1)} \cdot a^{(1)}$ and 
** $a^{(2)} = g(z^{(2)}) \in \mathbb{R}^3$
* next step
** we add $a_0^{(2)} = 1$, so $a^{(2)} = [1, a_1^{(2)},  a_2^{(2)},  a_3^{(2)}]^T \in \mathbb{R}^{4}$
** and calculate $z^{(3)} = \theta^{(2)} \cdot a^{(2)}$
* finally 
** $h_{\theta}(x) = a^{(3)} = g(z^{(3)})$

This process is called ''forward propagation''


=== What's going on? ===
Let's have a look at the 2nd and 3rd layers of our NN 
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/nn-representation.png

* $h_{\theta} = g((\theta^{(2)})^T \cdot a^{(2)})$, and $a^{(2)}$ is given by the 2nd level units 
* so it's doing a [[Logistic Regression|logistic regression]], but it uses $a^{(2)} = [a_0^{(2)} ... a_3^{(2)}]$ for features (instead of $x$s)
* and features $a^{(2)} = [a_0^{(2)} ... a_3^{(2)}]$ are themselves learned by the previous layer 


* We can create NNs with as many layers as we want 
* The way the neurons are connected is called ''architecture''


== Multi-class Classification ==
What to do if we what to use it for multi-class classification? 
* We can have multiple output units! (similar to [[One-vs-All Classification]])

So we want 
* $h_{\theta}(x) \approx \left[\begin{matrix} 1 \\ 0 \\ 0 \\ 0\end{matrix} \right]$ if an item belongs to 1st category
* $h_{\theta}(x) \approx \left[\begin{matrix} 0 \\ 1 \\ 0 \\ 0\end{matrix} \right]$ if it belongs to 2nd category 
* and so on


https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/nn-multiclass.png


For training set ${(x^{(i)}, y^{(i)})}$
* we turn $y$ into one of $\left\{ \left[\begin{matrix} 1 \\ 0 \\ 0 \\ 0\end{matrix} \right], \left[\begin{matrix} 0 \\ 1 \\ 0 \\ 0\end{matrix} \right], \left[\begin{matrix} 0 \\ 0 \\ 1 \\ 0\end{matrix} \right], \left[\begin{matrix} 0 \\ 0 \\ 0 \\ 1\end{matrix} \right] \right\}$  - instead of $y \in \{1, 2, 3, 4\}$, 
* so, when training, we would like to have $h_{\theta}(x^{(i)}) \approx y^{(i)} \in \mathbb{R}^4$
* then we select the class with highest $h_{\theta}^{(i)}(x^{(i)})$, as in [[One-vs-All Classification]]


== Cost Function ==
Suppose we have $m$ training examples $\{(x^{(i)}, y^{(i)})\}$
* $L$ - total number of layers in network
* $S_l$ - # of units (without bias) in layer $l$
* $K = S_L$ - number of units the output layer, i.e. the network classifies $K$ classes

output $h_{\theta}(x) \in \mathbb{R}^{K}$

For example,
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/nn-3layers.png
* $L = 3$
* $S_1 = 3, S_2 = 4, K = S_3 = 3$


For [[Logistic Regression]] with [[Regularization]] we have the following cost function:

$$J(\theta) = -\cfrac{1}{m} \sum \Big[ y^{(i)} \log h_{\theta}(x^{(i)}) + (1 - y^{(i)}) \log (1 - h_{\theta}(x^{(i)})) \Big] + \cfrac{\lambda}{2m} \sum_{j = 1}^{n} \theta_j^2$$


In neural networks
* $h_{\theta}(x) \in \mathbb{R}^K$
* let $h_{\theta}(x)_i$ - be $i$th output 

So we have 

$$J(\theta) = -\cfrac{1}{m} \sum_{i = 1}^{m} \sum_{k = 1}^{K} \Big[ y_k^{(i)} \log h_{\theta}(x^{(i)})_k  + (1 - y_k^{(i)}) \log (1 - h_{\theta}(x^{(i)})_k ) \Big] + \cfrac{\lambda}{2m} \sum_{l = 1}^{L - 1} \sum_{i = 1}^{S_l} \sum_{j = 1}^{S_{l + 1}} (\theta_{ji}^{l})^2$$

here we also don't regularize bias inputs 


== Back Propagation ==
* we need to find such $\theta$ that $J(\theta)$ is minimal
* for that we can use [[Gradient Descent]] or other advanced optimization techniques 
* for GD we need to compute partial derivative $\cfrac{\partial}{\partial \theta_{ij}^{(l)}} J(\theta)$ with respect to each $\theta_{ij}^{(l)}$

''Back Propagation'' is a technique for calculating partial derivatives in neural networks


https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/nn-propagation-ex.png

suppose we have a training example $(x, y)$
: To compute cost $J(\theta)$ we use [[#Forward Propagation|Forward Propagation]] (vectorized)
* $a^{(1)} = x$
* $z^{(2)} = \theta^{(1)} \cdot a^{(1)}$
* $a^{(2)} = g(z^{(2)})$ (plus adding $a_0^{(2)} = 1$)
* $z^{(3)} = \theta^{(2)} \cdot a^{(2)}$
* $a^{(3)} = g(z^{(3)})$ (plus adding $a_0^{(3)} = 1$)
* $z^{(4)} = \theta^{(3)} \cdot a^{(4)}$
* $a^{(4)} = g(z^{(4)})$ (plus adding $a_0^{4)} = 1$)


=== Back Propagation Overview ===
To compute derivatives we use Back Propagation
* let $\delta_j^{(l)} $be &quot;error&quot; of node $j$ in layer $i$ (for $a_j^{(l)}$)
* for each output unit we compute 
** $\delta_k^{(L)} = a_j^{(L)} - y_j = h_{\theta}(x)_j - y_j$
** or, vectorized: 
*: $\delta^{(L)} = a^{(L)} - y$


next, we compute $\delta$ for all earlier layers
* $\delta^{(3)} = (\theta^{(3)})^T \cdot \delta^{(4)} * g'(z^{(3)})$
* where
** $*$ - element-wise product
** $g'(z^{(3)})$ - derivative of function $g$ in  $z^{(3)}$
** $g'(z^{(3)}) = a^{(3)} * (1 - a^{(3)})$
* $\delta^{(2)} = (\theta^{(2)})T \cdot \delta^{(3)} .* g'(z^{(2)})$
* We don't compute anything for the first layer - it's the input layer, and there can be no errors 


Our partial derivative is 
* $\cfrac{\partial}{\partial \theta_{ij}^{(l)}} J(\theta) = a_j^{(l)} \cdot \delta_i^{(l + 1)}$ 
* (here we ignore regularization parameter $\lambda$ - i.e. we assume no regularization at the moment)


=== Back Propagation Algorithm ===
We have training set $\{(x^{(i)}, y^{(i)}\}$ with $m$ training examples 

Set $\Delta_{ij}^{(l)} \leftarrow 0$ for all $l$, $i$, $j$ (it's used to compute$ \cfrac{\partial}{\partial \theta_{ij}^{(l)}} J(\theta)$ )

For each $\{(x^{(i)}, y^{(i)}\}$:
* set $a^{(1)} = x^{(i)}$
* perform Forward Propagation to compute $a^{(l)}$ for $l = 2, 3, ..., L$
* perform Back Propagation
** Using $y^{(i)}$ compute $\delta^{(L)} = a^{(L)} - y^{(i)}$
** Then compute 
*** all $\delta^{(L - 1)}, \delta^{(L - 2)}, ..., \delta^{(2)}$
*** Set $\Delta_{ij}^{(l)} \leftarrow \Delta_{ij}^{(l)} + a_j^{(l)} \delta_i^{(l + 1)} $
*** or, vectorized: 
**: $\Delta^{(l)} \leftarrow \Delta^{(l)} + \delta^{(l + 1)} (a^{(l)})^T$
* Then we calculate
** $D_{ij}^{(l)} \leftarrow \cfrac{1}{m} \delta_{ij}^{(l)} + \lambda \theta_{ij}^{(l)}$ if $j \ne 0$
** $D_{ij}^{(l)} \leftarrow \cfrac{1}{m} \delta_{ij}^{(l)}$ if $j = 0$
* That value can we used for GD:
: $\cfrac{\partial}{\partial \theta_{ij}^{(l)}} = D_{ij}^{(l)}$



To sum up, for each training example we 
* propagate forward using $x$
* we back-propagate using $y$
* add up all error units (for each $\theta$) into matrix $\Delta$


=== Intuition ===
Say we have a single training example $(x, y)$ and 1 output unit and we ignore regularization 

$\text{cost}(x, y) = y \log h_{\theta}(x) + (1 - y) \log h_{\theta}(x)$
* it calculates how well is the network doing for that training example  - how close it is to $y$?
* $\delta_j^{(l)}$ = &quot;error&quot; of cost for $a_j^{(l)}$ (unit $j$ in layer $l$)


formally, 
* $\delta_j^{(l)} = \cfrac{\partial}{\partial z_j^{(l)}} \text{cost}(x, y)$
* it's a partial derivative with respect to $z_j^{(l)}$
* they are measures how much we would like to change the NN weights in order 
** to affect intermediate values $z^{(2)}, z^{(3)}, ...,$
** and the final output $z^{(4)}$, 
** and therefore, overall cost


=== Numerical Gradient Checking ===
Implementing back-propagation can be hard and bug-prone, but we can perform Numerical Gradient Checking to test our implementation

suppose $\theta \in \mathbb{R}$
* We can estimate real slope of the derivative by calculating $J(\theta + \epsilon) - J(\theta - \epsilon)$ for small $\epsilon$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/nn-backprop-gradientcheck.png
* $\cfrac{d}{d \theta} J(\theta) \approx \cfrac{J(\theta + \epsilon) - J(\theta - \epsilon)}{2\epsilon}$
* And that will give us a numerical estimate of the gradient and that point


when $\theta \in \mathbb{R}^n$
* for partial derivative with respect to each $\theta_i$ we calculate 
* $\cfrac{\partial}{\partial \theta_1} J(\theta) \approx \cfrac{J(\theta_1 + \epsilon, \theta_2, ..., \theta_n) - J(\theta_1 - \epsilon, \theta_2, ..., \theta_n)}{2\epsilon}$
* $\cfrac{\partial}{\partial \theta_2} J(\theta) \approx \cfrac{J(\theta_1, \theta_2 + \epsilon, ..., \theta_n) - J(\theta_1, \theta_2 - \epsilon, ..., \theta_n)}{2\epsilon}$
* ...
* $\cfrac{\partial}{\partial \theta_2} J(\theta) \approx \cfrac{J(\theta_1, \theta_2, ..., \theta_n + \epsilon) - J(\theta_1, \theta_2, ..., \theta_n - \epsilon)}{2\epsilon}$

* i.e. we add and subtract only values for $\theta_i$ we calculate derivative for
* this gives us a way to numerically estimate all partial derivatives
* and then we check if this numerical estimate $\approx$ the derivative from back propagation


=== Implementation Notes ===
To implement Back Propagation use the following approach:
* Implement back propagation to compute $D^{(1)}, D^{(2)}, ...$
* Implement numerical gradient check to compute approximations of partial derivatives 
* Make sure they have similar values 
* Turn off gradient checking, use only back propagation for learning (it's much more computationally efficient)


== Random Initialization ==
* We need to have initial values for $\theta$
* In [[Logistic Regression]] we used $\theta = [0, 0, ..., 0]^T$
* It won't work for NNs

Suppose we set all $\theta_{ij}^{(l)}$ to 0
* Then we'll have same values for $a_1^{(2)} = a_2^{(2)} = ... = a_{s_2}^{(2)}$ and same for $\delta^{(2)}$
: (after each update, parameters corresponding to inputs are identical, and all hidden units will compute the same value)
* And therefore, all partial derivatives will also we equal 
* This is called ''the problem of symmetric weights'' 

We can break the symmetry with random initialization
* so, initialize each $\theta_{ij}^{(l)}$ with random value from $[-\epsilon; \epsilon]$:
* $\theta_{ij}^{(l)} \leftarrow_{r} [-\epsilon; \epsilon]$


== Implementation ==
=== Algorithm ===
* [[#Random Initialization|Randomly initialize weights]] $\theta$
* Implement [[#Forward Propagation|forward propagation]] to get $h_{\theta}(x^{(i)})$ for any $x^{(i)}$
* Implement code to compute [[#Cost Function|cost function]] $J(\theta)$
* Implement [[#Back Propagation|back propagation]] to compute partial derivatives $\cfrac{\partial}{\partial \theta_{ij}^{(l)}} J(\theta)$
* Use [[#Numerical Gradient Checking|gradient checking]] to compare numerical estimations of partial derivatives vs values from back propagation
* Use [[Gradient Descent]] or another optimization technique to minimize $J(\theta)$

'''NB''': $J(\theta)$ in non-convex and can get stuck in local minimum - but usually it's not a problem 


=== Octave ===
* [https://code.google.com/p/stolzen/source/browse/trunk/courses/coursera/Machine%20Learning/week05/mlclass-ex4/nnCostFunction.m Cost Function] (both forward propagation and back propagation)
* [https://code.google.com/p/stolzen/source/browse/trunk/courses/coursera/Machine%20Learning/week04/mlclass-ex3/predict.m One-vs-All Prediction for NN]
* [https://code.google.com/p/stolzen/source/browse/trunk/courses/coursera/Machine%20Learning/week05/mlclass-ex4/computeNumericalGradient.m Numerical Gradient Check]



== See also ==
* [[Logistic Regression]]

== Sources ==
* [[Machine Learning (coursera)]]

[[Category:Machine Learning]]</text>
      <sha1>2fbp9ishb40xzp07u4t2ajvwraevana</sha1>
    </revision>
  </page>
  <page>
    <title>Cross-Validation</title>
    <ns>0</ns>
    <id>129</id>
    <revision>
      <id>130</id>
      <timestamp>2014-06-08T20:03:37Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7605">== Test Errors ==
How you can tell that a hypothesis [[Overfitting|overfits]]? 
* plotting - not always good

We can split all the data into 2 subsets 
* training set $\approx$ '''70%''' of data, $m$ - number of examples in the training set
* testing set $\approx$ '''30%''' of data, $m_{\text{test}}$ - number of examples in the testing set

it's better to choose examples for training/testing sets randomly 


{| class=&quot;wikitable&quot; style=&quot;text-align: center;&quot;
|+ Error Metrics
! || Prediction || Classification 
|-
! Example Model 
| [[Multivariate Linear Regression|Linear Regression]] || [[Logistic Regression]]
|-
! Test Error
|colspan=&quot;2&quot; | $J_{\text{test}}(\theta) = \cfrac{1}{m_{\text{test}}} \sum \text{error} \big(h_{\theta}(x_{\text{test}}^{(i)}), y_{\text{test}}^{(i)} \big)$
|-
! $\text{error}(h_{\theta}(x), y)$
| Average Square Error &lt;br&gt; $\text{error}(h_{\theta}(x), y) = \cfrac{1}{2} (h_{\theta}(x) - y)^2$
| Misclassification Error &lt;br&gt; $\text{error}(h_{\theta}(x), y) = \left\{\begin{array}{l} 0 \text { if classification is correct} \\ 1 \text{ otherwise} \end{array}\right.$
|}



== Cross-Validation ==
Generally cross-validation is used to find the best value of some parameter
* we still have training and test sets
* but additionally we have a cross-validation set to test the performance of our model depending on the parameter


=== Motivation: [[Model Selection]] Problem ===
We have a following problem of [[Model Selection]]
: Suppose we are about to create a model and not sure what degree of polynomial to choose

So the problem
* So we want to try 10 models
* let $d$ denote the degree of polynomial 
* $d=1: h_{\theta} = \theta_0 + \theta_1 x$
* $d=2: h_{\theta} = \theta_0 + \theta_1 x + \theta_2 x^2$
* ...
* $d=10: h_{\theta} = \theta_0 + \theta_1 x + \theta_2 x^2 + ... + \theta_{10} x^{10}$

Results
* Each $d$ will give us a vector (or matrix) $\theta^{(d)}$
* Now we can try all $d$ models  and see which gives the best (lowest) $J_{\text{test}}(\theta^{(i)})$
* Let's say we decided to choose 5th model


How well this model generalize? 
* the test error is $J_{\text{test}}(\theta^{(5)})$
* but $J_{\text{test}}(\theta^{(5)})$ is a very optimistic estimate of the generalization error 
** (because the lowest/best error was picked up - so the test error might be biased towards that)
* i.e. we the extra parameter $d$ was fit to test, and it's not fair to estimate our hypothesis on the test set, because we already used that set to get the best $d$


To address that problem 
* instead of splitting the data set into 2 categories, we split into 3 sets: 
* training set ($\approx$ '''60%''')
** $x^{(i)}, y^{(i)}$, total $m$ examples
* cross-validation set (or cv, $\approx$ '''20%''')
** $x_{\text{cv}}^{(i)}, y_{\text{cv}}^{(i)}$, total $m_{\text{cv}}$ examples
* test set ($\approx$ '''20%''')
** $x_{\text{test}}^{(i)}, y_{\text{test}}^{(i)}$, total $m_{\text{test}}$ examples


Now we can define 
* ''Training error''
: $J(\theta) = J_{\text{train}}(\theta) = \cfrac{1}{2m} \sum \text{cost}(x^{(i)}, y^{(i)})$
* ''Cross-Validation error''
: $J_{\text{cv}}(\theta) = \cfrac{1}{2m_{\text{cv}}} \sum \text{cost}(x_{\text{cv}}^{(i)}, y_{\text{cv}}^{(i)})$
* ''Test Error ''
: $J_{\text{test}}(\theta) = \cfrac{1}{2m_{\text{test}}} \sum \text{cost}(x_{\text{test}}^{(i)}, y_{\text{test}}^{(i)})$


So for [[Model Selection]] to fit $d$, we 
* obtain $\theta^{(1)}, ..., \theta^{(d)}$ and select best (lowest) $J_{\text{cv}}(\theta^{(i)})$
* estimate generalization error for the test set $J_{\text{test}}(\theta^{(i)})$


=== Tuning Learning Parameter ===
General algorithm
* Split data set into
** Learning set 
** Validation set 
** Test set 
* use validation set for tuning control parameters 
* use test set only for final evaluation

Let $\gamma$ be the control parameter
* for every possible value of $\gamma$
** build a classification model $C$ using the learning set
** use the validation set to estimate the expected error rate of $C$
* select the optimal value of the control parameter 
** that is the value of $\gamma$ s.t. the error rate is minimal


=== [[Regularization]] Parameter $\lambda$ ===
Suppose now we're fitting a model with high-order polynomial 
* $h_{\theta}(x) = \theta_0 + \theta_1 x + ... + \theta_4 x^4$
* to prevent overfitting we use [[Regularization|regularization]]
* $J(\theta) = \cfrac{1}{m} \sum \text{cost}(h_{\theta}(x^{(i)}), y^{(i)}) + \cfrac{\lambda}{2m} \sum_{j=1}^{m} \theta_j^2$


https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/diagnosis-regularization.png
* (a) If $\lambda$ if large (say $\lambda = 10000$), all $\theta$ are penalized and $\theta_1 \approx \theta_2 \approx ... \approx 0$, $h_{\theta}(x) \approx \theta_0$
* (b) if $\lambda$ is intermediate, we fit well
* (c) if $\lambda$ is small (close to 0) we fit too well, i.e. we overfit


How can we chose good $\lambda$? Let's define 
* $J_{\text{train}}(\theta) = \cfrac{1}{m} \sum \text{cost}(h_{\theta}(x^{(i)}), y^{(i)})$ (same as $J(\theta)$, but without regularization)
* $J_{\text{cv}}(\theta)$ and $J_{\text{test}}(\theta)$ - same, but on cross-validation and test datasets respectively 

Now we 
* Choose a range of possible values for $\lambda$ (say 0, 0.01, 0.02, 0.04, ..., 10.24) - that gives us 12 models to checks 
* For each $\lambda^{(i)}$, 
** calculate $\theta^{(i)}$, 
** calculate $J_{\text{cv}}(\theta^{(i)})$, 
** and take $\lambda^{(i)}$ with lowest $J_{\text{cv}}(\theta^{(i)})$


After that we report the test error $J_{\text{test}}(\theta^{(i)})$



== K-Fold Cross-Validation ==
$K$-Fold Cross-Validation
If we want to reduce variability in the data
* we can perform multiple rounds of cross-validation using different partitions
* and then average the results over all the rounds

We're given a dataset $S$ sampled from the population $D$
* we partition $S$ into $K$ equal disjoint subsets $(T_1, ..., T_K)$ (typically 5-10 subsets)
* then perform $K$ steps, and at step $k$ do:
** use $R_k = S - T_k$ as the training set
** build classifier $C_k$ using $R_k$
** use $T_k$ as the test test, compute error $\delta_k = \text{error}(C_k, T_k)$
* let $\delta^* = \cfrac{1}{K} \sum_{k = 1}^K \delta_k$
** this is the expected error rate 

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/k-fold-cv.png
* note that there's only two subsets at each iteration
** and they are used to estimate the true error 


=== Tuning Learning Parameter ===
Choosing best value for parameter $\gamma$ with $K$-Fold Cross-Validation
* you have to put some data aside before training your classifier
** i.e. split your data into learning set and test set
* for every possible value of $\gamma$
** use $K$-fold Cross-Validation to estimate the expected error rate
** use the learning set as the set $S$ (and do $K$-fold Cross-Validation only on it)
* select the optimal value of $\gamma$
* and then use the test set for the final evaluation


=== Stratified K-Fold Cross-Validation ===
What if we want to preserve the class distribution over $K$ runs?
* then for each $T_i$ pick up the same proportion of labels as in the original dataset
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/k-fold-cv-strat.png
* it's very important if the test distribution is not uniform 


== See Also ==
* [[Overfitting]]
* [[Model Selection]]

== Sources ==
* [[Machine Learning (coursera)]]
* [[Data Mining (UFRT)]]
* http://en.wikipedia.org/wiki/Cross-validation_(statistics)

[[Category:Machine Learning]]
[[Category:Model Performance Evaluation]]
[[Category:Classifiers]]</text>
      <sha1>02j4hmgksw9q75jnmj6wn1ij2px6d5j</sha1>
    </revision>
  </page>
  <page>
    <title>Model Selection</title>
    <ns>0</ns>
    <id>130</id>
    <revision>
      <id>131</id>
      <timestamp>2013-08-23T11:04:59Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="410">== Model Selection ==
Model Selection is a way to fit parameters such as 
* learning rate $\alpha$ for [[Gradient Descent]]
* regularization term $\lambda$ for [[Regularization]]
* what degree of polynomial to use (see [[Cross-Validation#Cross-Validation]])
* and so on 

== Criteria for Model Selection ==
* [[Cross-Validation]]


== Sources ==
* [[Machine Learning (coursera)]]

[[Category:Machine Learning]]</text>
      <sha1>kq1zw8tg8840mluhihx8i3eaugleaat</sha1>
    </revision>
  </page>
  <page>
    <title>Machine Learning Diagnosis</title>
    <ns>0</ns>
    <id>131</id>
    <revision>
      <id>132</id>
      <timestamp>2013-08-26T12:18:52Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3193">== Machine Learning Diagnosis ==
Suppose you created a model, but when you tested it, you found that it makes large errors 

What should you try? 
* Get more training examples
* Try smaller set of features 
* Try getting additional features
* Try adding polynomial features (beware of [[Overfitting]]!)
* Try increasing [[Regularization|regularization parameter]] $\lambda$
* Try decreasing $\lambda $


''Diagnosis'' - a test that you can run to gain insights what is working with the learning algorithms and what is not, and gain guidance as how to improve the performance.


=== Evaluating a Hypothesis ===
To test if we overfit, we can perform [[Cross-Validation#Evaluating a Hypothesis|Cross-Validation]]: 
* train the model on the training set 
* check the model on the test set 



== Diagnosing Bias vs Variance ==
the main sources of problems are 
* high bias (underfit)
* high variance ([[Overfitting]])


=== Fitting Polynomial ===
How to distinguish between them and say which one of them we experience? 
* Suppose we want to fit parameter $d$ - what degree of polynomial to use (see [[Cross-Validation#Cross-Validation|here]])
* with $d = 1$ we underfit
* with $d = 2$ we are just right 
* with $d = 4$ we overfit 


We can plot the cost function errors vs degree of polynomial $d$ for 
* the training set $J_{\text{train}}(\theta)$
* the cross-validation (or test) set $J_{\text{cv}}(\theta)$

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/diagnosis-bias-variance.png

in case of bias (underfit) we have 
* both $J_{\text{train}}(\theta)$ and $J_{\text{cv}}(\theta)$ are high 
* and $J_{\text{train}}(\theta) \approx J_{\text{cv}}(\theta)$

in case of variance (overfit)
* $J_{\text{train}}(\theta)$ is low, $but J_{\text{cv}}(\theta)$ is high 
* and $J_{\text{cv}}(\theta) \gg J_{\text{train}}(\theta)$ (much greater)


=== Fitting Regularization Parameter ===
When we [[Cross-Validation#Cross-Validation for Regularization|try to find the best]] [[Regularization|Regularization parameter]] for a hypothesis we get similar curves:
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/diagnosis-regularization-curve.png
* with small $\lambda$ we have high variance
* with large $\lambda$ we have high bias


=== [[Learning Curves]] ===
[[Learning Curves]] is a technique that is used to
* sanity-check our algorithm or
* improve performance 
* [[Learning Curves#Diagnose High Bias (Underfitting)|diagnose high bias]] (underfit)
* [[Learning Curves#Diagnose High Variance (Overfitting)|diagnose high variance]] (overfit)


== What To Do Next? ==
So, depending on what kind of problem we have, we should decide what to do next

To fix high variance:
* Get more training examples
* Try smaller set of features
* Try decreasing [[Regularization|regularization parameter]] $\lambda$

To fix high bias:
* Try getting additional features
* Try adding polynomial features (beware of [[Overfitting]]!)
* Try increasing [[Regularization|regularization parameter]] $\lambda$



== See also ==
* [[Overfitting]]
* [[Learning Curves]]
* [[Model Selection]]


== Sources ==
* [[Machine Learning (coursera)]]

[[Category:Machine Learning]]</text>
      <sha1>53prx3psm0oa76m14ii1yag3w7kd94g</sha1>
    </revision>
    <revision>
      <id>772</id>
      <parentid>132</parentid>
      <timestamp>2017-04-27T20:26:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3708">== Machine Learning Diagnosis ==
Suppose you created a model, but when you tested it, you found that it makes large errors 

What should you try? 
* Get more training examples
* Try smaller set of features 
* Try getting additional features
* Try adding polynomial features (beware of [[Overfitting]]!)
* Try increasing [[Regularization|regularization parameter]] $\lambda$
* Try decreasing $\lambda$


''Diagnosis'' - a test that you can run to gain insights what is working with the learning algorithms and what is not, and gain guidance as how to improve the performance.


=== Evaluating a Hypothesis ===
To test if we overfit, we can perform [[Cross-Validation#Evaluating a Hypothesis|Cross-Validation]]: 
* train the model on the training set 
* check the model on the test set 



== Diagnosing Bias vs Variance ==
the main sources of problems are 
* high bias (underfit)
** tendency to constantly learn the same wrong thing 
** you're always missing in the same way
* high variance ([[Overfitting]])
** tendency to output random things irrespective to the input data
** you depend too much on the training data 


Dart throwing illustration:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/ds/high-variance-bias.png



=== Fitting Polynomial ===
How to distinguish between them and say which one of them we experience? 
* Suppose we want to fit parameter $d$ - what degree of polynomial to use (see [[Cross-Validation#Cross-Validation|here]])
* with $d = 1$ we underfit
* with $d = 2$ we are just right 
* with $d = 4$ we overfit 


We can plot the cost function errors vs degree of polynomial $d$ for 
* the training set $J_{\text{train}}(\theta)$
* the cross-validation (or test) set $J_{\text{cv}}(\theta)$

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/diagnosis-bias-variance.png

in case of bias (underfit) we have 
* both $J_{\text{train}}(\theta)$ and $J_{\text{cv}}(\theta)$ are high 
* and $J_{\text{train}}(\theta) \approx J_{\text{cv}}(\theta)$

in case of variance (overfit)
* $J_{\text{train}}(\theta)$ is low, $but J_{\text{cv}}(\theta)$ is high 
* and $J_{\text{cv}}(\theta) \gg J_{\text{train}}(\theta)$ (much greater)




=== Fitting Regularization Parameter ===
When we [[Cross-Validation#Cross-Validation for Regularization|try to find the best]] [[Regularization|Regularization parameter]] for a hypothesis we get similar curves:
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/diagnosis-regularization-curve.png
* with small $\lambda$ we have high variance
* with large $\lambda$ we have high bias


=== [[Learning Curves]] ===
[[Learning Curves]] is a technique that is used to
* sanity-check our algorithm or
* improve performance 
* [[Learning Curves#Diagnose High Bias (Underfitting)|diagnose high bias]] (underfit)
* [[Learning Curves#Diagnose High Variance (Overfitting)|diagnose high variance]] (overfit)


== What To Do Next? ==
So, depending on what kind of problem we have, we should decide what to do next

To fix high variance:
* Get more training examples
* Try smaller set of features
* Try decreasing [[Regularization|regularization parameter]] $\lambda$

To fix high bias:
* Try getting additional features
* Try adding polynomial features (beware of [[Overfitting]]!)
* Try increasing [[Regularization|regularization parameter]] $\lambda$



== See Also ==
* [[Overfitting]]
* [[Learning Curves]]
* [[Model Selection]]


== Sources ==
* [[Machine Learning (coursera)]]
* Domingos, Pedro. &quot;A few useful things to know about machine learning.&quot; [http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf]


[[Category:Machine Learning]]
[[Category:Model Performance Evaluation]]</text>
      <sha1>mx5xx8m9staj88zp4cq3e30orwqr3e3</sha1>
    </revision>
    <revision>
      <id>814</id>
      <parentid>772</parentid>
      <timestamp>2017-12-18T19:34:07Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3708">== Machine Learning Diagnosis ==
Suppose you created a model, but when you tested it, you found that it makes large errors 

What should you try? 
* Get more training examples
* Try smaller set of features 
* Try getting additional features
* Try adding polynomial features (beware of [[Overfitting]]!)
* Try increasing [[Regularization|regularization parameter]] $\lambda$
* Try decreasing $\lambda$


''Diagnosis'' - a test that you can run to gain insights what is working with the learning algorithms and what is not, and gain guidance as how to improve the performance.


=== Evaluating a Hypothesis ===
To test if we overfit, we can perform [[Cross-Validation#Evaluating a Hypothesis|Cross-Validation]]: 
* train the model on the training set 
* check the model on the test set 



== Diagnosing Bias vs Variance ==
the main sources of problems are 
* high bias (underfit)
** tendency to constantly learn the same wrong thing 
** you're always missing in the same way
* high variance ([[Overfitting]])
** tendency to output random things irrespective to the input data
** you depend too much on the training data 


Dart throwing illustration:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/ds/high-variance-bias.png



=== Fitting Polynomial ===
How to distinguish between them and say which one of them we experience? 
* Suppose we want to fit parameter $d$ - what degree of polynomial to use (see [[Cross-Validation#Cross-Validation|here]])
* with $d = 1$ we underfit
* with $d = 2$ we are just right 
* with $d = 4$ we overfit 


We can plot the cost function errors vs degree of polynomial $d$ for 
* the training set $J_{\text{train}}(\theta)$
* the cross-validation (or test) set $J_{\text{cv}}(\theta)$

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/diagnosis-bias-variance.png

in case of bias (underfit) we have 
* both $J_{\text{train}}(\theta)$ and $J_{\text{cv}}(\theta)$ are high 
* and $J_{\text{train}}(\theta) \approx J_{\text{cv}}(\theta)$

in case of variance (overfit)
* $J_{\text{train}}(\theta)$ is low, $but J_{\text{cv}}(\theta)$ is high 
* and $J_{\text{cv}}(\theta) \gg J_{\text{train}}(\theta)$ (much greater)




=== Fitting Regularization Parameter ===
When we [[Cross-Validation#Cross-Validation for Regularization|try to find the best]] [[Regularization|Regularization parameter]] for a hypothesis we get similar curves:
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/diagnosis-regularization-curve.png
* with small $\lambda$ we have high variance
* with large $\lambda$ we have high bias


=== [[Learning Curves]] ===
[[Learning Curves]] is a technique that is used to
* sanity-check our algorithm or
* improve performance 
* [[Learning Curves#Diagnose High Bias (Underfitting)|diagnose high bias]] (underfit)
* [[Learning Curves#Diagnose High Variance (Overfitting)|diagnose high variance]] (overfit)


== What To Do Next? ==
So, depending on what kind of problem we have, we should decide what to do next

To fix high variance:
* Get more training examples
* Try smaller set of features
* Try increasing [[Regularization|regularization parameter]] $\lambda$

To fix high bias:
* Try getting additional features
* Try adding polynomial features (beware of [[Overfitting]]!)
* Try decreasing [[Regularization|regularization parameter]] $\lambda$



== See Also ==
* [[Overfitting]]
* [[Learning Curves]]
* [[Model Selection]]


== Sources ==
* [[Machine Learning (coursera)]]
* Domingos, Pedro. &quot;A few useful things to know about machine learning.&quot; [http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf]


[[Category:Machine Learning]]
[[Category:Model Performance Evaluation]]</text>
      <sha1>58aeffi2pb51wib5mm2xcrhprkssp1c</sha1>
    </revision>
  </page>
  <page>
    <title>Learning Curves</title>
    <ns>0</ns>
    <id>132</id>
    <revision>
      <id>133</id>
      <timestamp>2013-08-26T12:11:56Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2731">== [[Learning Curves]] ==
This is a good technique (a part of [[Machine Learning Diagnosis]])
* to sanity-check a model 
* to improve performance 

A ''learning curve'' is a plot where we have two functions of $m$ ($m$ is a set size): 
* training set error $J_{\text{train}}(\theta)$, 
* the cross-validation error $J_{\text{cv}}(\theta)$


We can artificially reduce our training set size. 
* We start from $m = 1$, then $m = 2$ and so on 

So suppose we have the following model:
* $h_{\theta}(x) = \theta_0 + \theta_1 x + \theta_2 x^2$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/learning-curves-trainingset-red.png
* for each $m$ we calculate $J_{\text{train}}(\theta)$ and $J_{\text{cv}}(\theta)$ and plot the values  
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/learning-curves-grow.png
* This is the learning curve of the model


== Diagnose High Bias (Underfitting) ==
Suppose we want to fit a straight line to out data: 
: $h_{\theta}(x) = \theta_0 + \theta_1 x$

As $m$ increases we have pretty same line: 

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/learning-curves-lin.png

If we draw the learning curves, we'll have 

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/learning-curves-lin2.png

So we see that 
* as $m$ grows $J_{\text{cv}}(\theta) \to J_{\text{train}}(\theta)$
* and both errors are high 

$\Rightarrow$
If learning algorithm is suffering from high bias, getting more examples will not help

== Diagnose High Variance ([[Overfitting]]) ==
Now suppose we have a model with polynomial of very high order: 
: $h_{\theta}(x) = \theta_0 + \theta_1 x + \theta_2 x^2 + ... + \theta_{100} x^{100}$

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/learning-curves-overfit1.png
* at the beginning we very much overfit
* as we increase $m$, we still able to fit the data well


https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/learning-curves-overfit2.png

So we can see that as $m$ increases,
* $J_{\text{train}}(\theta)$ increases (we have more and more data - so it's harder and harder to fit $h_{\theta}(x)$), but it increases very slowly 
* on the other hand, $J_{\text{cv}}(\theta)$ decreases, but also very very slow 
* and there's a huge gap between these 2
* to fill that gap we need many many more training examples

$\Rightarrow$ if a learning algorithm is suffering from high variance (i.e. it overfits), getting more data is likely to help




== See also ==
* [[Machine Learning Diagnosis]]
* [[Model Selection]]
* [[Cross-Validation]]


== Sources ==
* [[Machine Learning (coursera)]]

[[Category:Machine Learning]]</text>
      <sha1>kxn7lkx7kpd07ewrz4592gg6yfaadc4</sha1>
    </revision>
  </page>
  <page>
    <title>Error Analysis</title>
    <ns>0</ns>
    <id>133</id>
    <revision>
      <id>134</id>
      <timestamp>2013-08-27T07:45:39Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1824">== Prioritizing ==
* Suppose we want to build a spam classifier 
* How we should spend time to do that? 

Options: 
* Collect more data to have more samples 
* Develop sophisticated features based on email routing etc 
* Develop sophisticated algorithm to detect misspelled words such as m0rtgage etc 

How to choose what is better? 


== Error Analysis ==
Recommended Approach 
* Start with the simplest possible algorithm (avoid premature optimization!) that you can implement quickly
** Implement it and test it on your [[Cross-Validation|cross-validation set]]
* Plot [[Learning Curves]] to decide if more data features is likely to help
* Do the Error Analysis 
** Manually examine the examples (in your CV set) that your algorithm misclassified.
** See if you spot any systematic trend in what types of examples it makes errors on


=== Example ===
$m_{\text{cv}} = 500$, and our algorithm misclassifies 100 of them 

so we manually examine the 100 errors and categorize them based on
* what type of email it is 
** pharmacy 12
** replica 4
** '''steal password 53''' - seems it's worth investing time in this category!
** other 31
* what features might help the algorithm to classify it correctly 
** deliberate misspelling 15
** unusual email routing 16
** '''unusual punctuation 32''' - so concentrate on this! 


== Numerical Evaluation ==
* Error Analysis may not be helpful for deciding if this is likely to improve performance 
* The only solution in this case is to try it and see if it works 
* But we need a numerical evaluation (e.g. [[Cross-Validation]] error) of algorithm's performance with and without the new code/idea/etc
* So we need to use [[Error Metrics]]


== See also ==
* [[Cross-Validation]]
* [[Learning Curves]]

== Sources ==
* [[Machine Learning (coursera)]]

[[Category:Machine Learning]]</text>
      <sha1>5r2zz4ov666vhh8oa3fs0pqbncr825f</sha1>
    </revision>
  </page>
  <page>
    <title>Evaluation of Binary Classifiers</title>
    <ns>0</ns>
    <id>134</id>
    <revision>
      <id>135</id>
      <timestamp>2015-04-28T19:51:23Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7962">== Evaluation of Binary Classifiers ==
Evaluation is important:
* models have to predict classes of new unlabeled data
* sometimes it's an integral part of the training process (e.g. in [[Decision Tree (Data Mining)]] for pruning) (see [[Cross Validation]])
* also it's needed when we want to compare two or more different models (see [[Meta Learning]])



=== Baseline ===
So for evaluating a classifier we need to set some baseline 
* base rate
** accuracy of a trivial classifier
** the one that always predicts the majority class 
* random rate
** accuracy of random guess
** need to have some domain knowledge to assign Random [[Distribution]]


=== Skewed Classes ===
* Suppose we have a binary classifier, e.g. cancer prediction. 
** We built some classification model $h_{\theta}(x)$
** if we have $h_{\theta}(x) = 1$, we predict cancer, and if $h_{\theta}(x) = 0$, we predict no cancer. 
* Then we find out that we have 1% errors for our classifier on test set, and 99% were correctly diagnosed 
** So the ''error rate'' is 1%
* But now suppose only 0.5% of patients have cancer 
** This is a ''skewed class'' - it's a tiny portion of another class 
* We would predict better by always returning 0 (by using the trivial classifier)
** (we'll have 0.5% error which is better than 1%)
* $\Rightarrow$ We need different evaluation metrics, not just error rate



== Confusion Matrix ==
Confusion matrix is a $2 \times 2$ [[Contingency Table]]
* We divide our predictions and mis-predictions into this matrix


{| class=&quot;wikitable&quot; align=&quot;center&quot; style=&quot;text-align:center; border:none; background:transparent;&quot;
|+ Diagnostic Testing Measures  [http://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram]
| colspan=&quot;2&quot; rowspan=&quot;2&quot; style=&quot;border:none;&quot;|
! colspan=&quot;2&quot; | Actual Class $y$
|-
| Positive
| Negative
|-
! rowspan=&quot;2&quot; | $h_{\theta}(x)$ &lt;br/&gt; Test&lt;br /&gt;outcome
| Test&lt;br /&gt;outcome&lt;br /&gt;positive
|style=&quot;background:#ccffcc;&quot;| '''True positive'''&lt;br/&gt; ($\text{TP}$)
|style=&quot;background:#eedddd;&quot;| '''False positive'''&lt;br /&gt;($\text{FP}$, Type I error)
| Precision =&lt;br /&gt; $\cfrac{\# \text{TP}}{\# \text{TP} + \# \text{FP}}$
|-
| Test&lt;br /&gt;outcome&lt;br /&gt;negative
|style=&quot;background:#eedddd;&quot;| '''False negative'''&lt;br /&gt;($\text{FN}$, Type II error)
|style=&quot;background:#ccffcc;&quot;| '''True negative'''&lt;br /&gt; ($\text{TN}$)
| Negative predictive value =&lt;br /&gt; $\cfrac{\# \text{TN}}{\# \text{FN} + \# \text{TN}}$
|-
|colspan=&quot;2&quot; style=&quot;border:none;&quot; |
| Sensitivity =&lt;br /&gt; $\cfrac{\# \text{TP}}{\# \text{TP} + \# \text{FN}}$
| Specificity =&lt;br /&gt; $\cfrac{\# \text{TN}}{\# \text{FP} + \# \text{TN}}$
| Accuracy =&lt;br /&gt; $\cfrac{\# \text{TP} + \# \text{TN}}{\# \text{TOTAL}}$
|}


Main values of this matrix:
* '''True Positive''' - we predicted &quot;+&quot; and the true class is &quot;+&quot;
* '''True Negative''' - we predicted &quot;-&quot; and the true class is &quot;-&quot;
* '''False Positive''' - we predicted &quot;+&quot; and the true class is &quot;-&quot; (Type I error)
* '''False Negative''' - we predicted &quot;-&quot; and the true class is &quot;+&quot; (Type II error)
* (see also [[Statistical Tests of Significance#Type I and Type II Errors]])


The following measures can be calculated:
* Accuracy
* Misclassification Error (or Error Rate)
* Positive predictive value (or precision)
** $P = \cfrac{\text{TP}}{\text{TP} + \text{FP}}$
* Negative predictive value
* True Positive Rate (also Sensitivity or Recall)
** Fraction of positive examples correctly classified 
** $\text{tpr} = \cfrac{\text{TP}}{\text{TP} + \text{FN}}$  
* False Positive Rate (also Fall-Out)
** Fraction of negative examples incorrectly classified
** $\text{fpr} = \cfrac{\text{FP}}{\text{FP} + \text{TN}}$  
* Specificity
* Support - fraction of positively classified examples
** $\text{sup} = \cfrac{\text{TP} + \text{FP}}{N} = \cfrac{\text{predicted pos}}{\text{total}}$



=== Accuracy and Error Rate ===
In practice, these are the most widely used metrics
* Accuracy: $\text{acc} = \cfrac{TP + TN}{N}$
** fraction of correctly classified examples
* Error Rate: $\text{error} = \cfrac{FN + FP}{N} = 1 - \text{acc}$
** Fraction of misclassified examples 


=== Precision ===
For all input data that we predicted $h_{\theta}(x) = 1$ what fraction actually have $y = 1$?

$P = \text{Precision} = \cfrac{\text{# TP}}{\text{# predicted positives}} = \cfrac{\text{# TP}}{\text{# TP} + \text{# FP}}$

* Out of all the people we thought have cancer, how many actually had it? 
* High precision is good
* we don't tell many people that they have cancer when they actually don't 


=== Recall ===
For all input data that actually have $y = 1$, what fraction did we correctly detect as $h_{\theta}(x) = 1$?

$R = \text{Recall} = \cfrac{\text{# TP}}{\text{# actual positives}} = \cfrac{\text{# TP}}{\text{# TP + # FN}}$

* Out of all the people that do actually have cancer, how much we identified? 
* The higher the better:
* We don't fail to spot many people that actually have cancer


* For a classifier that always returns zero (i.e. $h_{\theta}(x) = 0$) the Recall would be zero
* That gives us more useful evaluation metric
* And we're much more sure 


The [[F Measure]] is a combination of [[Precision and Recall]]


=== Example ===

{| class=&quot;wikitable&quot; style=&quot;text-align:center; border:none; background:transparent;&quot;
|+ Diagnostic Testing Wikipedia Example [http://en.wikipedia.org/wiki/Template:DiagnosticTesting_Example]
|colspan=&quot;2&quot; rowspan=&quot;2&quot; style=&quot;border:none;&quot;|
|colspan=&quot;2&quot; style=&quot;background:#eeeebb;&quot;|'''Patients with bowel cancer&lt;br /&gt;(as confirmed on endoscopy)'''
|-
|style=&quot;background:#ffffcc;&quot;| Positive
|style=&quot;background:#ddddaa;&quot;| Negative
|-
|rowspan=&quot;2&quot; style=&quot;background:#bbeeee;&quot;|'''Fecal&lt;br /&gt;Occult&lt;br /&gt;Blood&lt;br /&gt;Screen&lt;br /&gt;Test&lt;br /&gt;Outcome'''
|style=&quot;background:#ccffff;&quot;|Test&lt;br /&gt;Outcome&lt;br /&gt;Positive
|style=&quot;background:#ccffcc;&quot;|&lt;span style=&quot;color:#006600;&quot;&gt;'''True Positive'''&lt;/span&gt;&lt;br /&gt;(TP) = 20
|style=&quot;background:#eedddd;&quot;|&lt;span style=&quot;color:#cc0000;&quot;&gt;'''False Positive'''&lt;/span&gt;&lt;br /&gt;(FP) = 180
|style=&quot;background:#ccffff;&quot;|Positive predictive value&lt;div style=&quot;text-align:left; margin-left:1em;&quot;&gt;= TP / (TP + FP)&lt;br /&gt;= 20 / (20 + 180)&lt;br /&gt;= '''10%'''&lt;/div&gt;
|-
|style=&quot;background:#aadddd;&quot;|Test&lt;br /&gt;Outcome&lt;br /&gt;Negative
|style=&quot;background:#eedddd;&quot;|&lt;span style=&quot;color:#cc0000;&quot;&gt;'''False Negative'''&lt;/span&gt;&lt;br /&gt;(FN) = 10
|style=&quot;background:#bbeebb;&quot;|&lt;span style=&quot;color:#006600;&quot;&gt;'''True Negative'''&lt;/span&gt;&lt;br /&gt;(TN) = 1820
|style=&quot;background:#aadddd;&quot;|Negative predictive value&lt;div style=&quot;text-align:left; margin-left:1em;&quot;&gt;= TN / (FN + TN)&lt;br /&gt;= 1820 / (10 + 1820)&lt;br /&gt;&amp;asymp; '''99.5%'''&lt;/div&gt;
|-
|colspan=&quot;2&quot; style=&quot;border:none;&quot; |
|style=&quot;background:#ffffcc;&quot;|Sensitivity&lt;div style=&quot;text-align:left;&quot;&gt;= TP / (TP + FN)&lt;br /&gt;= 20 / (20 + 10)&lt;br /&gt;&amp;asymp; '''67%'''&lt;/div&gt;
|style=&quot;background:#ddddaa;&quot;|Specificity&lt;div style=&quot;text-align:left;&quot;&gt;= TN / (FP + TN)&lt;br /&gt;= 1820 / (180 + 1820)&lt;br /&gt;= '''91%'''&lt;/div&gt;
|}




== Visual Analysis ==
Visual ways of evaluating the performance of a classifier
* [[ROC Analysis]] - True Positive Rate vs False Positive Rate
* [[Cumulative Gain Chart]]s - True Positive Rate vs Predicted Positive Rate



== Not Binary Classifiers ==
When we have multi-class classifiers we can use:
* [[Contingency Table]]
** just show misclassified examples side-by-side
* [[Cost Matrix]]
** we define the cost for each misclassification 
** and calculate the total cost
* some measures can be extended to multiclass classifiers: 
** see [[Evaluation of Multiclass Classifiers]]


== See Also ==
* [[Statistical Tests of Significance]]


== Sources ==
* [[Machine Learning (coursera)]]
* [[Data Mining (UFRT)]]
* http://en.wikipedia.org/wiki/Binary_classification#Evaluation_of_binary_classifiers
* http://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram
* http://en.wikipedia.org/wiki/Template:DiagnosticTesting_Example
* [[Introduction to Data Science (coursera)]]

[[Category:Machine Learning]]
[[Category:Classifiers]]
[[Category:Model Performance Evaluation]]</text>
      <sha1>pa1qnmsq212lb422otj776erpeeuvae</sha1>
    </revision>
  </page>
  <page>
    <title>Support Vector Machines</title>
    <ns>0</ns>
    <id>135</id>
    <revision>
      <id>136</id>
      <timestamp>2013-12-17T20:14:19Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13133">== Support Vector Machines ==

== SVM vs Logistic Regression ==
Recall [[Logistic Regression]]:
* the hypothesis is of the form $h_{\theta}(x) = g(\theta^T x) = \cfrac{1}{1 + e^{-\theta^T x}}$
** if $y = 1$ we want $h_{\theta}(x) \approx 1$, or $\theta^T x \gg 0$
** if $y = 0$ we want $h_{\theta}(x) \approx 0$, or $\theta^T x \ll 0$

=== Cost Function ===
[[Logistic Regression]] cost function is 
* $\text{cost}(h_{\theta}(x), y) = \left\{\begin{array}{l l} -\log(h_{\theta}(x)) &amp; \text{ if } y = 1 \\ - \log(1 - h_{\theta}(x)) &amp; \text{ if } y = 0 \end{array} \right. $
* let's have a look at contribution of each part of the cost function:
** $- \log \cfrac{1}{1 + e^{-z}}$: if $y = 1$, it gives $\theta^T x \gg 0$
** $- \log \left(1 - \cfrac{1}{1 + e^{-z}} \right)$: if $y = 0$, it gives $\theta^T x \ll 0$

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/svm-vs-lr-cost.png

Let's change that function onto 2 straight lines: 
* one with some slope, 
* and second is flat (see the picture) 

That gives us 
* an approximation of the regression function
* computational advantages and 
* easier optimization


=== Objective Function ===
for [[Logistic Regression]] we had 
* $J(\theta) = \cfrac{1}{m} \sum_{i = 1}^{m} \left [ y^{(i)} \cdot \text{cost}_{1}(\theta^T x^{(i)}) + (1 - y^{(i)}) \cdot \text{cost}_{0}(\theta^T x^{(i)})    \right]  + \cfrac{\lambda}{2m} \sum_{j = 1}^{n} \theta_j^2$
** where $\text{cost}_{1}(\theta^T x^{(i)})$ and $\text{cost}_{0}(\theta^T x^{(i)})$ are logarithmic cost functions for $y = 1$ and $y = 0$ respectively. 
* Let's change them onto svm's cost functions $\text{cost}_{1}(\theta^T x^{(i)})$ and $\text{cost}_{0}(\theta^T x^{(i)})$
* Now, to transform it to svm's objective function:
** we multiply it by $m$, 
** divide by $\lambda$, 
** and let $C = \cfrac{1}{\lambda}$

Finally we have: 
* $J(\theta) = C \cdot \sum_{i = 1}^{m} \left [ y^{(i)} \cdot \text{cost}_{1}(\theta^T x^{(i)}) + (1 - y^{(i)}) \cdot \text{cost}_{0}(\theta^T x^{(i)})    \right]  + \cfrac{1}{2} \sum_{j = 1}^{n} \theta_j^2$
* This is just different convention and it doesn't change the value of $\theta$ that minimizes this function

=== Hypothesis ===
The final difference is that 
* [[Logistic Regression]] outputs probabilities 
* but for SVM out hypothesis is 
: $h_{\theta}(x) = \left\{ \begin{array}{l l} 1 &amp; \text{ if  } \theta^T x \geqslant 0 \\ 0 &amp; \text{ otherwise }   \end{array} \right.$


== Large Margin ==
Here's the SVM cost functions:
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/svm-cost.png

Large margin means that 
* when $y = 1$ we want $\theta^T x \geqslant 1$, not just $\geqslant 0$
* when $y = 0$ we want $\theta^T x \leqslant -1$, not just $&lt; 0$

That gives larger margin for SVM


=== SVM Decision Boundary ===
* SVM sometimes is referred as Large Margin classifier 
* The reason for that is SVM tries to find a decision boundary that has the widest distance (''margin'' from the dataset samples)
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/svm-margin.png
* here we see the margin


When $C$ is big, the algorithm becomes sensitive to outliers, decreasing $C$ makes it less sensitive
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/svm-outliers.png


=== Math Behind It ===
For SVM, suppose our cost function is 
* $J(\theta) = \cfrac{1}{2} \sum_{j = 1}^{n} \theta_j^2$ s.t. 
** $\theta^T x^{(i)} \geqslant 1$ if $y^{(i)} = 1$ and 
** $\theta^T x^{(i)} \leqslant -1$ if  $y^{(i)} = 0$
* For simplification we skip the fist term of our sum and we assume that $\theta_0 = 0$ and number of features $n = 2$
* $\theta^2 = \theta^T \theta$ is an [[Inner Product]]
* so we get:
: $J(\theta) = \cfrac{1}{2} \sum_{j = 1}^{n} \theta_j^2 = \cfrac{1}{2} (\theta_1^2 + \theta_2^2) = \cfrac{1}{2} \left( \sqrt{\theta_1^2 + \theta_2^2} \right)^2 = \cfrac{1}{2} \| \theta \|^2$
* our optimization objective is to minimize the norm of $\theta$! 


Next, let's have a look at  $\theta^T \cdot x^{(i)}$
* this is [[Inner Product]] as well
* let $p^{(i)}$ be projection from $x^{(i)}$ to $\theta$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/svm-vectors-projection_training.png
* $\theta^T \cdot x^{(i)} = \theta_1 x_1^{(i)} + \theta_2 x_2^{(i)} $
* It means that we can replace the constraints $\theta^T x^{(i)} \geqslant 1$ on $p^{(i)} \| \theta \|  \geqslant 1$

Thus we get the following optimization objective: 
* $\min_{\theta} \cfrac{1}{2} \sum_{j = 1}^{n} \theta_j^2$, s.t. 
** $p^{(i)} \cdot \| \theta \| \geqslant 1$ if $y^{(i)} = 1$
** $p^{(i)} \cdot \| \theta \| \leqslant -1$ if $y^{(i)} = 0$


Suppose we have the following decision boundary

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/svm-decision-boundary-bad.png

But SVM will never give us such line
* both $p^{(1)}$ and $p^{(2)}$ are small numbers (see the picture)
* $\Rightarrow$ $\| \theta \|$ has to be large!


Let's now imagine that SVM chooses 
* $OY$ axis as a decision boundary and 
* vector $\theta$ is orthogonal - goes along $OX$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/svm-decision-boundary-good.png

Here again we have 
* $p^{(1)} &gt; 0$ and $p^{(2)} &lt; 0$, but they are much bigger now 
* $\| \theta \|$ doesn't have to be big 

That is how SVM gets large margins: because our projections are large. 


As a simplification, we assumed $\theta_0 = 0$
* which just means that the boundary always goes through the origin (0, 0)
* if $\theta_0 \neq 0$, it will simply mean that the boundary doesn't pass (0, 0) but otherwise works in exactly same way


== Kernels ==
''Kernels'' is a technique for using a SVN as a complex, non-linear classifier 

Suppose we have the following data
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/svm-kernels-nonlinear.png
* The decision boundary is non linear 
* so we predict $y = 1$ if 
: $\theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_1 x_2 + \theta_4 x_1^2 + + \theta_5 x_2^2 + ... \geqslant 0$

Let's denote each feature as $f$:
* $f_1 = x_1$, $f_2 = x_2 $, $f_3 = x_1 x_2$, $f_4 = x_1^2$, $f_5 = x_2^2$
* So we have 
: $\theta_0 + \theta_1 f_1 + \theta_2 f_2 + \theta_3 f_1 f_2 + \theta_4 f_1^2 + \theta_5 f_2^2 + ... \geqslant 0$


Is there a different / better choice of features $f_1, f_2, f_3, ...$? 

=== Similarity ===
Say our $x \in \mathbb{R}^2$
* We may pick up 3 data points, or ''landmarks'': $l^{(1)}, l^{(2)}, l^{(3)}$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/svm-kernels-landmarks.png
* So given a new $x$ we compute new features as proximity to these $l^{(1)}$, $l^{(2)}$ and $l^{(3)}$

We compute $f_1$, $f_2$ and $f_3$ as follows: 
* $f_1 = \text{similarity}(x, l^{(1)})$
* $f_2 = \text{similarity}(x, l^{(2)})$
* $f_3 = \text{similarity}(x, l^{(3)})$

These similarity functions are called ''Kernels''


== Gaussian Kernel ==
As a similarity function we  may use a ''Gaussian Kernel'': 
* $\text{similarity}(x, l) = \exp \left( \cfrac{\| x - l \|^2 }{2 \cdot \sigma^2} \right)$
* where $\| x - l \|^2 = \sum_{j = 1}^n (x_j - l_j)^2$

Similarity
* Suppose $x$ is close to $l^{(1)}$, i.e. $x \approx l^{(1)}$,
** then the Euclidean distance will be close to 0
** or $f_1 \approx e^0 \approx 1$
* if $x$ is far from $l^{(1)}$ then 
** $f_1 \approx \exp \left( \cfrac{(\text{large number})^2}{2 \sigma^2} \right) \to 0$

So each $l^{(1)}, l^{(2)}, l^{(3)}$ defines a feature $f^{(1)}, f^{(2)}, f^{(3)}$ respectively 

parameter $\sigma^2$:
* and $\sigma^2$ defines how narrow the gaussian kernels are
* so here's an example with $\sigma^2 = 1$, $\sigma^2 = 0.5$ and $\sigma^2=3$:
* http://stolzen.googlecode.com/svn/trunk/courses/coursera/Machine%20Learning/figures/svm-kernels-sigma.jpg

Now given $x$ we can compute all these features 


=== Example ===
Suppose we have the following model:
* $\theta_0 + \theta_1 f_1 + \theta_2 f_2 + \theta_3 f_3 \geqslant 0$
* let's say we have the following $\theta$:
: $\theta_0 = -0.5, \theta_1 = 1, \theta_2 = 1, \theta_3 = 0$
* which gives us the following contour:
: https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/svm-kernels-landmarks-with.png


Say we have a $x$ near $l^{(1)}$ (green one on the left)
* we have $f^{(1)} \approx 1, f^{(2)} \approx 0, f^{(3)} \approx 0$
* putting it to the model we get
* $\theta_0 + \theta_1 f_1 + \theta_2 f_2 + \theta_3 f_3 \approx -0.5 + 1 = 0.5 \geqslant 0$
* so we predict $y = 1$

Next, say we have a $x$ close to $l^{(3)}$ (blue one on the bottom), 
* so $f^{(1)} \approx 0, f^{(2)} \approx 0, f^{(3)} \approx 1$, and we have 
* $\theta_0 + \theta_1 f_1 + \theta_2 f_2 + \theta_3 f_3 \approx -0.5 &lt; 0 $
* so we predict $y = 0$


Thus in this example 
* for points near $l^{(1)}$ and $l^{(2)}$ we end up predicting $y = 1$
* in other cases we predict $y = 0$


=== Choosing Landmarks ===
How to choose the landmarks? 
* Suppose we have $m$ training examples $\{(x^{(i)}, y^{(i)})\}$ 
* Now we just put a landmark at the exactly same locations, i.e. l^{(i)} = x^{(i)}
* And we'll end up with $m$ landmarks $l^{(i)}$

=== Usage Notes ===
* We need to perform [[Feature Scaling]] before applying Gaussian Kernel, or one feature may dominate over others.



=== Other Kernels ===
Mercer's Theorem 
* Not all similarity functions are valid kernels: they have to satisfy a condition called Mercer's Theorem 
* It makes sure they run correctly and don't diverge (to support optimization)

Other kernels:
* No Kernel (or linear kernel)
** predict &quot;$y = 1$&quot; if $\theta^T x \geqslant 0$
** standard linear classifier
* Polynomial Kernel
* String Kernel
* Chi-square Kernel 
and so on


== Training ==
* Given example $x^{(i)}$ we compute 
** $f_1^{(i)} = \text{similarity}(x^{(i)}, l^{(1)})$
** $f_2^{(i)} = \text{similarity}(x^{(i)}, l^{(2)})$
** ...
** $f_m^{(i)} = \text{similarity}(x^{(i)}, l^{(m)})$
* And we also add an extra feature $f_0 = 1$ (intercept term)
* That gives us a feature vector $f^{(i)} = [f_0^{(i)}, f_1^{(i)}, ..., f_m^{(i)}]^T \in \mathbb{R}^{m + 1}$
* somewhere in this list we'll have a feature $f_i^{(i)} = \text{similarity}(x^{(i)}, l^{(i)}) = 1$

=== Getting $\theta$ ===
* To get $\theta$ we need to train our classifier
* recall that our objective function is 
: $\min_{\theta}  C \cdot \sum_{i = 1}^{m} \left [ y^{(i)} \cdot \text{cost}_{1}(\theta^T x^{(i)}) + (1 - y^{(i)}) \cdot \text{cost}_{0}(\theta^T x^{(i)})    \right]  + \cfrac{1}{2} \sum_{j = 1}^{n} \theta_j^2$
* with Kernels, we now have $n = m + 1$ features 

Let's take a closer look at the second term
* as we know, this is an [[Inner Product]]:
* $\sum_{j = 1}^{n} \theta_j^2 = \| \theta \|^2 = \theta^T \theta$
* In reality, for SVM implementation a re-scaled version is often used: 
** $\theta^T \cdot M \cdot  \theta$
** which is a numerical optimization trick


== Additional Notes ==
=== Hypothesis ===
Given $x$, 
* compute features $f \in \mathbb{R}^{m + 1}$ 
* and predict $y = 1$ if $\theta^T f \geqslant 0$
* ($\theta$ also $\in \mathbb{R}^{m + 1}$)

=== SVM parameters ===
SVM has two parameters
* $C$ (which is equivalent to $\cfrac{1}{\lambda}$  where $\lambda$ is a [[Regularization]] term)
** large $C$: lower bias, higher variance (same as small $\lambda$): prone to [[Overfitting|overfitting]]
** small $C$: higher bias, lower variance (same as big $\lambda$): prone to underfitting
* $\sigma^2$ for Gaussian Kernels 
** large $\sigma^2$: features $f_i$ vary more smoothly, results in higher bias, lower variance
** small $\sigma^2$: features $f_i$ vary less smoothly, results in lower bias, higher variance

see also [[Machine Learning Diagnosis]]

=== Multi-Class Classification ===
Use [[One-vs-All Classification]]: 
* Train $K$ SVMs, each to distinguish $y = i$ from the rest
* Get $\theta^{(1)}, \theta^{(2)}, ..., \theta^{(K)}$
* Pick class $i$ with largest $(\theta^{(i)})^T x$


== SVN vs Other Classifiers ==
=== vs [[Logistic Regression]] ===
Suppose we have 
* $n$ features ($x \in \mathbb{R}^{n + 1}$)
* $m$ training examples 

if $n$ is large (relative to $m$)
* e.g. $n = 10000$, $m \in [10, 1000]$
* use [[Logistic Regression]]
* or SVM without kernel 

if $n$ is small, $m$ in intermediate 
* e.g. $n \in [1, 1000], m \in [10, 10000]$
* Use SVM with Gaussian Kernel

if $n$ is small, m is large
* say $n \in [1, 1000], m = 50000+ $
* SVM is too slow for that 
* create more features 
* then use [[Logistic Regression]] or SVM without a kernel 

[[Logistic Regression]] and SVM without a kernel are pretty similar and have similar performance

=== vs [[Neural Networks]] ===
* [[Neural Networks]] are likely to work for all these cases, but they are slower to train.
* SVM models always have global optimum, whereas [[Neural Networks]] have local optima


== See also ==
* [[Logistic Regression]]
* [[Machine Learning Diagnosis]]
* [[One-vs-All Classification]]

== Links ==
* http://www.tristanfletcher.co.uk/SVM%20Explained.pdf

== Sources ==
* [[Machine Learning (coursera)]]

[[Category:Kernel Methods]]
[[Category:Machine Learning]]</text>
      <sha1>137fr6fqpkp6xeq90zilj7pea5g56en</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Algebra</title>
    <ns>14</ns>
    <id>136</id>
    <revision>
      <id>137</id>
      <timestamp>2013-08-30T10:22:35Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24">[[Category:Mathematics]]</text>
      <sha1>b9vk507szcbw6tn1xarrdf31jl1qtsn</sha1>
    </revision>
  </page>
  <page>
    <title>Dot Product</title>
    <ns>0</ns>
    <id>137</id>
    <revision>
      <id>138</id>
      <timestamp>2015-05-23T10:09:58Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4992">== Dot Product ==

== Geometric Definition ==
Let $\vec v \cdot \vec w$ denote the ''dot product'' between vectors $\vec v$ and $\vec w$
* definition: $\vec v \cdot \vec w = \| \vec v \| \cdot \| \vec w \| \cdot \cos \theta$ where $\theta$ is the angle between $\vec v$ and $\vec w$
* $\| \vec v \|$ denotes the length of $\vec v$
* if two vectors are perpendicular, then $\cos \theta = 0$ and thus $\vec v \cdot \vec w = 0$
* if they co-directional, then $\theta = 0$ and $\vec v \cdot \vec w = \| \vec v \| \cdot \| \vec w \|$
* consequently, we have $\vec v \cdot \vec v = \| \vec v \|^2$

http://habrastorage.org/files/4a7/cd6/a98/4a7cd6a988b24d629f728b7216536b07.png


=== Projections ===
Dot product is a projection:
* let's project $\vec v$ onto $\vec w$: $\text{proj}_{\vec w} (\vec v) = \| \vec v \| \cos \theta$ (by the $\cos$ definition)
* we're interested only in the direction of $\vec w$, so let's normalize it to get $\hat w = \vec w / \| \vec w \|$ - it's the unit vector in the direction $\vec w$
* $\vec v \cdot \hat w$ - dot product of $\vec v$ and some unit vector
** $\vec v \cdot \hat w = \| \hat w \| \| \vec v \| \cos \theta = \| \vec v \| \cos \theta$
** it is a projection in the direction of $\vec w$ 
* so $\vec v \cdot \hat w$ corresponds to the projection of $\vec v$ onto $\vec w$
* $\text{proj}_{\vec w} (\vec v) = \vec v \cdot \hat w = \| \vec v \| \cos \theta$ - is the length of this projection
* thus, $\vec v \cdot \vec w = \| \vec v \|  \| \vec w \| \cos \theta = \| \vec w \|  \cdot \text{proj}_{\vec w} (\vec v) = \| \vec v \| \cdot \text{proj}_{\vec v} (\vec w)$



$p = \text{proj}_{\vec u} (\vec v) = \vec v \cdot \hat u = \| \vec v \| \cos \theta$
* it can be positive or negative
* positive when angle between vectors is less than $90^o$
* negative when angle between vectors is greater than $90^o$

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/svm-vectors-projection.png



=== The Cosine Theorem ===
Why does this geometric definition make sense?

* consider vectors $\vec u$, $\vec v$ and $\vec w$
* let $\vec v + \vec u = \vec w$ or $\vec u = \vec w - \vec v$
* http://habrastorage.org/files/d9f/8b1/073/d9f8b10734864b92bdcf9cf5ac92a0dc.png
* $\| \vec u \|^2 =  \| \vec w - \vec v \|^2 = (\vec w - \vec v) \cdot (\vec w - \vec v) = \| \vec w \|^2 + \| \vec v \|^2 - 2 \cdot \vec w \vec v$
* by the Cosine Theorem we know that 
** $\| \vec u \|^2 =  \| \vec w - \vec v \|^2 = \| \vec w \|^2 + \| \vec v \|^2 - 2 \cdot \| \vec w \| \cdot \| \vec v \| \cdot \cos \theta$ 
** so $\| \vec w \| \cdot \| \vec v \| \cdot \cos \theta = \cfrac{1}{2} (\| \vec w \|^2 + \| \vec v \|^2 - \| \vec w - \vec v \|^2) = \cfrac{1}{2} (\| \vec w \|^2 + \| \vec v \|^2 - \| \vec w \|^2 - \| \vec v \|^2 + 2 \cdot \vec w \vec v) = \vec w \cdot \vec v$
* thus $\vec w \cdot \vec v = \| \vec w \| \cdot \| \vec v \| \cdot \cos \theta$
* i.e. the definition makes sense from the The Cosine Theorem point of view



== Algebraic Definition ==
For two vectors $\mathbf v, \mathbf w \in \mathbb R^n$ we define the dot product as $\mathbf v^T \mathbf w = \sum\limits_{i = 1}^n v_i w_i$


=== [[Vector Orthogonality]] ===
$\mathbf v \; \bot \; \mathbf w \iff \mathbf v^T \mathbf w = 0$

Why?
* by the Pythagoras theorem: $\| \mathbf v \|^2 + \| \mathbf w \|^2 = \| \mathbf v + \mathbf w \|^2$
* $\mathbf v^T \mathbf v + \mathbf w^T \mathbf w = (\mathbf v + \mathbf w)^T (\mathbf v + \mathbf w) = \mathbf v^T \mathbf v + \mathbf v^T \mathbf w + \mathbf w^T \mathbf v + \mathbf w^T \mathbf w$
* or $\mathbf v^T \mathbf w + \mathbf w^T \mathbf v = 0$
* note that $\mathbf v^T \mathbf w = \mathbf w^T \mathbf v$, so we have 
* $2 \mathbf v^T \mathbf w = 0$ or $\mathbf v^T \mathbf w = 0$



== Equivalence of Definitions ==
Both definitions are equivalent. 

I.e. $\vec v \cdot \vec w = \mathbf v^T \mathbf w = \| \vec v \| \| \vec w \| \cos \theta = \sum\limits_{i = 1}^n v_i w_i$

Why? 
* let $\vec e_1, \ ... \ , \vec e_n$ be the standard basis in $\mathbb R^n$
* these vectors are orthonormal, i.e. $\vec e_i \cdot \vec e_j = \begin{cases} 
1 &amp; \text{if } i = j \\
0 &amp; \text{if } i \ne j \\
\end{cases}$
* let's consider a dot product $\vec v \cdot \vec e_i$: $\vec v \cdot \vec e_i = \| \vec v \| \cos \theta = v_i$ - it's a projection of $\vec v$ onto $ \vec e_i$ - which is $i$th component of $\vec v$
* we can project $\vec v$ and $\vec w$ onto the entire basis and get
* $\vec v = \sum\limits_{i = 1}^n v_i \cdot \vec e_i$ and $\vec w = \sum\limits_{i = 1}^n w_i \cdot \vec e_i$
* So, $\vec v \cdot \vec w = \vec v \cdot \sum\limits_{i = 1}^n w_i \vec e_i = \sum\limits_{i = 1}^n w_i (\vec v \cdot \vec e_i) = \sum\limits_{i = 1}^n v_i w_i$

$\square$


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* [[Machine Learning (coursera)]]
* http://en.wikipedia.org/wiki/Dot_product
* http://math.oregonstate.edu/bridge/papers/dot+cross.pdf
* http://en.wikipedia.org/wiki/Law_of_cosines

[[Category:Linear Algebra]]
[[Category:Geometry]]</text>
      <sha1>gv9yz4m9vka4ywk908wxywnlbqfvuc7</sha1>
    </revision>
  </page>
  <page>
    <title>Feature Normalization</title>
    <ns>0</ns>
    <id>138</id>
    <revision>
      <id>139</id>
      <timestamp>2014-05-12T09:32:06Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1185">== Data Normalization ==
Typically, ''normalization'' refers to
* transforming all values of some continuous variable to the same scale
* it's done at the [[Data Transformation]] stage

There are several approaches 
* Min-Max
* $Z$-score


== Min-Max Normalization ==
Min-max normalization
* normalize to scale $[\text{new_min}_A, \text{new_max}_A]$
* for each new value, calculate $v'= \cfrac{v - \text{min}_A}{\text{max}_A - \text{min}_A} \cdot (\text{new_max}_A - \text{new_min}_A) + \text{new_min}_A$
* the easiest model
* not always good - if there are [[outliers]] 

Example
* income range between 12K to 98K
* want to normalize to $[0.0, 1.0]$. 
* so, for 73K have $\cfrac{73-12}{98-12} \approx 0.716$


== $Z$-score Normalization ==
$v'= \cfrac{v - \mu_A}{\sigma_A}$
* $\mu_A$ is [[Mean]] of $A$ and $\sigma_A$ is [[Standard Deviation]]
* less susceptible to outliers 

Example 
* Assume that $\mu = 54K$ and $\sigma = 16K$
* So 73K becomes 1.225 


== Usages ==
* to help [[Gradient Descent]] converge faster, typically normalize to $[-1, 1]$ 


== Sources ==
* [[Data Mining (UFRT)]]
* [[Machine Learning (coursera)]]

[[Category:Data Transformation]]
[[Category:Statistics]]</text>
      <sha1>bj2fsvcj8kue5y1l37var04y6zbcb8x</sha1>
    </revision>
    <revision>
      <id>702</id>
      <parentid>139</parentid>
      <timestamp>2015-11-23T13:33:00Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <comment>Alexey moved page [[Data Normalization]] to [[Feature Normalization]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1185">== Data Normalization ==
Typically, ''normalization'' refers to
* transforming all values of some continuous variable to the same scale
* it's done at the [[Data Transformation]] stage

There are several approaches 
* Min-Max
* $Z$-score


== Min-Max Normalization ==
Min-max normalization
* normalize to scale $[\text{new_min}_A, \text{new_max}_A]$
* for each new value, calculate $v'= \cfrac{v - \text{min}_A}{\text{max}_A - \text{min}_A} \cdot (\text{new_max}_A - \text{new_min}_A) + \text{new_min}_A$
* the easiest model
* not always good - if there are [[outliers]] 

Example
* income range between 12K to 98K
* want to normalize to $[0.0, 1.0]$. 
* so, for 73K have $\cfrac{73-12}{98-12} \approx 0.716$


== $Z$-score Normalization ==
$v'= \cfrac{v - \mu_A}{\sigma_A}$
* $\mu_A$ is [[Mean]] of $A$ and $\sigma_A$ is [[Standard Deviation]]
* less susceptible to outliers 

Example 
* Assume that $\mu = 54K$ and $\sigma = 16K$
* So 73K becomes 1.225 


== Usages ==
* to help [[Gradient Descent]] converge faster, typically normalize to $[-1, 1]$ 


== Sources ==
* [[Data Mining (UFRT)]]
* [[Machine Learning (coursera)]]

[[Category:Data Transformation]]
[[Category:Statistics]]</text>
      <sha1>bj2fsvcj8kue5y1l37var04y6zbcb8x</sha1>
    </revision>
  </page>
  <page>
    <title>K-Means</title>
    <ns>0</ns>
    <id>139</id>
    <revision>
      <id>140</id>
      <timestamp>2015-07-09T16:16:16Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11466">== $K$-Means ==
This is the most popular [[Cluster Analysis|clustering]] algorithm 


== Lloyd Algorithm ==
Lloyd algorithm is the most popular way of implementing k-means 


=== Algorithm ===
* First we choose $k$ - the number of clusters we want to get
* Then we randomly initialize k cluster centers (cluster centroids)

This is an iterative algorithm, and on each iteration it does 2 things 
* cluster assignment step
* move centroids step

Cluster Assignment Step:
* go through each example and choose the closest centroids 
* and assign the example to it

Move Centroids Step:
* Calculate the average for each group
* and move the centroids there

Repeat this until converges 


=== Pseudo Code ===
$k$-means($k$, $\{ \mathbf x_i \}$):
* randomly initialize $k$ cluster centroids $\boldsymbol \mu = \Big( \mu_1, \mu_2, \, ... \, , \mu_k \Big) \in \mathbb{R}^{k + 1}$
* repeat: 
* cluster assignment step:
** for $i = 1$ to $m$:
** $c_i \leftarrow$ closest to $\mathbf x_i$ centroid using [[Euclidean Distance]] $\text{dist} = \| \mathbf x_i - \boldsymbol \mu_i \|^2$
* move centroids step: 
** for $i = 1$ to $k$:
** $\boldsymbol \mu_k \leftarrow$ average of all points assigned to $c_k$


=== Optimization Objective ===
Let's have the following notation 
* $c_i \in \{ 1, 2, \ ... \ , k \}$ - index of cluster to which example $\mathbf x_i$ is assigned
* $\boldsymbol \mu_k$ - cluster centroid $k$ ($\boldsymbol \mu_k \in \mathbb{R}^n$)
* $\mu_{c_i}$ - cluster centroid of example $\mathbf x_i$

e.g. 
* $\mathbf x_i$ is assigned to $5$
* $c_i = 5$ and
* $\mu_{c_i} = \boldsymbol \mu_5$


So optimization objective (cost function, or sometimes called ''distortion''): 
* $J(c_1, \ ... \ , c_m, \boldsymbol \mu_1, \ ... \ , \boldsymbol \mu_k) = \cfrac{1}{m} \sum_i \left\| \mathbf x_i - \boldsymbol \mu_{c_i} \right\|^2$


we want to find $\min J(c_1, \ ... \ , c_m, \boldsymbol \mu_1, \ ... \ , \boldsymbol \mu_k)$ with respect to $c_1, \ ... \ , c_m, \boldsymbol \mu_1, \ ... \ , \boldsymbol \mu_k$
* cluster assignment - minimizes $J$ 
** with $c_1, \ ... \ , c_m$
** holding $\boldsymbol \mu_1, \ ... \ , \boldsymbol \mu_k$ fixed
* move centroids - minimizes $J$  
** with $\boldsymbol \mu_1 \ , ... \ , \boldsymbol \mu_k$
** holding $c_1, \ ... \ , c_m$ fixed



=== Seed Selection ===
Seed selection is the process of selecting the initial centroids 



== Implementation Notes ==
=== Random Initialization ===
How to initialize centroids $\mu = \Big( \boldsymbol \mu_1, \boldsymbol \mu_2, \, ... \, , \boldsymbol \mu_k \Big)$?
* should have $k &lt; m$
* randomly pick $k$ training examples
* set $\boldsymbol \mu_1, \ ... \ , \boldsymbol \mu_k$ to these $k$ examples


Different clusters
* So $k$-means may converge to different clusters depending on how the centroids were initialized 
* Particularly it may end up in a local optimum - and the split won't be the best 
* what we can do is to try it several times and choose the best 


'''Algorithm''':
* repeat $n$ times (typically 50 - 1000)
** randomly initialize $k$ centroids 
** run k-means, get $c_1, \ ... \ , c_m, \boldsymbol \mu_1, \ ... \ , \boldsymbol \mu_k$
** compute the cost function $J$
* pick clustering with lowest cost


If the number of clusters $k$ is 2-10 then the random initialization makes sense, otherwise - probably not



=== No Data Assigned ===
If at iteration step we end up with a cluster with no assigned data points, we can:
* get rid of it - look for $k-1$ clusters at the next step (advised)
* randomly re-initialize that cluster centroid (if you really want $k$ clusters)


== Choosing the Number of Clusters ==
How to choose $k$? 
* manually - by looking at the data (best)
* other methods: e.g. the Elbow Method


=== Elbow Method ===
We can plot values of our distortion function for different $k$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/kmeans-elbow.png
* at first it goes down rapidly
* then goes down slowly 
* this is called an &quot;elbow&quot;
* so in this case we choose $k = 3$ because of the elbow


=== Domain Knowledge ===
But often it gives a smooth curve with no visible elbow
* In this case you need to use a metrics how well it performs for a particular purpose
* Use domain knowledge, if possible, to come up with good $k$



== Disadvantages ==
* Quite sensitive to initial seeds - so may need to choose them carefully
* For high dimensional data such as [[Document Clustering|documents]] may be not practical
** centroids may contain lots of words - but we usually want to have sparse centroids
* doesn't perform well on data with outliers or with clusters of different sizes or shapes



== Seed Selection ==
Seed selection procedure is very important 
* K-means is sensitive to the initial position (which is why in random initialization we run it many times)
* especially it's noticeable in data with high dimensionality


Can try do it smarter than random
* e.g. sample and then select seeds using [[Hierarchical Clustering]] (like in [[Scatter/Gather]])
* if have some partial knowledge about labels - use it (it'll be so-called [[Semi-Supervised Clustering]])


=== K-Means++ ===
It's a smart way of doing seed selection
* see http://en.wikipedia.org/wiki/K-means%2B%2B


== Variants ==
=== [[Weighted K-Means]] === 
Objective:
* $$J(\boldsymbol \mu_1, \dots, \boldsymbol \mu_K) = \cfrac{\sum_{i} w_i \min_k \| \mathbf x_i- \boldsymbol \mu_k\|^2}{\sum_{i} w_i},$$
* $\boldsymbol \mu_i$ is $i$ centroid 
* $w_i$ is weight assigned to each $\mathbf x_i$


Solution:
* Expectation step:
** Find the nearest centroid for each data point:
** $$\forall \ 1 \leqslant k \leqslant K: \quad \mathcal{C}(k) \leftarrow \Big\{ i ~:~ k = \mathrm{arg}\min_k \| \mathbf x_i - \boldsymbol \mu_k \|^2 \Big\}$$
* Minimization step:
** Recompute the centroid as a the (weighted) mean of the associated data points:
** $$\forall \ 1 \leqslant k \leqslant K: \quad c_k \leftarrow \frac{\sum_{i \in \mathcal{C}(k)} w_i \cdot \mathbf x_i}{\sum_{i \in \mathcal{C}(k)} w_i}$$
* until $J$ converges


=== [[K-Medoids]] ===
Instead of mean, we take the &quot;medoid&quot; of each cluster to represent its centroid
* works better for non-euclidean distances than k-means


=== Bisecting K-Means ===
This is a variant of K-Means 
* it's a [[Hierarchical Clustering]] method, and it's useful for [[Document Clustering]]


Algorithm:
* start with a single cluster
* repeat until have desired number of clusters
** choose a cluster to split (e.g. the largest one)
** find two subclusters using K-means with $k = 2$ and split 
** may repeat this procedure several times and take the clusters with highest overall similarity


=== [[Scatter/Gather]] ===
* a special version of k-means for [[Document Clustering]]
* uses [[Hierarchical Clustering]] on a sample to do seed selection



=== Approximate K-Means ===
* Philbin, James, et al. &quot;Object retrieval with large vocabularies and fast spatial matching.&quot; 2007. [http://research.microsoft.com/pubs/64602/philbin07.pdf]


=== Mini-Batch K-Means ===
Lloyd's classical algorithm is slow for large datasets (Sculley2010)
* Use [[Mini-Batch Gradient Descent]] for optimizing K-Means
* reduces complexity while achieving better solution than [[Stochastic Gradient Descent]]

Notation:
* $f(C, \mathbf x)$ returns the nearest centroid for $\mathbf x$


Algorithm:
* given $k$, batch size $b$, max. number of iterations $t$ and dataset $X$
* initialize each $\boldsymbol \mu$ with randomly selected elements from $X$ 
* repeat $t$ times:
* $M \leftarrow b$ random examples from $X$ 
* for $\mathbf x \in M$:
** $d[\mathbf x] = f(C, \mathbf x)$ // cache the centroid nearest to $\mathbf x$
* for $\mathbf x \in M$:
** $\boldsymbol \mu \leftarrow d[\mathbf x]$
** $v[\boldsymbol \mu] = v[\boldsymbol \mu] + 1$ // counts per centroid
** $\eta = 1 / v[\boldsymbol \mu]$ // per-centroid learning rate
** $\boldsymbol \mu \leftarrow (1 - \eta) \cdot \boldsymbol \mu + \eta \cdot \mathbf x$ //gradient step


Can enforce sparsity by $L_1$ regularization: see Sculley2010


Implementation:
* [http://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html MiniBatchKMeans] in scikit-learn


=== [[Fuzzy C-Means]] ===
Modify the membership function s.t. it outputs the degree of association between item and cluster
* degree of membership to the cluster depends on the distance from the document to the cluster centroid


Reference:
* Bezdek, James C., Robert Ehrlich, and William Full. &quot;FCM: The fuzzy c-means clustering algorithm.&quot; 1984. [http://web-ext.u-aizu.ac.jp/course/bmclass/documents/FCM%20-%20The%20Fuzzy%20c-Means%20Clustering%20Algorithm.pdf]



== Implementation ==
Usual version:

&lt;code&gt;D = distmat(X, C)&lt;/code&gt; calculates the squared distance matrix $D$ between each $x_i \in X$ and each $\mathbf c_k \in C$

&lt;pre&gt;
def distmat(X, C):    
    X2 = np.sum(X * X, axis=1, keepdims=True)
    C2 = np.sum(C * C, axis=1, keepdims=True)

    XC = np.dot(X, C.T)

    D = X2 - 2 * XC + C2.T
    return D
&lt;/pre&gt;

&lt;code&gt;A = closest(D)&lt;/code&gt;: returns the closest centroid matrix $A$: with $(A)_{ik} = 1$ if $w_i \in c_k$ and $(A)_{ik} = 0$ if $w_i \not \in c_k$


&lt;pre&gt;
def closest(D):
    D_min = D.min(axis=1, keepdims=True)
    return (D == D_min).astype(int)

&lt;/pre&gt;


&lt;code&gt;C = new_centers(X, A, w)&lt;/code&gt; calculates new centroids 

&lt;pre&gt;
def newcenters(X, A):
    summed = np.dot(X, A.T)
    counts = np.sum(A, 1)
    return summed / counts
&lt;/pre&gt;


For weighted k-means it would be 

&lt;pre&gt;
def new_centers(X, A, w):
    W = A * w.reshape(-1, 1)
    weighted_sum = np.dot(W.T, X)
    weights = np.sum(W, axis=0).reshape(-1, 1)
    return weighted_sum / weights
&lt;/pre&gt;


Finally, the cost function for weights:

&lt;pre&gt;
def J(X, D, w):
    D_min = D.min(axis=1)
    return (w * D_min).sum() / w.sum()
&lt;/pre&gt;


The algorithm:

&lt;pre&gt;
def kmeans(X, k):
    d, n = X.shape
    M_idx = np.random.choice(np.arange(n), k, replace=False)
    M = X[:, M_idx]
    
    converged = False
    while not converged:
        D = kmu.distmat(M, X)
        A = kmu.closest(D)
        M_new = kmu.newcenters(X, A)

        converged = np.abs(M_new - M).sum() &lt;= 1e-8
        M = M_new    
    return M
&lt;/pre&gt;

With weighted &lt;code&gt;J&lt;/code&gt;:

&lt;pre&gt;
while not converged:
    D = distmat(X, M)
    M = closest(D)
    J_new = J(X, D, w)

    M_new = new_centers(X, A, w)
    converged = np.abs(J_new - J_old) &lt;= 0.01

    M = M_new
    J_old = J_new
&lt;/pre&gt;


See ipython notebook for complete code:
* [http://nbviewer.ipython.org/github/alexeygrigorev/notebooks/blob/master/studies/tub-ml1/sheet06-kmeans.ipynb sheet06-kmeans.ipynb] 


== Sources ==
* [[Machine Learning (coursera)]]
* [[Python for Machine Learning (TUB)]]
* [[Machine Learning 1 (TUB)]]
* Steinbach, Michael, George Karypis, and Vipin Kumar. &quot;A comparison of document clustering techniques.&quot; 2000.
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. Springer US, 2012. [http://ir.nmu.org.ua/bitstream/handle/123456789/144935/d1784ebed3eab2708026b202b2b65309.pdf?sequence=1#page=90]
* Oikonomakou, Nora, and Michalis Vazirgiannis. &quot;A review of web document clustering approaches.&quot; 2010. [https://scholar.google.com/scholar?cluster=1261203777431390097&amp;hl=ru&amp;as_sdt=0,5]
* Sculley, David. &quot;Web-scale k-means clustering.&quot; 2010. [http://www.ra.ethz.ch/CDstore/www2010/www/p1177.pdf]


[[Category:Machine Learning]]
[[Category:Unsupervised Learning]]
[[Category:Cluster Analysis]]
[[Category:Python]]</text>
      <sha1>ossou42or52tpnz67u53me033b1ef8o</sha1>
    </revision>
  </page>
  <page>
    <title>Dimensionality Reduction</title>
    <ns>0</ns>
    <id>140</id>
    <revision>
      <id>141</id>
      <timestamp>2015-05-01T21:07:08Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2344">== Dimensionality Reduction ==
This is a technique to reduce the dimensionality of our data sets 
* we have a data set of $\{ \mathbf x_i \}$ of $\mathbf x_i \in \mathbb R^D$ with very large $D$
* the goal is to find a mapping $f: \mathbb R^D \mapsto \mathbb R^d$ s.t. $d \ll D$
* for [[Visualization]] the target dimension is usually small, e.g. $d = 2$ or $d =3$


=== Overfitting ===
* DR techniques tend to reduce [[Overfitting]]: 
* if dimensionality of data is $D$ and there are $N$ examples in the training set
* then it's good to have $D \approx N$ to avoid overfitting


=== Agressiveness ===
* Note that DR techniques sometimes may remove important information 
* Aggressiveness of reduction is $D / d$



== [[Feature Selection]] ==
=== [[Information Retrieval]] and [[Text Mining]] ===
In IR these techniques are usually called &quot;Term Selection&quot; rather than &quot;Feature selection&quot;


Usual IR and indexing techniques for reducing dimensionality are
* [[Stop Words]] Removal
* [[Stemming]] or [[Lemmatization]]  
* less common techniques are [[Term Strength]] and [[Term Contribution]]

[[Term Clustering]]
* [[Concept Decomposition]] 


=== General Techniques ===
* [[Subset Selection]] (&quot;Wrapper Approach&quot;) take subset of features and see if it's better or not
* [[Feature Filtering]]: rank features according to some &quot;usefulness&quot; function
** [[Entropy-Based Ranking]]
** [[Information Gain]]
** [[Mutual Information]]
** [[Odds Ratio]]
** [[Chi-Squared Ranking]]


== Feature Extraction ==
[[Factor Analysis]]

Generate new features based on the original ones  


Linear 
* [[Principal Component Analysis]] (often done via [[Eigendecomposition]] or [[SVD]])
* [[Fisher Discriminant Analysis]] (sometimes Linear Discriminant Analysis) - supervised technique for Dimensionality Reduction


Non-Linear
* [[Locally Linear Embedding]]


== Links ==
* http://www.public.asu.edu/~jtang20/publication/feature_selection_for_classification.pdf
* http://www.public.asu.edu/~jtang20/publication/FSClustering.pdf


== Sources ==
* [[Machine Learning (coursera)]]
* [[Machine Learning 1 (TUB)]]
* [[Machine Learning 2 (TUB)]]
* Sebastiani, Fabrizio. &quot;Machine learning in automated text categorization.&quot; (2002). [http://arxiv.org/pdf/cs/0110053.pdf]


[[Category:Machine Learning]]
[[Category:Dimensionality Reduction]]
[[Category:Feature Selection]]</text>
      <sha1>o66hjak31231b3xj9w5sf8cj1eleul4</sha1>
    </revision>
  </page>
  <page>
    <title>Principal Component Analysis</title>
    <ns>0</ns>
    <id>141</id>
    <revision>
      <id>142</id>
      <timestamp>2013-09-02T14:05:22Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1156">== Principal Component Analysis ==
Principal Component Analysis is the most popular and commonly used technique for [[Dimensionality Reduction]]

Suppose we want to reduce from 2D to 1D
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/dim-red-intuition.png
* how to find the best projection line? 

We want to find a line which would give us the smallest square distance from the data points to their projection
* http://stolzen.googlecode.com/svn/trunk/courses/coursera/Machine%20Learning/figures/pca-projection-error
* the sum of squared length of projection liens is called a ''projection error''

Before running PCA it's a good idea to perform [[Feature Scaling]]
* so features have zero mean and
* comparable ranges of values 

To reduce from $N$-dim to $K$-dim
* we find a direction (a vector $u^{(1)} \in \mathbb{R}^n$, say $n = 2$)
* we project the data onto this direction
* and we want the projection error to be as small as possible
* doesn't matter if $u^{(1)}$ is 



== See also ==
* [[Dimensionality Reduction]]

== Sources ==
* [[Machine Learning (coursera)]]

[[Category:Machine Learning]]
[[Category:Algebra]]</text>
      <sha1>bnltibccmdsvtg8n5hgmxq5uctsk1mj</sha1>
    </revision>
  </page>
  <page>
    <title>Advanced Databases (ULB)</title>
    <ns>0</ns>
    <id>142</id>
    <revision>
      <id>143</id>
      <timestamp>2015-04-19T11:28:42Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1023">* The course was taken in autumn 2013 at the ULB
* Taught by professor Esteban Zimányi


== Course Content  ==
=== [[Active Databases]] ===
* [[Replication]]
* Management of Derived data: [[View Materialization]]


=== [[Temporal Databases]] ===
* Temporal data and applications
* Time ontology
* [[Temporal Entity-Relationship Model]]
* [[Sequenced Queries]]


=== [[Object Databases]] ===
* Object-oriented model. 
* Object Persistance
* ODMG standard: Object Definition Language and Object Query Language.


=== [[Spatial Databases]] ===
* Spatial data and applications. 
* Space ontology. 
* Conceptual modeling of spatial aspects. 
* Manipulation of spatial data with standard SQL.


== [[CouchDB]] Project ==
* [[NoSQL]], when to use, why better that RDBMS?
* The [[CAP Theorem]]
* [[Consistency]], [[Eventual Consistency]]
* [[ACID]] vs [[BASE]]
* [[CouchDB|CouchDB overview]]


== Info ==
* Public webpage: http://cs.ulb.ac.be/public/teaching/infoh415


[[Category:Databases]]
[[Category:IT4BI]]
[[Category:Notes]]</text>
      <sha1>p82qfjglxf48bzr8gpbr43jeptdle51</sha1>
    </revision>
  </page>
  <page>
    <title>Playground</title>
    <ns>0</ns>
    <id>143</id>
    <revision>
      <id>144</id>
      <timestamp>2014-02-24T08:38:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="980">Conjunctie query

$ 
\begin{array}{l l}
Q(\text{$E_1$.eid}) \leftarrow &amp; \text{Emp}(\text{$E$.eid}, \text{$E$.did}, \text{$E$.sal}, \text{$E$.hobby}), \\
&amp; \text{Emp}(\text{$E_1$.eid}, \text{$E_1$.did}, \text{$E_1$.sal}, \text{$E_1$.hobby}), \\
&amp; \text{Emp}(\text{$E_2$.eid}, \text{$E_2$.did}, \text{$E_2$.sal}, \text{$E_2$.hobby}), \\
&amp; \text{Dept}(\text{$D_1$.did}, \text{$D_1$.dname}, \text{$D_1$.floor}, \text{$D_1$.phone}), \\
&amp; \text{Dept}(\text{$D_2$.did}, \text{$D_2$.dname}, \text{$D_2$.floor}, \text{$D_2$.phone}), \\
&amp; \text{Finance}(\text{$F$.did}, \text{$F$.budget}, \text{$F$.sales}, \text{$F$.expenses}) \\
\end{array}
$


$R^k_{ij} = \color{grey}{\underbrace{{\color{black}{ \ R^{k-1}_{ij} \ }}}_{\small\text{(1)}} {\color{black}{+}} \underbrace{{\color{black}{ \ R^{k-1}_{ik}  \  }}}_{\small\text{(2)}} \underbrace{{\color{black}{  \  \big( R^{k-1}_{kk} \big)^*  \  }}}_{\small\text{(3)}} \underbrace{{\color{black}{  \  R^{k-1}_{kj}  \  } }}_{\small\text{(4)}}}$</text>
      <sha1>gz4eot2733hh6aody5xiv2843cf9bew</sha1>
    </revision>
  </page>
  <page>
    <title>Database Systems Architecture (ULB)</title>
    <ns>0</ns>
    <id>144</id>
    <revision>
      <id>145</id>
      <timestamp>2014-01-03T09:35:55Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2040">* The course was taken in autumn 2013 at the ULB
* Taught by Stijn Vansummeren


== Content ==
=== [[Query Processing]] ===
[[Query Plan#Logical Query Plan|Logical Query Plan]]
* [[Relational Algebra]]
* [[Translating SQL to Relational Algebra]]
* [[Logical Query Plan Optimization]]: Heuristics and optimization of [[Conjunctive Query|Conjunctive Queries]]

[[Query Plan#Physical Query Plan|Physical Query Plan]]
* [[Physical Operators (databases)]]
* [[Physical Query Plan Optimization]]
** [[Query Result Size Estimation]] to estimate the result size 
** [[Join Ordering]] to select the optimal way of ordering join operations
** [[Physical Query Plan Optimization#Greedy Algorithm|Greedy Algorithm]] to select the optimal plan


=== [[Indexing (databases)|Indexing]] ===
Simple (Conventional) Indexes
* [[Dense Index]]
* [[Sparse Index]]
* [[Secondary Index]]

Tree-Based Indexes
* [[B-Tree]]

Hash-Based Indexes
* [[Open Hashing Index]]
* [[Extensible Hashing]]
* [[Linear Hashing]]

=== [[Multi-Dimensional Indexes]] ===
Conventional
* [[Multiple-Key Index]]

Tree-Based Indexes
* [[kd-Trees]]
* [[Quad Trees]]
* [[R-Tree]]

Hash-Based Indexes
* [[Grid File Index]]
* [[Partitioned Hash Function Index]]

=== Different Stuff ===
* [[Physical Data Organization (databases)]]
* [[Database#Classical DBMS Architecture|Typical DB Architecture]]

=== Ensuring [[ACID]] ===
; [[Atomicity (databases)|A]], [[Consistency (databases)|C]] and [[Durability (databases)|D]]
* [[Crash Recovery]]
* [[Database Transaction Log]]
** [[Undo Logging]]
** [[Redo Logging]]
** [[Undo/Redo Logging]]
; [[Isolation (databases)|I]]
* [[Concurrency Control]] and [[Serializable Scheduling]]
* [[Scheduler]]s:
** [[Lock-Based Scheduler]]
** [[Timestamp-Based Scheduler]]
** [[Validation-Based Scheduler]]


== Info ==
* Course Webpage http://cs.ulb.ac.be/public/teaching/infoh417
* Dropbox folder with all the materials https://www.dropbox.com/sh/r0zvy3zaycbevx8/yLvz9YdT-f

[[Category:Database Systems Architecture]]
[[Category:Databases]]
[[Category:IT4BI]]</text>
      <sha1>hk7e2hbx37hn1cnok7x22b5ljtmi3u1</sha1>
    </revision>
  </page>
  <page>
    <title>Business Process Management (ULB)</title>
    <ns>0</ns>
    <id>145</id>
    <revision>
      <id>146</id>
      <timestamp>2014-02-08T14:37:36Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1045">* The course was taken in autumn 2013 at the ULB
* Taught by professor Toon Calders


== Course Content ==
=== Overview ===
* [[Business Process Management]]
* [[Enterprise System Architecture]]

=== [[Workflow Nets]] ===
* [[Petri Nets]]
* [[Workflow Nets]]
* [[Workflow Soundness]]
* Graph Representation of states:
** [[Reachability Graph]]
** [[Coverability Graph]]

=== [[YAWL]] ===
* [[Workflow Patterns]]
* [[Deferred Choice]] versus Exclusive Choice (xor-split)
* [[Cancellation Regions]]
* [[Discriminator Pattern]]
* [[Milestone Pattern]]

=== [[BPMN]] ===
* [[BPeL]]

=== [[Process Mining]] ===
* [[Alpha Algorithm]] and [https://docs.google.com/document/d/1JtuECbGZ3DusNpmBZhXeq8R_UPCRU5V7NG8GL17h1aA/pub BPM project: The $\alpha^+$ algorithm]
* [[Region-Based Process Miner]]
* [[Genetic Process Miner]]


== Info ==
* Public website: http://cs.ulb.ac.be/public/teaching/infoh420
* Dropbox folder: https://www.dropbox.com/sh/hjd9y0v3351csv6/8j9iMILIeH


[[Category:IT4BI]]
[[Category:Business Process Management]]
[[Category:Notes]]</text>
      <sha1>2xijihthkcrn5rozdyo012p6sjpm6t1</sha1>
    </revision>
  </page>
  <page>
    <title>Web Intelligence and Big Data (coursera)</title>
    <ns>0</ns>
    <id>146</id>
    <revision>
      <id>147</id>
      <timestamp>2013-11-04T17:57:29Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="589">== Web Intelligence and Big Data ==
(Spring 2013)


Look
* Big Data and Search
* Indexing, PageRank and Memory

Listen
* Information, Language and Classifiers
* Analyzing Sentiment and Intent

Load
* Big data technology, MapReduce
* Databases and their evolution
* Large scale Graph Databases

Learn
* Learning: Clustering, Mining, Machine Learning and its Limits
* Information Extraction

Connect
* Reasoning: Logic and its Limits
* Dealing with Uncertainty
* Programming HW6: Medical Diagnostics

Predict
* Hierarchical Reasoning
* Predictive Analytics in Business

[[Category:Coursera]]</text>
      <sha1>79g5re5pa88akifkz1tq6qyt37clh9d</sha1>
    </revision>
  </page>
  <page>
    <title>Introduction to Data Science (coursera)</title>
    <ns>0</ns>
    <id>147</id>
    <revision>
      <id>148</id>
      <timestamp>2013-12-25T07:47:52Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="946">(Spring 2013)


== Syllabus ==
=== Part 1: Data Manipulation, at Scale ===
* [[Databases]]
* Traditional [[Relational Databases]] and [[Relational Algebra]]
* [[MapReduce]]
** [[Hadoop]], algorithms, 
** extensions ([[Hive]], [[Pig]]); 
* [[NoSQL]]
** [[Document-Oriented Databases]] and [[Eventual Consistency]]
** [[Column-Oriented Databases]]
** Tradeoffs of SQL and NoSQL
* Data cleaning, entity resolution, data integration, information extraction


=== Part 2: Analytics ===
* Basic statistical modeling, experiment design
* Introduction to [[Machine Learning]]
** Supervised Learning: decision trees/forests, simple nearest neighbor
** Unsupervised learning: [[K-Means]], multi-dimensional scaling


=== Part 3: Interpreting and Communicating Results ===
* Visualization, visual data analytics

== Links ==
* [https://www.dropbox.com/s/t80ks03gqvbq3rs/Introduction%20to%20Data%20Science%20coursera.pdf Lecture Notes]

[[Category:Coursera]]</text>
      <sha1>a2wu24jyy8kbx7cwqh5wz2xygxa9ejm</sha1>
    </revision>
  </page>
  <page>
    <title>Data Warehousing (ULB)</title>
    <ns>0</ns>
    <id>148</id>
    <revision>
      <id>149</id>
      <timestamp>2013-11-06T13:26:38Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1116">== Info ==
* Course page: http://cs.ulb.ac.be/public/teaching/infoh419

== Syllabus ==
=== Introduction ===
* OLTP vs OLAP
* Why a RDBMS is not suitable for Analytical Queries
** Important conceptual notions
** Data cube
** Dimensions
** Hierarchy
* Data Explosion Problem


Important database notions:
* ER Modelling
* Translation to the relational model
* Dependencies: Functional and foreign key dependencies

=== Dimensional Modeling ===
* Dimensional Modeling
* Roll-up lattice

=== Logical Modelling ===
* Special aggregation cases
* Additive and non-additive measures
* Star and snowflake schemas

* Logical design
* Dealing with changing dimensions
* Slowly Changing Dimensions
** Type I, II, and II
** Rapidly changing dimensions
** Mini dimension
* Specific dimension types
** Junk dimension
** Outriggers
** Degenerate dimension

=== Physical level ===
* View materialization
* Indexing
** Bitmap index, Projection index, Join index, Bitmap-join index
** Indexing dimension and fact tables
* Partitioning


=== ETL ===
* Data warehouse architectures
* ETL

[[Category:IT4BI]]
[[Category:Data Warehousing]]</text>
      <sha1>jrnry05czaboeg1xt6z11h90gz7ofpn</sha1>
    </revision>
  </page>
  <page>
    <title>NoSQL</title>
    <ns>0</ns>
    <id>149</id>
    <revision>
      <id>150</id>
      <timestamp>2013-11-15T06:58:23Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3551">== [[Relational Databases|RDBMSs]] / Row-Oriented databases ==
* Typically have strict schema
* Declarative query language SQL (excellent for ad-hoc queries, easy joins)
* Good transactions support ([[ACID]])
* Algebraic Optimization
* Caching / Materialized Views 
* Strong [[Consistency (databases)| Consistency]]

=== Downsides ===
* many services don't require complex ad-hoc querying
* typically choose consistency over availability (see the [[CAP Theorem]])
* replication solutions are limited
** use traditional replication algorithms to give strong consistency (like [[Two-Phase Commit]])
** but data is not made available until the commit finishes (and the database is back to the consistent state)
** not an option for systems where network failures are possible!
* as the volume of data grows, queries become inefficient - not easily scalable
** need to wait too long for all replicas to finish with commit
* hard to load-balance

== NoSQL ==
=== [[Column-Oriented Databases]] ===
Are better for storing large amounts of data, especially when the number of columns is very large

* Sets of columns are stored together, so a particular record is actually split across several blocks
* Within each block data is stored in sorted order
* Need to maintain &quot;join index&quot; - to pull together different blocks that are for the same record
* Especially good for analytical queries (such as [[OLAP]])

=== [[Document-Oriented Databases]] ===
Main unit of data is a document - a self-contained (typically) record with all information at hand
* no (little) need for joins

=== In-Memory DBs ===
* Real-time transactions
* Variety of indexing
* Complex joins - still possible 
* Not for big data

=== NoSQL features ===
* No [[ACID]] transactions, usually use weaker concurrency model ([[BASE]])
* Simpler API - usually no query language
* restricted joins (for better efficiency)
* Ability to horizontally scale &quot;simple operations&quot; throughput over many servers 
: simple = key lookups, read/write of one record
* Ability to replicate and partition data over many servers 
* Efficient use of distributed indexes and RAM for data storage 
* The ability to dynamically add new attributes to data records 


== Major impact systems ==
=== Memcached ===
Showed that in-memory indexes can be highly scalable and it's possible to distribute and replicate objects over multiple nodes

* main-memory caching service 
: no persistence, replication or fault-tolerance 
* mature system, in wide use
* important concept: [[Consistent Hashing]]

=== Dynamo ===
Pioneered the idea of eventual consistency as a new way to achieve higher availability and scalability :
* data fetches are not guaranteed to be up-to-date, but
* updates are guaranteed to be propagated to all nodes (eventually)
* DHT (Distributed Hash Table) with replication 
** for $N$ replicas stores values at servers $k$, $k + 1$, ..., $k + N - 1$ 
** [[Eventual Consistency|eventually consistent]] via [[Vector Clock|vector clock]] to capture causality
* Reconciliation at read time:
** writes never fail
** conflict resolution: last write wins or application specific
* [[Eventual Consistency#Configurable Consistency|Configurable Consistency]]


=== BigTable ===
Showed that persistend record storage could be scaled to thousands of nodes 



== Sources ==
* [[Introduction to Data Science (coursera)]]
* [[Web Intelligence and Big Data (coursera)]]
* Amazon's Dynamo paper [http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf]



[[Category:NoSQL]]
[[Category:Databases]]</text>
      <sha1>6qko7gti0tycfc06kxcn7g6fmyoigcd</sha1>
    </revision>
  </page>
  <page>
    <title>Consistency (databases)</title>
    <ns>0</ns>
    <id>150</id>
    <revision>
      <id>151</id>
      <timestamp>2014-01-01T21:04:26Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3829">== Consistency ==
For databases, ''consistency'' means satisfying integrity constraints, which are about the correctness of the data in a database. So a database is ''consistent'' if all its constraint are satisfied. 

=== Integrity Constraints ===
Some of the integrity constraints are: 
* entity integrity constraint (a primary key cannot be null)
* referential integrity constraint (if a tuple $X$ in one relation refers to some other tuple $Y$ in another relation, $Y$ must always exist in that relation)

Examples of predicates that must hold:
* $x$ is a key of relation $R$ 
* [[Functional Dependency]] $x \to y$ holds in $R$ 
* domain($x$) = {Red, Green, Blue} - the only allowed values
* no employee should make more than twice average salary (achieved with triggers in [[Active Databases]])

In a database to specify if data is valid we use constraints. 


== Transaction Constraints ==
Transaction Consistency
* essentially involve two database states: the old state (before $T$) and the new state (after $T$)
* but '''always''' maintaining a database in a consistent state is impossible 

Example:
* we have $n$ accounts in a bank: $a_1, ..., a_n$
* suppose that we store the total sum somewhere in the database
* constraint: $a_1 + ... + a_n = \text{TOTAL}$
* but during a transaction the database may be in inconsistent state 
* transaction: deposit 100 USD to $a_2$
* to do that we need:
** update $a_2: a_2 \leftarrow a_2 + 100$
** (at this moment the constraint is not satisfied)
** update TOTAL: $\text{TOTAL} \leftarrow \text{TOTAL} + 100$
* so during the transaction we'll have a state in which the DB is not consistent

We can define a ''transaction'' as a sequence of updates on the database. 
* It ''preserves consistency'' if executing it brings a database from one consistent state to another. 
* The database doesn't have to be consistent during the transaction.  
* For transactions, consistency is the letter &quot;C&quot; in the [[ACID]].
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/transaction-consistency.png
* And a transaction should happen in [[Isolation (databases)|Isolation]] (Letter &quot;I&quot; in ACID)


=== [[Crash Recovery]] ===
But what if during the execution of a transaction a crash occurs?
* if we take no action the database will be left in an inconsistent state 
* main techniques: [[Database Transaction Log]]s
** [[Undo Logging]], [[Redo Logging]], [[Undo/Redo Logging]]


== Consistency Models ==
For [[Distributed Databases]] maintaining consistency is harder. Consistency models determine rules for ''visibility'' and ''order'' of updates.

=== Strict Consistency ===
* every replica sees every update in the same order 
* all reads return the most up-to-date data no matter what replica is asked 
* need to employ some techniques for commit propagation, for example, [[Two-Phase Commit]] 
* according to the [[CAP Theorem]], cannot achieve strict consistency at the same time with partition-tolerance

=== [[Eventual Consistency]] ===
* order in which updates received is important
* as $t \to \infty$ all readers will see the writes
* but updates are not atomic as in case of Strict Consistency 

=== Weak Consistency ===
* every replica will see updates
* but there's no guarantee on the order

in this case later updates may be overwritten by earlier ones because they arrived later


== Sources ==
* [[Database Systems Architecture (ULB)]]
* [http://www.slideshare.net/guestdfd1ec/design-patterns-for-distributed-nonrelational-databases Design Patterns for Distributed Nonrelational Databases]
* [http://the-paper-trail.org/blog/consistency-and-availability-in-amazons-dynamo/ Consistency and availability in Amazon's Dynamo]

== See also ==
* [[BASE]] - weaker alternative to [[ACID]]
* the [[CAP Theorem]]

[[Category:Distributed Systems]]
[[Category:Databases]]</text>
      <sha1>negq14gayoj8ziyicipx57u7d8js3nt</sha1>
    </revision>
  </page>
  <page>
    <title>ACID</title>
    <ns>0</ns>
    <id>151</id>
    <revision>
      <id>152</id>
      <timestamp>2013-11-14T20:02:00Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="381">== ACID == 
ACID is an acronym that stands for 
* [[Atomicity (databases)|'''A'''tomicity]]
* [[Consistency (databases)|'''C'''onsistency]]
* [[Isolation (databases)|'''I'''solation]]
* [[Durability (databases)|'''D'''urability]]

ACID defines desirable properties for database transactions

== Sources ==
* http://www.articleworld.org/Database_consistency


[[Category:Databases]]</text>
      <sha1>h4f0w25q9tm5hfepxmg1rak53oe0d5o</sha1>
    </revision>
  </page>
  <page>
    <title>Consistency</title>
    <ns>0</ns>
    <id>152</id>
    <revision>
      <id>153</id>
      <timestamp>2013-11-14T20:02:42Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="59">#перенаправление [[Consistency (databases)]]</text>
      <sha1>72ozrq7gguzr7p2q5jngwpubv5condi</sha1>
    </revision>
  </page>
  <page>
    <title>BASE</title>
    <ns>0</ns>
    <id>153</id>
    <revision>
      <id>154</id>
      <timestamp>2013-11-17T13:42:18Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="260">== BASE ==
* Basically Available
* Soft state 
* [[Eventual Consistency|Eventually Consistent]]


== Sources ==
* [[Introduction to Data Science (coursera)]]

== See also ==
* [[ACID]]

[[Category:NoSQL]]
[[Category:Distributed Systems]]
[[Category:Databases]]</text>
      <sha1>nvd8q5172o3eyo94qprap5y6yluud0i</sha1>
    </revision>
  </page>
  <page>
    <title>Distributed Databases</title>
    <ns>0</ns>
    <id>154</id>
    <revision>
      <id>155</id>
      <timestamp>2014-01-02T06:39:33Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2385">== Architectures ==
Evolution of Distributes DBs 

Logical multi-processor database design:

* Shared memory (easiest to program, but most expensive)
* Shared disks (easier)
* Shared nothing (hard: [[MapReduce]], etc)

https://raw.github.com/alexeygrigorev/ulb-adb-project-couchbd/master/report/images/parallel-arhitectures.png

=== Shared Nothing Architecture ===
* each processing unit (node, process, thread) is independent and self-sufficient
* it has its own memory and storage
* these is no single point of connection in the system
* allows individual servers to fail (with proper replication)
* data records are distributed by messaging



== Assumptions ==
Assumptions that we make about distributes systems

Data size
* the amounts of data is so big to fit on one node
* and even on a single rack
* $\to$ therefore we need to partition the data across many nodes

Reliability 
* the system must be highly available to serve all applications 
* nodes may occasionally crash 
* but data must be safe 
* $\to$ therefore we need to replicate each row to multiple nodes and remain available despite failures 

Performance 
* for real-time use
* 95/99 percentile is more important than the average latency (we care about longest latency measures)
* want it run on cheap commodity hardware
* $\to$ need to be able to maintain low latency even during recovery operations



== Design Principles ==
Partitioning / Incremental Scalability
* Scale out one node at a time with minimal impact (with techniques like [[Consistent Hashing]])

Symmetry
* no special role node (with extra responsibilities)
* simplifies maintenance

Decentralization
* extension of Symmetry:
* favor peer-to-peer techniques over centralized control

Heterogeneity
* work distribution must be proportional to the capabilities of individual servers 
* don't need to upgrade old servers when adding a newer one

== Concurrency Control ==
{{ Main | Concurrency Control }}

== Sources ==
* [[Introduction to Data Science (coursera)]]
* [http://www.slideshare.net/guestdfd1ec/design-patterns-for-distributed-nonrelational-databases Design Patterns for Distributed Non-relational Databases]
* Amazon's Dynamo paper [http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf]


== See also ==
* [[Distributed File Systems]]


[[Category:Distributed Systems]]
[[Category:NoSQL]]
[[Category:Databases]]</text>
      <sha1>37uq5hwl053cloe9bklttsf7iu11ek5</sha1>
    </revision>
  </page>
  <page>
    <title>Hadoop Distributed File System</title>
    <ns>0</ns>
    <id>155</id>
    <revision>
      <id>156</id>
      <timestamp>2013-12-24T14:48:44Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2390">== Distributed File Systems ==
Typically [[MapReduce]] I/O operations are performed on distribute file systems.  

One such file system is HDFS - [[Hadoop]] Distribute File System
* ''Name Node'' - the node that orchestrates the process of data distributing and knows where everything is stored

Large files are typically distributed in chunks 64 mb each, and they are stored in data nodes. Each chuck is replicated (typically stored on 3 servers)


=== Hadoop DFS ===
* block-structured file system managed by a single master node 
* MR runs on some underlying storage for reading and writing
* such storage may be distributes
* chunk-based distributed file system
* gives fault tolerance by data partitioning and replication


==== not a DBS! ====
* no indexing
* no random access to files
* no SQL
* if you need DB capabilities on top of HDFS use HBase


== Maintaining Consistency ==
How to maintain [[Consistency (databases)|consistency]] across all these replicas? 

=== Reading ===
When a client needs to read data, it needs to know where this piece of data is:
; a &quot;read&quot; command is issued with an offset - how many bytes the client wants to read 
# The '''name node''' knows where every chunk of data is kept, so the clients read the metadata from it. 
# After getting the metadata, the client reads the data from the '''data node''' (so there's no centralized bottleneck - all reads are in parallel) 

In case the client fails to read a chunk of data, it asks the '''name node''' where the next replica is - and tries again


=== Writing ===
We need to make sure that all the replicas contain the same data (i.e. they are consistent) 
# One replica is considered &quot;main&quot;, and the master knows which one. 
# Client sends the data to be written to all replicas 
: it's written to the main one and propagated to the rest 

* So it supports parallel reads and writes from a large number of processors 
* The reads are arbitrary and random access, but the writes are best when they are added to the end (i.e. appended) 
* Because the architecture relies on the main replica for deciding the order in which multiple append requests are processed, the data is always consistent


https://raw.github.com/alexeygrigorev/ulb-adb-project-couchbd/master/report/images/DFS.png


== Sources ==
* [[Web Intelligence and Big Data (coursera)]]


[[Category:Distributed Systems]]
[[Category:Hadoop]]</text>
      <sha1>a1622r0ggu16ks9sn97l0wb6v12i9ay</sha1>
    </revision>
    <revision>
      <id>678</id>
      <parentid>156</parentid>
      <timestamp>2015-11-23T11:08:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4094">== Distributed File Systems ==
Typically [[MapReduce]] I/O operations are performed on distribute file systems.  
* a distributed FS is a FS that manages data across several machines, so it's network based 
* One such file system is HDFS - [[Hadoop]] Distribute File System


=== Hadoop DFS ===
[[Hadoop MapReduce]] (and other engines) run on an underlying storage for reading and writing
* This storage is typically HDFS
* Large files are typically distributed in chunks, and they are stored in data nodes. 
* Each chuck is replicated (typically stored on 3 servers)


== File Storage ==
=== Blocks ===
* On [[Secondary Storage|disks]], the disk block size is the minimal amount of data that disks can read
* same for DFS: files are broken into block-sized chunks, which are stored as independent units 
* by default a block is ~ 128 mb
* result: a file can be larger than any of the disks on the cluster
* it's also good for replication


=== Namenodes &amp; Datanodes ===
* HDFS uses the master-workers pattern 
* the master is called the Name node
* the workers are called the Data nodes


Namenode
* ''Name Node'' - the node that orchestrates the process of data distributing and knows where everything is stored
* Namenode manages the filesystem namespace, maintains the file tree and metadata for all files and directories 
* given a file, it knows where its block are located - on which datanodes
* the namenode knows how to reconstruct a file from the blocks 
* it's also a single point of failure - if it fails, this information is lost


Datanodes
* datanodes store blocks, and retrieve them when asked by clients 
* periodially report the namenode the list of stored blocks 


== Maintaining Consistency ==
How to maintain [[Consistency (databases)|consistency]] across all these replicas? 


=== Reading ===
When a client needs to read data, it needs to know where this piece of data is:
* a &quot;read&quot; command is issued with an offset - how many bytes the client wants to read 
* The '''name node''' knows where every chunk of data is kept, so the clients read the metadata from it. 
* After getting the metadata, the client reads the data from the '''data node''' (so there's no centralized bottleneck - all reads are in parallel) 

In case the client fails to read a chunk of data, it asks the '''name node''' where the next replica is - and tries again


=== Writing ===
We need to make sure that all the replicas contain the same data (i.e. they are consistent) 
* One replica is considered &quot;main&quot;, and the master knows which one. 
* Client sends the data to be written to all replicas 
* it's written to the main one and propagated to the rest 

* So it supports parallel reads and writes from a large number of processors 
* The reads are arbitrary and random access, but the writes are best when they are added to the end (i.e. appended) 
* Because the architecture relies on the main replica for deciding the order in which multiple append requests are processed, the data is always consistent


https://raw.github.com/alexeygrigorev/ulb-adb-project-couchbd/master/report/images/DFS.png


=== Failure Handling ===
* Namenode is a single point of failure
* to prevent losing data, we can have a secondary namenode
* it's not really a &quot;namenode&quot;, it only keeps a copy of the namespace image - with some logs 
* but logs might not be up-to-date, so you potentially may lose some data if the namenode fails


== HDFS Federation ==
Can federate several namenodes: 
* if there are too many files in HDFS - it's hard for the namenode to manage all of them
* can add another namenode, so each namenode will manage only a portion of the namespace


== Pros and Cons ==
=== Cons ===
Not good for:
* low-latency reads and writes (it's not a Database!)
* lots of small files 


=== HDFS is not a [[Database]]! ===
HDFS has:
* no indexing
* no random access to files
* no SQL
* if you need DB capabilities on top of HDFS use [[HBase]]


== Sources ==
* [[Hadoop: The Definitive Guide (book)]]
* [[Web Intelligence and Big Data (coursera)]]

[[Category:Distributed Systems]]
[[Category:Hadoop]]</text>
      <sha1>ri2k0gj6086g9hhw4gnfxbik2cxrgmz</sha1>
    </revision>
  </page>
  <page>
    <title>CAP Theorem</title>
    <ns>0</ns>
    <id>156</id>
    <revision>
      <id>157</id>
      <timestamp>2014-06-22T16:12:19Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1958">== CAP Theorem ==
'''CAP''' stands for [[Consistency (databases)|'''C'''onsistency]], '''A'''vailability and '''P'''artition tolerance

=== [[Consistency (databases)|Consistency]] ===
In a consistent system values of any objects don't contradict each other
* Do all applications see the same data? 

=== Availability ===
An available system is always usable
* If some nodes fail, does everything still works? 

=== Partition Tolerance  ===
If two parts of your system cannot communicate to each other, can they proceed on their own? 
* if not - sacrifice availability 
* if yes - you need to sacrifice consistency 

If a system is partition-tolerant, then it can continue to operate even in presence of failures


'''Theorem:''' It is impossible to implement a [[Distributed Databases|distributed system]] which will have all three mentioned properties. Only 2 of the 3 is possible to achieve


== Choices ==
* Consequently, one of the 3 must be abandoned
* Different databases choose different options:


https://raw.github.com/alexeygrigorev/ulb-adb-project-couchbd/master/report/images/cap-triangle.png


== Consistency and Availability ==
* But no Partition tolerance
* This is typically preferred by [[Relational Databases|RDBMSs]] - which is why they usually don't offer scalability
* Easy to achieve [[ACID]] under C+A
* Need special algorithms to ensure consistency (like [[Two-Phase Commit]])

== [[Consistency (databases)|Consistency]] and Partition tolerance ==
* But no availability
* HBase chooses consistency and partitioning (no availability)

== Availability and Partition tolerance ==
* but no consistency! Instead, they usually have [[Eventual Consistency]]
* historical example: DNS
* databases: Memcache, [[CouchDB]]

== See also ==
* [[Consistency (databases)]]
* [[BASE]]
* [[Eventual Consistency]]

== Sources ==
* [[Introduction to Data Science (coursera)]]


[[Category:Distributed Systems]]
[[Category:NoSQL]]
[[Category:Databases]]</text>
      <sha1>6shoj3msaqb9g43bdmn2laqd5zlpqcu</sha1>
    </revision>
  </page>
  <page>
    <title>Eventual Consistency</title>
    <ns>0</ns>
    <id>157</id>
    <revision>
      <id>158</id>
      <timestamp>2013-11-15T06:19:16Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3384">== Eventual Consistency ==
* In highly available systems it is very hard to keep replicas consistent, because they have to contact each other every time a write occurs (e.g. with [[Two-Phase Commit]]) to preserve [[Consistency (databases)|consistency]].
* During the time the replicas synchronize everybody should be prevented from writing 
* But that impacts availability, and to have high availability we have to sacrifice that (See the [[CAP Theorem]])


Reasons for Eventual Consistency:
* need to insure high availability 
* need to always support updates (no matter what happens)


So, Eventual consistency is a [[Consistency (databases)|Consistency Model]] in which
* Updates are propagated to replicas eventually, 
* not synchronously with the write 


That is, suppose we have two methods: '''put''' and '''get'''
* put call returns to the caller before the update is applied to all replicas
* but get may return no the most up-to-date object

And there are applications that can tolerate that.



== Conflict Resolution ==
Each modification is a new immutable version of data, which allows multiple versions to be present.
But branching of versions may happen (because of network failures, concurrent updates, etc), so there should be a way to resolve these conflicts.


Also it is important to keep the order in which updates appear 
* to capture causality between different objects: 
* we don't want to overwrite later updates by information in earlier updates when they arrive late. 
* For this mechanisms such as [[Vector Clock]] are used.
* when a client wants to update, it must specify the version it updates 


There are two design choices when dealing with conflicts: 
* who will handle the conflict?
* when it will be handled? 

=== Who? ===
Data storage
* usually not a good option because it knows little about the data it stores 
* although might attempt to merge, for example, text data (like in version control systems)
* usually it means applying policies like &quot;last write wins&quot; to resolve conflicts

Application 
* it knows what data is stored
* so it decide how to resolve the conflict in the way best for it 

=== When? ===
During writes 
* a write may be rejected if the storage is in conflict (while it waits for reconciliation)
* always read non-conflicting data
* (better availability for reads)

During reads
* always writable (better availability for writes)
* rejecting an update may lead to poor customer experience 
* so may read conflicting data, and ourselves have to read it back 



In many systems (Dynamo, MongoDB, [[CouchDB]]) conflicts are allowed and it is usually up to the application to resolve them, and then put the reconciled version back to the database. 


== Configurable Consistency ==
Suppose we have
* $R$ - minimum number of nodes that participate in a successful read
* $W$ - minimum number of nodes that participate is a successful write 
* $N$ - replication factor 


* if $R + W &gt; N$ we can claim consistency
* but $R + W &lt; N$ means lower latency


== Sources ==
* [[Introduction to Data Science (coursera)]]
* [http://the-paper-trail.org/blog/consistency-and-availability-in-amazons-dynamo/ Consistency and availability in Amazon's Dynamo]
* Amazon's Dynamo paper [http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf]


[[Category:Distributed Systems]]
[[Category:NoSQL]]
[[Category:Databases]]</text>
      <sha1>2hf0f335c9tc5fc7se848ib3zu51e6r</sha1>
    </revision>
  </page>
  <page>
    <title>Consistent Hashing</title>
    <ns>0</ns>
    <id>158</id>
    <revision>
      <id>159</id>
      <timestamp>2013-12-25T07:43:08Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2683">== Consistent [[Hash Function|Hashing]] ==
To scale incrementally, [[Distributed Databases]] need a mechanism to dynamically partition over a set of nodes. Consistent Hashing is one of them: it allows to distribute load across several nodes. 


=== &quot;Regular&quot; hashing ===
* need assign  $M$ data keys to $N$ servers 
* assign each key to server number $k \text{ mod } N$

What happens if we increase a number of serves from $N$ to $2N$?
Every existent key will have to be remapped.


=== Consistent Hashing approach ===
* In ''consistent hashing'' a hash function is viewed as a ring: largest hash values wrap around to smallest
* The ring is divided onto $N$ regions ($N$ - number of servers)
* Each server has its own key region (its &quot;position&quot; on the ring)
* $\Rightarrow$ adding or removing a node affects only direct neighbors


https://raw.github.com/alexeygrigorev/ulb-adb-project-couchbd/master/report/images/consistent-hashing-1.png


for example
* the key region for 2nd server is the area between 1 and 2
* and only 2 is responsible for keys in that region

Suppose we want to add a new server
* we just pick some area
* and divide it on 2 parts
* and then assign the new server one of these two
* the keys that happen to be in that region are moved to the new server


https://raw.github.com/alexeygrigorev/ulb-adb-project-couchbd/master/report/images/consistent-hashing-2.png


So routing is simple in this schema:
* each server knows the key range which it manages 
* so we can route the request to the server that is closes to the key we're looking for 


=== Virtual Nodes ===
There are some challenges with this basic approach
* random position assignment may lead to non-uniform data/load distribution
* heterogeneity is performance is assumed (that is, we assume that all the servers have same performance)

A variant of Consistent Hashing algorithm addresses this issue:
* instead of mapping a single node to the ring, 
* each node gets multiple points there 
* so each node has several ''virtual nodes''

A virtual node looks like a single node, but it refers to the real node. 


Advantages
* if a node becomes unavailable, the load is distributes across the remained nodes uniformly (not just the closest neighbor gets all the load)
* and when a new node is added, it gets roughly equivalent amount of load from each node
* number of virtual nodes is chosen  based on the capabilities of a node


== Sources ==
* [[Introduction to Data Science (coursera)]]
* Amazon's Dynamo paper [http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf]


[[Category:Distributed Systems]]
[[Category:Database Systems Architecture]]
[[Category:Algorithms]]</text>
      <sha1>mx4ibdsbjyqeql2f181w57nokk90249</sha1>
    </revision>
  </page>
  <page>
    <title>Vector Clock</title>
    <ns>0</ns>
    <id>159</id>
    <revision>
      <id>160</id>
      <timestamp>2013-12-25T07:39:10Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4363">== Vector Clock ==
Vector Clock is a popular data structure for ensuring ordering of events in distributes systems. It is often used for achieving [[Eventual Consistency]]


'''def:''' a vector clock is a tuple $(t_1, ..., t_n)$  of clock values for each node, with $n$ nodes in total. 

Notation:
for a vector clock $v$, $v[i]$ is the value for node $i$ 

=== Comparison ===
$v_1 &lt; v_2$ if
* for all $i$: $v_1[i] \leqslant v_2[i]$
* for at least one $j$: $v_1[j] &lt; v_2[j]$

$v_1 &lt; v_2$ implies global time ordering 

When data is written to a node $i$, it sets its timestamp $t_i$ to its clock value


=== Causation ===
Suppose we have two events $e_1$ with vector clock $v_1$, and $e_2$ with vector clock $v_2$

$e_1$ happens ''before'' $e_2$ if
* $v_1$ &lt; $v_2$

$e_1$ happens ''concurrently'' to $e_2$ if
* there exist $i, j$ s.t. $v_1[i] &lt; v_2[i]$ and $v_1[j] &gt; v_2[j]$
* (cannot say if $v_1 &lt; v_2$ or $v_2 &lt; v_1$)

$e_1$ happens ''after'' $e_2$ if
* $v_1$ &gt; $v_2$ 


== Usage in databases ==
* Every replica in a database keeps a list of number of updates it has seen. 
* When an update comes, the replica increases its update counter in the vector clock 
* and sends the new clock value with the update to other replicas
* if a read returns a conflicting version, application must reconcile the data and put it back to the database


== Implementation ==
Since the number of nodes may be big, may prefer to have sparse representation, i.e. to store the vector clock as '''(node_id, version)''' pairs


=== Voldemort implementation ===
Here's the [http://www.project-voldemort.com/voldemort/ Voldemort] implementation [http://code.google.com/p/project-voldemort/source/browse/trunk/src/java/voldemort/versioning/VectorClock.java]


class '''ClockEntry'''
* has 2 fields: nodeId and verstion
* method incremented() returns a new ClockEntry with incremented version (same nodeId)


'''VectorClock'''
* 2 fields:
** versions: list of ClockEntry classes
** timestamp: time of the last update
* method incrementVersion(nodeId, time)
: finds the clock entry for the given node and increments the version; also updates the timestamp
* method incremented(nodeId, time)
: same as incrementVerstion, but returns a new VectorClock object
* getMaxVersion() traverses versions and returns the max one
* merge with another VectorClock. Creates a new VectorClock in which
** nodes are merged in sorted order (as in [[Merge Sort]])
** if two nodes have the same nodeId, the max version is used
* method compare returns a value from enum '''{BEFORE, AFTER, CONCURRENT}'''


== Example ==
https://raw.github.com/alexeygrigorev/ulb-adb-project-couchbd/master/report/images/vector-clock-ex.png

Suppose we have 3 servers: $S_x$, $S_y$, $S_z$
# a client writes $D_1$ at $S_x$: $D_1([S_x, 1])$
# another client reads $D_1$ and writes back to $D_2$ (also handled by $S_x$)
#: $D_2([S_x, 2])$ (no conflict and $D_1$ may get garbage collected afterwards)
# another client reads $D_2$, writes back $D_3$ handled by $S_y$: $D_3([S_x, 2], [S_y, 1])$
# at the same time someone else also reads $D_2$ and writes back $D_4$ handled by $S_z$
#: $D_4([S_x, 2], [S_z, 1])$
# now we have two conflicting versions $D_3$ and $D_4$ (there is no causal relation between these versions, i.e. we cannot decide which one came first - the changes there are different)
#: both versions must be kept and presented to the client 
# with next read a client gets both $D_3$ and $D_4$, it merges them and writes back. 
#: this is handled by $S_x$: now the version is $D_4([S_x, 3], [S_y, 1], [S_z, 1])$


== Conflicts ==
How to see if there is a conflict? 


{| border=&quot;1&quot; class=&quot;wikitable&quot;
| Data 1 || Data 2 || Conflict?
|-
| $([S_x, 3], [S_y, 6])$ || $([S_x, 3], [S_z, 2])$ || Yes
|-
| $([S_x, 3])$ || $([S_x, 5])$ || No
|-
|$([S_x, 3], [S_y, 6])$ || $([S_x, 3], [S_y, 6], [S_z, 6])$ || No
|}


== See also ==
* [[Eventual Consistency]]

== Sources ==
* [[Introduction to Data Science (coursera)]]
* [http://www.slideshare.net/guestdfd1ec/design-patterns-for-distributed-nonrelational-databases Design Patterns for Distributed Nonrelational Databases]
* Voldemort vector clock implementation [http://code.google.com/p/project-voldemort/source/browse/trunk/src/java/voldemort/versioning/VectorClock.java]

[[Category:Distributed Systems]]
[[Category:Database Systems Architecture]]
[[Category:Algorithms]]</text>
      <sha1>gtju01sp8d2t8afc9zshpnmocxzctca</sha1>
    </revision>
  </page>
  <page>
    <title>Column-Oriented Databases</title>
    <ns>0</ns>
    <id>160</id>
    <revision>
      <id>161</id>
      <timestamp>2013-11-15T06:49:27Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2763">(article needs improving)

== Column-Oriented databases ==

Are better for storing large amounts of data, especially when the number of columns is very large

* Sets of columns are stored together, so a particular record is actually split across several blocks
* Within each block data is stored in sorted order
* Need to maintain &quot;join index&quot; - to pull together different blocks that are for the same record
* These column-oriented databases are especially good for [[OLAP]] 


== BigTable (HBase) ==
https://raw.github.com/alexeygrigorev/ulb-adb-project-couchbd/master/report/images/Hbase.png


* Tables are distributes across different servers 
* A table is broken into many ''tablets'', each containing multiple rows (''regions'' in HBase) 
* Each tablet is broken into ''column families'', each containing set of columns 
* Each column family spans multiple rows - and stored in chunks of the [[Distributed File Systems|Distributed File System]]
* Each chunk is served by a tablet server (which also takes care of replicas) 


=== Search ===
In order to access any particular record/column, we need to know which tablet server has them 
For that purpose there is a Metadata Table which knows on what tablet server a particular record is.

Search:
* Search starts from the Root Tablet
* We want to find columns for a particular row 
* We look up the root tablet which gives us Child Tablets that contain record's data. 
* Then we get actual chunks where data is stored  



== Example ==
https://raw.github.com/alexeygrigorev/ulb-adb-project-couchbd/master/report/images/col-oriented-db-example.png

* The row is indexed by a key ('''transaction ID''')
* Column families have multiple columns, and columns are stored within single chunks 
* Each Column Family may be stored on different chunk servers 
* The number of column families is fixed, but the number of columns isn't - you may create as many as you want. 

* Additionally each column combination can be timestamped. 
* For example, today the region is one, but tomorrow is another, but you change it not by updating the value, but * rather by inserting a new value with the current timestamp (so versioning is done automatically) 
* Because these DBs rely on DFS - they can do large parallel reads and inserts efficiently. 
* For aggregation queries it's very fast to get results this way 


Downside 
* there is only one key - so you cannot access a record by any value other than id, there is no index for this. 
* If you really need that, you'll have to traverse all the data. 

But it can be overcome by adding a special table with indexes (it's used by Google App Engine) -- Add details? 


== Sources ==
* [[Web Intelligence and Big Data (coursera)]]


[[Category:NoSQL]]
[[Category:Databases]]</text>
      <sha1>kv1mvolmgm07bcaff7cameodnszwuhd</sha1>
    </revision>
  </page>
  <page>
    <title>Two-Phase Commit</title>
    <ns>0</ns>
    <id>161</id>
    <revision>
      <id>162</id>
      <timestamp>2014-01-01T21:23:11Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="921">== Two-Phase Commit ==
A way to ensure consistency in a [[Distributed Databases|distributed system]]


== Two Phases ==
; Phase 1
* coordinator sends &quot;prepare to commit&quot; message
* subordinates make sure they can do that no matter what happens 
* write the action to a [[Database Transaction Log]] to tolerate failures
* subordinates reply with &quot;ready to commit&quot; message

; Phase 2
* if all ready, send &quot;commit&quot;
* if anyone fails, send &quot;abort&quot;


== Example ==
https://raw.github.com/alexeygrigorev/ulb-adb-project-couchbd/master/report/images/two-phase-commit.png

# Coordinator: update
# Coordinator: prepare to commit
# Subordinate: write to log
# Subordinate: say &quot;ready&quot;
# Coordinator: commit


== See also ==
* [[ACID]]: [[Consistency (databases)]] and [[Durability (databases)]]

== Sources ==
* [[Introduction to Data Science (coursera)]]

[[Category:Distributed Systems]]
[[Category:Database Systems Architecture]]</text>
      <sha1>6yp5r5swrfchistmc6nqylck66kqru6</sha1>
    </revision>
  </page>
  <page>
    <title>Document-Oriented Databases</title>
    <ns>0</ns>
    <id>162</id>
    <revision>
      <id>163</id>
      <timestamp>2013-11-17T13:24:07Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1837">== Document-Oriented Databases ==
A document-oriented database is a database designed for storing document-oriented information. Instead of records, as in traditional [[Relational Databases]], these databases use structured and semi-structured documents. It may be XML, JSON or any other structured format. 


=== Documents ===
The central abstraction of these databases is documents.

A ''document'' is 
* a self-contained record: it contains everything it needs (thus, no or little need for joining with other documents)
* a semi-structured record: it is a set of values, each of which may be complex (i.e. hold other values)
* a record with no imposed structure, other then the structure of the format (XML, JSON, etc) that is used to represent the record

Documents inside such databases are not rigid: there are usually no requirements to adhere to any schema, and records are not required to have same files. 

Categorizing
* there are ways to organize records into categories (like relations in [[Relational Databases]])
* typical way: add ''tags'' to mark the category of a record. A tag is usually just another field that specifies the type of a record
* databases usually don't provide tools for categorizing, and it's up to users to decide whether to use tags or not



== Document-Oriented Databases ==
=== MongoDB ===
* JSON (BSON) for storing documents
* [[Eventual Consistency]]

=== [[CouchDB]] ===
* JSON for storing documents
* [[Eventual Consistency]]
* [[REST]] Api

=== OrientDB ===
* 

=== XML Databases ===
Most XML databases are Document-Oriented 


== Sources ==
* [[Introduction to Data Science (coursera)]]
* [http://en.wikipedia.org/wiki/Document-oriented_database Document-oriented database (wikipedia)]

== See also ==
* [[NoSQL]]


[[Category:Distributed Systems]]
[[Category:NoSQL]]
[[Category:Databases]]</text>
      <sha1>6iliz678a5byw6njrlbum5c1zavplez</sha1>
    </revision>
  </page>
  <page>
    <title>CouchDB</title>
    <ns>0</ns>
    <id>163</id>
    <revision>
      <id>164</id>
      <timestamp>2014-01-02T07:15:05Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24822">This is a part of the report made for [[Advanced Databases (ULB)]] course
* The report is available [https://docs.google.com/document/d/1pCfUo8TmxZkl5eFtyZGa42T5HlJJRqOBnc0TFiQAIFM/pub here]


== Couch DB ==
Key features
* HTTP-based [[REST]] Api
* [[Distributed Databases|Distributed]], scalable and fault-tolerant
* [[Document-Oriented Databases|Document-oriented storage]]: the data is self-contained 
** i.e. it contains everything it needs - like real-world document
** not a relational model (with rigid schemata and normal forms)
** [[Relational Databases|Traditional (Relational) DBs]] require you to model the data up-front 
Schema-free design (like in CouchDB) allows to aggregate data after some fact has happened


=== Documents ===
A document is the central data structure in CouchDB, and it uses JSON to store documents

Each document has an id, which must be unique per database. Usually the best ids are UUIDs (Universal Unique ID - random string with extremely low collision probability [http://en.wikipedia.org/wiki/Universally_unique_identifier]), but generally it can be anything 

* A good example of a document is a file for a word processor or a user profile.
* This sort of data you want to denormalize as mush as possible 
* Usually you want to fetch in one request as mush data as it makes sense to display 
* If we need to join some records, we want to precompute as much as possible and store related data together so it's retrieved at the same time. For that there's notion of ''virtual documents'' for that 



=== CouchDB Locally ===
How CouchDB works on a single machine 

https://github.com/alexeygrigorev/ulb-adb-project-couchbd/raw/master/report/images/couchdb-scheme.png

It consists of two components: 
* HTTP REST API
* CouchDB core


== HTTP REST API Overview ==
* CouchDB provides [[REST]]ful HTTP Api to interact with it (To see what's REST consult [http://en.wikipedia.org/wiki/Representational_state_transfer])
* When it's installed with default settings, it can be accessed via http://localhost:5984/


To check if it's running, send a GET request to this address :
&lt;pre&gt;curl -X GET http://localhost:5984/&lt;/pre&gt;
('''curl''' is an unix utility for sending HTTP requests [http://curl.haxx.se/])

The database replies with the following: (if you see that, everything works)
&lt;pre&gt;{
  &quot;couchdb&quot;: &quot;Welcome&quot;,
  &quot;uuid&quot;: &quot;2af023889ce22a70de68547c956e273a&quot;,
  &quot;version&quot;: &quot;1.4.0&quot;,
  &quot;vendor&quot;: {
    &quot;version&quot;: &quot;1.4.0&quot;,
    &quot;name&quot;: &quot;The Apache Software Foundation&quot;
  }
}&lt;/pre&gt;
(here and henceforth formatted for better readability)


To get the list of all available databases, use command &quot;_all_dbs&quot;
&lt;pre&gt;curl -X GET http://localhost:5984/_all_dbs&lt;/pre&gt;

To create a new database, issue a '''PUT''' request to database you want to create 
&lt;pre&gt;curl -X PUT http://localhost:5984/new_database&lt;/pre&gt;

When an operation is successful, it replies with
&lt;pre&gt;{&quot;ok&quot;:true}&lt;/pre&gt;


Adding
* To add new document, we issue a PUT request to url/{database_name}/{document_id}
* since the schema is not rigid, we may put there everything we want, for example 
&lt;pre&gt;curl -X PUT http://localhost:5984/new_database/super_toaster -d '{&quot;title&quot;:&quot;toaster&quot;,&quot;price&quot;:&quot;10$&quot;}'&lt;/pre&gt;
&lt;pre&gt;{&quot;ok&quot;:true,&quot;id&quot;:&quot;super_toaster&quot;,&quot;rev&quot;:&quot;1-8f71d392bd5139ba142eb87ea52096d7&quot;}&lt;/pre&gt;
it returns id of the newly added plus revision id

To retrieve this document use the same url 
&lt;pre&gt;curl -X GET http://localhost:5984/new_database/super_toaster&lt;/pre&gt;
&lt;pre&gt;{
  &quot;_id&quot;: &quot;super_toaster&quot;,
  &quot;_rev&quot;: &quot;1-8f71d392bd5139ba142eb87ea52096d7&quot;,
  &quot;title&quot;: &quot;toaster&quot;,
  &quot;price&quot;: &quot;10$&quot;
}&lt;/pre&gt;
Note that we don't have to specify the id in the document, CouchDB takes care of adding it itself

Mechanisms behind versioning and revisions will be discussed below.


=== Generating a database ===
* You can easily generate a lot of json data with http://json-generator.appspot.com/
* It's easy to bulk post your data to CoachDB [https://couchdb.readthedocs.org/en/latest/api/database.html#post-db-bulk-docs]

We have prepared 80k+ lines of JSON code (1500 documents) with user data to be inserted to the database (available at http://goo.gl/jkcCim)

To create this database execute the following: 
&lt;pre&gt;
# create a database &quot;users&quot;
curl -X PUT http://localhost:5984/users/
# download database data into &quot;database.json&quot;
wget http://goo.gl/jkcCim --no-check-certificate -O test-database.json
# use bulk post to add your data to CouchDB
curl -X POST http://localhost:5984/users/_bulk_docs -H &quot;Content-Type:application/json&quot; -d @test-database.json
# at this point, CouchDB will answer with a list of newly added ids
&lt;/pre&gt;


=== Futon ===
You don't have to interact with CouchDB only via HTTP requests: there is a web application for managing the database through a web browser, called Futon, which comes along with CouchDB. To access it, open your browser and go to http://localhost:5984/_utils/

https://github.com/alexeygrigorev/ulb-adb-project-couchbd/raw/master/report/images/futon.png

With Futon you can create databases and explore existing ones

To see what's inside a document, just chick on it

There are two options: 
* to see formatted version of JSON 
* or raw JSON data


== Core ==
Main core components:
* [[B-Tree]]-based storage engine
* [[MapReduce]] for querying (MapReduce queries are called ''views'')


=== Design Documents ===
A ''design document'' is a special type of documents that contain application code. 
* They also live inside the database, but they are highly structured.
* These documents are very similar to usual documents: they can be replicated, have id and revision id. 


Virtual Documents
* We typically want to fetch all the data we want to display in one request, so it makes sense to store related records together, and if there is a need for joining, we want to precompute this.
* For that there's a technique called &quot;virtual documents&quot; which uses views to collate data together


A design document starts with a special prefix &quot;_design/&quot;.

A design document may contain:
* [[MapReduce]] queries: &quot;views&quot; field
* &quot;show&quot; and &quot;list&quot; functions to render responses in other formats rather than JSON: XML, HTML, whatever you want 


=== Validation ===
Validation is a powerful tool to ensure that only document you need/want end up in your database 
* There is a function &quot;validate_doc_update&quot; in a design document 
* this function must not have any side-effects, and they are run in isolation 
* it also can block invalid updated from other CouchDB instances during replication 
* This function is executed each time a document is added or updated 
** if it raises an exception, the update is canceled, otherwise - accepted 
* Validation is optional, if there's no such function, every update will get accepted 


A design document may contain only one validation function, but if you have several design documents, all the validation function will be executed on a write request. If at least one of them decides to reject, the update is rejected. 
* NB: order of execution is not defined, so you must not make any assumptions about it 


&lt;pre&gt;function(newDoc, savedDoc, ctx) {
  // some logic 
  if (/* validation */) {
    throw({unauthorized: 'some message'})
  }
}
&lt;/pre&gt;


=== Types ===
Types are needed to ensure that documents have proper type - i.e. have all required fields 
* This is a common pattern: to assign document types to records 
* It's not the part of CouchDB and it's up to user to decide whether to include type fields or not 

Consider the following validation query

&lt;pre&gt;function(newDoc, oldDoc, ctx) {
  if (newDoc.type == &quot;post&quot;) {
    // validate post
  }
  if (newDoc.type == &quot;comment&quot;) {
    // validate comment
  }
}
&lt;/pre&gt;



== Queries and MapReduce ==
For [[Relational Databases]] you can issue any query, and as long as you data is structured correctly, you'll be able to get an answer. 

However, documents aren't always as structured as relations in Relational Databases, and for that we need a different approach. For CouchDB this approach is [[MapReduce]].

A user has to provide two functions that will operate on all data:
* Map - apply to each document and emit zero or more key/value pairs
* Reduce - apply reduce function to the result of Map function grouped by key
* A combination of Map and Reduce functions is called a ''view'' 

These functions provide CouchDB with great flexibility: they can adapt to various document structures. 


=== Views ===
So a view is a combination of map and reduce functions

Views:
* allows for parallel and incremental computation of views (described below)
* since MapReduce produces key-value pairs, the results are also stored in the B-Trees 
* View results are stored in a B-Tree (like documents), but in their own file 

View functions are stored inside &quot;views&quot; field of a design document
* Once you create a view, you query it to get results 


=== Map ===
* Map is applied to each document and emits zero or more key/value pairs - ''view rows''
* A map function doesn't depend on any information outside of the document, which allows CouchDB views be generated incrementally and in parallel 
* Views are stored as rows that are sorted by key in a [[B-Tree]], which makes range retrievals efficient
* When writing a map function, your goal is to build an index that stores related data recodes under nearby keys.

Incremental Computation of Map Results 
* a map function runs through all records when you first query the view 
* a call to emit creates an entry in the view results where everything is sorted by the key
* indexes for each document can be computed independently and in parallel 
* if a document is changed, the map function is run only once to recompute the key and values for this single documents 
* if a document is deleted, corresponding entries are marked ''invalid'' - and they don't show up in the results 


=== Reduce ===
Reduce is applied after map


=== Querying Views ===
to query a view use the following url

&lt;pre&gt;curl -X GET HOST/db/_design/{design_document}/_views/{view_name}&lt;/pre&gt;

but you also can pass a ''view parameter''

&lt;pre&gt;curl -X GET HOST/db/_design/{design_document}/_views/{view_name}?key=&quot;abcd&quot; &lt;/pre&gt;

where &quot;abcd&quot; is the key we used in &quot;emit&quot; call


=== Examples ===
Retrieve all active users that are women with more than 3 friends

&lt;pre&gt;function(doc) {
  if (doc.isActive &amp;&amp; doc.gender == 'female' &amp;&amp; doc.friends.length &gt;= 3) {
    emit(null, doc);
  }
}&lt;/pre&gt;


This gives us unsorted output (it is sorted by document id, which gives us an impression that the result is not ordered)

Since the results are sorted by keys emitted by a map function, we to order the result on the last name of a user, we pass their name as the first argument of emit function

&lt;pre&gt;function(doc) {
  if (doc.isActive &amp;&amp; doc.gender == 'female' &amp;&amp; doc.friends.length &gt;= 3) {
    var lastName = doc.name.split(&quot; &quot;)[1];
    emit(lastName, doc);
  }
}&lt;/pre&gt;


Consider another view:
&lt;pre&gt;function(doc) {
 if (doc.isActive &amp;&amp; doc.gender == 'female' &amp;&amp; doc.friends.length &gt;= 3) {
   var lastName = doc.name.split(&quot; &quot;)[1];
   emit(lastName, {&quot;name&quot;: doc.name, &quot;email&quot;: doc.email});
 }
}
&lt;/pre&gt;

It outputs names and emails of all active female users with at least 3 friends and sorts the result by their last names.


Suppose we want to calculate what is the average balance for all active female users with at least 3 friends. Here is our view:

&lt;pre&gt;
function(doc) {
 if (doc.isActive &amp;&amp; doc.gender == 'female' &amp;&amp; doc.friends.length &gt;= 3) {
   var sum = doc.balance.replace(',', '').slice(1);
   emit(null, parseInt(sum));
 }
}

function(keys, values) {
 return sum(values) / values.length;
}
&lt;/pre&gt;


The result is only one value. It is also possible to calculate the average value per group. Say, we want to see the average salary per first letter of user’s last name

&lt;pre&gt;
function(doc) {
 if (doc.isActive &amp;&amp; doc.gender == 'female' &amp;&amp; doc.friends.length &gt;= 3) {
   var sum = doc.balance.replace(',', '').slice(1);
   var lastName = doc.name.split(&quot; &quot;)[1];
   var firstLetter = lastName[0];
   emit(firstLetter , parseInt(sum));
 }
}

function(keys, values) {
 return sum(values) / values.length;
}
&lt;/pre&gt;


== Replication ==
A replication is a mechanism that allows to synchronize two or more database instances.

Reasons for doing replication:
* reliability 
* scaling
* load balancing


=== [[Eventual Consistency]] ===
* [[Distributed Databases|Distributed systems]] operate over some network, 
* and networks are often segmented (see Partition Tolerance in the [[CAP Theorem]]). 
* Eventual consistency means that data will be consistent eventually, but the database is always available


=== Incremental Replication ===
Data is kept locally
* no need for constant network access for communicating with other CouchDB instances
* synchronization happens whenever possible (when a network connection appears, etc)

Replication in CouchDB works incrementally
* only differences are replicated, not whole databases
* if something during the replication goes wrong,
* when this is fixed, next time it starts from the same moment 


Note that replication is unidirectional (from source to target)
If you want bidirectional replication, run it twice, swapping the source and the target for the second run.


Incremental Replication
* CouchDB achieves eventual consistency by Incremental Replication - this is the process when all document changes are copied periodically.
* This is called &quot;Shared Nothing&quot; cluster of databases with each node being independent and self-sufficient: these is no single point of connection in the system.
* Changes can be propagated in any way we like, and after replication each server can continue working independently 


This is how it works 
: https://github.com/alexeygrigorev/ulb-adb-project-couchbd/raw/master/report/images/couchdb-changes-propagation.png
: (figure source [http://guide.couchdb.org/draft/consistency.html#figure/4])

To scale the system we just add another server


Schematically we may show replication like that:

https://github.com/alexeygrigorev/ulb-adb-project-couchbd/raw/master/report/images/couchdb-replication.png

When the replication process is run
* first, it runs the comparison between the two servers, which returns a list of changed documents
*: this includes:
** new documents
** changed documents
** deleted documents
: documents that exist both on source and on target are not transfered (only differences will be moved)


Databases in CouchDB have a ''sequence number''
* it gets incremented when any change occurs 
* it remembers what change was associated with a particular sequence number

So calculating difference between source and target is efficient

If replication process is interrupted, the target database may be left in an inconsistent state.
But if you trigger the replication again, it will continue from the moment of interruption 


=== Replication API ===
To synchronize two databases we issue a simple PUT request where we specify
* the source of the updates 
* the target 

CouchDB will figure out what are the new documents and what are the new revisions that are no the source but not yet on the targer, and will transfer it to the target 
&lt;pre&gt;curl -X PUT http://localhost:5984/_replicate -d '{&quot;source&quot;:&quot;users&quot;,&quot;target&quot;:&quot;users_replica&quot;}'&lt;/pre&gt;
The database replies with some statistics and tells if it was successful or not 

'''NB''': the request for replication will stay open till the replication process finishes, so it may take a while 


== Concurrency ==
In a typical relational database when we modify a table, we put a lock - and all other clients that want to access the table are queued

This sequential execution of tasks wastes a lot of processor's power and time: under high load it may spend a lot of time trying to figure out whose turn is next

MVCC, [[Multi-Version Concurrency Control]], is used to manage concurrent access to the data in CouchDB 

https://github.com/alexeygrigorev/ulb-adb-project-couchbd/raw/master/report/images/couchdb-concurrency.png

(figure source: [http://guide.couchdb.org/draft/consistency.html#figure/3])

This concurrency model allows CouchDB to run effectively even under high load, without worrying about queuing requests. 


=== [[B-Tree]] storage engine ===
B-Tree (CouchDB uses a variation of a B-Tree [http://en.wikipedia.org/wiki/B-tree] [http://www.scholarpedia.org/article/B-tree_and_UB-tree] called B+Tree [http://en.wikipedia.org/wiki/B%2B_tree])
* ''B-Tree'' is a sorted data structure that allows for searching, insertions and deletion in logarithmic time 
* Lookup is $O(\log N)$ time, and range is $O(\log N + K)$


This data structure is used everywhere, also for internal data: documents and views
* Usage of this data structure imposes an important restriction: can access only by key. 
* Reason: to be make huge performance gains 

In CouchDB the implementation is a little bit different from original B+Trees. It adds:
* Support for MVCC 
** reads and writes without locking the system 
** writes do not block reads 
** this is because of append-only design 
* append-only design 
** old versions are not deleted
** every time something is updated, a new node is created, and a new root as well
*** but old reads still have references to the old root,
*** so they are able to continue reading without being interrupted, 
*** i.e. have old consistent state 
** data never lost and never corrupted


== Conflicts Management ==
=== Versioning ===
All documents have versions (like in version control systems such as SVN)

If you want to change a document, you create a new one and save it over the old one. After doing that there will be two versions of the same document. Since a new version is just appended to the database, the read requests don't have to be suspended. 

Once a new version is appended, all new requests are routed to this newer version


Updates in CoachDB
* load object
* change something
* save as a new revision


each revision is identified with a new &quot;_rev&quot; value

if you want to update or delete a document, you must specify the revision you're updating. This is to ensure that you will not overwrite some other update 

suppose you want to update a document without providing the revision id: 

&lt;pre&gt;curl -X PUT http://localhost:5984/new_database/super_toaster -d '{&quot;title&quot;:&quot;toaster&quot;,&quot;price&quot;:&quot;15$&quot;}'&lt;/pre&gt;

CouchDB responses with an error:

&lt;pre&gt;{&quot;error&quot;:&quot;conflict&quot;,&quot;reason&quot;:&quot;Document update conflict.&quot;}&lt;/pre&gt;

So we add the revision id to the document we're updating: 

&lt;pre&gt;curl -X PUT http://localhost:5984/new_database/super_toaster -d '{&quot;title&quot;:&quot;toaster&quot;,&quot;price&quot;:&quot;15$&quot;,&quot;_rev&quot;:&quot;1-8f71d392bd5139ba142eb87ea52096d7&quot;}'&lt;/pre&gt;

This time the database replies with &quot;ok&quot; and a new revision update:
&lt;pre&gt;{&quot;ok&quot;:true,&quot;id&quot;:&quot;super_toaster&quot;,&quot;rev&quot;:&quot;2-9c85d3c3324c3777a4665f00330b73b5&quot;}&lt;/pre&gt;


=== Conflicts ===
A ''conflicting'' change is a change that occurs simultaneously in two or more replicas. This happens regularly in [[Distributes Databases]].

So a ''document conflict'' means that now there are two latest revisions of the same document.


CouchDB can detect a conflicting change in a document and signals it with &quot;_conflict&quot; flag set to true.

When there are two revisions of the same file, CouchDB has to choose one ''winning'' revision - revision that will be stored and the latest revision. However the ''loosing'' revisions aren't deleted - they are stored as well, but as previous revisions. 


CouchDB doesn't attempt to reconcile the conflicting changes: it ensures that all conflicts are detected, but it's up to the application to deal with them. Essentially this is the same mechanism used by SVN [http://en.wikipedia.org/wiki/Apache_Subversion] and other popular version control systems. 


=== Conflict Resolution ===
Replication from $A$ to $B$ (assuming triggered replication, not continuous)
Direction $A \to B$ (not $B \to A$)

All other types of replication are reduced to these steps

# $A$: create document $d_1$
# trigger replication $A \to B$
# now $B$ also has $d_1$
# change $d_1$ on $B$ (CouchDB generates a new revision id)
# change $d_1$ on $A$ (CouchDB also generates a new different revision id)
# trigger replication $A \to B$
# CouchDB detects a conflict (two conflicting revisions of the same document)
# Application resolves the conflict:
#* it tells CouchDB which revision to keep 
#* another way: we merge two revisions, update the document and CouchDB will generate a hew revision and mark the conflict resolved

To see if we have any conflicts we may use this simple view: 

&lt;pre&gt;
function(doc) {
  if (doc._conflicts) {
    emit(doc._conflicts, null)
  }
}
&lt;/pre&gt;

&quot;_conflict&quot; is an array that contains all conflicting revisions


=== Choosing Winning Revision ===
CouchDB uses a deterministic algorithm to ensure that each CouchDB instance will come up with the same winning and loosing revision. 

Note that your application should never depend on these details and should treat the results as an  arbitrary choice rather than some deterministic algorithm. 

Algorithm
* Each revision has a revision history: a list with all previous revision IDs. 
* A version with longest revision history wins
* If the length is the same, &quot;_rev&quot; values are compared in ASCII sort order
: for example, &quot;2-de...&quot; wins over &quot;2-7e...&quot;

If we don't agree with CouchDB automatic choice, we delete one revision and keep another 

&lt;pre&gt;curt -X DELETE $HOST/database/document_id?rev=2-de...&lt;/pre&gt;

This returns a new revision (remember that a delete is also an update)

Next, we put the values we want to keep back to the database, specifying the revision we like

&lt;pre&gt;curl -X PUT $HOST/database/document_id -d '{..., &quot;_rev&quot;:&quot;2-7e...&quot;}'&lt;/pre&gt;

It also responses with a new revision ID. 

This way we resolve the conflict 

Now we need to replicate $B \to A$, so both instances are synchronized. 


=== Revision ID ===
Let's have a look at a typical revision ID:

3-dad88c6c6a0df7f0e09e1e2d0d145eeb
* 3 - an integer, the current version number, it gets incremented with each update
* dad88c6c6a0df7f0e09e1e2d0d145eeb - md5 hash over a set of properties: JSON body, attachments, &quot;_delete&quot; flag


It means that:
* updates on the same document on different instances create their own independent revision IDs. 
* for two different documents with same data the right part of the revision ID will be the same:

&lt;pre&gt;$ curl -X PUT $HOST/db/a -d '{&quot;a&quot;:1}'
{&quot;ok&quot;:true,&quot;id&quot;:&quot;a&quot;,&quot;rev&quot;:&quot;1-23202479633c2b380f79507a776743d5&quot;}
$ curl -X PUT $HOST/db/b -d '{&quot;a&quot;:1}'
{&quot;ok&quot;:true,&quot;id&quot;:&quot;b&quot;,&quot;rev&quot;:&quot;1-23202479633c2b380f79507a776743d5&quot;}&lt;/pre&gt;


=== Revision Tree ===
https://github.com/alexeygrigorev/ulb-adb-project-couchbd/raw/master/report/images/revisions-list1.png

When there is a conflict, the history branches into a tree
* each branch can extent its own history independently 
* the last documents in the tree (i.e. leaves) are the set of conflicting revisions
** in this case these are $r_{4a}, r_{3b}, r_{2c}$

The way to resolve conflict: 
* combine all the conflicting revisions ($r_{4a}, r_{3b}, r_{2c}$) into a single document 
* replace one of them, say $r_{4a}$ with the new document. That will give us a new revision $r_{5a}$ 
* delete all the remaining of leaves: $r_{3b}, r_{2c}$
 
https://github.com/alexeygrigorev/ulb-adb-project-couchbd/raw/master/report/images/revisions-list2.png

* Note that when we delete a record, another revision is added to the revision tree, and the deleted record still exists, but as &quot;deleted&quot; node. 
* It will be still possible to retrieve this record, but it will be marked with &quot;_deleted&quot; flag set to true
* Also afterwards during compaction data from non-leaf nodes will be removed
** leaving only a chunk of metadata called ''tombstone'' plus 
** the list of historical &quot;_revs&quot; is still retained in case in future you meet old database replicas 
* There also is a mechanism for &quot;pruning&quot; the revision tree to prevent it from growing too large 


== Misc ==
=== Compaction ===
Compaction is a mechanism used to reduce disk space usage 
* by removing unused and old data from database or view index files

During the compaction of a database CouchDB 
* creates a new file with &quot;.compact&quot; extension and transfers only actual data into it
* when the data successfully transferred, the &quot;.compact&quot; file replaces the actual database file 

Old revisions are replaced with a ''tombstone'' - a small piece of metadata that will be used for conflict resolution 

To cause the compaction manually, run 

&lt;pre&gt;curl -X POST HOST/{database}/_compact&lt;/pre&gt;





== Sources ==
* [http://guide.couchdb.org/draft CouchDB The Definitive Guide by Anderson, Lehnardt and Slater]
* [http://docs.couchdb.org/en/latest/replication/conflicts.html CouchDB documentation: Replication and Conflict Model]

[[Category:NoSQL]]
[[Category:Distributed Systems]]
[[Category:Databases]]</text>
      <sha1>c0d8lw957x6b9uo5znbxoum4g3sefup</sha1>
    </revision>
  </page>
  <page>
    <title>Relational Algebra</title>
    <ns>0</ns>
    <id>164</id>
    <revision>
      <id>165</id>
      <timestamp>2014-01-03T09:15:58Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11128">\(\newcommand{\AntiJoin}{ \ \bar{\Join} \ } \)

== Relational Algebra ==
* Relational Algebra repesents the operations on relations for [[Relational Databases]]
* Relational Algebra is algebra that consists of operations for constructing new relations from given relations 
** (it's ''closed'', i.e. each operation always produces another relation)
* RA is not used as a query language, but usually [[Translating SQL to Relational Algebra|SQL is translated to it]] in RDBMS


== Relational Algebra Operators ==
Operations of traditional RA:
* usual set operations (union, intersection, difference)
* operations that remove some parts of the relation
: selections eliminate tuples (rows)
: projections eliminate attributes (columns)
* operations to combine tuples of two relations: Cartesian product, joins, etc
* renaming

Binary
* Union U
* Intersection
* Difference 

Unary
* Projection
* Join

Extended RA
* bags semantic
* duplicate elimination: $d$
* Grouping and aggregation: $\gamma$
* Sorting: $t$


== Traditional RA Operations ==
=== Set-Based Union ===
$R_1 \cup R_2$

* Both $R_1$ and $R_2$ must have the same schema
* And the result is a relation with the same schema
* The result contains elements that are in $R_1$ or in $R_2$

SQL:
&lt;pre&gt;
SELECT * FROM R1
UNION
SELECT * FROM R2
&lt;/pre&gt;

Example:

$\begin{array}{ c | c }
  A &amp; B \\
  \hline
  \hline
  a_1 &amp; b_1 \\ 
  a_2 &amp; b_1 \\
\end{array}
\cup
\begin{array}{ c | c }
  A &amp; B \\
  \hline
  \hline
  a_1 &amp; b_1 \\ 
  a_3 &amp; b_3 \\
\end{array}
=
\begin{array}{ c | c }
  A &amp; B \\
  \hline
  \hline
  a_1 &amp; b_1 \\ 
  a_2 &amp; b_1 \\
  a_3 &amp; b_3 \\
\end{array}
$


=== Set-Based Difference ===
$R_1 - R_2$

* Both $R_1$ and $R_2$ must have the same schema
* And the result is a relation with the same schema
* The result contains elements that are in $R_1$ but not in $R_2$


&lt;pre&gt;
SELECT * FROM R1
EXCEPT 
SELECT * FROM R2
&lt;/pre&gt;


Example: 
* $\begin{array}{ c | c }
  A &amp; B \\
  \hline \hline
  a_1 &amp; b_1 \\ 
  a_2 &amp; b_1 \\
\end{array}
\cup
\begin{array}{ c | c }
  A &amp; B \\
  \hline \hline
  a_1 &amp; b_1 \\
  a_3 &amp; b_3 \\
\end{array}
=
\begin{array}{ c | c }
  A &amp; B \\
  \hline \hline
  a_2 &amp; b_1 \\
\end{array}
$


=== Set-Based Intersection ===
$R_1 \cap R_2$

* Both $R_1$ and $R_2$ must have the same schema
* And the result is a relation with the same schema
* The result contains elements that are in $R_1$ and in $R_2$


SQL 
&lt;pre&gt;
SELECT * FROM R1
INTERSECT 
SELECT * FROM R2
&lt;/pre&gt;


Example

$\begin{array}{ c | c }
  A &amp; B \\
  \hline
  \hline
  a_1 &amp; b_1 \\ 
  a_2 &amp; b_1 \\
\end{array}
\cup
\begin{array}{ c | c }
  A &amp; B \\
  \hline
  \hline
  a_1 &amp; b_1 \\ 
  a_3 &amp; b_3 \\
\end{array}
=
\begin{array}{ c | c }
  A &amp; B \\
  \hline
  \hline
  a_1 &amp; b_1 \\ 
\end{array}
$


Can be expressed via [[#Set-Based Union|Union]] and [[#Set-Based Difference|Difference]]
* $R_1 \cap R_2 = R_1 - (R_1 - R_2)$
* $R_1 \cap R_2 = R_1 \Join R_2$


=== Selection ===
A binary operator 
* Takes a relation $R$
* Outputs all  tuples of $R$ that satisfy a certain condition $\theta$
* Attributes that take part in $\theta$ must be present in the relation $R$

in SQL:
&lt;pre&gt;SELECT ... FROM R WHERE {condition}&lt;/pre&gt;

For example
* $\sigma_\theta(\text{Relation})$
* $\sigma_{A \geqslant 3} \left (
\begin{array}{ c | c }
  A &amp; B \\
  \hline \hline
  1 &amp; 2 \\ 
  3 &amp; 4 \\
\end{array} 
\right) 
= 
\begin{array}{ c | c }
  A &amp; B \\
  \hline \hline
  3 &amp; 4 \\
\end{array}
$


A condition can be anything
* salary &gt; 40000 (inequality)
* name = &quot;Smith&quot; (equation)
* etc


=== Set-Based Projection ===
$\pi_{A_1, ..., A_n}(R)$ 

A binary operator 
* Takes a relation $R$
* Outputs only specified attributes $A_1, ..., A_n$ of $R$
* All $A_1, ..., A_n$ must be present in $R$

SQL:
&lt;pre&gt;SELECT A1, ..., An FROM R&lt;/pre&gt;

example
* $\pi_{\text{SSN}, \text{name}}(\text{Employee})$


Note that for set-based projection there are no duplicated in the output:
* $\pi_{A, C} \left( 
\begin{array}{ c | c | c | c}
  A &amp; B &amp; C &amp; D \\
  \hline \hline
  1 &amp; 2 &amp; 3 &amp; 4 \\ 
  1 &amp; 2 &amp; 3 &amp; 5 \\
  3 &amp; 4 &amp; 5 &amp; 6 \\
  5 &amp; 6 &amp; 3 &amp; 4 \\
\end{array}
\right) = 
\begin{array}{ c | c}
  A &amp; C \\
  \hline \hline
  1 &amp; 3 \\ 
  3 &amp; 5 \\
  5 &amp; 3 \\
\end{array}$



=== Cartesian Product ===
Sometimes also called &quot;Cross-Product&quot;

$R_1 \times R_2$
* Result of $R_1 \times R_2$ is a new relation 
* in which each tuple in $R_1$ concatenated with each tuple in $R_2$
* i.e. it outputs all possible combinations of tuples
* $R_1$ and $R_2$ must have disjoint schema

SQL 
&lt;pre&gt;SELECT * FROM R1, R2&lt;/pre&gt;

Example:
* $\begin{array}{ c | c}
  A &amp; B \\
  \hline \hline
  1 &amp; 2 \\ 
  3 &amp; 4 \\
\end{array} 
\times 
\begin{array}{ c | c}
  C &amp; D \\
  \hline \hline
  2 &amp; 6 \\ 
  3 &amp; 7 \\
  4 &amp; 9 \\
\end{array} 
=
\begin{array}{ c | c | c | c}
  A &amp; B &amp; C &amp; D \\
  \hline \hline
  1 &amp; 2 &amp; 2 &amp; 6 \\
  1 &amp; 2 &amp; 3 &amp; 7 \\
  1 &amp; 2 &amp; 4 &amp; 9 \\
  3 &amp; 4 &amp; 2 &amp; 6 \\
  3 &amp; 4 &amp; 3 &amp; 7 \\
  3 &amp; 4 &amp; 4 &amp; 9 \\
\end{array}
$


=== Natural Join ===
Or &quot;Equi-Join&quot; 

$R \Join S$
* no requirements for schema for $R$ and $S$
* if they have one or more attributes in common, in the output tuples with same values will be matched
* if they don't have attributes in common - the result is the same as $R \times S$ ([[#Cartesian Product|Cartesian Product]])

Example:
* $\begin{array}{ c | c}
  A &amp; B \\
  \hline \hline
  1 &amp; 2 \\ 
  3 &amp; 4 \\
\end{array} 
\Join
\begin{array}{ c | c}
  B &amp; D \\
  \hline \hline
  2 &amp; 6 \\ 
  3 &amp; 7 \\
  4 &amp; 9 \\
\end{array} 
=
\begin{array}{ c | c | c}
  A &amp; B &amp; D \\
  \hline \hline
  1 &amp; 2 &amp; 6 \\
  3 &amp; 4 &amp; 9 \\
\end{array}
$
* $\begin{array}{ c | c}
  A &amp; B \\
  \hline \hline
  1 &amp; 2 \\ 
  3 &amp; 4 \\
\end{array} 
\Join 
\begin{array}{ c | c}
  C &amp; D \\
  \hline \hline
  2 &amp; 6 \\ 
  3 &amp; 7 \\
  4 &amp; 9 \\
\end{array} 
=
\begin{array}{ c | c | c | c}
  A &amp; B &amp; C &amp; D \\
  \hline \hline
  1 &amp; 2 &amp; 2 &amp; 6 \\
  1 &amp; 2 &amp; 3 &amp; 7 \\
  1 &amp; 2 &amp; 4 &amp; 9 \\
  3 &amp; 4 &amp; 2 &amp; 6 \\
  3 &amp; 4 &amp; 3 &amp; 7 \\
  3 &amp; 4 &amp; 4 &amp; 9 \\
\end{array}
$

=== Theta Join ===
$R_1 \Join_{\theta} R_2$

* A join that involves some predicate $\theta$ 
* For all combinations of tuples from $R_1 \Join_{\theta} R_2$, a tuple is output if $\theta$ holds for the combination
* essentially is the same as [[#Cartesian Product|Cartesian Product]] plus [[#Selection|Selection]]

Examples
* $R_1 \Join_{\theta} R_2 = \sigma_{\Theta}{R_1 \times R_2}$ 
* $\begin{array}{ c | c}
  A &amp; B \\
  \hline \hline
  1 &amp; 2 \\ 
  3 &amp; 4 \\
\end{array} 
\Join_{B = C}
\begin{array}{ c | c}
  C &amp; D \\
  \hline \hline
  2 &amp; 6 \\ 
  3 &amp; 7 \\
  4 &amp; 9 \\
\end{array} 
=
\begin{array}{ c | c | c | c}
  A &amp; B &amp; C &amp; D \\
  \hline \hline
  1 &amp; 2 &amp; 2 &amp; 6 \\
  3 &amp; 4 &amp; 4 &amp; 9 \\
\end{array}
$


=== Anti-Join ===
$R \AntiJoin S$
* if for a tuple in $R$ there is a match in $S$, we do not output this tuple from $R$
* $R \AntiJoin S \equiv R - (R \Join S)$
* The result is only tuples from $R$ (the resulting schema is also the same as in $R$)


Difference between $R \AntiJoin S$ and $R - S$ ([[#Set-Based Difference|Difference]]):
* for Difference $R - S$ both $R$ and $S$ need to have the same schema
* for $R \AntiJoin S$ - any schema
* if $R$ and $S$ have the same schema, then $R \AntiJoin S \equiv R - S$

Example
* $\begin{array}{ c | c}
  A &amp; B \\
  \hline \hline
  1 &amp; 2 \\ 
  3 &amp; 4 \\
  5 &amp; 6 \\
  6 &amp; 7 \\
\end{array} 
\AntiJoin
\begin{array}{ c | c | c }
  B &amp; C &amp; D \\
  \hline \hline
  2 &amp; 5 &amp; 6 \\ 
  6 &amp; 4 &amp; 2 \\
\end{array} 
=
\begin{array}{ c | c }
  A &amp; B \\
  \hline \hline
  3 &amp; 4 \\
  6 &amp; 7 \\
\end{array}
$



=== Renaming ===
$\rho_{\text{prefix}}(R)$
* takes all attributes of $R$ and
* produces a new relation with $\text{prefix.}$ appended to all of them
* so the resulting relation is the same, but with changed schema 

SQL

&lt;pre&gt;SELECT * FROM Relation R&lt;/pre&gt;

Example 
* $\rho_T \left( 
\begin{array}{ c | c}
  A &amp; B \\
  \hline \hline
  1 &amp; 2 \\ 
  3 &amp; 4 \\
\end{array}
\right)
= 
\begin{array}{ c | c}
  T.A &amp; T.B \\
  \hline \hline
  1 &amp; 2 \\ 
  3 &amp; 4 \\
\end{array}$


=== Examples ===
find all hospitals within 5 ms of a school


&lt;pre&gt;
SELECT DISTINCT h.name 
FROM Hospital h, School s
WHERE distance(h.location, s.location) &lt; 5
&lt;/pre&gt;

$\pi_\text{name} ( \rho_{\text{h}}(\text{Hospital}) \Join_{\text{h.location = s.location}} \rho_{\text{s}}(\text{School}) )$


=== Outer Joins ===
...


=== Semi Joins ===
$R \ltimes S = \pi_{R.*}(R \Join S)$

== Extended RA ==
* Adds additional operations to Transitional RA 
* Allows Bag semantics for operations

=== Sets vs Bags ===
* ''Set'' of tuples: no duplicates allowed
* ''Bag'' of tuples: there can be duplicates
* In theory set semantics is usually assumed
* But in implementation - bag semantics

Duplicates 
* Practically we don't care about duplicates 
* We remove them only when required (duplicate elimination: $d$)

RA has two semantics: 
* set semantics = traditional RA
* bag semantics = extended RA 

All set-based operations are straightforwardly extended to bags


=== Bag-Based Intersection, Difference, Union ===
Intersection
* If the same tuple occurs twice in one relation, 
* It must also occur twice in the second relation
* Then the result will also contain 2 tuples

Same idea with Difference and Union


=== Grouping ===
$\gamma_{\text{grouping_attribute}, \ \text{func}(A) \ \to \ \text{name}}(R)$
* unary relation that takes $R$ as input 
* first parameter ($\text{grouping_attribute}$) is attribute on which $R$ will be grouped 
* function $\text{func}$ is applied to each group, and the result is written to attribute $\text{name}$
* '''NB''': all other (non-mentioned) attributes are not output to the result! 

Example
* $\gamma_{A, \ \text{min}(B) \ \to \ D} \left(
\begin{array}{ c | c | c }
  A &amp; B &amp; C \\
  \hline \hline
  1 &amp; 2 &amp; a \\
  1 &amp; 3 &amp; b \\
  2 &amp; 3 &amp; c \\
  2 &amp; 4 &amp; a \\
  2 &amp; 5 &amp; d \\
\end{array}
\right)
= 
\begin{array}{ c | c | c }
  A &amp; D \\
  \hline \hline
  1 &amp; 2 \\
  2 &amp; 3 \\
\end{array}
$



=== Projection ===
* same as [[#Set-Based Projection|Set-Based Projection]], but we don't need to eliminate duplicates
* hence it's more efficient 


In Extended RA we also can allow renaming in projection
* $\pi_{A, C \to D} \left( 
\begin{array}{ c | c | c | c}
  A &amp; B &amp; C &amp; D \\
  \hline \hline
  1 &amp; 2 &amp; 2 &amp; 6 \\
  1 &amp; 2 &amp; 2 &amp; 7 \\
  1 &amp; 2 &amp; 2 &amp; 9 \\
  3 &amp; 4 &amp; 3 &amp; 6 \\
  3 &amp; 4 &amp; 3 &amp; 7 \\
  3 &amp; 4 &amp; 3 &amp; 9 \\
\end{array}
\right) = 
\begin{array}{ c | c}
  A &amp; D \\
  \hline \hline
  1 &amp; 2 \\
  1 &amp; 2 \\
  1 &amp; 2 \\
  3 &amp; 3 \\
  3 &amp; 3 \\
  3 &amp; 3 \\
\end{array}
$ (bag semantics)
* $\pi_{A, C \to D} \left( 
\begin{array}{ c | c | c | c}
  A &amp; B &amp; C &amp; D \\
  \hline \hline
  1 &amp; 2 &amp; 2 &amp; 6 \\
  1 &amp; 2 &amp; 2 &amp; 7 \\
  1 &amp; 2 &amp; 2 &amp; 9 \\
  3 &amp; 4 &amp; 3 &amp; 6 \\
  3 &amp; 4 &amp; 3 &amp; 7 \\
  3 &amp; 4 &amp; 3 &amp; 9 \\
\end{array}
\right) = 
\begin{array}{ c | c}
  A &amp; D \\
  \hline \hline
  1 &amp; 2 \\
  3 &amp; 3 \\
\end{array}
$ (set semantics)
* $C$ is renamed to $D$

== Translating SQL to RA ==
{{ Main | Translating SQL to Relational Algebra}}



== Sources ==
* [[Database Systems Architecture (ULB)]]
* [[Introduction to Data Science (coursera)]]
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom


[[Category:Relational Databases]]</text>
      <sha1>cgnoqew8tecica54p84zr4mna0xtvek</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Relational Databases</title>
    <ns>14</ns>
    <id>165</id>
    <revision>
      <id>166</id>
      <timestamp>2015-06-27T08:46:00Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22">[[Category:Databases]]</text>
      <sha1>9er5ql6pu57qzhet55yxlpr10hmmb4n</sha1>
    </revision>
  </page>
  <page>
    <title>Category:NoSQL</title>
    <ns>14</ns>
    <id>166</id>
    <revision>
      <id>167</id>
      <timestamp>2015-06-27T08:45:44Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22">[[Category:Databases]]</text>
      <sha1>9er5ql6pu57qzhet55yxlpr10hmmb4n</sha1>
    </revision>
  </page>
  <page>
    <title>Translating SQL to Relational Algebra</title>
    <ns>0</ns>
    <id>167</id>
    <revision>
      <id>168</id>
      <timestamp>2013-12-25T15:16:08Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="18170">\(\require{color}\)
\(\newcommand{\AntiJoin}{ \ \bar{\Join} \ } \)

== Translating SQL to [[Relational Algebra]] ==
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/query-processing-1st.png

Translating SQL to RA expression is the second step in [[Query Processing]] Pipeline
* Input: Logical Query Plan - expression in Extended [[Relational Algebra]]
* Output: Optimized Logical Query Plan - also in Relational Algebra



== Union, Intersection, Difference ==
Translation is straightforward

&lt;pre&gt;(SELECT * FROM R1) INTERSECT (SELECT * FROM R2)&lt;/pre&gt;

Is $R_1 \cap R_2$


UNION $\to R_1 \cup R_2$

EXCEPT $\to R_1 - R_2$


== Select-From-Where No Subqueries ==
Query
&lt;pre&gt;
SELECT movieTitle
FROM StarsIn, MovieStarM
WHERE starName = M.name AND M.birthdate = 1960
&lt;/pre&gt;

* in the '''from''' clause we have all relations we need
* so we make a Cartesian Product for all relations there
* if there is an alias - we do Renaming 
* then we filter the Cartesian Product 
* then translate the '''where''' clause too

So we get:
: $\pi_\text{movieTitle} \sigma_{\text{starName = M.name } \land \text{M.birthdate = 1960}}(\text{StartsIn} \times \rho_M (\text{MovieStar}))$

(Maybe not the most efficient way, but it will be [[Logical Query Plan Optimization|optimized further]])

== Normalization Step ==
Suppose we have subqueries in the &quot;Where&quot; clause 

&lt;pre&gt;
SELECT movieTitle FROM StarsIn
WHERE starName IN (
    SELECT name
    FROM MovieStar
    WHERE birthdate=1960)
&lt;/pre&gt;

Here we may have different constraints:
* $\text{in}, \leqslant, &lt;, \geqslant, &gt;, =, \neq$, etc
* whenever we have such constraints, we may replace them with quantifiers $\forall$ and $\exists$
* or with '''EXISTS''' and '''IN''' or '''NOT EXISTS'''
* so we first translate a SQL query to the equivalent SQL with '''EXISTS''' or '''NOT EXISTS'''


'''Example 1''': IN
&lt;pre&gt;
SELECT movieTitle FROM StarsIn
WHERE starName IN (
    SELECT name
    FROM MovieStar
    WHERE birthdate=1960)
&lt;/pre&gt;

to 

&lt;pre&gt;
SELECT movieTitle FROM StarsIn
WHERE EXISTS (
    SELECT name
    FROM MovieStar
    WHERE birthdate=1960 AND name=starName)
&lt;/pre&gt;


'''Example 2''': $\geqslant$
&lt;pre&gt;
SELECT name FROM MovieExec
WHERE netWorth &gt;= (
    SELECT E.netWorth
    FROM MovieExec E)
&lt;/pre&gt;

to 

&lt;pre&gt;
SELECT name FROM MovieExec
WHERE NOT EXISTS (
    SELECT E.netWorth
    FROM MovieExec E
    WHERE netWorth &lt; E.netWorth)
&lt;/pre&gt;


'''Example 3:''' aggregated attributes 
&lt;pre&gt;
SELECT C FROM S
WHERE C IN (
    SELECT SUM(B) FROM R
    GROUP BY A)
&lt;/pre&gt;

to

&lt;pre&gt;
SELECT C FROM S
WHERE EXISTS (
    SELECT SUM(B) FROM R
    GROUP BY A
    HAVING SUM(B) = C)
&lt;/pre&gt;

(note that in this case we use &quot;HAVING&quot; and not &quot;WHERE&quot;)


So the first step when processing these kinds of queries is ''normalization'' step: 
* translate a query into EXISTS/NOT EXISTS form

Hence we can assume that all queries are in this form
* We then apply the next step: for correlated queries 


== Correlated Queries ==
* A subquery can refer to attributes of relations that are introduces in the outer query
* '''def''': we call such queries ''correlated subqueries''
* the outer relation is called the ''context relation'' - a correlated subquery uses its attributes 
* a ''parameter'' - is a set of attributes of all context relations of a subquery

Example:

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/correlated-subqueries-1.png

here
* the subquery refers to S.starName, so it's correlated
* S is the context relation for the subquery
* S.starName is a parameter to the correlated subquery

=== EXISTS in the Where Clause (by example) ===
&lt;pre&gt;
SELECT S.movieTitle, M.studioName
FROM StarsIn S, Movie M
WHERE S.movieYear &gt;= 2000
AND S.movieTitle = M.title
AND EXISTS (
    SELECT name
    FROM MovieStar
    WHERE birthdate = 1960 AND name = S.starName)
&lt;/pre&gt;


Algorithm
* it's recursive: translate the subqueries first
** $\pi_\text{name} 
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar})$
** problem: cannot find '''S.starName''' in the input relation
** so it must be a correlated query
** we therefore need to recognize that this is a context relation's parameter 
* so we need to add the context relations and parameters 
** $\pi_{
  \begin{subarray}{l}
    \color{blue}{\text{S.movieTitle}}, \\
    \color{blue}{\text{S.movieYear}}, \\
    \color{blue}{\text{S.starName}}, \\
    \text{name} \\
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar} {\color{red}{\times \rho_S(\text{StarsIn}) }})$
* next, we translate the &quot;from&quot; clause
** $\rho_S(\text{StarsIn}) \times \rho_M(\text{Movie})$
* now we need to ''synchronize'' the subresult by join
** from the subquery we need to keep only the parameter attributes (the blue ones) - can remove $\text{name}$
** join: if something exists, we will join on it
** $\big[ \rho_S(\text{StarsIn}) \times \rho_M(\text{Movie}) \big]
\Join
\big[
\pi_{
  \begin{subarray}{l}
    \color{blue}{\text{S.movieTitle}}, \\
    \color{blue}{\text{S.movieYear}}, \\
    \color{blue}{\text{S.starName}}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar} {\color{red}{\times \rho_S(\text{StarsIn}) }})
\big]$
* note that we have $\rho_S(\text{StarsIn})$ on the both sides of the join
** can just drop it (it won't affect the join)
** $\big[ \rho_M(\text{Movie}) \big]
\Join
\big[
\pi_{
  \begin{subarray}{l}
    \text{S.movieTitle}, \\
    \text{S.movieYear}, \\
    \text{S.starName}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar})
\big]$
* finally we translate &quot;WHERE&quot; and &quot;SELECT&quot;
** $\pi_{
  \begin{subarray}{l}
    \text{S.movieTitle}, \\
    \text{M.studioName}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{S.movieYear $\geqslant$ 2000 } \land \\
    \text{S.movieTitle = M.title} \\
  \end{subarray}
}
\big[ \rho_M(\text{Movie})
\Join
\pi_{
  \begin{subarray}{l}
    \text{S.movieTitle}, \\
    \text{S.movieYear}, \\
    \text{S.starName}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar})
\big]$


=== NOT EXISTS in the Where Clause (by example) ===
&lt;pre&gt;
SELECTS.movieTitle, M.studioName
FROM StarsIn S, Movie M
WHERE S.movieYear &gt;= 2000
AND S.movieTitle = M.title
AND NOT EXISTS (
    SELECT name
    FROM MovieStar
    WHERE birthdate = 1960 AND name = S.starName)
&lt;/pre&gt;


Algorithm
* Same as before: we translate the subquery
** $\pi_\text{name} 
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar})$
* Then we add context relations and context parameters
** $\pi_{
  \begin{subarray}{l}
    \color{blue}{\text{S.movieTitle}}, \\
    \color{blue}{\text{S.movieYear}}, \\
    \color{blue}{\text{S.starName}}, \\
    \text{name} \\
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar} {\color{red}{\times \rho_S(\text{StarsIn}) }})$
* And same for the FROM clause
** $\rho_S(\text{StarsIn}) \times \rho_M(\text{Movie})$
* Then we need to ''synchronize'' the results, but this time with [[Relational Algebra#Anti-Join|Anti-Join]] ($\AntiJoin$)
** $\big[ \rho_S(\text{StarsIn}) \times \rho_M(\text{Movie}) \big]
\AntiJoin
\big[
\pi_{
  \begin{subarray}{l}
    \text{S.movieTitle}, \\
    \text{S.movieYear}, \\
    \text{S.starName}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar} \times \rho_S(\text{StarsIn}) )
\big]$
** note that here the simplification is not possible: the semantics of Anti-Join is different from Join
** so we cannot remove $\rho_S(\text{StarsIn})$ from both parts
* the last step is the same: we translate &quot;WHERE&quot; and &quot;SELECT&quot;
** $\pi_{
  \begin{subarray}{l}
    \text{S.movieTitle}, \\
    \text{M.studioName}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{S.movieYear $\geqslant$ 2000 } \land \\
    \text{S.movieTitle = M.title} \\
  \end{subarray}
}
\bigg[
\big[ \rho_S(\text{StarsIn}) \times \rho_M(\text{Movie}) \big]
\AntiJoin
\big[
\pi_{
  \begin{subarray}{l}
    \text{S.movieTitle}, \\
    \text{S.movieYear}, \\
    \text{S.starName}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar} \times \rho_S(\text{StarsIn}) )
\big]
\bigg]
$


=== EXISTS Subqueries in WHERE Combined with Other ===
So far we've considered only queries of the following form:

&lt;pre&gt;SELECT ... FROM ...
WHERE ... AND
      EXISTS (...) AND
      ... AND
      NOT EXISTS (...)
&lt;/pre&gt;

I.e. EXISTS and NOT EXISTS are in the &quot;WHERE&quot; clause joined by &quot;AND&quot;


What about the following query?

&lt;pre&gt;SELECT ... FROM ...
WHERE
    A = B AND NOT (EXISTS (...) AND C &lt; 6)&lt;/pre&gt;


* First, we translate the condition into [[Disjunctive Normal Form]]
&lt;pre&gt;
SELECT ... FROM ...
WHERE
    (A = B AND NOT (EXISTS (...))) OR
    (A = B AND C &gt;= 6)
&lt;/pre&gt;

* Then we distribute OR (to UNION)
&lt;pre&gt;
(SELECT ... FROM ...
  WHERE
    A = B AND NOT EXISTS (...))
UNION
(SELECT ... FROM ...
  WHERE
    A = B AND C &gt;= 6)
&lt;/pre&gt;

As we've seen, UNION is translated as $\cup$


=== Union In Subqueries ===
We may have UNOIN in subqueries 

&lt;pre&gt;
SELECT S1.C, S2.C
FROM S S1, S S2
WHERE EXISTS (
  (SELECT R1.A, R1.B FROMR R1
   WHERE A = S1.C AND B = S2.C) -- (1)
  UNION
  (SELECT R2.A, R2.B FROMR R2
   WHERE B = S1.C) -- (2)
)
&lt;/pre&gt;

* Recall that to be able to UNION two relations, they must have the same schema
* But in this case:
** (1) has 2 context relations $S_1$ and $S_2$
** (2) has only 1 context relation $S_1$
* $\Rightarrow$ When translating, need to add $S_2$ to (2) as well
* and make sure that they have the same name

$\bigg(
\underbrace{
\pi_{
  \begin{subarray}{l}
    S_1.C, \ S_2.C, \\
    R_1.A \ {\color{blue} \to \ A}, \\
    R_1.B \ {\color{blue} \to \ B}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    A = S_1.C \ \land \\
    B = S_2.C \\
  \end{subarray}
}
\big[\rho_{R_1}(R) \times \rho_{S_1}(S) \times \rho_{S_2}(S) \big]
}_{(1)}
\bigg)
\ {\color{blue} \cup } \
\bigg(
\underbrace{
\pi_{
  \begin{subarray}{l}
    S_1.C, \ S_2.C, \\
    R_1.A \ {\color{blue} \to \ A}, \\
    R_1.B \ {\color{blue} \to \ B}
  \end{subarray}
}
\sigma_{B = S_1.C}
\big[\rho_{R_1}(R) \times \rho_{S_1}(S) {\color{blue} \times \rho_{S_2}(S) } \big]
}_{(2)}
\bigg)
$


== Translating Joins ==
=== Joins ===
&lt;pre&gt;(SELECT * FROM R R1) JOIN (SELECT * FROM R R1) ON R1.A = R2.B&lt;/pre&gt;

We translate as follows:
* $\rho_{R_1}(R) \Join_{R_1.A = R_2.B} \rho_{R_2}(R)$


=== Group and Having ===
Suppose we have the following query:
&lt;pre&gt;
SELECT name, SUM(length)
FROM MovieExec, Movie
WHERE cert = producer
GROUP BY name
HAVING MIN(year) &lt; 1930
&lt;/pre&gt;

We translate it as 
* $\pi_{
  \begin{subarray}{l}
    \text{name}, \\
    \text{SUM(length)}
  \end{subarray}
}
{\color{blue} 
  \sigma_{\text{MIN(year) &lt; 1930}} 
  \gamma_{
    \begin{subarray}{l}
      \text{name}, \\
      \text{MIN(year)}, \\
      \text{SUM(length)}
    \end{subarray}
  }
}
\sigma_{\text{cert = producer}}
(\text{MovieExec} \times \text{Movie})$

* here the translate the '''HAVING''' clause as $\sigma$ before the $\gamma$
* also note that '''SUM(length)''' goes to $\gamma$



== Exercises ==
Exercises from [[Database Systems Architecture (ULB)]]
* the exercises: [https://dl.dropboxusercontent.com/sh/r0zvy3zaycbevx8/8ZdHjWVPN8/lect1-exercise.pdf]
* the proposed solutions [https://dl.dropboxusercontent.com/sh/r0zvy3zaycbevx8/WbFRIKUVMc/lect1-exercise-solution.pdf]


=== Exercise 1 ===
The given relations:
* Student(snum, sname, major, level, age)
* Class(name, meets_at, room, fid)
* Enrolled(snum, cname)
* Faculty(fid, fname, deptid)


&lt;pre&gt;
SELECT C.name
FROM Class C
WHERE C.room = 'R128' OR 
      C.name IN (
          SELECT E.cname
          FROM Enrolled E
          GROUP BY E.cname
          HAVING COUNT(*) &gt;= 5)
&lt;/pre&gt;

First we distribute OR 
&lt;pre&gt;
SELECT C.name
FROM Class C
WHERE C.room = 'R128'

UNION 

SELECT C.name
FROM Class C
WHERE C.name IN (
    SELECT E.cname
    FROM Enrolled E
    GROUP BY E.cname
    HAVING COUNT(*) &gt;= 5)
&lt;/pre&gt;

for the subquery we replace IN to EXISTS

&lt;pre&gt;SELECT C.name
FROM Class C
WHERE EXISTS (
    SELECT E.cname
    FROM Enrolled E
    WHERE E.cname = C.name
    GROUP BY E.cname
    HAVING COUNT(*) &gt;= 5)
&lt;/pre&gt;


Now we translate the subquery
* $q_1 = 
\pi_{\text{E.name, C.*}}
\sigma_{\text{cat} \geqslant 5}
\gamma_{
  \begin{subarray}{l}
    \text{E.cname}, \\
    \text{count(*) $\to$ cnt}, \\
    \text{C.*}
  \end{subarray}
  }
\sigma_{\text{E.cname = C.name}}
\big(
\rho_E(\text{Enrolled}) \times \rho_C(\text{Class})
\big)
$
* '''note''' that we use $\gamma_{
  \begin{subarray}{l}
    \text{E.cname}, \\
    \text{count(*) $\to$ cnt}, \\
    \text{C.*}
  \end{subarray}
}$ and not $\gamma_{
  \begin{subarray}{l}
    \text{E.cname}, \\
    \text{count(*) $\to$ cnt}
  \end{subarray}
}$, because in the second case it will return only the two specified columns

Next, we need to synchronize (or &quot;decorrelate&quot;) the subquery $q_1$ and the outer query
* $
\pi_{\text{C.name}}
\Big[
\rho_C(\text{Class})
\Join
\pi_{\text{C.*}}
\pi_{\text{E.name, C.*}}
\sigma_{\text{cat} \geqslant 5}
\gamma_{
  \begin{subarray}{l}
    \text{E.cname}, \\
    \text{count(*) $\to$ cnt}, \\
    \text{C.*}
  \end{subarray}
  }
\sigma_{\text{E.cname = C.name}}
\big(
\rho_E(\text{Enrolled}) \times \rho_C(\text{Class})
\big)
\Big]
$
* add $\pi_{\text{C.*}}$ because we need only these values - '''E.name''' was used for EXISTS part only
* since we have $\rho_C(\text{Class})$ on both sides of the Join - we can drop the first one (as well as the Join)
* and we also can merge successive projections 
* so we get:
* $\pi_{\text{C.name}} 
\sigma_{\text{cat} \geqslant 5}
\gamma_{
  \begin{subarray}{l}
    \text{E.cname}, \\
    \text{count(*) $\to$ cnt}, \\
    \text{C.*}
  \end{subarray}
  }
\sigma_{\text{E.cname = C.name}}
\big(
\rho_E(\text{Enrolled}) \times \rho_C(\text{Class})
\big)$


Now we do the union (easy)
* Since both parts have the same schema, union is possible
* The total results is:
* $
\pi_\text{C.name} \sigma_\text{C.room = 'R128'}
\rho_C(\text{Class})
\cup
\pi_{\text{C.name}}
\sigma_{\text{cat} \geqslant 5}
\gamma_{
  \begin{subarray}{l}
    \text{E.cname}, \\
    \text{count(*) $\to$ cnt}, \\
    \text{C.*}
  \end{subarray}
}
\sigma_{\text{E.cname = C.name}}
\big(
\rho_E(\text{Enrolled}) \times \rho_C(\text{Class})
\big)
$

=== Exercise with the Count Bug ===
&lt;pre&gt;
SELECT F.fname
FROM Faculty F
WHERE 5 &gt; (
    SELECT COUNT(E.snum)
    FROM Class C, Enrolled E
    WHERE C.name = E.cname AND
    C.fid = F.fid)
&lt;/pre&gt;

First translate to an equivalent EXISTS query
&lt;pre&gt;
SELECT F.fname
FROM Faculty F
WHERE EXISTS (
    SELECT COUNT(E.snum) as CNT
    FROM Class C, Enrolled E
    WHERE C.name = E.cname AND
    C.fid = F.fid
    HAVING CNT &lt; 5)
&lt;/pre&gt;

Remarks
* note the change in the sign from &gt; to &lt;
* also we use HAVING instead of WHERE - because GROUP is assumed 
* not all databases will take this kind of query. 
** For instance, MySQL will not (however it's not fully SQL compliant)

Using the rules, we try to translate the query this way:
* first we translate the subquery 
** $
\pi_{
  \begin{subarray}{l}
    \text{cnt)}, \\
    \text{F.fid}, \\
    \text{F.fname}, \\
    \text{F.deptid}
  \end{subarray}
}
\sigma_\text{cnt &lt; 5}
\gamma_{
  \begin{subarray}{l}
    \text{count(E.snum) $\to$ cnt}, \\
    \text{F.*}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{C.name = E.cname } \land \\
    \text{C.fid = F.fid}
  \end{subarray}
}
\Big[
\rho_C(\text{Class}) \times \rho_E(\text{Enrolled}) \times \rho_F(\text{Faculty}) 
\Big]
$
* then decorrelate it:
** $
\rho_F(\text{Faculty})
\Join
\bigg(
\pi_{\text{F.*}}
\pi_{
  \begin{subarray}{l}
    \text{cnt}, \\
    \text{F.fid}, \\
    \text{F.fname}, \\
    \text{F.deptid}
  \end{subarray}
}
\sigma_\text{cnt &lt; 5}
\gamma_{
  \begin{subarray}{l}
    \text{count(E.snum) $\to$ cnt}, \\
    \text{F.*}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{C.name = E.cname } \land \\
    \text{C.fid = F.fid}
  \end{subarray}
}
\Big[
\rho_C(\text{Class}) \times \rho_E(\text{Enrolled}) \times \rho_F(\text{Faculty}) 
\Big]
\bigg)
$
* can remove $\rho_F(\text{Faculty})$ and keep only needed projection attributes
** $\pi_{\text{F.name}}
\sigma_\text{cnt &lt; 5}
\gamma_{
  \begin{subarray}{l}
    \text{count(E.snum) $\to$ cnt}, \\
    \text{F.*}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{C.name = E.cname } \land \\
    \text{C.fid = F.fid}
  \end{subarray}
}
\Big[
\rho_C(\text{Class}) \times \rho_E(\text{Enrolled}) \times \rho_F(\text{Faculty}) 
\Big]$

Note that this is '''not the query we want'''!!!
* Faculty members who don't teach any class are not output by the expression, but they are output by the original SQL query


Count bug
* this issue is known as the ''count bug''
* it occurs when we have subqueries use COUNT without GROUP BY
* to solve it we need to use right outer join instead of $\times$

$\pi_{\text{F.name}}
\sigma_\text{cnt &lt; 5}
\gamma_{
  \begin{subarray}{l}
    \text{count(E.snum) $\to$ cnt}, \\
    \text{F.*}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{C.name = E.cname } \land \\
    \text{C.fid = F.fid}
  \end{subarray}
}
\Big[
\rho_C(\text{Class}) \times \rho_E(\text{Enrolled}) \Join^{R}_\text{C.fid = F.fid} \rho_F(\text{Faculty}) 
\Big]$



== See also ==
* [[Relational Algebra]]
* Lecture Notes by S. Vansummeren [https://dl.dropboxusercontent.com/s/5e6w6pia970bnki/lect1-notes-relalg.pdf]  

== Sources ==
* [[Database Systems Architecture (ULB)]]


[[Category:Relational Databases]]</text>
      <sha1>nihwueuhtgd1jtqqg898k5juomwy1gc</sha1>
    </revision>
    <revision>
      <id>823</id>
      <parentid>168</parentid>
      <timestamp>2018-08-14T19:46:15Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="18418">\(\require{color}\)
\(\newcommand{\AntiJoin}{ \ \bar{\Join} \ } \)

== Translating SQL to [[Relational Algebra]] ==
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/query-processing-1st.png

Translating SQL to RA expression is the second step in [[Query Processing]] Pipeline
* Input: Logical Query Plan - expression in Extended [[Relational Algebra]]
* Output: Optimized Logical Query Plan - also in Relational Algebra



== Union, Intersection, Difference ==
Translation is straightforward

&lt;pre&gt;(SELECT * FROM R1) INTERSECT (SELECT * FROM R2)&lt;/pre&gt;

Is $R_1 \cap R_2$


UNION $\to R_1 \cup R_2$

EXCEPT $\to R_1 - R_2$


== Select-From-Where No Subqueries ==
Query
&lt;pre&gt;
SELECT movieTitle
FROM StarsIn, MovieStarM
WHERE starName = M.name AND M.birthdate = 1960
&lt;/pre&gt;

* in the '''from''' clause we have all relations we need
* so we make a Cartesian Product for all relations there
* if there is an alias - we do Renaming 
* then we filter the Cartesian Product 
* then translate the '''where''' clause too

So we get:
: &lt;math&gt;\pi_\text{movieTitle} \sigma_{\text{starName = M.name } \land \text{M.birthdate = 1960}}(\text{StartsIn} \times \rho_M (\text{MovieStar}))&lt;/math&gt;

(Maybe not the most efficient way, but it will be [[Logical Query Plan Optimization|optimized further]])

== Normalization Step ==
Suppose we have subqueries in the &quot;Where&quot; clause 

&lt;pre&gt;
SELECT movieTitle FROM StarsIn
WHERE starName IN (
    SELECT name
    FROM MovieStar
    WHERE birthdate=1960)
&lt;/pre&gt;

Here we may have different constraints:
* $\text{in}, \leqslant, &lt;, \geqslant, &gt;, =, \neq$, etc
* whenever we have such constraints, we may replace them with quantifiers $\forall$ and $\exists$
* or with '''EXISTS''' and '''IN''' or '''NOT EXISTS'''
* so we first translate a SQL query to the equivalent SQL with '''EXISTS''' or '''NOT EXISTS'''


'''Example 1''': IN
&lt;pre&gt;
SELECT movieTitle FROM StarsIn
WHERE starName IN (
    SELECT name
    FROM MovieStar
    WHERE birthdate=1960)
&lt;/pre&gt;

to 

&lt;pre&gt;
SELECT movieTitle FROM StarsIn
WHERE EXISTS (
    SELECT name
    FROM MovieStar
    WHERE birthdate=1960 AND name=starName)
&lt;/pre&gt;


'''Example 2''': $\geqslant$
&lt;pre&gt;
SELECT name FROM MovieExec
WHERE netWorth &gt;= (
    SELECT E.netWorth
    FROM MovieExec E)
&lt;/pre&gt;

to 

&lt;pre&gt;
SELECT name FROM MovieExec
WHERE NOT EXISTS (
    SELECT E.netWorth
    FROM MovieExec E
    WHERE netWorth &lt; E.netWorth)
&lt;/pre&gt;


'''Example 3:''' aggregated attributes 
&lt;pre&gt;
SELECT C FROM S
WHERE C IN (
    SELECT SUM(B) FROM R
    GROUP BY A)
&lt;/pre&gt;

to

&lt;pre&gt;
SELECT C FROM S
WHERE EXISTS (
    SELECT SUM(B) FROM R
    GROUP BY A
    HAVING SUM(B) = C)
&lt;/pre&gt;

(note that in this case we use &quot;HAVING&quot; and not &quot;WHERE&quot;)


So the first step when processing these kinds of queries is ''normalization'' step: 
* translate a query into EXISTS/NOT EXISTS form

Hence we can assume that all queries are in this form
* We then apply the next step: for correlated queries 


== Correlated Queries ==
* A subquery can refer to attributes of relations that are introduces in the outer query
* '''def''': we call such queries ''correlated subqueries''
* the outer relation is called the ''context relation'' - a correlated subquery uses its attributes 
* a ''parameter'' - is a set of attributes of all context relations of a subquery

Example:

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/correlated-subqueries-1.png

here
* the subquery refers to S.starName, so it's correlated
* S is the context relation for the subquery
* S.starName is a parameter to the correlated subquery

=== EXISTS in the Where Clause (by example) ===
&lt;pre&gt;
SELECT S.movieTitle, M.studioName
FROM StarsIn S, Movie M
WHERE S.movieYear &gt;= 2000
AND S.movieTitle = M.title
AND EXISTS (
    SELECT name
    FROM MovieStar
    WHERE birthdate = 1960 AND name = S.starName)
&lt;/pre&gt;


Algorithm
* it's recursive: translate the subqueries first
** &lt;math&gt;\pi_\text{name} 
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar})&lt;/math&gt;
** problem: cannot find '''S.starName''' in the input relation
** so it must be a correlated query
** we therefore need to recognize that this is a context relation's parameter 
* so we need to add the context relations and parameters 
** &lt;math&gt;\pi_{
  \begin{subarray}{l}
    \color{blue}{\text{S.movieTitle}}, \\
    \color{blue}{\text{S.movieYear}}, \\
    \color{blue}{\text{S.starName}}, \\
    \text{name} \\
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar} {\color{red}{\times \rho_S(\text{StarsIn}) }})&lt;/math&gt;
* next, we translate the &quot;from&quot; clause
** $\rho_S(\text{StarsIn}) \times \rho_M(\text{Movie})$
* now we need to ''synchronize'' the subresult by join
** from the subquery we need to keep only the parameter attributes (the blue ones) - can remove $\text{name}$
** join: if something exists, we will join on it
** &lt;math&gt;\big[ \rho_S(\text{StarsIn}) \times \rho_M(\text{Movie}) \big]
\Join
\big[
\pi_{
  \begin{subarray}{l}
    \color{blue}{\text{S.movieTitle}}, \\
    \color{blue}{\text{S.movieYear}}, \\
    \color{blue}{\text{S.starName}}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar} {\color{red}{\times \rho_S(\text{StarsIn}) }})
\big]&lt;/math&gt;
* note that we have $\rho_S(\text{StarsIn})$ on the both sides of the join
** can just drop it (it won't affect the join)
** &lt;math&gt;\big[ \rho_M(\text{Movie}) \big]
\Join
\big[
\pi_{
  \begin{subarray}{l}
    \text{S.movieTitle}, \\
    \text{S.movieYear}, \\
    \text{S.starName}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar})
\big]&lt;/math&gt;
* finally we translate &quot;WHERE&quot; and &quot;SELECT&quot;
** &lt;math&gt;\pi_{
  \begin{subarray}{l}
    \text{S.movieTitle}, \\
    \text{M.studioName}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{S.movieYear $\geqslant$ 2000 } \land \\
    \text{S.movieTitle = M.title} \\
  \end{subarray}
}
\big[ \rho_M(\text{Movie})
\Join
\pi_{
  \begin{subarray}{l}
    \text{S.movieTitle}, \\
    \text{S.movieYear}, \\
    \text{S.starName}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar})
\big]&lt;/math&gt;


=== NOT EXISTS in the Where Clause (by example) ===
&lt;pre&gt;
SELECTS.movieTitle, M.studioName
FROM StarsIn S, Movie M
WHERE S.movieYear &gt;= 2000
AND S.movieTitle = M.title
AND NOT EXISTS (
    SELECT name
    FROM MovieStar
    WHERE birthdate = 1960 AND name = S.starName)
&lt;/pre&gt;


Algorithm
* Same as before: we translate the subquery
** &lt;math&gt;\pi_\text{name} 
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar})&lt;/math&gt;
* Then we add context relations and context parameters
** &lt;math&gt;\pi_{
  \begin{subarray}{l}
    \color{blue}{\text{S.movieTitle}}, \\
    \color{blue}{\text{S.movieYear}}, \\
    \color{blue}{\text{S.starName}}, \\
    \text{name} \\
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar} {\color{red}{\times \rho_S(\text{StarsIn}) }})&lt;/math&gt;
* And same for the FROM clause
** $\rho_S(\text{StarsIn}) \times \rho_M(\text{Movie})$
* Then we need to ''synchronize'' the results, but this time with [[Relational Algebra#Anti-Join|Anti-Join]] ($\AntiJoin$)
** &lt;math&gt;\big[ \rho_S(\text{StarsIn}) \times \rho_M(\text{Movie}) \big]
\AntiJoin
\big[
\pi_{
  \begin{subarray}{l}
    \text{S.movieTitle}, \\
    \text{S.movieYear}, \\
    \text{S.starName}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar} \times \rho_S(\text{StarsIn}) )
\big]&lt;/math&gt;
** note that here the simplification is not possible: the semantics of Anti-Join is different from Join
** so we cannot remove $\rho_S(\text{StarsIn})$ from both parts
* the last step is the same: we translate &quot;WHERE&quot; and &quot;SELECT&quot;
** &lt;math&gt;\pi_{
  \begin{subarray}{l}
    \text{S.movieTitle}, \\
    \text{M.studioName}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{S.movieYear $\geqslant$ 2000 } \land \\
    \text{S.movieTitle = M.title} \\
  \end{subarray}
}
\bigg[
\big[ \rho_S(\text{StarsIn}) \times \rho_M(\text{Movie}) \big]
\AntiJoin
\big[
\pi_{
  \begin{subarray}{l}
    \text{S.movieTitle}, \\
    \text{S.movieYear}, \\
    \text{S.starName}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{birthDate = 1960 } \land \\
    \text{name = S.starName} \\
  \end{subarray}
}
(\text{MovieStar} \times \rho_S(\text{StarsIn}) )
\big]
\bigg]&lt;/math&gt;



=== EXISTS Subqueries in WHERE Combined with Other ===
So far we've considered only queries of the following form:

&lt;pre&gt;SELECT ... FROM ...
WHERE ... AND
      EXISTS (...) AND
      ... AND
      NOT EXISTS (...)
&lt;/pre&gt;

I.e. EXISTS and NOT EXISTS are in the &quot;WHERE&quot; clause joined by &quot;AND&quot;


What about the following query?

&lt;pre&gt;SELECT ... FROM ...
WHERE
    A = B AND NOT (EXISTS (...) AND C &lt; 6)&lt;/pre&gt;


* First, we translate the condition into [[Disjunctive Normal Form]]
&lt;pre&gt;
SELECT ... FROM ...
WHERE
    (A = B AND NOT (EXISTS (...))) OR
    (A = B AND C &gt;= 6)
&lt;/pre&gt;

* Then we distribute OR (to UNION)
&lt;pre&gt;
(SELECT ... FROM ...
  WHERE
    A = B AND NOT EXISTS (...))
UNION
(SELECT ... FROM ...
  WHERE
    A = B AND C &gt;= 6)
&lt;/pre&gt;

As we've seen, UNION is translated as $\cup$


=== Union In Subqueries ===
We may have UNOIN in subqueries 

&lt;pre&gt;
SELECT S1.C, S2.C
FROM S S1, S S2
WHERE EXISTS (
  (SELECT R1.A, R1.B FROMR R1
   WHERE A = S1.C AND B = S2.C) -- (1)
  UNION
  (SELECT R2.A, R2.B FROMR R2
   WHERE B = S1.C) -- (2)
)
&lt;/pre&gt;

* Recall that to be able to UNION two relations, they must have the same schema
* But in this case:
** (1) has 2 context relations $S_1$ and $S_2$
** (2) has only 1 context relation $S_1$
* $\Rightarrow$ When translating, need to add $S_2$ to (2) as well
* and make sure that they have the same name

&lt;math&gt;\bigg(
\underbrace{
\pi_{
  \begin{subarray}{l}
    S_1.C, \ S_2.C, \\
    R_1.A \ {\color{blue} \to \ A}, \\
    R_1.B \ {\color{blue} \to \ B}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    A = S_1.C \ \land \\
    B = S_2.C \\
  \end{subarray}
}
\big[\rho_{R_1}(R) \times \rho_{S_1}(S) \times \rho_{S_2}(S) \big]
}_{(1)}
\bigg)
\ {\color{blue} \cup } \
\bigg(
\underbrace{
\pi_{
  \begin{subarray}{l}
    S_1.C, \ S_2.C, \\
    R_1.A \ {\color{blue} \to \ A}, \\
    R_1.B \ {\color{blue} \to \ B}
  \end{subarray}
}
\sigma_{B = S_1.C}
\big[\rho_{R_1}(R) \times \rho_{S_1}(S) {\color{blue} \times \rho_{S_2}(S) } \big]
}_{(2)}
\bigg)&lt;/math&gt;



== Translating Joins ==
=== Joins ===
&lt;pre&gt;(SELECT * FROM R R1) JOIN (SELECT * FROM R R1) ON R1.A = R2.B&lt;/pre&gt;

We translate as follows:
* $\rho_{R_1}(R) \Join_{R_1.A = R_2.B} \rho_{R_2}(R)$


=== Group and Having ===
Suppose we have the following query:
&lt;pre&gt;
SELECT name, SUM(length)
FROM MovieExec, Movie
WHERE cert = producer
GROUP BY name
HAVING MIN(year) &lt; 1930
&lt;/pre&gt;

We translate it as 
* &lt;math&gt;\pi_{
  \begin{subarray}{l}
    \text{name}, \\
    \text{SUM(length)}
  \end{subarray}
}
{\color{blue} 
  \sigma_{\text{MIN(year)} &lt; 1930} 
  \gamma_{
    \begin{subarray}{l}
      \text{name}, \\
      \text{MIN(year)}, \\
      \text{SUM(length)}
    \end{subarray}
  }
}
\sigma_{\text{cert = producer}}
(\text{MovieExec} \times \text{Movie})&lt;/math&gt;

* here the translate the '''HAVING''' clause as $\sigma$ before the $\gamma$
* also note that '''SUM(length)''' goes to $\gamma$



== Exercises ==
Exercises from [[Database Systems Architecture (ULB)]]
* the exercises: [https://dl.dropboxusercontent.com/sh/r0zvy3zaycbevx8/8ZdHjWVPN8/lect1-exercise.pdf]
* the proposed solutions [https://dl.dropboxusercontent.com/sh/r0zvy3zaycbevx8/WbFRIKUVMc/lect1-exercise-solution.pdf]


=== Exercise 1 ===
The given relations:
* Student(snum, sname, major, level, age)
* Class(name, meets_at, room, fid)
* Enrolled(snum, cname)
* Faculty(fid, fname, deptid)


&lt;pre&gt;
SELECT C.name
FROM Class C
WHERE C.room = 'R128' OR 
      C.name IN (
          SELECT E.cname
          FROM Enrolled E
          GROUP BY E.cname
          HAVING COUNT(*) &gt;= 5)
&lt;/pre&gt;

First we distribute OR 
&lt;pre&gt;
SELECT C.name
FROM Class C
WHERE C.room = 'R128'

UNION 

SELECT C.name
FROM Class C
WHERE C.name IN (
    SELECT E.cname
    FROM Enrolled E
    GROUP BY E.cname
    HAVING COUNT(*) &gt;= 5)
&lt;/pre&gt;

for the subquery we replace IN to EXISTS

&lt;pre&gt;SELECT C.name
FROM Class C
WHERE EXISTS (
    SELECT E.cname
    FROM Enrolled E
    WHERE E.cname = C.name
    GROUP BY E.cname
    HAVING COUNT(*) &gt;= 5)
&lt;/pre&gt;


Now we translate the subquery
* &lt;math&gt;q_1 = 
\pi_{\text{E.name, C.*}}
\sigma_{\text{cat} \geqslant 5}
\gamma_{
  \begin{subarray}{l}
    \text{E.cname}, \\
    \text{count(*) $\to$ cnt}, \\
    \text{C.*}
  \end{subarray}
  }
\sigma_{\text{E.cname = C.name}}
\big(
\rho_E(\text{Enrolled}) \times \rho_C(\text{Class})
\big)&lt;/math&gt;

* '''note''' that we use &lt;math&gt;\gamma_{
  \begin{subarray}{l}
    \text{E.cname}, \\
    \text{count(*) $\to$ cnt}, \\
    \text{C.*}
  \end{subarray}
}&lt;/math&gt; and not &lt;math&gt;\gamma_{
  \begin{subarray}{l}
    \text{E.cname}, \\
    \text{count(*) $\to$ cnt}
  \end{subarray}
}&lt;/math&gt;, because in the second case it will return only the two specified columns

Next, we need to synchronize (or &quot;decorrelate&quot;) the subquery $q_1$ and the outer query
* &lt;math&gt;
\pi_{\text{C.name}}
\Big[
\rho_C(\text{Class})
\Join
\pi_{\text{C.*}}
\pi_{\text{E.name, C.*}}
\sigma_{\text{cat} \geqslant 5}
\gamma_{
  \begin{subarray}{l}
    \text{E.cname}, \\
    \text{count(*) $\to$ cnt}, \\
    \text{C.*}
  \end{subarray}
  }
\sigma_{\text{E.cname = C.name}}
\big(
\rho_E(\text{Enrolled}) \times \rho_C(\text{Class})
\big)
\Big]&lt;/math&gt;

* add $\pi_{\text{C.*}}$ because we need only these values - '''E.name''' was used for EXISTS part only
* since we have $\rho_C(\text{Class})$ on both sides of the Join - we can drop the first one (as well as the Join)
* and we also can merge successive projections 
* so we get:
* &lt;math&gt;\pi_{\text{C.name}} 
\sigma_{\text{cat} \geqslant 5}
\gamma_{
  \begin{subarray}{l}
    \text{E.cname}, \\
    \text{count(*) $\to$ cnt}, \\
    \text{C.*}
  \end{subarray}
  }
\sigma_{\text{E.cname = C.name}}
\big(
\rho_E(\text{Enrolled}) \times \rho_C(\text{Class})
\big)&lt;/math&gt;


Now we do the union (easy)
* Since both parts have the same schema, union is possible
* The total results is:
* &lt;math&gt;
\pi_\text{C.name} \sigma_\text{C.room = 'R128'}
\rho_C(\text{Class})
\cup
\pi_{\text{C.name}}
\sigma_{\text{cat} \geqslant 5}
\gamma_{
  \begin{subarray}{l}
    \text{E.cname}, \\
    \text{count(*) $\to$ cnt}, \\
    \text{C.*}
  \end{subarray}
}
\sigma_{\text{E.cname = C.name}}
\big(
\rho_E(\text{Enrolled}) \times \rho_C(\text{Class})
\big)&lt;/math&gt;


=== Exercise with the Count Bug ===
&lt;pre&gt;
SELECT F.fname
FROM Faculty F
WHERE 5 &gt; (
    SELECT COUNT(E.snum)
    FROM Class C, Enrolled E
    WHERE C.name = E.cname AND
    C.fid = F.fid)
&lt;/pre&gt;

First translate to an equivalent EXISTS query
&lt;pre&gt;
SELECT F.fname
FROM Faculty F
WHERE EXISTS (
    SELECT COUNT(E.snum) as CNT
    FROM Class C, Enrolled E
    WHERE C.name = E.cname AND
    C.fid = F.fid
    HAVING CNT &lt; 5)
&lt;/pre&gt;

Remarks
* note the change in the sign from &gt; to &lt;
* also we use HAVING instead of WHERE - because GROUP is assumed 
* not all databases will take this kind of query. 
** For instance, MySQL will not (however it's not fully SQL compliant)

Using the rules, we try to translate the query this way:
* first we translate the subquery 
** &lt;math&gt;
\pi_{
  \begin{subarray}{l}
    \text{cnt)}, \\
    \text{F.fid}, \\
    \text{F.fname}, \\
    \text{F.deptid}
  \end{subarray}
}
\sigma_{\text{cnt} &lt; 5}
\gamma_{
  \begin{subarray}{l}
    \text{count(E.snum) $\to$ cnt}, \\
    \text{F.*}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{C.name = E.cname } \land \\
    \text{C.fid = F.fid}
  \end{subarray}
}
\Big[
\rho_C(\text{Class}) \times \rho_E(\text{Enrolled}) \times \rho_F(\text{Faculty}) 
\Big]&lt;/math&gt;
* then decorrelate it:
** &lt;math&gt;
\rho_F(\text{Faculty})
\Join
\bigg(
\pi_{\text{F.*}}
\pi_{
  \begin{subarray}{l}
    \text{cnt}, \\
    \text{F.fid}, \\
    \text{F.fname}, \\
    \text{F.deptid}
  \end{subarray}
}
\sigma_{\text{cnt} &lt; 5}
\gamma_{
  \begin{subarray}{l}
    \text{count(E.snum) $\to$ cnt}, \\
    \text{F.*}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{C.name = E.cname } \land \\
    \text{C.fid = F.fid}
  \end{subarray}
}
\Big[
\rho_C(\text{Class}) \times \rho_E(\text{Enrolled}) \times \rho_F(\text{Faculty}) 
\Big]
\bigg)&lt;/math&gt;
* can remove $\rho_F(\text{Faculty})$ and keep only needed projection attributes
** &lt;math&gt;\pi_{\text{F.name}}
\sigma_{\text{cnt} &lt; 5}
\gamma_{
  \begin{subarray}{l}
    \text{count(E.snum) $\to$ cnt}, \\
    \text{F.*}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{C.name = E.cname } \land \\
    \text{C.fid = F.fid}
  \end{subarray}
}
\Big[
\rho_C(\text{Class}) \times \rho_E(\text{Enrolled}) \times \rho_F(\text{Faculty}) 
\Big]&lt;/math&gt;

Note that this is '''not the query we want'''!!!
* Faculty members who don't teach any class are not output by the expression, but they are output by the original SQL query


Count bug
* this issue is known as the ''count bug''
* it occurs when we have subqueries use COUNT without GROUP BY
* to solve it we need to use right outer join instead of $\times$

&lt;math&gt;\pi_{\text{F.name}}
\sigma_{\text{cnt} &lt; 5}
\gamma_{
  \begin{subarray}{l}
    \text{count(E.snum) $\to$ cnt}, \\
    \text{F.*}
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    \text{C.name = E.cname } \land \\
    \text{C.fid = F.fid}
  \end{subarray}
}
\Big[
\rho_C(\text{Class}) \times \rho_E(\text{Enrolled}) \Join^{R}_\text{C.fid = F.fid} \rho_F(\text{Faculty}) 
\Big]&lt;/math&gt;



== See also ==
* [[Relational Algebra]]
* Lecture Notes by S. Vansummeren [https://dl.dropboxusercontent.com/s/5e6w6pia970bnki/lect1-notes-relalg.pdf]  

== Sources ==
* [[Database Systems Architecture (ULB)]]


[[Category:Relational Databases]]</text>
      <sha1>oqlzvrpczwmvcnkpqchnnkg474wf6n6</sha1>
    </revision>
  </page>
  <page>
    <title>Conjunctive Query</title>
    <ns>0</ns>
    <id>168</id>
    <revision>
      <id>169</id>
      <timestamp>2015-01-06T20:08:44Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8878">== Conjunctive Query ==
A ''Conjunctive Query'' (CQ) is
* a [[First Order Logic]] expression without negations and disjunctions


A CQ is an expression of the following form:

$\underbrace{Q(x_1, ..., x_n)}_{\text{head}} \leftarrow 
\underbrace{R(a_1, ..., a_m), ..., S(c_1, ..., c_k)}_{\text{body}}$
* it consists of two parts: head and body
* $V = (a_1, ..., a_m, ..., c_1, ..., c_k)$ - variables and constants from the body
* $X = (x_1, ..., x_n)$ is a set of variables from the head
** $X \subseteq V$
** the variables from $X$ are called ''distinguished variables'' (also ''free'' or ''placeholder'' variables)
* $Y = V - X$  - variables from the body which aren't in the head
** $Y \subseteq V$
** variables from $Y$ are called ''existential variables'' (also ''bound'' variables)
* note that the head doesn't necessarily have to contain only variables, it might as well contain constants
** these constants will be returned in the results



$R(a_1, ..., a_m)$ is called an ''atom'' 
* if an atom does not contain any variables, only constants, it's a ''fact''
* so we can view a database as a set of facts 


Alternative vector form:
* $Q( \vec{x} ) \leftarrow A_1(\vec{u}_1), \ ..., \ A_k(\vec{u}_k)$


=== Example ===
Suppose we have the following database

$
R \\
\begin{array}{| c c |}
  \hline
  1 &amp; 2 \\
  2 &amp; 3 \\
  2 &amp; 5 \\
  6 &amp; 7 \\
  7 &amp; 5 \\
  5 &amp; 5 \\
  \hline
\end{array}
$
$
S \\
\begin{array}{| c |}
  \hline
  2 \\
  7 \\
  \hline
\end{array}
$

the query $Q(x, y) \leftarrow R(x, y), R(y, 5), S(y)$ wants to retrieve all pairs $(x, y)$ s.t.
* $(x, y)$ occurs in $R$
* $y$ then occurs in $R$ together with 5
* and that $y$ occurs as a value in $S$


=== Substitution ===
'''def''': a ''substitution'' $f$ of $Q$ into database $D$ is 
: a function that maps all variables from $Q$ to constants from $D$

'''def''': a substitution $f$ of $Q$ into a database $D$ is a ''matching'' if
: $f(\text{body}) \subseteq D$, i.e. if we evaluate $f$ on the body of the query $Q$, we will get a subset of $D$
: so when we apply $f(\text{head})$ we get a tuple that is a part of the result of evaluating $Q$ on $D$

Then the result of a conjunctive query can be shown as:
* $Q(D) \leftarrow \{ f(\text{head}) | f \text{ is a matching of $Q$ to $D$ } \}$


Let's consider the previous example: $Q(x, y) \leftarrow \underbrace{R(x, y)}_{(1)}, \underbrace{R(y, 5)}_{(2)}, \underbrace{S(y)}_{(3)}$ for the same database

Example with matching
# $(1)$ gets a tuple form $R$
#* say it's (1, 2)
#* so it assigns $x \mapsto 1, y \mapsto 2$
#: so our substitution so far is $f: x \mapsto 1, y \mapsto 2$
# $(2)$ looks for a tuple in $R$ with $y = 2$ 
#* because we established the matching $f$ with $y \mapsto 2$
#* second value of this tuple must be a constant 5
#* we find such tuple: it's (2, 5)
#* nothing gets assigned at this step 
# $(3)$ looks for a value in $S$ with $y = 2$
#* same reason: we have $y \mapsto 2$
#* it finds a fact $S(2)$ in the database
# so it returns a matching pair (1, 2)
#* we say there is a matching (1, 2) in the database $D$


Example without matching
# $(1)$ we try another tuple from $R$, say (7, 5)
#* we assign $x \mapsto 7, y \mapsto 5$
# $(2)$ now we try to find a tuple ($y$, 5) = (5, 5) in $R$
#* no such tuple
# therefor (7, 5) is not a matching and will not be returned by $Q$


So this way we try all values of our database table and return only matching ones 
* for this particular example the query returns two tuples: (1, 2) and (6, 7)
* i.e. $Q(D) = \{ (1, 2), (6, 7) \}$


=== Translation ===
[[First Order Logic]]
* CQs can be translated to [[First Order Logic]] expressions
* for query $q(x_1, ..., x_n) = A_1(...), \ ..., \ A_n(...)$
* FOL expressions is $\{ x_1, ..., x_n \ | \ \exists \ y_1, ..., y_m : A_1(...) \ \land \ ... \ \land \ A_n(...) \}$
** $x_1, ..., x_n$ - distinguished variables, and $y_1, ..., y_m$ are existential


[[Relational Algebra]]
* CQs can be translated to a subset of RA expressions - [[Select-Project-Join Expressions]]
* see [[Conjunctive Query/Translation]]


=== Properties ===
CQs have an interesting property
* The query containment problem is undecidable for SQL and [[Relational Algebra]] (see [[Logical Query Plan Optimization]]), but it is decidable for Conjunctive Queries 
* The decidability of containment is NP-complete problem, but usually CQs are not big, so it is acceptable 

This makes CQs very suitable for [[Logical Query Plan Optimization]], namely, for [[Logical Query Plan Optimization#Removing Redundant Joins|removing redundant joins]]



== Containment and Equivalence ==
=== Containment ===
$Q_1$ ''is contained in'' $Q_2$ (denoted as $Q_1 \subseteq Q_2$) if
* for any database $D$ holds $Q_1(D) \subseteq Q_2(D)$
* i.e. the result of $Q_1$ is always a subset of the result of $Q_2$, no matter what database $D$ they are evaluated on

$Q_1$ ''is equivalent to'' $Q_2$ (denoted as $Q_1 \equiv Q_2$)
* iff $Q_1 \subseteq Q_2 \land Q_2 \subseteq Q_1$

Example 
* $A(x, y) \leftarrow R(x, w), G(w, z), R(z, y)$
* $B(x, w) \leftarrow R(x, w), G(w, w), R(w, y)$
* $B \subseteq A$

To show that we use the definition
* let $D$ be an arbitrary DB and 
* let $t \in B(D)$ (one arbitrary result of $B$ evaluated on $D$)
* there exists a matching $f$ of $B$ into $D$ s.t. $t = (f(x), f(y))$ (by definition of matching)
** so we need to show that $t = (f(x), f(y)) \in A(D)$
* let $h$ be a substitution:
** $h: x \mapsto f(x), y \mapsto f(y), w \mapsto f(w), z \mapsto f(w)$ 
* then $h$ is a matching of $A$ into $D$
** $t = (f(x), f(y)) = (h(x), h(y)) \in A$ 


It is also possible to show that containment is decidable.


=== Homomorphism ===
'''def''': a ''homomorphism'' of $Q_2$ to $Q_1$ is 
* a function $h$ that maps each variable in $Q_2$ to either
** a variable from $Q_1$ or
** a constant form $Q_1$
* s.t. 
** $h(\text{head}_2) = \text{head}_1$
** $h(\text{body}_2) \subseteq \text{body}_1$
** i.e. the values returned by queries are always the same, and body of one query is a subset of the other's query body


Examples
* see [[Conjunctive Query/Homomorphism]]


=== Containment Theorem ===
'''Thm''': $Q_1 \subset Q_2 \iff $ there's a homomorphism from $Q_2$ to $Q_1$

Proof of $\Leftarrow$ (if)
* let $h: Q_2 \to Q_1$ be a homomorphism
* let $D$ be a database
* if we fix an arbitrary tuple $t \in Q_1(D)$, we need to prove that $t \in Q_2(D)$
* since $t \in Q_1(D)$ we know that 
** $t = f(\text{head}_1)$ 
** with a matching $f$ of $Q_1$ into $D$ 
** (by semantics of CQs)
* let's consider a composition $f \circ h$ (composition of $f$ with the homomorphism $h$)
** this is a substitution of $Q_2$ into $D$! (we fist applied the homomorphism and then the matching - and got the substitution)
** since $h$ is a homomorphism, $h(\text{body}_2) \subseteq \text{body}_2$ (by def of homomorphism)
** $\to$ $f(h(\text{body}_2)) \subseteq f(\text{body}_1) \subseteq D$
** in other words, $f \circ h$ is a matching of $Q_2$ into $D$
* hence 
** $f(h(\text{body}_2)) \in Q_2(D)$
** and finally $t = f(\text{head}_1) = f(h(\text{head}_2)) \in Q_2(D)$

Proof of $\Rightarrow$ (only if) 
* suppose that $Q_1 \subseteq Q_2$
* let's consider variables in $Q_1$ as constants
** we can view $\text{body}_1$ as a mini-database $D_{Q_1}$ 
** (this database is called a ''canonical database'' of $Q_1$) 
* the identity function is a matching of $Q_1$ to $D_{Q_1}$
** hence $\text{head}_1 \in Q_1(D_{Q_1})$
* since $Q_1 \subseteq Q_2$ we know that $\text{head}_1 \in Q_2(D_{Q_1})$
** by construction of our database $D_{Q_1}$
* so there exists a matching $f$ from $Q_2$ to $D_{Q_1}$ s.t.
** $\text{head}_1 = f(\text{head}_2)$ and
** $f(\text{body}_2) \subseteq D_{Q_1} = \text{body}_1$
* $f$ is a homomorphism of $Q_2$ to $Q_1$ by the definition (by considering variables again as variables)

$\blacksquare$


From the second part of the proof we may get a way of checking for containment: the Golden Method


=== The Golden Method ===
To decide whether $Q_1 \subseteq Q_2$
* evaluate $Q_2$ on a canonical database $D_{Q_1}$ (which is a body of $Q_1$, see [[#Containment Theorem]])
* check if the head of $Q_1$ is in the results 


QueryContainment($Q_1$, $Q_2$)
* input
** $Q_1(\vec{x}) \leftarrow g_1(\vec{x}_1), ..., g_n(\vec{x}_n)$
** $Q_2(\vec{y}) \leftarrow h_1(\vec{y}_1), ..., h_m(\vec{y}_m)$
* freeze $Q_1$: construct a canonical database $D_{Q_1} \equiv \{ g_i \big( v( \vec{x}_i ) \big) \}$
** with $v$ being a matching 
* if $v(\vec{x}) \in Q_2(D_{Q_1})$ return '''yes''', otherwise '''no'''



=== Exercise ===
* [[Conjunctive Query/Containment Exercise]]


== Sources ==
* [[Database Systems Architecture (ULB)]]
* Database Systems Architecture lecture notes #2 by S. Vansummeren [https://dl.dropboxusercontent.com/sh/r0zvy3zaycbevx8/U0XnqCSwGZ/lect2-notes-conjunctive.pdf]
* Web Data Management book [http://webdam.inria.fr/Jorge]


[[Category:Relational Databases]]</text>
      <sha1>87hcriki0wj3mw3lqqjpytda8ma2anb</sha1>
    </revision>
    <revision>
      <id>686</id>
      <parentid>169</parentid>
      <timestamp>2015-11-23T12:35:55Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8904">== Conjunctive Query ==
A ''Conjunctive Query'' (CQ) is
* a [[First Order Logic]] expression without negations and disjunctions


A CQ is an expression of the following form:

$\underbrace{Q(x_1, ..., x_n)}_{\text{head}} \leftarrow 
\underbrace{R(a_1, ..., a_m), ..., S(c_1, ..., c_k)}_{\text{body}}$
* it consists of two parts: head and body
* $V = (a_1, ..., a_m, ..., c_1, ..., c_k)$ - variables and constants from the body
* $X = (x_1, ..., x_n)$ is a set of variables from the head
** $X \subseteq V$
** the variables from $X$ are called ''distinguished variables'' (also ''free'' or ''placeholder'' variables)
* $Y = V - X$  - variables from the body which aren't in the head
** $Y \subseteq V$
** variables from $Y$ are called ''existential variables'' (also ''bound'' variables)
* note that the head doesn't necessarily have to contain only variables, it might as well contain constants
** these constants will be returned in the results



$R(a_1, ..., a_m)$ is called an ''atom'' 
* if an atom does not contain any variables, only constants, it's a ''fact''
* so we can view a database as a set of facts 


Alternative vector form:
* $Q( \vec{x} ) \leftarrow A_1(\vec{u}_1), \ ..., \ A_k(\vec{u}_k)$


=== Example ===
Suppose we have the following database

&lt;math&gt;R \\
\begin{array}{| c c |}
  \hline
  1 &amp; 2 \\
  2 &amp; 3 \\
  2 &amp; 5 \\
  6 &amp; 7 \\
  7 &amp; 5 \\
  5 &amp; 5 \\
  \hline
\end{array}&lt;/math&gt;&lt;math&gt;S \\
\begin{array}{| c |}
  \hline
  2 \\
  7 \\
  \hline
\end{array}&lt;/math&gt;

the query $Q(x, y) \leftarrow R(x, y), R(y, 5), S(y)$ wants to retrieve all pairs $(x, y)$ s.t.
* $(x, y)$ occurs in $R$
* $y$ then occurs in $R$ together with 5
* and that $y$ occurs as a value in $S$


=== Substitution ===
'''def''': a ''substitution'' $f$ of $Q$ into database $D$ is 
: a function that maps all variables from $Q$ to constants from $D$

'''def''': a substitution $f$ of $Q$ into a database $D$ is a ''matching'' if
: $f(\text{body}) \subseteq D$, i.e. if we evaluate $f$ on the body of the query $Q$, we will get a subset of $D$
: so when we apply $f(\text{head})$ we get a tuple that is a part of the result of evaluating $Q$ on $D$

Then the result of a conjunctive query can be shown as:
* $Q(D) \leftarrow \{ f(\text{head}) | f \text{ is a matching of $Q$ to $D$ } \}$


Let's consider the previous example: $Q(x, y) \leftarrow \underbrace{R(x, y)}_{(1)}, \underbrace{R(y, 5)}_{(2)}, \underbrace{S(y)}_{(3)}$ for the same database

Example with matching
# $(1)$ gets a tuple form $R$
#* say it's (1, 2)
#* so it assigns $x \mapsto 1, y \mapsto 2$
#: so our substitution so far is $f: x \mapsto 1, y \mapsto 2$
# $(2)$ looks for a tuple in $R$ with $y = 2$ 
#* because we established the matching $f$ with $y \mapsto 2$
#* second value of this tuple must be a constant 5
#* we find such tuple: it's (2, 5)
#* nothing gets assigned at this step 
# $(3)$ looks for a value in $S$ with $y = 2$
#* same reason: we have $y \mapsto 2$
#* it finds a fact $S(2)$ in the database
# so it returns a matching pair (1, 2)
#* we say there is a matching (1, 2) in the database $D$


Example without matching
# $(1)$ we try another tuple from $R$, say (7, 5)
#* we assign $x \mapsto 7, y \mapsto 5$
# $(2)$ now we try to find a tuple ($y$, 5) = (5, 5) in $R$
#* no such tuple
# therefor (7, 5) is not a matching and will not be returned by $Q$


So this way we try all values of our database table and return only matching ones 
* for this particular example the query returns two tuples: (1, 2) and (6, 7)
* i.e. $Q(D) = \{ (1, 2), (6, 7) \}$


=== Translation ===
[[First Order Logic]]
* CQs can be translated to [[First Order Logic]] expressions
* for query $q(x_1, ..., x_n) = A_1(...), \ ..., \ A_n(...)$
* FOL expressions is $\{ \, x_1, ..., x_n \ \mid \ \exists \ y_1, ..., y_m : A_1(...) \ \land \ ... \ \land \ A_n(...) \, \}$
** $x_1, ..., x_n$ - distinguished variables, and $y_1, ..., y_m$ are existential


[[Relational Algebra]]
* CQs can be translated to a subset of RA expressions - [[Select-Project-Join Expressions]]
* see [[Conjunctive Query/Translation]]


=== Properties ===
CQs have an interesting property
* The query containment problem is undecidable for SQL and [[Relational Algebra]] (see [[Logical Query Plan Optimization]]), but it is decidable for Conjunctive Queries 
* The decidability of containment is NP-complete problem, but usually CQs are not big, so it is acceptable 

This makes CQs very suitable for [[Logical Query Plan Optimization]], namely, for [[Logical Query Plan Optimization#Removing Redundant Joins|removing redundant joins]]



== Containment and Equivalence ==
=== Containment ===
$Q_1$ ''is contained in'' $Q_2$ (denoted as $Q_1 \subseteq Q_2$) if
* for any database $D$ holds $Q_1(D) \subseteq Q_2(D)$
* i.e. the result of $Q_1$ is always a subset of the result of $Q_2$, no matter what database $D$ they are evaluated on

$Q_1$ ''is equivalent to'' $Q_2$ (denoted as $Q_1 \equiv Q_2$)
* iff $Q_1 \subseteq Q_2 \land Q_2 \subseteq Q_1$

Example 
* $A(x, y) \leftarrow R(x, w), G(w, z), R(z, y)$
* $B(x, w) \leftarrow R(x, w), G(w, w), R(w, y)$
* $B \subseteq A$

To show that we use the definition
* let $D$ be an arbitrary DB and 
* let $t \in B(D)$ (one arbitrary result of $B$ evaluated on $D$)
* there exists a matching $f$ of $B$ into $D$ s.t. $t = (f(x), f(y))$ (by definition of matching)
** so we need to show that $t = (f(x), f(y)) \in A(D)$
* let $h$ be a substitution:
** $h: x \mapsto f(x), y \mapsto f(y), w \mapsto f(w), z \mapsto f(w)$ 
* then $h$ is a matching of $A$ into $D$
** $t = (f(x), f(y)) = (h(x), h(y)) \in A$ 


It is also possible to show that containment is decidable.


=== Homomorphism ===
'''def''': a ''homomorphism'' of $Q_2$ to $Q_1$ is 
* a function $h$ that maps each variable in $Q_2$ to either
** a variable from $Q_1$ or
** a constant form $Q_1$
* s.t. 
** $h(\text{head}_2) = \text{head}_1$
** $h(\text{body}_2) \subseteq \text{body}_1$
** i.e. the values returned by queries are always the same, and body of one query is a subset of the other's query body


Examples
* see [[Conjunctive Query/Homomorphism]]


=== Containment Theorem ===
'''Thm''': $Q_1 \subset Q_2 \iff $ there's a homomorphism from $Q_2$ to $Q_1$

Proof of $\Leftarrow$ (if)
* let $h: Q_2 \to Q_1$ be a homomorphism
* let $D$ be a database
* if we fix an arbitrary tuple $t \in Q_1(D)$, we need to prove that $t \in Q_2(D)$
* since $t \in Q_1(D)$ we know that 
** $t = f(\text{head}_1)$ 
** with a matching $f$ of $Q_1$ into $D$ 
** (by semantics of CQs)
* let's consider a composition $f \circ h$ (composition of $f$ with the homomorphism $h$)
** this is a substitution of $Q_2$ into $D$! (we fist applied the homomorphism and then the matching - and got the substitution)
** since $h$ is a homomorphism, $h(\text{body}_2) \subseteq \text{body}_2$ (by def of homomorphism)
** $\to$ $f\big(h(\text{body}_2)\big) \subseteq f(\text{body}_1) \subseteq D$
** in other words, $f \circ h$ is a matching of $Q_2$ into $D$
* hence 
** $f\big(h(\text{body}_2) \big) \in Q_2(D)$
** and finally $t = f(\text{head}_1) = f\big(h(\text{head}_2) \big) \in Q_2(D)$

Proof of $\Rightarrow$ (only if) 
* suppose that $Q_1 \subseteq Q_2$
* let's consider variables in $Q_1$ as constants
** we can view $\text{body}_1$ as a mini-database $D_{Q_1}$ 
** (this database is called a ''canonical database'' of $Q_1$) 
* the identity function is a matching of $Q_1$ to $D_{Q_1}$
** hence $\text{head}_1 \in Q_1(D_{Q_1})$
* since $Q_1 \subseteq Q_2$ we know that $\text{head}_1 \in Q_2(D_{Q_1})$
** by construction of our database $D_{Q_1}$
* so there exists a matching $f$ from $Q_2$ to $D_{Q_1}$ s.t.
** $\text{head}_1 = f(\text{head}_2)$ and
** $f(\text{body}_2) \subseteq D_{Q_1} = \text{body}_1$
* $f$ is a homomorphism of $Q_2$ to $Q_1$ by the definition (by considering variables again as variables)

$\blacksquare$


From the second part of the proof we may get a way of checking for containment: the Golden Method


=== The Golden Method ===
To decide whether $Q_1 \subseteq Q_2$
* evaluate $Q_2$ on a canonical database $D_{Q_1}$ (which is a body of $Q_1$, see [[#Containment Theorem]])
* check if the head of $Q_1$ is in the results 


QueryContainment($Q_1$, $Q_2$)
* input
** $Q_1(\vec{x}) \leftarrow g_1(\vec{x}_1), ..., g_n(\vec{x}_n)$
** $Q_2(\vec{y}) \leftarrow h_1(\vec{y}_1), ..., h_m(\vec{y}_m)$
* freeze $Q_1$: construct a canonical database $D_{Q_1} \equiv \{ g_i \big( v( \vec{x}_i ) \big) \}$
** with $v$ being a matching 
* if $v(\vec{x}) \in Q_2(D_{Q_1})$ return '''yes''', otherwise '''no'''



=== Exercise ===
* [[Conjunctive Query/Containment Exercise]]


== Sources ==
* [[Database Systems Architecture (ULB)]]
* Database Systems Architecture lecture notes #2 by S. Vansummeren [https://dl.dropboxusercontent.com/sh/r0zvy3zaycbevx8/U0XnqCSwGZ/lect2-notes-conjunctive.pdf]
* [[Web Data Management (book)]]

[[Category:Relational Databases]]</text>
      <sha1>sce624bmkgc8poruhayw0at1vu1b7ad</sha1>
    </revision>
  </page>
  <page>
    <title>Logical Query Plan Optimization</title>
    <ns>0</ns>
    <id>169</id>
    <revision>
      <id>170</id>
      <timestamp>2014-05-06T18:39:21Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4786">== [[Query Plan#Logical Query Plan|Logical Query Plan]] Optimization ==
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/query-processing-1st.png

Translating SQL to RA expression is the first step in [[Query Processing]] Pipeline
* Input: SQL
* Output: Logical Query Plan - expression in Extended Relational Algebra



=== Example ===
Suppose we have this query
&lt;pre&gt;SELECT DISTINCT x.name, z.name
FROM Product x, Purchase y, Customer z
WHERE x.pid = y.pid AND y.cid = z.cid AND
      x.price &gt; 100 AND z.city = 'Seattle'
&lt;/pre&gt;

We translate it to the following expression:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/logical-query-plan-ex2.png


But there is a more optimal way to obtain the same results 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/logical-query-plan-ex2-opt.png

The process of finding a cheaper equivalent expression is called (logical) ''query optimization''


== Optimality ==
* every node needs executing 
* hence, the fewer nodes we have, the faster the execution 

A [[Relational Algebra]] expression $e$ is optimal if there is no other expression $e'$ s.t.
* $e'$ is equivalent to $e$ (i.e. for every database $D:$ $e(D) = e'(D)$)
* $e'$ is shorten (i.e. has fewer operations)


=== The Optimization Problem ===
The Optimization Problem
* input: a RA expression $e$
* output: the optimal expression $e'$ s.t. $e \equiv e'$

Undecidability 
* This problem in [[Decidability|undecidable]]: on some expressions it may run forever.
* However we can optimize plans of a particular form


== Select-Project-Join Expression ==
In practice, most queries are of the form [[Select-Project-Join Expression|Select-Project-Join]] (SPJ)

Example
* $\pi_\text{...} \sigma_{A_1 = B_1 \land ... \land A_n = B_n} (R_1 \times ... \times R_n)$
* only selections, projections and joins, 
* for selections only equalities are used as predicates

And we can optimize this kind of queries! 


=== Example ===
&lt;pre&gt;
SELECT movieTitle FROM StarsIn S1
WHERE starName IN (
    SELECT name
    FROM MovieStar, StarsIn S2
    WHERE birthdate = 1960
    ANDS2.movieTitle = S1.movieTitle)
&lt;/pre&gt;

Note that this query is equivalent to 
&lt;pre&gt;
SELECT movieTitle FROM StarsIn
WHERE starName IN (
    SELECT name
    FROM MovieStar
    WHERE birthdate = 1960)&lt;/pre&gt;

This one has one join less to execute (and the join is the most expensive operation!)

Why? 
* the first query may be a result of view expansion (the subquery is actually a view that is expanded for query evaluation)
* careless programmers

It is possible to automatically translate from first kind of query to second one
* the process is called ''removing redundant joins''


=== Removing Redundant Joins ===
The problem:
* given SPJ expression $e$
* eliminate as many joins as possible 
* and return equivalent expression $e'$

To do that we could exploit one of the properties of [[Conjunctive Query]]s: 
* the containment problem (and therefore the equivalence problem) is decidable in them


The algorithm to remove redundant joins is as follows:
* find the minimal [[Select-Project-Join Expression|Select-Project-Join]] expression
* [[Conjunctive Query#Translation to CQ|translate it to Conjunctive Query]]
* try removing each atom of the expression and check for equivalence with the original query
** if removing leads to an equivalent query, use it for later checks 
** at the end return the simplest version
** it suffices to do a single pass
* once found the optimized CQ query, [[Conjunctive Query#Translation from CQ|translate it back to Relational Algebra]]

This will eliminate the redundant joins in an RA expression


== Heuristics ==
To optimize an RA expression further (after eliminating redundant joins) we can use some heuristics 

For relations $R(A, B), S(C, D)$ consider the following expression
* $\pi_A \sigma_{A = 5 \land B &lt; D} (R \times S)$


=== Pushing Selection ===
* we want to have selections as close as possible to the actual tables
* so this way we eliminate some tuples before joining them

$\pi_A \sigma_{B &lt; D} \big( \sigma_{A = 5}(R) \times S \big)$


=== Recognizing Joins ===
* we replace Cartesian product with Joins
* to help the optimizer assign the best [[Physical Operators (databases)|physical operation]] to this join

$\pi_A \big( \sigma_{A = 5}(R) \Join_{B &lt; D} S \big)$



=== Introduce Projections ===
* in this example we see that we need only attribute $D$ in the relation $S$
* so we can introduce projections to save memory

$\pi_A \big( \sigma_{A = 5}(R) \Join_{B &lt; D} \pi_D (S) \big)$


== Integrated Exercises ==
See [[LQP Optimization Exercises (DBSA)]]




== Sources ==
* [[Database Systems Architecture (ULB)]]
* [[Introduction to Data Science (coursera)]]


[[Category:Relational Databases]]</text>
      <sha1>m7coiubsuf2se1ngpq7zeahmxdix9jl</sha1>
    </revision>
  </page>
  <page>
    <title>Select-Project-Join Expressions</title>
    <ns>0</ns>
    <id>170</id>
    <revision>
      <id>171</id>
      <timestamp>2013-12-21T07:52:05Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="945">== Select-Project-Join Expression ==
In practice, most [[Relational Algebra]] expressions (i.e. queries) are of the ''Select-Project-Join'' form (SPJ)

an ''SPJ expression'' is
* a [[Relational Algebra]] expression
* it consists only of selections, projections and joins
* there are only equality predicates for selection (i.e. of form $A_j = B_i$)

&lt;pre&gt;
SELECT ...
FROM R1, ..., Rn
WHERE A1 = B1 AND ... AND An = Bn
&lt;/pre&gt;

The corresponding RA expression is
* $\pi_\text{...} \sigma_{A_1 = B_1 \land ... \land A_n = B_n} (R_1 \times ... \times R_n)$


== Applications ==
This type of query is very interesting for [[Logical Query Plan Optimization]] since it allows
* to translate a RA expression to [[Conjunctive Query]]
* and optimize the CQ to remove redundant joins



== See also ==
* [[Logical Query Plan Optimization]]
* [[Conjunctive Query]]

== Sources ==
* [[Database Systems Architecture (ULB)]]


[[Category:Relational Databases]]</text>
      <sha1>0b8udugzc7jqfj5fc60nemuvno2gg4z</sha1>
    </revision>
  </page>
  <page>
    <title>Secondary Storage</title>
    <ns>0</ns>
    <id>171</id>
    <revision>
      <id>172</id>
      <timestamp>2013-12-07T07:12:54Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5398">== Secondary Storage ==
This is a part of the [[Memory Hierarchy]]

Disks is the most common secondary storage 
* The disk is organized into disk ''blocks'' (or ''pages'', from the OS point of view) of 4-64 KBs each
* ''Buffers'' - entire blocks are moved to and from a continuous sections of main memory 

Key technique: organize data in a way that  
* when something is needed from a block 
* it's likely that other information from that block will also be needed 


=== Main Components ===
Consists of two main components: 
* Disk Assembly
* Head Assembly

Disk Assembly
* has one or more circular ''platters''  that rotate around a central spindle
* upper and lower surfaces are covered with magnetic materials (that store 1s and 0s)

Hierarchy
* disk is organized into ''tracks'' - concentric circles on a single platter 
* tracks that are at fixed radius from the center (among all the surfaces) form one ''cylinder''
* tracks are organized into ''sectors'' - segments that are separated by non-magnetic ''gaps'' 
* for each surface there's one head that reads data, and all the heads form ''the head assembly''


=== Disk Controller ===
Disk drives are controlled by a ''disk controller'' (DC): a small processor that
* controls the head assembly
* selects a needed sector 
* transfers bits between sectors and the main memory
* buffers entire track in local memory of the disk controller (in hope it will be needed soon)

It communicates with the main memory via the ''data bus''

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/disk-controller.png


=== Accessing ===
Accessing (reading or writing) a block of data requires 3 steps:

# DC positions the head assembly at the cylinder that contains the needed block
#: the time to do it is the ''seek time''
# DC waits until the first sector of the block appears under the head
#: the ''rotation latency''
#: typically 0-10 mls, 5 mls on average (1 rotations is 10 mls)
# DC reads/writes sectors under the head while sectors pass under it
#: the ''transfer time''
#: quite small 

the ''latency of disk'' is a sum of the three:
* seek time + rotation latency + transfer time
* usually ~10-11 mls 
* but it doesn't mean that the system will get all data in 10 mls after sending a request to DC: it may be busy with another processes

Another measure: 
* ''throughput'' - the number of dist accesses per second that the system can accommodate 


== Techniques to Speed Up Access ==
=== Optimizing by Cylinders ===
place blocks that are accessed together on the same (or adjacent) cylinder 
* this way can decrease seek time and possibly the rotation latency
* if we read blocks consequently, then we may neglect all seek times (except for first)

=== Striping ===
divide data among several smaller disks (rather than one large one)
* in result, you'll have more independent head assemblies
* increases the number of block accesses per unit of time

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/disk-controller-ndisks.png
* As long as DC, bus, memory can handle $n$ times the data-transfer rate,
* then $n$ disks will have approximately the performance of 1 disk operating $n$ times faster
* but if the system is overloaded, when requests are delayed (or even cancelled)

''Striping'' - this is a technique to speed up access to large DB objects 
* (a large DB object is one that spans several disk blocks)

Idea:
* Suppose we have 4 disks and want to access a relation faster
* then we can &quot;stripe&quot; this relation by dividing it among the 4 disks:
** 1 disk receives blocks 1, 5, 9, ...
** 2 disk received blocks 2, 6, 10, ...
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/disk-controller-striping.png

=== Mirroring ===
&quot;Mirror&quot; a disk
* have 2 or more copies of the same information on different disks
* like the previous technique - allows to access several blocks at the same time
** for $n$ disks, rate at which we can read goes up by a factor of $n$ 
** the speedup can be even greater if DC chooses the disk with its head being closest to the needed block
* but writing doesn't speed up at all: we need to write data to all $n$ disks
* reliability as a bonus we have a backup if one of the disks fails

=== Scheduling ===
it's possible to use a disk-scheduling algorithm 
* to select the order in which several blocks are read/written
* cannot use this approach if we need to have some certain sequence
* but if requests come from independent processes, they can benefit from it (on average)

The Elevator Algorithm: to schedule large numbers of block requests

Idea:
* disk heads go from innermost to outermost cylinder, and then back again
** just as an elevator from bottom to top and back
* as heads pass a cylinder, they stop if there's a request for block on that cylinder
* they proceed in the same direction until the next required cylinder is met
* if there are no requests ahead, heads reverse the direction

=== Prefetching ===
We also can prefetch blocks to the main memory in anticipation they'll be needed soon
* sometimes it's possible to predict the order in which blocks will be requested 



== See also ==
* [[Memory Hierarchy]]
* [[I/O Model of Computation]]

== Sources ==
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom


[[Category:Computer Architecture]]
[[Category:Database Systems Architecture]]</text>
      <sha1>3r0o6a42gbvjbiot5krawg7zfkjl4kc</sha1>
    </revision>
  </page>
  <page>
    <title>Memory Hierarchy</title>
    <ns>0</ns>
    <id>172</id>
    <revision>
      <id>173</id>
      <timestamp>2013-12-03T21:08:24Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1340">== The Memory Hierarchy ==
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/memory-hierarchy.png

Two main categories:
* ''volatile'': forgets what it stores when power goes off
* ''non-volatile'': can persist data for a long time

Normally data is moved only between adjacent levels of hierarchy 


=== Cache ===
* size: 1 mb or more
* access time: a few nanoseconds 

data and instructions are moved to cache from the main memory when they are needed by the CPU

=== Main Memory ===
* to more from memory to cache/processor: 10-100 nanoseconds 

stores all data and instructions

=== [[Secondary Storage]] ===
* 10 milliseconds to transfer data from disk to memory 

''Secondary storage'': disks and other devices that can store large amounts of data 

=== Virtual Memory ===
''Virtual Memory'' is an address space (32 or 64 bits) 
* the OS manages VM keeping needed parts at hand (in the main memory)
* and the rest on disk 

So beware: data can be moved to and fro by the OS!

=== Tertiary Storages ===
* very high read/write times
* may be optical disks stored somewhere 

a storage with very large capacity (petabytes, etc)


== See also ==
* [[Secondary Storage]]

== Sources ==
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom


[[Category:Computer Architecture]]</text>
      <sha1>k2u2yobyhfn6k7eb4u6herm15dshqwb</sha1>
    </revision>
  </page>
  <page>
    <title>Physical Data Organization (databases)</title>
    <ns>0</ns>
    <id>173</id>
    <revision>
      <id>174</id>
      <timestamp>2013-12-31T11:25:08Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11040">== [[Memory Hierarchy]] ==
* CPU and its cache
* Main Memory
* [[Secondary Storage]]

Important consequence: 
* [[I/O Model of Computation]]


== Block and Record Addresses ==
Blocks (and Records) can be in
* the main memory
** their '''address''' is the address of the 1st byte of the block (record)
* the secondary storage
** and the '''address''' is: device id, cylinder number, etc. 
** A record can be identified by an offset within a block

There are several ways to represent an address in the [[Secondary Storage|secondary memory]]


=== Physical Address ===
* host, disk id, cylinder id, track, block, offset


=== Logical (Structured) Address ===
* arbitrary string of some fixed length
* a ''map table'' knows how to translate logical address to physical 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/map-table.png

Logical table and map table give us flexibility
* may move data around as we want
* making sure we maintain same logical address


=== [[Point Swizzling]] ===
* Initially all pointers have physical address
* but when we load them into memory, we need to ''swizzle'' (translate) them to main memory address


== Arranging Data on Disk ==
[[Physical Operators (databases)|physical algorithms]] depend on 
* how data (relations, records, shemas) is organized on disk 
* what data structures are used 

Definitions
* a ''data element'' (a tuple of object) is represented by a ''record'', which consists of consecutive bytes on some disk block
* ''header'' is a region that contains some meta information about the record

many machines allow more efficient access for main memory chunks when the data is addressed by a multiplier of 4 or 8


=== Fixed-Length Records ===
This is the simplest sort of records
* they consist only of fixed-length fields

a record starts with a fixed-length header, which may store
* a pointer to the schema
* length of the record (to go through records without looking at the schema)
* timestamps - when the record was last modified or read (useful for transactions)

Example
&lt;pre&gt;CREATE TABLE MovieStar (
  name CHAR(30) PRIMARY KEY,
  address VARCHAR(255),
  gender CHAR(1),
  birthday DATE
);&lt;/pre&gt;

* name: 30 bytes - allocate 32 (multiplier of 4) to allow faster access
* address: 255 + 1 bytes (255 bytes for text, 1 for the string endmarker)
* gender: either M or F, 4 bytes
* birthday: 10 bytes, allocate 12 bytes

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/layout-fixed-record.png

Blocks
* There records are stored in blocks of the disk and moved into the main memory along with the entire block
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/layout-fixed-block.png
* we pack as much as possible to the block, and leave the remaining space unused 

A ''block header'' may hold
* which relation this block belongs to
* timestamp that shows time of the last access 
* other things 


=== Offset Table ===
Another way to organize records within a block is to keep an ''offset table'' in the header

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/offset-table.png

The block is populated with records from the end
* useful when records can be of different length 
* in this case don't know in advance how many records the block will hold 


=== Variable-Length Data Records ===
Not everything can be represented by fixed-length records:
* data items with varying size
** addresses can be 256 bits, but usually not longer than 50 bits
** can safe a lot of space!
* repeated fields
** for example in many-to-many relationships we want to store many pointers within one record
* variable-format records 
** when schema is not knows in advance (say JSON or XML)
* media streams 
** MPEG video or audio

When there are fields whose length can vary we should locate them in such a way that we can find them 

==== Put Fixed-Length Fields Ahead ====
* Put all fixed-length fields ahead
* then add to the header: 
** length of the whole record
** pointers (offsets) to all variable-length fields
** not needed to include the pointer to the first such field - since there are only fixed-length fields before it, can already calculate the address

To represent a NULL value we just put a null-pointer value to the pointer

Example 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/var-len-records-1.png

==== Repeating Fields ====
Say we have a fixed-length field $F$ but it can repeat a number of times
* in this case we can group all occurrences together
* to locate an item we keep 2 values: length $L$ and offset $O$ to the first item
** to get $i$th value we can:
** $O + (i - 1) \cdot L$

Example
* one movie star can have several movies
* we can represent it by pointers to movie records 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/var-len-fixed-len.png

==== Alternative Approach ====
Alternatively to [[#Put Fixed-Length Fields Ahead]]
* we keep records of fixed length in the block, but 
* the variable-length portion of a record - in a separate block 
* good for variable-length fields and repeating fields

So in records we keep 
* pointers to place where each var-length field begins and
* either how many repetitions there are or
* where the field ends 

Example
* address + len, name + len, movies + number of references
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/var-len-alt1.png

Advantages
* keeping records fixed-sized allows for more efficient serach 
* minimizes overhead in block records 
* allows records to be moved easier

Disadvantaged
* storing record on another block increases the number of I/O operations (see [[I/O Model of Computation]])

==== Records Spanning Several Blocks ====
How to store records that are larger than a block? 
* technique for storing such records as called ''spanned records''

This technique is also useful when records are smaller than a block, but storing them within a block wastes lots of space 
* say a record takes 51% of a block 
* then 49% of each block will be wasted (cannot put another record there)

* A portion of a record that appears in one block is called a ''record fragment''
* A record with 2 or more fragments is called ''spanned'', otherwise (it lays within one block) - it's ''unspanned''


To store a record fragment we need some extra information in the header 
* a bit to indicate if it's a fragment or not
* 2 bits to tell if it's the first of the last fragment of a record
* if there's a next or previous fragment we need a pointer to them 

Example of a record spanning 2 blocks:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/spanned-record.png


=== BLOBs ===
Now let's consider truly enormous records 
* Such objects are binary and large 
* BLOBs - binary large objects 

Storage of BLOBs
* a BLOB should be stored sequentially, so it may be retrieved efficiently 
* it's also possible to store it in a linked list of blocks 


=== Column Stores ===
See [[Column-Oriented Databases]]

{{ TODO | add more info }}


== Record Modification ==
* Insertions, deletions and updates of records often cause problems 
* Most severe problems happen when records change their length 


=== Insertion ===
Suppose we insert a new record into a relation

if there's no particular order,
* we just find a block with some empty space (or get a new one) 
* and put the record there

But if we must keep some order (say we want records be sorted on the primary key):
* first locate the appropriate block
* suppose there's room to fit the record
** to preserve order we may need to slide down some records to free space at the proper point
** and then we just put the record into that place 
** in this case may also need to modify the offset table:
*** change pointers for the moved records 
*** add a pointer to the new one
*** be careful with [[Point Swizzling]]
* if no room for a records in the block
** need to find space outside of the block
** (2 major approaches discussed below)

==== Approach 1: Nearby Blocks ====
Look for room on a nearby block

For example
* block $B_1$ doesn't have space, but following it $B_2$ has 
* so we move the highest records of $B_1$ to $B_2$
* slide the records around on both blocks 

==== Approach 2: Overflow Blocks ====
We can create ''an overflow block''
* each block $B$ has a pointer to a special block where additional records are kept
* by &quot;additional&quot; we mean records that theoretically belong to $B$, but don't fit in 
* these blocks are called ''overflow'' blocks 
* in such a way we can link blocks together to have a list of overflow blocks
: https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/overflow-blocks.png


=== Deletion ===
When we delete a record, we may want to reclaim the freed space

If we use an [[#Offset Table|offset table]], and can move records around the block, 
* then we can compact the space 
: https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/offset-table.png
* note the unused space: we can just shift all the remaining records a bit 

If we cannot move records, 
* we should maintain a list of available space addresses in the header
* to be used afterwards when inserting


==== Tombstones ====
Dangling Pointers
* there might be pointers to occupied records (e.g. see [[Point Swizzling]])
* we don't want these pointers to dangle or point to wrong records

Usual technique in this case 
* to place a ''tombstone'' in place of the record being deleted 
* the tombstone is permanent: it must exist until the DB is reconstructed 

Where to put a tombstone depends on the nature of record pointers 
* for [[#Offset Table|offset table]]: could be a NULL-pointer in the offset table
* for map table (see [[#Logical (Structured) Address]]): a tombstone could be a NULL-pointer returned from the map table 


If we need to replace records by tombstones, 
* we should have a bit that indicates whether a record is a tombstone or not
* only this bit (or byte) must remain untouched
* the rest can be reused safely 
* example
: https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/tombstones.png


=== Update ===
When a fixed-length record is updated, it causes no effect on the storage system

But it's not the case for variable-length records
* here we have all problems associated with both insertions and deletions
* (except for tombstones - we won't create them)

If the updated version is longer that the old one
* we'll need to find more space on the block 
* it may involve [[#Approach 1: Nearby Blocks|sliding records]] or [[#Approach 2: Overflow Blocks|creating overflow blocks]] 
* if portions are stored on another block, we may need to move elements around that block or create a new one

If the new version is shorter, we may want to reclaim the freed space for later use
* same as with [[#Deletion]]


== Sources ==
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom
* [[Database Systems Architecture (ULB)]]


[[Category:Database Systems Architecture]]</text>
      <sha1>alsv5k4c7b01f65pvler2h9k67kqu2c</sha1>
    </revision>
  </page>
  <page>
    <title>Point Swizzling</title>
    <ns>0</ns>
    <id>174</id>
    <revision>
      <id>175</id>
      <timestamp>2013-12-07T07:10:16Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4091">How to manage pointers to blocks and records if they are moved between main and secondary memory? 

== Translation Table ==
Translation table
* when a record is stored on disk, it's pointers are in physical address form 
* but when we load it into memory, it remains in this form 
* to convert the physical address to the main memory address we use the same idea as for ''map table'':
* we keep a ''translation table'' to do that
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/translation-table.png


When following a pointer,
* if the block is already in the translation table (and therefore in the main memory) - it's okay, don't need to load it
* if not - need to load it into the main memory, and add to the table


== Point Swizzling ==
But for some frequently accessed pointers we don't want to repeatedly look up the address 
* to avoid that we use ''pointer swizzling'' techniques
* pointer is ''swizzled'' when it's translated to main memory address (and saved in this form)

So in memory with these techniques a pointer consists of 
* a bit indicating whether this pointer is a physical address or (swizzled) memory address
* and physical or memory address itself


=== Example ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/point-swizzling.png

* At the beginning both records are on disk 
* Then we load the first one to memory 
* It points to two other records 
** first gets swizzled because it points to another record that is also in the memory
** another one doesn't, because it points to a record not yet brought to memory


== Strategies ==
There are several strategies to do that 

=== Automatic Swizzling ===
as soon as block is brought into memory, we swizzle the pointers and enter them into translation table

=== On Demand ===
* leave all pointers unswizzled, just enter the addresses to the translation table 
* when we follow a pointer, we swizzle it if it's not swizzled and leads to a block in memory

=== No Swizzling ===
* always consult the translation table
* advantage: gives us flexibility so we can move blocks around as we like, and when moving we just need update the address in the table

=== Programmer Control ===
* application programmer may know if some pointers are likely to be followed more frequently than other
* e.g. if he knows that the block will be heavily accessed (because it's the root of a [[B-Tree]]), then it needs to be swizzled
* so he can say which pointers need swizzling and which don't

== Unswizzling ==
When a block is flushed back to dist, all pointers in the block must be unswizzled (memory addressed replaced by physical addresses)

This can be done using the transformation table but in the opposite direction 


== Pinning ==
A block in memory is ''pinned'' if it cannot be moved back to disk safely
* a bit signifying if a block is pinned in located in header

reasons for pinning 
* if a block $B_1$ has a swizzled pointer $B_2$ then we must be careful about moving block $B_2$ to avoid dangling pointers
** blocks like $B_2$ that are referred from outside, should be pinned 

So when we write a block back, we need to make sure it's not pinned and then unswizzle all pointers 
To unpin a pinned block we need to unswizzle any pointers to it

Consequently the translation table must record for each DB address
* where are the swizzled pointers 

Possible approaches 
* keep the list of references to a memory address
** can be a linked list attached to an entry in the translation table
* if memory address is significantly shorter than the physical address, we can relace the PA with
** the swizzled pointer
** another pointer to the next occurrence of usage of this pointer 
** together they will form a linked list of all pointer occurrences 
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/translation-table-unswizzling.png


== See also ==
* [[Physical Data Organization (databases)]]

== Sources ==
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom


[[Category:Database Systems Architecture]]</text>
      <sha1>m92inli7x690e5zzbbeh4mltdq0ib5p</sha1>
    </revision>
  </page>
  <page>
    <title>I/O Model of Computation</title>
    <ns>0</ns>
    <id>175</id>
    <revision>
      <id>176</id>
      <timestamp>2013-12-07T07:13:07Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="836">== I/O Model of Computation ==
'''The Rule:''' Dominance of I/O cost
* The time taken to perform a [[Secondary Storage|disk access]] is much larger than the time needed for manipulating data in the [[Memory Hierarchy|main memory]]
* Thus, the number of block accesses (Disk I/Os) is a good approximation to the time needed for an algorithm

=== Example ===
* read a block is ~11 mls (see [[Secondary Storage#Accessing]])
* search for a tuple within a block when it's in the main memory is ~1000 instructions (even with sequential search)
* i.e. search in the main memory is less than %1 of the block access time, can neglect it safely


== Sources ==
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]</text>
      <sha1>f9lhhyy51aw8pq6as0kye5xx7kbdsik</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Database Systems Architecture</title>
    <ns>14</ns>
    <id>176</id>
    <revision>
      <id>177</id>
      <timestamp>2015-06-27T08:45:31Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22">[[Category:Databases]]</text>
      <sha1>9er5ql6pu57qzhet55yxlpr10hmmb4n</sha1>
    </revision>
  </page>
  <page>
    <title>Big O</title>
    <ns>0</ns>
    <id>177</id>
    <revision>
      <id>178</id>
      <timestamp>2014-02-08T15:43:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="775">== Big O ==
* &lt;math&gt;T(n) = O(f(n))&lt;/math&gt;
* if there exists a constant c, such that
* &lt;math&gt;T(n) \leqslant c \cdot f(n)&lt;/math&gt; for all &lt;math&gt;n \geqslant n_0&lt;/math&gt;
* i.e. $T(n)$ is bound above $c \cdot f(n)$


== Big Omega ==
* &lt;math&gt;T(n) = \Omega(f(n))&lt;/math&gt;
* if &lt;math&gt;T(n) \geqslant c \cdot f(n)&lt;/math&gt; for all &lt;math&gt;n \geqslant n_0&lt;/math&gt; for any c


== Theta ==
* &lt;math&gt;T(n) = \Theta(f(n))&lt;/math&gt;
* if &lt;math&gt;T(n) = O(f(n))&lt;/math&gt; and &lt;math&gt;T(n) = \Omega(f(n))&lt;/math&gt;
* (&quot;sandwich&quot; between &lt;math&gt;O&lt;/math&gt; and &lt;math&gt;\Omega&lt;/math&gt;)


== Links ==
* [http://stackoverflow.com/questions/487258/plain-english-explanation-of-big-o Plain English explanation of Big O (stackoverflow)]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]

[[Category:Algorithms]]</text>
      <sha1>pzcexg83xc6igs81rx1vpia9bql8lfc</sha1>
    </revision>
  </page>
  <page>
    <title>Indexing (databases)</title>
    <ns>0</ns>
    <id>178</id>
    <revision>
      <id>179</id>
      <timestamp>2015-07-04T09:37:28Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2439">== Motivation: Searching ==
Suppose we have a relation $R(A, B, C, D)$, each tuple - 32 bytes
* $128 \times 10^6$ tuples is $R$
* Block size is $B$ = 4kb
* I.e. can store 128 tuples per block, $10^6$ tuples in total

Suppose we want to find a tuple with $C = 10$


Searching in [[I/O Model of Computation]]
* for each block $X \in R$
** load $X$
** check if there's a tuple $T \in X$ with $C = 10$
** yes - output $T$
** no - continue
** release $X$ from memory

In worst case it's $10^6$ I/Os 
* suppose $10^{-3}$ seconds per I/O operation
* 16.6 minutes in total

Can we do better? 


== Indexing ==
An ''index'' is any [[Secondary Storage|secondary memory]] data structure that
* takes a search key as input
* efficiently returns the collection of matching records


== One-Dimensional Indexes ==
=== Conventional Indexes ===
* [[Dense Index]]
* [[Sparse Index]]
* [[Secondary Index]] as a combination of both

=== Tree-Based Indexes ===
* [[B-Tree]]

=== Hash-Based Indexes ===
* [[Open Hashing Index]]
* [[Extensible Hashing]]
* [[Linear Hashing]]


== [[Multi-Dimensional Indexes]] ==
=== Conventional ===
* [[Multiple-Key Index]]

=== Tree-Based Indexes ===
* [[kd-Trees]]
* [[Quad Trees]]
* [[R-Tree]]
* [[Metric Trees]] and [[Spill-Trees]] 

=== Hash-Based Indexes ===
* [[Grid File Index]]
* [[Partitioned Hash Function Index]]



== Clustered Index ==
Index can be clustered or unclustered
* When index is clustered it means the records themselves are stored in index, not pointers
* I.e. a clustered index ensures that all data is stored in some order 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/hash-ways-to-store.png
* Usually there is only one clustered index per relation (otherwise the data will be duplicated)

If an index (say, [[B-Tree]]) is not clustered, then instead of following each pointer other techniques can be used, such as [[Bitmap Heap Scan]]


== [[Information Retrieval]] Indexing ==
Indexing can also be applied to unstructured data such as text
* [[Inverted Index]] builds an index from words to documents where these words are contained
* [[Locality Sensitive Hashing]] gives an approximate answer to [[KNN]] queries



== Sources ==
* [[Database Systems Architecture (ULB)]]
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom

[[Category:Database Systems Architecture]]
[[Category:Database Indexes]]
[[Category:Databases]]</text>
      <sha1>qeeios6ut5adfi0v9dzlsm7g8ex0ucd</sha1>
    </revision>
  </page>
  <page>
    <title>Dense Index</title>
    <ns>0</ns>
    <id>179</id>
    <revision>
      <id>180</id>
      <timestamp>2014-01-03T10:07:18Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2426">== Dense Index ==
A dense [[Indexing (databases)|index]] is a sequence of blocks that can hold only keys and pointers.
* here all records have a record in the index that point to them

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/dense-ind1.png


Assumptions
* out file (on the right) is ''sequential'' 
** i.e. it's created by sorting all tuples by some attribute, say, primary key
* we can keep 2 records in one block

Benefits
* Can fit more keys in memory at once - and scan there in memory, which is way faster
* can check if record exists without following a pointer (less additional IOs)


Unlike [[Sparse Index]], we cannot stack dense indexes on top of each other


== Operations ==
=== Lookup ===
* suppose we want to find a record with $k = 20$
* we locale a record in the index with $k = 20$
* follow the pointer: read the block where it points to

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/dense-ind-lookup.png


=== Deletion ===
Suppose we want to delete $k = 30$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/dense-ind-delete-1.png
* we follow the pointer for $k = 30$ 
* then remove the record and the pointer from the index
* we leave a tombstone and reorganize if needed
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/dense-ind-delete-2.png


=== Insertion ===
* Find the place where the key should belong to
* if there is room in the block, add it there (make sure the order is maintained)
* if not - shift some records out from the block (to a new one or to its neighbor)
* update the index accordingly


== Duplicate Keys ==
Suppose we have duplicate keys in our database. How to build index?

=== Option 1 ===
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/dense-ind-dup-1.png
* still like the original dense index: each record has it's pointer in the index

=== Option 2 ===
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/dense-ind-dup-2.png
* or we may record only the first occurrence of the key
* assuming the file is sequential, we are sure that the rest will follow
* of course it won't work if the file is not sequential



== See also ==
* [[Indexing (databases)]]
* [[Sparse Index]]
* [[Secondary Index]]

== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]
[[Category:Database Indexes]]</text>
      <sha1>tehq4too9kblar96ctgq5ahn0dbzp1n</sha1>
    </revision>
  </page>
  <page>
    <title>Sparse Index</title>
    <ns>0</ns>
    <id>180</id>
    <revision>
      <id>181</id>
      <timestamp>2013-12-11T19:55:33Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4358">== Sparse Index ==
A sparse [[Indexing (databases)|index]] has one (key, pointer) per each block
* so it uses less space than [[Dense Index]]
* but requires more time to find a record


https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/sparse-ind-1.png
* not all keys are referenced by this index
* pointers point only to the 1st key of the block
* cannot say from index if a key is present or not, always need to follow a pointer, load the block and check the key there

=== Nested Levels ===
Key benefit of this
* we can build the 2nd index on top of index
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/sparse-ind-2lev.png


== Operations ==
=== Lookup ===
Rule to retrieve record with specified $k$
* we find such $k$ in index that 
** is greater or equal to $k$,
** but less than consequent one

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/sparse-ind-lookup.png
* suppose we want to find a record with $k = 20$
** $10 \leqslant k = 20 &lt; 90$, follow 10
** $10 \leqslant k = 20 &lt; 30$, follow 10
** load (10, 20) block
* if we looked for $k = 15$
** we also would follow 10, and 10, then read the block and discover it's not there 

=== Deletion ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/sparse-delete-1.png

suppose we want to delete $k = 40$
* we locate the record, remove it and leave a tombstone there 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/sparse-delete-2.png

if we want to delete $k = 30$
* locate the record, delete it and leave a tombstone there
* but we want to keep it sequential and continuous: so we move 40 up
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/sparse-delete-3.png
* also note that we need to update the index as well: not it needs to point to 40 instead of 30

what if we want to delete both $k = 30$ and $k = 40$?
* locate the records and delete both
* the whole block is no longer needed - we remove the pointers to it along with corresponding index record
* so we remove 30 from the index and move 50 and 70 up
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/sparse-delete-4.png


=== Insertion ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/sparse-ind-insert-1.png

insert key 34
* we first locate where we insert
* lucky case: some room in the block, just add the record there

insert key 15
* this time no room in the block where we want to insert it 
* there are two options 
** Immediate Reorganization
** Overflow Blocks

'''Immediate Reorganization'''
* re-distribution data
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/sparse-ind-insert-2.png
* we try to push the data down
* in this case 20 is moved to the next block
* note that we also have to update the index key that points to the second block since its first key got updated
* worst case: we will move all the data blocks 
* variant: insert a new block and update the index 

'''Overflow Blocks'''
* we create a new block and create a pointer to it from 
* it will be reorganized later 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/sparse-ind-insert-3-overflow.png
* it may degenerate to a linked list 
** may have to traverse the whole chain only to find out that the value is not there
** i.e. back to linear search 


== Duplicate Keys ==
Suppose we have duplicate keys in our database. How to build index?

=== Option 1 ===
There could be some problems we build it same way as without assuming duplicate keys
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/sparse-ind-dup-problems.png
* careful with looking for 20 or 30!
* if we follow the pointer for 20, we'll loose the previous record for 20
* so in this case will need to also load the previous block to check if it contains something

=== Option 2 ===
We may point to previous values, so we know the range
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/sparse-ind-dup-2.png
* so in the index we indicate the ''first new'' (not seen previously) key from block


== See also ==
* [[Indexing (databases)]]
* [[Dense Index]]
* [[Secondary Index]]

== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]
[[Category:Database Indexes]]</text>
      <sha1>72jm4fnqmgflaci80ynj4pje9yuy6qr</sha1>
    </revision>
  </page>
  <page>
    <title>B-Tree</title>
    <ns>0</ns>
    <id>181</id>
    <revision>
      <id>182</id>
      <timestamp>2013-12-18T20:08:47Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10479">== B+ Tree ==
A [[Binary Search Trees|search tree]] is a way to organize data to allow efficient 
* ''B-Tree'' - same idea, but for secondary memory, for blocks
* A ''B+ Tree'' variation of B-Tree. Here if B-Tree is mentioned, it's usually referred to B+ Tree

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/btree-ex.png
* consists of ''leaf nodes'' and ''intermediate nodes''


=== Order of Tree ===
parameter $n$ is the order of a tree
* it determines the layout of the block 
* each block will have
** $n$ search keys
** $n + 1$ pointer

Example
* suppose our block has size 4096 bytes 
* integers are 4 bytes long, pointers are 8 bytes long
* suppose there's no header
* then we want such $n$ that $4n + 8(n + 1) \leqslant 4096$
* that $n = 340$

Example 2
* block size 4096 
* 8 bytes per pointer and 8 bytes per key
* $(n + 1) \cdot 8 + n \cdot 8 \leqslant 4096$
* $n = 255$: we can store 256 pointers and 255 keys in one block


=== Height ===
How to estimate height?
* Suppose $128 \times 10^6$ tuples in $R$
* we have a b-tree index with order $n = 255$ on attribute $C$
* assuming all leaf blocks are full, what's the height?
** so there are $\left\lceil \cfrac{128 \times 10^6}{255} \right\rceil$ leaf blocks
** $\left\lceil \cfrac{128 \times 10^6}{255^2} \right\rceil$ blocks at level 2
** $\left\lceil \cfrac{128 \times 10^6}{255^3} \right\rceil$ blocks at level 3
** ...
** $\left\lceil \cfrac{128 \times 10^6}{255^h} \right\rceil$ blocks at level $h$
** so it's logarithm 
* $h = \lceil \log_{255} (128 \cdot 10^6) \rceil = 4$
* so [[#Lookup]] is 4 + 1 I/Os

What if blocks are half-full?
* since leaves are half-full, they keep 128 records
* $h = \lceil \log_{128} (128 \cdot 10^6) \rceil = 4$
* again 4 + 1 I/Os 


=== Non-Leaf Node ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/btree-leaf-ex.png
* $n$ search keys, $n + 1$ pointers
* first pointer points to keys that are strictly less than the first key
* last pointer points to keys that are greater or equal to the last key
* for in-between pointers, if $k_i$ is a key, and $p_{i-1}$ and $p_i$ are pointers around it, then $p_{i-1} \leqslant k_i &lt; p_i$


=== Leaf Node ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/btree-non-leaf-ex.png
* $n$ keys, 
* $n$ pointers to actual records, 1 extra pointer to the next leaf in the sequence


== Balancing ==
Reasons
* I/O cost of [[#Lookup|looking up]] is the longest path from the root to a leaf
* so we want our tree be balanced: 
* to have paths as short as possible - with all the leaves at the same depth 

Idea 
* Recall that for $n$ we have $n + 1$ pointers and $n$ keys
* we don't want to have too empty nodes 
* so we will require all nodes to be at least half-full

=== Size Invariants ===
nodes are half-full: 
* at least $\left\lceil \cfrac{n + 1}{2} \right\rceil$ pointers for non leaf
* at least $\left\lfloor \cfrac{n + 1}{2} \right\rfloor$ pointers for leaf
* the only exception is root: it can contain any number of pointers

for example 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/btree-invariants-ex.png
* note that for leaf nodes a pointer to the next node counts as well

{| border=&quot;1&quot; class=&quot;wikitable&quot;
!
! max # pointers
! max # keys
! max # pointers to data
! min # keys
|-
! non-leaf
| $n + 1$ || $n$ || $\left\lceil \cfrac{n + 1}{2} \right\rceil$ || $\left\lceil \cfrac{n + 1}{2} \right\rceil - 1$
|-
! leaf
| $n + 1$ || $n$ || $\left\lfloor \cfrac{n + 1}{2} \right\rfloor$ || $\left\lfloor \cfrac{n + 1}{2} \right\rfloor$
|-
! root
| $n + 1$ || $n$ || 2 || 1
|}


== Operations ==
Cost of operations are expressed in [[I/O Model of Computation]]

=== Lookup ===
suppose we are looking for $k = 35$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/btree-ex.png

Algorithm
* start at the root
* follow the suitable pointer (as described in [[#Leaf Node]]) - this is the left root pointer
* for the next, take the last ($k \geqslant 35$)
* and finally read the block 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/btree-ex-lookup.png

==== I/O Cost ====
* head of the tree + 1 I/O to read
* for $k = 35$: 3 I/O
* for $k = 40$ (which doesn't exist): same path as for $k = 35$, cost is 3 I/O
* so I/O cost = the longest path from the root to leaf (which is why we want it balanced)

==== Range Lookups ====
* BTree supports range queries as well
* such as $35 \leqslant k \leqslant 40$
* we lookup the key corresponding to the left range boundary 
* since we have a pointer to the next block, we follow it until we hit the right range boundary
* I/O cost in this case is 
** length of the path from the root to the leaf
** then the number of leaves that we need to follow
** and also we need to follow a pointer for '''each''' key in the range


=== Insert ===
4 cases 
* simple case - space available in leaf
* leaf overflow
* intermediate node overflow
* new root

==== Simple Case ====
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/btree-insert-case1.png
* add $k = 32$
* look up $k$ to identify the block where it should be stored
* we have some room there - so just add the record there

==== Leaf Overflow ====
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/btree-insert-case2.png
* add $k = 7$
* look up the block for 7, but it's fyll 
* so we ''split'' this block
** create a new one and re-distribute items between them
** this way they both become half-full (the invariant is maintained)
* then in the new block we have some space (Simple Case) and we can put this record there

==== Intermediate Node Overflow ====
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/btree-insert-case3.png
* add $k = 160$ ($n = 3$)
* there's no room in $\fbox{150, 156, 179}$ to add $160$ (Leaf Overflow case)
** so we create a new block and re-distribute the keys between them
* since we created a new block, we need to add a pointer to it, but there is no room in $\fbox{120, 150, 180}$
* so we split the intermediate block and move $180$ to the new block 
* also need to modify the root block to add pointer to the new block $\fbox{180}$

==== New Root ====
* sometimes we need to create a new root 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/btree-insert-case4.png
* add $k = 45$ ($n = 3$)
* we cannot add it to $\fbox{30, 32, 40}$ (Leaf Overflow case)
** split it to 2 nodes, need to add the pointer to the new node
* cannot add it to $\fbox{10, 20, 30}$ (Intermediate Node Overflow case)
** split it into 2 nodes, need to add the pointer to new block
* but $\fbox{10, 20, 30}$ is a root! 
** need to split it to two nodes 
** and promote $\fbox{30}$ to the root


==== I/O Cost ====
* operations
** search 
** create a new block (split, write two blocks): 2 operations
** go level up 
* so in the worst case 2 I/O at each level + possibly writing a new root (1 I/O) 
* then the total cost is 
** $\text{depth} + 2 \times \text{depth} + 1 = 3 \times \text{depth} + 1$


=== Deleting ===
Again 4 cases 
* Simple - just delete it 
* Coalesce Leaf With Siblings 
* Redistribute Keys
* Intermediate Nodes Coalescing

==== Coalesce Leaf With Siblings ====
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/btree-delete-case2.png
* we delete $k = 50$ ($n = 4$)
* we locate the block with 50 and remove this record from it
* now the block becomes too empty (recall [[#Size Invariants]])
* so we coalesce it with $\fbox{10, 20, 30}$
* now we have a new block, and the old one is not needed anymore - we remove it 
* additional bookkeeping: need to make sure the next pointer point to the record the old block pointed to

==== Redistribute Keys ====
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/btree-delete-case3.png
* we delete $k = 50$ ($n = 4$)
* when we delete 50, the block that contained it becomes almost empty
* cannot coalesce with $\fbox{10, 20, 30, 35}$ because it's full
* so to fix that we borrow a key from $\fbox{10, 20, 30, 35}$ to become half-full again
* and update the parents accordingly

==== Intermediate Nodes Coalescing ====
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/btree-delete-case4.png
* we delete $k = 37$ ($n = 4$)
* first we locate the block with 37 and remove the record from it (Coalesce Leaf With Sibling case)
** since this block $\fbox{30}$ becomes too small we coalesce it with $\fbox{25, 26}$ 
** need to remove the pointer to the deleted block from the parental node $\fbox{30, 40}$
** i.e. we remove 30 from there 
* but then the parental also node becomes too small, so we coalesce it with its sibling as well
* finally we don't need the root $\fbox{25}$ anymore since new block $\fbox{10, 20, 25, 40}$ can reference all the records

==== I/O Cost ====
Cost 
* search: depth of the tree
* remove and regroup: 2 I/Os at each level
* no need to follow the pointer (i.e. don't do +1 as with [[#Insertion]])
* total: $\text{depth} + 2 \times \text{depth} = 3 \times \text{depth}$


== Multiple Keys ==
Sometimes we want to address a key made of several keys

=== Lexicographical Order ===
For B-Trees have to be ordered somehow
* we may need to compare tuples in ''lexicographical order''
** so we define this ordering as
** $(x, y, z) \leqslant (x', y', z') \iff \\ x &lt; x' \lor (x = x' \land y &lt; y') \lor (x = x' \land y = y' \land z \leqslant z')$

=== Problem with Lexicographical Order ===
Assume index of (age, salary) pairs with lexicographical order
* btree-lex-ord.png
* query age &lt; 20 - ok
** start at the beginning of index ans scan till see 20
* query salary &lt; 30 - not fine
** linear scan, need to scan everything
* query age &lt; 20 $\land$ sal &lt; 20
** also scan index till see 20, 
** meanwhile filtering records with sal &lt; 20
* so using lexicographical ordering doesn't allow all queries we want

need other types of indexes - [[Multi-Dimensional Indexes]]
* [[R-Tree]] in particular: it's generalization of B-Trees to multidimensional data


== See also ==
* [[Indexing (databases)]]
* [[Multi-Dimensional Indexes]]
* [[R-Tree]]
* Wikipedia articles [http://en.wikipedia.org/wiki/B-tree] and [http://en.wikipedia.org/wiki/B%2B_tree] 
* http://www.scholarpedia.org/article/B-tree_and_UB-tree 


== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]
[[Category:Data Structures]]
[[Category:Database Indexes]]</text>
      <sha1>ip5pqdsd5zllvqnhk56jbtx0z0tpthw</sha1>
    </revision>
  </page>
  <page>
    <title>Hash Function</title>
    <ns>0</ns>
    <id>182</id>
    <revision>
      <id>183</id>
      <timestamp>2013-12-11T18:14:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1023">== Hash Function ==
Performance of [[Hash Tables]] depends on how good a hash functions is

In chaining implementation
* insert/delete could be anywhere from $\cfrac{m}{n}$ to $m$ for $m$ objects
* $\cfrac{m}{n}$ - equally distributed
* $m$ - all in the same bucket

That means that performance depends on the choice of hash function

=== Good Hash Function ===
So a good hash function should
* spread data out evenly
* be easy to store
* be fast to evaluate


=== Bad Hash Function ===
Example of bad function
* given: memory locations for objects
* $h(x) = x \mod 1000$
* all odd buckets will be empty!

Pathological data sets
* even a super-clever hash function does not guarantee even distribution
* for every hash function there exists a pathological data set


== Collisions ==
A ''collision'' is
* distinct $x, y \in U$
* such that $h(x) = h(y)$

Well-known issue: [[Birthday paradox]]


== See also ==
* [[Hash Tables]]

== Sources ==
* [[Algorithms Design and Analysis Part 1 (coursera)]]


[[Category:Algorithms]]</text>
      <sha1>opuok1ir8cy1cz5ef3t9fxnurwbjna5</sha1>
    </revision>
  </page>
  <page>
    <title>Open Hashing Index</title>
    <ns>0</ns>
    <id>183</id>
    <revision>
      <id>184</id>
      <timestamp>2013-12-19T20:45:48Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3661">== Open Hashing Index ==
Idea: 
* apply [[Hash Tables|Open Hashing]] to [[Secondary Storage]] to build an [[Indexing (databases)|index]]

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/hash-idea.png

Given:
* We have $n$ hashing buckets (each bucket is typically one disk block)
* a [[Hash Function]] $h$ that maps a key $k$ to a bucket: an integers $\in [0 .. n - 1]$

=== Examples ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/hash-example.png
* assume we have 2 records per bucket
* hash function: $h(a) = 1, h(b) = 2, h(c) = 1, h(d) = 0$


== Storing ==
Two options 
* store records themselves in the buckets (clustered index) 
* store only pointers to actual records (the only option for secondary index) (unclustered index)
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/hash-ways-to-store.png
* also see ([[Indexing (databases)#Clustered Index|Clustered Index]])

Do we sort records by key withing buckets
* we may if we want faster retrieval
* and inserts and deletes are not frequent (they get slower)


== Overflow Blocks ==
We allow overflow blocks
* when we want to insert something, but there's no room in the bucket
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/hash-example-overflow.png


== Operations ==
=== Lookup ===
* for a search key $k$ calculate $h(k)$ (apply hash function to the key)
* use the returned value to locate the bucket with our record
* if the record is not there we follow the overflow pointer
* once we've reached the end of chain and still haven't found anything - there is no such record


=== Insert ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/hash-example.png
* suppose we want to insert $e, h(e) = 1$
* but bucket 1 is already full 
* we create an overflow block and put it there 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/hash-example-overflow.png

Algorithm
* calculate $h(k)$ to locate bucket $B$ to use
* if $B$ is not full, just add
* if $B$ is full, and there's an overflow block, try putting it there
* otherwise create a new overflow and store this record there

'''NB:''' performance degrades as the number of overflow blocks grows! see [[#Reorganization]]


=== Deletion ===
* for search key $k$ calculate $h(k)$ to locate the bucket $B$
* find the record in bucket $B$
* if there not there - follow the overflow pointer
* if there - remove it
* if you're in an overflow block and this record was the last one - also remove the block 
* if not last one - you may want to shift elements from other overflow blocks


== Reorganization ==
Rule: we want to keep space utilization between 50% and 80%

''space utilization'' - how much space is used
* $u = \cfrac{\text{# keys used}}{\text{total # of keys}}$
* the denominator is the # of keys that we can store if we used '''only''' main buckets, without any overflow blocks 
** e.g. 2 items per block, 3 blocks = 6 keys
* if $u &lt; 50\%$ - lots of space wasted (many empty buckets)
* if $u &gt; 80\%$ - significant overflow
* if we go beyond the boundaries, we need to do rehashing 

Rehashing: creating new buckets or eliminating wasted space 
* very costly 


=== Other Hash-Based Indexes ===
To be able to better cope with growth, there are other approaches:
* Dynamic Hashing:
** [[Extensible Hashing]]
** [[Linear Hashing]]


== See also ==
* [[Indexing (databases)]]
* http://dblab.cs.toronto.edu/courses/443/2013/06.hash-index.html


== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]
[[Category:Data Structures]]
[[Category:Database Indexes]]</text>
      <sha1>j89u8iwzvhveekanww6a1q57gaorevj</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Database Indexes</title>
    <ns>14</ns>
    <id>184</id>
    <revision>
      <id>185</id>
      <timestamp>2015-06-27T08:45:00Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22">[[Category:Databases]]</text>
      <sha1>9er5ql6pu57qzhet55yxlpr10hmmb4n</sha1>
    </revision>
  </page>
  <page>
    <title>Extensible Hashing</title>
    <ns>0</ns>
    <id>185</id>
    <revision>
      <id>186</id>
      <timestamp>2013-12-17T08:13:57Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3609">== Extensible Hashing ==
Hash-based [[Secondary Storage|secondary memory]] [[Indexing (databases)|index]] structure for [[Databases|databases]]

Main ideas:
* Growing hash function
* Directory


=== Growing Hash Function ===
Variables we use:
* $b$ - length of bit-string that [[Hash Function]] outputs (typically 64)
* $i$ - number of bits we can use
** as number of keys grows, we increase $i$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/ex-hashing-hash-function.png


=== Directory ===
''Directory'' introduces additional level of indirection 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/ex-hashing-directory.png
* here we keep all possible combinations of $i$ bits with pointers to associated buckets

Example 
* suppose for key $k$: $h(k) = \fbox{1010}$
* we take first $i$ bits of this value, i.e. $h(k)[0..i] = 1$
* so we find record with 1 in the directory and this way we locate the needed bucket


https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/ex-hashing-example-i1.png


== Operations ==
=== Lookup ===
* we take first $i$ bits of hash and find a corresponding record in the directory
* then we follow the pointer and find the whole key (all $b$ bits) there


=== Insert === 
==== Simple Case ====
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/ex-hashing-add-1.png
* suppose $i = 1$
* for key $k:$ $h(k) = 0010$ and first $i$ bits are 0: look it up in the directory
* follow the pointer
* there is enough room so add in there 

==== Creating New Directory ====
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/ex-hashing-add-2.png
* suppose $i = 1$
* given hash $h(k) = 1010$ we extract first 1 bit which is 1
* we look 1 up in the directory and follow the pointer 
* but there's no room in this block 
** so we split it into 2 parts 
** keep ones that start with 10 in one 
** and move ones that start with 11 to another
** that means that both blocks use 2 bits to assign a key to a bucket (and we indicate that value on top of the buckets)
* but to address these new buckets now we need 2 bits, and still $i = 1$
** i.e. $i$ in the directory becomes less than at least one $i$ from buckets
** that means we need to '''create a new directory'''
** if it wasn't the case, we just would re-wire pointers to the dict
* note that bucket for (0) is still the same - so both 00 and 01 in the new directory point to this bucket 
* if now we insert 0000 and 0100, we will reorganize the first bucket, but will not rebuild the directory


So the rule is: 
* if $i$ for one of the bucket grows more than $i$ of the directory
* we need to rebuild the prefix directory 
* all other blocks are kept untouched (otherwise we would have to re-organize the whole thing)


=== Deletion ===
Just the opposite of [[#Insertion]]


== Summary ==
Pros
* can handle growing files with less wasted space than [[Open Hashing Index]]

Cons
* another level of indirection. Not that bad if we can store the entire directory in memory, but it's not often the case
* size of directory growth is exponential to $i$ - quickly becomes the bottleneck and may introduce a lot of latency 
** it fits into memory and then all of a sudden it doesn't 

[[Linear Hashing]] is another alternative that can handle growing files better


== See also ==
* [[Open Hashing Index]]
* [[Linear Hashing]]
* [http://dblab.cs.toronto.edu/courses/443/2013/06.hash-index.html Hash Indexes]

== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]
[[Category:Database Indexes]]</text>
      <sha1>n88b0qfxxqgx8xci2ezfvr1911z3dy0</sha1>
    </revision>
  </page>
  <page>
    <title>Linear Hashing</title>
    <ns>0</ns>
    <id>186</id>
    <revision>
      <id>187</id>
      <timestamp>2013-12-17T16:53:51Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4587">== Linear Hashing ==
* another dynamic hashing schema
* but without a directory that doubles in size as in [[Extensible Hashing]]

=== Variables we use ===
* $b$ - length of bit-string that [[Hash Function]] outputs (typically 64)
* $i$ - number of bits we can use
** as number of keys grows, we increase $i$
** but in contrast to [[Extensible Hashing]], we use $i$ ''least'' significant bits if key 
** for example, $\overbrace{0 1 1 1 0 \underbrace{1 0 1 1}_{i}}^{b}$ with $i$ = 4 and $b$ = 9
* $n$ - number of buckets we use now, $n \leqslant 2^i$
** $2^i$ - max number of items we can address with current $i$ 
** $n$ grows linearly 


== Lookup Rule ==
* if $\underbrace{h(k)[i..b]}_{\text{$i$ least significant bits}} \leqslant n$
* then look at bucket $h(k)[i..b]$
* otherwise look at the bucket $h(k)[i..b] - 2^{i - 1}$ (i.e. just flip the most significant bit of the hash)
* this rule is used for inserting and looking up

'''Example'''
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/lin-hashing-ex1.png
* $b$ = 4 bits 
* $i = 2$, can address $2^i = 4$ buckets
* $n = 01_2 = 2_{10}$ i.e. we use only two buckets at the moment
** the remaining 2 buckets are reserved for future growth 
* note that in the first bucket there are 2 values: 0000 (2 last bits are $00$) and 1010 (with $10$)
** they are different but ended up in the same bucket
** since $10_2 \leqslant n = 01_2$ we flip the first significant bit of $10$ and get $00$
* also we allow overflow blocks for this data structure 


== Increasing Parameters ==
=== Increasing $n$ ===
* when we increase $n$ we start using a new block
* and we need to re-organize data so the [[#Lookup Rule]] invariant is maintained
** if there's an overflow block, we will reduce it

Reorganization
* for that we see the block with current $n$ but most significant bit flipped
** i.e. for $10$ it's $00$ 
* then we go through all records there and move those that should belong to new block $10$
* after doing that the Lookup Rule invariant will be maintained

=== Increasing $i$ ===
If we increase $i$
* now number of buckets we can address becomes two times higher
* nothing will move: we don't touch $n$ 
* but $i$ gets increased only when $n$ increases, but doesn't fit to current $i$

=== When ===
When it's better to increment $n$?
* Similar to ideas from [[Open Hashing Index#Reorganization|Open Hashing Index]]
* $u = \cfrac{\text{# records}}{\text{# buckets}}$ where $u$ is ''space utilization''
* and we set some threshold - once we exceed it, we increment $n$
* $i$ is incremented when $n$ becomes high enough so it no longer fits in $i$ bites

=== Algorithm ===
When increasing $n$ 
* $n \leftarrow n + 1$
* if $n &gt; i$, then $i \leftarrow i + 1$
* let $k$ be equal to $n$ with first significant bit flipped
* look for all keys that end with $n$ in the bucket #$k$
* and move them to the new bucket 
* remove overflow blocks when needed 


=== Example ===
$b = 4$

Growing $n$
* suppose we have 2 blocks not in use, $n = 01$, $i = 2$
* we increase $n$: $n \leftarrow 10$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/lin-hashing-reorg1.png
* we transfer one record from 00 to 10 (which now becomes in use)

Removing overflow blocks
* suppose now we increase $n$ again: $n \leftarrow 11$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/lin-hashing-reorg2.png
* we transfer records from 01 to 11
** we move record 1111 to the new block
** since now there's some free room, we move records from the overflow block
** after moving them the overflow block becomes empty - so we may remove it altogether

note that in all cases we need to reorganize at most one bucket

Increasing $i$
* nothing moves as long as we don't touch $n$
* just append zeros before old bucket numbers + add new ones
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/lin-hashing-reorg3.png
* now can increase $n$ again


== Summary ==
* Can handle growing files (+)
* No additional level of indirection like in [[Extensible Hashing]] (+)
* Can still have overflow chains (-)


Very Bad Case
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/lin-hashing-bad-case.png
* suppose for block $011$ we have huge overflow chain
* to reconstruct this chain, $n$ has to reach $111$ (twice more!)
* lots of time! especially when $i$ becomes longer


== See also ==
* [[Open Hashing Index]]
* [[Extensible Hashing]]

== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]
[[Category:Database Indexes]]</text>
      <sha1>ioa5szuhek700f0kg73ziwz3y3ed41m</sha1>
    </revision>
  </page>
  <page>
    <title>SVM</title>
    <ns>0</ns>
    <id>187</id>
    <redirect title="Support Vector Machines" />
    <revision>
      <id>188</id>
      <timestamp>2013-12-17T20:15:39Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="37">#REDIRECT [[Support Vector Machines]]</text>
      <sha1>8hr5g239fkqs6qr8oxq2moe4v37u73e</sha1>
    </revision>
  </page>
  <page>
    <title>Multi-Dimensional Indexes</title>
    <ns>0</ns>
    <id>188</id>
    <revision>
      <id>189</id>
      <timestamp>2013-12-18T20:58:48Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1979">== Multi-Dimensional Indexes ==
=== Typical Applications ===
* Searching [[OLAP|Data Cube]] for [[Data Warehousing]]
* [[Spatial Databases]]


== Typical Queries ==
=== Point Query ===
Find all values for the (multi-dimensional) search key
* for product &quot;TV&quot; sold in Ireland with ALL for date
* does there exist a star on coordinate (10, 3, 5)

=== Partial Match Queries ===
Not all values of a search key are specified
* return the coordinates pf all stars with $x=5$ and $z=3$

=== Range Queries (Dicing) ===
* return all cube cells with date $\geqslant Q_1$ and date $\leqslant Q_2$ and sales $\leqslant 100$
* return coordinates of all stars with $x \geqslant 10$ and $20 \leqslant y \leqslant 35$

=== Nearest-Neighbor Queries ===
* return closest 3 stars to a star at (10, 15, 20) 

== Can Use One-Dimensional Indexes? ==
[[Indexing (databases)#One-Dimensional Indexes|One-Dimensional Indexes]] (such as [[B-Tree]])
* take one single key
* can use one key made of multiple attributes 

=== [[B-Tree]] ===
Need to impose [[B-Tree#Lexicographical Order|lexicographical order]] on keys in B-Tree to do that
* don't answer all our queries - see [[B-Tree#Multiple Keys]]

=== Hash Tables ===
For [[Indexing (databases)#Hash-Based Indexes|Hash-Based Indexes]] we need to compute [[Hash Function]] for tuples
* extend hash function: $h(x, y, z) = h_1(x) + h_2(y) + h_3(z)$

Problem 
* cannot answer range queries at all 
* age &lt; 20
* sal &lt; 30
* age &lt; 20 and sal &lt; 20
* all lead to linear scan


== Types ==
=== Other Types ===
* [[Multiple-Key Index]]

=== Hash-Based Multi-Dimensional Indexes ===
* [[Grid File Index]]
* [[Partitioned Hash Function Index]]

=== Tree-Based Multi-Dimensional Indexes ===
* [[kd-Trees]]
* [[Quad Trees]]
* [[R-Tree]]

== Sources ==
* [[Database Systems Architecture (ULB)]]
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom


[[Category:Database Systems Architecture]]
[[Category:Database Indexes]]</text>
      <sha1>hz8z6ypkdh3674k3fe8ysvqimrrahxo</sha1>
    </revision>
  </page>
  <page>
    <title>Multiple-Key Index</title>
    <ns>0</ns>
    <id>189</id>
    <revision>
      <id>190</id>
      <timestamp>2013-12-18T20:39:03Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1130">== Multiple-Key Index ==
This is a very simple conventional [[Multi-Dimensional Indexes|Multi-Dimensional]] [[Indexing (databases)|Index Structure]]


=== Idea ===
The main idea is a nested index:
* the index on indexes
* index could be anything: [[B-Tree]] or Hash-Based one-dimensional index

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/mult-key-ind-ex1.png
* in this case we have a tree 
* nodes at each level of this tree are also indexes 
* so for this example we have an index on the first attribute that points to an index on 2nd attribute


=== Example ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/mult-key-ind-ex2.png


== Types of Queries ==
* partial match queries 
** easy if first attribute is specified
** otherwise must look through every subindex
* range queries 
** easy - provided individual indexes support range queries 


== Sources ==
* [[Database Systems Architecture (ULB)]]
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom


[[Category:Database Systems Architecture]]
[[Category:Database Indexes]]</text>
      <sha1>re6cczugfiwf5kb1p86iu9xyp9wxq5y</sha1>
    </revision>
  </page>
  <page>
    <title>Grid File Index</title>
    <ns>0</ns>
    <id>190</id>
    <revision>
      <id>191</id>
      <timestamp>2013-12-18T20:42:58Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2575">== Grid File Index ==
This is [[Hash Function|Hash-Based]] [[Multi-Dimensional Indexes|Multi-Dimensional]] [[Indexing (databases)|Index Structure]] 

== Main Idea ==
In each dimension, using ''Grid Lines'', we divide our key space into ''stripes''
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/grid-files-ex1.png
* lines divide the space into subspaces that are large enough to store ''one block''
* if needed, overflow blocks may be used 

=== Representation ===
Each stripe points to some block on [[Secondary Storage|disk]]
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/grid-files-repr.png
* note that we have two empty buckets there, and don't have any pointers to actual blocks
* may allow for overflow blocks


== Operations ==
=== Lookup ===
* need to know values for each grid line 
* so it's different from just applying a Hash Function
* we look at each component of the tuple and determine the position in the grid
* may add single-dimension index (such as [[B-Tree]]) for coordinates of each line to speed up finding the proper coordinate

=== Insert ===
* Locate the needed bucket 
* if there is room - insert
* no room - two options
** Overflow blocks
** Split by creating new grid lines (hard)

Splitting
* causes additional problems:
* content of blocks is linked across dimensions
* so adding a grid line will split all the buckets along this line
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/grid-files-split.png
* for $n$ dimensions we may choose which dimension to split
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/grid-files-split-ndim.png

=== Delete ===
* Find the corresponding bucket
* delete the record
* reorganize if needed 


== Summary ==
Recall [[Multi-Dimensional Indexes#Typical Queries|the typical of queries]] we want to answer for [[Multi-Dimensional Indexes]]
* (+) good support for 
** point queries
** partial match queries (we know where to look to needed data)
** range queries
* (+) reasonable support for 
** nearest neighbor queries (first look withing the bucket, then neighbor buckets and so on)
* (-) downsides 
** many empty buckets when data is not uniformly distributed
** need to have a good algorithm that splits the space 


== See also ==
* [[Partitioned Hash Function Index]]

== Sources ==
* [[Database Systems Architecture (ULB)]]
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom


[[Category:Database Indexes]]
[[Category:Database Systems Architecture]]</text>
      <sha1>si04yn8f60sxyguczw4bxuotmkax03i</sha1>
    </revision>
  </page>
  <page>
    <title>Partitioned Hash Function Index</title>
    <ns>0</ns>
    <id>191</id>
    <revision>
      <id>192</id>
      <timestamp>2013-12-18T20:48:24Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1965">== Partitioned Hash Function Index ==
This is [[Hash Function|Hash-Based]] [[Multi-Dimensional Indexes|Multi-Dimensional]] [[Indexing (databases)|Index Structure]] 

=== Typical Approach ===
Suppose we use classical approach for hashing a tuple $(a, b)$
* $h(a, b) = h_1(a) + h_2(b)$
* in this case we need to provide both $a$ and $b$ 
* but what if we want to [[Multi-Dimensional Indexes#Typical Queries|query only for $a$]]?
* this will not work

=== Partitioned Hash Function ===
To tackle this problem, we define a hash function $h$ in a different way
* $h(v_1, ..., v_n) = h_1(v_1) || ... || h_n(v_n)$
** where $||$ means concatenation
** so it's a list of functions $h_i$
* $h$ produces $k$-bit output
** each function $h_i$ produces $k_i$ bits and $\sum k_i = k$

Example
* assume we have 1024 buckets, to address each one we need at least 10 bits
* i.e. $k = 10$ and $2^k = 1024$
* suppose we decide (say, based on density, etc) that 
** $f(x)$ reserves 2 bits, 
** $g(y)$ gets 5 bits and
** $h(z)$ - last 3 bits
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/part-hash-ex1.png

By partition a hash function this way we can query only for some attributes 
* suppose we want to query for $x = 10$ and $y = 20$
* calculate hash for there two values
* then we enumerate all possible values for $h(z)$ - and go through them
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/part-hash-ex-enum.png


== Queries ==
Good support:
* point queries
* partial match queries 

No Support for:
* range queries 
* nearest-neighbor queries (physical distance is not reflected in the way we build $h$)

And
* less space wasted than in [[Grid File Index]]


== See also ==
* [[Grid File Index]]

== Sources ==
* [[Database Systems Architecture (ULB)]]
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom


[[Category:Database Systems Architecture]]
[[Category:Database Indexes]]</text>
      <sha1>q0be7f4bjsvo5bow5cl5jzkif2lmh20</sha1>
    </revision>
  </page>
  <page>
    <title>Kd-Trees</title>
    <ns>0</ns>
    <id>192</id>
    <revision>
      <id>193</id>
      <timestamp>2013-12-18T20:56:40Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2142">== $kd$-Trees ==
* it's a generalization of [[Binary Search Trees|binary search trees]] to multidimensional data
* Main Memory structure (not [[Secondary Storage]]!)


== Classical $kd$-Tree ==
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/kd-tree-ex.png
* ''split attributes'' at different levels are different
** in the example: first split by $Y$, then by $X$, then by $Y$...
* interior nodes of the tree contain
** attribute on which we divided the space
** a dividing value
** left and right pointers (only 2!)
* leaves are blocks with records


== Operations ==
=== Lookup ===
* similar to [[Binary Search Trees|binary search trees]]
* but need to use only attribute specified in a interior node of the tree

=== Insertion ===
* look up the block 
* if there's room - put it there
* not - split into 2
** we divide by the most appropriate attribute
* and create a new interior node that points to the split halves


== Queries ==
Good for See [[Multi-Dimensional Indexes#Typical Queries]]
* Point Queries (just lookup)
* Partial Match
** suppose we specified only $Y$
** then if it's not $Y$ follow both left and right pointers 
** if it's $Y$ then use the dividing value in the node to decide whether to go left or right

Reasonable Support
* Nearest-Neighbor 


== Adaptation to [[Secondary Storage]] ==
The described algorithm is for Main Memory, not for disk

2 ways to adapt
* Multi-Way Branches
** like in [[B-Tree]]: $n$ keys, $n + 1$ pointers
** hard to merge to keep it balanced
* Several Nodes Per Block
** Keep 2 children per block as described
** but store several nodes per one block 
** to minimize I/O it's better to put in the same block records that are likely to be accessed together 
** For example, a node and it's descendants


== See also ==
* [[Binary Search Trees]]
* [[Quad Trees]]
* [[R-Tree]]
* [[Multi-Dimensional Indexes]]

== Sources ==
* [[Database Systems Architecture (ULB)]]
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom

[[Category:Data Structures]]
[[Category:Database Indexes]]
[[Category:Database Systems Architecture]]</text>
      <sha1>n7q4gaxh5wi9ko7zp3b186yzs0uuvau</sha1>
    </revision>
  </page>
  <page>
    <title>Quad Trees</title>
    <ns>0</ns>
    <id>193</id>
    <revision>
      <id>194</id>
      <timestamp>2013-12-18T20:56:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1112">== Quad Trees ==
This is [[Binary Search Trees|Tree-Based]] [[Multi-Dimensional Indexes|Multi-Dimensional]] [[Indexing (databases)|Index Structure]] 

Idea:
* for $k$-dimensional space 
* each node corresponds to a $k$-dimensional cube
* for 2D it's a square region


=== Building ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/quad-tree-1.png

Algorithm
* if a number of points in a cube is larger that can fit in a block
* then we create an interior node 
* and divide the cube recursively (i.e. we create 4 children for each quadrant)
* otherwise we create a leaf block

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/quad-tree-repr.png


== Operations ==
Lookups, Insertions and Deletions are very similar to [[kd-Trees]]


== See also ==
* [[Binary Search Trees]]
* [[kd-Trees]]
* [[R-Tree]]
* [[Multi-Dimensional Indexes]]

== Sources ==
* [[Database Systems Architecture (ULB)]]
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom


[[Category:Database Indexes]]
[[Category:Database Systems Architecture]]</text>
      <sha1>bm2blvmh17tg18t3sni8spetq3c1ujz</sha1>
    </revision>
  </page>
  <page>
    <title>R-Tree</title>
    <ns>0</ns>
    <id>194</id>
    <revision>
      <id>195</id>
      <timestamp>2013-12-18T20:57:16Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3108">== R-Tree ==
This is [[Binary Search Trees|Tree-Based]] [[Multi-Dimensional Indexes|Multi-Dimensional]] [[Indexing (databases)|Index Structure]] 
* Generalization of a [[B-Tree]] to multidimensional space
* Indexes ''regions'' 


=== B-Tree ===
In a B-Tree we can view a node as a line (1-dimensional space)
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/rtree-1dim-btree.png
* and it divides a line into ''segments''

=== R-Tree ===
Same, but for 2D and more
* we divide data into data ''regions''
* interior nodes of an R-Tree correspond to interior region
** not data region as in B-Tree, but just a region
* A region can be of any shape, but usually it's a rectangle or other simple shape
* A node has subregions - its children
** subregions are allowed to overlap
** but it's usually better to keep the overlap small


== Example ==
Suppose we have a region
* it fits in one block
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/rtree-ex1.png
* but we insert an new object - and it no longer fits
** need to split the block into two regions
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/rtree-ex2.png
** note that (a) the blocks overlap and (b) how we represent these blocks in out database
* when we insert next time, a new object can be added to an existent block
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/rtree-ex3.png
** note that we have to adjust regions boundaries to include the new object


== Operations ==
=== Lookup ===
specify a point $P$ and ask what regions $P$ lies in (''where-am-I'' query)
* start with the root
* find which children correspond to interior regions that contain $P$
* if there are no such regions - we're done ($P$ doesn't belong to any region)
* if there are more than 1 region - apply recursively to each
* when we reach the leaf regions - we find the actual data regions

=== Insert ===
* start at root and try to find a region where $R$ fits
* if found: go inside and repeat
* if not: need to expand an existing region
** we want to expand as little as possible
** so we find the one that gives the smallest expansion
* when we reach a leaf, we insert $R$
* if there's no room - we split it
** remember that we want regions to be as small as possible
** so we find the split that gives us that
** after that we insert the new subregion to the leaf's parent
** essentially the same procedure as for [[B-Tree]]


== Summary ==
Good for:
* Where-am-I (point) queries
* Finding intersecting regions (e.g. when a user selects an area on map)
* Partial Range queries
* Range queries 
* nearest neighbor

Also
* Always balanced
* often used in practice


== See also ==
* [[B-Tree]] and [[Binary Search Trees]]
* [[Multi-Dimensional Indexes]]
* [[kd-Trees]] and [[Quad Trees]]
* [[Spatial Databases]]

== Sources ==
* [[Database Systems Architecture (ULB)]]
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom

[[Category:Database Systems Architecture]]
[[Category:Data Structures]]
[[Category:Database Indexes]]</text>
      <sha1>rim3ii3y309vtpwgbjnfdysgb7pdxt6</sha1>
    </revision>
  </page>
  <page>
    <title>File:Tick.png</title>
    <ns>6</ns>
    <id>195</id>
    <revision>
      <id>196</id>
      <timestamp>2013-12-19T20:57:58Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="0" />
      <sha1>phoiac9h4m842xq45sp7s6u21eteeq1</sha1>
    </revision>
  </page>
  <page>
    <title>File:Cross-1.png</title>
    <ns>6</ns>
    <id>196</id>
    <revision>
      <id>197</id>
      <timestamp>2013-12-19T21:01:04Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="0" />
      <sha1>phoiac9h4m842xq45sp7s6u21eteeq1</sha1>
    </revision>
  </page>
  <page>
    <title>Template:Yes</title>
    <ns>10</ns>
    <id>197</id>
    <revision>
      <id>198</id>
      <timestamp>2013-12-19T21:15:47Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3">✔</text>
      <sha1>6vxex4vr905iiqqrc26y2xewo9r9hz9</sha1>
    </revision>
  </page>
  <page>
    <title>Template:No</title>
    <ns>10</ns>
    <id>198</id>
    <revision>
      <id>199</id>
      <timestamp>2013-12-19T21:16:35Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3">✘</text>
      <sha1>anv29hjjrrnve1hsx19yco1vm51xfqd</sha1>
    </revision>
  </page>
  <page>
    <title>External Merge Sort</title>
    <ns>0</ns>
    <id>199</id>
    <revision>
      <id>200</id>
      <timestamp>2013-12-19T22:06:07Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2489">== External Merge Sort ==
Full name: ''External Memory Multi-Way Merge Sort''
* same idea as in in-memory [[Merge Sort]], but extended to [[Secondary Storage]]


== Algorithm ==
This is a multi-way algorithms. That is, the sorting of relation $R$ is done in several passes
* First Pass - in memory sorting 
* Second and onwards - merging

Notation:
* $R$ relation we want to sort
* $M$ - max # of blocks we can use in memory

=== First Pass ===
1-st pass:
* read $M$ blocks
* sort all elements in memory with any sorting algorithm (say, [[Merge Sort]] or [[Quick Sort]])
* write sorted results back to disk 
* repeat for remaining blocks of $R$ until all are processed

After the first pass we have $\left\lceil \cfrac{B(R)}{M} \right\rceil $ sorted sub-results


=== Second Pass ===
* Since we have $M$ available buffers, we can simultaneously process at most $M$ sorted sub-results from the previous pass 
* So we divide all sub-results into categories with $M$ sub-results in each 
* Since we have $M$ sub-results and $M$ blocks in each, each result of this pass should have $M \times M$ blocks
* After this pass we will have $\left \lceil \cfrac{B(R) / M}{M} \right\rceil  = \left \lceil \cfrac{B(R)}{M^2} \right\rceil$ sorted subresults 


2-nd pass:
* merge the first $M$ sublists to a single sublist of $M^2$ blocks
* by synchronous iteration 


=== Synchronous Iteration ===
This is essentially the merging phase of [[Merge Sort]]

Algorithm:
* load block of $R$ to $N_R$, block of $S$ to $N_S$
* iterate over tuples $t_R \in N_R$ and $t_S \in N_S$ ''synchronously''
** if $t_R \geqslant t_S$
*** output $t_R$ 
*** move $t_R$ pointer to the next tuple in $R$ (load next block if needed)
** if $t_R &gt; t_S$
*** output $t_S$ 
*** move $t_S$ pointer to the next tuple in $S$ (load next block if needed)


=== Third and Onwards Passes ===
* if needed - repeat the second pass again 
* until everything is sorted 


== Cost ==
* at each pass we read and write the entire relation once
* there are $P = \lceil \log_M B(R) \rceil$ passes
* so the total cost is $\underbrace{2 \times B(R)}_\text{1 read + 1 write} \times P =  2 \times B(R) \times \lceil \log_M B(R) \rceil$


== See also ==
* [[Merge Sort]]
* [[Physical Operators (databases)]]

== Sources ==
* [[Database Systems Architecture (ULB)]]
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom

[[Category:Database Systems Architecture]]
[[Category:Algorithms]]
[[Category:Sorting]]</text>
      <sha1>633i4md8v0k8thcyoyj0qse9qx1pp33</sha1>
    </revision>
  </page>
  <page>
    <title>Physical Operators (databases)</title>
    <ns>0</ns>
    <id>200</id>
    <revision>
      <id>201</id>
      <timestamp>2013-12-20T08:54:13Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16703">== Intro ==
Each node in a Logical [[Query Plan]] may be executed in several ways 
* there is no single implementation that is always better than the others 
* so we need to compare alternatives based on their costs (in [[I/O Model of Computation]] it's # of I/O operations)

=== Statistics ===
To estimate a cost we use the following statistics from [[Database System Catalog]]:
* $B(R)$ - # of blocks that relation $R$ holds
* $T(R)$ - # of tuples in $R$
** typically can be used to calculate $B(R)$ when we know how many bytes we have per block
* $V(R, A_1, ..., A_n) = | \delta \pi_{A_1, ..., A_n} (R)  |$ - # of distinct values 

=== Parameters ===
And also we use 
* $M$ - number of available main memory buffers 

To simplify we suppose that the situation is ideal
* all buffers of [[Database#Buffer Manager|Buffer Manager]] are available 
* there are no other operations that concurrently claim the space


== Operators Overview ==

{| cellpadding=&quot;20&quot; cellspacing=&quot;0&quot;
! Type $\downarrow$
! [[#Bag Union|Bag Union]]
! [[#Set Union|Set Union]]
! [[#Set Intersection|Set Intersection]]
! [[#Bag Intersection|Bag Intersection]]
! [[#Set Difference|Set Difference]] 
! [[#Bag Difference|Bag Difference]]
! [[#Join|Join]]
|-
! One-Pass
| [[#Bag Union|{{yes}}]]
| [[#One-Pass Set Union|{{yes}}]]
| [[#One-Pass Set Intersection|{{yes}}]]
| [[#One-Pass Bag Intersection|{{yes}}]]
| [[#One-Pass Set Difference|{{yes}}]]
| [[#One-Pass Bag Difference|{{yes}}]]
| [[#One-Pass Join|{{yes}}]]
|-
! Sort-Based 
| {{no}}
| [[#Sort-Based Set Union|{{yes}}]]
| [[#Sort-Based Set Intersection|{{yes}}]]
| [[#Sort-Based Bag Intersection|{{yes}}]]
| [[#Sort-Based Set Difference|{{yes}}]]
| [[#Sort-Based Bag Difference|{{yes}}]]
| [[#Sort-Based Join|{{yes}}]]
|-
! Hash-Based
| {{no}}
| [[#Hash-Based Set Union|{{yes}}]]
| not here
| not here
| not here
| not here
| [[#(Partition) Hash Join|{{yes}}]]
|}

Also:
* For Joins: [[#Nested Loop Join]]


== Bag Union ==
$R \cup_B S$
* all elements from both
* no need to remove duplicates
* for this operation just need to use one buffer block 
* load elements to the block and then just output 

'''Algorithm'''
* for each block $B_R \in R$
** load $B_R$ to buffer $N$
** for each tuple $t_R \in N$
*** output $t_R$
* for each block $B_S \in S$
** load $B_S$ to buffer $N$
** for each tuple $t_S \in N$
*** output $t_S$

'''Cost'''
* $B(R) + B(S)$
* we don't count output 
* and we must have some available buffers: $M \geqslant 1$


== Set Union ==
$R \cup_B S$
* this time we care about duplicates
* assume that $R$ is smaller than $S$

=== One-Pass Set Union ===
$R$ fits into memory:
* We assume that we have $B(R) + 1$ available buffers 
* i.e. $R$ can fit into memory and after that there's at least one remaining available buffer

Idea:
* load all elements of $R$ 
* using 1 extra buffer go through all blocks of $S$
* output element if only it's not in $R$

'''Algorithm'''
* load $R$ to $N_1, ..., N_{B(R)}$ buffers
* for each tuple $t_R \in \cup_i N_i$
** output $t_R$
* for each block $B_S \in S$
** load $B_S$ to $N_0$
** for each tuple $t_S \in N_0$
*** if $t_S \not \in \cup_i N_i$, output $t_S$

'''Cost'''
* $B(R) + B(S)$
* pass once through $R$ and once through $S$
* we ignore the cost of searching in memory - interested only in I/O cost

Problem: 
* We can do it only when one of the relations fin into memory 
* usually they don't fit!


=== Sort-Based Set Union ===
what if there's no enough memory available? 

Algorithm:
* Sort $R$ with [[External Merge Sort]]
* Sort $S$ with [[External Merge Sort]]
* Iterate Synchronously over $R$ and $S$
** like in [[External Merge Sort]], but don't output repeating values
** i.e.: increase both pointers when see a duplicate 

Synchronous Iteration:
* load block of $R$ to $N_R$, block of $S$ to $N_S$
* iterate over tuples $t_R \in N_R$ and $t_S \in N_S$ ''synchronously''
** if $t_R &lt; t_S$
*** output $t_R$ 
*** move $t_R$ pointer to the next tuple in $R$ (load next block if needed)
** if $t_R &gt; t_S$
*** output $t_S$ 
*** move $t_S$ pointer to the next tuple in $S$ (load next block if needed)
** if $t_R = t_S$
*** output $t_S$ 
*** move '''both''' $t_R$ and $t_S$

Cost:
* $2 B(R) \lceil \log_M B(R) \rceil$: cost of sorting $R$
* $2 B(S) \lceil \log_M B(S) \rceil$: cost of sorting $S$
* $B(R) + B(S)$ to iterate synchronously to output the results


==== Optimization ====
* Synchronous Iteration of Sort-Based Union is very similar to the merge phase of [[External Merge Sort]]
* Sometimes we can combine them - and avoid doing the last pass of Merge Sort!

Algorithm:
* Sort $R$, but don't execute the last merge phase
** we know that after that $R$ is divided into $l$ sorted lists
** $1 &lt; l \leqslant M$
* Sort $S$, but don't execute the last merge phase
** we know that after that $S$ is divided into $k$ sorted lists
** $1 &lt; k \leqslant M$
* if $l + k \leqslant M$ then we can apply the optimization
** because there are enough buffers available to synchronously iterate through both set of sub-results


Cost:
* $2 B(R) \big( \lceil \log_M B(R) \rceil - 1 \big)$: cost of sorting $R$ without last pass
* $2 B(S) \big( \lceil \log_M B(S) \rceil - 1 \big)$: cost of sorting $S$ without last pass
* $B(R) + B(S)$ to iterate synchronously to output the results
* or $2 B(R) \lceil \log_M B(R) \rceil + 2 B(S) \lceil \log_M B(S) \rceil - B(R) - B(S)$
* we save $B(R) + B(S)$ I/Os!


Note that
* this optimization is only possible if $k + l \leqslant M$
* can calculate $k$ and $l$ as
** $l = \left\lceil \cfrac{B(R)}{ M^{\lceil \log_M B(R) \rceil - 1} } \right\rceil $ - # of passes to sort $R$ - 1
** $k = \left\lceil \cfrac{B(S)}{M^{\lceil \log_M B(S) \rceil - 1}} \right\rceil$ - # of passes to sort $S$ - 1

it's usually sufficient to have only 2 passes for sorting
* in this case can apply optimization if 
* $\left\lceil \cfrac{B(R)}{M} \right\rceil  + \left\lceil \cfrac{B(S)}{M} \right\rceil \leqslant M$ or
* $B(R) + B(S) \leqslant M^2$
* cost in this case is $3B(R) + 3B(S)$ with optimization 
* $5B(R) + 5B(S)$ without optimization


==== Example ====
Suppose $M = 15, B(R) = 100, B(S) = 120$
* to sort $R$ need $\lceil \log_M B(R) \rceil = 2$ passes
* to sort $S$ need $\lceil \log_M B(S) \rceil = 2$ passes
* $l = \left\lceil \cfrac{100}{15^2} \right\rceil$
* $k = \left\lceil \cfrac{120}{15^2} \right\rceil$
* $l + k = 15 \leqslant M$, therefore we can apply optimization
* cost is $2 \cdot 100 \cdot 2 + 2 \cdot 120 \cdot 2 - 100 - 120 = 660$


=== Hash-Based Set Union ===
Main idea: we want to partition both $R$ and $S$ in such a way that
* if a tuple appears in some bucket from $R$ it should appear in the corresponding bucket from $S$
* each bucket contains no more that $M - 1$ blocks 
* so it is possible to apply [[#One-Pass Set Union|One-Pass Set Union]] to each bucket

==== Record distribution ====
* $B(R) &lt; B(S)$ - $R$ is smaller than $S$
* we suppose that we can partition $R$ in $k$ buckets $R_i$
** to do that we apply some hash function $h$
* and then distribute tuples from $S$ also into $k$ buckets $S_i$
** also by applying $h$ 
* all records in $R_i$ and $S_i$ ended up in the bucket $i$ because they have the same hash value
** if there's a record that occurs both in $R_i$ and $S_i$, it's a duplicate 
** and we need to consider only these buckets, this record cannot appear in buckets other than $i$


==== Computing Set Union ====
* to compute set union we compute unions for all buckets $i$: $R_i \cup_S S_i$ 
* since $R_i$ contains at most $M - 1$ block can do that in one pass


==== Partitioning $R$ ====
How to partition $R$ in blocks of size at most $M - 1$?

Algo
* first pass
** we load each block of $R$ into buffer $N_0$
** and we have $M - 1$ remaining buffers - we will use them as buckets
** for each tuple $t_R \in R$ we calculate $h(t_R)$ to find which bucket it belongs to
** once a bucket buffer is full, we flush it to disk to some block, empty the buffer and continue 
** $\Rightarrow$ after first pass we'll have $M - 1$ buckets of $\cfrac{B(R)}{M - 1}$ blocks (assuming $h$ distributes records uniformly)
* 2+ passes 
** if there are buckets that have more that $M - 1$ blocks we need to hash them again
** but this time with another hash function $h'$ (otherwise the old $h$ will just put all the tuples back to the same bucket)
** so we repeat the first pass again, but for each overfull bucket separately
** $\Rightarrow$ after second pass we'll have $(M - 1)^2$ buckets of $\cfrac{B(R)}{(M - 1)^2}$ blocks
* continue this process until all buckets have no more than $M - 1$ blocks 
** $\Rightarrow$ after $k$ passes we'll have $(M - 1)^k$ buckets of $\cfrac{B(R)}{(M - 1)^k}$ blocks


One level of partitioning is usually enough
* so we need two passes
* 1st: to partition
* 2nd: to do pair-wise single pass unions of buckets
* it's sufficient when $\cfrac{B(R)}{M - 1} \leqslant M - 1$ or $\approx B(R) \leqslant M^2$

Cost of partitioning
* $2B(R) \underbrace{\lceil log_{M - 1} B(R) - 1 \rceil}_\text{# of passes}$:
* at each pass we read and write $R$ once
* so for one pass it's just $2B(R)$ 


==== Cost ====
Total cost of partitioning
* $2B(R) \lceil \log_{M - 1} B(R) - 1 \rceil$ for $R$
* $2B(S) \lceil \log_{M - 1} B({ \color{blue}{R} }) - 1 \rceil$ for $S$
** note that number of passes for $S$ is the same as of $R$
* $B(R) + B(S)$ one pass union for each bucket
* if one pass is sufficient, then the total cost is $3B(R) + 3B(R)$


== Set Intersection ==
$R \cap_S S$
* assume $R$ is smaller than $S$

=== One-Pass Set Intersection ===
Essentially same as [[#One-Pass Set Union ]] 
* if $R$ is small enough to fit into $M - 1$ buffers 

Algorithm 
* load $R$ to $K_R = N_1, ..., N_{B(R)}$ buffers
* for each block $B_S \in S$
** load $B_S$ to $N_0$
** for each tuple $t_S \in N_0$
*** if $t_S \in K_R$, output $t_S$

=== Sort-Based Set Intersection ===
* same as [[#Sort-Based Set Union]]
* output $t$ if it appears in both $R$ and $S$


== Bag Intersection ==
$R \cap_B S$
* assume $R$ is smaller than $S$

=== One-Pass Bag Intersection ===
Essentially same as [[#One-Pass Set Union]] 
* if $R$ is small enough to fit into $M - 1$ buffers 
* but for each distinct value we associate a '''count''' - number of times this tuple occurred
** generally, this structure can take more that $M - 1$ memory buffer if there are few duplicates
** but if there are a lot of duplicates - this way of organizing will take less room than $M - 1$


Algorithm
* load $R$ to $K_R = N_1, ..., N_{B(R)}$ buffers
* for each block $B_S \in S$
** load $B_S$ to $N_0$
** for each tuple $t_S \in B_S$
*** if $t_S \in K_R$
**** output $t_S$
**** decrease '''count''' of $t_S$ in $K_R$
**** if '''count''' = 0 then remove this tuple from memory


=== Sort-Based Bag Intersection ===
* same as [[#Sort-Based Set Union]]
* output $t$ the number of times it appears both in $R$ and $S$


== Set Difference ==
Note that this operation is not commutative
* $S -_S R$ is not the same as $R -_S S$
* assume that $R$ is smaller than $S$

=== One-Pass Set Difference ===
For this we assume $R$ fits into $M-1$ blocks


$S -_S R$ case 
* read $R$ into buffers $K_R = N_1, ..., N_{B(R)}$
* for each block $B_S \in S$
** load $B_S$ into $N_0$
** for each tuple $t_S \in B_S$
*** if $t_S \not \in K_R$ output $t_S$


$R -_S S$ case
* read $R$ into buffers $K_R = N_1, ..., N_{B(R)}$
* for each block $B_S \in S$
** load $B_S$ to $N_0$
** for each tuple $t_S \in B_S$
*** if $t_S \in K_R$ remove $t_S$ from $K_R$ 
* for each tuple $t_R$ that is still in $K_R$ output $t_R$

=== Sort-Based Set Difference ===
* same as [[#Sort-Based Set Union]]
* output $t$ if it appears in $R$ but not in $S$


== Bag Difference ==
* same as in [[#Bag Intersection]]: we '''count''' the number of occurrences
* also two cases: $S -_B R$ and $R -_B S$

=== One-Pass Bag Difference ===
For this we assume $R$ fits into $M-1$ blocks


$S -_B R$ case: count $c$ in this case is $c$ reasons not to output a tuple
* read tuples of $R$ to $K_R = N_1, ..., N_{B(R)}$, '''count''' the number of occurrences
* load each block $B_S$ to $N_0$
** for each tuple $t_S \in B_S$
*** if $t_S \not \in K_R$: output $t_S$
*** otherwise 
**** decrement '''count''' of $t_S$ and 
**** remove $t_S$ from $K_S$ if count = 0


$R -_B S$ case
* read tuples of $R$ to $K_R = N_1, ..., N_{B(R)}$, '''count''' the number of occurrences
* load each $B_S$ to $N_0$
** if $t_S \in K_R$
*** decrement '''count''' for $t_S$ in $K_R$
*** remove $t_S$ from $K_R$ if '''count''' = 0
* for each remaining $t_R \in K_R$
** output $t_R$ '''count''' times

=== Sort-Based Bag Difference ===
* same as [[#Sort-Based Set Union]]
* for each tuple $t$
** let $c_R$ = number of times $t$ appears in $R$
** let $c_S$ = number of times $t$ appears in $S$
** if $c = c_R - c_S \leqslant 0$ don't output anything
** otherwise output $t$ $c$ times


== Join ==
Join is most costly operator to evaluate
* sometimes it's quadratic (when it's equivalent to cartesian product)

Suppose we want to evaluate $R(X, Y) \Join S(Y, Z)$
* $Y$ is a matching attribute and we will join on it
* we again assume that $B(R) &lt; B(S)$

=== One-Pass Join ===
To be able to do it in one pass $R$ must fit into memory
* $R(B) \leqslant M -1$

Algo
* load $R$ into buffers $N_1, ..., N_{B(R)}$
* for each block $B_S \in S$
** load $B_S$ to $N_0$
** for each tuple $t_S \in N_0$
*** for each matching tuple $t_R \in \U_i N_i$
*** output $t_R \Join t_S$

Cost
* $B(R) + B(S)$
* again ignore cost of finding matching tuple in memory


=== Nested Loop Join ===
==== Tuple-Based Nested Join Loop ====
First variant is ''tuple-based nested join loop''
* for each $r \in R$
* for each $s \in S$
** if $r$ matches $s$ output $r \Join s$

We need only one buffer for $R$ and one buffer for $S$

Cost
* $T(R) \times T(S)$ - very expensive!

==== Block-Based Nested Join Loop ====
* We divide $R$ into segments of $M - 1$ blocks
* and for each such segment we go through entire $S$

Algo
* load each segment of $R$ into buffers $N_1, ..., N_{M - 1}$
* for each block $B_S \in S$
** load $B_S$ into $N_0$
** for each tuple $t_R \in \cup_i N_i$ 
*** for each matching tuple $t_S \in N_0$: output $t_R \Join t_S$

=== Sort-Based Join ===
Essentially the same as [[#Sort-Based Set Union]]
* but in this case we need to take care about duplicates that may be in both $R$ and $S$

Algo
* Sort $R$ on matching attribute $Y$
* Sort $S$ on matching attribute $Y$
* Iterate Synchronously through $R$ and $S$ 
** if $t_R.Y &lt; t_S.Y$ then advance pointer $t_R$
** if $t_R.Y &gt; t_S.Y$ then advance pointer $t_S$
** if $t_R.Y = t_S.Y$ then
*** for each pointers $t'_S$ with same $Y$ value that follow $t_S$ (including $t_S$ itself)
**** output $t_R \Join t'_S$ 
*** advance pointer $t_R$ and rewind $t'_S$ to $t_S$
*** (this way we join each tuple from $R$ that has value $Y$ with each tuple from $S$ that also has value $Y$)


Cost
* usually depends of the number of tuples with equal values 
* worst case: all tuples have the same value for $Y$ - in this case the cost is $B(R) \times B(S)$
* but joins are usually performed on foreign keys 
** i.e. tuples in $R$ have distinct values for $Y$ 
** and for each tuple $t_R$ we have several (maybe 0) tuples $t_S$ - one-to-many relationship
** so we don't need to rewind the pointer for $t_S$
** in this case the cost analysis is similar to the [[#Sort-Based Set Union]]
*** sorting cost + $B(R) + B(S)$
** it's also possible to optimize and save additional $B(R) + B(S)$ I/Os
*** sorting cost - $B(R) - B(S)$
* '''NB''': if there's a [[Indexing (databases)#Clustered Index|clustered index]] on $Y$ we don't need to sort it - it's already sorted


=== (Partition) Hash Join ===
* Essentially the same as [[#Hash-Based Set Union]]
* the only difference is that we hash the join attribute and not the whole tuple

Algo
* partition $R$ by hashing $Y$ into buckets each with at most $M-1$ blocks
* let $k$ be the number of buckets we got in result
* partition $S$ by hashing $Y$ into $k$ buckets
* let $R_i$ and $S_i$ be blocks of bucket #$i$ that ended up there because their $Y$ values have the same hash
** a tuple $t_S \in S$ matches $t_R \in S$ $\iff$ there $\exists$ a bucket $i$ s.t. $t_R \in R_i$ and $t_S \in S_i$
* we compute join by calculating $R_i \Join S_i$ for all $i$ using [[#One-Pass Join]] algorithm

Cost
* same as for Hash-Based Set Union
* $k = \lceil \log_{M - 1} B(R) - 1 \rceil$
* total # of I/Os: $2B(R) \cdot k + 2B(S) \cdot k + B(R) + B(S)$



== See also ==
* [[Query Plan]]
* [[Query Processing]]

== Sources ==
* [[Database Systems Architecture (ULB)]]
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom

[[Category:Database Systems Architecture]]</text>
      <sha1>juuw5os2skj245axmfugis4ocrx4n2b</sha1>
    </revision>
  </page>
  <page>
    <title>Database System Catalog</title>
    <ns>0</ns>
    <id>201</id>
    <revision>
      <id>202</id>
      <timestamp>2014-05-10T17:06:05Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1417">== Database System Catalog ==
To estimate a cost of [[Physical Operators (databases)|Physical operators]] in a DBMS we use the following statistics:
* $B(R)$ - # of blocks that relation $R$ holds
* $T(R)$ - # of tuples in $R$
** typically can be used to calculate $B(R)$ when we know how many bytes we have per block
* $V(R, A_1, ..., A_n) = | \delta \pi_{A_1, ..., A_n} (R)  |$ - # of distinct values 


This statistics in DBMS is a ''system catalog''
* they are regularly collected (when needed, scheduled, etc) 
* and regularly revisited 
* note that this data is kept only for base relations, not for subresults of a query!


== Statistics ==
For base relations we typically have some [[Histogram]]s that show how values are distributed

=== [[Data Discretization#Equal-Width Partitioning|Equal-Width Histogram]] ===
* In this type of histograms the values are grouped in equal-width buckets
* We assume that the values are distributed uniformly within there buckets 

Example 

{| class=&quot;wikitable&quot;
|-
! range 
| [1, 10)  || [11, 20) || [21, 30) || [31, 40) || [41, 50) 
|- 
! # of tuples 
| 50 || 2000 || 2000 || 3000 || 2950 
|}



== See Also ==
* [[Physical Operators (databases)]]
* [[Data Discretization]]

== Sources ==
* [[Database Systems Architecture (ULB)]]
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom

[[Category:Database Systems Architecture]]</text>
      <sha1>rk8x62nldpjfn9qvzuu5v3icve3lta7</sha1>
    </revision>
  </page>
  <page>
    <title>Select-Project-Join Expression</title>
    <ns>0</ns>
    <id>202</id>
    <revision>
      <id>203</id>
      <timestamp>2013-12-21T07:52:05Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="67">#перенаправление [[Select-Project-Join Expressions]]</text>
      <sha1>es0w28cj2c6qpabr8030on9kgvyv37y</sha1>
    </revision>
  </page>
  <page>
    <title>Distributed File Systems</title>
    <ns>0</ns>
    <id>203</id>
    <revision>
      <id>204</id>
      <timestamp>2013-12-21T20:50:26Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="66">#перенаправление [[Hadoop Distributed File System]]</text>
      <sha1>0mf84pgu9o1ijyf979d0imt27gla3qs</sha1>
    </revision>
  </page>
  <page>
    <title>MapReduce</title>
    <ns>0</ns>
    <id>204</id>
    <revision>
      <id>205</id>
      <timestamp>2013-12-23T17:34:49Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5424">== Map Reduce ==
Map-Reduce is a paradigm of parallel computation that initially comes from [[Functional Programming]]

The main characteristics
* it's scalable and fault tolerant 
* it a data processing tool that can handle parallel processing of large volumes of data
* it typically runs on a [[Hadoop Distributed File System|Distributed File System]]

Main Idea:
* hide details of parallel execution
* allow user to focus only on data processing strategies


=== Programming Model ===
The Map-Reduce model is simple. A programmer needs to specify two primitives:
* a Map function which produces &quot;intermediate&quot; result
* a Reduce function which produces the final result
* There's also a combine stage in-between 

==== Map Function ====
Map($[(k, v)]$) $\to [(k_2, v_2)]$
* input: a list of $(k, v)$ pairs
* the map function is applied to each pair in the input
* and it outputs a list of $(k_2, v_2)$ pairs 

==== Combine ====
Combine
* from a list of $(k2, v2)$ pairs form a list of $(k_2, [v_2])$ pairs
* i.e. group intermediate results by key

==== Reduce Function ====
Reduce($[(k_2, [v_2])]$)
* now for each combined pair we apply reduce

=== Map-Reduce Job Execution ===
Procession
* each processing job is broken down to pieces
* each piece is given for a map task to execute
* also there are one or more reduce tasks

https://raw.github.com/alexeygrigorev/ulb-adb-project-couchbd/master/report/images/map-reduce.png

So it's performed in two steps 
* map phase 
* reduce phase

Implementation on top of [[Hadoop Distributed File System|Distributed File System]] is little bit more complex and needs some additional logic for replicating and so on. 
* For Hadoop implementation refer to [[Hadoop#Map-Reduce Job Execution]]


=== Example ===
Word-Counting: need to calculate how many occurrences of each word there are 
* distribute all documents among $k$ computers 
* for each document return a set of (word, freq) pairs (the map phase) 
* now sum the occurrences for each word (the reduce phase)

Pseudo-code
&lt;pre&gt;
def map(String input_key, String doc):
  for each word w in doc:
    EmitIntermediate(w, 1)

def reduce(String output_key, Iterator output_vals):
  int res = 0
  for each v in output_vals:
    res += v
  Emit(res)
&lt;/pre&gt;


== High Level Languages ==
There are SQL-like languages that work on top of [[Hadoop]] and translate into a set of Map-Reduce jobs 
* [[Pig]]
* [[Hive]]


== Joins in Map-Reduce ==
=== Broadcast-Join ===
* when one table is small enough to fit into memory
* small one is broadcasted to each mapper and kept in memory there
* go through blocks of other one and do the join


=== Reduce-Side Join ===
* preparation step
** each mapper tags each record to identify which entity it is
* mapper outputs (id, record) for each record
** same keys will be copied to same reducer during shuffling
* each reducer does the join based on equal kets
* similar to [[Physical Operators (databases)#(Partition) Hash Join|Hash Join]] in DBMS

note
* it may lead to massive data re-distribution 
* when input is huge
* even though data may be on one node it may be moved to others
* need to take the cost of communication into account


==== Example ====
Suppose we have the following schema: 
* Employee(name, SSN)
* Department(emplSSN, depName)

We want to have the following join: 
* $\text{Employee} \Join_\text{SSN = emplSSN} \text{Department}$

Our tagged dataset 
{| class=&quot;wikitable&quot;
|-
| Emp || Sue || 999
|-
| Emp || Tony || 777
|-
| Dep || 999 || Accounts 
|-
| Dep || 777 || Sales
|-
| Dep || 777 || Marketing
|}


After applying map we get
{| class=&quot;wikitable&quot;
|-
| 999 || (Emp, Sue, 999)
|-
| 777 || (Emp, Tony, 777)
|-
| 999 || (Dep, 999, Accounts)
|-
| 777 || (Dep, 777, Sales)
|-
| 777 || (Dep, 777, Marketing)
|}


And finally after the reduce stage we get 

{| class=&quot;wikitable&quot;
|-
| key=999 || [(Emp, Sue, 999), (Dep, 999, Accounts)]
|-
| key=777 || [(Emp, Tony, 777), (Dep, 777, Sales), (Dep, 777, Marketing)]
|}


For additional code refer to this [http://code.google.com/p/stolzen/source/browse/trunk/courses/coursera/Introduction%20to%20Data%20Science/assignment3/p2_join.py implementation in Python]


== Other Map-Reduce Examples ==
=== Matrix Multiplication ===
* Suppose we have two sparse matrices: $A (l \times m)$ and $B (m \times n)$
* We want to calculate $C = A \times B$

Map: 
* for each element $(i, j) \in A$
: emit $((i, k), A[i, j])$ for $k \in 1..N$
* for each element $(j, k) \in B$
: emit $((i, k), B[j, k])$ for $i \in 1..L$

Reduce: 
* key = $(i, k)$
* value = $\sum_j (A[i, j] \times B[j, k])$

[http://code.google.com/p/stolzen/source/browse/trunk/courses/coursera/Introduction%20to%20Data%20Science/assignment3/p6_matrixmult.py Implementation in Python]


== MapReduce vs RDBMS ==
[[Relational Databases|RDBMS]] 
* Declarative query language
* Schemas 
* Logical Data Independence
* [[Indexing (databases)|Indexing]] 
* [[Logical Query Plan Optimization|Algebraic Optimization]] 
* Caching / [[View Materialization|Materialized Views]] 
* [[ACID]] and transactions 

MapReduce
* High Scalability 
* Fault-tolerance



== See also ==
* [[Hadoop]]
* [[Hadoop Distributed File System]]

== Sources ==
* [[Introduction to Data Science (coursera)]]
* Lee et al, Parallel Data Processing with MapReduce: A Survey [http://www.cs.arizona.edu/~bkmoon/papers/sigmodrec11.pdf]


[[Category:Algorithms]]
[[Category:Hadoop]]
[[Category:Distributed Systems]]</text>
      <sha1>1iyulbqd8bd14642zxd8ly4x8nb1tqk</sha1>
    </revision>
    <revision>
      <id>747</id>
      <parentid>205</parentid>
      <timestamp>2015-12-30T15:10:14Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3401">== Map Reduce ==
Map-Reduce is a paradigm of parallel computation that initially comes from [[Functional Programming]]

The main characteristics
* it's scalable and fault tolerant: it scales lineraly with amount of data
* it a data processing tool that can handle parallel processing of large volumes of data
* it typically runs on a [[Hadoop Distributed File System|Distributed File System]]


Main Idea:
* hide details of parallel execution
* allow user to focus only on data processing strategies


== Programming Model ==
The Map-Reduce model is simple. A programmer needs to specify two primitives:
* a '''Map''' function which produces &quot;intermediate&quot; result
* a '''Reduce''' function which produces the final result
* And there's a shuffle stage in-between


=== Map Function ===
Map($[(k, v)]$) $\to [(k_2, v_2)]$
* input: a list of $(k, v)$ pairs
* the map function is applied to each pair in the input
* and it outputs a list of $(k_2, v_2)$ pairs 

=== Shuffle ===
Shuffle
* from a list of $(k_2, v_2)$ pairs form a list of $(k_2, [v_2])$ pairs
* i.e. group intermediate results by key

=== Reduce Function ===
Reduce($[(k_2, [v_2])]$)
* now for each combined pair we apply reduce


== Program Execution ==
Procession
* input is broken into pieces
* each piece is given for a map to execute
* there are one or more reduces

{{void|https://raw.github.com/alexeygrigorev/ulb-adb-project-couchbd/master/report/images/map-reduce.png}}

http://hsto.org/files/9f4/126/a0c/9f4126a0c41c47c7a21c3f4888f5966e.png


=== [[Hadoop MapReduce]] ===
For Hadoop implementation refer to [[Hadoop MapReduce#Map-Reduce Job Execution]]


== Example ==
=== Word Count ===
Word-Counting: need to calculate how many occurrences of each word there are 
* distribute all documents among $k$ computers 
* for each document return a set of (word, freq) pairs (the map phase) 
* now sum the occurrences for each word (the reduce phase)

Pseudo-code
&lt;pre&gt;
def map(String input_key, String doc):
  for each word w in doc:
    EmitIntermediate(w, 1)

def reduce(String output_key, Iterator output_vals):
  int res = 0
  for each v in output_vals:
    res += v
  Emit(res)
&lt;/pre&gt;


=== [[Matrix-Matrix Multiplication]] ===
* Suppose we have two sparse matrices: $A$, a $m \times k$ matrix and $B$, a $k \times n$ matrix
* We want to calculate $C = A \times B$

Map: 
* for each element $(i, j) \in A$
** emit $((i, k), A[i, j])$ for $k \in 1..N$
* for each element $(j, k) \in B$
** emit $((i, k), B[j, k])$ for $i \in 1..L$

Reduce: 
* key = $(i, k)$
* value = $\sum_j (A[i, j] \times B[j, k])$

[http://code.google.com/p/stolzen/source/browse/trunk/courses/coursera/Introduction%20to%20Data%20Science/assignment3/p6_matrixmult.py Implementation in Python]



== MapReduce Patterns ==
=== Joins ===
* see [[MapReduce/Joins]]


== Implementations ==
MapReduce is implemented on the following systems:
* [[Hadoop MapReduce]]
* [[CouchDB]] uses MapReduce for querying the database
* [[Spark]], [[Flink]] also provide map and reduce functions


== See also ==
* [[Hadoop]] and [[Hadoop MapReduce]]
* [[Hadoop Distributed File System]]

== Sources ==
* [[Introduction to Data Science (coursera)]]
* Lee et al, Parallel Data Processing with MapReduce: A Survey [http://www.cs.arizona.edu/~bkmoon/papers/sigmodrec11.pdf]
* [[Hadoop: The Definitive Guide (book)]]

[[Category:Algorithms]]
[[Category:Hadoop]]
[[Category:MapReduce]]</text>
      <sha1>le2usijyaiau9ykpaceng0zij49lp4t</sha1>
    </revision>
  </page>
  <page>
    <title>Pig</title>
    <ns>0</ns>
    <id>205</id>
    <revision>
      <id>206</id>
      <timestamp>2013-12-23T19:02:51Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1134">== Pig ==
Pig Latin is a SQL-like declarative query language that runs on top of [[Hadoop]]

Pig Latin
* needs data model in form of UDF (user defined function)
* first it generated a query plan
* then compiles it into a set of MR jobs
* some optimizations are applied


== Example ==
SQL:

&lt;pre&gt;SELECT SUM(s.Sale), c.City 
FROM Sales s, Cities c
WHERE s.AddrId = c.AddrId
GROUP BY City;&lt;/pre&gt;


Pig Latin
&lt;pre&gt;-- 1
tmp = COGROUP Sales BY AddrId,
              Cities BY AddrId
-- 2 
join = FOREACH tmp GENERATE 
       FLATTEN(Sales), FLATTEN(Cities)
-- 3
grp = GROUP join BY City

-- 4
res = FOREACH grp GENERATE SUM(Sale)
&lt;/pre&gt;

in Pig FOREACH $\approx$ [[MapReduce#Map Function|Map]]


== See also ==
* [[Hadoop]]
* [[Hive]]

== Links ==
* http://www.slideshare.net/jayshao/introduction-to-apache-pig
* Official website: http://pig.apache.org/ 
* Process your data with Apache Pig [http://www.ibm.com/developerworks/linux/library/l-apachepigdataquery/] and [http://www.ibm.com/developerworks/ru/library/l-apachepigdataquery/] (на русском)

== Sources ==
* [[Introduction to Data Science (coursera)]]

[[Category:Hadoop]]</text>
      <sha1>nwluqwnr2prlws09nad9k4sq3tt7m4c</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Hadoop</title>
    <ns>14</ns>
    <id>206</id>
    <revision>
      <id>207</id>
      <timestamp>2013-12-23T19:03:30Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="32">[[Category:Distributed Systems]]</text>
      <sha1>4ur8ixqy5pdviwj71fdkm4ueu49sydj</sha1>
    </revision>
  </page>
  <page>
    <title>HDFS</title>
    <ns>0</ns>
    <id>207</id>
    <redirect title="Hadoop Distributed File System" />
    <revision>
      <id>208</id>
      <timestamp>2013-12-23T19:32:31Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="44">#REDIRECT [[Hadoop Distributed File System]]</text>
      <sha1>mrgor6yvnsujofe7cyniczjki5hng9e</sha1>
    </revision>
  </page>
  <page>
    <title>Hive</title>
    <ns>0</ns>
    <id>208</id>
    <revision>
      <id>209</id>
      <timestamp>2014-01-07T09:17:47Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3664">== Hive ==
Hive is a [[Data Warehousing|Data Warehouse]] solution built on top of [[Hadoop]]
* Main feature - Hive QL: Declarative Query language for ad-hoc analytics


== Hive [[Data Model]] ==
Basic structures:
* Tables
** like tables in RDBs
** each table has a corresponding [[HDFS]] directory
* [[Database Partitioning|Partitions]]
** each table has one or more partitions
* Buckets
** data in each partition is divided into buckets

Data type system
* primitives
** int, float, string, date, boolean
* collections
** arrays and maps
** nestable
* can define own data types


== Achitecture ==
https://raw.github.com/alexeygrigorev/ulb-dw-project-hadoop/master/report/images/hive-architecture.png

(figure source: [http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.151.2637])

Main Components
* External Interfaces
** CLI
** JDBC + Thrift
** Web
* [[Database System Catalog|System Catalog]]
** called Metastore
** contains schemas
** keeps statistics - like in [[Databases|DBMS]]
** enables optimization techniques (but only naive rule-based optimizations)
* Driver that manages HiveQL queries, contains 
** optimizer
** executor (which executes the plan in [[Topological Ordering]])
* Hadoop as the execution engine


=== Query Execution ===
* a query plan consists of several MapReduce jobs
* results of each job is stored (materialized) on [[HDFS]]
* and the results are consumed by the next job in the graph
* so a job that depends on some other job must wait until it finishes
* it cannot start until all results are materialized to disk, i.e. no [[Pipelining]]!


== Hive QL ==
Hive Query Language is a SQL-like declarative query language for ad-hoc queries 

Main Features
* it compiles into a [[Graphs#Directed Acyclic Graph|DAG]] of [[MapReduce]] jobs that are executed in [[Hadoop]]
* also can plug custom MapReduce scripts 


=== Example ===
Suppose we have the following tables:
* status_update(user_id int, status string, ds string)
** '''ds''' is date
* profiles(userid int, school string, gender int)


To load data into a table we use 

&lt;pre&gt;LOAD DATA LOCAL INPATH 'logs/status_updates'
INTO TABLE status_updates 
PARTITION (ds='2009-03-20')
&lt;/pre&gt;

In this query we want to [[Database Partitioning|partition]] our table by date

==== Query 1 ====
Compute daily statistics on how often a status is updated based on gender and school

&lt;pre&gt;
FROM 
(SELECT a.status, b.school, g.gender
 FROM status_updates a JOIN profiles b
 ON (a.userid = b.userid and a.ds = '2009-03-20') subq1

-- groups by gender
INSERT OVERWRITE TABLE gender_summary -- inserts the result into another table
PARTITION (ds='2009-03-20')
SELECT subq1.gender, count(1)
GROUP BY subq1.gender

-- groups by school
INSERT OVERWRITE TABLE school_summary
PARTITION (ds='2009-03-20')
SELECT subq.school, count(1)
GROUP BY subq1.school
&lt;/pre&gt;

note that we have 2 operations in one query
* they are performed in a single scan

==== Query 2 ====
suppose we want to display top 10 memes per school

&lt;pre&gt;REDUCE subq2.school, subq2.meme, subq2.cnt
-- using custom python script
USING 'top10.py' AS (school, meme, cnt)
FROM (
	SELECT subq1.school, subq1.meme, count(1) as cnt
	FROM
	(MAP b.school, a.status
		USING 'meme_extractor.py'
		AS (school, meme)
		FROM status_update a JOIN profiles b
		ON (a.userid = b.userid)) subq1
	GROUP BY subq1.school, subq1.meme
	DISTRIBURE BY school, meme
	SORT BY school, meme, cnt desc)
) subq2&lt;/pre&gt;


== See also ==
* [[Hadoop]] and [[MapReduce]]
* [[Pig]]

== Sources ==
* Thusoo et all, Hive: A Warehousing Solution Over a Map-Reduce Framework (2009). [http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.151.2637]


[[Category:Hadoop]]</text>
      <sha1>es3bkaslp2xpk75nn4dv5zz9urj9741</sha1>
    </revision>
  </page>
  <page>
    <title>Hadoop in Data Warehousing</title>
    <ns>0</ns>
    <id>209</id>
    <revision>
      <id>210</id>
      <timestamp>2015-06-24T20:10:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8972">[[Hadoop]] for [[Data Warehouse|Data Warehousing]]
* This is a part of a project for [[Data Warehousing (ULB)]] course
* link to the final report: [http://alexeygrigorev.github.io/ulb-dw-project-hadoop/report/report.pdf report]
* presentation: [http://alexeygrigorev.github.io/ulb-dw-project-hadoop/presentation/dw-presentation.html html] or [http://www.slideshare.net/AlexeyGrigorev/hadoop-in-data-warehousing slide share]


== Introduction ==
Today the amounts of data stored in [[Data Warehouse]]s are becoming more and more enormous. While traditional ways of Data Warehousing design on top of [[Relational Databases]] are still popular, they fail to curb terabytes of data efficiently, which is mostly attributed to complexity of scaling relational databases. There are new emerging approaches that try to address this problem. 

One of such approaches is to use the [[MapReduce]] paradigm and [[Hadoop]] as the implementation for building large Data Warehouses over distributed network of servers that can handle huge volumes of data. Hadoop has already become a proven tool for BigData analytics and now there is a rising interest in this technology for Data Warehousing purposes .

The goal of the work is to discuss in what ways Hadoop, as a Map-Reduce framework, can be used in Data Warehouses then compare it with traditional approaches and see in which situations it should be beneficial to use Hadoop in a Data Warehousing project. Additionally we plan to see what are cases where traditional approaches should still be preferred over Hadoop. 


=== Motivation ===
* Proven useful in Big Data challenges
* Interesting in [[Business Intelligence]]
* Many companies want to integrate Hadoop into existent Data Warehousing solutions


=== [[Types of Data]] ===
* Hadoop can handle Structured data (Relational), Semi-structured (XML, JSON, ...) 
* but also it's very good at unstructured and machine-generated data: Data with no [[Data Model]]
* Hadoop will help to structure large amounts of unstructured data


=== Growth ===
Today have lots of documents
* Not all structured (Text, audio, video)
* Want to structure then
* E.g. Lots of recorded calls - we want to extract certain keywords from them

The number of structured documents is also growing rapidly
* Transactions
* etc


== Entire Data Warehouse on Hadoop ==
It's possible to build entire Data Warehouse on top of Hadoop
* Example: Cheetah by Turn.inc
* It's a specialized Data Warehouse 
* [[Hive]] is a more generic Data Warehouse solution


=== Design ===
Virtual views
* based on Star and Snowflake schemas 
** central Fact Table
** connected to dimension tables via primary key and foreign key dependencies
** they are needed for joining
* they join the fact table with its dimensions
* only views are exposed to users for querying, not the tables
* https://raw.github.com/alexeygrigorev/ulb-dw-project-hadoop/master/report/images/virt-views.png


=== Operations ===
* Filtering, Grouping and Aggregations
** easily supported by hadoop
* joins
** recall that [[MapReduce#Reduce-Side Join|Reduce-Side Joins]] are expensive - it may lead to data re-distribution
** it's better to denormalize dimension tables as much as possible
** i.e. store all data in fact tables

Denormalization works well
* all dimensions are either insertion only or [[Slowly Changing Dimensions]]


=== Queries ===
Special-purpose QL for querying it
* Like [[Pig]] and [[Hive]] they are compiled to [[MapReduce]] jobs
* With some optimizations

Unfortunately Chetach is proprietary - wasn't able to play with it


== Hadoop and Data Warehouse ==
Hadoop as a Part of Data Warehouse
* they are interchangeable
* and have lots of differences
* often used side by side
* and it can help to make the costs lower

It can be
* Transitory Platform for [[ETL]]
* Active Storage

=== Transitory platform for [[ETL]] ===
Hadoop as an [[ETL]] process
* this was the initial use case of Hadoop
* goal: extract value from terabytes of information
* Hadoop is rather a component in ETL tools, not an ETL tool itself
** it's just another channel in ETL designers
** many vendors came up with Hadoop components in their graphical languages
** and it's possible to do [[Pig]] and [[Hive]] queries inside these channels
** for example, Informatica can do that 


Algorithm
* load data into [[Hadoop]]
* discover something there with it
* '''E''' parse and prepare (with [[MapReduce]])
* '''T''' clean and transform to some structured format (with [[MapReduce]])
* '''L''' extract data from Hadoop and load to a Data Warehouse

Input:
* not structured provisional data
* semi-structured, unstructured or machine-generated data
* provisional - meaning analyzed or used in isolation and don't need integration
** unlike traditional operational Data Warehousing data
* i.e. this data don't really fit into DW paradigm, but Hadoop was created to handle it


==== Text Processing ====
* most common use case of Hadoop (the survey)
* RDBMs not good for this!
* no SQL functions for text processing
* text stream -&gt; structured data

Examples
* like: finding keywords, sentiment analysis
* once refined and structured the text, can put it into DW for further analysis
* say to match sentiment with customer profile


==== Examples ====
Example 1
* process raw click streams
* use [[Data Mining]] to detect patterns 
* then put all the findings into a [[Data Warehouse]]

Example 2
* suppose we run a eBay-like website
* someone publishes an advertisement - it's a dress with some description
* but the description doesn't mention the color
** user thinks it's obvious - it can be seen on the picture!
* but we want to be able to answer queries such as &quot;red dress&quot;
* so we process this image to retrieve features
** color
** type
** other things that might be used for search
* not possible with SQL 
* but this information can be used in out Data Warehouse as well


=== Repository ===
Hadoop can store lots of data

It's possible to use it in 2 ways (as a storage)
* Active Storage for unstructured data
* Live Archive for &quot;dormant&quot; structured enterprise data


==== Active Storage ====
First use-case 
* storage cost: Hadoop cluster typically costs 50-100 times less than typical DB solutions (per Tb)
* data access is fast
* can use it as a long-term storage
** not necessary to move everything to a Data Warehouse each time we need to do some analysis - can do that with Hadoop
** but still can move some portions of processed data to a DW for BI analysis


Example
* need to capture data arriving from raw streams
* want to store reliably and cost efficiently
* put it into Hadoop


==== Enterprise Data Live Archive ====
Second use case: Live archive for traditional enterprise data

motivation
* 85% of tables in DW are not used 
* can transfer this &quot;dormant&quot; data to low cost hadoop storage
* result in extraordinary savings


=== Analytical Sandboxes ===
Last common use case:
* Our input data is not structured
* That means we do not know yet what we want to derive from it 
* Need to play around to see what value we can extract
* And hadoop (along with [[Hive]] or [[Pig]] for ad-hoc queries) is good for it


==== How to Integrate ====
* step-by step recommendations
* first: use it as a big staging area
** for mining unstructured (and structured) data
** then execute some ETL transformations on it
* next: use as non-dimensional warehouse for raw data
* integrate more


== Conclusion ==
Hadoop and Data Warehouses should work together in a single information chain

Hadoop use cases:
* front end: preprocessing raw unstructured data
* front end: analytical sandbox
* back end: long-term active storage
* in-between: supplementing existent technologies with parallel processing


Data Warehousing use cases: 
* structured and integrated data for BI and OLAP


== Questions ==
Q: Why?
* to be able to run on commodity hardware

Q: Who should adapt this?

Q: How much data a company should have?
* when data no longer fits in MySQL or PostreSQL - it's a good point that should adopt Hadoop


== See also ==
* [[Data Warehouse]]
* [[Hadoop]]
* [[MapReduce]]
* [[Hadoop Distributed File System]]

== Sources ==
* Lee et al, Parallel Data Processing with MapReduce: A Survey [http://www.cs.arizona.edu/~bkmoon/papers/sigmodrec11.pdf]
* Ordonez et al, Relational versus non-relational database systems for data warehousing [http://www2.cs.uh.edu/~ordonez/w-2010-DOLAP-relnonrel.pdf]
* Paper by Cloudera and Teradata, Awadallah and Graham, Hadoop and the Data Warehouse: When to Use Which. [http://www.teradata.com/white-papers/Hadoop-and-the-Data-Warehouse-When-to-Use-Which/]
* Chen. Cheetah: A High Performance, Custom Data Warehouse on Top of MapReduce. [http://www.vldb.org/pvldb/vldb2010/papers/I08.pdf]
* Russom, Integrating Hadoop into Business Intelligence and Data Warehousing. [http://www.slideshare.net/emcacademics/tdwi-best-practices-report-hadoop-foro-bi-and-dw-april-2013]


[[Category:Hadoop]]
[[Category:Data Warehousing]]</text>
      <sha1>lrk5hh0px6w6irloal1sma7zn79tuh7</sha1>
    </revision>
  </page>
  <page>
    <title>Hadoop</title>
    <ns>0</ns>
    <id>210</id>
    <revision>
      <id>211</id>
      <timestamp>2014-01-07T13:35:19Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7229">== Hadoop ==
usually the term ''Hadoop'' refers to an entire family of products. 

So it's usually a set of products:
* parallel storage ([[Hadoop Distributed File System|HDFS]])
* processing framework ([[MapReduce]] implementation)
* [[Pig]]/[[Hive]] for declarative high-level language support
* [[HBase]] as non-relational NoSQL database that runs on HDFS
* Mahout - [[Data Mining]] and [[Machine Learning]] tool that works on top of Hadoop


Hadoop
* Any combination of them is still referred as Hadoop 
* Lots of vendors (like HortonWorks) provide their own distributions of Hadoop
* Even though [[MapReduce]] is considered the most important part, it is entirely optional: we may just use HDFS and HBase - and still will consider this combination Hadoop 


== MapReduce Component ==
This is a data processing tool on top of HDFS

=== [[MapReduce]] Job Execution ===
Procession
* each processing job is broken down to pieces
* each piece is given for a map task to execute
* also there are one or more reduce tasks

So it's performed in two steps 
* map phase 
* reduce phase

=== Algorithm  ===
* master picks some idle workers and assigns them a map task
* preparations (before starting the map task)
** input file is loaded to DFS
** it's partitioned into blocks (typically 64 kb each)
** each block is replicated 3 times to guarantee fault-tolerance
* '''map phase'''
** each block is assigned to a map worker
** it applies the [[MapReduce#Map Function|map function]] to it
** intermediate results are sorted locally
** then it's stored on local disk of mapper
** it's partitioned into $R$ reduce tasks 
*** $R$ is specified beforehand
*** partitioning is typically done by '''hash(key) % $R$'''
* wait until ''all'' map tasks are completed
* before reduce
** the master assigns reduce task to workers
** the intermediate results are shuffled and assigned to reducers
** each reduces pulls its partition from mapper's disk
*** all map results are already partitioned and stored on mapper disks
*** read the input and group it by key
** each record is assigned to only one reduces 
* '''reduce phase'''
** now apply the [[MapReduce#Reduce Function|reduce function]] to each group
** output is stored and replicated 3 times


Hadoop in one picture: 

https://raw.github.com/alexeygrigorev/ulb-adb-project-couchbd/master/report/images/hadoop.png

(Figure source: Huy Vo, NYU Poly and [http://escience.washington.edu/get-help-now/what-hadoop])


In short:
* There's only one Name Node 
* the Name Node divides input files into $M$ ''splits'' (by key)
* then the Name Node assigns ''workers'' (servers) to perform $M$ map tasks
* while they are computing, it keeps track on their progress 
* Workers write their results on local disk dividing it into $R$ regions
* once Map part is done, the Name Node assigns workers to the $R$ reduce tasks 
* Reduce workers read the regions from the map workers' local disks 


https://raw.github.com/alexeygrigorev/ulb-adb-project-couchbd/master/report/images/map-reduce2.png


=== Fault-Tolerance ===
Achieved because of its Execution Scheme
* detect failures and re-assigns tasks of failed nodes to others in the cluster
* naturally leads to load balancing 


=== Runtime Scheduling Scheme ===
* For job execution MapReduce component doesn't build any execution plan beforehand
* It relies on the fault-tolerance scheme that naturally leads to load balancing
* Nodes that have completed are assigned to other data blocks 

Result: no communication costs
* MR tasks are done without communication between tasks


== Advantages ==
* [[MapReduce]] is simple and expressive
** computing aggregation is easy
* flexible
** no dependency on [[Data Model]] or schema
*** especially good for unstructured data
*** cannot do that in [[Database]]s
** can write in any programming language
* fault-tolerance
** detect failures and re-assigns tasks of failed nodes to others in the cluster
* high scalability
* even though not in the most efficient way
* cheap
** runs on commodity hardware
** open source


== Disadvantages ==
However it has many disadvantages

=== No Query Language ===
No high-level declarative language as SQL
* [[MapReduce]] is very low level - need to know programming languages 
* programs are expensive to write and to maintain
* programmers that can do that are expensive
* for [[Data Warehousing]]: [[OLAP]] is not that good in MapReduce

Possible solutions: 
* [[Pig]] and [[Hive]]


=== Performance ===
Performance issues:
* no schema, no index, need to parse each input
** may cause performance degradation
* not tuned for multidimensional queries
* possible solutions: [[HBase]], [[Hive]]
* because of fault-tolerance and scalability - it's not always optimized for I/O cost
** all intermediate results are materialized (no [[Pipelining]])
** triple replication
* low latency
** big overhead for small queries (job start time + jvm start time)

Solutions for I/O optimization
* [[HBase]]
** [[Column-Oriented Databases|Column-Oriented Database]] that has index structures
** data compression (easier for Column-Oriented Databases)
* Hadoop++ [https://infosys.uni-saarland.de/projects/hadoop.php]
** HAIL (Hadoop Aggressive Indexing Library) as an enhancement for HDFS 
** structured file format
** 20x improvement in Hadoop performance


=== Map and Reduce are Blocking ===
* a transition from Map phase to Reduce phase cannot be made while Map tasks are still running
** reason for it is that relies on [[External Merge Sort]] for grouping intermediate results
** [[Pipelining]] is not possible
* latency problems from this blocking processing nature
* causes performance degradation - bad for [[OLAP|on-line processing]]

Solution
* Incremental MapReduce (like in [[CouchDB]] [http://stackoverflow.com/questions/11236676/why-is-mapreduce-in-couchdb-called-incremental] [http://eagain.net/articles/incremental-mapreduce/])


=== Bad High Availability ===
* single point of failure: the Name Node
* it name node fails, it brings down the entire cluster
* solutions: 
** use special hardware for it
** regularly back up


=== Fixed Data Flow ===
* Sometimes the abstraction is too simple
** many complex algorithms are hard to express with this paradigm
* Design
** read simple input
** generate simple output
* Again, tools like [[Hive]] can help


=== Other ===
And finally, it's very young



== Hadoop for Data Warehousing ==
{{ Main | Hadoop in Data Warehousing }}


== Links ==
* http://www.stanford.edu/class/ee380/Abstracts/111116.html - a lecture about Hadoop from Cloudera CTO 

== See also ==
* [[MapReduce]]
* [[Hadoop Distributed File System]]
* [[Hadoop in Data Warehousing]]

== Sources ==
* Lee et al, Parallel Data Processing with MapReduce: A Survey [http://www.cs.arizona.edu/~bkmoon/papers/sigmodrec11.pdf]
* Ordonez et al, Relational versus non-relational database systems for data warehousing [http://www2.cs.uh.edu/~ordonez/w-2010-DOLAP-relnonrel.pdf]
* Paper by Cloudera and Teradata, Awadallah and Graham, Hadoop and the Data Warehouse: When to Use Which. [http://www.teradata.com/white-papers/Hadoop-and-the-Data-Warehouse-When-to-Use-Which/]
* [[Introduction to Data Science (coursera)]]


[[Category:Hadoop]]
[[Category:Distributed Systems]]</text>
      <sha1>jvupdpflqeunrxf0ocbugush97xj7tk</sha1>
    </revision>
    <revision>
      <id>681</id>
      <parentid>211</parentid>
      <timestamp>2015-11-23T11:58:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2530">== Hadoop ==
Usually the term ''Hadoop'' refers to an entire family of tools but mostly to
* [[HDFS]] distributed storage
* [[Hadoop MapReduce]] - processing framework ([[MapReduce]] implementation)


=== Hadoop Ecosystem ===
Other tools in the Hadoop ecosystem
* [[Pig]] declarative high-level language for running on [[Hadoop MapReduce]]
* [[Impala]], [[Hive]], [[Tez]] interactive SQL (SQL-like) languages
* [[Spark]], [[Flink]] for fast iterative processing, especially when data can be put in memory
* [[Storm]], [[Samza]], [[Flink]] for streaming
* [[HBase]] non-relational [[NoSQL]] database that runs on [[HDFS]]
* [[Mahout]] - [[Data Mining]] and [[Machine Learning]] tool that works on top of Hadoop
* [[Solr]] - for [[Inverted Index|document indexing]] on top of [[HDFS]]


=== What is &quot;Hadoop&quot; ===
* Any combination of them is still referred as &quot;Hadoop&quot; 
* Lots of vendors (Cloudera, HortonWorks, MapR) provide their own distributions of Hadoop
* Even though [[Hadoop MapReduce]] is an most important part of Hadoop, it is entirely optional: we may just use HDFS and HBase - and still will consider this combination Hadoop 


=== Hadoop1 vs Hadoop2 ===
* Hadoop1 uses its own executing engine (&lt;code&gt;TaskTracker&lt;/code&gt;)
* new generation of Hadoop - Hadoop2 - relies on [[YARN]] for this 


== Hadoop Configuration ==
There's a Hadoop configuration folder, and each component typically has a file there with the configuration properties 

Hadoop looks for configurations if &lt;code&gt;/etc/hadoop&lt;/code&gt; or in &lt;code&gt;HADOOP_CONFIG_DIR&lt;/code&gt;

common properties: 
* &lt;code&gt;core-site.xml&lt;/code&gt; - common properties
* &lt;code&gt;hdfs-site.xml&lt;/code&gt; HDFS properties 
* &lt;code&gt;mapred-site.xml&lt;/code&gt;
* &lt;code&gt;yarn-site.xml&lt;/code&gt;

Depending on the values of these files, Hadoop can be run in several modes:
* Standalone/Local: for testing, run on a local machine
* [[Hadoop Pseudo Distributed Mode|Pseudodistributed]]: also run on a local machine, but jobs are executed by hadoop services (see [[Hadoop Pseudo Distributed Mode]] for configuration example)
* Fully Distributed: cluster (configuration is usually downloaded from cluster managers, e.g. Ambari or Cloudera Manager)



== Hadoop for Data Warehousing ==
{{ Main | Hadoop in Data Warehousing }}


== See also ==
* [[MapReduce]]
* [[Hadoop Distributed File System]]
* [[Hadoop in Data Warehousing]]

== Sources ==
* [[Introduction to Data Science (coursera)]]
* [[Hadoop: The Definitive Guide (book)]]

[[Category:Hadoop]]
[[Category:MapReduce]]
[[Category:Distributed Systems]]</text>
      <sha1>cbdl0a7m8c9iwvudk72qkm23b7kntc9</sha1>
    </revision>
  </page>
  <page>
    <title>Data Warehousing</title>
    <ns>0</ns>
    <id>211</id>
    <redirect title="Data Warehouse" />
    <revision>
      <id>212</id>
      <timestamp>2013-12-24T13:18:23Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="28">#REDIRECT [[Data Warehouse]]</text>
      <sha1>k97tcwmussu1f2j23ia6jqxa0xp86ox</sha1>
    </revision>
  </page>
  <page>
    <title>Data Warehouse</title>
    <ns>0</ns>
    <id>212</id>
    <revision>
      <id>213</id>
      <timestamp>2014-05-12T09:30:52Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3824">== Data Warehouse ==
=== Definition ===
A data warehouse is a storage with the following four characteristics: it's subject-oriented, integrated, time-variant and non-volatile.

==== Subject-Oriented ====
* A data warehouse is organized around a particular subject area.
* For example, around &quot;sales&quot;. 

==== Integrated ====
* Data comes from different sources and is integrated into one.
* Integrated also implies consistency
* For example, in source A and source B products have different identifiers, but in a data warehouse data from all sources have adhere to the same way of identifying.
* Another example: date may be stored in different format, but it's converted to the single common format in a data warehouse

==== Time-Variant ====
* It keeps historical data.
* We can retrieve 3-month-old data, 6-month, one year and even older data from a data warehouse. 
* In contrast to a [[OLTP|transactional system]], where typically only the most recent data is kept.
* For example, in OLTP system we have the most recent address of a customer, while in a data warehouse we keep all the history (see [[Slowly Changing Dimensions]])

==== Non-volatile ====
* Once we put data into a data warehouse, we never change it. 
* If it's there - it's there forever.

=== Alternative Definition ===
A Data Warehousing is a platform for supplying clean, standardized, dimensional, aggregated data


=== Goal ===
The main role of data warehouses is to support decision making process.
* i.e. answer essential business questions


=== Features ===
Best for most BI deliverables
* reports
* performance management metrics
* operational [[Business Intelligence]] data
* [[OLAP]] cubes

Other systems, like [[Hadoop]], are not good at this.


== Data Warehouses on Top of [[Relational Databases]] ==
Usually DWs are built on RBDs
* this structure dominates in data warehousing
* so far it's best technology to manage and analyze DWs
** very mature here

RDBMSs are likely to remain standard in Data Warehousing worlds
* it's unlikely that they will be replaced by [[MapReduce]] or [[Hadoop]] 


=== Language ===
For Data Warehousing purposes we can use 
* standard SQL (joins, group by, etc)
* ROLAP - SQL extensions for [[OLAP]] (group by cube, ect)
* Queries are ad-hoc


=== Performance ===
Data Warehouses (especially expensive solutions) are very effective performance-wise.

There are a lot of techniques for speeding up query executions
* [[View Materialization|Materialized Views]]
* [[Multi-Dimensional Indexes]], Cube indexes, etc
* [[Physical Query Plan Optimization|Cost-Based Optimization]] based on [[Database System Catalog|database statistics]]
* parallel procession of structured data


=== Disadvantages ===
Nowadays there are lots of not structured data 
* RDBs not flexible enough to manage and analyze that
* possible solutions: [[Column-Oriented Databases]] or [[MapReduce]] (with [[Hadoop]] as implementation)

Difficult to integrate [[Data Mining]] Algorithms
* Data Mining typically happens outside of [[Relational Databases|RDBs]]

It's costly 
* costly to run scalable parallel RDBs
* need expensive specialized hardware (like IBMs Aster)

Amounts of Data
* new data arrive to fast to process


== See Also ==
* [[Hadoop]]
* http://it.toolbox.com/wiki/index.php/Data_Warehouse_Fundamentals

== Sources ==
* [[Data Warehousing (ULB)]]
* [http://www.1keydata.com/datawarehousing/data-warehouse-definition.html Data Warehouse definition]
* Ordonez et al, Relational versus non-relational database systems for data warehousing [http://www2.cs.uh.edu/~ordonez/co_research_proceedings.html]
* Paper by Cloudera and Teradata, Awadallah and Graham, Hadoop and the Data Warehouse: When to Use Which. [http://www.teradata.com/white-papers/Hadoop-and-the-Data-Warehouse-When-to-Use-Which/]


[[Category:Data Warehousing]]</text>
      <sha1>767hvl1cvb2d05ktsxfmk5r8xaxf410</sha1>
    </revision>
  </page>
  <page>
    <title>Query Processing</title>
    <ns>0</ns>
    <id>213</id>
    <revision>
      <id>214</id>
      <timestamp>2013-12-25T17:45:51Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="920">== Query Processing Pipeline ==
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/query-processing-outline.png

Steps:
# [[Translating SQL to Relational Algebra]]
# [[Logical Query Plan Optimization]]
#* finding cheaper equivalent expression:
#* translating to [[Conjunctive Query]] and simplifying it
#* applying some heuristics (pushing selections and projections, etc)
# [[Physical Query Plan Optimization]]
#* doing the cost-based assignment of [[Physical Operators (databases)|physical operators]]
#* assigning each node of Logical [[Query Plan]] a physical operator
#* for that need to know statistics from [[Database System Catalog]] 
# execution engine - for that important things are:
#* [[Physical Data Organization (databases)]]
#* [[Indexing (databases)]]


== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]
[[Category:Relational Databases]]</text>
      <sha1>56qtaxqk8h1joy20nt39aqzxtui1gr8</sha1>
    </revision>
  </page>
  <page>
    <title>Query Plan</title>
    <ns>0</ns>
    <id>214</id>
    <revision>
      <id>215</id>
      <timestamp>2013-12-25T17:51:14Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1728">== Logical Query Plan ==
In [[Relational Databases]], Logical Query Plan - intermediate code in the [[Query Processing]] pipeline (typically a [[Relational Algebra]] expression)
* Essentially it's an execution tree
* We evaluate it bottom-up
* Usually need to [[Logical Query Plan Optimization|optimize it]] before executing  to make the execution faster


=== Example ===
Suppose we have a Relational Algebra expression:
* $\pi_{A, B} \big(\sigma_{A = 5}(R) \cup (S \Join T) \big)$
* this defines the following execution tree 
: https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/logical-query-plan-ex.png


== Physical Query Plan ==
A ''Physical Query Plan'' is the same as Logical Query Plan, but with [[Physical Operators (databases)|specific algorithms]] assigned to each operation (node of the tree)
* I.e. it defines how exactly a query will be executed
* [[Query Result Size Estimation]] to estimate the size of [[Physical Operators (databases)|physical operator's]] output  
* [[Physical Query Plan Optimization]] to select the best plan


Questions to consider
* What algorithms are available to do selections, joins, projections? These algorithms are called [[Physical Operators (databases)|physical operators]] 
* each physical operator has an associated cost - number of I/O operations (in [[I/O Model of Computation]])
* It also highly depends on [[Physical Data Organization (databases)|how data is stored]]

=== Example ===
We just assign some operation to each node: 
: https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/plan-selection-bad.png


== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Relational Databases]]
[[Category:Database Systems Architecture]]</text>
      <sha1>qnb6xoc97vxp1ctc1zwak8xuge2au9w</sha1>
    </revision>
  </page>
  <page>
    <title>Pipelining</title>
    <ns>0</ns>
    <id>215</id>
    <revision>
      <id>216</id>
      <timestamp>2013-12-25T17:52:19Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1436">== Pipelining ==
Sometimes the output of one [[Physical Operators (databases)|physical operator]] can be used directly as input for other operator. This technique is called ''pipelining''.
* output of an operator is stored in a buffer that serves as input for the next operator
* results are computed as early as possible - and its as soon as enough data is available
* no need to wait unit the previous operator finishes its work 
* dramatically speeds up the execution process!


=== Operators ===
Operators that usually can be pipelined
* projections
* selections
* renaming
* bag-based union
* merge-joins for which input is known to be sorted

An operator that cannot be pipelined is called ''blocking''


=== Example ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/pipelining-ex.png
* output from index scan on $R$ can be pipelined to filter
* filter output can be pipelined to union
* union result can be pipelined to projection
* (given we have enough memory buffers available)


== Materialization ==
When we cannot pipeline, we have to ''materialize'' everything. It means we have to write all the intermediate sub-results to disk. 

* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/materialization.png
* also the next operator cannot start working until everything is materialized


== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]</text>
      <sha1>fqi92g6buzx41xjxasd8q3fowncicvm</sha1>
    </revision>
  </page>
  <page>
    <title>Data Model</title>
    <ns>0</ns>
    <id>216</id>
    <revision>
      <id>217</id>
      <timestamp>2014-02-13T17:28:29Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1540">== Data Model ==
A ''data model'' is a notation for describing data. 
* It makes sure that all applications see clean and organized data


It consists of 3 parts 
* Structure of Data
* Operations on Data 
* Data Constraints 


=== Structure of Data ===
* conceptual model (schemata, etc)
* how data should be physically organized? i.e. how is it allocated in memory
** rows and columns?
** nodes and edges?
** key-value pairs?
** sequences of bytes?


=== Operations on Data === 
* what queries are efficiently supported by this organization and what are not? 

It can be
* some limited set of queries to retrieve and modify the data
* limitation is needed to be able to describe operations at a high level

Questions to consider
* how hard it is to update or add? 
* do I reorganize the data? how hard is it? 

Examples
* find the value of key $x$
* find the rows where column &quot;Lastname&quot; is &quot;Johnson&quot;
* get the next $N$ bytes


=== Data Constraints ===
Constraints express what are the legal structured we're allowed to create 

For example
* all rows must have the same number of columns
* all values in a column must have the same type
* a child can't have two parents


== Examples ==
* [[Relational Databases#Relational Data Model|Relational Data Model]]
* [[Semi-Structured Data Model]]s: [[XML]] or JSON data models
* etc


== Sources ==
* [[Introduction to Data Science (coursera)]]
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom


[[Category:Databases]]
[[Category:Data Models]]</text>
      <sha1>s33jurmuc4k0kua8dmr379imp3c79if</sha1>
    </revision>
  </page>
  <page>
    <title>Query Plan Selection Exercises</title>
    <ns>0</ns>
    <id>217</id>
    <revision>
      <id>218</id>
      <timestamp>2013-12-26T14:26:23Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7841">Cost-Based Plan Selection exercises 
* Wiki Articles:
** [[Physical Operators (databases)]] 
** [[Physical Query Plan Optimization]] 
** [[Join Ordering]]
** [[Query Result Size Estimation]]
* exercises handout: [https://www.dropbox.com/s/9euhatg7nn1cuf2/lect7-ex-cost-based-plan-selection.pdf]
* solutions: [https://www.dropbox.com/s/ce99x2vu4u7z9kf/lect7-ex-cost-based-plan-selection-sol.pdf]

== Exercise 2 ==
Suppose we have 3 relations
* $E$(&lt;u&gt;eid: int&lt;/u&gt;, did: int, sal: int, hobby: char(20))
* $D$(&lt;u&gt;did: int&lt;/u&gt;, dname: char(20), floor:int, phone: char(10))
* $F$(&lt;u&gt;did: int&lt;/u&gt;, budget: int, sales: int, expenses: int)

Statistics and parameters:
* 2048 bytes per block, 10 memory buffers are available
* record from $E$ is 35 bytes long, from $D$ - 40 bytes, from $F$ - 15 bytes
* indexes: 
** unclustered [[B-Tree]]s on $E$.did and $D$.floor 
** clustered [[B-Tree]]s on $E$.sal, $D$.did and $F$.did
* statistics:
** $E$'s salaries are distributed uniformly within range [10 000, 60 000]
** in $E$ there are 200 distinct hobbies - $V(E, \text{hobby}) = 200$ 
** there are 2 floors 
** $T(E) = 50000, T(D) = 5000$

Select the Physical [[Query Plan]] based on [[I/O Model of Computation|I/O Cost]]

=== Query ===
$
\pi_{
  \begin{subarray}{l}
    \text{D.dname} \\
    \text{F.budget} \\
  \end{subarray}
} 
\big[
\sigma_{
  \begin{subarray}{l}
    \text{E.hobby = 'yodeling' } \land \\
    \text{E.sal } \geqslant 59000  \\
  \end{subarray}
} 
(E)
\Join
\sigma_\text{D.dloor = 1}
(D)
\Join
F
\big]
$
* logical query plan:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/plan-selection-ex-lqp.png


=== Solution Plan ===
* calculate number of blocks for each relations
* find the best plan for each selection individually
** [[Query Result Size Estimation|Estimate result size]] for each
* find the optimal [[Join Ordering]]


=== Some calculations ===
* for $E$ we can store $\left\lfloor \cfrac{2048}{35} \right\rfloor = 58$ tuples in one block
* $B(E) = \left\lceil \cfrac{50k}{58} \right\rceil = 863$
* for $D$ can store $\left\lfloor \cfrac{2048}{40} \right\rfloor = 51$ tuples in one block
* $B(D) = \left\lceil \cfrac{5k}{51} \right\rceil = 99$
* for $F$ can store $\left\lfloor \cfrac{2048}{15} \right\rfloor = 136$ tuples in one block
* $B(F) = \left\lceil \cfrac{5k}{136} \right\rceil = 37$


=== Selection 1 ===
$s_R = \sigma_{
  \begin{subarray}{l}
    \text{E.hobby = 'yodeling' } \land \\
    \text{E.sal} \geqslant 59k  \\
  \end{subarray}
} 
(E)$ 
* same as  
* $e_E \equiv \sigma_\text{E.hobby = 'yodeling'}\sigma_{\text{E.sal} \geqslant 59k} (E)$

Selectivity
* $\text{sel}_{\text{E.sal} \geqslant 59k}(E) \approx \cfrac{60k-59k}{60k-10k} \approx \cfrac{1}{50}$
* $\text{sel}_{\text{E.hobby = 'yodeling'}}(E) \approx \cfrac{1}{200}$ (200 distinct hobbies)
* it therefore produces $T(E) \times \text{sel}_{\text{E.sal} \geqslant 59k}(E) \times \text{sel}_{\text{E.hobby = 'yodeling'}}(E) = \cfrac{T(E)}{50 \times 200} = 5$ tuples  
* output can be stored in one block

ways to get the results:
# use the clustered B-Tree on $\text{E.sal}$ 
#* index scan: get records that satisfy $\text{E.sal} \geqslant 59k$
#* while doing index scan, filter records with $\text{E.hobby = 'yodeling'}$
#* cost:
#** number of accessed tuples $\text{sel}_{\text{E.sal} \geqslant 59k}(E) \times T(E) = 1000$
#** index is clustered - no need to follow each pointer (index scan)
#** $\left\lceil \cfrac{1000}{58} \right\rceil = 18$ Blocks (and therefore 18 I/Os)
# don't use the index
#* table scan on $E$ 
#* filter records that satisfy both criteria
#* cost: $B(E) = 863$ 

Note:
* filtering on hobby does not require additional I/Os (it's [[Pipelining|pipelined]])
* here we don't take index lookup cost into account (however it can be 2-3 I/Os per lookup - can increase the total I/O cost significantly if index is not clustered)

The first approach (index scan) yields better results - we will use it.


=== Selection 2 ===
$s_D = \sigma_\text{D.dloor = 1}(D)$
* selectivity: $\text{sel}_\text{D.dloor = 1} (D) = \cfrac{T(D)}{V(D, \text{floor})} = \cfrac{5000}{2} = 2500$
* output can be stored in 49 blocks

ways to get the result
# use unclustered B-Tree 
#* 2500 I/Os since the index is not clustered, need to follow each pointer
# full table scan
#* 99 I/Os 


=== [[Join Ordering]] ===
Result so far:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/plan-selection-ex-cost1.png
* now need to determine in what order we will execute the joins

Pair-wise comparison:
* $s_E \Join s_D$ 
* $s_E \Join F$
* $s_D \Join F$

Note
* we need to take into account the possibility of [[Pipelining]]
* no index on intermediate results $s_E$ and $s_D$


$s_E \Join s_D$ 
* one-pass join
** cost: $B(s_E) + B(s_D) = 1 + 50 = 51$
* can't apply index-based join
* other algorithms are always worse than these two
* result: 5 tuples (1 block)

$s_E \Join F$
* we use 1 buffer for selection of $E$ and pipeline the output to this join
** i.e. we have 9 buffers at our disposal
* can apply one-pass join 
** cost: $B(s_E) + B(F) = 1 + 37 = 38$
** here we also ignore the output cost 
** note that if these two relations had no attributes in common, it would result in a Cartesian product, and the output would be huge. Here for simplicity we do not consider the output cost,  only the I/O cost of performing the operation
* also can apply index-join (have a clustered BTree on F.did)
** cost: 1 + 5
** load $s_E$ into memory and for each tuple there look up a record block
* index-join is better
* result: 5 tuples (1 block)

$s_D \Join F$
* $M = 9$ buffers at our disposal (1 is used for pipelining from selection)
* can't use one-pass join algorithm (not enough memory)
* sort-based join
** note that $F$ is already sorted on F.did (it has a clustered index), so we need to sort only $s_D$
** also output from selection of $E$ should be already sorted ($E$ has a clustering index on E.did), but normally we don't assume anything about the intermediate results - so we also calculate in the cost of sorting
** cost: $2 B(s_D) \lceil \log_M B(s_D) \rceil + B(s_D) + B(F) = 2 \cdot 50 \cdot 2 + 50 + 37 = 287$
** we can apply the optimization: $\left\lceil \cfrac{B(s_D)}{M} \right\rceil + 1 \leqslant M = 9$
*: in this case the cost is:
*: $2 B(s_D) [\lceil \log_M B(s_D) \rceil - 1] + B(s_D) + B(F) = 187$
* hash-based join
** $k = \lceil \log_{M - 1} B(F) \rceil - 1 = 1$
** cost: $2 \cdot B(s_D) \cdot k + 2 \cdot B(F) \cdot k + B(s_D) + B(F) = 2 \cdot 50 \cdot 1 + 2 \cdot 37 \cdot 1 + 50 + 37 = 261$
* index-join (using the clustered B-Tree on F.did)
** cost: $B(s_D) + T(s_D) \times \left\lceil \cfrac{B(F)}{V(F, \text{did})} \right\rceil = 50 + 2500 \cdot \left\lceil \cfrac{37}{5000} \right\rceil = 2550$
* optimized sort-merge join is preferred


The best performing pair is $s_E \Join F$
* so we execute this join first
* and then join the results with $s_D$
* for that it's enough to have 2 memory buffers
** one for pipelining $E$ from selection
** another for one-pass join


Last join: $(s_E \Join F) \Join s_D$
* for $(s_E \Join F)$ we already use 2 buffers, therefore only 8 buffers left available
* one-pass join
** cost: $B(s_E \Join F) + B(s_D) = 1 + 50 = 51$
* all other methods always cost more that one-pass join


The last projection also can be done on the fly - without materializing anything

=== Result ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/plan-selection-ex-pqp.png
* note that we did not materialize anything:
* everything was done on the fly


== See also ==
* [[Physical Operators (databases)]]
* [[Query Result Size Estimation]]
* [[Physical Query Plan Optimization]]
* [[Join Ordering]] 
* [[B-Tree]]

== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Relational Databases]]
[[Category:Database Systems Architecture]]</text>
      <sha1>ko0kor6ma1ebxdkzn6563c21k6wyet0</sha1>
    </revision>
  </page>
  <page>
    <title>Physical Query Plan Optimization</title>
    <ns>0</ns>
    <id>218</id>
    <revision>
      <id>219</id>
      <timestamp>2013-12-26T14:21:38Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2148">== [[Query Plan#Physical Query Plan|Physical Query Plan]] Optimization ==
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/query-processing-3rd.png

Translating SQL to RA expression is the first step in [[Query Processing]] Pipeline
* Input: Optimized Logical Query plan - expression in Extended [[Relational Algebra]]
* Output: Optimized Physical Query Plan - expression in Relational algebra with each node assigned some [[Physical Operators (databases)|physical algorithm]]


== Cost-Based Plan Selection ==
We need to select the optimal plan based on 
* Cost of [[Physical Operators (databases)|Physical Operators]] and 
* on [[Query Result Size Estimation|estimated cost of subqueries]]

This is an [[Optimization Problem]]
* One of the possible approaches is [[Greedy Algorithms]]


== Greedy Algorithm ==
At each step we choose the operation with least local cost

Bottom-up approach:
* first assign physical operators to leaves 
* then to parents of the leaves 
* then to their parents 
* and so on
* at each step choose an operator that gives the lowest cost
* for join operators use a [[Join Ordering#Greedy Algorithm|gredy algorithm for join ordering]]

=== Limitations ===
Doesn't take into account the properties of the output of an operator

Consider this example:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/plan-selection-bad.png
* suppose optimized sort-merge join is not available - not enough memory
* so the Greedy algorithm decides to use hash-based join (recall that its output is not sorted)
* we could've taken slightly more expensive sort-merge join 
** but instead of 3-pass duplicate elimination we'd just need one pass for $\delta$
** which would give us overall lower total cost


== Exercises ==
{{ Main | Query Plan Selection Exercises }}


== See also ==
* [[Query Plan]]
* [[Physical Operators (databases)]]
* [[Query Result Size Estimation]]
* [[Join Ordering]]
* [[Pipelining]]

== Sources ==
* [[Database Systems Architecture (ULB)]]


[[Category:Relational Databases]]
[[Category:Database Systems Architecture]]
[[Category:Optimization]]
[[Category:Greedy Algorithms]]</text>
      <sha1>afkcwqtqxhxp59eyh4si2vfxiovu6wj</sha1>
    </revision>
  </page>
  <page>
    <title>Join Ordering</title>
    <ns>0</ns>
    <id>219</id>
    <revision>
      <id>220</id>
      <timestamp>2013-12-26T14:25:37Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4687">== Join Ordering ==
This is a part of [[Physical Query Plan Optimization]] procedure

In a Logical [[Query Plan]] the order of joins is not fixed
* there we assumed that this is a polyadic operation 

Example
* $R(A, B), S(B, C), T(C, D), U(D, A)$
* want $R \Join S \Join T \Join U$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/joins-ordering-logical.png


== Importance of Orderings ==
But [[Physical Operators (databases)#Join|physical join operators]] are binary!
* Order becomes important

how can we order these joins?
* $R \Join S \Join T \Join U \equiv$
* $((R \Join S) \Join T) \Join U \equiv$
* $(R \Join S) \Join (T \Join U) \equiv$
* $((R \Join T) \Join U) \Join S \equiv$
* $...$
* A lot! (note that natural join is possible even if there are no matching tuples)

Recall that Join is the most expensive operation
* need to carefully choose the order 

=== Example ===
* given: $R(A, B), S(B, C), T(A, E)$
* statistics:
** $B(R) = 50, B(S) = 50, B(T) = 50$
** $B(R \Join S) = 150$
** $B(S \Join T) = 2500$ ($S$ and $T$ don't have anything in common - so it's a cartesian product)
** $B(R \Join T) = 200$
* assume ideal case: everything can be done with [[Physical Operators (databases)#One-Pass Join|one-pass join]] algorithm 
** i.e. we have # of free buffers $M = 51$
* what's the best ordering for $R \Join S \Join T$?

$R \Join (S \Join T)$
* $S \Join T$ - the largest
* cost: 
** $B(R) +$ (read $B$ once)
** $B(S \Join T) +$ (too big intermediate result - need to flush to disk)
** $B(S) + B(T)$
** = 2650

$S \Join (R \Join T)$
* cost: $B(S) + B(R \Join T) + B(R) + B(T) = 350$

$(R \Join S) \Join T$
* cost: $B(T) + B(R \Join S) + B(R) + B(S) = 300$

So we see that the order is indeed important
* we want to avoid computing big subresults that we don't need afterwards


== Optimization Problem ==
=== Possibly Orderings ===
We see that we need to enumerate all possible join orderings 
* in how many ways we can put ()s?
* how many permutations are there?

$\Rightarrow$ the number of possible orderings is $n! \times T(n)$
* $n!$ - number of ways to permute $n$ relations
* $T(n)$ ways to create a binary tree over $n$ leaf nodes 
** $T(1) = 1, T(n) = \sum_{i = 1}^{n - 1} T(i) \times T(n - 1)$

The resulting space is super-exponential:

{| class=&quot;wikitable&quot;
|-
! $n$
| 2 || 3 || 4 || 5 || 6 || 7 || 8
|- 
! $n! \times T(n)$
| 2 || 12 || 120 || 1680 || 30 240 || 665 580 || 17 297 280
|}

The query optimization must not take longer than the most stupid and naive way of executing it
* so we disregard the option of trying all possible orderings and infeasible


=== Types of Ordering ===
Instead of listing all possible orderings we will consider only one of the following types 

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/joins-ordering-types.png
* (a): $((R \Join S) \Join T) \Join U$
* (b): $(R \Join S) \Join (T \Join U)$
* (c): $R \Join (S \Join (T \Join U))$

a typical query optimizer usually looks only at left-deep join orderings
* (a) $\approx$ (c), but there are subtle implementation-wise differences
* (like being able to [[Pipelining|pipeline]] some results, etc)
* still, there are $n!$ possible orderings (and it's still exponential)


This is an [[Optimization Problem]]. Solutions:
* some heuristics
* [[Branch and Bound]]
* [[Dynamic Programming]]
* [[Greedy Algorithms]]


== Greedy Algorithm ==
Always make locally optimal choices

Algorithm
* start with two relations that give the best cost
* for remaining relations choose the cheapest relation to join with the result-so-far
* repeat until there are no relations left

That generates a left-deep join ordering


=== Not Always Optimal ===
Of course since it uses some kind of [[Local Search]], it may stuck in local optima

Suppose:
* join on $R(A, B), S(B, C), T(C, D), U(A, D)$
* costs: 
** $\underbrace{B(R \Join S) = 100}_{(1)}, \underbrace{B((R \Join S) \Join T)) = 2000}_{(2)}$
** $\underbrace{B(R \Join U) = 200}_{(3)}, \underbrace{B((R \Join U) \Join T)) = 1000}_{(4)}$
* Greedy algorithm will select 
** $((R \Join S) \Join T) \Join U$
** $(1)$ gives us better cost than $(3)$
* alternative ordering:
** $((R \Join U) \Join T) \Join S$
** $(3)$ is not better than $(1)$, but $(4)$ (given $(3)$) is better than $(2)$ (given $(1)$)
** 900 I/Os saved!


== Exercises ==
{{ Main | Query Plan Selection Exercises }}


== See also ==
* [[Physical Operators (databases)]]
* [[Query Result Size Estimation]]
* [[Physical Query Plan Optimization]]

== Sources ==
* [[Database Systems Architecture (ULB)]]


[[Category:Relational Databases]]
[[Category:Database Systems Architecture]]
[[Category:Optimization]]
[[Category:Greedy Algorithms]]</text>
      <sha1>q6o36tvtc9ljd0v4eawmxt4mizmyv9t</sha1>
    </revision>
  </page>
  <page>
    <title>Query Result Size Estimation</title>
    <ns>0</ns>
    <id>220</id>
    <revision>
      <id>221</id>
      <timestamp>2013-12-26T14:31:08Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9520">== Query Result Size Estimation ==
Choosing a [[Physical Operators (databases)|physical operator]] for a [[Relational Algebra]] operator depends on
* a particular case and statistics kept in [[Database System Catalog]]
* note that this data is kept only for base relations, not for sub-results
** but we need to be able to estimate them for sub-results as well! 


https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/plan-selection-int-res.png
* note that these measures depend only on
** statistics 
** and [[Query Plan#Logical Query Plan|Logical Query Plan]] and not on [[Query Plan#Physical Query Plan|Physical Query Plan]] (no matter what [[Physical Operators (databases)|physical algorithm]] we apply we will end with exactly same result)

So the goal:
* for every internal node $n$ estimate parameters 
** $B(n)$ - the number of blocks, 
** $T(n)$ - the number of tuples,
** $V(n, A_1, ..., A_k)$ - the number of distinct values 
* note that we can compute $B(n)$ given (1) $T(n)$ (2) size of each tuple in $n$ and (3) size of a block


== Projection ==
for ''bag-based'' projection $\pi_L (R)$ the general formula is 
* $T(\pi_L (R)) = T(R)$: tuples are not eliminated
* but $B(\pi_L (R))$ can change since the size of each tuple changes

=== Example ===
Relation $R(A, B, C)$
* $A, B$ - 4 bytes int, $C$ - 100 bytes string
* each tuple has header 12 bytes 
* block size: 1024 bytes, and block header is 24 bytes 
* $T(R) = 10000, B(R) = 1250$
* how many blocks needed to store $\pi_{A,B}(R)$

Solution
* 1024 - 24 = 1000 bytes per block
* 12 + 4 + 4 = 20 bytes per projected record
* 1000 / 20 = 50 tuples per block 
* $B(\pi_{A,B}(R)) = T(\pi_{A,B}(R)) / 50 = 10000 / 50 = 200$

If size of records is [[Physical Data Organization (databases)#Variable-Length Data Records|variable]], it's harder.
* In this case usually keep some statistics to estimate the avg size of a projected record


== Selection ==
$\sigma_p(R)$ for some filtering predicate $p$ 
* estimation is $T(\sigma_p(R)) = T(R) \times \text{sel}_p (R)$
* where $\text{sel}_p (R)$ is selectivity of predicate $p$ on relation $R$ 
** or the probability that a tuple $t \in R$ will satisfy $p$ 
* calculating $\text{sel}_p$ depends on the type of predicate $p$ 

=== Equality ===
Selection $\sigma_{A = c}(R)$ where $c$ is a constant 
* $\text{sel}_{A = c} (R) = \cfrac{1}{V(R, A)}$
* where $V(R, A)$ is the number of distinct values in $R$ 
* in this case for simplicity we assume the uniform distribution of values in $R$ 

Example
* Given: $R(A, B, C)$, $T(R) = 10000$, $V(R, A) = 50$
* $T(\sigma_{A = 10}(R)) = \cfrac{T(R)}{V(R, A)} = \cfrac{10000}{50} = 200$

But typically [[Databases]] collect some statistics in the [[Database System Catalog]]

{| class=&quot;wikitable&quot;
|-
! range 
| [1, 10)  || [11, 20) || [21, 30) || [31, 40) || [41, 50) 
|- 
! # of tuples 
| 50 || 2000 || 2000 || 3000 || 2950 
|}

* suppose we have [[Database System Catalog#Equal-Width Histogram|equal-width histogram]] on $A$:
* then we can estimate $\text{sel}_{A = 10} = \underbrace{\cfrac{50}{10000}}_{50 values} \times \underbrace{\cfrac{1}{10}}_{10 possible values}$


=== Inequality ===
Selection $\sigma_{A &lt; c} (R)$ where $c$ is constant 

Suppose we don't have any statistics
* in this case we apply a simple following heuristic
** $\text{sel}_{A &lt; c} = \cfrac{1}{2} or \text{sel}_{A &lt; c}(R) = \cfrac{1}{3}$
* rationale: queries with inequalities usually retrieve a small fraction of the possible tuples, not all of them

Example 
* Given: $R(A, B, C), T(R) = 10 000$
* estimation: $T(\sigma_{B &lt; 100} (R)) = T(R) / 3 = 3334$


Better estimates are possible if we have some statistics
* Given: $R(A, B, C), T(R) = 10 000$, values of $B$ lay in range [8, 57] distributed uniformly
* Therefore $V(R, B) \leqslant 57 - 8 + 1$ - that many values of $B$ are possible
* Estimate $\text{sel}_{B &lt; 10} (R)$
* only $B = 8$ and $B = 9$ satisfy $B &lt; 10$ 
* therefore $\text{sel}_{B &lt; 10} (R) = \cfrac{2}{50} = 0.04$
* and $T(\sigma_{B &lt; 10} (R)) = T(R) \times 0.04 = 400$


=== Inequality ===
Selection $\sigma_{A \ne c} (R)$ where $c$ is constant 
* this is the inverse of $\sigma_{A = c} (R)$
* $\text{sel}_{A \ne c} (R) = \cfrac{V(R, A) - 1}{V(R, A)}$
* this is estimated probability that a tuple doesn't satisfy the predicate $A = c$


=== Inversion (Not) ===
Selection $\sigma_{\text{not}(p)} (R) $ 
* same as for Inequality
* $\text{sel}_{\text{not}(p)} (R) = 1 - \text{sel}_{p} (R)$


=== And ===
Selection $\sigma_{p_1 \land p_2} (R)$ 
* $\sigma_{p_1 \land p_2} (R) = \sigma_{p_1} \sigma_{p_2} (R) = \sigma_{p_2} \sigma_{p_1} (R)$ (order doesn't matter)
* in this case, $\text{sel}_{p_1 \land p_2}(R) = \text{sel}_{p_1}(R) \times \text{sel}_{p_2}(R)$ 
* important assumption: $p_1$ and $p_2$ are independent 
** for example, doesn't hold for $A &gt; 100 \land A &lt; 200$ - because the conditions are correlated in this case

Example
* $T(R) = 10000, V(R, A)$ = 50
* estimate $T(\sigma_{A = 10 \land B &lt; 10 (R)})$:
* $T(R) \times \text{sel}_{A = 10} (R) \times \text{sel}_{B &lt; 10} (R) = \cfrac{T(R)}{V(R, A) \times 3} = 67$


=== Or ===
Selection $\sigma_{p_1 \lor p_2} (R)$ 
* $\text{sel}_{p_1 \lor p_2} (R) = \min (\text{sel}_{p_1} (R) + \text{sel}_{p_2} (R), 1)$
** it cannot be greater than 1
* assumptions
** $p_1$ and $p_2$ are independent
** also they select disjoint sets of tuples (otherwise we would count some tuples twice)

Another way: to use De-Morgan Rule
* $p_1 \lor p_2 \equiv \overline{\overline{p_1} \land \overline{p_2}}$ (the line over means '''not''')
* $\text{sel}_{p_1 \lor p_2}(R) = 1 - (1 - \text{sel}_{p_1}(R)) \times (1 - \text{sel}_{p_2}(R))$
* in this case we also have the same assumptions


== Cartesian Product ==
$R \times S$

The general formula is:
* $T(R \times S) = T(R) \times T(S)$


== Joins ==
=== Simple Cases ===
$R \Join S, R(X, Y), S(Y, Z)$ (i.e. we join on $Y$)

# $R$ and $S$ have no tuples in common 
#* $T(R \Join S) = 0$ 
# $Y$ is a key in $S$ and a foreign key of $R$
#* each tuple of $R$ joins exactly with one tuple in $S$ 
#* $T(R \Join S) = T(R)$
# almost all tuples of $R$ and $S$ have the same $Y$ value 
#* then $T(R \Join S) \approx T(R) \times T(S)$ (degenerates to a Cartesian product)


=== One Join Attribute ===
$R \Join S, R(X, Y), S(Y, Z)$ (i.e. we join on $Y$)
* it's same as selection with predicate $R.Y = S.Y$

==== Simplifications ====
For other harder cases we need the following simplifications:

'''Containment''' of Value Sets
* if $R(V, Y) \leqslant V(S, Y)$
* then every value of $Y \in R$ will have a joining tuple with $Y \in S$
* that means: all matched values in $X$ will have a corresponding value in $Y$ - or vice-versa

'''Preservation''' of Value Sets
* when joining two relations, all non-matching attributes are not lost
* i.e. they get transfered to the results 
* (if we join two relations on $Y$, $R$ has $X$ and $S$ has $Z$, then all possible values are going to occur in the output)
* i.e. $V(R \Join S, X) = V(R, X)$ and $V(R \Join S, Z) = V(S, Z)$

Under there simplification we will consider two cases 

==== Case 1 ====
$V(R, Y) \leqslant V(S, Y)$ (say one-to-many relationship)
* every tuple if $R$ has a match is $S$ by the containment assumption
* or each tuple in $R$ has $\approx \cfrac{T(S)}{V(S, Y)}$ tuples in $S$ (assuming uniform distribution)
* therefore $T(R \Join S) = T(R) \times \cfrac{T(S)}{V(S, Y)}$

==== Case 2 ====
$V(R, Y) \geqslant V(S, Y)$ (say many-to-one relationship)
* each tuple in $S$ has $\approx \cfrac{T(R)}{V(R, Y)}$ tuples in $R$
* therefore $T(R \Join S) = T(S) \times \cfrac{T(R)}{V(R, Y)}$

==== General Case ====
$T(R \Join S) = \cfrac{T(S) \times T(R)}{\min(V(R, Y), V(S, Y))}$


=== More Join Attributes ===
Now assume that we join on two attributes $Y_1, Y_2$:
* $R(X, Y_1, Y_2) \Join S(Y_1, Y_2, Z)$
* (under the same assumptions)
* same as selection with predicate with AND: $R.Y_1 = S.Y_1 \land R.Y_2 = S.Y_2$ 

==== Case 1 ====
$V(R, Y_1) \leqslant V(S, Y_1)$ and $V(R, Y_2) \leqslant V(S, Y_2)$
* a tuple in $R$ has $\cfrac{1}{V(S, Y_1)} \times \cfrac{1}{V(S, Y_2)}$ chance of joining with a tuple in $S$ 
** (again assuming uniform distribution)
* therefore $T(R \Join S) = T(R) \times \cfrac{T(S)}{V(S, Y_1) \times V(S, Y_2)}$

==== Case 2 ====
$V(S, Y_1) \leqslant V(R, Y_1)$ and $V(S, Y_2) \leqslant V(R, Y_2)$
* symmetric to Case 1
* chance of tuple from $S$ joining with $R$ is $\cfrac{1}{V(R, Y_1)} \times \cfrac{1}{V(R, Y_2)}$
* therefore $T(R \Join S) = T(S) \times \cfrac{T(R)}{V(R, Y_1) \times V(R, Y_2)}$

==== Case 3 ====
$V(R, Y_1) \leqslant V(S, Y_1)$ but $V(S, Y_2) \leqslant V(R, Y_2)$
* chance of tuple from $R$ joining with $S$ is $\cfrac{1}{V(R, Y_1)} \times \cfrac{1}{V({\color{blue}{S}}, Y_2)}$
* therefore $T(R \Join S) = T(R) \times \cfrac{T(S)}{V(R, Y_1) \times V(S, Y_2)}$

==== Case 4 ====
$V(S, Y_1) \leqslant V(R, Y_1)$ but $V(R, Y_2) \leqslant V(S, Y_2)$
* chance of tuple from $R$ joining with $S$ is $\cfrac{1}{V({\color{blue}{S}}, Y_1)} \times \cfrac{1}{V(R, Y_2)}$
* therefore $T(R \Join S) = T(R) \times \cfrac{T(S)}{V(S, Y_1) \times V(R, Y_2)}$

==== General Formula ====
$T(R \Join S) = \cfrac{T(R) \times T(S)}{\max(V(R, Y_1), V(S, Y_1) \times \max(V(R, Y_2), V(S, Y_2)}$

This formula generalizes to more than 2 joining attributes


== See also ==
* [[Database System Catalog]]
* [[Relational Algebra]]
* [[Physical Operators (databases)]] 

== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]
[[Category:Relational Databases]]</text>
      <sha1>ptsqxkvbif8pe80k4zcfyl39ofol7vz</sha1>
    </revision>
  </page>
  <page>
    <title>Dot for Petri Nets</title>
    <ns>0</ns>
    <id>221</id>
    <revision>
      <id>222</id>
      <timestamp>2014-02-02T11:17:13Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5059">Dot for [[Petri Nets]]

== Simplest Petri Net ==
&lt;pre&gt;
digraph G {
  rankdir=LR;
  center=true; margin=1; 
  subgraph place {
    node [shape=circle,fixedsize=true,label=&quot;&quot;, height=.3,width=.3];
    # i [label=&quot;&amp;bull;&quot;, fontsize=20];
    p1, p2;
  }
  subgraph transitions {
    node [shape=rect,height=0.4,width=.4];
    t1 [label=&lt;t&lt;SUB&gt;1&lt;/SUB&gt;&gt;];
  }
  
  p1-&gt;t1-&gt;p2;
}
&lt;/pre&gt;

http://habrastorage.org/files/5f9/02c/cbd/5f902ccbdb4243f0b8ded50791a67159.png


== Nodes Alignment ==
&lt;pre&gt;
digraph G {
  rankdir=LR;
  subgraph place {
    node [shape=circle,fixedsize=true,label=&quot;&quot;,height=.3,width=.3];
    i [label=&quot;&amp;amp;bull;&quot;, fontsize=20];
    o; p1; p2;
  }
  subgraph transitions {
    node [shape=rect,height=0.4,width=.4];
    a; b; c; d; e; f;
  }

  # align horizontally
  {edge [weight=2]; i-&gt;a-&gt;p1; p2-&gt;f-&gt;o;}

  p1-&gt;c-&gt;p2;
  p2-&gt;d-&gt;p1;
  i-&gt;e-&gt;p2;
  p1-&gt;b-&gt;o; 
  # align vertically
  {rank=same; b;c;d;e;}  
}
&lt;/pre&gt;

http://habrastorage.org/files/2b5/6cf/d24/2b56cfd24a924d05b6e4d823971535cd.png


== Red Color and Alignment ==
&lt;pre&gt;
digraph G {
  rankdir=LR;
  ranksep=0.3;
  subgraph place {
    node [shape=circle,fixedsize=true,label=&quot; &quot;,height=.3,width=.3];
    i [label=&quot;&amp;amp;bull;&quot;, fontsize=20];
    p6 [color=red];
    o; p1; p2; p3; p4; p5; 
  }
  subgraph transitions {
    node [shape=rect,height=.4,width=.4];
    a; b; c; d; e; f;
  }

  i -&gt; a -&gt; p1 -&gt; b -&gt; p3 -&gt; d -&gt; o;
  a -&gt; p2 -&gt; c -&gt; p4 -&gt; d;
  i -&gt; e; f-&gt;o;
  e -&gt; p5 -&gt; f [weight=2]; # makes it straight
  a -&gt; p6 -&gt; d [color=red];

  {rank=same;p5;p6;b;c;}
}
&lt;/pre&gt;

http://habrastorage.org/files/aa7/b07/5fe/aa7b075fe4984ae7af0640a62e52f285.png


== Clusters ==
Using keyword &lt;code&gt;cluster&lt;/code&gt; before name of a subgraph

&lt;pre&gt;
digraph G1 {
  rankdir=LR;
  subgraph place {
    node [shape=circle,fixedsize=true,label=&quot; &quot;,height=.3,width=.3];
    p1;
  }
  subgraph transitions {
    style=&quot;rounded,dashed&quot;;
    color=red;
    node [shape=rect,height=.4,width=.4];
    subgraph cluster_a {
      label=&quot;A&quot;;
      a;b;        
    }
    subgraph cluster_b {
      label=&quot;B&quot;;
      c;d;
    }
  }

  {a,b}-&gt;p1-&gt;{c,d};
}
&lt;/pre&gt;

http://habrastorage.org/files/719/a01/946/719a019467fa4637b85191631e22abe4.png


== Records ==
Special shape: record

&lt;pre&gt;
digraph G1 {
  rankdir=LR;
  s1 [style=&quot;invisible&quot;, shape=record, label=&quot;&lt;0&gt;|&lt;1&gt;||&lt;2&gt;|&lt;3&gt;&quot;];
  s2 [style=&quot;invisible&quot;, shape=record, label=&quot;&lt;0&gt;|&lt;1&gt;||&lt;2&gt;|&lt;3&gt;&quot;];
  
  subgraph place {
    node [shape=circle,fixedsize=true,label=&quot; &quot;];
    p1;p2;
  }
  subgraph transitions {
    node [shape=rect,height=.5,width=.5];
    a;
  }

  s1:0-&gt;p1 [color=red];
  s1:1-&gt;p1;
  {p1, p2}-&gt;a;
  s1:2-&gt;p2;
  s1:3-&gt;p2 [color=red];
  a-&gt;s2:2;
  a-&gt;s2:3;
}
&lt;/pre&gt;

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/not-allowed-1.png

&lt;pre&gt;
digraph G2 {
  rankdir=LR;
  s1 [style=&quot;invisible&quot;, shape=record, label=&quot;&lt;0&gt;|&lt;1&gt;||&lt;2&gt;|&lt;3&gt;&quot;];
  s2 [style=&quot;invisible&quot;, shape=record, label=&quot;&lt;0&gt;|&lt;1&gt;||&lt;2&gt;|&lt;3&gt;&quot;];
  
  subgraph place {
    node [shape=circle,fixedsize=true,label=&quot; &quot;];
    p1;
  }
  subgraph transitions {
    node [shape=rect,height=.5,width=.5];
    a;b;
  }

  s1:0-&gt;a [color=red];
  s1:1-&gt;p1;
  s1:2-&gt;p1;
  p1-&gt;{a, b};
  s1:3-&gt;b [color=red];
  a-&gt;s2:0;
  a-&gt;s2:1;
  b-&gt;s2:2;
  b-&gt;s2:3;
}
&lt;/pre&gt;

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/not-allowed-2.png

== Candy Storage (neato) ==
&lt;pre&gt;
digraph G {
  center=true; margin=1; 
  normalize=true;
  subgraph place {
    node [shape=circle,fixedsize=true,label=&quot;&quot;, height=.3,width=.3];
    p1, p2, p3, p4, p5;
  }
  subgraph transitions {
    node [shape=rect,height=0.4,width=.4, rotate=90];
    refill;
    disp [label=&quot;dispence\ncandy&quot;];
    rej [label=&quot;reject\ncoin&quot;];
    ins [label=&quot;insert\ncoin&quot;];
    ac [label=&quot;accept\ncoin&quot;];
  }

  refill-&gt;p1-&gt;disp-&gt;p3-&gt;ins-&gt;p4-&gt;ac-&gt;p5-&gt;disp-&gt;p2-&gt;refill;
  p4-&gt;rej-&gt;p3;
  rej-&gt;p5 [style=invis]; 
}
&lt;/pre&gt;


http://habrastorage.org/files/69c/8b7/2b4/69c8b72b47f540399701f3a4ed6b6b9f.png


== [[Reachability Graph]] ==
&lt;pre&gt;
digraph G {
  center=true; margin=1; 

  fontsize=12;
  normalize=true;
 
  edge [len=1.3, minlen=1];
  node [shape=none, fixedsize=true];

  i [label=&quot;[i]&quot;];
  p1 [label=&lt;&amp;amp;#91;p&lt;SUB&gt;1&lt;/SUB&gt;, p&lt;SUB&gt;5&lt;/SUB&gt;&amp;amp;#93;&gt;];
  p2 [label=&lt;&amp;amp;#91;p&lt;SUB&gt;2&lt;/SUB&gt;, p&lt;SUB&gt;5&lt;/SUB&gt;&amp;amp;#93;&gt;];
  p3 [label=&lt;&amp;amp;#91;p&lt;SUB&gt;3&lt;/SUB&gt;, p&lt;SUB&gt;5&lt;/SUB&gt;&amp;amp;#93;&gt;];
  p4 [label=&lt;&amp;amp;#91;p&lt;SUB&gt;1&lt;/SUB&gt;, p&lt;SUB&gt;6&lt;/SUB&gt;&amp;amp;#93;&gt;];
  p5 [label=&lt;&amp;amp;#91;p&lt;SUB&gt;2&lt;/SUB&gt;, p&lt;SUB&gt;6&lt;/SUB&gt;&amp;amp;#93;&gt;];
  p6 [label=&lt;&amp;amp;#91;p&lt;SUB&gt;3&lt;/SUB&gt;, p&lt;SUB&gt;6&lt;/SUB&gt;&amp;amp;#93;&gt;];
  p7 [label=&lt;&amp;amp;#91;p&lt;SUB&gt;4&lt;/SUB&gt;&amp;amp;#93;&gt;];
  o [label=&quot;[o]&quot;];

  i-&gt;p1 [label=x];
  p1-&gt;p2 [label=a];
  p2-&gt;p5 [label=d];
  p5-&gt;p2 [label=e];
  p1-&gt;p3 [label=b];
  p3-&gt;p6 [label=d];
  p6-&gt;p3 [label=e];
  p1-&gt;p4 [label=d];
  p4-&gt;p1 [label=e];
  p4-&gt;p5 [label=b];
  p4-&gt;p6 [label=a];
  p7-&gt;o [style=invis];
  p4-&gt;{o, p7} [style=invis];
}
&lt;/pre&gt;

http://habrastorage.org/files/904/16d/d88/90416dd883c54d8c8412b31da4fe7274.png


[[Category:Business Process Management]]
[[Category:Petri Nets]]
[[Category:Dot]]
[[Category:Snippets]]</text>
      <sha1>n41jfg56ywjg6zmxu7uyqxne843glc6</sha1>
    </revision>
  </page>
  <page>
    <title>Alpha Algorithm</title>
    <ns>0</ns>
    <id>222</id>
    <revision>
      <id>223</id>
      <timestamp>2014-02-02T12:35:02Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15925">== Alpha Algorithm ==
$\alpha$ algorithm one of the first [[Process Mining]] algorithm that discovers [[Workflow Nets]] (in form of [[Petri Nets]]) from logs 


The process of (re-)discovering a workflow consists of 3 phases:
* pre-processing
** inferring relations between the transitions
* processing
** execution of the alpha algorithm
* post-processing


== Definitions ==
=== Implicit Places ===
One important caveat: implicit places. A place is ''implicit'' if adding or removing it does not cause the behavior of a workflow. 

Example
* This workflow does not contain any implicit places
*: https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/impl-places-no.png
* but if we connect $a$ and $d$ with a new place - this place will be implicit
*: https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/implicit-places.png


These places cannot be seen from the logs since they have no affect on the behavior 
* typically mining algorithm cannot find such places 


=== Complete Log ===
We assume that the log we feed into this algorithm is complete.

A log of a workflow net $N$ is ''complete'' if
* if it contains all other possible logs of $N$
* it contains all transitions $t$ from this $N$ 


For example,
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/impl-places-no.png
* for this workflow the complete log is $[abcd, acbd, ef]$ - it covers all possible traces 


== The Alpha Algorithm ==
=== Relations ===
In order to find discover a workflow net from logs, we need to establish the ordering between the transitions of this workflow. These relations will later be used in order to find places and connection between the transitions and these places. 


We define the following relations between transitions in the log
* ''direct succession'' $x &gt; y$ 
** $x &gt; y \iff$ we see in log sub-traces $...xy...$
* ''causality'' $x \to y$
** $x \to y \iff x &gt; y \land y \not &gt; x$
** i.e. if there are traces $...xy...$ and no traces $...yx...$
** this relation may mean that we will need to put a place between $x$ and $y$
* ''parallel'' $x \ || \ y$
** $x \ || \ y \iff x &gt; y \land y &gt; x$
** i.e. can see both $...xy...$ and $...yx...$
** cannot put a place for such $x$ and $y$ - if we placed, we'd impose some order on them
** this is symmetric relation ($a \ || \ b \to b \ || \ a$)
* ''unrelated'' $x \ \# \ y$
** $x \ \# \ y \iff x \not &gt; y \land y \not &gt; x$
** i.e. there are no traces $...xy...$ nor $...yx...$
** this is also symmetric relation $x \ \# \ y \to y \ \# \ x$


The set of all relations for a log $L$ 
* is called the ''footprint'' of $L$



==== Example ====
For example,
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/impl-places-no.png
* the log is $L_1 = [abcd, acbd, ef]$
* $a &gt; b, a &gt; c, b &gt; c, b &gt; d, c &gt; b, c &gt; d, e &gt; f$
* $a \to b, a \to c, b \to d, c \to d, e \to f$
* $b \ || \ c$


Consider another example:
* $L_2 = [abcd, acbd, aed]$
* The footprint can be represented with a table
* in rows we have the left-hand-side operand, in columns - the right-hand-side operand

{| class=&quot;wikitable&quot;
! || $a$ || $b$ || $c$ || $d$ || $e$ 
|-
! $a$ 
| $\#$ || $\to$ || $\to$ || $\#$ || $\to$
|-
! $b$ 
| $\leftarrow$ || $\#$ || $||$ || $\to$ || $\#$ 
|-
! $c$ 
| $\leftarrow$ || $||$ || $\#$ || $\to$ || $\#$ 
|-
! $d$ 
| $\#$ || $\leftarrow$ || $\leftarrow$ || $\#$ || $\leftarrow$ 
|-
! $e$ 
| $\leftarrow$ || $\#$ || $\#$ || $\to$ || $\#$ 
|}



=== $\alpha$ Algorithm ===
With these relations we define the $\alpha$ algorithm as follows.

$\alpha(L):$
* extract all transition names from $L$ to set $T$
* let $T_I$ be the set of all initial transitions and $T_O$ the set of all end transitions
* find all pairs of sets $(A, B)$ such that 
** $t_A \in A$ should be connected to all $t_B \in B$ via some place $p$ 
** $\forall a \in A$ and $\forall b \in B$ holds that $a \to b$
** $\forall a_1, a_2 \in A: a_1 \ \# \ a_2$ and $\forall b_1, b_2 \in B: b_1 \ \# \ b_2$
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/alpha-4-AB.png
** in this example: $a \ \# \ b, c \ \# \ d, a \to c, a \to d, b \to c, b \to d$
** in other words: all transitions from $A$ put tokens to the place $p$, and transitions of $B$ take tokes from $p$
* once found all such sets, we retain only the maximal ones
** a ''maximal set'' contains the maximal possible number of elements that can be connected via single place
* for each such pair $(A, B)$ we connect all elements from $A$ with all elements from $B$ with one single place $p_{(A, B)}$ 
* then we also connect appropriate transitions with the input and output places
* finally we connect the start place $i$ to all transitions from $T_I$
* and all transitions from $T_O$ with the final state $o$


==== Example ====
for the log $L_2 = [abcd, acbd, aed]$ the footprint is

{| class=&quot;wikitable&quot;
! || $a$ || $b$ || $c$ || $d$ || $e$ 
|-
! $a$ 
| $\#$ || $\to$ || $\to$ || $\#$ || $\to$
|-
! $b$ 
| $\leftarrow$ || $\#$ || $||$ || $\to$ || $\#$ 
|-
! $c$ 
| $\leftarrow$ || $||$ || $\#$ || $\to$ || $\#$ 
|-
! $d$ 
| $\#$ || $\leftarrow$ || $\leftarrow$ || $\#$ || $\leftarrow$ 
|-
! $e$ 
| $\leftarrow$ || $\#$ || $\#$ || $\to$ || $\#$ 
|}


* $T_I$: the set of all first transitions in the log, 
** in the table, for such transitions we don't have any incoming edges
** i.e. it has only $\leftarrow$, no $\to$ in its column
** $T_I = \{a\}$
* $T_O$: the set of all last transitions in the log
** no outcoming edges, only incoming - in the rows
** $T_O = \{d\}$

With this table, using $\to$ and $||$ relations we can draw the following graph:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-alpha-ex-graph.png
* (a directed edge represents $\to$ relation, undirected double edge represents $||$)

Now with this graph can enumerate the maximal sets $A$ and $B$ 
* recall that for sets $A$ and $B$ 
** $\forall a_1, a_2 \in A: a_1 \ \# \ a_2$
** $\forall b_1, b_2 \in B: b_1 \ \# \ b_2$
** $\forall a_1 \in A, \forall b_1 \in B: a_1 \to b_1$

{| class=&quot;wikitable&quot;
! || $A$ || $B$ 
|-
! (1) 
| $\{a\}$ || $\{b, e\}$
|-
! (2) 
| $\{a\}$ || $\{c, e\}$
|-
! (3) 
| $\{b,e\}$ || $\{d\}$
|-
! (4) 
| $\{c,e\}$ || $\{d\}$
|}

Note that $b$ and $c$ cannot belong to the same set 
* they are parallel

Based on these sets 
* we add 4 places for each pair $(A, B)$ to connect all elements from $A$ with all elements from $B$ with one place
* and we add 2 more places: the start place $i$ and the final state $o$


{| class=&quot;wikitable&quot;
! || $A$ || $B$ ||
|-
! $p_1$ 
| $\{a\}$ || $\{b, e\}$ || https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-alpha-ex-pl1.png
|-
!  $p_2$ 
| $\{a\}$ || $\{c, e\}$ || https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-alpha-ex-pl2.png
|-
! $p_3$ 
| $\{b,e\}$ || $\{d\}$ || https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-alpha-ex-pl3.png
|-
! $p_4$  
| $\{c,e\}$ || $\{d\}$ || https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-alpha-ex-pl4.png
|}

So we have:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-alpha-ex-complete.png



== Limitations ==
There are some limitations of the $\alpha$ algorithm.

=== Loops of Length One === 
If there are short loops of length one, $\alpha$ cannot re-discover them. 

suppose we have the following log
* $[ac, abc, abbc, abbbc]$
* model that generated this log:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/short-loop-1-orig.png

but here is what $\alpha$ finds:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/short-loop-1-res.png

reason
* the step for finding sets $A$ and $B$
* in this case we want that $b \in A$ and $b \in B$
* but it cannot happen because $b \ \not \# \ b$


=== Loops of Length Two ===
If there are short loops of length two, $\alpha$ cannot re-discover them either.

suppose we have the following log
* $[abd, abcbd, abcbcbd]$
* model that generated this log:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/short-loop2-orig.png

but here is what $\alpha$ finds:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/short-loop2-res.png

reason
* here we think that $b \ || \ c$, since $b &gt; c$ and $c &gt; b$
* but it's not the case 


=== Other Loops ===
No problems


=== Non-Local Dependencies ===
Non-Local dependencies results from some process constraints. 
* These constraints cannot be captured by the $\alpha$ algorithm
* They are not visible in the logs!
* (It's actually the problem of many [[Process Mining]] algorithms, not just $\alpha$)


For example, 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/non-local-dependencies.png
* log: $[acd, bce]$
* If I came to work by car ($p_1$) - I will leave by car 
* If I came to work by train ($p_2$) - I will leave by train
* the blue places represent non-local dependencies that will not be discovered 


In general, the constraints the difficult constraints are:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/not-allowed-1.png
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/not-allowed-2.png

We want to avoid such constructs in out workflow nets because they cannot be discovered.


A workflow net belongs to ''Structured Workflow Net'' (SWF) class of workflow nets if
* it doesn't have such constructions
* it has no implicit places

$\alpha$ mines all SWF nets except for ones with short loops



== The Alpha Plus Algorithm ==
$\alpha^+$ handles short loops 

=== Loops of Length 2 ===
First, let's have a look at loops of length 2. 

Recall our example: 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/short-loop2-orig.png
* $[abd, abcbd, abcbcbd]$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/short-loop2-res.png

We see that the problem with these loops is incorrect assumption that $b || c$. 
* because from the logs we see that $b &gt; c$ and $c &gt; b$, therefore we cannot cay $b \to c$ based on the defined relations
* need to define new relations that can capture such behavior


We need another notion of log completeness to handle such loops:

for a workflow net $N$ a log is loop-complete if
* it is complete 
* there's enough information to detect loops of length two (i.e. we see sequences of $...t_1 t_2 t_1...$ s.t. $t_1 \ne t_2$)

Example
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/short-loop2-2-orig.png
* a loop-compete log in this case contain one or more traces with $...cdc...$ and $...dcd...$


=== New Ordering Relations ===
Recall that we need to be able to distinguish $a \to b$ and $a \ || \ b$, which is not possible for loops of length 2 with the old notion of these relations. 


Same as previously
* $a &gt; b \iff$ we see trace $...ab...$
* $a \ \# \ b \iff a \not &gt; b \land b \not &gt; a$

New relations
* $a \ \triangle \ b \iff$ there is a subsequence $...aba...$ in the logs
* $a \ \diamondsuit \ b \iff$ there are sequences $...aba...$ and $...bab...$


And we redefine the relations that cause the error 
* $a \to b \iff a &gt; b \land (b \not &gt; a \lor a \ \diamondsuit \ b)$
** this way we can correctly identify the ''follow'' relation when there's a loop of length 2
* $a \ || \ b \iff a &gt; b \land b &gt; a \land a \ \not \diamondsuit \ b$
** by adding the last condition way we don't misidentify the ''parallel'' relation 


However, there's one caveat. Short loops of length one also can produce such sequences  
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/short-loop1-problem-for2.png
* therefore at this step we assume that the net is ''one-loop-free'' - i.e. it does not contain loops of length 1
* if it's not the case, we can turn our worflow net into ''one-loop-free'' by removing all transitions that create these loops. we discuss below why it is possible.  
* we will address this problem during pre-procession step
* also note that for one-loop-free workflow nets $a \ \triangle \ b \Rightarrow b \ \triangle \ a$


=== Loops of Length 1 ===
a transition is ''one-loop'' transition if it participates in a loop of length 1 

Properties 
* one-loop transition cannot be connected to the input or output places (otherwise such a network would not be a workflow net) 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/short-loop1-output-not-wf.png https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/short-loop1-input-not-wf.png


We can safely remove such a transition from a workflow net
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/short-loop1-can-remove.png
* it will clearly not affect other transitions and the net will remain sound
* we can proof this statement by checking the reachability graph of the net with these transitions and without them - in both cases the states of a graph will be the same

For example:
* consider the net above
* if we remove transition $a$, we will get the following [[Reachability Graph]]
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/alpha-one-loop-remove-rg.png


Idea: 
* handle these transitions during pre- and post-processing stages
* identify ''one-loop'' transition $t$ by searching for patterns like $...tt...$

determine the places $p$ to which it should be connected 
to do it we check: 

what are the transitions $a$ s.t. 
* $t &gt; a \land a \not &gt; t$ 
** i.e. transitions $a$ that are followed by $t$, but don't follow $t$ themselves
** $p$ should be an input place for $a$ and output place for $t$
* $b &gt; t \land t \not &gt; b$ 
** transitions $b$ that follow $t$, but are not followed by $t$ 
** $p$ should be an output place for $b$ and input place for $t$ 



=== $\alpha^+$ Algorithm ===
$\alpha^+(W)$:
* let $T$ be all transitions found in the log $W$
* identify all one-loop transitions and put them into set $L1L$
* let $T'$ be all non-one-loop transitions: $T' \leftarrow T - L1L$
* let $F_{L1L}$ be the set of all arcs to transitions from $L1L$
*: it consists of:
** all transitions $a$ that happen before $t$: $a \in T'$ s.t. $a &gt; t$
** all transitions $b$ that happen after $t$: $b \in T'$ s.t. $t &gt; b$
* now remove all occurrences of transitions $t \in L1L$ from the log $W$, let the result be $W^{-L1L}$
* run the $\alpha$ algorithm on $W^{-L1L}$: $\alpha(W^{-L1L})$
* reconnect one-loop transitions back: add all transitions and from $L1L$ and arcs from $F_{L1L}$ to transitions and arcs discovered by $\alpha$



=== Examples of Petri Nets ===
Examples of petri-nets that $\alpha^+$ can re-discover (and $\alpha$ cannot):
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/short-loop1-problem-for2.png
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/short-loop2-orig.png
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/short-loop-can-mine.png



=== Conclusions ===
There have been made some assumptions:
* perfect information (the log completeness)
* absence of noise in the logs 

usually it's not the case in real life and different mining algorithms should be used
* such as [[Genetic Miner]]


== Examples ==
* The [[Housing Agency Workflow]] was successfully re-discovered with the $\alpha^+$ algorithm


== Links ==
* [https://docs.google.com/document/d/1JtuECbGZ3DusNpmBZhXeq8R_UPCRU5V7NG8GL17h1aA/pub BPM project: the $\alpha^+$ algorithm]

== Sources ==
* Medeiros, van Dongen, van der Aalst and Weijters. Process Mining: Extending the alpha-algorithm to Mine Short Loops, 2004 [http://www.processmining.org/blogs/pub2004/process_mining_extending_the_alpha-algorithm_to_mine_short_loops]
* van der Aalst. Process Mining: Discovery, Conformance and Enhancement of Business Processes, 2011 [http://www.processmining.org/book/start]
* [[Business Process Management (ULB)]]


[[Category:Business Process Management]]
[[Category:Process Mining]]</text>
      <sha1>qmvtjjj5qu9eyj6oh0ak8r4ccatbep5</sha1>
    </revision>
  </page>
  <page>
    <title>Atomicity (databases)</title>
    <ns>0</ns>
    <id>223</id>
    <revision>
      <id>224</id>
      <timestamp>2014-01-01T21:05:42Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="565">== Atomicity ==
''Atomicity'' is a desired property of a transaction according to [[ACID]]
* a transaction should be either executed completely - or not executed at all
* If it executed - it takes database from one [[Consistency (databases)|consistent]] state to another
* if not executed - it takes database back to the consistent state it was before execution
* It's especially important when dealing with [[Crash Recovery]]

Ways to ensure Atomicity:
* [[Database Transaction Log]]

== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Databases]]</text>
      <sha1>kfq338nu01nku2dnxl1tjdh56ix1cbx</sha1>
    </revision>
  </page>
  <page>
    <title>Crash Recovery</title>
    <ns>0</ns>
    <id>224</id>
    <revision>
      <id>225</id>
      <timestamp>2014-01-01T21:07:10Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2157">== Crash Recovery ==
=== Failure Model ===
Events can be: desired (things that are supposed to happen) and undesired

Undesired events can be:
* expected - we know that they may occur so we guard against them
** system crashes: memory lost, CPU halts, etc
* unexpected
** everything else

=== [[Memory Hierarchy]] ===
Recall that 
* we may be operating on things in memory that have not been flushed to disk yet
* suppose the power is cut - this means these changes are lost  
* if only a part of transaction was written to disk - the database is left in in[[Consistency (Databases)|consistent]] state

=== Operations ===
Under this model we define the following operations:
* input($x$) load block containing $x$ into memory
* output($x$) flush the block containing $x$ to disk
* read(database object $x$, variable $t$)
** load $x$ to memory if not already there (input($x$))
** write value from $x$ to $t$
* write(database object $x$, variable $t$)
** input($x$) if $x$ not in memory
** replace value of $x$ by $t$ (in memory) - no output to disk yet
** read and write operate on variables and buffers in memory


=== Unfinished Transaction ===
This is the key problem we want to address 

Example
* suppose we have two database items $A$ and $B$ and constraint $A = B$ 
* $T_1 = A \leftarrow A \times 2; B \leftarrow B \times B$
* on low level:
** (1) read($A, t$); $t \leftarrow t \times 2$;
** (2) write($A, t$); 
** (3) read($B, t$); $t \leftarrow t \times 2$;
** (4) write($B, t$); 
** (5) output($A$)
** (6) output($B$)

suppose a crash happens between (5) and (6)
* when we get the database back to work, it's not in a consistent state:
* $A \ne B$: 
** the new results of $A$ was written to disk and it contains 16
** the new results of $B$ was not written to disk and it contains 8
** the constraint is not satisfied 

Usually deal with it with [[Database Transaction Log]] (e.g. [[Undo/Redo Logging]])


== See also ==
* [[ACID]]: [[Consistency (databases)]] and [[Durability (databases)]]
* [[Database Transaction Log]]
* [[Undo/Redo Logging]]

== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]</text>
      <sha1>nvao1tc0mz30v3hw78j6ijl00owo1mj</sha1>
    </revision>
  </page>
  <page>
    <title>Durability (databases)</title>
    <ns>0</ns>
    <id>225</id>
    <revision>
      <id>226</id>
      <timestamp>2014-01-01T21:07:58Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="659">== Durability ==
One of the [[ACID]] properties of transactions. It says if a transaction has committed, then it should be permanently persisted on disk, even if a crash occurs

Techniques for [[Crash Recovery]] are usually [[Database Transaction Log]]s:
* [[Undo Logging]]
* [[Redo Logging]]
* [[Undo/Redo Logging]]

In [[Distributed Databases]] for distributed transactions there are also some protocols for ensuring durability:
* [[Two-Phase Commit]] 

== Sources ==
* [[Database Systems Architecture (ULB)]]
* [http://en.wikipedia.org/wiki/Durability_%28database_systems%29 Durability (database systems)]

== See also ==
* [[ACID]]

[[Category:Databases]]</text>
      <sha1>j47z99phh2go9u9j8wlr7qoa2cn795d</sha1>
    </revision>
  </page>
  <page>
    <title>Database Transaction Log</title>
    <ns>0</ns>
    <id>226</id>
    <revision>
      <id>227</id>
      <timestamp>2014-01-01T21:09:28Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="474">== Database Transaction Log ==
A way to ensure [[Atomicity (databases)|atomicity]], [[Consistency (databases)|consistency]] and [[Durability (databases)|durability]] in [[Database]]s
* Important for [[Crash Recovery]]

=== Types of Loggings ===
* [[Undo Logging]]
* [[Redo Logging]]
* [[Undo/Redo Logging]]


== Exercises ==
{{ Main | Database Transaction Log Exercises }}


== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]</text>
      <sha1>hbvg3vmz3fe0dqdd7a23mxwi2o94yqm</sha1>
    </revision>
  </page>
  <page>
    <title>Undo Logging</title>
    <ns>0</ns>
    <id>227</id>
    <revision>
      <id>228</id>
      <timestamp>2014-01-01T21:11:51Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11515">== Undo Logging ==
This is a [[Database Transaction Log]] for dealing with [[Crash Recovery]]

=== Idea ===
Hansel and Gretel
* poor parents dropped the children in the forest
* the children trace the steps they take and recover the path back to parents 

The same in databases:
* we keep a log of things we do
* but the [[Memory Hierarchy]] changes a little bit: 
* additionally to Main Memory and [[Secondary Storage]] we now have Log

Undo Logging or ''Immediate Modification'' log
* before writing anything to disk, we record the &lt;u&gt;old value&lt;/u&gt; to the log
* and only after that write 

=== Example ===
So the way we do it is:
* we allow to modify things in memory 
* while modifying them we create corresponding records in the log that keeps the old value 
* all the log records have to already be on disk before writing database items back to disk

Example 

{| class=&quot;wikitable&quot;
! Transaction $T_1$ || Log || Comment
|-
|   || $\langle T_1, \text{start} \rangle$ || when the transaction starts
|- 
| read($A, t$); $t \leftarrow t \times 2$; ||  ||
|- 
| write($A, t$) || $\langle T_1, A, 8 \rangle$ || now it's allowed to output($A$)
|-
| read($B, t$); $t \leftarrow t \times 2$; || ||
|- 
| write($B, t$) || $\langle T_1, B, 8 \rangle$ || now it's allowed to output($B$)
|-
| output($A$) || ||
|-
| output($B$) || || now all modifications are on disk
|-
|  ||  $\langle T_1, \text{commit} \rangle$  || transaction has finished
|}


The log record's form is:
* $\langle \text{transaction id}, \text{DB item}, \text{old value} \rangle$
* $\langle T_1, B, 8 \rangle$ means $T_1$ made modification to database item $B$ and the old value is 8
* $\langle T_1, \text{commit} \rangle$ means $T_1$ has successfully completed and it everything has been written to disk


=== Complications ===
* Logs are as well first written to memory and then to disk 
* we cannot flush logs to disk on every action - it would result in too much I/O

Bad States we want to avoid:
* A database item is modified on disk, but no corresponding log record is not yet written
* The entire log is on disk (including $\langle T, \text{commit} \rangle$ record) but new values themselves are not


== Rules ==
=== Undo Logging Rules ===
* for every action generate an undo log record with the old value
* before element $X$ is modified on disk, we write all log records that belong to $X$ to disk
** this is called ''Write-Ahead Logging'': 
** before writing a new value, write all corresponding log records
* before you write '''commit''' to logs, all modifications should be already flushed on disk


=== Undo Logging Recovery Rules ===
How to [[Crash Recovery|recover from failures]] with Undo Logging:
* we undo the failed transactions 
* i.e. we put the database in the state it was prior this transaction

Recover(log $L$)
* for every transaction $T_i$ that has a $\langle T_i, \text{start} \rangle$ record in the log
** if there's already $\langle T_i, \text{commit} \rangle$ or $\langle T_i, \text{abort} \rangle$
*** do nothing
** otherwise - rollback:
** for all $\langle T_i, X, v \rangle \in L$
*** write($X, v$)
*** output($X$)
** write $\langle T_i, \text{abort} \rangle$ to $L$

$\langle T_i, \text{abort} \rangle$ record &quot;commits&quot; the abort of transaction
* to avoid the situation when in the middle of abortion the power was cut again
* it says if we undid a transaction successfully we never have to do it again

If during rollback the power was cut again - it's not really a problem 
* we will just overwrite the old value again - and that's it
* writing the old value twice it's the same as writing it once (it's idempotent) 
* this way you're guaranteed to bet back to a consistent state 

Problem:
* what if a transaction changes a value of some variable several times? 
* in this case we should recover only the first one and ignore the rest

Recover(log $L$)
* let $S^*$ be all set of transactions $T_i$ with $\langle T_i, \text{start} \rangle \in L$
* (1) let $S$ be all transaction $T_i \in S^*$ without $\langle T_i, \text{commit} \rangle \in L$ or $\langle T_i, \text{abort} \rangle \in L$
* (2) for each $\langle T_i, X, v \rangle \in \text{reverse}(L)$ (reverse order: latest $\to$ earliest)
** if $T_i \in S$:
*** write($X, v$)
*** output($X$)
* (3) for each $T_i \in S$
** write $\langle T_i, \text{abort} \rangle$ to $L$


== Several Transactions ==
Note that there can be several transactions that are happening at the same time.
* Can writes of $\langle T_i, \text{abort} \rangle$ records to log be done in any order? 

=== Example ===
* $T_1$ and $T_2$ both write $A$, $T_1$ before $T_2$ 
* suppose that both $T_1$ and $T_2$ are rolled back

Suppose we undo both, but write only $\langle T_1, \text{abort} \rangle$ (power was cut when writing $\langle T_2, \text{abort} \rangle$) 
* undoing something 2 times is not a problem, but here we have two transactions
* recall that $\langle T_1, \text{abort} \rangle$ means the value on disk is the value $A$ had prior to $T_1$
* we have undone $T_1$ and now trying to undo $T_2$ 
* this will rollback to value that was there prior to $T_2$, overwriting value that was prior to $T_1$ 
* (That actually could be the value written by $T_1$ which we rolled back)
* '''BAD STATE''' 

If we write $\langle T_2, \text{abort} \rangle$, but not $\langle T_1, \text{abort} \rangle$
* no problems in this case 

$\Rightarrow$
* we must write the abort record in the reversed order of starting times of transactions
* i.e. latest to start - the first to be undone, and its $\langle \text{abort} \rangle$ record should appear first in the log


== Checkpoints ==
If we keep track on everything we do we'll quickly run out of log space
* we can free some space by truncating the log
* are there parts of the log we know for sure are not needed anymore and can be safely discarded? 

Need to be careful:
* just anything before a $\langle T_i, \text{commit} \rangle$? 
* will not work in case of multiple transactions:
* one transaction could commit, but before this commit there may be records of another transaction that has not committed yet - we'd need to undo them as well


=== Stop the World ===
The simplest way

Periodically do the following
* do not accept any transactions (say &quot;stop&quot; to everybody)
* wait until all running transactions finish
* flush their modification to disk (as well as their commit record)
* commit all log records to disk
* write a $\langle \text{ckpt} \rangle$ - checkpoint record - to logs
* now can resume accepting all transactions again


Example
{| class=&quot;wikitable&quot;
|-
| $\langle T_1, \text{start} \rangle$ 
| rowspan=&quot;8&quot; bgcolor=&quot;green&quot; style=&quot;text-align: center;&quot; |  this can &lt;br&gt; be removed &lt;br&gt; from logs 
|-
| $\langle T_1, A, 5 \rangle$
|-
| $\langle T_2, \text{start} \rangle$
|-
| $\langle T_2, B, 10 \rangle$
|-
| $\langle T_2, C, 15 \rangle$
|-
| $\langle T_1, D, 20 \rangle$
|-
| $\langle T_1, \text{commit} \rangle$
|-
| $\langle T_2, \text{commit} \rangle$
|-
| bgcolor=&quot;green&quot; | $\langle \text{ckpt} \rangle$ 
| bgcolor=&quot;green&quot; |
|-
| $\langle T_3, \text{start} \rangle$
| rowspan=&quot;3&quot; style=&quot;text-align: center;&quot; | undoing only &lt;br&gt; this part
|-
| $\langle T_3, E, 25 \rangle$
|-
| $\langle T_3, F, 30 \rangle$
|-
| FAILURE ||
|}


Rollback:
* If a failure occurs we know that it's enough just to get back to the latest successful checkpoint
* everything started before the checkpoint had been committed 

Problem:
* we're shutting down the system while doing the checkpoint
* especially bad when the number of transactions is very high
* we'd like to avoid that 


=== Non-Quiescent Checkpoint ===
This is a more complex technique
* allow  new transactions to enter the system during the checkpoint 

Algorithm: 
* write to log
** $\langle \text{start ckpt} (T_1, ..., T_k) \rangle$
** where $T_1, ..., T_k$ is the list of all active transactions that have not committed yet (and therefore not flushed their results to disk)
* wait until all $T_1, ..., T_k$ commit or abort 
** and there should the corresponding records in the log 
** don't prohibit other transactions to start
* when all $T_1, ..., T_k$ have finished
** write $\langle \text{end ckpt} \rangle$ to log on dist


Idea:
* to undo we scan backwards until we see the end checkpoint ($\langle \text{end ckpt} \rangle$)
* at this point we know that all transaction that were active when the checkpoint started had committed 
* so everything before $\langle \text{start ckpt} (T_1, ..., T_k) \rangle$ is already committed - no need to consider them 
* also: every $\langle \text{start ckpt} \rangle$ should have corresponding $\langle \text{end ckpt} \rangle$


So rollback:
* undo till the latest start checkpoint  $\langle \text{start ckpt} (T_1, ..., T_k) \rangle$


==== Example 1 ====

{| class=&quot;wikitable&quot;
|- 
| $\langle T_1, \text{start} \rangle$  
| rowspan=&quot;4&quot; bgcolor=&quot;red&quot; | can truncate this part
|- 
| $\langle T_1, A, 5 \rangle$
|- 
| $\langle T_2, \text{start} \rangle$
|- 
| $\langle T_2, B, 10 \rangle$
|- 
| bgcolor=&quot;green&quot; | $\langle \text{start ckpt} (T_1, T_2) \rangle$ 
| bgcolor=&quot;green&quot; | $T_1$ and $T_2$ are active
|- 
| $\langle T_2, C, 15 \rangle$ 
| rowspan=&quot;8&quot; | undoing &lt;br&gt; only this part &lt;br&gt;&lt;br&gt; note that $T_3$ started &lt;br&gt; after checkpoint
|- 
| $\langle T_3, \text{start} \rangle$ 
|- 
| $\langle T_1, D, 20 \rangle$ 
|- 
| $\langle T_1, \text{commit} \rangle$
|- 
| $\langle T_3, E, 25 \rangle$
|- 
| $\langle T_2, \text{commit} \rangle$
|- 
| $\langle \text{end ckpt} \rangle$
|- 
| $\langle T_3, F, 30 \rangle$
|- 
| FAILURE ||
|}

In this case 
* we undo only $T_3$ 
* $T_1$ and $T_2$ are not undone - we see their commit records


==== Example 2: Failure during checkpoint ====
{| class=&quot;wikitable&quot;
|-
| $\langle T_1, \text{start} \rangle$ 
| rowspan=&quot;10&quot; bgcolor=&quot;red&quot; style=&quot;text-align: center;&quot; | $\uparrow$ &lt;br&gt; undo to &lt;br&gt; last &lt;br&gt; complete &lt;br&gt; checkpoint &lt;br&gt;&lt;br&gt; only &lt;br&gt; not committed  &lt;br&gt; transactions &lt;br&gt; ($T_2$)
|-
| $\langle T_1, A, 5 \rangle$
|-
| $\langle T_2, \text{start} \rangle$
|-
| $\langle T_2, B, 10 \rangle$
|-
| $\langle \text{start ckpt} (T_1, T_2) \rangle$
|-
| $\langle T_2, C, 15 \rangle$
|-
| $\langle T_3, \text{start} \rangle$
|-
| $\langle T_1, D, 20 \rangle$
|-
| $\langle T_1, \text{commit} \rangle$
|-
| $\langle T_3, E, 25 \rangle$
|-
| FAILURE || (before $\text{ckpt}$)
|}


In this case:
* haven't seen $\langle T_3, \text{commit} \rangle$ - undoing $T_3$
* also have to undo $T_2$
* don't have to undo $T_1$ - it's committed
* when going back, cannot stop at $\langle \text{start ckpt} (T_1, T_2) \rangle$:
** still have to undo all active transactions from the list that haven't committed yet
** the list is $(T_1, T_2)$, $T_1$ has committed - i.e. undoing only $T_2$
* so it may be enough to go up until you see that all not-committed transactions start 
** but it can be as far as the last completed checkpoint
** at this point you're certain that you've undone everything


== Drawbacks and Benefits ==
* (+) don't need much memory for logging - keep as much as you can, flush when there's no memory
* (-) not good for backups - it goes back it time, not forward 
** backup with such logging approach: stop the world and do the backup
** [[Redo Logging]] is another alternative without this drawback


== Undo/Redo Logging ==
[[Undo/Redo Logging]] is the combination of Undo Logging and [[Redo Logging]]


== Exercises ==
{{ Main | Database Transaction Log Exercises }}


== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]</text>
      <sha1>brg44mdoa9fgy40sqk4h8mne5mgvuxf</sha1>
    </revision>
  </page>
  <page>
    <title>Redo Logging</title>
    <ns>0</ns>
    <id>228</id>
    <revision>
      <id>229</id>
      <timestamp>2014-01-01T21:13:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7421">== Redo Logging ==
This is a [[Database Transaction Log]] for dealing with [[Crash Recovery]]

Also called ''deferred modification'' 
* we don't record the old value, but the new value 
* instead of undoing actions, we will do them 
* $\langle T_i, \text{commit} \rangle$ record may appear earlier than the actual modification is written to disk
* but as soon as modified data is flushed, we write $\langle T_i, \text{end} \rangle$


=== Example ===
{| class=&quot;wikitable&quot;
! Transaction $T_1$ || Log || Comment
|-
|   || $\langle T_1, \text{start} \rangle$ || when the transaction starts
|- 
| read($A, t$); $t \leftarrow t \times 2$; ||  ||
|- 
| write($A, t$) || $\langle T_1, A, 16 \rangle$ || $A$'s new value is 16
|-
| read($B, t$); $t \leftarrow t \times 2$; || ||
|- 
| write($B, t$) || $\langle T_1, B, 16 \rangle$ || $B$'s new value is 16
|-
|  ||  $\langle T_1, \text{commit} \rangle$  || record in log appear earlier then actual modification
|-
| output($A$) || ||
|-
| output($B$) || || now all modifications are on disk
|-
|  ||  $\langle T_1, \text{end} \rangle$  || transaction finishes
|}


== Rules ==
=== Redo Logging Rules ===
* for every action we keep a redo log with new values 
* before a DB item $X$ is flushed to disk, all log records for transactions $T_i$ that have modified $X$ (including $\langle T_i, \text{commit} \rangle$) must be on disk
* flush the log on commit 
* write $\langle T_i, \text{end} \rangle$ only when all modified BD items are on disk

Note that we cannot go to the previous state with this approach: no rollback
* need to use [[Undo Logging]] for this or [[Undo/Redo Logging]]


=== Redo Logging Recovery Rules ===
$\langle T_i, \text{commit} \rangle$ means
* user knows that the transaction was executed correctly 
* even if now some error happens we have to ensure that the DB state is the state that the user expects after the transaction happens

$\langle T_i, \text{end} \rangle$ says
* the results are on disk - no need to redo anything

Redo(log $L$)
* let $S$ be set of all transactions $T_i$ with $\langle T_i, \text{commit} \rangle \in L$ but without $\langle T_i, \text{end} \rangle$
* for each $T_i \in S$ and for each $\langle T_i, \text{commit} \rangle \in L$ in forward order (earliest $\to$ latest)
** write($X, v$)
** output($X$) (write and ensure the modifications appear on disk)


== Non-Quiescent Checkpoint ==
Idea similar to [[Undo Logging#Non-Quiescent Checkpoint|Undo Logging]], but different semantics

Algo for creating checkpoints:
* write a log records $\langle \text{start ckpt} (T_1, ..., T_k) \rangle$
** $T_1, ..., T_k$ are active not-committed transactions 
* flush the log
* write to disk modifications of all transactions T_i that have $\langle T_i, \text{commit} \rangle$ record, but don't have $\langle T_i, \text{end} \rangle$ records
** it means the modifications are still in memory buffers and have not been flushed to disk yet
* one the modifications are written to disk, write $\langle \text{end ckpt} \rangle$ and flush the log


=== Example ===
{|
| $\langle T_1, \text{start} \rangle$ || ||
|- 
| $\langle T_1, A, 5 \rangle$ || || 
|- 
| $\langle T_2, \text{start} \rangle$
| rowspan=&quot;11&quot; bgcolor=&quot;red&quot; | $\uparrow$
| 
|- 
| $\langle T_1, \text{commit} \rangle$ ||
|- 
| $\langle T_2, B, 10 \rangle$ ||
|- 
| bgcolor=&quot;green&quot; | $\langle \text{start ckpt} (T_2) \rangle$
| $T_2$ is the only active transaction (no $\langle T_2, \text{commit} \rangle$ record)
|- 
| $\langle T_2, C, 15 \rangle$ ||
|- 
| $\langle T_3, \text{start} \rangle$ ||
|- 
| $\langle T_3, D, 20 \rangle$ ||
|- 
| $\langle T_1, \text{end} \rangle$ || $T_1$ had $\langle T_1, \text{commit} \rangle$, but didn't have $\langle T_1, \text{end} \rangle$ when $\langle \text{start ckpt} \rangle$ was added
|- 
| $\langle \text{end ckpt} \rangle$ || now $T_1$ ended, it means we can end the checkpoint 
|- 
| $\langle T_2, \text{commit} \rangle$ ||
|- 
| $\langle T_3, \text{commit} \rangle$ ||
|-
| FAILURE || || 
|}


We redo all transactions that:
* were active and not-committed when the checkpoint begun
* or started later - after the checkpoint begun

In this case
* these transactions are $T_2$ and $T_3$
* i.e. we need to read the log records till we see  $\langle T_2, \text{start} \rangle$ 
** which was before $\langle \text{start ckpt} (T_2) \rangle$
* anything else is already on disk for sure

To recover, we :
* scan backwards till we see the $\langle \text{end ckpt} \rangle$ and corresponding $\langle \text{start ckpt} (T_1, ..., T_k) \rangle$
* then we scan a little bit more upwards till we see all records $\langle T_1, \text{start} \rangle ... \langle T_k, \text{start} \rangle$
* redo them from this point 


If we see both $\langle \text{start ckpt} (T_1, ..., T_k) \rangle$ and $\langle \text{end ckpt} \rangle$ it means
* while scanning back when see $\langle \text{start ckpt} (T_1, ..., T_k) \rangle$ after $\langle \text{end ckpt} \rangle$ it tells us that:
* all transactions $T_j$ that 
** had committed before $\langle \text{start ckpt} (T_1, ..., T_k) \rangle$ 
** but their modifications had not been flushed to disk (they didn't have $\langle T_j, \text{end} \rangle$ records)
** they would write all their modifications to disk 
** otherwise there would not be $\langle \text{end ckpt} \rangle$ record


=== Example 2 ===
{|
| $\langle T_1, \text{start} \rangle$ || 
|- 
| $\langle T_1, A, 5 \rangle$ || 
|- 
| $\langle T_2, \text{start} \rangle$
| rowspan=&quot;10&quot; bgcolor=&quot;red&quot; | $\uparrow$
|- 
| $\langle T_1, \text{commit} \rangle$
|- 
| $\langle T_2, B, 10 \rangle$
|- 
| bgcolor=&quot;green&quot; | $\langle \text{start ckpt} (T_2) \rangle$
|- 
| $\langle T_2, C, 15 \rangle$
|- 
| $\langle T_3, \text{start} \rangle$
|- 
| $\langle T_3, D, 20 \rangle$ 
|- 
| $\langle T_1, \text{end} \rangle$
|- 
| $\langle \text{end ckpt} \rangle$  
|- 
| $\langle T_2, \text{commit} \rangle$
|- 
| FAILURE ||
|-
| $\langle T_3, \text{commit} \rangle$ ||
|}


This case a little bit different 
* we still have to re-do $T_2$, but not $T_3$ 
* $T_3$'s commit record is not on disk - don't need to redo it


=== Example 3 ===
If a failure occurs after $\langle \text{start ckpt} (T_2) \rangle$ but before $\langle \text{end ckpt} \rangle$  
* you'll have to redo from the previous &lt;u&gt;complete&lt;/u&gt; $\langle \text{start ckpt} (...) \rangle$
* (or from the beginning of the log)

{|
| $\langle T_1, \text{start} \rangle$ 
| rowspan=&quot;10&quot; bgcolor=&quot;red&quot; | $\uparrow$
|- 
| $\langle T_1, A, 5 \rangle$ 
|- 
| $\langle T_2, \text{start} \rangle$
|- 
| $\langle T_1, \text{commit} \rangle$
|- 
| $\langle T_2, B, 10 \rangle$
|- 
| bgcolor=&quot;green&quot; | $\langle \text{start ckpt} (T_2) \rangle$
|- 
| $\langle T_2, C, 15 \rangle$
|- 
| $\langle T_3, \text{start} \rangle$
|- 
| $\langle T_3, D, 20 \rangle$ 
|- 
| $\langle T_1, \text{end} \rangle$
|- 
| FAILURE ||
|}


Note:
* for the Non-Quiescent Check Logging records $\langle T_i, \text{end} \rangle$ are redundant 
* the checkpoints give us the same information


== Drawbacks and Benefits ==
* (-) need to keep all modified blocks in memory until the commit happens 
* (+) good for backups: just replay the logs on another DB instance 


== Undo/Redo Logging ==
[[Undo/Redo Logging]] is the combination of [[Undo Logging]] and Redo Logging


== Exercises ==
{{ Main | Database Transaction Log Exercises }}


== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]</text>
      <sha1>6whfw69szjcy2jp2xtzxtpioga1n62f</sha1>
    </revision>
  </page>
  <page>
    <title>Undo/Redo Logging</title>
    <ns>0</ns>
    <id>229</id>
    <revision>
      <id>230</id>
      <timestamp>2014-01-01T21:13:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2308">== Undo/Redo Logging ==
This is a [[Database Transaction Log]] for dealing with [[Crash Recovery]]. 

Undo/Redo Logging is a combination of two logging approaches:
* [[Undo Logging]] and
* [[Redo Logging]]


=== Log Record === 
Each log record has the following form:
* $\langle T_i, X, v_\text{new}, v_\text{old} \rangle$
* $T_i$ - transaction identifier
* $X$ - id of database object
* $v_\text{new}$ - new value of $X$ (like in [[Redo Logging]])
* $v_\text{old}$ - old value of $X$ (like in [[Undo Logging]])


== Rules ==
* object $X$ can be flushed either before or after $\langle T_i, \text{commit} \rangle$ - it doesn't matter
* all the log records should be flushed before corresponding modifications are written to disk (write-ahead logging, WAL)
* flush at commit: once there's $\langle T_i, \text{commit} \rangle$, flush the log


== Non-Quiescent Checkpoint ==
Algorithm
* write $\langle \text{start ckpt} (T_1, ..., T_k) \rangle$ and flush the log
** $(T_1, ..., T_k)$ - all active transactions 
* write to disk all ''dirty'' memory buffers 
** a memory buffer is ''dirty'' if it contains a modified item
** no matter whether it was committed or not
* write $\langle \text{end ckpt} \rangle$ and flush the log


== Recovery ==
The recovery procedure happens in two passes
* backwards pass 
** undo not committed 
** end $\to$ last valid $\langle \text{start ckpt} (T_1, ..., T_k) \rangle$
* forwards pass 
** redo committed but not flushed 
** last valid $\langle \text{start ckpt} (T_1, ..., T_k) \rangle$ $\to$ end

Notation:
* let $S^+$ be all committed transactions and $S^-$ all not-committed transactions

'''Backwards Pass'''
* undo transactions $T_i \in S^-$ - ones that have not committed 
* for doing that may have to go little bit further than the last valid $\langle \text{start ckpt} (T_1, ..., T_k) \rangle$


'''Forwards Pass'''
* redo all transactions $T_j \in S^+$ 


== Drawbacks and Benefits ==
* (-) requires more memory - need to store both old and new values
* (+) can flush to disk whenever we want - gives us more flexibility 


== Exercises ==
{{ Main | Database Transaction Log Exercises }}


== See also ==
* [[Crash Recovery]]
* [[Undo Logging]] and [[Redo Logging]]

== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]</text>
      <sha1>odwsyn396rqwmogvlcaoq83uo0stgoq</sha1>
    </revision>
  </page>
  <page>
    <title>Database Transaction Log Exercises</title>
    <ns>0</ns>
    <id>230</id>
    <revision>
      <id>231</id>
      <timestamp>2014-01-01T21:17:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13035">== Database Transaction Log Exercises ==
Exercises [https://www.dropbox.com/s/remf9pcuw94qvow/lect8-ex-crash-recovery.pdf] and solutions [https://www.dropbox.com/s/tcbmgtqtiffdjrg/lect8-ex-crash-recovery-sol.pdf]

Materials:
* [[Undo Logging]]
* [[Redo Logging]]
* [[Undo/Redo Logging]]


== Exercise 1 ==
Consider the following log:
* $\langle T, \text{start} \rangle; \langle T, A, 10 \rangle; \langle T, B, 20 \rangle; \langle T, \text{commit} \rangle$ 
* and events: Output($A$), Output($B$), Flush-Log($A$), Flush-Log($B$), Commit
* what sequences of events are valid for this log? 

=== Undo Logging ===
According [[Undo Logging#Undo Logging Rules]], we have the following constraints (&lt; = &quot;occurs before&quot;)
* Flush-Log($A$) &lt; Output($A$) and Flush-Log($B$) &lt; Output($B$)
** should always flush before writing the modified item to disk
* Flush-Log($A$) &lt; Flush-Log($B$) &lt; Commit
** assume DB items are flushed on disk in the order they are created $\to$ flushing logs for $A$ before logs for $B$ 
** both have to be flushed before we write the commit record
* Output($A$) &lt; Commit and Output($B$) &lt; Commit
** should write the modified database element to disk before the commit

Hence, the following sequences are legal:
* Flush-Log($A$), Output($A$), Flush-Log($B$), Output($B$), Commit
* Flush-Log($A$), Flush-Log($B$), Output($A$), Output($B$), Commit
* Flush-Log($A$), Flush-Log($B$), Output($B$), Output($A$), Commit


=== Redo Logging ===
According [[Redo Logging#Redo Logging Rules]], we have the following constraints (&lt; = &quot;occurs before&quot;)
* Flush-Log($A$) &lt; Output($A$) and Flush-Log($B$) &lt; Output($B$)
** same as for Undo Logging: should always flush before writing the modified item to disk
* Flush-Log($A$) &lt; Flush-Log($B$) &lt; Commit
** same as for Undo Logging: assume DB items are flushed on disk in the order they are created
** both have to be flushed before we write the commit record
* Commit &lt; Output($A$) and Commit &lt; Output($B$)
** in contract to Undo Logging: can write modifications on disk only after the commit record was flushed 

Hence, the following sequences are legal:
* Flush-Log($A$), Flush-Log($B$), Commit, Output($A$), Output($B$)
* Flush-Log($A$), Flush-Log($B$), Commit, Output($B$), Output($A$)


=== Undo/Redo Logging ===
According [[Undo/Redo Logging#Rules]], we have the following constraints (&lt; = &quot;occurs before&quot;)
* Flush-Log($A$), Output($A$) and Flush-Log($B$), Output($B$)
** log records should appear before a database item is modified on disk
* Flush-Log($A$) &lt; Flush-Log($B$) &lt; Commit
** logs must be flushed before the commit record

This gives mush more sequences 
* Flush-Log($A$); Output($A$); Flush-Log($B$); Output($B$); Commit
* Flush-Log($A$); Flush-Log($B$); Output($A$); Output($B$); Commit
* Flush-Log($A$); Flush-Log($B$); Output($B$); Output($A$); Commit
* Flush-Log($A$); Flush-Log($B$); Commit; Output($A$); Output($B$)
* Flush-Log($A$); Flush-Log($B$); Commit; Output($B$); Output($A$)
* Flush-Log($A$); Output($A$); Flush-Log($B$); Commit; Output($B$)
* Flush-Log($A$); Flush-Log($B$); Output($A$); Commit; Output($B$)
* Flush-Log($A$); Flush-Log($B$); Output($B$); Commit; Output($A$)


== Exercise 2.1 ==
Events
* Start transaction $T$
* $T$ modifies $A \leftarrow 11$ (was 10)
* Start transaction $U$
* Failure occurs

Questions:
* what values might have changed?
* how to recover?


=== Undo Logging ===
Log 
: $\langle T, \text{start} \rangle$
: $\langle T, A, 10 \rangle$
: $\langle U, \text{start} \rangle$
: FAILURE

$A$ might have changed its value

Recall the rule: 
* scan backwards from the end to the beginning
* undo things that have not committed

Recovering (while scanning backwards):
# see $\langle U, \text{start} \rangle$
#* we've successfully undone it 
#* so write $\langle U, \text{abort} \rangle$
# see the modification $\langle T, A, 10 \rangle$
#* write 10 to $A$ (rewriting the old value back) 
# see $\langle T, \text{start} \rangle$
#* we've successfully undone it 
#* so write $\langle T, \text{abort} \rangle$


=== Redo Logging ===
Log 
: $\langle T, \text{start} \rangle$
: $\langle T, A, 11 \rangle$
: $\langle U, \text{start} \rangle$
: FAILURE

$A$ cannot have changed its value - the crash occurred
* no commit record $\langle T, \text{commit} \rangle$ was written to disk
* no need to redo it

Recall the rule: 
* scan from the beginning to the end
* redo things that have committed but were not flushed to disk

Recovering (while scanning forwards):
# see $\langle T, \text{start} \rangle$
#* write $\langle T, \text{abort} \rangle$
# see the modification $\langle T, A, 11 \rangle$
#* do nothing - it has not changed the value on disk 
# see $\langle U, \text{start} \rangle$
#* write $\langle U, \text{abort} \rangle$


=== Undo/Redo Logging ===
Log
: $\langle T, \text{start} \rangle$
: $\langle T, A, 10, 11 \rangle$
: $\langle U, \text{start} \rangle$
: FAILURE

$A$ might have changed its value 
* recover in the same way as for Undo Logging

Recovering (while scanning backwards):
# see $\langle U, \text{start} \rangle$
#* we've successfully undone it 
#* so write $\langle U, \text{abort} \rangle$
# see the modification $\langle T, A, 10, 11 \rangle$
#* write 10 to $A$ (rewriting the old value back) 
# see $\langle T, \text{start} \rangle$
#* we've successfully undone it 
#* so write $\langle T, \text{abort} \rangle$


== Exercise 2.2 ==
Events
* Start transaction $T$
* $A \leftarrow 11$ (was 10) by $T$
* Start transaction $U$
* $B \leftarrow 21$ (was 20) by $U$
* $C \leftarrow 31$ (was 30) by $T$
* $D \leftarrow 41$ (was 40) by $U$
* $U$ commits 
* Failure occurs

Questions:
* what values might have changed?
* how to recover?


=== Undo Logging ===
Log
: $\langle T, \text{start} \rangle$
: $\langle T, A, 10 \rangle$
: $\langle U, \text{start} \rangle$
: $\langle U, B, 20 \rangle$
: $\langle T, C, 30 \rangle$
: $\langle U, D, 40 \rangle$
: $\langle U, \text{commit} \rangle$
: FAILURE

Only transaction $T$ has to be undone
* $U$ committed

Changed values:
* $A$ and $C$ might have changed the values (don't see $\langle T, \text{commit} \rangle$)
* $B$ and $D$ have changed the values (see $\langle U, \text{commit} \rangle$)


Recovering (while scanning backwards):
# see $\langle U, \text{commit} \rangle$
#* ignoring changes of $U$ altogether 
# see $\langle U, D, 40 \rangle$
#* skipping it
# see $\langle T, C, 30 \rangle$
#* write value 30 back to $C$
# see $\langle U, B, 20 \rangle$ and $\langle U, \text{start} \rangle$
#* skipping it
# see $\langle T, A, 10 \rangle$
#* write value 10 back to $C$
# see $\langle T, \text{start} \rangle$
#* we've successfully undone it 
#* so write $\langle T, \text{abort} \rangle$


=== Redo Logging ===
Log
: $\langle T, \text{start} \rangle$
: $\langle T, A, 11 \rangle$
: $\langle U, \text{start} \rangle$
: $\langle U, B, 21 \rangle$
: $\langle T, C, 31 \rangle$
: $\langle U, D, 41 \rangle$
: $\langle U, \text{commit} \rangle$
: FAILURE

Need to redo only transaction $U$
* only $U$ has a commit record $\langle U, \text{commit} \rangle$ 
* $T$ has not committed - no need to redo it 

Changed values 
* $A$ and $C$ have not changed ($T$ has not committed)
* $B$ and $D$ might have changed ($U$ has committed)

Recovering (while scanning forwards):
# $\langle T, \text{start} \rangle$
#* we know that we ignore changes of $T$ - ignoring it
# $\langle T, A, 11 \rangle$
#* skipping
# $\langle U, \text{start} \rangle$
# $\langle U, B, 21 \rangle$
#* writing 21 to $B$ 
# $\langle T, C, 31 \rangle$
#* skipping
# $\langle U, D, 41 \rangle$
#* writing 41 to $D$ 
# $\langle U, \text{commit} \rangle$
# write $\langle T, \text{abort} \rangle$ to log
#* don't write $\langle U, \text{abort} \rangle$ to log


=== Undo/Redo Logging ===
Log
: $\langle T, \text{start} \rangle$
: $\langle T, A, 10, 11 \rangle$
: $\langle U, \text{start} \rangle$
: $\langle U, B, 20, 21 \rangle$
: $\langle T, C, 30, 31 \rangle$
: $\langle U, D, 40, 41 \rangle$
: $\langle U, \text{commit} \rangle$
: FAILURE


Changed values:
* everything might have changed 
** we don't know whether it was before or after the commit when the database elements were supposed to be modified
** so need to undo all not-committed transactions
** and redo all committed transactions
* all $A$, $B$, $C$, $D$ might have changed their values


* $U$ must be redone (it has the commit record $\langle U, \text{commit} \rangle$)
* $T$ must be undone (it doesn't have a commit record $\langle T, \text{commit} \rangle$)


'''Recovering:'''

forwards (redoing) - same as for Redo Logging:
* ignoring changes of $T$
* write 21 to $B$ 
* write 41 to $D$

backwards (undoing) - same as for Undo Logging
* ignore changes of $U$ 
* write 30 to $C$
* write 10 to $A$ 
* write $\langle T, \text{abort} \rangle$ to log


== Exercise 3 ==
Question
* for a given log, where a $\langle \text{end ckpt} \rangle$ can be added?
* what happens if a crash occurs?


=== Undo Logging ===
Consider this log
: $\langle S, \text{start}  \rangle$
: $\langle S, A, 60 \rangle$
: $\langle S, \text{commit} \rangle$
: $\langle T, \text{start}  \rangle$
: $\langle T, A, 10 \rangle$
: $\langle \text{start ckpt} \rangle$ 
:* here it should identify the active transactions 
:* hence it's $\langle \text{start ckpt} (T) \rangle$ ($S$ already committed)
:* we can add $\langle \text{end ckpt} \rangle$ only once $T$ commits 
: $\langle U, \text{start} \rangle$
: $\langle U, B, 20 \rangle$
: $\langle T, C, 30 \rangle$
: $\langle V, \text{start}  \rangle$
: $\langle U, D, 40 \rangle$
: $\langle V, F, 70 \rangle$
: $\langle U, \text{commit} \rangle$
: $\langle T, E, 50 \rangle$
: $\langle T, \text{commit} \rangle$
:* since $T$ has committed, here can add $\langle \text{end ckpt} \rangle$
: $\langle V, B, 80 \rangle$
: $\langle V, \text{commit}  \rangle$


Recovery:
* depends on whether we first meet $\langle \text{end ckpt} \rangle$ or $\langle \text{start ckpt} \rangle$ 
* if $\langle \text{end ckpt} \rangle$ - go backwards till $\langle \text{start ckpt} (T) \rangle$
* if $\langle \text{start ckpt} (T) \rangle$ - then go backwards till $\langle T, \text{start}  \rangle$ ($T$ was the only active transaction when the checkpoint started)


=== Redo Logging ===
Consider this log
: $\langle S, \text{start}  \rangle$
: $\langle S, A, 61 \rangle$
: $\langle S, \text{commit} \rangle$
: $\langle T, \text{start}  \rangle$
: $\langle T, A, 11 \rangle$
: $\langle \text{start ckpt} \rangle$ 
:* we keep that on the transactions that have committed at this point, but have not yet flushed the modifications to disk:  we wait until they do that 
:* only after that we end the checkpoint (put $\langle \text{end ckpt} \rangle$)
:* The only transaction that has committed is $S$, so the $\langle \text{end ckpt} \rangle$ can occur anywhere after this record: we cannot predict when exactly the dirty blocks will be written to disk 
:* the log record actually is $\langle \text{start ckpt} (T) \rangle$  since $T$ is the only active transaction at this point
: $\langle U, \text{start} \rangle$
: $\langle U, B, 21 \rangle$
: $\langle T, C, 31 \rangle$
: $\langle V, \text{start}  \rangle$
: $\langle U, D, 41 \rangle$
: $\langle V, F, 71 \rangle$
: $\langle U, \text{commit} \rangle$
: $\langle T, E, 51 \rangle$
: $\langle T, \text{commit} \rangle$
: $\langle V, B, 81 \rangle$
: $\langle V, \text{commit}  \rangle$

Recovery
* also depends when the crash occurs 
* $\langle \text{end ckpt} \rangle$ is last, then we know that $S$ was written fully 
** transactions that we active at start or started later must be redone
** these transactions are $T$, $U$ and $V$
* $\langle \text{start ckpt} (S) \rangle$ is last - need to go to the previous checkpoint end


=== Undo/Redo Logging ===
For this we do the same reasoning as for Redo Logging

: $\langle S, \text{start}  \rangle$
: $\langle S, A, 60, 61 \rangle$
: $\langle S, \text{commit} \rangle$
: $\langle T, \text{start}  \rangle$
: $\langle T, A, 10, 11 \rangle$
: $\langle \text{start ckpt} \rangle$ 
:* again cannot predict where exactly to put $\langle \text{end ckpt} \rangle$
:* it will be written once $S$ flushes its modifications to disk
: $\langle U, \text{start} \rangle$
: $\langle U, B, 20, 21 \rangle$
: $\langle T, C, 30, 31 \rangle$
: $\langle V, \text{start}  \rangle$
: $\langle U, D, 40, 41 \rangle$
: $\langle V, F, 70, 71 \rangle$
: $\langle U, \text{commit} \rangle$
: $\langle T, E, 50, 51 \rangle$
: $\langle T, \text{commit} \rangle$
: $\langle V, B, 80, 81 \rangle$
: $\langle V, \text{commit}  \rangle$

Recovery
* if last is $\langle \text{end ckpt} \rangle$
** all dirty blocks were written to disk
** need to redo only active transactions from the moment when $\langle \text{start ckpt} \rangle$ occurred (i.e. $T$)
** for that may need to go further - to $\langle T, \text{start}  \rangle$
* if last is $\langle \text{start ckpt} (T) \rangle$
** go back to the previously successfully completed checkpoint (or the beginning of the log)


== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]</text>
      <sha1>a63f2mndzichhflz3kqcccq29vefc1d</sha1>
    </revision>
  </page>
  <page>
    <title>Concurrency Control</title>
    <ns>0</ns>
    <id>231</id>
    <revision>
      <id>232</id>
      <timestamp>2014-01-03T10:16:20Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3442">== Concurrency Control ==
A database typically serves multiple users at the same time 
* the goal in this case is to make an impression that everything works in [[Isolation (databases)|isolation]]
* Concurrency Control deals with that: it ensures that transactions have the same effect as if they were run in isolation 


== Conflicts ==
=== Write-Read Conflict ===
Problem:
* one transaction $T_1$ is reading a DB item that was written by another transaction $T_2$
* without $T_2$ having completed 
* this results in Write-Read Conflict


Illustrative Example
* suppose there are two transactions $T_1$ and $T_2$
* $T_1$ transfers 100 USD from one account to another 
* $T_2$ gives 6% interest rate to all accounts

{|  class=&quot;wikitable&quot;
! $T_1$ || $T_2$ || 
|-
| Read($A, s$) || || read from $A$ to main-memory variable $s$
|-
| $s \leftarrow s - 100$ || || withdraw 100 USD from $A$
|-
| Write($A, s$) || || persist the result to disk
|-
|  || Read($A, t$) || 
|-
|  || $t \leftarrow t \times 1.06$ || give 6% interest rate to $A$
|-
|  || Write($A, t$) || note that at this moment the money hasn't appeared at $B$ yet
|-
|  || Read($B, t$) || 
|-
|  || $t \leftarrow t \times 1.06$ || give 6% interest rate to $B$
|-
|  || Write($B, t$) || 
|-
| Read($B, s$) || || 
|-
| $s \leftarrow s + 100$ || || put 100 USD to $B$
|-
| Write($B, s$) || || persist the result to disk
|}

Assume both $A$ and $B$ have 100 USD
* $A$ won't get any interest (no money at the moment of interest calculation)
* $B$ will get interest only on 100 USD instead of 200 USD

Reason: 
* two transactions interleaved, 
* it should be either 
** first all actions of $T_1$ and then all actions of $T_2$ or
** first all actions of $T_2$ and then all actions of $T_1$

=== Write-Write Conflict ===
Problem:
* both transactions are just writing new values without reading the old ones 

Example
* $T_1$ puts 100 USD to both $A$ and $B$ 
* $T_2$ puts 200 USD to both $A$ and $B$ 

{| class=&quot;wikitable&quot;
! $T_1$ || $T_2$
|-
| $s \leftarrow 100$ ||
|-
| Write($A, s$) ||
|-
| || $t \leftarrow 200$
|-
| || Write($A, t$)
|-
| || $t \leftarrow 200$
|-
| || Write($B, t$)
|-
| $s \leftarrow 100$ ||
|-
| Write($B, s$) ||
|}

We want the transactions to run in some sequence
* as if they were not allowed to interleave 

Not [[Consistency (databases)|consistent]] state:
* $B$ has 100 USD, $A$ has 200 

Consistent state:
* both have 200 USD (first $T_1$ then $T_2$)
* both have 100 USD (first $T_2$ then $T_1$)


=== Scheduling ===
* The [[Scheduler]] is responsible for creating an impressions that all transactions are run in isolation 


== Approaches ==
* [[Lock-Based Scheduler]]
* [[Timestamp-Based Scheduler]] [http://en.wikipedia.org/wiki/Timestamp-based_concurrency_control]
* [[Validation-Based Scheduler]]
* [[Multi-Version Concurrency Control]] (MVCC) [http://en.wikipedia.org/wiki/Multiversion_concurrency_control] ([[CouchDB]]) (also &quot;optimistic concurrency model&quot;)
* [[Vector Clock]] (like in Amazon Dynamo etc)


== Distributed Concurrency ==
* Multi-Master
* Master/Slave
* Partitioning 
* Sharding 
* Write thought Caches


== Sources ==
* [[Introduction to Data Science (coursera)]]
* [http://www.slideshare.net/guestdfd1ec/design-patterns-for-distributed-nonrelational-databases Design Patterns for Distributed Non-relational Databases]
* http://en.wikipedia.org/wiki/Concurrency_control

[[Category:Concurrency]]
[[Category:Database Systems Architecture]]</text>
      <sha1>l0gvgpmzhjitmb51tbmr4hv12hzeae5</sha1>
    </revision>
  </page>
  <page>
    <title>Multi-Version Concurrency Control</title>
    <ns>0</ns>
    <id>232</id>
    <revision>
      <id>233</id>
      <timestamp>2014-01-02T07:15:54Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1952">== Concurrency Control ==
In a typical relational database when we modify a table, we put a lock - and all other clients that want to access the table are queued
* This sequential execution of tasks wastes a lot of processor's power and time: 
* under high load it may spend a lot of time trying to figure out whose turn is next

MVCC, Multi-Version Concurrency Control, is one of the [[Concurrency Control]] techniques. 
* it is used to manage concurrent access to the data 
* it runs effectively even under high load, without worrying about queuing requests

https://github.com/alexeygrigorev/ulb-adb-project-couchbd/raw/master/report/images/couchdb-concurrency.png

(figure source: [http://guide.couchdb.org/draft/consistency.html#figure/3])



This is used in:
* [[CouchDB]]


== Ways to Achieve ==
=== [[B-Tree]] Storage Engine ===
This way it is achieved in [[CouchDB]]

[[B-Tree]] is used everywhere, also for internal data: documents and views
* Usage of this data structure imposes an important restriction: can access only by key. 
* Reason: to be make huge performance gains 

Modification in B-Trees to support MVCC:
* reads and writes without locking the system 
* writes do not block reads 
* this is because of append-only design 


Append-only design 
* old versions are not deleted
* every time something is updated, a new node is created, and a new root as well
** but old reads still have references to the old root,
** so they are able to continue reading without being interrupted, 
** i.e. have old consistent state 
* data never lost and never corrupted

Idea:
* When a new request comes, it uses the current root for querying
* If the root changes by other transaction, this request is still active and will get the old valid and consistent value


== Sources ==
* [http://guide.couchdb.org/draft CouchDB The Definitive Guide by Anderson, Lehnardt and Slater]

[[Category:Database Systems Architecture]]
[[Category:Concurrency]]</text>
      <sha1>1m7jx3lj6zwy1nmrq09tijsvl6ir1gj</sha1>
    </revision>
  </page>
  <page>
    <title>Multi-Vestion Concurrency Control</title>
    <ns>0</ns>
    <id>233</id>
    <revision>
      <id>234</id>
      <timestamp>2014-01-02T07:15:54Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="69">#перенаправление [[Multi-Version Concurrency Control]]</text>
      <sha1>ntoubxq45c3jm77s933s1dokpei445n</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Maven</title>
    <ns>14</ns>
    <id>234</id>
    <revision>
      <id>235</id>
      <timestamp>2014-01-02T07:20:59Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17">[[Category:Java]]</text>
      <sha1>9igx8un2j0lurpeyj8zj5vrkwfu22yr</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Books</title>
    <ns>14</ns>
    <id>236</id>
    <revision>
      <id>237</id>
      <timestamp>2014-01-02T07:22:31Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="0" />
      <sha1>phoiac9h4m842xq45sp7s6u21eteeq1</sha1>
    </revision>
    <revision>
      <id>238</id>
      <parentid>237</parentid>
      <timestamp>2015-11-07T00:48:48Z</timestamp>
      <contributor>
        <username />
        <id>0</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="0" />
      <sha1>phoiac9h4m842xq45sp7s6u21eteeq1</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Подготовка к ШАД</title>
    <ns>14</ns>
    <id>237</id>
    <revision>
      <id>239</id>
      <timestamp>2014-01-02T07:23:01Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="0" />
      <sha1>phoiac9h4m842xq45sp7s6u21eteeq1</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Scala</title>
    <ns>14</ns>
    <id>238</id>
    <revision>
      <id>240</id>
      <timestamp>2014-01-02T07:23:40Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24">[[Category:Programming]]</text>
      <sha1>kf5psdimgr1sx9e80utmmehom1l3auk</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Greedy Algorithms</title>
    <ns>14</ns>
    <id>239</id>
    <revision>
      <id>241</id>
      <timestamp>2014-01-02T07:24:45Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="49">[[Category:Optimization]]
[[Category:Algorithms]]</text>
      <sha1>kncuxr2qtza1qv1m1t9mdyi5do2ui8v</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Optimization</title>
    <ns>14</ns>
    <id>240</id>
    <revision>
      <id>242</id>
      <timestamp>2014-01-02T07:24:39Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23">[[Category:Algorithms]]</text>
      <sha1>r76apkj24r65uprb4tc339y8073prph</sha1>
    </revision>
  </page>
  <page>
    <title>Secondary Index</title>
    <ns>0</ns>
    <id>241</id>
    <revision>
      <id>243</id>
      <timestamp>2014-01-03T10:06:28Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2343">== Secondary Index ==
What if we want to support efficient search by some other attribute (not one that is already indexed)
* then the file is not sequentially sorted by this other attribute (it's sorted on the pk)
* we can make a copy of the entire table - but it's too expensive

Index structures to do that are Secondary [[Indexes (databases)|Indexes]]

=== [[Sparse Index]]? ===
Doesn't make sense
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/secondary-sparse-no-sense.png
* since the file is sorted by another key

=== [[Dense Index]]? ===
Idea: 
* build a dense index, sort it,
* construct sparse index on it
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/secondary-dense-sparse.png


== Duplicates ==
=== Just Repeat ===
Suppose we use [[Dense Index]] as our secondary index
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/secondary-dense-dups-1.png
* Same is [[Dense Index#Option 1|Option 1]] from [[Dense Index]] (note that [[Dense Index#Option 2|Option 2]] will not work here - file is not ordered by this key)
* 10 occurs 3 times - may lead to waste of space
* may look innocent for integers, but often keys are strings

=== Variable-Length Records ===
Another way is to use variable-length records
* now need to store the key value only once
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/secondary-dense-dups-2.png
* problem now: need to support variable-length records (which is hard)

=== Buckets of Pointers ===
We add one more level of indirection
* we have index on buckets
* buckets are pointers to the actual tuples

So now we have
# [[Dense Index]] where each value is stored once
# ''Bucket list'' where we have multiple occurrences
#* pointers to actual values 
#* should be sequential: i.e. ordered by the key
# Actual blocks

Also saves space!

Example
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/secondary-level-of-ind.png
* index pointers point to the first occurrence of 10
* we read buckets down till there's no 10 anymore

This idea is used in [[Buckets of Pointers]]


== See also ==
* [[Indexing (databases)]]
* [[Sparse Index]]
* [[Dense Index]]

== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]
[[Category:Database Indexes]]</text>
      <sha1>a0a83xtopghaz931sb7eij7nh6jxhuv</sha1>
    </revision>
  </page>
  <page>
    <title>Buckets of Pointers</title>
    <ns>0</ns>
    <id>242</id>
    <revision>
      <id>244</id>
      <timestamp>2014-01-03T09:37:22Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1355">== Buckets of Pointers ==
We add one more level of indirection for [[Indexing (databases)|indexing]]
* we have index on buckets
* buckets are pointers to the actual tuples

So now we have
# [[Dense Index]] where each value is stored once
# ''Bucket list'' where we have multiple occurrences
#* pointers to actual values 
#* should be sequential: i.e. ordered by the key
# Actual blocks

Also saves space!

Example
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/secondary-level-of-ind.png
* index pointers point to the first occurrence of 10
* we read buckets down till there's no 10 anymore

Good for Range Queries
* These buckets are also useful for ''Range Queries''

Suppose we have 
* relation Emp(name, dept, floor)
* name is primary key (main index)
* dept and floor are secondary keys ([[Secondary Index]]es on them)

Suppose we want to ask the following:
&lt;pre&gt;SELECT * FROM Emp where dept = 'Toy' AND floor = 2&lt;/pre&gt;
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/secondary-buckets-range-q.png
* need to compute the intersection of set of pointers (very fast)
* and this is before reading from disk


== See also ==
* [[Indexing (databases)]]
* [[Secondary Index]]

== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]
[[Category:Database Indexes]]</text>
      <sha1>rx80pnx9pno8j5c1p5if8fnop3869zx</sha1>
    </revision>
  </page>
  <page>
    <title>Database</title>
    <ns>0</ns>
    <id>243</id>
    <revision>
      <id>245</id>
      <timestamp>2014-01-03T10:10:33Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4811">== Databases ==
A database
* is a collection of information that is organized to afford efficient retrieval 
* this collection exists over a long period of time

Data in a database should be self-describing and have a schema 

What problems databases solve? 
* Sharing 
: should support concurrent access between multiple readers and writers 
* [[Data Model]] Enforcement
: should make sure all applications see clean and organized data
* Scale (see [[Secondary Storage]])
: should work with datasets too large to fit into main memory
* Flexibility
: should allow using the data in new unexpected ways 


== DBMS ==
* usually the term database refers to a collection of data that is managed by a ''DBMS'' - a tool for managing large amounts of data

A Database Management System (DBMS) is expected to (by [[Data Model]] Enforcement)
* allow users to create DBs and specify the schema - logical structure of the data 
: (using DDL - data definition language)
* allows to query and modify the data with some query language or data manipulation language
* support storing very large amounts of data 
* etc


== Classical DBMS Architecture ==
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/db-architecture.png


=== Recovery Manager ===
deals with [[Crash Recovery]]
* Ensures that Database can be put back into a consistent state after a crush
* Uses [[Database Transaction Log]]s for that

=== [[Concurrency Control]] ===
* ''Transaction Manager'' is responsible for receiving read and write requests (SQL is eventually translated to them)
* it has a [[Scheduler]]: a component  that schedules commands in some sequence thus creating an impression that all users work in [[Isolation (databases)|isolation]]



=== Query Evaluation Engine ===
Responsible for [[Query Processing]]
* Transforms SQL to [[Relational Algebra]] (see [[Translating SQL to Relational Algebra]])
* [[Logical Query Plan Optimization|Optimizes RA expressions]]
* Creates [[Query Plan#Physical Query Plan|Physical Query Plan]] from Logical Query Plan using [[Physical Operators (databases)|physical operators]]
* [[Physical Query Plan Optimization]] is used for finding the cheapest physical query plan


=== File &amp; Access Methods ===
* Provides Wrapper Around Buffer Manager
* here [[B-Tree]] and other [[Indexing (databases)|Indexes]] are implemented


=== Buffer Manager ===
''Buffer Manager'' is mediator between [[Secondary Storage|external storage]] and main memory (see [[Memory Hierarchy]])

Main Responsibility: Partitioning main memory into buffers
* it maintains a ''buffer pool''
* it's a collection of memory slots (called ''buffers'')
* a ''buffer'' is a page-sized regions into which disk blocks are transferred 
* disk blocks are brought into memory per request
** sometimes it may allocate more blocks when asked - in anticipation that some blocks will be needed

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/db-architecture-buffermanager.png

A ''replacement policy'' decides which block gets evicted when the buffer pool is full
* popular policies&quot; FIFO, Least Recently Used, Clock, etc

Blocks Management
* Higher levels don't care care if a block in memory or not
** BM loads it if it's not 
** BM doesn't load if it's already there
** if no empty buffers, but need to load something, it uses the replacing policy
* Higher levels also inform when a block is no longer needed 
** so BM can reuse the space
* ''pinned block'' - block that should remain in the memory because it's still needed 
** ''pinning'' - making a block pinned
** ''unpinning'' - telling BM that a block is no longer needed
* if a block is modified, BM makes sure the changes are propagated to dosk


=== Disk Space Manager ===
sometimes also ''Storage Manager''
* controls where the data in main memory or on disk is stored 
* keeps track on locations of data requested by buffer manager  
* deals with requests from upper layers to allocate, deallocate, read and write blocks 
* hides details of underlaying hardware and OS 
* typically uses functionality provided by OS



== Stored Information ==
* data - content of the DS
* metadata - DB schema that describes the DB
* [[Database Transaction Log|log records]] - information about recent changes to the database 
* Statistics - sizes, values, relation to other components of DB, stored in [[Database System Catalog]]
* [[Indexing (databases)|Indexes]] to support efficient access to data


== Databases ==
* [[Relational Databases]]
* [[NoSQL]]
** [[Column-Oriented Databases]]
** [[Document-Oriented Databases]] ([[CouchDB]])


== Sources ==
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom
* [[Database Systems Architecture (ULB)]]
* [[Introduction to Data Science (coursera)]]

[[Category:Databases]]</text>
      <sha1>cx3dhzh403m6jvlapd275hihfvoomku</sha1>
    </revision>
  </page>
  <page>
    <title>Relational Databases</title>
    <ns>0</ns>
    <id>244</id>
    <revision>
      <id>246</id>
      <timestamp>2015-06-24T20:17:00Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2251">== Relational [[Data Model]] ==
A relational database is a collection of ''relations''
* everything is a table 
* every row in a table has the same number of columns 
* relations are implicit: no pointers


=== Structure of Data ===
A ''relation'' is a two-dimension table 

For example, Consider a '''Movie''' relation: 

{| class=&quot;wikitable&quot;
! Title || Year || Length || Genre 
|-
| Gone with the Wind || 1939 || 231 || Drama 
|-
| Star Wars || 1977 || 124 || Sci-Fi
|}


Columns
* The columns of a relation are named by ''attributes''
* E.g.: Title, Year, etc.
* They describe the meaning of entities in columns


The name of a relation with its attributes is called ''schema''
* e.g.: Movies(Title, Year, Length, Genre)
* Note that the attributes form a set, not a list
* A database consists of one or more relations, each with a schema 
* And the set of all schemata within one database is called ''Relational DB Schema''


Rows of a relation (other than the header row - which describes the attributes) are called ''tuples''
* (&quot;Gone with the Wind&quot;, 1939, Drama)
* We don't include the attribute names, so the order is important here 


We usually associate a ''domain'' with each attribute - a particular elementary type 
* E.g.: Movie(Title: String, Year: Integer, Length: Integer, Genre: String)


=== Operations on Data ===
* Usually the operations are [[Relational Algebra]] expressions
* SQL is usually transformed to Relational Algebra for processing 


=== Constraint ===
One fundamental constraint in this model is ''key constraint'' 

A set of attributes form a ''key'' for a relation if there are no two tuples with the same values in for the attributes of the key

We indicate that the attributes form a key by &lt;u&gt;underlining&lt;/u&gt; them:
* e.g.: Movies(&lt;u&gt;Title&lt;/u&gt;, &lt;u&gt;Year&lt;/u&gt;, Length, Genre)


== Modeling Relational Databases ==
* Conceptual level: [[Entity-Relationship Model]]



== Query Processing ==
{{Main | Query Processing}}
How to translate a SQL query into physical query plan


== Sources ==
* Database Systems: The Complete Book (2nd edition) by H. Garcia-Molina, J. D. Ullman, and J. Widom
* [[Introduction to Data Science (coursera)]]

[[Category:Relational Databases]]
[[Category:Databases]]
[[Category:Data Models]]</text>
      <sha1>lym17ik8lajbhsvz2nbksj5zb4kjy3m</sha1>
    </revision>
  </page>
  <page>
    <title>Bitmap Heap Scan</title>
    <ns>0</ns>
    <id>245</id>
    <revision>
      <id>247</id>
      <timestamp>2014-02-08T15:21:40Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="901">{{stub}}

== Bitmap Heap Scan ==
Index can be clustered or unclustered
* When index is clustered it means the records themselves are stored in index, not pointers
* I.e. a clustered index ensures that all data is stored in some order 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/ind/hash-ways-to-store.png
* Usually there is only one clustered index per relation (otherwise the data will be duplicated)

If an index (say, [[B-Tree]]) is not clustered, 
* then instead of following each pointer 
* can use Bitmap Heap Scan


=== Algorithm ===
* Collect all the pointers 
* Then group them by pages on disk 
* And retrieve them one-by-one 

Reasons:
* to avoid following each pointer separately 
* to make scans on clustered indexes more efficient

== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Database Systems Architecture]]
[[Category:Database Indexes]]</text>
      <sha1>ryhzx6y1vh8me6lfh2k9gx0to5dgept</sha1>
    </revision>
  </page>
  <page>
    <title>Scheduler</title>
    <ns>0</ns>
    <id>246</id>
    <revision>
      <id>248</id>
      <timestamp>2014-01-03T10:17:03Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1119">== Scheduler ==
The ''Transaction Manager'' is a component of a [[Database#Classical DBMS Architecture|Database]] that issues read and write requests to the ''scheduler''.

The ''scheduler'' determines the order of execution of these requests
* Given some transactions,  
* Find a [[Serializable Schedule|conflict-serializable schedule]] to execute them

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/transaction-manager.png

Problem:
* Read/Write requests arrive continuously and the scheduler never knows the whole transaction
* it also may be a long running transaction 

$\Rightarrow$ the scheduler has to construct the schedule dynamically by
* allowing some read/write requests 
* blocking others 
* restarting some transactions when necessary
* all to ensure that the resulting schedule is conflict-serializable

There are many schedulers:

Serializable Level of Isolation
* [[Lock-Based Scheduler]]
* [[Timestamp-Based Scheduler]]
* [[Validation-Based Scheduler]]


== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Concurrency]]
[[Category:Database Systems Architecture]]</text>
      <sha1>n5g57izbpbhpkcy3wyd8o1v7592idc4</sha1>
    </revision>
  </page>
  <page>
    <title>Lock-Based Scheduler</title>
    <ns>0</ns>
    <id>247</id>
    <revision>
      <id>249</id>
      <timestamp>2014-01-03T10:20:17Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4035">== Lock-Based Scheduler ==
This is a [[Scheduler]] that gives [[Serializable Sheduling|Conflict-Serializable Schedule]]

This scheduler is pessimistic: 
* it assumes that something will go wrong, and it's going to prevent that

Notation:
* $w(X)$ - write $X$
* $r(X)$ - read $X$
* $l(X)$ - lock $X$
* $u(X)$ - unlock $X$

Rule:
* before a transaction $T_i$ can read or write a database item $X$, it must obtain the lock on $X$
* if $T_i$ requests a lock that is already taken by other transaction $T_j$, it's paused until $T_j$ releases the lock
* so it's impossible for both $T_i$ and $T_j$ to have a lock on the same database element at the same time


=== Example ===
The following is a legal lock-based schedule:

{| class=&quot;wikitable&quot;
! $T_1$ || $T_2$ ||
|-
| $l_1(A), r_1(A)$ || ||
|-
| $w_1(A)$ || ||
|-
| $l_1(B), u_1(A)$ || ||
|-
| || $l_1(A), r_2(A)$ ||
|-
| || $w_2(A)$ || 
|-
| $l_2(B)$ || || lock is denied, $T_2$ pauses
|-
| $r_1(B), w_1(B)$ || ||
|-
| $r_1(B), w_1(B)$ || ||
|-
| $u_1(B)$ || || $T_1$ releases $B$, $T_2$ can proceed 
|-
| || $l_2(B), u_2(A)$ ||
|-
| || $r_2(B), w_2(B)$ ||
|-
| || $u_2(B)$ ||
|}


Another example:

$S = $
{| class=&quot;wikitable&quot;
! $T_1$ || $T_2$
|-
| $l_1(A), r_1(A), w_1(A), u_1(A),$ ||
|-
| || $l_2(A), r_2(A), w_2(A), u_2(A),$
|-
| || $l_2(B), r_2(B), w_2(B), u_2(B),$
|-
| $l_1(B), r_1(B), w_1(B), u_1(B)$ ||
|}

Is it [[Serializable Scheduling|conflict-serializable]]? 
* We build a precedence graph:
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/pred-graph-3.png
* there is a cycle! $\to$ no conflict serializability
* so even if a lock-based schedule is legal, it doesn't mean it's conflict-serializable


== Tho-Phase Locking ==
To get a conflict-serializable schedule:
* for each $T_i$, all lock requests $l_i$ must precede unlock requests $u_i$

In other words
* we can acquire as many locks as you want,
* but then can only unlock them without being able to acquire them again
* $\to$ cannot do $l_i(X), u_i(X), l_i(X), u_i(X)$ within the same transaction $T_i$

$\to$ all locks are released after the entire manipulation with a DB object is completed
* this way the schedule is guaranteed to be conflict-serializable


=== Theorem ===
A schedule $S$ obtained by Tho-Phase Locking is conflict-serializable


'''Proof:'''

Suppose we have a schedule $S$ in which a transaction doesn't lock after unlocking
* we want to show that we can transform $S$ into a conflict-serializable one by conflict-free swapping

For a schedule with one transaction it's trivial
* assume several transactions

Suppose we have the following schedule: 
* $S = ..., w_B(X), ..., u_B(X), ..., l_A(X), ..., u_A(X), ..., r_A(X), ...$ 
* since $B$ unlocks $X$ there must be $l_B(X)$ that precedes $u_B(X)$
* in this case all actions for element $X$ are performed only by transaction $B$
* by conflict-free swapping can move all actions on $X$ to the front of the schedule
* then remove them and repeat for the remaining elements

$\square$


=== In Practice ===
* Transaction manager sends read/write requests 
* The scheduler itself inserts locks and unlocks - the transactions don't know anything about them 
* Also the locks are usually released after commit
* so if a transaction $T_2$ waits for a lock, it will usually wait until another transaction $T_1$ that keeps the lock commits


== Cons and Pros ==
* Locking is very effective when we have many transactions that both read and write
* When you have few transactions that write it's not efficient - many transactions will have to wait for locks


== Other Approaches ==
There are no problems with two transactions that read at the same time (as long as none of them write)
* there are different kind of locks for that 
* Shared Locks - for reading at the same time
* Exclusive Locks - if you also want to write 

Also there are hierarchical locks 
* locks not on a tuple, but on the whole block


== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Concurrency]]
[[Category:Database Systems Architecture]]</text>
      <sha1>6fhocf2bka3wsz3xeftwqd2ak8oqpia</sha1>
    </revision>
  </page>
  <page>
    <title>Timestamp-Based Scheduler</title>
    <ns>0</ns>
    <id>248</id>
    <revision>
      <id>250</id>
      <timestamp>2014-01-13T09:05:05Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6128">== Timestamp-Based Scheduler ==
This is a [[Scheduler]] that gives [[Serializable Sheduling|Conflict-Serializable Schedule]]

This scheduler is optimistic: 
* it allows any sequence of action
* periodically it checks if everything is okay. yes - continue, no - abort the transaction and restart 


Assume we execute 3 transactions $T_1, T_2, T_3$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/timestamp-scheduler.png
* we allow arbitrary reordering of actions from these transactions
* but we also consistently check if the reordering is equivalent to the [[Serializable Scheduling|serial schedule]] $(T_1, T_2, T_3)$
* if not - some transactions are aborted and restarted 


== Rules ==
Additional information:
* every transaction $T_i$ receives a timestamp $TS(T_i)$
** $TS(T_i)$ can be either a datetime or just a value that gets incremented on each operation 
** the higher the $TS(T_i)$, the later $T_i$ started 
* for each DB item $X$ we associate two timestamps and a boolean flag $C(X)$
** $RT(X)$ - read time of $X$: the $TS(T)$ of the last transaction $T$ that read $X$
** $WT(X)$ - write time of $X$: the $TS(T)$ of the last transaction $T$ that wrote $X$

Basic Rule: 
* $RT(X)$: every time $X$ is read by $T$ check if 
** $TS(T) &gt; RT(X)$
** yes - update the $RT(X) \leftarrow TS(T)$
* $WT(X)$ (initially 0): on every write to $X$ by $T$ check if
** $TS(T) &gt; WT(X)$
** yes - update $WT(X) \leftarrow TS(T)$
* $C(X)$
** true if the latest transaction that wrote to $X$ has committed 
*: this is the transaction $T$ that wrote its $TS(T)$ to $WT(X)$
** false otherwise


=== Problematic Situations ===
==== Problematic Situation 1 ====
suppose we have the following sequence of actions:
# $T_\text{start},$ 
# $U_\text{start},$
# ${\color{blue}{U \text{ writes } X}},$ - allow this because we're optimistic 
# ${\color{red}{T \text{ reads } X}},$  - not consistent with the serial schedule $(T, U)$ $\Rightarrow$ abort $T$
# $...$ 

So the problem is
* $T$ starts before $U$, but $U$ writes before $T$ reads
* should be $T$ reads then $U$ writes

To avoid it we want to check if 
* $TS(T) \geqslant WT(X)$ then we grant a read request $r_T(X)$ to transaction $T$
** i.e. we should not allow reading of things that were modified by transactions that started later than $T$
* otherwise we abort $T$


==== Problematic Situation 2 ====
The sequence of actions:
# $U_\text{start},$ 
# $U \text{ writes } X,$ 
# $T_\text{start},$
# $T \text{ reads } X,$
# ${\color{red}{U_\text{abort}}}, $
# $...$

Problem:
* Actions 1-4 are consistent with the serial schedule $(U, T)$
* However $U$ aborts 
* that means that read of $X$ by $T$ was inconsistent - it will be rolled back to the old value on $U_\text{abort}$

To avoid that:
* reads to $X$ should be delayed until
* the transaction that last modified $X$ has committed 
** i.e. the transaction with timestamp $WT(X)$
** and we wait until $C(X)$ is set to true
* so we do not abort, just pause


==== Problematic Situation 3 ====
Sequence of Actions:
# $T_\text{start},$
# $U_\text{start},$ 
# ${\color{blue}{U \text{ reads } X}},$ - we're optimistic, so the read is successful
# ${\color{red}{T \text{ writes } X}},$ - not consistent with the serial schedule $(T, U)$
# $...$

The problem:
* $T$ starts before $U$, but $U$ reads before $T$ writes
* should be $T$ first writes, then $U$ reads the value written by $T$

Solution:
* a write request $w_T(X)$ should be granted if $TS(T) \geqslant RT(X)$
* i.e. if the transaction $U$ that last read $X$ was created before the current transaction $T$


==== Problematic Situation 4 ====
# $S_\text{start},$
# ${\color{blue}{S \text{ read } X}},$
# $T_\text{start},$
# $U_\text{start},$
# ${\color{blue}{U \text{ writes } X}},$
# ${\color{blue}{T \text{ writes } X}},$ - note that in this case we allow $w_T(X)$ (but ignore it) since it &quot;will&quot; be overwritten if executed $(T, U)$
# $T_\text{commit},$
# ${\color{red}{U_\text{abort}}}, $
# $...$

The problem
* we allow, but ignore write of $T$ to $X$: 
** we know that the value stored in $X$ should be the value written by $U$
** because in the serial schedule $(T, U)$, $U$ would execute after $T$ and overwrite the value of $X$
* but $U$ aborts afterwards
** it means we shouldn't have ignored the write by $T$
** and $X$ should store the value written by $T$ 

Solution:
* $w_T(X)$ is realizable by $T$ if $TS(T) \geqslant RT(X)$ and $TS(T) &lt; WT(X)$
** the transaction $T$ started later that the transaction $S$ that did the last read of $X$
*: $S_\text{start}, T_\text{start}, S \text{ reads } X, T \text{ writes } X$
** and $T$ started earlier than some transaction $R$ that did the write to $X$
*: $T_\text{start}, R_\text{start}, R \text{ writes } X, T \text{ writes } X$
* if $C(X)$ is false then $T$ must be delayed till $C(X)$ becomes true
** i.e. the transaction $R$ that last wrote $X$ has committed
* if $C(X)$ we can ignore the write

=== Timestamp-Based Schedule Rules ===
The rules are:
* every transactin $T$ receives a timestamp $TS(T)$
* to each DB item $X$ we associate values $RT(X), WT(X), C(X)$

Suppose we have a transaction $T$ with $TS(T) = t$ 

$T$ is allowed to read $X$ if
* $t \geqslant WT(X)$
* if $C(X)$ is false, then $T$ is paused until $C(X)$ becomes true or transaction that last wrote $X$ aborts
* if $t &lt; WT(X)$ we abort $T$ and restart it with the next available $TS(T)$

$T$ is allowed to write to $X$ if
* $RT(X) \leqslant t$ and $WT(X) \leqslant t$
* if $t &lt; RT(X)$ then $T$ is aborted and restarted
* if $RT(X) \leqslant t &lt; WT(X)$
** if $C(X)$ is true we do nothing (keep the current state of $X$)
** otherwise we pause $T$ until $C(X)$ becomes true or transaction that last wrote $X$ aborts 

These rules prevent all bad cases



== Cons and Pros ==
* Not very effective when we have many transactions that both read and write - in this case we have to abort and restart many transactions
* When you have few transactions that write it's very efficient - they can proceed immediately


== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Concurrency]]
[[Category:Database Systems Architecture]]</text>
      <sha1>i1106oc30sz7n9l23ia5wkoz7mda8c4</sha1>
    </revision>
  </page>
  <page>
    <title>Validation-Based Scheduler</title>
    <ns>0</ns>
    <id>249</id>
    <revision>
      <id>251</id>
      <timestamp>2014-01-03T10:26:15Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3546">== Validation-Based Scheduler ==
This is a [[Scheduler]] that gives [[Serializable Sheduling|Conflict-Serializable Schedule]]

This scheduler is optimistic (similar idea to [[Timestamp-Based Scheduler]]): 
* it allows any sequence of action
* periodically it checks if everything is okay. yes - continue, no - abort the transaction and restart 


== Rules ==
for every transaction $T$ we record 
* a set of database items $RS(T)$ that were read by $T$
* a set of database items $WS(T)$ that is wants to write / were written by $T$

All transactions are executed in 3 phases
* transactions are '''only allowed to read''' 
** when an item $X$ is read by $T$, $X$ is added to $RS(T)$
* the scheduler validated the schedule based on 
*# actions read by $T$: $RT(T)$
*# actions $T$ wants to write: $WS(T)$ (but has not written yet)
*: if validation fails, $T$ is restarted
* $T$ can write all items from $WS(T)$


=== Problematic Situations ===
==== Problematic Situation 1 ====
Actions:
# $U_\text{start},$
# $T_\text{start},$
# ${\color{red}{T \text{ reads } X}},$
# $U_\text{validate},$
# ${\color{red}{U \text{ writes } X}},$
# $T_\text{validate},$
# ...

The problem:
* $U$ should have written $X$ before $T$ reads it
* not consistent with the serial schedule $(U, T)$
* i.e. it should be $U \text{ writes } X, T \text{ reads } X$

For every transaction $T$ we records 
* $\text{START}(T)$ - the time when $T$ starts
* $\text{VAL}(T)$ - the time when $T$ validates
* $\text{FIN}(T)$ - the time when $T$ finishes

$T$ can successfully validate if 
* $RS(T)$ is disjoint with $WS(U)$: $RS(T) \cap WS(U) = \varnothing$
** $RS(T)$ - reads by the current transactions
** $WS(U)$ - writes by other transactions $U$
** $U$ - all transactions that already validated, but have not finished when $T$ started
** (i.e. those $U$ for which $\text{FIN}(U) &gt; \text{START}(T)$)

In this problematic example we have:
* $X \in WS(U)$ - $U$ has already validated, but has not finished
* $RT(T) \cap WS(U) = \{ X \}$: $T$ read $X$ that was later modified by $Y$
* $T$ will be restarted


==== Problematic Situation 2 ====
Actions:
# $U_\text{validate},$
# $T_\text{validate},$
# ${\color{red}{T \text{ writes } X}},$
# $U \text{ writes } X,$
# $U_\text{finish},$
# $...$

The problem:
* $T$ writes $X$ first - before $U$
** not consistent with the serial schedule $(U, T)$
* should be first write by $U$, then write by $T$
* after validation they are allowed to write in any order, but we have to make sure it respects the $(U, T)$ order

$T$ can successfully validate if 
* $WS(T) \cap WS(U) = \varnothing$
** $WS(T)$ - items that $T$ wants to write (before validation - means &quot;it wants to write&quot;)
** $WS(U)$ - items that $U$ writes (after validation - means either &quot;it wants to write&quot; or &quot;it has written&quot;)
* should hold for all previously validated $U$ that did not finish before $T$ validated,
** i.e. for such $U$ that $\text{FIN}(U) &gt; \text{VAL}(T)$

In this problematic example we have:
* $WS(T) \cap WS(U) = \{ X \}$
** $T$ wants to write $X$
** $U$ also wants to write $X$, but $U$ was validated before $T$
* therefore $T$ is not allowed to start


=== Summary ===
$T$ passes validation if 
* $RS(T) \cap WS(U) = \varnothing$ for all $U$ s.t. $\text{FIN}(U) &gt; \text{START}(T)$
* $WS(T) \cap WS(U) = \varnothing$ for all $U$ s.t. $\text{FIN}(U) &gt; \text{VAL}(T)$

Everything that doesn't pass the validation is aborted and restarted 


== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Concurrency]]
[[Category:Database Systems Architecture]]</text>
      <sha1>183ouucdry2ixvzso7qaj178cnpnyq9</sha1>
    </revision>
  </page>
  <page>
    <title>Serializable Schedule</title>
    <ns>0</ns>
    <id>250</id>
    <revision>
      <id>252</id>
      <timestamp>2014-01-03T10:27:32Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5819">== Serializable Schedule ==
=== Definitions ===
An ''action'' is 
* $r(X)$ - read database element $X$ or 
* $w(X)$ - write database element $X$
* we abstract away from the actual values that are read/written, we are not interested in them

A ''transaction'' $T$ is a sequence of action 
* $r(A), r(B), w(A), w(B)$

A ''schedule'' is a sequence of actions that belong to different transactions 
* $r_1(A), w_1(A), r_2(A), w_2(A), r_1(B), w_1(B), r_2(B), w_2(B)$
* $r_i(X)$ denotes that this action belongs to transaction $T_i$


=== Serializability ===
a ''serial schedule'' is a schedule in which transactions are executed consequently, not concurrently
* e.g. first all actions of $T_1$ and then all actions of $T_2$
* $\underbrace{r_1(A), w_1(A), r_1(B), w_1(B)}_{\text{all actions of $T_1$}}, \underbrace{r_2(A), w_2(A), r_2(B), w_2(B)}_{\text{all actions of $T_2$}}$

Serializable Schedule
* a schedule is called ''serializable'' is there exists an equivalent serial schedule 
* even though we may execute actions concurrently, the effect is guaranteed to be the same as if it was run in isolation

* $S_1 = r_1(A), w_1(A), r_2(A), w_2(A), r_1(B), w_1(B), r_2(B), w_2(B)$
* $S_2 = r_1(A), w_1(A), r_1(B), w_1(B), r_2(A), w_2(A), r_2(B), w_2(B)$
* $S_1 \equiv S_2$, $S_2$ is serial, so $S_1$ is serializable

Not serializable:
* Write-Read conflict: 
** $r_1(A), w_1(A), r_2(A), w_2(A), r_2(B), w_2(B), r_1(B), w_1(B)$
** write by $T_2$ happens before read by $T_1$, but $T_1$ started earlier
** it's not equivalent to any serial schedule

We want to schedule our actions in such a way that the result is serializable

=== Conflict-Serializability ===
Serializability is very hard to achieve 

two actions are ''in conflict'' if
# they belong to the same transaction 
# both deal with the same element and one of the actions is a write

A schedule is ''conflict-serializable'' if
* we can obtain a serial schedule by swapping actions that are not in conflict

Example:
* $S_1 = r_1(A), w_1(A), \underbrace{r_2(A)}_\text{(1)}, \underbrace{w_2(A)}_\text{(2)}, \underbrace{r_1(B)}_\text{(3)}, \underbrace{w_1(B)}_\text{(4)}, r_2(B), w_2(B)$
** $(1) + (2)$ are not in conflict with $(3) + (4)$: they use different DB items
** can swap them and get a serial schedule
* $S_2 = r_1(A), w_1(A), r_1(B), w_1(B), r_2(A), w_2(A), r_2(B), w_2(B)$
* i.e. $S_1$ is conflict-serializable

NB: 
* you never can reorder actions of the same transaction
* otherwise you may change the behavior of this transaction
* what is more, by reordering actions within same transactions it's not possible to get something serial from not serializable schedule


Conflict-Serializability $\Rightarrow$ Serializability

but converse is not true
* $S_1 = w_1(Y), w_2(Y), w_1(X), w_3(X)$
* $S_2 = w_1(Y), w_1(X), w_2(X), w_3(X)$
* $S_1 \equiv S_2$: in $Y$ there's a value written by $T_2$, and in $X$ the value written by $T_3$ 
* but S_1 is not Conflict-Serializable, but Serializable: we cannot swap $w_2(X)$ and $w_1(X)$

== Precedence Graph ==
There is an algorithm that checks if a schedule is conflict-serializable

construct a ''precedence graph'':
* suppose you have a schedule $S$ with several transactions 
* create a node for each transaction 
* connect $T_i$ with $T_j$ if 
** there $\exists$ actions $a_i \in T_i, a_j \in T_j$ s.t. 
** $a_i$ precedes $a_j$ and
** $a_i$ are in conflict $a_j$ and

Example 1:
* $S_1 = {\color{red}{r_2(A)}}, {\color{blue}{r_1(B)}}, w_2(A), r_3(A), w_1(B), {\color{red}{w_3(A)}}, r_2(B), {\color{blue}{w_2(B)}}$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/pred-graph-1.png

Example 2:
* $S_2 = w_1(Y), w_2(y), w_2(X), w_1(X), w_3(X)$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/pred-graph-2.png


'''Thm''' If the precedence graph $G$ of a schedule $S$ is a [[Graphs#Directed Acyclic Graph|DAG]] then
* $S$ is conflict-serializable 
* otherwise it's not

Suppose we have a cycle $T_1 \to ... \to T_n \to T_1$ in $G$
* it means there $\exists$ action $a_1 \in T_1$ on some database item $X$ that follows $a'_n \in T_n$ on the same $X$
** we cannot move $a_1$ by conflict-free swapping to the front
** i.e. cannot put $a_1$ before all actions of $T_n$
* there also $\exists$ $a_n$ that follows some action $a'_1 \in T_1$
** but we cannot move $a_n$ either because of some action $a_{n-1} \in T_{n-1}$
* i.e. we cannot have a conflict-serializable schedule 


But if $G$ is a DAG, we can obtain an equivalent conflict-serializable schedule by [[Topological Ordering]]
* if there are no cycles in $G$ then 
** there $\exists$ a transaction $T_A$ that has no incoming edges in $G$
** otherwise there would be a cycle
* let $a_1$ be the first action of $T_A$
* can move $a_1$ by conflict-free swapping to the front 
** since $T_A$ has no incoming edges, there are no actions that conflict with $a_2$ 
* let $a_2$ be the second action of $T_A$
** also can move it to the front
* repeat for all actions $a_i \in T_A$
* we end up with the following schedule:
** $S' = \underbrace{a_1, a_2, ..., a_k}_{\text{all actions $\in T_A$}}, \underbrace{b_1, c_1, ..., z_p}_{\text{all actions $\not \in T_A$}}$
* now remove all actions of $T_A$, let $G$ be the precedence graph of this schedule and repeat

If there are 2 or more nodes with no incoming edges, just pick one of them 
* the result in any case will be serial
* only the order may be different

$\square$

== Schedulers ==
A [[Scheduler]] is a component of [[Database|Transaction Manager]] that schedules read/write requests.

The following schedulers produce Conflict-Serializable Schedules:
* [[Lock-Based Scheduler]]
* [[Timestamp-Based Scheduler]]
* [[Validation-Based Scheduler]]

== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Concurrency]]
[[Category:Database Systems Architecture]]</text>
      <sha1>esbibhjvn9wl7p95nkww3opiwsvm5m6</sha1>
    </revision>
  </page>
  <page>
    <title>Serializable Sheduling</title>
    <ns>0</ns>
    <id>251</id>
    <redirect title="Serializable Schedule" />
    <revision>
      <id>253</id>
      <timestamp>2014-01-03T10:28:57Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="35">#REDIRECT [[Serializable Schedule]]</text>
      <sha1>nrx2mzlkt13oudr8977nefikimh6u78</sha1>
    </revision>
  </page>
  <page>
    <title>Serializable Scheduling</title>
    <ns>0</ns>
    <id>252</id>
    <redirect title="Serializable Schedule" />
    <revision>
      <id>254</id>
      <timestamp>2014-01-03T10:29:38Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="35">#REDIRECT [[Serializable Schedule]]</text>
      <sha1>nrx2mzlkt13oudr8977nefikimh6u78</sha1>
    </revision>
  </page>
  <page>
    <title>Isolation (databases)</title>
    <ns>0</ns>
    <id>253</id>
    <revision>
      <id>255</id>
      <timestamp>2014-01-03T10:30:48Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1331">== Isolation ==
A transaction is a sequence of updates to the database 
* a transaction must be [[Consistency (databases)|consistent]]
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/dbsa/transaction-consistency.png
* we need to ensure that all the transactions run in isolation
* that is, while one transactions is running, no other transaction should see its intermediate results (which can be inconsistent)


=== Causes ===
Data Sharing (Concurrency)
* suppose that two transactions $T_1$ and $T_2$ are running at the same time
* $T_1$: give 10% rise to all programmers 
* $T_2$: transfer some programmers to business analysts 

Problem here:
* it should be either first $T_1$ and then $T_2$ or vice-versa
* otherwise there will be a lot of problems and unexpected results 
* [[Concurrency Control]] techniques are used for that

=== Transaction Manager ===
* Transaction Manager is a component of a [[Database|DBMS]] that has a scheduler
* The ''scheduler'' is responsible for creating an impressions that all transactions are run in isolation


== Levels of Isolation ==
* Serializable (see [[Serializable Scheduling]])
* ...
* ...
* No Isolation (actions of transactions can be executed in any order)


== See also ==
* [[ACID]]

== Sources ==
* [[Database Systems Architecture (ULB)]]

[[Category:Databases]]</text>
      <sha1>sdw91t20yp6eg61sxa6l2skun55b8nq</sha1>
    </revision>
  </page>
  <page>
    <title>Decision Engineering (ULB)</title>
    <ns>0</ns>
    <id>254</id>
    <revision>
      <id>256</id>
      <timestamp>2014-05-12T09:11:29Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2358">* The course was taken in autumn 2013 at the ULB
* Taught by professor Yves De Smet 


== Syllabus ==
Decision Engineering is about helping to make a decision

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/vt/decision-enginering-overview.png

It includes several disciplines: 
* Voting Theory
* Multicriteria Decision Aid
* Decision Under Risk and Uncertainty
* Game Theory


=== [[Voting Theory]] ===
* [[Voting Theory Relations]]
* [[Voting Theory Examples]]
* [[Voting Theory Exercises]]

{| class=&quot;wikitable&quot;
! Methods || Criteria
|-
|
[[Plurality Voting]] &lt;br/&gt;
[[Two-Round Voting]] &lt;br/&gt;
[[Borda's Rule]] &lt;br/&gt;
[[Condorcet's Rule]]
|
[[Monotonicity]] &lt;br/&gt;
[[Independence to Third Alternatives]] &lt;br/&gt;
[[Condorcet's Rule#Fairness|Condorcet Fairness Criterion]] &lt;br/&gt;
[[Separability]]
|}

Theorems:
* [[May's Theorem]]
* [[Arrow's Impossibility Theorem]]

Other concepts:
* [[Banzhaf Power Index]]
* [[Parliamentary Allocation]]
** [[Hamilton's Method]]
** [[Jefferson's Method]]


=== [[Multi-Criteria Decision Aid]] ===
[[Multi-Objective Optimization]]
* [[Dominance]]
* [[Waste Utilization Problem]]
* [[Weighted Sum Model]]
* [[Ideal Point Model]]

MCDA:
* [[Modeling Preferences]]
* [[Preferential Independence]]

Methods:
* [[Multi-Attribute Utility Theory]]
* [[ELECTRE]]
* [[PROMETHEE]]


=== [[Game Theory]] ===
* [[Normal Form Game]]s
* [[Nash Equilibrium]], [[Dominance]], [[Iterative Removal]]
* [[Prisoner's Dilemma]], [[Battle of the Sexes]]
* [[Cournot Duopoly Model]] and [[Bertrand Duopoly Model]]
* the [[Median Voter Theorem]]


=== Decisions Under Risk and Uncertainty ===
[[Decision Under Uncertainty]]
* [[Max Min Strategy]] and [[Max Max Strategy]]
* [[Hurwitz's Index]]
* [[Min Max Regret Strategy]]
* [[Laplace Rule]]


[[Decision Under Risk]]
* [[Decision Tree (Decision Theory)|Decision Trees]] and [[Decision Tree Exercises]]
* [[Expected Values for Lotteries]]
* [[Expected Utility Theory]]


=== [[Inventory Management]] ===
* Wilson EOQ Model
* EOQ with Gradual Replenishment
* EOQ with Planned Storage


== Info ==
* no public webpage
* http://uv.ulb.ac.be/ course: MATH-H-405, user: &lt;code&gt;visiteur&lt;/code&gt;, password: &lt;code&gt;visiteur&lt;/code&gt;
* folder with all the materials: [[https://www.dropbox.com/sh/gu9dn03vl3y3gk9/u2pLE109sn]]

[[Category:Decision Engineering]]
[[Category:IT4BI]]
[[Category:Notes]]</text>
      <sha1>our4xdejrgn83nunsyc1uuophvz7wtu</sha1>
    </revision>
  </page>
  <page>
    <title>Voting Theory</title>
    <ns>0</ns>
    <id>255</id>
    <revision>
      <id>257</id>
      <timestamp>2014-01-18T10:47:29Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3714">== Voting Theory ==
Voting Theory studies how to take individual rankings of voters and aggregate them to form the global ranking.

Examples:
* Votes for a president of a company/country, etc. All voters communicate their results and based on that the president is chosen
* Search engines: there are many results, how to show them? 


== Notation and Relations ==
* let $A = \{a, b, c, ...\}$ be the set of candidates
* there are $N$ voters 
* each voter can express his preference on the basis of a ''total order''
** i.e. he has to rank all the candidates 

For this notation we define the following relations ([[Voting Theory Relations]])
* Weak and Strong Preference
* Indifference


== Voting Mechanisms and Principles ==
A ''voting mechanism'' (or ''voting procedure'' or ''voting method'') takes a collection of votes (individual preferences of the candidates from set $A$) and forms the global ranking. Usually it choses a single candidate from the set $A$.

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/vt/voting-mechanism.png

There are several voting procedures:
* [[Plurality Voting]]
* [[Two-Round Voting]]
* [[Borda's Rule]]
* [[Condorcet's Rule]]


=== Criteria ===
How to characterize &quot;good&quot; voting methods?

There are several criteria 
* [[Monotonicity]]
* [[Independence to Third Alternatives]]
* [[Condorcet's Rule#Fairness|Condorcet Fairness Criterion]]
* Solution Existence 
* [[Separability]]


{| class=&quot;wikitable&quot;
! || [[Plurality Voting|PV]] || [[Two-Round Voting|2PV]] || [[Borda's Rule|Borda]] || [[Condorcet's Rule|Cond.]]
|-
! [[Monotonicity]]
| [[Plurality Voting#Monotonicity|{{yes}}]]
| [[Two-Round Voting#Monotonicity|{{no}}]] 
| [[Borda's Rule#Monotonicity|{{yes}}]]
| [[Condorcet's Rule#Monotonicity|{{no}}]]
|-
! Solution Existence
| {{yes}} || {{yes}} || {{yes}} || [[Condorcet's Rule#Condorcet Paradox|{{no}}]]
|-
! [[Independence to Third Alternatives|Manipulation]]
| [[Plurality Voting#Independence to Third Alternatives|{{no}}]]
| [[Two-Round Voting#Independence to Third Alternatives|{{no}}]] 
| [[Borda's Rule#Independence to Third Alternatives|{{no}}]] 
| [[Condorcet's Rule#Independence to Third Alternatives|{{no}}]]
|-
! [[Separability]]
| [[Plurality Voting#Separability|{{yes}}]]
| [[Two-Round Voting#Separability|{{no}}]] 
| [[Borda's Rule#Separability|{{yes}}]]
| [[Condorcet's Rule#Separability|{{yes}}]]
|-
! [[Condorcet's Rule#Fairness|Condorcet Fairness]]
| {{no}} 
| {{no}} 
| [[Borda's Rule#Condorcet Fairness|{{no}}]] 
| {{yes}}
|}


Other principles:
* [[Unanimity]]


== Theorems ==
* [[May's Theorem]]
* [[Arrow's Impossibility Theorem]]


== Examples and Exercises ==
* [[Voting Theory Exercises]]
* [[Voting Theory Examples]]


== Misc. ==
* [[Banzhaf Power Index]] - shows how strong a party is
* [[Parliamentary Allocation]] - how to allocate seats between parties in a parliament


== Links ==
* Mathematics of Voting - slides [http://www.ms.uky.edu/~lee/ma111fa09/slides01.pdf] 
* Criteria [http://www.ctl.ua.edu/math103/voting/whatdowe.htm]
* EC228 Voting Theory Lecture Notes [http://www2.warwick.ac.uk/fac/soc/economics/current/modules/ec228/details/lecturenotes/lecturenotesbook.pdf]
* Social Choice Theory and Multicriteria Decision Aiding [http://www-desir.lip6.fr/publications/pub_1389_1_BouyssouMarchantPerny_soc_choice.pdf]
* Book: Voting, Arbitration, and Fair Division [http://xaravve.trentu.ca/pivato/Teaching/voting.pdf]
* Methods vs Voting Criteria [http://en.wikipedia.org/wiki/Voting_system_criterion]

== Sources ==
* [[Decision Engineering (ULB)]]
* The mathematics of voting and elections: Paradox, deception, and chaos [http://xaravve.trentu.ca/pivato/Teaching/votingslides.pdf]

[[Category:Voting Theory]]</text>
      <sha1>9skzvj6kfh9sjrt04x4m38lyjctambm</sha1>
    </revision>
  </page>
  <page>
    <title>Voting Theory Relations</title>
    <ns>0</ns>
    <id>256</id>
    <revision>
      <id>258</id>
      <timestamp>2014-01-09T17:26:35Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3025">== Voting Theory Relations ==
The relations that are defined for [[Voting Theory]] principles and methods. Also used in theorems such as [[May's Theorem]] or [[Arrow's Impossibility Theorem]]


=== Notation ===
* let $A = \{ a_1, ..., a_k \}$ be the set of candidates
* let $V = \{ 1, 2, ..., N \}$ be the set of voters; there are $N$ voters 
* each voter can express his preference on the basis of a ''total order''
** i.e. he has to rank all the candidates
** $R_j(a_i)$ is the position of candidate $a_i$ in the ranking of voter $j$


Based on this notation let us define the following relations:
* Preference (or Strong Preference)
* Indifference 
* &quot;At least as good as&quot; Relation (or Weak Preference) - the combination of preference and indifference


== Preference Relation ==
$&gt;$ (or $P$) is the (strong) preference relation, voters use it to express the preference

Example: 
* $A = \{a, b, c, d\}$
* a vote is $b &gt; a &gt; c &gt; d$

It satisfies three axioms:
* ''completeness''
** for any $x$ and $y$ either $x &lt; y$ or $y &lt; x$
* ''transitivity'' (or ''consistency'')
** $\forall x, y, z \in A: x &gt; y \land y &gt; z \Rightarrow x &gt; z$
* ''asymmetric''
** $\forall x, y: (x &gt; y) \Rightarrow \overline{ y &gt; x }$


Notation
* $P_i$ shows the individual preference of voter $i$
** $x \ P_1 \ y$  means that voter 1 prefers $x$ to $y$
* $P$ shows the global aggregated preference 



== Indifference Relation ==
$\sim$ or $I$ is the indifference relation, voters use it to express that both candidates are equally good

Properties: 
* indifference is ''symmetric''
** $x \ I \ y \iff y \ I \ x$
* indifference is not always transitive
** cups of coffee!
** but in some cases is: for instance, in the [[Arrow's Impossibility Theorem]] it's considered transitive


Notation
* $I_i$ is an individual indifference of voter $i$
* $I$ is the global indifference  


=== At Least As Good As Relation ===
$\geqslant$ or $S$ - means &quot;at least as good as&quot; - indifferent or better, sometimes referred as ''weak preference''
* $S \equiv (P \lor I)$ or $\geqslant \equiv [&lt; \lor \sim]$
* the opposite of $a \ S \ b$ is $b \ P \ A$:
** $\overline{a \ S \ b} \equiv (a \ \overline{S} \ b) \equiv (a \ \overline{P \lor I} \ b) \equiv (a \ (\overline{P} \land \overline{I}) \ b) \equiv a \ \overline{P} \ b \equiv b \ P \ a$
** not preferred and not indifferent


Properties
* for any pair $(x, y), x,y \in A, x \ne y$ 
** $x \ S \ y \iff [x \ P \ y] \lor [x \ I \ y]  \lor [y \ I \ x]$
** $x \ S \ y \not \Rightarrow y \ P \ x$!!!
* ''completeness''
** $\forall x, y \in A:$ either  $x \ S \ y$ or $y \ S \ x$
* ''transitivity''  (or ''consistency'')
** $\forall x, y, z \in A: x \ S y \land y \ S \ z \Rightarrow x \ S \ z$

We can use express Preference and Indifference via this relation:
* $x \ P \ y \equiv [x \ S \ y] \land [y \ \overline{S} \ x]$
* $x \ I \ y \equiv [x \ S \ y] \land [y \ S \ x]$



== Links ==
* http://en.wikipedia.org/wiki/Pairwise_comparison

== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Voting Theory]]</text>
      <sha1>a7m39qx1q6c27t9nxntcvhvbkpu8d2z</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Voting Theory</title>
    <ns>14</ns>
    <id>257</id>
    <revision>
      <id>259</id>
      <timestamp>2014-01-06T06:35:04Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="58">[[Category:Decision Engineering]]
[[Category:Mathematics]]</text>
      <sha1>m64yiwzb06ruxl4t8egov65w89w1k1b</sha1>
    </revision>
  </page>
  <page>
    <title>Plurality Voting</title>
    <ns>0</ns>
    <id>258</id>
    <revision>
      <id>260</id>
      <timestamp>2014-01-06T06:51:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3318">== Plurality Voting ==
This a voting mechanism from [[Voting Theory]]

* $A$ - the sets of candidates
* Every voter tells his preferred candidate in the form of personal ranking
* let $S(a)$ define the number of voters that prefer $a$ to all other candidates
* the candidate $a$ that gets the majority of votes (the best $S(a)$ score) gets elected 


=== Example ===
* $a &gt; b &gt; c$ - 11 votes
* $b &gt; a &gt; c$ - 8 votes
* $c &gt; b &gt; a$ - 2 votes

$a$ wins:
* $S(a) = 11, S(b) = 8, S(c) = 2$


== Criteria ==
Satisfies: 
* [[Monotonicity]]
* [[Separability]]

Does not satisfy:
* [[Independence to Third Alternatives]]
* [[Condorcet's Rule#Fairness|Condorcet Fairness Criterion]]


=== [[Monotonicity]] ===
$R$ some ranking and $S$ are the Plurality Voting scores

Suppose the candidate $a$ improves his positions by one vote
* let $S'$ be the new scores and $R'$ be the new ranking
* let $b$ be the candidate from who $a$ took the vote
* $S'(a) = S(a) + 1, S'(b) = S(b) - 1$
* we don't care about other candidates $c$: $S'(c) = S(c)$


Consider two cases: 
* (a) the candidate $x$ does not become the winner
* (b) the candidate $x$ becomes the winner 

Case (a): 
* $R'(a) \ne 1$: $a$ is not the winner
* then he was not the winner before: $R(a) \ne 1$
* his position didn't become worse nor better: he still looses 

Case (b):
* $R'(a) = 1$: the candidate $a$ is now the winner
* there are two cases:
** either he was the winner already and took one vote from a loosing candidate - and $a$ still winner (his position didn't become worse)
** or he took the vote from the winner and became the winner himself - $a$ improved his positions


Therefore, the [[Monotonicity]] criterion is satisfied by the Plurality Voting.


=== [[Separability]] ===
Suppose we have two regions: $A$ and $B$, $V = A \cup B$
* for $A$ the ranking is $a_1 &gt; ... &gt; a_n$
* for $B$ the ranking is $a_1 &gt; ... &gt; a_n$

Then the scores are:
* for $A$: $S_A(a_1) &gt; ... &gt; S_A(a_n)$
* for $B$: $S_B(a_1) &gt; ... &gt; S_B(a_n)$

And for $V$ they are:
* $S_V(a_1) = S_A(a_1) + S_B(a_1)$
* $S_V(a_2) = S_A(a_2) + S_B(a_2)$
* $...$
* $S_V(a_n) = S_A(a_n) + S_B(a_n)$

Or,
* $S_V(a_1) &gt; ... &gt; S_V(a_n) \Rightarrow$
* for $V$ the ranking is $a_1 &gt; ... &gt; a_n$
* therefore, [[Separability]] is satisfied

Note that it will hold for any partition of $V$


=== [[Independence to Third Alternatives]] ===
There is a counter-example that shows that this property is not satisfied. 

Preferences:
* $4: a {\color{grey}{&gt; b &gt; c}}, S(a) = 4$
* $2: c {\color{grey}{&gt; b &gt; a}}, S(c) = 2$
* $3: b {\color{grey}{&gt; c &gt; a}}, S(b) = 3$
* note that here only the first candidate in ranking is important
* $a$ wins the election

Now assume $c$ withdraws:
* $4: a &gt; b$
* $2 + 3: b &gt; a$
* two extra voters now prefer $b$ because they can no longer vote for $c$ 
* so now $b$ wins
* therefore this method suffers from Manipulation


=== [[Condorcet's Rule#Fairness|Condorcet Fairness Criterion]] ===
This property is not satisfied
* see example in [[Voting Theory Examples#Example 1: Plurality Voting]]


== Links ==
* http://www.ctl.ua.edu/math103/voting/pluralit.htm


== Sources ==
* [[Decision Engineering (ULB)]]
* Social Choice Theory and Multicriteria Decision Aiding [http://www-desir.lip6.fr/publications/pub_1389_1_BouyssouMarchantPerny_soc_choice.pdf]

[[Category:Voting Theory]]</text>
      <sha1>rzkhge4hvx87wsps7rcdjtlvdgdr4cj</sha1>
    </revision>
  </page>
  <page>
    <title>Two-Round Voting</title>
    <ns>0</ns>
    <id>259</id>
    <revision>
      <id>261</id>
      <timestamp>2014-01-06T06:53:41Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2802">== Two-Round Voting ==
This a voting mechanism from [[Voting Theory]]. It is essentially the same as [[Plurality Voting]], but run in two rounds

Given set $A$ of candidates
* Round 1: Using plurality voting mechanism, choose two candidates $a, b \in A$
* Round 2: Plurality voting only between the two $a$ and $b$ 


Example
* here we assume that preferences are ''stable'': people don't change their preferences between two rounds
* Round 1:
** $a &gt; b &gt; c$ - 11 votes
** $b &gt; a &gt; c$ - 8 votes
** $c &gt; b &gt; a$ - 2 votes
** $a$ and $b$ win the 1st round
* Round 2:
** (we just remove $c$ from the previous rankings)
** $a &gt; b$ - 11 votes
** $b &gt; a$ - 8 + 2 votes



== Criteria ==
This method satisfies:


This method does not satisfy:
* [[Monotonicity]]
* [[Separability]]
* [[Condorcet's Rule#Fairness|Condorcet Fairness]]


=== [[Monotonicity]] ===
$N = 16$ and $A = \{x, y, z\}$ 

We have the following individual preferences: 
* 6 voters $x &gt; y &gt; z$
* 5 voters $z &gt; x &gt; y$
* 4 voters $y &gt; z &gt; x$
* 2 voters $y &gt; x &gt; z$

Elections:
* Round 1: $x$ and $y$ win ($x=6, z=5, y=6$)
* Round 2: $x$ wins (6+5: $x &gt; y$, 6: $y &gt; x$)


But suppose that $x$ manages to also convince the last two voters that he is better:
* 6 voters $x &gt; y &gt; z$
* 5 voters $z &gt; x &gt; y$
* 4 voters $y &gt; z &gt; x$
* 2 voters $x &gt; y &gt; z$

Note that $x$ by improving his position should remain the winner

Elections:
* Round 1: $x$ and $z$ ($x=6+2, z=5, y=4$)
* Round 2: $z$ wins! (not $x$!) (6+2: $x &gt; y$, 9: $z &gt; x$)

This counter-example shows that the [[Monotonicity]] principle is not respected by Two-Round Voting method.


=== [[Separability]] ===
Suppose we run an election in Belgium
* there are 2 communes - 2 regions
* we have 3 candidates: $A = \{a, b, c\}$
* $N = 13$ for each region

{| class=&quot;wikitable&quot;
! || Region I || Region II 
|-
| preferences
| 
* 4: $a &gt; b &gt; c$
* 3: $b &gt; a &gt; c$
* 3: $c &gt; a &gt; b$
* 3: $c &gt; b &gt; a$
|
* 4: $a &gt; b &gt; c$
* 3: $c &gt; a &gt; b$
* 3: $b &gt; a &gt; c$
* 3: $b &gt; a &gt; c$
|-
| Round 1
| ${\color{blue}{a: 4}}, b: 3, {\color{blue}{c: 6}}$
| ${\color{blue}{a: 4}}, {\color{blue}{b: 6}}, c: 3$
|-
| Round 2
| ${\color{blue}{a: 7}}, c: 6$
| ${\color{blue}{a: 7}}, b: 6$
|}

In both regions $a$ wins.

But if we consider the global region, we'll have different results:
* Round 1: ${\color{red}{a: 8}}, {\color{blue}{b: 9, c: 9}}$ - note that $a$ loses and doesn't go to the next round
* Round 2: ${\color{blue}{b: 17}}, c: 9$
* $c$ wins

So the separability principle is not satisfied in this example. 


=== [[Condorcet's Rule#Fairness|Condorcet Fairness Criterion]] ===
Is not satisfied
* see an example in [[Voting Theory Examples#Example 1: Two-Round Voting]]



== Links ==
* http://www.ctl.ua.edu/math103/voting/methodof.htm

== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Voting Theory]]</text>
      <sha1>gex7uhvpf22jswf7jb0p09uoxcokzjm</sha1>
    </revision>
  </page>
  <page>
    <title>Borda's Rule</title>
    <ns>0</ns>
    <id>260</id>
    <revision>
      <id>262</id>
      <timestamp>2014-02-09T13:31:55Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5336">== Borda's Rule ==
Borda was a director for the French Academy of science. He proposed a Voting Mechanism for [[Voting Theory]] based on points:
* assign weights to all the candidates in the ranking
* do not consider just the most preferable 


The Borda Rule: 
* $k$ candidates from set $A$  
* $N$ voters communicate their individual preferences $P_i$
* for each individual preference $P_i$ assign the points:
** the 1st candidate in $P_i$ gets $k$ points
** the 2nd candidate in $P_i$ gets $k - 1$ points
** the $j$th candidate in $P_i$ gets $k - j + 1$ points
** the $k$th candidate in $P_i$ gets 1 point
** so define the ''individual Borda score'' $S_i(a)$ as the score that candidate $a$ receivers from a voter $i$
** $S_i(a) = k - \text{pos}_i (a)$ where $\text{pos}_i(a)$ is the position of $a$ in $R_i$
* define the ''Borda score'' $B(c)$ for candidate $c$ as the sum of points from all $P_i$
** $B(c) = \sum_j S_j(c)$
* the candidate with the highest Borda score wins the election


=== Example ===
Individual preferences:
* $a &gt; b &gt; c$ - 11 votes
* $b &gt; a &gt; c$ - 8 votes
* $c &gt; b &gt; a$ - 2 votes

Scores:
* $B(a) = 3 \cdot 11 + 2 \cdot 8 + 1 \cdot 2 = 51$
* $B(b) = 3 \cdot 8 + 2 \cdot 11 + 2 \cdot 2 = 50$
* $B(c) = 1 \cdot 11 + 1 \cdot 8 + 2 \cdot 3 = 25$

$a$ gets elected


== Criteria ==
This method satisfies:
* [[Monotonicity]]
* [[Separability]]

This method does not satisfy:
* [[Independence to Third Alternatives]]
* [[Condorcet's Rule#Fairness|Condorcet Fairness]]


=== [[Monotonicity]] ===
* let $A$ be the set of candidates: $A = \{a, b, c, ...\}$
* $N$ voters 
* suppose $x$ improves its positions only for one voter $j$
** i.e. there's a new preference ranking $P'_j$ where the candidate $x$ has a better position than in the old preference ranking $P_j$
** if $a$ improved his ranking on $m$ positions, then $S'_j(x) = S_j(x) + m$ ($m &gt; 0$)

Now let's analyze how it will affect the global score
* the score before: $B(x) = \sum_i S_i(x)$ 
* the score after: $B'(x) = \sum_i S'_i(x) = ...$
** $... \sum_{i \ne j} S'_x(x) + S'_j(x) = ...$ 
** the scores for $i \ne j$ has not changed, so can replace them by the old score
** $... \sum_{i \ne j} S_x(x) + S'_j(x) = ...$
** and  $S'_j(x) = S_j(x) + m$
** $... \sum_{i \ne j} S_x(x) + S_j(x) + m = B(x) + m$
* so $B'(x) = B(x) + m \Rightarrow B'(x) &gt; B(x)$
* and therefore the Monotonicity principle is respected


=== [[Separability]] ===
[[Separability]] is respected if
* we divide the region $\Omega$ into two regions $N$ and $\overline{N}$
* the global ranking is the same in $N$ and $\overline{N}$ and the same candidate $a$ wins
* then if considered the whole region $\Omega$, the global ranking should be the same and the same candidate $a$ should win

Suppose that 
* $S_N(a) \geqslant S_N(b)$ and $S_\overline{N}(a) \geqslant S_\overline{N}(b)$
** and therefore $B_N(a) \geqslant B_N(b)$ and $B_\overline{N}(a) \geqslant B_\overline{N}(b)$ (1)
** i.e. in two regions the relation between candidates $a$ and $b$ is the same
* consider the whole region $\Omega$: 
** $B(a) = \sum_j S_j(a) = ...$ 
** can split the sum into two parts: for $N$ and for $\overline{N}$
** $... \sum_{j \in N} S_j(a) + \sum_{j \not \in N} S_j(a) = B_N(a) + B_\overline{N}(a)$ 
** the same for $b$: $B(b) = B_N(b) + B_\overline{N}(b)$
* so because of (1) can say that $B(a) \geqslant B(b)$
* thus the Separability principle is respected


=== [[Independence to Third Alternatives]] ===
Consider this example:
* $N = 7, A = \{a, b, c, d\}$

Preferences:
* 3 voters: $c &gt; b &gt; a &gt; d$
* 2 voters: $b &gt; a &gt; d &gt; c$
* 2 voters: $a &gt; d &gt; c &gt; b$
* The outcome is $a &gt; b &gt; c &gt; d$

$d$ decides to withdraw - anyway he has no chance of winning
* but it has a strong effect on the result!
* Now the global ranking is $c &gt; b &gt; a$ - the complete opposite!


Another example:
* $N = 5, A = \{a, b, c\}$

Preferences:
* 2: $a &gt; b &gt; c$
* 1: $c &gt; a &gt; b$
* 2: $b &gt; c &gt; a$

Scores:
* $B(a) = 9, B(b) = 11, B(c) = 9$ 
* outcome: $b &gt; a \geqslant c$

Now $d$ also decides to participate:
* 2: $a &gt; d &gt; b &gt; c$
* 1: $c &gt; a &gt; d &gt; b$
* 2: $b &gt; c &gt; a &gt; d$

Scores are:
* $B(a) = 15 &gt; B(b) = 14 &gt; B(c) = 10 &gt; B(d) = 9$
* note that even though $d$ is the last one in the global rating, adding him changed the winner!


So we see that by carefully choosing new candidates it's possible to manipulate the results. 


=== [[Condorcet's Rule#Fairness|Condorcet Fairness]] ===
Consider these individual rankings for $A = \{a, b, c\}, N = 5$
* 3: $a &gt; b &gt; c$
* 2: $b &gt; c &gt; a$

Borda Score:
* $S(a) = 3 \cdot 3 + 2 \cdot 1 = 11$
* $S(b) = 3 \cdot 2 + 2 \cdot 3 = 12$
* $S(c) = 2 \cdot 2 + 3 \cdot 1 = 7$
* $b$ wins the election

However in pair-wise comparison we see that 
* $a &gt; b$ for 3 voters
* $b &gt; a$ for 2 voters

$\to$ the majority prefers $a$ over $b$ but $b$ wins the election
* the Condorcet Fairness criterion is not satisfied 


== &quot;Modified&quot; Borda's Rule ==
Slightly different approach
* instead of assigning points to all $k$ candidates
* assign points to $n &lt; k$ candidates
* i.e. assign $n$ points to 1st, $n-1$ to 2nd, ..., $1$ to $n$th and 0 to the rest


== Links ==
* http://www.ctl.ua.edu/math103/voting/borda.htm

== Sources ==
* [[Decision Engineering (ULB)]]
* Voting Fairness Criteria [http://www.math.unl.edu/~bharbourne1/M203JSpr09/VotingFairnessHandout.pdf]

[[Category:Voting Theory]]</text>
      <sha1>4pzjvsjxuyosaso7hn3xws80p5mp9qv</sha1>
    </revision>
  </page>
  <page>
    <title>Condorcet's Rule</title>
    <ns>0</ns>
    <id>261</id>
    <revision>
      <id>263</id>
      <timestamp>2014-01-06T06:59:36Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4366">== Condorcet's Rule ==
This a voting mechanism from [[Voting Theory]].

The main idea:
* all candidates are compared in pairs
* prefer the candidate who are preferred by the majority in pair-wise comparison


=== Fairness ===
We say that a voting system (procedure) is ''fair'' when 
* if we choose a candidate $x$ then 
* $x$ can beat every other candidate in a pair-wise election
* in this case $x$ is called ''the Condorcet winner''

If $x$ wins the election but it loses in pairwise comparison
* then the Condorcet fairness criteria is not satisfied

Many other [[Voting Theory]] methods do not satisfy this criterion:
* [[Plurality Voting]]
* [[Two-Round Voting]]
* [[Borda's Rule]]

But the ''Condorcet Voting System'' (discussed below) does satisfy it.


=== Condorcet Voting System ===
Idea:
* all candidates from the set $A$ are compared in pairs 
* there are $N$ voters
* $n_{ij}$ is the number of voters that prefer $i$ to $j$ (i.e. they say $i &gt; j$) 
* $n_{ij} + n_{ji} = N$

$i$ is preferred globally to $j$ $\iff n_{ij} &gt; \cfrac{N}{2}$

Preference Graph:
* we depict all preferences in a graph
* each candidate is a node
* an edge between two nodes $a$ and $b$ means &quot;$a$ is preferred over $b$&quot; ($a &gt; b$)

We find the winner by looking for an node that has no incoming edges
* it means that this candidate is preferred to all other candidates 


=== Example ===
Individual rankings:
* $a &gt; b &gt; c$ - 11 voters
* $b &gt; a &gt; c$ - 8 voters
* $c &gt; b &gt; a$ - 2 voters

Pair-wise comparisons:
* $a \text{ vs } b$: $n_{ab} = 11, n_{ba} = 10 \Rightarrow a &gt; b$
* $a \text{ vs } c$: $n_{ac} = 19, n_{ca} = 2 \Rightarrow a &gt; c$
* $b \text{ vs } c$: $n_{bc} = 19, n_{cb} = 2 \Rightarrow b &gt; c$

The Preference Graph for this example is
: https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/vt/condorcet-ex1.png


== Condorcet Paradox ==
The Condorcet winner does not always exist - this is called ''the Condorcet Paradox''.
* when there's a cycle in the Preference Graph - there is no winner 

=== Example ===
$A = \{x, y, z\}, N = 60$

Individual rankings:
* 23: $x &gt; y &gt; z$
* 17: $y &gt; z &gt; x$
* 2:  $y &gt; x &gt; z$
* 10: $z &gt; x &gt; y$
* 8:  $z &gt; y &gt; x$

The preference graph has a cycle:
: https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/vt/condorcet-paradox.png


== Criteria ==
This rule satisfies:
* Condorcet's Fairness Criteria
* [[Separability]]

Does not satisfy:
* [[Monotonicity]]
* Solution Existence (see [[Condorcet Paradox]])


=== [[Monotonicity]] ===
Suppose we have the following ranting:
* 1 vote: $a &gt; b &gt; c$
* 1 vote: $b &gt; c &gt; a$
* 1 vote: $a &gt; c &gt; b$

Let's build the preference graph:
* $a$ vs $b$: $n_{ab} = 2, n_{ba} = 1 \Rightarrow a &gt; b$
* $a$ vs $c$: $n_{ac} = 2, n_{ca} = 1 \Rightarrow a &gt; c$
* $b$ vs $c$: $n_{bc} = 2, n_{cb} = 1 \Rightarrow b &gt; c$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/vt/condorcet-monotonicity-1.png

Suppose now $c$ improves his position:
* 1 vote: $a &gt; b &gt; c$
* 1 vote: $b &gt; c &gt; a$
* 1 vote: ${\color{blue}{c &gt; a}} &gt; b$

We have the following preference graph:
* $a$ vs $b$: $n_{ab} = 2, n_{ba} = 1 \Rightarrow a &gt; b$
* $a$ vs $c$: $n_{ac} = 1, n_{ca} = 2 \Rightarrow {\color{blue}{c &gt; a}}$
* $b$ vs $c$: $n_{bc} = 2, n_{cb} = 1 \Rightarrow b &gt; c$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/vt/condorcet-monotonicity-2.png
* no one is the winner now - there is no solution

So by improving his position $c$ should stay in at least the same position
* but now he is not - everybody loses


=== [[Separability]] ===
Say we have two regions $A$ and $B$, and $A \cup B = V$. 
* suppose for both $A$ and $B$ we have same ranking: $a$ is preferred to $b$
** $n^A_{ab} &gt; n^A_{ba}$ for $A$ and $n^B_{ab} &gt; n^B_{ba}$ for $B$ 
* if we run the election in $V$ we will get:
** $n_{ab} = n^A_{ab} + n^B_{ab}$, $n_{ba} = n^A_{ba} + n^B_{ba}$
** $n^A_{ab} &gt; n^A_{ba} \land n^B_{ab} &gt; n^B_{ba} \Rightarrow n_{ab} &gt; n_{ba}$
* so $a$ is preferred over $b$ in the whole region $V$ as well

Thus, [[Separability]] is respected. 



== Links ==
* http://www.ctl.ua.edu/math103/voting/methodpc.htm

== Sources ==
* [[Decision Engineering (ULB)]]
* Mathematics of Voting, slides [[http://www.ms.uky.edu/~lee/ma111fa09/slides01.pdf]]
* Voting Fairness Criteria [http://www.math.unl.edu/~bharbourne1/M203JSpr09/VotingFairnessHandout.pdf]

[[Category:Voting Theory]]</text>
      <sha1>cejtd82njge39zddw4d4j1q6qhf3exi</sha1>
    </revision>
  </page>
  <page>
    <title>Monotonicity</title>
    <ns>0</ns>
    <id>262</id>
    <revision>
      <id>264</id>
      <timestamp>2014-02-09T13:36:51Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="910">== Monotonicity ==
The monotonicity is a [[Voting Theory]] criterion/principle that characterizes voting methods for choosing the winner. 


''Monotonicity'' is satisfied when:
* if 
** an alternative $x$ rises or does not fall in the individual ordering and
** $x$ was preferred to another alternative $y$ before the change in the individual orderings
* then
** (1) $x$ should still remain at least at the same position
** (2) if $x$ is a winner, it should remain the winner
** (note that (1) $\Rightarrow$ (2))


== Theorems ==
This principle is used in two important [[Voting Theory]] theorems:
* [[May's Theorem]]
* [[Arrow's Impossibility Theorem]]


== Methods ==
Methods that respect Monotonicity:
* [[Plurality Voting]]
* [[Borda's Rule]]

Methods that don't respect Monotonicity
* [[Two-Round Voting]]
* [[Condorcet's Rule]]


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Voting Theory]]</text>
      <sha1>1c5lvmjwvh5jpbech2ntll8kitn336u</sha1>
    </revision>
  </page>
  <page>
    <title>Independence to Third Alternatives</title>
    <ns>0</ns>
    <id>263</id>
    <revision>
      <id>265</id>
      <timestamp>2014-02-09T13:41:45Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3325">== Independence to Third Alternatives ==
Independence to Third Alternatives, or Independence to Irrelevant alternatives is a principle of [[Voting Theory]].
* it says that if another alternative is added or removed, the position of a candidate should remain at least as good as it was
* this is an important principle in [[Arrow's Impossibility Theorem]]
* also in [[MCDA]] methods violation of this principle leads to [[Rank Reversal]]


=== Definition ===
* Suppose we have a set of alternatives (candidates) $A^*$
* Let us consider 4 different individual rankings over the sets $A^*$ and $A$ s.t. $A \subset A^*$ 
: (note that $A$ is a strict subset of $A^*$)
* The rankings are $R_1, R_2$ and $R'_1, R'_2$
* $S_1, S_2, S'_1, S'_2$ are indifference relations defined by these orderings (respectively)
* we assume that $R_1 \equiv R'_1$ and $R_2 \equiv R'_2$ for the set $A$
*: that is, $\forall x,y \in A$: 
*# $x \ S_1 \ y \iff x \ S'_1 \ y$ 
*# $x \ S_2 \ y \iff x \ S'_2 \ y$ 

Example:
* $A^* = \{x, y, z\}$
** $R_1: x &gt; y &gt; z, R'_1: z &gt; y &gt; z$
** $R_2: z &gt; y &gt; x, R'_2: y &gt; x &gt; z$ 
* now restrict ourselves to $A = \{x, y\} \subset A^*$
** $R_1 \equiv R'_1$ and $R_2 \equiv R'_2$ 
** the only thing that changes is the relative position of $z$ within the pairs of rankings


A voting method $H$ is ''independent to third alternatives'' if 
* the global ordering produced by $H$ under the set $A$ is the same for both rankings such rankings:
* $H(R_1, R_2) |_A \equiv  H(R'_1, R'_2) |_A$

In other words, ordering of the set $A^* - A$ is irrelevant to the choice over $A$


=== Example 1 ===
* Consider two dishes: beef and lamb
* The choice between these two alternatives should not change when pork is also available
* pork is ''irrelevant alternative'' to the preference ordering of beef and lamb


=== Example 2 ===
Suppose there exist two ways to subscribe to some newspaper:
* paper subscription $P$: 100 USD
* web version $W$: 60 USD

Note that for the publisher the web version costs nearly nothing


The publisher proposes the following:
* $P$: 100 USD, $W$: 60 USD, $P+W$ also 100 USD.
* in this case we see that no rational decision taker will ever take just $P$, but always $P+W$

Before the preposition the distribution of readers could be this:
* $P$ for 100 USD: 30%
* $W$ for 60 USD: 70%

After: 
* $P$ for 100 USD: 0%
* $W$ for 60 USD: 30%
* $P+W$ for 100 USD: 70% 

The part of readers switched $\Rightarrow$ More money


----

There are several ways in which a method may suffer from dependence to 3rd alternatives:
* Risk of Manipulation



== Risk of Manipulation ==
A method suffers from the ''Risk of Manipulation'' if the outcome of an election can be changed by
* adding a new candidate or
* deleting a candidate 

This manipulation is also sometimes called ''control''.

Manipulation:
* suppose somebody knows the individual rankings 
* they may propose a new candidate that will take some votes 
* this way influencing the final result

Methods that suffer from the manipulation:
* [[Plurality Voting]]
* [[Two-Round Voting]]
* [[Condorcet's Rule]]
* [[Borda's Rule]]



== Sources ==
* [[Decision Engineering (ULB)]]
* EC228 Voting Theory Lecture Notes [http://www2.warwick.ac.uk/fac/soc/economics/current/modules/ec228/details/lecturenotes/lecturenotesbook.pdf]

[[Category:Voting Theory]]</text>
      <sha1>gpgjh5n4xipwcp8br559umd9hwntuw4</sha1>
    </revision>
  </page>
  <page>
    <title>Separability</title>
    <ns>0</ns>
    <id>264</id>
    <revision>
      <id>266</id>
      <timestamp>2014-02-09T13:33:37Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1154">== Separability ==
The monotonicity is a [[Voting Theory]] principle that characterizes voting methods for choosing the winner. 

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/vt/separability.png

The ''separability'' principle is satisfied if
* when we split a region $\Omega$ into subregions $B$ and $\Omega - B$ and run the election in both
* if the same candidate $a$ wins in both sub regions $B$ and $\Omega - B$
* then $a$ should win if the election were run for the whole region $\Omega$


Also, when considering the whole rankings:
* suppose for $B$ the ranking is $a_1 &gt; ... &gt; a_n$ and for $\Omega - B$ the ranking is $a_1 &gt; ... a_n$
* then for $\Omega$ the ranking should also be  $a_1 &gt; ... &gt; a_n$


It this criterion is not satisfied, then we can split the region into subregions in such a way that we achieve the desired outcome (i.e. it may lead to manipulation)


== Methods ==
Methods that respect Separability:
* [[Plurality Voting]]
* [[Condorcet's Rule]]
* [[Borda's Rule]]

Methods that don't respect Separability:
* [[Two-Round Voting]]



== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Voting Theory]]</text>
      <sha1>op8ev62u7dcras0qd8gh4gm75r6ttkx</sha1>
    </revision>
  </page>
  <page>
    <title>May's Theorem</title>
    <ns>0</ns>
    <id>265</id>
    <revision>
      <id>267</id>
      <timestamp>2014-01-06T07:25:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1872">== May's Theorem ==
May's Theorem is a [[Voting Theory]] theorem

Desirable Properties 
* Neutrality - we don't look at the names of candidates
* Anonymity - we just count the votes without looking at the names of voters
* [[Monotonicity]]

=== Theorem ===
With two candidates ($A = \{a, b\}$) the only voting mechanism that satisfies all these three  properties is [[Plurality Voting]]

; Anonymity:
* the only possible thing to do is to count the number of voters that prefer $a$ to $b$ and $b$ to $a$:
* let $N(a &gt; b)$ denote the number of people who prefer $a$ to $b$ and $N(b &gt; a)$ - $b$ to $a$
* by neutrality we can say without loss of generality that $N(a &gt; b) &gt; N(b &gt; a)$

For the case when $N(a &gt; b) &gt; N(b &gt; a)$ there are two possible outcomes:
# $a$ is elected - this case is the [[Plurality Voting]] case
# $b$ is elected - not [[Plurality Voting]]

Case 2
: $N(a &gt; b) &gt; N(b &gt; a)$ but $b$ wins over $a$ - let's show that this assumption leads to contradiction

So suppose that the candidate who receives less votes gets elected
* $N(a &gt; b) &gt; N(b &gt; a) \Rightarrow N(a &gt; b) = N(b &gt; a) + k$ for some $k &gt; 0$
* by applying the [[Monotonicity]] principle (we assume it's satisfied) we improve $b$'s position:
: $N(a &gt; b) = N(b &gt; a) + 1$: $b$ still gets elected
* continue improving $b$'s positions
: $N(a &gt; b) = N(b &gt; a) - k' \Rightarrow N(a &gt; b) &lt; N(b &gt; a)$
* since the candidate with fewer votes gets elected, not $a$ wins
* thus [[Monotonicity]] is not satisfied: by improving his position $b$ no longer wins
* contradiction: by monotonicity $b$ should remain elected, but by the assumption - $a$


Therefore the only possible outcome under the assumed principles is $a$ wins - which is the [[Plurality Voting]] mechanism.

$\square$


== See also ==
* [[Arrow's Impossibility Theorem]]

== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Voting Theory]]</text>
      <sha1>a5eh1qgftxoftbk0h1vjfx0knrrqgk0</sha1>
    </revision>
  </page>
  <page>
    <title>Arrow's Impossibility Theorem</title>
    <ns>0</ns>
    <id>266</id>
    <revision>
      <id>268</id>
      <timestamp>2014-01-06T07:37:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9632">== Arrow's Impossibility Theorem ==
Arrow's Impossibility Theorem is a [[Voting Theory]] theorem (sometimes called ''Arrow's Paradox'')

In contrast to [[May's Theorem]], in this theorem we assume 3 (and more) candidates, not 2:
* $A = \{x, y, z\}$


== [[Voting Theory Relations]] ==
We define the following [[Voting Theory Relations|relations]]:

$P$ the preference relation 
* $P_i$ is a individual preference of voter $i$
** $x \ P_1 \ y$  means that voter 1 prefers $x$ to $y$
* $P$ is the global aggregated preference

$I$ is the indifference relation
* $I_i$ is an individual indifference of voter $i$
* $I_i$ is symmetric: $a \ I_1 \ b \iff b \ I_1 \ a$ 

$S$ is the &quot;at least as good as&quot; relation
* $S \equiv (P \lor I)$
* $x \ S \ y \iff x \ (P \lor I) \ y \Rightarrow {\color{grey}{(1)}} \ x \ P \ y  \lor {\color{grey}{(2)}} \ x \ I \ y \lor {\color{grey}{(3)}} \ y \ P \ x$


; We can express $P$ and $I$ only via $S$
# $x \ P \ y \equiv [x \ S \ y] \land [y \ \overline{S} \ x]$
# $x \ I \ y \equiv [x \ S \ y] \land [y \ S \ x]$


== Axioms ==
; Axiom 1: ''Completeness''
: $\forall x, y \in A:$ either  $x \ S \ y$ or $y \ S \ x$

; Axiom 2: ''Consistency'' (or ''Transitivity'')
: $\forall x, y, z \in A: x \ S \ y \land y \ S \ z \Rightarrow x \ S \ z$


== Lemmas ==
$\forall x, y, z \in A:$
* (1) $x \ S \ x$ (''reflectivity'')
* (2) $x \ P \ y \Rightarrow x \ S \ y$
* (3) $x \ P y \land y \ P \ z \Rightarrow x \ P \ z$ (''transitivity'' for $P$)
* (4) $x \ I \ y, y \ I \ z \Rightarrow x \ I \ z$ (?)
* (5) either $x \ S \ y$ or $y \ P \ x$
* (6) $x \ P \ y \land y \ S \ z \Rightarrow x \ P \ z$


=== Lemma 3: Transitivity for $P$ ===
We want to show that $\forall x, y \in A: x \ P \ y \land y \ P \ z \Rightarrow x \ P \ z$

By Axiom 2 we have transitivity for $S$:
* $x \ S \ y \land y \ S \ z \Rightarrow x \ S \ z$

$x \ S \ z \equiv x \ (P \lor I) \ y \equiv \underbrace{[x \ P \ y]}_\text{(1)} \lor \underbrace{[x \ I \ z]}_\text{(2)}$
* (1) this is what we want to show
* (2) want to show that assuming it leads to contradiction and therefore the only possible outcome is (1)


Assuming (2): $x \ I \ z$
* by Symmetry $x \ I \ z \iff z \ I \ x$
* $z \ I \ x \Rightarrow [z \ S \ x] \land [x \ S \ z] \Rightarrow z \ S \ x$

$z \ S \ x \land x \ S \ y \Rightarrow z \ S \ y$ (by transitivity of $S$)
* since $S$ is less strict than $P$ we have:
: $x \ P \ y \Rightarrow x \ S \ y$ and $y \ P \ z \Rightarrow y \ S \ z$
* $z \ S \ y$ contradicts with $y \ P \ z$
: $z \ S \ y$ means one of the following: $z \ P \ y$ or $z \ I \ y$, and neither of them are true

Contradiction. $\square$


=== Lemma 5 ===
$\forall x, y \in A: x \ S \ y \lor y \ P \ x$

Let's prove that by contradiction:
* assume the opposite: $\exists x, y \in A: \overline{ x \ S \ y \lor y \ P \ x }$
* $\overline{ x \ S \ y \lor y \ P \ x } \equiv  \overline{ x \ S \ y} \land  \overline{ y \ P \ x } \equiv y \ P \ x  \land y \ \overline{S} \ x$
* this is clearly a contradiction: they both can never be true at the same time


Another way to show that is by completeness of $P$ and $S$


=== Lemma 6 ===
$\forall x, y \in A: x \ P \ y \land y \ S \ z \Rightarrow x \ P \ z$

* $x \ P \ y \equiv [x \ S \ y] \land [y \ \overline{S} \ x]$ just rewriting $P$ with $S$ 
* $[x \ S \ y] \land [y \ S \ z] \Rightarrow x \ S \ z$ by transitivity
* $x \ S \ z \iff \underbrace{ x \ P \ z}_\text{(1)} \lor \underbrace{x \ I \ z}_\text{(2)}$
* if (2) is false then (1) must be true for the Lemma to hold

Assume $x \ I \ z$
* $x \ I \ z \equiv \underbrace{x \ S \ z}_\text{true} \land z \ S \ x$
* consider the initial hypothesis $y \ S \ z$ and $z \ S \ x$:
** by transitivity  $y \ S \ z \land z \ S \ x \Rightarrow y \ S \ x$
* but $y \ S \ x$ contractions with $a \ P \ y$
* therefore $x \ P \ y$  (1) must be true

$\square$



== Conditions ==
The ''social welfare function'' $H$ it takes two individual rankings and produces the global (social) choice:
: $H(R_1, R_2) \to R$

$H$ must satisfy the following conditions:
* Universality
* [[Monotonicity]]
* [[Independence to Third Alternatives]]
* Non-Imposition
* No Dictatorship


=== Condition 1: Universality ===
$H$ is defined for every pair $R_1$ and $R_2$
* i.e. for each pair there should exist a solution
* we want to avoid the [[Condorcet's Rule#Condorcet's Paradox|Condorcet Problem]] - a cycle

This condition is also called ''Unrestricted Domain''


=== Condition 2: [[Monotonicity]] ===
Monotonicity is satisfied if
* if an alternative $x$ rises or does not fall in the individual ordering
* and if $x$ was preferred to another alternative $y$ before the change in the individual orderings
* then $x$ should still be preferred to $y$ in the global ordering


=== Condition 3: [[Independence to Third Alternatives]] ===
Independence to Third Alternatives is satisfied when
* given the set of alternatives $A = \{x, y\}$
* individual preferences over $A$ are not affected by other alternatives $z$ that are not in $A$
* when these alternatives $z$ are also considered in $A' = A \cup {z}$ it should not affect the ordering between alternatives from $A$  


=== Condition 4: Non-Imposition ===
$H$ should not be imposed

$H$ is ''imposed'' if
* for some distinct $x$ and $y$, for rankings $R_1$ and $R_2$: $x \ S \ y$
* $S$ relates to the global ordering obtained from $H$

In other words, 
* $x$ is always as good as $y$ or better in the aggregated ordering
* no matter what $y$ is 

Example of some imposed conditions:
* men preferred to women, 
* one religion is preferred to other,
* etc


=== Condition 5: No Dictatorship ===
$H$ should not be dictatorial

$H$ is dictatorial if 
* $\exists$ individual $i$ s.t. $\forall x, y \in A: x \ P_i \ y \Rightarrow x \ P \ y$
* no matter what is the individual ranking $R_i$
* such individual $i$ is called ''the dictator''

In other words:
* for any alternatives, the choice of the dictator determines the outcome


== Theorem ==
; Arrow's Impossibility Theorem
: All five conditions cannot be satisfied simultaneously. 


== Consequences ==
=== Consequence 1: [[Unanimity]] ===
Unanimity is satisfied ($N = 2$) if
* $x \ P_1 \ y$ and $x \ P_2 \ y$ then $x \ P \ y$
* or $x$ is globally preferred to $y$ if both voters vote for $x$

It follows from Non-Imposition and Monotonicity

Non-Imposition
* $H$ is imposed if $\exists x, y: \forall R_1, R_2: x \ S \ y$
* thus $H$ is not imposed if $\exists R_1, R_2: x \ P \ y$

From $R_1$ and $R_2$ we can build two rankings
* $R_1 \to R'_1$ and $R_2 \to R'_2$
* we assume only that $x$ improves his positions in these rankings: 
* $x$ has the same or better position in $R' = H(R'_1, R'_2)$ 
* by [[Monotonicity]] if he was preferred to $y$ in $R$, he's still preferred to $y$ in $R'$

?

For example: 
* $R: y &lt; x &lt; z \ \to \ R': x &lt; y &lt; z$
* $x$ improved his positions 


=== Consequence 2: Dictatorship ===
We have a dictator if:
* $\exists x, y \in A: x \ P \ y \land x \ P_1 \ y \land y \ P_2 \ x \Rightarrow [ x \ P_1 \ y \to x \ P \ y ]$
* if we have two opposite points of view of voters $a_1$ ($x$ is better) and $a_2$ ($y$ is better) and the opinion of voter $a_1$ becomes the global opinion
* then no matter how $a_2$ votes, the opinion of $a_1$ determines the global preference 

Let's consider two rankings:
* $R_1: x &lt; \ ...$ one where $x$ is on the first position
* $R_2$ any ranking with $x$ at some position - $R_2: \ ... &lt; x &lt; \ ...$ 

We can build two new rankings $R'_1$ and $R'_2$ from them:
* $R'_1 \equiv R_1$: also with $x$ on the first position
* $R'_2: \ ... &lt; x$: by taking $R_2$ and moving $x$ to the last position
* this way we constructed two rankings with completely opposite points of view 
** (this corresponds to $x \ P_1 \ y \land y \ P_2 \ x$)
* $H(R'_1, R'_2) = R'$, and by our hypothesis $x \ P \ y$ in $R'$

Now let's return from $R'_2$ to $R_2$:
* $x$ improves his positions by going from $R'_2$ to $R_2$:
* by [[Monotonicity]] he should remain the winner 

I.e. no matter what is the ranking $R_2$, $R_1$ always determines the outcome
* or $x \ P_1 \ y \to x \ P \ y$

$\square$


=== Consequence 3: Indifference ===
In a strong conflict the only possible outcome is indifference:
* if $x \ P_1 \ y \land y \ P_2 \ x \Rightarrow x \ I \ y$
* otherwise we have dictatorship

Assume $x \ I \ y$ is false. It means:
* ether $x \ P \ y$
* or $y \ P \ x$ 

Assume $x \ P \ y$:
* $x \ P_1 \ y \land y \ P_2 \ x \Rightarrow x \ P \ y$
* it means that the voter 1 is dictator 

Same for $y \ P \ x$:
* it would mean the the voter 2 is dictator


=== Consequence of Consequences ===
Suppose we have two ratings:
* $R_1: {\color{blue}{x &lt; y}} &lt; z$
* $R_2: z &lt; {\color{blue}{x &lt; y}}$
* i.e. both candidates agree that $x \ P \ y$

But there's a strong opposition when it comes to $z$:
* '''(1)''' $x$ vs $z$
** $x \ P_1 z \land z \ P_2 \ x$
** the only possible outcome in this case is indifference (by Consequence 3)
** $x \ I \ z$
* '''(2)''' $y$ vs $z$
** $y \ P_1 z \land z \ P_2 \ y \Rightarrow y \ I \ z$


by '''(1)''' + '''(2)''':
* $y \ I \ z  \equiv z \ I \ y $
* $x \ I \ z \land z \ I \ y \Rightarrow x \ I \ y$ by transitivity of $I$ (Lemma 4)
* but it contradicts with $x \ P \ y$

Therefore, these 5 conditions cannot be satisfied simultaneously.


== Solution ==
How to overcome this limitation? 
* Relax 1-st condition: don't need to always return the entire rankings, it's enough to return just one candidate 


== Sources ==
* [[Decision Engineering (ULB)]]
* EC228 Voting Theory Lecture Notes [http://www2.warwick.ac.uk/fac/soc/economics/current/modules/ec228/details/lecturenotes/lecturenotesbook.pdf]

[[Category:Voting Theory]]</text>
      <sha1>5dp96yjgd7bn7xymh6b83q03ir7dvtd</sha1>
    </revision>
  </page>
  <page>
    <title>Voting Theory Exercises</title>
    <ns>0</ns>
    <id>267</id>
    <revision>
      <id>269</id>
      <timestamp>2014-01-06T07:42:16Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2820">== [[Voting Theory]] Exercises ==
* Exercises: [https://www.dropbox.com/s/lfu7jt16n99pmyj/session-01-voting%20theory.pdf]
* Solutions: [https://www.dropbox.com/s/69u5we1cuux1z67/session-01-voting%20theory%20solutions.pdf]
* Used Notation: [[Voting Theory Relations]]


== Exercise 4 ==
* $N = 10$, $A$ - set of candidates
* define a relation $a \ B \ b$ as &quot;$a$ is better than $b$&quot;
* if this relation transitive and can it have cycles?

=== Exercise 4.1 ===
Define $a \ B \ b$ as 
* $a \ B \ b \iff n_{ab} \geqslant 6$ where $n_{ab}$ is the number of people who rank $a$ before $b$ (like in [[Condorcet's Rule]])

This voting system is very similar to the [[Condorcet's Rule]]

We can show that it means to be transitive:
* ex-transitivity.png
* i.e. if there exists a loop then there can be no transitivity 
* so it suffices to show that there can be cycles and it will answer both questions

Consider the following ranking:
* $3: a &gt; b &gt; c$
* $3: b &gt; c &gt; a$
* $4: c &gt; a &gt; b$

Now calculate the $B$ relationship:
* $a \ B \ b$ since $n_{ab} = 7$
* $b \ B \ c$ since $n_{bc} = 6$
* $c \ B \ a$ since $n_{ca} = 7$

We have a cycle:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/vt/condorcet-monotonicity-2.png 


=== Exercise 4.1 ===
Define $a \ B \ b$ as 
* $a \ B \ b \iff n_{ab} \geqslant 7$ where $n_{ab}$ is the number of people who rank $a$ before $b$

In this case $B$ also is not always transitive.

Consider the following example: 
* $4: a &gt; b &gt; c$
* $3: b &gt; c &gt; a$
* $3: c &gt; a &gt; b$
* in this case there are not enough votes to have an edge $c \to a$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/vt/ex-not-completeness.png
* note that his shows that the relation $B$ is not complete (this can also be the case for the previous exercise)

And there can be no cycles: too few voters for this 
* consider the case with 3 candidates: $A = \{a, b, c\}$
* there are 6 possible individual rankings for elements from $A$: there are 3! permutations of $A$
** $R_1: a &lt; b &lt; c$ -- $n_1$ voters
** $R_2: a &lt; c &lt; b$ -- $n_2$ voters
** $R_3: b &lt; a &lt; b$ -- $n_3$ voters
** $R_4: b &lt; c &lt; a$ -- $n_4$ voters
** $R_5: c &lt; a &lt; b$ -- $n_5$ voters
** $R_6: c &lt; b &lt; a$ -- $n_6$ voters
** $n_i$ - the number of voters with ranking $R_i$
* to have a cycle we need to have:
** $n_{ab} = n_1 + n_2 + n_6 \geqslant 7$
** $n_{ba} = n_1 + n_3 + n_4 \geqslant 7$
** $n_{ca} = n_4 + n_5 + n_6 \geqslant 7$
* let's sum up these 
** $2 \cdot n_1 + n_2 + n_3 + 2 \cdot n_4 + n_5 + 2 \cdot n_6 \geqslant 21$ (1)
* recall that we have only 10 voters:
** $n_1 + n_2 + n_3 + n_4 + n_5 + n_6 = 10$ (2)
* now let's calculate (1) - (2):
** $n_1 + n_4 + n_6 \geqslant 11$
** this cannot happen: we have only 10 voters
* contradiction



== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Voting Theory]]</text>
      <sha1>bq8j45n0q60vsnh99g7b8ls2lvl95lq</sha1>
    </revision>
  </page>
  <page>
    <title>Voting Theory Examples</title>
    <ns>0</ns>
    <id>268</id>
    <revision>
      <id>270</id>
      <timestamp>2014-01-06T07:43:52Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1951">== [[Voting Theory]] Examples ==
Different examples from [[Voting Theory]] that illustrate some interesting properties.


== Example 1 ==
This is an example in which different voting mechanisms of [[Voting Theory]] produce different results.


Consider this example:
* $N = 24$
* $A = \{ t, x, y, z \}$

Votes:
* 5 votes $x &gt; y &gt; z &gt; t$
* 4 votes $x &gt; z &gt; y &gt; t$
* 2 votes $t &gt; y &gt; x &gt; z$
* 6 votes $t &gt; y &gt; z &gt; x$
* 8 votes $z &gt; y &gt; x &gt; t$
* 2 votes $t &gt; z &gt; y &gt; x$


=== Example 1: [[Plurality Voting]] ===
The global ranking is 
: $t &gt; x &gt; z &gt; y $
: $(10 &gt; 9 &gt; 8 &gt; 0)$

Therefore $t$ gets elected 
* But 17 voters (the majority!) prefer $x$ to $t$
* [[Condorcet's Rule#Fairness|Condorcet Fairness]] criterion is not satisfied


=== Example 1: [[Two-Round Voting]] ===
Round 1:
* $x$ and $t$ are selected 

Round 2:
* remove all other candidates:
** 5 + 4 + 8 = 17 votes $x &gt; t$
** 2 + 6 + 2 = 10 votes $t &gt; x$

$x$ wins
* but $y$ is preferred to $x$ by 18 voters (the majority!)
* [[Condorcet's Rule#Fairness|Condorcet Fairness]] criterion is not satisfied


=== Example 1: [[Borda's Rule]] ===
The Borda Scores:
* $B(t) = 57$
* $B(x) = 5 \cdot 4 + 4 \cdot 4 + 2 \cdot 2 + 6 \cdot 1 + 8 \cdot 2 + 2 \cdot 1 = 64$
* $B(y) = 75$
* $B(z) = 74$

$y$ wins
* note that $t$ is the last one, but for the [[Plurality Voting]] he is the winner 


=== Example 1: [[Condorcet's Rule]] ===
Pairwise comparison:
* $t,x: n_{xt} = 17, n_{tx} = 10 \Rightarrow x &gt; t$
* $x,y: n_{xy} = 9,  n_{yx} = 18 \Rightarrow y &gt; x$
* $t,y: n_{ty} = 10, n_{yt} = 17 \Rightarrow y &gt; t$
* $x,z: n_{xz} = 11, n_{zx} = 16 \Rightarrow z &gt; x$
* $y,z: n_{yz} = 13, n_{zy} = 14 \Rightarrow z &gt; y$
* $t,z: n_{tz} = 10, n_{zt} = 17 \Rightarrow z &gt; t$

We build the preference graph for this:
: https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/vt/condorcet-ex2.png

We see that $z$ is the winner 



== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Voting Theory]]</text>
      <sha1>gs5rftp5xn0m02vkrqa5umx70t8o4po</sha1>
    </revision>
  </page>
  <page>
    <title>Banzhaf Power Index</title>
    <ns>0</ns>
    <id>269</id>
    <revision>
      <id>271</id>
      <timestamp>2014-01-08T13:45:33Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2528">== Banzhaf Power Index ==
''Coalition'' is a group of people/parties that need to achieve some quota when voting for a law. Otherwise this law will not pass. 

The ''Banzhaf Power Index'' shows how strong a party is.


Suppose we have a company with 200 shares in total. 

There are three shareholders: 
* $D$ Doug: 101 shares,
* $N$ Nicolas: 97 shares,
* $E$ Elizabeth: 2 shares

For a decree to pass it should have 103 shares

Is $N$ 48 times more important then $E$? To assess the importance we use the Banzhaf index:


=== The Power Index ===
Critical Voter:
* A coalition is ''winning'' if it has enough power to pass a low/decree/whatever. 
* A voter in a winning coalition is ''critical'' if his withdrawal causes the coalition to become a loosing coalition 

Example:
* there are $2^3$ coalitions in total, and $3$ of them are winning
* $\{D, E\}$
** 103 votes - this is a winning coalition
** $E$ is a critical voter: if she withdraws, the coalition is no longer winning
** $D$ also is a critical voter
* $\{D, N\}$
** both $D$ and $N$ are critical
* $\{D, N, E\}$ ([[Unanimity]])
** everybody agrees: 200 votes
** $D$ and $N$ are critical voters
** but now $E$ is not: if she withdraws, the coalition is still winning


The Power: 
* The ''Banzhaf Power'' $BP(a)$ of a voter $a$ is the number of winning coalitions in which $a$ is critical. 
* The ''Total Banzhaf Power'' of a voting game is the sum of all Bahnzaf powers of all voters: $TBP = \sum_{a} BP(a)$
* The ''Banzhaf Index'' of a voter $a$ is $\cfrac{BP(a)}{TBP}$


Example:
{|  class=&quot;wikitable&quot;
! Voter || $BP$ || Index
|-
| $D: 101$ || 3 || 3/5
|-
| $N: 97$ || 1 || 1/5
|-
| $D: 101$ || 1 || 1/5
|-
| || $TBP = 5$ || 
|}

So we see that both $N$ and $E$ are equally important, even though they don't have the same number of shares.


== Example: Nassau County ==
Consider the following districts:
{| class=&quot;wikitable&quot;
! || District || Weight
|-
| (1) || Hempstead 1 || 31
|-
| (2) || Hempstead 2 || 31
|-
| (3) || Oyster Bay || 28
|-
| (4) || North Hempstead || 21
|-
| (5) || Long Beach || 2
|-
| (6) || Glen Cove || 2
|}

The threshold for a law to pass is $Q=58$

In this example all the power in equally distributed withing the 3 first districts (1), (2) and (3). 
* any 2 of these 3 always form a winning coalition
* no other two districts can form such a winning coalition



== Links ==
* http://en.wikipedia.org/wiki/Banzhaf_power_index

== See also ==
* [[Shapley Value]]

== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Voting Theory]]</text>
      <sha1>86991hei1dttp14v6zrezb7bs4tbrsx</sha1>
    </revision>
  </page>
  <page>
    <title>Parliamentary Allocation</title>
    <ns>0</ns>
    <id>270</id>
    <revision>
      <id>272</id>
      <timestamp>2014-01-08T13:34:24Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1403">== Parliamentary Allocation ==
Suppose we run an election. We want to allocate seats in the parliament proportionally to the number of votes each party received. 

Problem:
* $n$ - number of voters that participate in the elections
* $N$ - number of classes (parties) that are being elected
* $P_1, ..., P_k$ - are partitions of the population, \sum_P = N
* size of $P_i$ is $p_i$
* goal: to select $S$ representatives, $S$ - the total number of seats that are allocated 

A quota $q_i$ of party $i$ is the number of sets the party receives after election:
* $q_i = S \cdot \cfrac{P_i}{n}$
* but it must be an integer! Cannot divide one seat between two parties 


This is important not only for seats allocation, but for allocating in general.

For example,
* suppose we have some area that suffers from fire 
* we have only 10 medical units
* how to allocate them between the regions in that area? 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/vt/area-medicalunits.png
* can allocate as follows: the number of voters $p_i$ - density of a region, $n$ - all people of the area
* $S$ is the number of medical units 
* $q_i$ the number of medical units sent to region $i$ 
* $q_i = S \cdot \cfrac{P_i}{n}$ - again: it has to be an integer!


=== Methods ===
* [[Hamilton's Method]]
* [[Jefferson's Method]]


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Voting Theory]]</text>
      <sha1>5u0e3e6r93r474ujyn6ude54oujgz9a</sha1>
    </revision>
  </page>
  <page>
    <title>Hamilton's Method</title>
    <ns>0</ns>
    <id>271</id>
    <revision>
      <id>273</id>
      <timestamp>2014-11-23T16:37:00Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5481">== Hamilton's Method ==
This is a [[Parliamentary Allocation]] method, also known as the ''Largest Remainder method'' with the ''Hare Quota''.

The task is:
* given 
** $p_i$ - the number of voters in favor of party $i$ 
** $N$ - total number of parties, $i \in \{ 1, 2, ..., N\} \equiv P$
** $n$ - total number of voters
** the quota of $i$ is $q_i = S \cdot \cfrac{p_i}{n}$. Note that $q_i$ is a read number, not integer
* allocate $S$ seats in parliament
** $(s_1, ..., s_N)$ s.t. $\sum s_i = S$
** $s_i$ must be an integer

So $s_i$ should be either $\lfloor q_i \rfloor$ or $\lfloor q_i \rfloor + 1$
* it's always integer, so we either round down or up

Rule:
* initially allocate $\lfloor q_i \rfloor$ seats 
* then order all parties by their decimal part of the quota 
* the party with the highest decimal part gets the seat

Formally,
* $\forall i, j \in P: s_i = \lfloor q_i \rfloor + 1 \land s_j = \lfloor q_j \rfloor \iff q_i - \lfloor q_i \rfloor \geqslant q_j - \lfloor q_j \rfloor$ 
* $i$ gets the additional seat if its decimal part is larger than $j$'s 


=== Example ===
$S = 10$ 

{| class=&quot;wikitable&quot;
! || $p_i$ || $q_i$ || $\lfloor q_i \rfloor$ || $s_i$
|-
| $P_1$ || 6373 || 6.373 || 6 || 6 
|-
| $P_2$ || 2505 || 2.505 || 2 || 2 
|-
| $P_3$ || 602 || 0.602 || 0 || 0
|-
| $P_4$ || 520 || 0.520 || 0 || 0 
|}

There remain 2 places to allocate: $\sum_i s_i = 8, S = 10$
* we order the parties by the decimal part of their quota:
* ${\color{blue}{P_3: 0.602, P_4: 0.520}}, P_2: 0.505, P_1: 0.373$
* so in this case $P_3$ and $P_4$ get the additional seats


{| class=&quot;wikitable&quot;
! || $p_i$ || $q_i$ || $\lfloor q_i \rfloor$ || $s_i$
|-
| $P_1$ || 6373 || 6.373 || 6 || 6 
|-
| $P_2$ || 2505 || 2.505 || 2 || 2 
|-
| $P_3$ || 602 || 0.602 || 0 || 1
|-
| $P_4$ || 520 || 0.520 || 0 || 1 
|}



It's not always possible to split the seats

{| class=&quot;wikitable&quot;
! || $p_i$ || $q_i$ || $\lfloor q_i \rfloor$ || $s_i$
|-
| $P_1$ || 6373 || 6.373 || 6 || 6 
|-
| $P_2$ || 2512 || 2.512 || 2 || ? 
|-
| $P_3$ || 603 || 0.603 || 0 || 1
|-
| $P_4$ || 512 || 0.513 || 0 || ?
|}

We have a tie
* ties are broken arbitrarily


== Implementation ==
=== Python &amp; Numpy ===
&lt;pre&gt;
def hamilton_allocation(ratios, k):
    frac, results = np.modf(k * ratios)
    remainder = int(k - results.sum())
    
    indices = np.argsort(frac)[::-1]
    results[indices[0:remainder]] += 1
 
    return results.astype(int)
&lt;/pre&gt;

ratios here sum up to 1, and k is the total number of seats


== Paradoxes ==
=== Alabama Paradox ===
At first we have only 7 positions to allocate: $S = 7$


{| class=&quot;wikitable&quot;
! || $p_i$ || $q_i$ || $\lfloor q_i \rfloor$ || $s_i$
|-
| $P_1$ || 20 || 1.&lt;u&gt;373&lt;/u&gt; || 1 || 2
|-
| $P_2$ || 34 || 2.333 || 2 || 2 
|-
| $P_3$ || 48 || 3.294 || 3 || 3
|-
! $\sum$ ||  102 || || 6 || 7
|}


But suddenly we have an additional seat: $S = 8$

{| class=&quot;wikitable&quot;
! || $p_i$ || $q_i$ || $\lfloor q_i \rfloor$ || $s_i$
|-
| $P_1$ || 20 || 1.569 || 1 || ${\color{red}{\fbox{1}}}$
|-
| $P_2$ || 34 || 2.667 || 2 || 3
|-
| $P_3$ || 48 || 3.&lt;u&gt;765&lt;/u&gt; || 3 || 4
|-
! $\sum$ ||  102 || || 6 || 7
|}


$P_1$ loses one seat! 
* no [[Monotonicity]]!
* even with one additional vote $P_1$ cannot regain the seat!


{| class=&quot;wikitable&quot;
! || $p_i$ || $q_i$ || $\lfloor q_i \rfloor$ || $s_i$
|-
| $P_1$ || 21 || 1.631 || 1 || 1
|-
| $P_2$ || 34 || 2.641 || 2 || 3
|-
| $P_3$ || 48 || 3.&lt;u&gt;728&lt;/u&gt; || 3 || 4
|-
! $\sum$ ||  103 || || 6 || 7
|}


This is called the ''Alabama paradox'': increasing in the number of seats causes a party to lose a sit


=== Population Paradox ===
$S=20$

{| class=&quot;wikitable&quot;
! || $p_i$ || $q_i$ || $\lfloor q_i \rfloor$ || $s_i$
|-
| $P_1$ || 1786 || 9.654 || 9 || 10
|-
| $P_2$ || 1246 || 6.719 || 6 || 7
|-
| $P_3$ || 671 || 3.627 || 3 || 3
|-
! $\sum$ ||  3700 || || 18 || 20
|}


But assume that we have forgotten about additional 65 votes:
* 19 votes for $P_1$
* 40 votes for $P_2$
* and only 6 votes for $P_3$

{| class=&quot;wikitable&quot;
! || $p_i$ || $q_i$ || $\lfloor q_i \rfloor$ || $s_i$
|-
| $P_1$ || 1805 || 9.588 || 9 || '''9'''
|-
| $P_2$ || 1283 || 6.815 || 6 || 7
|-
| $P_3$ || 677 || 3.596 || 3 || '''4'''
|-
! $\sum$ ||  3700 || || 18 || 20
|}

Even though $P_1$ was winning and received more additional votes than $P_3$, $P_3$ takes one seat from $P_1$

So the outcome is not robust and it is possible to manipulate the result.


=== Population Transfer Paradox ===
Shows that [[Independence to Third Alternatives]] is not satisfies

$S = 5$

{| class=&quot;wikitable&quot;
! || $p_i$ || $q_i$ || $\lfloor q_i \rfloor$ || $s_i$
|-
| $P_1$ || 14 || 2.593 || 2 || 3
|-
| $P_2$ || 10 || 1.667 || 1 || 2
|-
| $P_3$ || 3 || 0.556 || 0 || 0
|-
! $\sum$ ||  27 || || 3 || 5
|}


Suppose $P_2$ lost one vote, and $P_3$ received this vote:
* That has an impact on $P_1$!

{| class=&quot;wikitable&quot;
! || $p_i$ || $q_i$ || $\lfloor q_i \rfloor$ || s_i
|-
| $P_1$ || 14 || 2.593 || 2 || '''2'''
|-
| $P_2$ || 9 || 1.667 || 1 || 2
|-
| $P_3$ || 3 || 0.741 || 0 || 1
|-
! $\sum$ ||  27 || || 3 || 5
|}


$P_1$ loses one seat, even though its position remained unchanged


== Links ==
* http://wiki.electorama.com/wiki/Hamilton_method
* http://wiki.electorama.com/wiki/Largest_remainder_method + the Hare Quote
* http://wiki.electorama.com/wiki/Alabama_paradox
* Alabama and Population Paradoxes http://en.wikipedia.org/wiki/Apportionment_paradox

== See also ==
* [[Jefferson's Method]]

== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Voting Theory]]</text>
      <sha1>jl6jkc9v1gts2wdi0npeofbmj533c92</sha1>
    </revision>
  </page>
  <page>
    <title>Jefferson's Method</title>
    <ns>0</ns>
    <id>272</id>
    <revision>
      <id>274</id>
      <timestamp>2014-01-08T13:44:10Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3918">== Jefferson's Method ==
This is a [[Parliamentary Allocation]] method.

The task is:
* given 
** $p_i$ - the number of voters in favor of party $i$ 
** $N$ - total number of parties, $i \in \{ 1, 2, ..., N\} \equiv P$
** $n$ - total number of voters
** the quota of $i$ is $q_i = S \cdot \cfrac{p_i}{n}$. Note that $q_i$ is a read number, not integer
* allocate $S$ seats in parliament
** $(s_1, ..., s_N)$ s.t. $\sum s_i = S$
** $s_i$ must be an integer

The main idea of this method is to satisfy the following constraint:
* $s_i \ne 0, \cfrac{p_i}{s_i} \geqslant \cfrac{p_j}{s_j + 1}$


If this constraint is not respected, we have:
* $\cfrac{p_i}{s_i} &lt; \cfrac{p_j}{s_j + 1}$
* but party $P_j$ won't be happy about it: they may need more people to allocate one seat than $P_i$


So we give a place to a party $i$ with maximal $\cfrac{p_i}{\lfloor s_i \rfloor + 1}$ score


Meaning:
* suppose $S=10, p_1 = 6373, q_1 = 6.4$
* allocate $s_1 = 6$ seats to $P_1$ 
* $\cfrac{p_1}{s_1 + 1}$ means &quot;to get one additional seat they need 910 people in the worst case&quot;


=== Example 1 ===
$S = 10$

{| class=&quot;wikitable&quot;
!      || $p_i$ || $q_i$ || $\lfloor q_i \rfloor$ || $s_i$ || $\cfrac{p_i}{\lfloor s_i \rfloor + 1}$
|-
| $P_1$ || 6373 || 6.373 || 6 || 6 || &lt;u&gt;910.42&lt;/u&gt; 
|-
| $P_2$ || 2505 || 2.505 || 2 || 2 || 835
|-
| $P_3$ || 602 || 0.602  || 0 || 0 || 602
|-
| $P_4$ || 520 || 0.520  || 0 || 0 || 502 
|-
|       ||     ||        || 8  || 8||    
|}

$P_1$ has the highest $\cfrac{p_1}{\lfloor s_1 \rfloor + 1}$ score
* so allocating additional seat to them
* note that we need to re-calculate the value $\cfrac{p_i}{\lfloor s_i \rfloor + 1}$ for $P_1$ after we allocate the seat to them


{| class=&quot;wikitable&quot;
!      || $p_i$ || $q_i$ || $\lfloor q_i \rfloor$ || $s_i $|| $\cfrac{p_i}{\lfloor s_i \rfloor + 1}$
|-
| $P_1$ || 6373 || 6.373 || 6 || &lt;font color=&quot;red&quot;&gt;7&lt;/font&gt; || 796
|-
| $P_2$ || 2505 || 2.505 || 2 || 2 || &lt;u&gt;835&lt;/u&gt;
|-
| $P_3$ || 602 || 0.602  || 0 || 0 || 602
|-
| $P_4$ || 520 || 0.520  || 0 || 0 || 502 
|-
|       ||     ||        || 8  || 9 ||    
|}

$P_2$ has the highest score now
* so allocating the 10th seat to them


=== Example 2 ===
$S = 10$

{| class=&quot;wikitable&quot;
!      || $p_i$ || $q_i$ || $\lfloor q_i \rfloor$ || $s_i$ || $\cfrac{p_i}{\lfloor s_i \rfloor + 1}$
|-
| $P_1$ || 6373 || 6.4 || 6 || 6 || &lt;u&gt;910.42&lt;/u&gt;
|-
| $P_2$ || 2505 || 2.505 || 2 || 2 || 768.33
|-
| $P_3$ || 702 || 0.602  || 0 || 0 || 702
|-
| $P_4$ || 620 || 0.520  || 0 || 0 || 620 
|-
|       ||     ||        || 8  || 8 ||    
|}

Give the seat to $P_1$, recalculate the score:

{| class=&quot;wikitable&quot;
!      || $p_i$ || $q_i$ || $\lfloor q_i \rfloor$ || $s_i$ || $\cfrac{p_i}{\lfloor s_i \rfloor + 1}$
|-
| $P_1$ || 6373 || 6.4 || 6 || 7 || &lt;u&gt;796.6&lt;/u&gt;
|-
| $P_2$ || 2505 || 2.505 || 2 || 2 || 768.33
|-
| $P_3$ || 702 || 0.602  || 0 || 0 || 702
|-
| $P_4$ || 620 || 0.520  || 0 || 0 || 620 
|-
|       ||     ||        || 8  || 9 ||    
|}

Again allocate the seat to $P_1$

{| class=&quot;wikitable&quot;
!      || $p_i$ || $q_i$ || $\lfloor q_i \rfloor$ || $s_i$
|-
| $P_1$ || 6373 || 6.4 || 6 || 7
|-
| $P_2$ || 2505 || 2.505 || 2 || 2
|-
| $P_3$ || 702 || 0.602  || 0 || 0
|-
| $P_4$ || 620 || 0.520  || 0 || 0
|-
|       ||     ||        || 8  || 10
|}

This shows that the method is still not perfect.



== Properties ==
=== Consistency ===
Show that 
* $\forall i, j \in P: p_i &lt; p_j \Rightarrow s_i \leqslant s_j$

Solution
* Jefferson Rule is: $\cfrac{p_i}{s_i} \geqslant \cfrac{p_j}{s_j + 1}$
* or $\cfrac{p_i}{p_j} \geqslant \cfrac{s_i}{s_j + 1}$
* $\cfrac{p_i}{p_j} &lt; 1$ always (by the hypothesis $p_i &lt; p_j$)
* thus, $\cfrac{s_i}{s_j + 1} &lt; 1$ or $s_i &lt; s_j + 1$


=== [[Monotonicity]] ===
Also respected



== Links ==
* http://www.math.colostate.edu/~spriggs/m130/apportionment2.pdf

== See also ==
* [[Hamilton's Method]]

== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Voting Theory]]</text>
      <sha1>f792lix4kmpev0m1z1vp2sj0xfhisr1</sha1>
    </revision>
  </page>
  <page>
    <title>Template:Stub</title>
    <ns>10</ns>
    <id>273</id>
    <revision>
      <id>276</id>
      <timestamp>2014-02-02T12:40:05Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="279">&lt;table class=&quot;metadata plainlinks stub&quot; style=&quot;background: transparent;margin: 0.5em auto;border: 1px solid #AAAAAA;&quot; &gt;
&lt;tr&gt;
  &lt;td&gt;[[File:Imbox_content.png]]&lt;/td&gt;
  &lt;td&gt;''This is a stub. [{{fullurl:{{FULLPAGENAME}}|action=edit}} Edit it].''&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
[[Category:Stubs]]</text>
      <sha1>ksarmqai1v0kk5ays4imext3li7b5xf</sha1>
    </revision>
    <revision>
      <id>717</id>
      <parentid>276</parentid>
      <timestamp>2015-11-23T15:59:31Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="317">&lt;table class=&quot;metadata plainlinks stub&quot; style=&quot;background: transparent;margin: 0.5em auto;border: 1px solid #AAAAAA;&quot; &gt;
&lt;tr&gt;
  &lt;td&gt;https://upload.wikimedia.org/wikipedia/en/3/38/Imbox_content.png&lt;/td&gt;
  &lt;td&gt;''This is a stub. [{{fullurl:{{FULLPAGENAME}}|action=edit}} Edit it].''&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
[[Category:Stubs]]</text>
      <sha1>i9vziiyodu3iu3s2n23c78dipjzp1d5</sha1>
    </revision>
  </page>
  <page>
    <title>Multi-Objective Optimization</title>
    <ns>0</ns>
    <id>274</id>
    <revision>
      <id>277</id>
      <timestamp>2014-02-05T12:57:03Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3227">== Multi-Objective Optimization ==
In contrast to Uni-Objective [[Optimization]] problems, in Multi-Objective Optimization problems there are multiple 

An usual model is:
* $\text{opt} f_1(x), ..., f_q(x), x \in A$
* but usually in this case there is no single ''optimal'' solution - but a set of solutions where you cannot say which one is better  


Example:
* suppose you want to buy a flat 
* there are 2 criteria: cost and comfort
* you want to minimize the cost and maximize the comfort 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/moo/moo-illustration.png
* note that you cannot say that $d$ is better than $b$ or better than $a$ 
* but $c$ is clearly [[Dominance|dominated]] by $b$: it's as comfortable as $c$, but cheaper
* the set of the best alternatives is called the ''Pareto-optimal'' set of alternatives


== Multi-Criteria Problem ==
We have $q$ criteria and $n$ items
{| class=&quot;wikitable&quot;
!  || Criterion 1 || Criterion 2 || ... || Criterion $q$
|-
| Item 1 || 100 || Medium || ... || 8
|-
| Item 2 || 100 || Medium || ... || 8
|-
| ... || ... || ... || ... || ...
|-
| Item $n$ || 55 || Very Bad || || 8
|}

Goal: to rank the items 
* there are lots of conflicting criteria (like price and comfort)
* there are different units and scales
* the single optimal solution does not exist

Instead of &quot;Item&quot; it can be &quot;Action&quot;, &quot;Alternative&quot;, etc

Formally we can write it as:
* objective: $\text{opt} z(x)$
* $z: \mathbb{R}^n \to \mathbb{R}^m$
* constraints: $g_i(x) \geqslant 0, x \in \mathbb{R}^n$


=== Link to [[Voting Theory]] ===
But it is possible to draw a direct parallel with [[Voting Theory]]!

{| class=&quot;wikitable&quot;
!             || Voter 1 || Voter 2 || ... || Voter $q$
|-
| Candidate 1 || 100 || Medium || ... || 8
|-
| Candidate 2 || 100 || Medium || ... || 8
|-
| ... || ... || ... || ... || ...
|-
| Candidate $n$ || 55 || Very Bad || || 8
|}

So these two problems are similar:
* Each voter ranks all candidates (alternatives)
* We apply some voting mechanism and find the global preference (the &quot;best&quot; alternative)
* All properties of Voting Theory are still available:
** [[Unanimity]], 
** [[Monotonicity]], 
** [[Independence to Third Alternatives]]
** and others


However there are differences:
* Not all criteria have the same weight 
** in Voting Theory all votes are equally important
** here some criteria may be more important than others
* We need more information than just ranking
** There are different scales
** Since the scales can be numerical, we can compare the intensity of preference 


== Multi-Objective Optimization Problems ==
* [[Multi-Objective Knapsack Problem]]
* [[Flowshop Problem]]
* [[Portfolio Management]]
* [[Waste Utilization Problem]]


== Choosing the Solution ==
Suppose we have obtained the Pareto-optimal set of solutions. How do we choose the &quot;best&quot; solution?

There are several approaches:
* [[Weighted Sum Model]]
* [[Ideal Point Model]]


=== [[Multi-Criteria Decision Aid]] ===
Also [[Multi-Criteria Decision Aid|MCDA]] is used for that:
* find the Pareto-optimal solutions
* apply MCDA to find the best one

== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Optimization]]
[[Category:Multi-Objective Optimization]]</text>
      <sha1>bra3wwsd8sxxopkc0lljcp6hhtba4y5</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Multi-Objective Optimization</title>
    <ns>14</ns>
    <id>275</id>
    <revision>
      <id>278</id>
      <timestamp>2014-01-09T16:05:26Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="25">[[Category:Optimization]]</text>
      <sha1>rmqiuysxzkl0gosyno5q97br447m3h4</sha1>
    </revision>
  </page>
  <page>
    <title>Optimization</title>
    <ns>0</ns>
    <id>276</id>
    <revision>
      <id>279</id>
      <timestamp>2014-01-09T16:06:16Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="162">== Optimization ==

Problems
* [[Knapsack Problem]]
* [[Graph Coloring]]
* [[Traveling Salesman Problem]]
* [[Vehicle Routing Problem]]

[[Category:Optimization]]</text>
      <sha1>0ok7vjgi0qimwmtz3dyuxufbsc3z4ja</sha1>
    </revision>
  </page>
  <page>
    <title>Dominance</title>
    <ns>0</ns>
    <id>277</id>
    <revision>
      <id>280</id>
      <timestamp>2014-01-17T11:52:25Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5068">== [[Unanimity]] ==
Unanimity is principle from [[Voting Theory]] that is the same as Dominance: 

If a candidate $a$ is always preferred by the majority to $b$, then we can say that $b$ is dominated by $a$ and never consider $b$ again


== Pareto-Optimal Solutions ==
In [[Multi-Objective Optimization]] and [[Multi-Criteria Decision Aid]] there could be many &quot;best&quot; solutions - these solutions are called the Pareto-Optimal solutions


Consider this example: 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/moo/knapsack.png
** the two alternatives along the blue line form the pareto-optimal set 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/moo/moo-illustration.png
** the solutions in blue circles also form the pareto-optimal set

Dominance
* for the second examples we can say that $b$ ''dominates'' $c$:
* $b$ has the same level of quality, but it is cheaper
* we can remove all ''dominated'' solutions from the solution space and this will give us the Pareto-optimal set of solutions
* in [[Multi-Objective Optimization|MOO]] this is also called the set of efficient solutions

; dominance
: $a$ dominates $b$ $\iff \forall i: f_i(a) \geqslant f_i(b)$ and $\exists i: f_j(a) &gt; f_j(b)$
: i.e. for all criteria $a$ is at least as good as $b$, but there's at least one criteria at which $a$ is strictly better than $b$


This is not always good. Consider this example
* you're looking for an apartment to rent 
* you consider price and distance to work (want to minimize both)
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/moo/dominance-bad-case.png
* in this case $c$ is dominated by $a$ and $b$: 
** $b$ is very cheap, $a$ is very close
** $c$ is a good compromise, but it's dominated


Another example
* suppose we're choosing a car
* there are 4 criteria: price, power, consumption, comfort
* there are 6 alternatives

{| class=&quot;wikitable&quot;
! || Price || Power || Consumption || Comfort
|-
| &lt;font color=&quot;grey&quot;&gt;Avg A.&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;18&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;75&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;8&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;3&lt;/font&gt;
|-
| Sport || 18.5 || 110 || 9 || 2
|-
| &lt;font color=&quot;red&quot;&gt;Avg B.&lt;/font&gt; || &lt;font color=&quot;red&quot;&gt;17.5&lt;/font&gt; || &lt;font color=&quot;red&quot;&gt;85&lt;/font&gt; || &lt;font color=&quot;red&quot;&gt;7&lt;/font&gt; || &lt;font color=&quot;red&quot;&gt;3&lt;/font&gt;
|-
| Lux 1 || 24 || 90 || 8.5 || 5
|-
| Exonomic || 12.5 || 50 || 7.5 || 1
|-
| Lux 2 || 22.5 || 85 || 9 || 4
|}

We see that '''Avg B''' is always better than '''Avg. A'''
* then nobody will ever choose Avg A: A is dominated by B

No other alternative can be eliminated this way


== [[Game Theory]] ==
This principle is as well applied in the [[Game Theory]]

Notation:
* $A_i$ - set of strategies for player $i$ 
* $u_i$ - the utility function of $i$
* $a, b \in A_i$ - two strategies in $A_i$
* denote $A_{-i}$ as the set of all strategies for other players 

; Strict dominance
: $a$ '' '''strictly''' dominates'' $b$ if $\forall c \in A_{-1}: u_i(a, c) &gt; u_i(b, c)$
: in other words: $a$ strictly dominates $b$ is for every action that other players can take, the action $a$ gives $i$ better payoff than $b$ 

; Weak dominance
: $a$ ''(weakly) dominates'' $b$ if $\forall c \in A_{-1}: u_i(a, c) \geqslant u_i(b, c)$


If $a$ dominates all other strategies $b$ of the player $i$ then it's ''dominant''
* in a strategy profile if every player plays their dominant strategies then it's a [[Nash Equilibrium|Nash Equilibria]]
* this idea is used in [[Iterative Removal]] for solving [[Normal Form Game]]s



=== Pareto Optimality ===
In Game Theory there's also a notion of Pareto Optimality 

Suppose you see a game as an outside observer, not a player
* Can we say that one outcome $O$ is better than some other outcome $O'$?

Pareto-Dominance
* suppose there's one outcome $O$ that is as good as some other outcome $O'$ for all players
* but there's one agent $i$ who strictly prefers $O$ to $O'$ 
* then $O$ is considered better than $O'$ 
* and $O$ ''pareto-dominates'' $O'$

Pareto-Optimality 
* outcome $O^*$ is ''pareto-optimal'' if there is no other outcome that pareto-dominates it
* a game can have more than one pareto-optimal outcome
* for [[Zero-Sum Game]]s every outcome is pareto-optimal



== Problems ==
=== Close Contenders ===
$b$ is a close contender if 
* it's dominated by some alternative $a$
* but $b$ is still a good choice

Consider this example:
* $A = \{a, b, c, d\}$
* $A^* = \{a, c, d\}$ - efficient (pareto-optimal) set of solutions

{| class=&quot;wikitable&quot;
! $c$ || $e_1$ || $e_2$ || $e_3$ || $...$ || $e_{100}$
|-
! $a$ 
| 100 || 100 || 100 || ... || 100
|-
! $b$ 
| 99 || 99 || 99 || ... || 99
|-
! $c$ 
| 101 || 0 || 0 || ... || 0
|-
! $d$ 
| 0 || 101 || 0 || ... || 0
|}

But we see that $c$ and $d$ aren't that good, but both are in $A^*$
* i.e. we should have taken $b$ instead them 


== Sources ==
* [[Decision Engineering (ULB)]]
* [[Game Theory (coursera)]]

[[Category:Game Theory]]
[[Category:Multi-Objective Optimization]]
[[Category:Multi-Criteria Decision Aid]]
[[Category:Decision Under Uncertainty]]</text>
      <sha1>1n7epg0ilq4qlxiiwmf6lhmw4q191h8</sha1>
    </revision>
  </page>
  <page>
    <title>Unanimity</title>
    <ns>0</ns>
    <id>278</id>
    <revision>
      <id>281</id>
      <timestamp>2014-01-09T16:10:28Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="914">== Unanimity ==
The unanimity principle is a [[Voting Theory]] principle. ''Unanimity'' means &quot;agreement reached by all people&quot;.

Using [[Voting Theory Relations]] for $N = 2$ we define Unanimity as:
* if $x \ P_1 \ y$ and $x \ P_2 \ y$ then  $x \ P \ y$
* or $x$ is globally preferred to $y$ if both voters vote for $x$

It follows from two principles
* Non-Imposition and [[Monotonicity]]
* shown in [[Arrow's Impossibility Theorem]] ([[Arrow's Impossibility Theorem#Consequence 1: Unanimity|Unanimity consequence]])

If a candidate $a$ is always preferred by the majority to $b$, then we can say that $b$ is dominated by $a$ and never consider $b$ again


== Dominance ==
The same concept in different disciplines is also often called [[Dominance]]
* [[Multi-Objective Optimization]]
* [[Game Theory]]
* [[Decision Under Uncertainty]]


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Voting Theory]]</text>
      <sha1>4zws1awb8djc7l0d7tzh0d3i4tcao50</sha1>
    </revision>
  </page>
  <page>
    <title>Multi-Objective Knapsack Problem</title>
    <ns>0</ns>
    <id>279</id>
    <revision>
      <id>282</id>
      <timestamp>2014-01-09T16:13:55Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1018">{{stub}}

== Multi-Objective Knapsack Problem ==
This is a [[Multi-Objective Optimization]] problem: a variation of uni-objective [[Knapsack Problem]]: In this case instead of maximizing profits we look at multiple objectives.


== Project Selection Problem ==
We want to select projects for investing some money 
* the budget is 900k euros (this this the constraint)

Objectives: 
* Maximize expected profits 
* Maximize the number of employees 

{| class=&quot;wikitable&quot;
! Projects $\to$ || $P_1$ || $P_2$ ||  $P_3$ || $P_4$
|-
! Investment, k-euro 
| 200 || 300 || 400 || 500
|-
! # of employees
| 2 || 3 || 5 || 6
|-
! Exp. return, %
| 2.5 || 4.5 || 4 || 2.5
|}

For example
* $P_3 + P_4 \leqslant 900$, can employ 11 people


https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/moo/knapsack.png

We see that there are only two interesting solutions
* all other solutions are [[Dominance|dominated]] by these two



== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Multi-Objective Optimization]]</text>
      <sha1>klufi43l326gn4mh4gz37dy9wwibroy</sha1>
    </revision>
  </page>
  <page>
    <title>Flowshop Problem</title>
    <ns>0</ns>
    <id>280</id>
    <revision>
      <id>283</id>
      <timestamp>2014-01-09T16:14:36Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="554">{{stub}}

== Flowshop Problem ==
This is a [[Multi-Objective Optimization]] Problem.

Given:
* $M$ products
* $N$ machines
* each product:
** has to pass through machine once (in the same sequence $1, 2, ..., N$)
** has some due date 
** has delay for each machine 

There are two objectives:
* minimize makespan (produce as fast as possible)
* minimize total tardiness (be able to meet deadlines)


== Links ==
* http://en.wikipedia.org/wiki/Flow_shop_scheduling

== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Multi-Objective Optimization]]</text>
      <sha1>dp3yer42hbywzc2bzwvlp14hfqp6veo</sha1>
    </revision>
  </page>
  <page>
    <title>Portfolio Management</title>
    <ns>0</ns>
    <id>281</id>
    <revision>
      <id>284</id>
      <timestamp>2014-01-09T16:15:45Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="544">{{stub}}

== Portfolio Management ==
This is a [[Multi-Objective Optimization]] Problem.

Given:
* capital $K$ to invest into equities
* objectives:
** maximize expected return (average of past returns)
** minimize risk (variance)

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/moo/portfolio-mgmt.png

We see that the solutions showed with a red line are the best alternatives:
* they are called the pareto-optimal set of alternatives

== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Multi-Objective Optimization]]</text>
      <sha1>d53qf849it4qqq63z75o5ex58ubjk3r</sha1>
    </revision>
  </page>
  <page>
    <title>Waste Utilization Problem</title>
    <ns>0</ns>
    <id>282</id>
    <revision>
      <id>285</id>
      <timestamp>2014-01-09T16:16:35Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2449">== Waste Utilization Problem ==
This is a [[Multi-Objective Optimization]] Problem
* 2 cities $X$ and $Y$ produce garbage
* there are two incinerators $I_1$ and $I_2$ with come capacity
* each incinerator has some cost of utilization per unit of waste
* there are some transportation costs per unit from a city to an incinerator

How much garbage to send from $X$ and $Y$ to $I_1$ and $I_2$?


Example:
* $X$ produces 100 tons of garbage, $Y$ produces 150 tons
* transportation costs: $X \to I_1: 2, X \to I_2: 3; Y \to I_1: 3, Y \to I_2: 4$
* cost of utilization: $I_1: 2, I_2: 1$
* capacities of $I_1$ and $I_2$ are 150

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/moo/waste-utilization.png

Define the following variables:
* $XI_1, XI_2$ - garbage sent from $X$ to $I_1$ and $I_2$ respectively
* $YI_1, YI_2$ - garbage sent from $Y$ to $I_1$ and $I_2$ respectively

Constraints:
* amount of produced garbage = amount of incinerated garbage
** $XI_1 + XI_2 = 100$
** $YI_1 + YI_2 = 150$
* $I_1$ and $I_2$ have capacity:
** $XI_1 + YI_1 \leqslant 150$
** $XI_2 + YI_2 \leqslant 150$
* all must be positive
** $XI_1, XI_2, YI_1, YI_2 \geqslant 0$

So we have the following objectives:
* we want to minimize the total cost of incineration
*: $z_1 = 2 \cdot (XI_1 + YI_1) + 1 \cdot (XI_2 + YI_2)$ 
* and we want to minimize the transportation cost
*: $z_2 = 2 \cdot XI_1 + 3 \cdot YI_1 + 3 \cdot XI_2 + 4 \cdot YI_2$ 

We evaluate all feasible solutions against $z_1$ and $z_2$
* and get something similar to this 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/moo/waste-utilization-solutions.png
* the Pareto-optimal solutions [[Dominance|dominate]] all other feasible solutions


How to select the best one?
* [[Multi-Objective Optimization/Weighed Sum|Weighed Sum]]
** will select only 4 solutions, the rest is ignored
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/moo/waste-utilization-solutions-weighted-sum.png
* [[Ideal Point]]
** we find the closest point to the ideal
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/moo/ideal-point.png


== Links ==
* Routing Optimization for Waste Management http://www.ma.iup.edu/~jchrispe/ORArticles/WasteManagement.pdf
* Ant Colony optimization for Waste Utilization problem: http://thescipub.com/pdf/10.3844/jmssp.2009.199.205 


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Multi-Objective Optimization]]</text>
      <sha1>3s8vmq9g7uti195xqksc5ifjzrmh4o7</sha1>
    </revision>
  </page>
  <page>
    <title>Graph</title>
    <ns>0</ns>
    <id>283</id>
    <redirect title="Graphs" />
    <revision>
      <id>286</id>
      <timestamp>2014-01-10T14:24:59Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20">#redirect [[Graphs]]</text>
      <sha1>410n0mgij9z2o83ize85f8b6lulfvvt</sha1>
    </revision>
  </page>
  <page>
    <title>Feature Scaling</title>
    <ns>0</ns>
    <id>284</id>
    <redirect title="Feature Normalization" />
    <revision>
      <id>287</id>
      <timestamp>2014-01-13T08:26:37Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="49">#перенаправление [[Normalization]]</text>
      <sha1>brtcfki7hw8eewxpaey95xphzyhtm8i</sha1>
    </revision>
    <revision>
      <id>700</id>
      <parentid>287</parentid>
      <timestamp>2015-11-23T13:32:00Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Redirected page to [[Feature Normalization]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="35">#REDIRECT [[Feature Normalization]]</text>
      <sha1>hjvibnq48frsh31oounip1warbupgmd</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Process Mining</title>
    <ns>14</ns>
    <id>285</id>
    <revision>
      <id>288</id>
      <timestamp>2014-01-13T08:27:19Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="40">[[Category:Business Process Management]]</text>
      <sha1>oele71ix1tan6de80vqvhgxpk5crhqs</sha1>
    </revision>
  </page>
  <page>
    <title>Multi-Criteria Decision Aid</title>
    <ns>0</ns>
    <id>286</id>
    <revision>
      <id>289</id>
      <timestamp>2014-01-14T17:08:20Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4730">== Multi-Criteria Decision Aid ==
This is a tool that helps a decision maker to choose a solution when he is facing conflicting criteria and cannot decide.

For example, you want to buy a new car:
* One is expensive, speed is good; 
* another is cheap but slow and with little comfort. 
* These criteria (cost vs speed) are conflicting. 

We need to find a compromise that answers the expectation of a decision maker


https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/mcda.png
* Step 1: Define the set of alternatives $A = \{a_1, ..., a_n\}$
* Step 2: Define the set of criteria $G = \{g_1, ..., g_k\}$
* Step 3: Define the Preferences (the expectations of a decision maker)
* Step 4: Apply methods to find the best alternative


== Alternatives ==
$A$ - set of alternatives (actions, options, items, decisions, etc)

$A$ can be
* finite or infinite
* countable or uncountable
* stable (always the same) or evolving


== Criteria ==
A ''criterion'' $g_i$ is a mapping from the set of alternatives $A$ to some totally ordered set $E_i$:
* $g_i: A \mapsto E_i$
* $g_i \in G$ form a set of criteria

With $E_i$ we can rank all elements of $A$ from best to worst

Examples:
* $E = \mathbb{R}$
* $E = \{\text{VB}, \text{B}, \text{M}, \text{G}, \text{VG}\}$

A set can be:
* ordinal (operations $&lt;, =, &gt;$)
** $E = \{\text{VB}, \text{B}, \text{M}, \text{G}, \text{VG}\}$
* interval (operations $&lt;, =, &gt;, +, -$)
** temperature
* ratio (operations $&lt;, =, &gt;, +, -, \cdot, / $)
** $E = \mathbb{R}$


Restrictions on $G$:
* For a set to be ordered, operations $&lt;$ and $&gt;$ must be defined there
* A set of criteria $G$ ideally should form a [[Consistent Family of Criteria]]


=== [[Dominance]] Principle ===
Some alternatives can be eliminated by Dominance principle
* If for two alternatives $a$ and $b$ for all criteria they are equally good
* but there exists one criteria at which $a$ is better than $b$
* then $b$ is dominated by $a$ and will never be chosen


Consider this example
* we're choosing a car
* there are 4 criteria: price, power, consumption, comfort
* there are 6 alternatives

{| class=&quot;wikitable&quot;
! || Price || Power || Consumption || Comfort
|-
| &lt;font color=&quot;grey&quot;&gt;Avg A.&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;18&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;75&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;8&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;3&lt;/font&gt;
|-
| Sport || 18.5 || 110 || 9 || 2
|-
| &lt;font color=&quot;red&quot;&gt;Avg B.&lt;/font&gt; || &lt;font color=&quot;red&quot;&gt;17.5&lt;/font&gt; || &lt;font color=&quot;red&quot;&gt;85&lt;/font&gt; || &lt;font color=&quot;red&quot;&gt;7&lt;/font&gt; || &lt;font color=&quot;red&quot;&gt;3&lt;/font&gt;
|-
| Lux 1 || 24 || 90 || 8.5 || 5
|-
| Exonomic || 12.5 || 50 || 7.5 || 1
|-
| Lux 2 || 22.5 || 85 || 9 || 4
|}


By [[Dominance]] principle:
* We see that '''Avg B''' is always better than '''Avg. A'''
* then nobody will ever choose Avg A: A is dominated by B
* but no other alternative can be eliminated this way

How to chose which one is the best?
* Need ''subjective'' preferences 


== Preferences ==
To be able to find the best solution we need to know ''subjective preferences''
* these are binary relations provided by a decision maker 
* defined analogously to [[Voting Theory Relations]]

Given two alternatives $a$ and $b$ a decision maker can say if
* $a \ P \ b$ or $b \ P \ a$: $a$ is preferred to $b$ - ''the preference relation''
* $a \ I \ b$ - the indifference relation (not transitive! see [[Luce's Coffee Cups]])
* $a \ J \ b$ - the incomparability relation, when you cannot compare things


https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/mcda-dm.png

How to represent a Decision Maker's preferences in some model?

With [[Modeling Preferences]]:
* [[Complete Pre-Order Preference Structure]] ($I$ is not transitive)
* [[SemiOrder Preference Structure]] ($I$ is transitive, no $J$)
* [[Partial Order Preference Structure]] (with $J$)
* [[Valued Preference]]


Important condition when modeling preferences:
* [[Preferential Independence]]



== Methods ==
There some important families of criteria:
* MAUT (Utility): [[Multi-Attribute Utility Theory]]
* Outranking methods 


=== Outranking ===
Outranking methods perform pair-wise comparisons (like in the [[Condorcet's Rule]])

Most famous methods:
* [[ELECTRE]] 
* [[PROMETHEE]]

Problems of outranking methods:
* [[Rank Reversal]]


== [[Multi-Objective Optimization]] ==
Once we found the [[Dominance|Pareto-optimal]] set of solutions in a  problem, we need to find the best solution, and MCDA can help with it


== Links ==
* http://www.lamsade.dauphine.fr/~bouyssou/TranspaOrbel16.pdf
* http://www.liacs.nl/~emmerich/moda03mcda.pdf


== Sources ==
* [[Decision Engineering (ULB)]]
* Multiple Criteria Decision Analysis: State of the Art Surveys, 2005 

[[Category:Multi-Criteria Decision Aid]]</text>
      <sha1>6j5ss1t8jt5liyztpce32a3h82728ql</sha1>
    </revision>
  </page>
  <page>
    <title>MCDA</title>
    <ns>0</ns>
    <id>287</id>
    <redirect title="Multi-Criteria Decision Aid" />
    <revision>
      <id>290</id>
      <timestamp>2014-01-14T17:19:02Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="41">#redirect [[Multi-Criteria Decision Aid]]</text>
      <sha1>klav6549b8ee4y9446t21bthl8fhizp</sha1>
    </revision>
  </page>
  <page>
    <title>Consistent Family of Criteria</title>
    <ns>0</ns>
    <id>288</id>
    <revision>
      <id>291</id>
      <timestamp>2014-01-14T17:19:27Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1141">== Consistent Family of Criteria ==
A family of criteria in an [[MCDA]] problem should satisfy the following three properties: 
* Exhaustivity
* Cohesion
* Non-Redundancy

These properties together form a consistent family of criteria

=== Notation ===
* $A = \{a, b, c, ...\}$ - set of alternatives
* $G = \{g_1, ..., g_k\}$ - set of criteria
* $a_1 \ P \ a_2$ - preference relation between two alternatives
* $a_1 \ I \ a_2$ - indifference relation between two alternatives


== Properties ==
=== Exhaustivity ===
$\forall g_i$ s.t. $g_i (a) = g_i (b) \Rightarrow a \ I \ b$


=== Cohesion ===
$\forall a, b \in A$ if
* $\exists g_i \in G: g_i(a) &gt; g_i(b)$ and
* $\forall g_j \in A, g_j \ne g_i: g_j(a) = g_j(b)$ 
* then $a \ P \ b$

Alternative formulation:
* The [[Dominance]] principle should be respected


=== Non-Redundancy ===
$G$ is not redundant if removal of any $g_i \in G$ leads to violation of exhaustivity or cohesion


== Links ==
* http://www.lamsade.dauphine.fr/~bouyssou/TranspaOrbel16.pdf

== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Multi-Objective Optimization]]
[[Category:Multi-Criteria Decision Aid]]</text>
      <sha1>jrsxjgjrreejiw7bth6w387ra1owgtn</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Multi-Criteria Decision Aid</title>
    <ns>14</ns>
    <id>289</id>
    <revision>
      <id>292</id>
      <timestamp>2014-01-14T17:20:21Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="33">[[Category:Decision Engineering]]</text>
      <sha1>ove3cyvlj6kmp2jvatn2y3g0z9phxws</sha1>
    </revision>
  </page>
  <page>
    <title>Weighted Sum Model</title>
    <ns>0</ns>
    <id>290</id>
    <revision>
      <id>293</id>
      <timestamp>2014-01-14T17:40:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2883">== Weighted Sum Model ==
In a [[Multi-Objective Optimization|MOO]] and [[MCDA]] Problems  there are a set of the &quot;best&quot; (Pareto-optimal) solutions. How to decide which one to take?

One possible approach is Weighted Sum

Suppose we have the following table:
* $f_1, ..., f_q$ are criteria
* $a_1, ..., a_n$ are alternatives
* each criteria is assigned some weight $w_i$

{| class=&quot;wikitable&quot;
! || $f_1$ || $f_2$ || ... || $f_q$
|-
! $a_1$  
| $f_1(a_1)$ || $f_2(a_1)$ || ... || $f_q(a_1)$
|-
! $a_2$  
| $f_1(a_2)$ || $f_2(a_2)$ || ... || $f_q(a_2)$
|-
! ...  
| ... || ... || ... || ...
|-
! $a_n$  
| $f_1(a_n)$ || $f_2(a_n)$ || ... || $f_q(a_1)$
|-
! || $w_1$ || $w_2$ || ... || $w_q$
|}


We rank alternatives based on the following score:
* $V(a) = \sum_{i = 1}^{q} w_i f_i (a)$
* $a_i \ P \ a_j \iff V(a_i) &gt; V(a_j)$
* $a_i$ is preferred to $a_j$ if $V(a_i) &gt; V(a_j)$


== Downsides ==
This approach is very simple, but introduces some effects on the decision

=== Bad Use Of Information ===
We consider only one aggregated value, and don't see all the data
* cannot identify weak and strong points

Example: 

{| class=&quot;wikitable&quot;
! || $f_1$ || $f_2$ || $f_3$ || $f_4$
|-
! $a$
| 5 || 5 || 5 || 2
|-
! $b$
| 4 || 4 || 4 || 4
|-
! $w$ || 0.25 || 0.25 || 0.25 || 0.25 
|}

* $V(a) = 4.25, V(b) = 4$
* $b$ is never the best one
* $a$ is the best almost at all criteria, except for $f_4$ (say he's in IT and this is a communication skill)
* cannot identify that by only looking at the $V(a)$ and $V(b)$ scores


=== Conflicts ===
{| class=&quot;wikitable&quot;
! || $f_1$ || $f_2$
|-
! $a$
| 5 || 5
|- 
! $b$ 
| 10 || 0
|-
! $c$ 
| 0 || 10
|- 
! $d$
| 5 || 5
|-
! || 0.5 || 0.5
|}

$V(a) = V(b) = V(c) = V(d) = 0.5$
* but inside they are very different!


=== Scale is Important ===
* suppose that we say that production $p$ is more important then quality $q$
* i.e. $w_p = 2/3, w_q = 1/3$
* $p$ - production per month

{| class=&quot;wikitable&quot;
! || $p$ || $q$ || Score
|-
! $a$
| 100 || 100 || 100
|-
! $b$ 
| 120 || 80 || 106.6
|-
! $w$
| 2/3 || 1/3 || 
|}

In this case $b$ is better 


But suppose now we want to use $p$ - production per week
{| class=&quot;wikitable&quot;
! || $p$ || $q$ || Score
|-
! $a$
| 25 || 100 || 50
|-
! $b$ 
| 30 || 80 || 46
|-
! $w$
| 2/3 || 1/3 || 
|}

Now all of a sudden $a$ becomes better 
* because the scale changed
* need normalization 


=== Not All Solutions ===
With weighted sum not all the solutions can be found
* With weighted sum approach we cannot find all the efficient solutions just by maximizing the sum

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/weighted-sum-non-convex.png
* (a) this solution can be found: this frontier is convex
* (b) cannot be found: only the convex part is discovered


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Multi-Objective Optimization]]
[[Category:Multi-Criteria Decision Aid]]</text>
      <sha1>9lpvlxhczmmy9swvvqt7q558nntev3e</sha1>
    </revision>
  </page>
  <page>
    <title>Ideal Point Model</title>
    <ns>0</ns>
    <id>291</id>
    <revision>
      <id>294</id>
      <timestamp>2014-01-14T17:28:18Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2078">== Ideal Point ==
In a [[Multi-Objective Optimization]] Problems there are a set of the &quot;best&quot; (Pareto-optimal) solutions. How to decide which one to take?

The ''ideal point'' (or ''datum point'') is a solution that is not feasible, but most desired:
* we take all the extreme solutions
* and take the values of criteria at which they are best
* from these criteria we form the ideal point $i$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/moo/ideal-point.png

Then we use the weighted distance to compute a point which is closest to the ideal

The distance function is:
* $\min \left[ \sum_{k=1}^m w_k (z_k(x) - i_k)^p \right]^{1/p}$
* this is called the $LP$-distance function


== Exercises ==
=== Exercise 1 ===
Consider the following multi-criteria problem: 
* $\max X_1 + 2 X_2$
* $\max X_1$

And the following constraints:
* $X_1 \leqslant 2$
* $X_1 + X_2 \leqslant 3$
* $- X_1 + X_2 \leqslant 1 $
* $X_1 \geqslant 0, X_2 \geqslant 0$

Compute 
* the efficient solution set 
* the datum point
* find the closest points to the datum point with $L_1$ and $L_2$ distances


First we construct the solution space:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/ideal-point-ex1-solset.png
* the efficient solution set is the one that maximizes everything
* we select the following points: $A(1, 2), B(2, 1), C(2, 0)$
* values that lay on line $ABC$ form the efficient set of solutions

Now we draw the criteria space 
* we build it from all possible values of the line $ABC$
* $P(X_1, X_2) \to P(X_1, X_1 + 2 X_2)$
* $A(1, 2) \to A(1, 1 + 2 \cdot 2) = A(1, 5)$ 
* $B(2, 1) \to B(4, 2)$
* $C(2, 0) \to C(2, 2)$
* the ideal point is $D$: a virtual point that would be best for both criteria
* $D(5, 2)$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/ideal-point-ex1-datum.png

Now we calculate which solutions are closest to $D$:
* for $L_1$: all values on the line $AB$
* for $L_2$: the middle between $A$ and $B$


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Multi-Objective Optimization]]</text>
      <sha1>6ivx2yix3hhfxc41458fgs8gtqrvgxh</sha1>
    </revision>
  </page>
  <page>
    <title>Luce's Coffee Cups</title>
    <ns>0</ns>
    <id>292</id>
    <revision>
      <id>295</id>
      <timestamp>2014-01-14T17:32:14Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1020">== Luce's Coffee Cups == 
This is a thought experiment that shows that the Indifference relation is not transitive

Suppose we have 402 cups of coffee:
* $c_0$ with 0 grains of coffee
* $c_1$ with 1 grain of coffee, $c_0 \ I \ c_1$
* $c_2$ with 2 grains of coffee, $c_1 \ I \ c_2$
* ...
* $c_{401}$ with 401 grain of coffee, $c_{400} \ I \ c_{401}$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/luce-1.png

But we cannot say that there's no difference in $c_0$ and $c_{401}$
* $c_0 \ \not I \ c_{401}$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/luce-2.png


It shows that $I$ is not transitive:
* $a \ I \ b, b \ I \ c \not \Rightarrow a \ I \ c$


The reason for it is that there's a sensitivity threshold that is not taken into account
* This is reflected in [[SemiOrder Preference Structure]]


== Links ==
* On Indifference: http://econweb.umd.edu/~ozbay/indifference.pdf

== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Multi-Criteria Decision Aid]]</text>
      <sha1>ksf91ti1nm52dymxtq8is5snsnb6zxh</sha1>
    </revision>
  </page>
  <page>
    <title>Modeling Preferences</title>
    <ns>0</ns>
    <id>293</id>
    <revision>
      <id>296</id>
      <timestamp>2014-01-14T17:35:45Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1893">== Modeling Preferences ==
To be able to find the best solution for [[Multi-Criteria Decision Aid|MCDA]] problems we need to know ''subjective preferences'':
* these are binary relations provided by a decision maker 
* defined analogously to [[Voting Theory Relations]]


So given two alternatives $a$ and $b$ a decision maker can say if
* $a \ P \ b$ or $b \ P \ a$: $a$ is preferred to $b$ - ''the preference relation''
* $a \ I \ b$ - the indifference relation
* $a \ J \ b$ - the incomparability relation, when you cannot compare things


Main properties:
* $P$ is asymmetric
** $a \ P \ b \equiv b \ \overline{P} \ a$
* $I$ is reflexive and symmetric:
** $a \ I \ a$ and $a \ I \ b \equiv b \ I \ a$
* $J$ is irreflexible and symmetric
** $a \ \overline{J} \ a$ and $a \ J \ b \equiv b \ J \ a$ 


Transitivity
* $P$ is transitive
* but $I$ is not! by [[Luce's Coffee Cups]] (In contract to [[Voting Theory]] - there we assumed it's transitive)


We can show the preferences of a decision maker with a graph:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/preference-modelling.png

 
== Preference Structures ==
How to build a mathematical model from statements of a decision maker? 

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/mcda-dm.png

There are several preference structures that can do that:
* [[Complete Pre-Order Preference Structure]] ($I$ is not transitive) - The Traditional Model
* [[SemiOrder Preference Structure]] ($I$ is transitive, no $J$) - The Threshold Model
* [[Partial Order Preference Structure]] (with $J$)
* [[Valued Preference]]


== Preferential Independence ==
{{ Main | Preferential Independence }}

This is an important condition between preferences and criteria: the criteria should be preferentially independent.


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Multi-Criteria Decision Aid]]</text>
      <sha1>sbphkqd7tm0r5in2vureyu5bvtqsp4o</sha1>
    </revision>
  </page>
  <page>
    <title>Complete Pre-Order Preference Structure</title>
    <ns>0</ns>
    <id>294</id>
    <revision>
      <id>297</id>
      <timestamp>2014-01-14T17:38:39Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1414">== Complete Pre-Order ==
This is a preference structure for [[Modeling Preferences]] in [[MCDA]]

Also called the traditional representation of preferences 

$\forall a,b \in A:$
* $a \ P \ b \iff g(a) &gt; g(b)$ (The complete order: $R$ relation)
* $a \ I \ b \iff g(a) = g(b)$ (The complete pre-oder: $I$ relation)

$g$ is some global aggregation function:
* [[Weighted Sum Model]]
* [[Ideal Point Model]]


This way we cannot model incomparability ($&gt;$ can always compare things)
* $J$ is always empty - everything is comparable
* $P$ is transitive 
* $I$ also becomes transitive


=== Example 1 ===
Suppose there are three sport teams: $a$, $b$, and $c$. 
* If $a$ beats $b$, $a$ receives 3 points and the loser receives 0 points
* If they draw, both receives 1 point. 
* The three teams will play with each other and at the end they will have total points. 
* If all total scores are different, there will be a ''complete order''
* If there is a tie, the order will be a ''complete preorder''


=== Example 2 ===
Expected gains of different actions:

{| class=&quot;wikitable&quot;
! $a$ || $b$ || $c$ || $d$ || $e$ || $f$ || $g$
|-
| 100 || 100 || 120 || 130 || 130 || 130 || 131
|}

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/graph-1.png



== Sources ==
* [[Decision Engineering (ULB)]]
* http://web.itu.edu.tr/~topcuil/ya/MDM03ConstructingModel.pptx

[[Category:Multi-Criteria Decision Aid]]</text>
      <sha1>1iqmaio98erbb8txf52iv19u4v8ec4u</sha1>
    </revision>
  </page>
  <page>
    <title>SemiOrder Preference Structure</title>
    <ns>0</ns>
    <id>295</id>
    <revision>
      <id>298</id>
      <timestamp>2014-01-14T17:43:19Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1674">== Semi Order ==
This is a preference structure for [[Modeling Preferences]] in [[MCDA]] that takes indifference threshold into account (and therefore can model situations such as in [[Luce's Coffee Cups]])

Also called semi-order
$\forall a,b \in A:$
* $a \ P \ b \iff g(a) &gt; g(b) + q$
* $a \ I \ b \iff | g(a) - g(b) | \leqslant q$

$q$ - some threshold


== Properties ==
=== Property 1 ===
$I$ is not transitive now:
* $g(b) = g(a) + 2/3 \cdot q \Rightarrow a \ I b$
* $g(c) = g(b) + 2/3 \cdot q \Rightarrow b \ I c$
* $a \ \overline{I} \ c$ because $|g(c) - g(a) | = 4/3 \cdot t &gt; q \Rightarrow a \ P \ c$


== Exercises ==
=== Exercise 1 ===
$a \ P \ b, b \ P \ c, a \ I \ d \Rightarrow d \ P \ c$
* (1) $a \ P \ b \iff g(a) &gt; g(b) + q$
* (2) $b \ P \ c \iff g(b) &gt; g(c) + q$
* (3) $a \ I \ d \iff | g(a) - g(d) | \leqslant q \iff -q + g(d) \leqslant g(a) \leqslant q + g(d)$
* (4), (1) + (2): $g(a) + g(b) &gt; g(b) + g(c) + 2q, g(a) &gt; g(c) + 2q$
* (3) &amp; (4) $q + g(d) \geqslant g(a) &gt; g(c) + 2q  \Rightarrow g(d) &gt; g(c) + q \iff d \ P \ c$

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/threshold-model-prop1.png

=== Exercise 2 ===
$a \ P \ b, b \ I \ c, c \ P \ d \Rightarrow a \ P \ d$
* (1) $a \ P \ b \iff g(a) &gt; g(b) + q$
* (2) $b \ I \ c \iff | g(b) - g(c) | \leqslant q  \iff g(b) - q \leqslant g(c) \leqslant g(b) + q$
* (3) $c \ P \ d \iff g(c) &gt; g(d) + q$
* (4), (3) &amp; left of (2): $g(d) + q &lt; g(c) \leqslant g(b) + q \Rightarrow g(b) + q&gt; g(d) + q$
* (1) &amp; (4): $g(a) &gt; g(b) + q &gt; g(d) + q \Rightarrow g(a) &gt; g(d) + q \Rightarrow a \ P \ d$ 



== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Multi-Criteria Decision Aid]]</text>
      <sha1>2hmbed76cmiy41rtoemjlrc7pib9uu3</sha1>
    </revision>
  </page>
  <page>
    <title>Partial Order Preference Structure</title>
    <ns>0</ns>
    <id>296</id>
    <revision>
      <id>299</id>
      <timestamp>2014-01-14T17:44:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1005">== Partial Order ==
This is a preference structure for [[Modeling Preferences]] in [[MCDA]] that includes $J$ - the Incomparability relation. 


Assume:
* there are different experts $\{1, 2, 3\}$
* they evaluate 4 projects $a, b, c, d$
* investment $a$ is preferred to investment $b$ if estimates from $a$ are higher than from $b$ (or $a$ [[Dominance|dominates]] $b$)
* i.e. there is [[Unanimity]] between the experts

{| class=&quot;wikitable&quot;
! || $a$ || $b$ || $c$ || $d$
|-
! 1 
| 10 || 8 || 7 || 6
|-
! 2 
| 9 || 7 || 5 || 6
|-
! 3 
| 12 || 8 || 9 || 4
|}

We can infer the following relations:
* $a \ P \ b$ because all three experts agree 
* but $b \ J \ c$:
** 1st expert say $b \ P \ c$
** but 3rd say $c \ P \ b$
** therefore we cannot compare $a$ and $b$

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/graph-2.png

so we have partial order:
* $P$ is transitive
* and $J$ is not empty


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Multi-Criteria Decision Aid]]</text>
      <sha1>0m4hmke4gtg2e8w2h2mtcog93l5rk2o</sha1>
    </revision>
  </page>
  <page>
    <title>Valued Preference</title>
    <ns>0</ns>
    <id>297</id>
    <revision>
      <id>300</id>
      <timestamp>2014-01-14T17:44:51Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="984">== Valued Preference ==
This is a preference structure for [[Modeling Preferences]] in [[MCDA]].


In this case the relation $P$ is not binary
* instead of saying $a \ P \ b$ or $b \ P \ a$ we express the intensity of preference:
* $v(a, b)$ is valued preference of $a$ to $b$ 
* $v(b, a)$ is valued preference of $b$ to $a$ 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/valued-pref.png

=== [[Voting Theory]] Analog ===
We can see the valued preference function as the proportion voters:
* $v(a, b)$ is the proportion of voters who prefer $a$ to $b$ 
* $v(b, a)$ is the proportion of voters who prefer $b$ to $a$, $v(b, a) = 1 - v(a, b)$

This is quite similar to [[Condorcet's Rule]]:
* $v(a, b) = \cfrac{N(a &gt; b)}{N}$ and $v(b, a) = \cfrac{N(b &gt; a)}{N}$

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/graph-3.png


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Multi-Criteria Decision Aid]]
[[Category:Voting Theory]]</text>
      <sha1>0jv044xknv4soev7fff4lk6pkud3rh4</sha1>
    </revision>
  </page>
  <page>
    <title>Preferential Independence</title>
    <ns>0</ns>
    <id>298</id>
    <revision>
      <id>301</id>
      <timestamp>2014-02-09T18:01:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4792">== Preferential Independence ==
The preference independence principle is an important principle from [[MCDA]] for choosing criteria: they should be preferential independent.

Suppose we have 4 alternatives $a,b,c,d$ and a subset of criteria $J \subset G$ such that
* $g_i(a) = g_i(b), \forall i \not \in J$
* $g_i(c) = g_i(d), \forall i \not \in J$
* $g_i(a) = g_i(a), \forall i \in J$
* $g_i(b) = g_i(d), \forall i \in J$

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/preferential-independence.png
* for criteria that are in $J$, $a$ is the same as $c$ and $b$ is the same as $d$
* for criteria not in $J$, $a$ is the same as $b$, $c$ is the same as $d$ 

Preferential Independence
* $J \subset A$ is ''preferentially independent'' within $G$ when 
* if $\forall a,b,c,d \in A$ these conditions hold
* then $a \ P \ b \iff c \ P \ d$ 


if a decision maker says $a \ P \ b$ we know that he bases his opinion on the set of $J$, because in $\overline{J}$ $a \ I \ b$ - they are the same 


== Examples ==
=== Example 1 ===
{|  class=&quot;wikitable&quot;
! || $g_1$ || $g_2$ || $g_3$
|- 
! $a$ 
| &lt;font color=&quot;blue&quot;&gt;45&lt;/font&gt; || 70 || &lt;font color=&quot;blue&quot;&gt;100&lt;/font&gt;
|- 
! $b$ 
| &lt;font color=&quot;blue&quot;&gt;50&lt;/font&gt; || 70 || &lt;font color=&quot;blue&quot;&gt;80&lt;/font&gt;
|- 
! $c$ 
| &lt;font color=&quot;blue&quot;&gt;45&lt;/font&gt; || 90 || &lt;font color=&quot;blue&quot;&gt;100&lt;/font&gt;
|- 
! $d$ 
| &lt;font color=&quot;blue&quot;&gt;50&lt;/font&gt; || 90 || &lt;font color=&quot;blue&quot;&gt;80&lt;/font&gt;
|}


criteria $\{g_1, g_3\}$ are preferentially independent 
* i.e. $a \ P \ b \iff c \ P \ d$


=== Example 2 ===
In this example the Preferential Independence principle is not satisfied

We're in a restaurant and there are 2 dishes and 2 drinks
* dishes: fish, meat
* drinks: red wine, white wine
* so we have 4 combinations:

{|  class=&quot;wikitable&quot;
! || colspan=&quot;2&quot; | drinks $\downarrow$
|-
! rowspan=&quot;2&quot; | meal $\to$
| $(a)$ fish + white || $(c)$ fish + red
|-
| $(b)$ meal + white || $(d)$ meal + red
|}

So we have two criteria: 
* $g_1$ - meal
* $g_2$ - drink


For meal:
* $g_1(a) = g_1(c)$ 
* $g_1(b) = g_1(d)$ 

For drink:
* $g_2(a) = g_2(b)$
* $g_2(c) = g_2(d)$

Not satisfied:
* If, when asked &quot;what would you prefer - meat or fish&quot;, the decision maker asks &quot;with what drink&quot;
* then the preferential independence is not satisfied: these two criteria are dependent 
* usually the case in real life

Satisfied
* if a DM can say 
* &quot;I always prefer meat to fish&quot; ($b \ P \ a \land d \ P \ c$) and
* &quot;I always prefer red wine to white wine&quot; ($c \ P \ a \land d \ P \ b$)
* then if he says &quot;I prefer meat with red wine to meat with white line&quot; then he will say &quot;I prefer fish with red wine to fish with white line&quot; ($d \ P \ c \Rightarrow c \ P \ a$)
* usually not the case 


=== Example 3 ===
Taken from [http://wiki.ece.cmu.edu/ddl/index.php/Preferential_independence]

Suppose we are choosing a car and there are two criteria
* style: sport, SUV
* color: red, black

Color is preferentially independent from style when
* if the DM prefers:
** (red, sport) to (black, sport)
** (red, SUV) to (black, SUV)
* then the color is preferentially independent from style
** red is preferred to black regardless of style
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/preferential-independence-ex0.png


However style is not necessarily independent from color
* if DM prefers 
** (red, sport) to (red, SUV), but
** (black, SUV) to (black, sport)
* then the style is not preferentially independent from color
** because the color influences what decision maker prefers


With graphical depiction it's clear:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/preferential-independence-ex1.png
* red is always preferred to black (all edges come from red to black)
* but when it comes to style, it's not the case: one edge comes from sport to SUV, another from SUV to sport


=== Example 4 ===
Consider a case when an employer wants to hire a new worker on the basis of their age, degree and professional experience. 

{| class=&quot;wikitable&quot;
! Worker || $g_A$: Age || $g_D$: Degree || $g_E$: Experience 
|- 
! $a$ 
| 25 || Master || No Experience
|- 
! $b$ 
| 25 || No Degree || 3 Years
|- 
! $c$ 
| 35 || Master || No Experience
|- 
! $d$ 
| 35 || No Degree || 3 Years
|}

We see that given $J = \{g_A\}$ and $\overline{J} = \{ g_D, g_e \}$:
* $g_i(a) = g_i(b), \forall i \not \in J$
* $g_i(c) = g_i(d), \forall i \not \in J$
* $g_i(a) = g_i(a), \forall i \in J$
* $g_i(b) = g_i(d), \forall i \in J$

However an employee would prefer:
* $a \ P \ b$ but $d \ P \ c$


== Preferential Independence in Methods ==
* in [[Multi-Attribute Utility Theory|MAUT]]
* in [[PROMETHEE]]


== Sources ==
* [[Decision Engineering (ULB)]]
* http://wiki.ece.cmu.edu/ddl/index.php/Preferential_independence

[[Category:Multi-Criteria Decision Aid]]</text>
      <sha1>tvimwogk70xn7iq8aewx5i21bd9i6e4</sha1>
    </revision>
  </page>
  <page>
    <title>Multi-Attribute Utility Theory</title>
    <ns>0</ns>
    <id>299</id>
    <revision>
      <id>302</id>
      <timestamp>2014-02-09T14:38:40Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4244">== Multi-Attribute Utility Theory ==
Multi-Attribute Utility Theory or MAUT is a method of [[Multi-Criteria Decision Aid]]


== Utility Functions ==
Suppose we have a global utility function $U(a)$ that aggregates all criteria into one value:
* $U(a) = U(g_1(a), ..., g_k(a))$


=== Additive Utility Functions ===
$U(a) = \sum_{j=1}^k u_j(g_j(a))$
* behind this we can have the [[Weighted Sum Model]]

{|
 | The evaluation table: &lt;br/&gt;
 
 {| class=&quot;wikitable&quot;
  ! || Price || Comfort
  |- 
  ! $a$ 
  | 300 || Medium
  |- 
  ! $b$ 
  | 350 || Good 
  |- 
  ! $c$ 
  | 400 || Good
  |- 
  ! $d$ 
  | 450 || Very Good
  |}

 | The utility functions: &lt;br/&gt;

 {| class=&quot;wikitable&quot;
  ! $u_1$ || $u_2$
  |- 
  | 8.5 || 4
  |- 
  | 8 || 7 
  |- 
  | 6 || 7
  |- 
  | 5 || 10
  |}


|}

With weights $k_1 = 7$ and $k_2 = 3$ we establish the ranking based on the following values:
* $u(a) = 7 \cdot 8.5 + 3 \cdot 4 = 71.5$
* $u(b) = 7 \cdot 8 + 3 \cdot 7 = 77$
* $u(c) = 7 \cdot 6 + 3 \cdot 7 = 63$
* $u(d) = 7 \cdot 5 + 3 \cdot 10 = 65$
* $b &gt; a &gt; d &gt; c$


=== Marginal Utilities ===
At first we transform the evaluation into two &quot;marginal utilities&quot;:
* we transform evaluation of all criteria into a scale $[0, 1]$

So with the weighted sum we have
* $U(a) = \sum{k=1}{n} w_k u_k(a)$
* we want $u_k \in [0, 1]$

Suppose you want to buy a car
* the prices range from 15k to 50k
* so first step is assigning 1 to 15k and 0 to 50k
** we've got a linear utility function
** but this is only just the first approximation of our preferences
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/maut-marginal-utilities.png
* we know that we're willing to spend somewhere around 20k 
** we want $u(20k) = 0.5$
** so we modify the function by adding an additional point - now there're two linear function
** this is the second approximation of our preferences
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/maut-marginal-utilities2.png
* can repeat this for both left and right sides to get the 3rd approximation
** and define $u(p_1) = 0.75$ and  $u(p_2) = 0.25$
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/maut-marginal-utilities3.png
* and so on


== Examples ==
Consider an additive model and the following evaluation table

{| class=&quot;wikitable&quot;
! || $g_1$ || $g_2$
|- 
! $a_1$ 
| 1 || 1
|- 
! $a_2$ 
| 1 || 3
|- 
! $a_3$ 
| 1 || 5
|- 
! $a_4$ 
| 2 || 1
|- 
! $a_5$ 
| 2 || 3
|- 
! $a_6$ 
| 2 || 5
|- 
! $a_7$ 
| 3 || 1
|- 
! $a_8$ 
| 3 || 3
|- 
! $a_9$ 
| 3 || 5
|}


Based on this table a Decision Maker gives his preferences:
* $a_9 \ P \ a_6 \ P \ a_8 \ P \ a_5 \ P \ a_3 \ I \ a_7 \ P \ a_2 \ I \ a_4 \ P \ a_1$

This ordering satisfied the [[Preferential Independence]] criteria.

Definition: $\exists a,b,c,d \in A$, and set of criteria $J \cup \overline{J} = G$
* $g_i(a) = g_i(b), \forall i \not \in J$
* $g_i(c) = g_i(d), \forall i \not \in J$
* $g_i(a) = g_i(a), \forall i \in J$
* $g_i(b) = g_i(d), \forall i \in J$


In this case $J = \{g_1\}, \overline{J} = \{g_2\}$
* under $J$: $a_1 = a_2 = a_3; a_4 = a_5 = a_6; a_7 = a_8 = a_8$ 
* under $\overline{J}$: $a_1 = a_4 = a_7; a_2 = a_5 = a_8; a_3 = a_7 = a_9$

Need to check if this principle is satisfied for all possible combinations

For example, $a_1, a_4, a_5, a_5$:
* $a_4 \ P \ a_1 \iff a_5 \ P \ a_2$
* this indeed holds 



Now we want to check how the decision maker obtained this ranking
* can we model it with an utility function? 
* note that $a_3 \ I \ a_7$
** then under the utility model it should be true that $U(a_3) = U(a_7)$
** $u_1(g_1(a_3)) + u_2(g_2(a_3)) = u_1(g_1(a_7)) + u_2(g_2(a_7)) = ...$ 
** $... = u_1(1) + u_2(5) = u_1(3) + u_2(1) \ \ \  (*)$
* also $a_2 \ I \ a_4$ 
** then $U(a_2) = U(a_4)$
** or $u_1(1) + u_2(3) = u_1(2) + u_2(1) \ \ \ (**)$
* let's try to find the utility function
** check $(*) - (**)$
** $u_2(5) - u_2(3) = u_1(3) - u_1(2) \Rightarrow u_1(2) + u_2(5) = u_1(3) + u_2(3)$
** we see that $a_6$ is evaluated to $(2, 5)$ and $a_8$ is evaluated to $(3, 3)$
** but it means that we should also have $a_6 \ I \ a_8$ - which is not the case
** thus it's not possible to establish 


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Multi-Criteria Decision Aid]]</text>
      <sha1>17hwpsvre22gj4vhjyow7ipikyqzi3m</sha1>
    </revision>
  </page>
  <page>
    <title>ELECTRE</title>
    <ns>0</ns>
    <id>300</id>
    <revision>
      <id>303</id>
      <timestamp>2014-01-14T18:02:48Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9146">== ELECTRE ==
This is a method from the family of outranking (i.e. based on pair-wise comparison) [[MCDA]] methods. The result is a partial ordering of alternatives (see [[Partial Order Preference Structure]])

Here:
* ELECTRE I

ELECTRE I chooses alternatives that are preferred by the majority of the criteria and which don;t cause an unacceptable level of discontentment on other criteria. 


== Preferences ==
; Main idea: 
: When we say $a \ P \ b$?
* (1) if we have a lot of criteria for which $u_i(a) &gt; u_i(b)$ (where $u_i$ - some utility function)
* (2) and we have no strong arguments that say the opposite of (1)


The ELECTRE methods are based on two concepts:
* Concordance Index 
* Discordance Index


=== Concordance Index ===
Or quantification of positive arguments

For ELECTRE 1, when comparing $a$ and $b$
* identify all criteria $g_j$ such that $g_j(a) \geqslant g_j(b)$
* for all such criteria $g_j$ sum their weights $w_j$, 
* let $W$  be the sum of all weights: $W = \sum_i w_i$ (we use this for normalization)
* define the concordance index as:
*: $c(a, b) = \cfrac{1}{W} \sum_{j: g_j(a) \geqslant g_j(b)} w_j$

Note that weight should sum up to 1 

There are two extreme cases:
* $c(a, b) = 1$: all criteria for $a$ are better than for $b$ ([[Unanimity]])
** have very good reasons to say $a \ P \ b$
* $c(a, b) = 0$: there is no criteria in which $a$ better than $b$ 


=== Discordance Index ===
Or quantification of negative arguments 

We want to find a strong argument against $a \ P \ b$
* if we find such an argument then we cannot say that $a \ P \ b$

For ELECTRE I, define $d(a, b)$ as 
* 0 when $\forall j: g_j(a) \geqslant g_j(v)$ (none when there's [[Unanimity]])
* if $\exists g_i: g_i(b) \geqslant g_i(a)$ then we have an argument against $a \ P \ b$
* in this case we want to identify the largest difference between $a$ and $b$:
** $\cfrac{1}{\delta} \max_j [g_j(b) - g_j(a)]$
** $\delta$ is normalization factor: $\delta = \max_{i,c,d} [g_i(c) - g_i(d)]$


Another way 
* let $D$ be the set of cases where we list cases that cannot be compared 
* if for a pair of alternatives $(a, b)$ there exists a criteria $g_i$ s.t. $(g_i(a), g_i(b)) \in D$ then we cannot compare these alternatives 


=== Outranking Preference Relation ===
For ELECTRE I we define $S \equiv P \lor I$ as: (the &quot;as good as relations&quot;, also see [[Voting Theory Relations]])
* $a \ S \ b \iff$
** (1) $c(a, b) \geqslant \tilde c$
**: a lot of positive arguments to say $a \ S \ b$
** (2) $d(a, b) \leqslant \tilde d$
**: not many negative arguments to say the opposite
* so for that we also have to provide two parameters:
** $\tilde c$ - the ''concordance threshold'' and $\tilde d$ - the ''discordance threshold''


Or:
* $a \ S \ b \iff$
** (1) $c(a, b) \geqslant \tilde c$
** (2) $\forall g_i: \big(g_i(a), g_i(b)\big) \not \in D$

Note that this relation gives us partial order:
* we have $P$ and $I$ (expressed via $S$) 
* and we have $J$ (when discordance threshold is exceeded)


== [[Graph Kernel]]s ==
Graph Kernels are used to identify good alternatives. 

It is possible to express the outranking relation $S$ in form of a directed graph 

Example:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/electree-graph.png
* $a$ is better than $e$ and $d$
* $d$ is better than $f$ and $c$ 
* etc

A ''kernel'' of a graph $K \subset A$ is
* $\forall a \in K, \not \exists b: a \ S \ b$
*: no alternative $a$ inside the kernel $K$ is better than any other alternative $b$ inside $K$
* $\forall a,b \in K: a \ ? \ b$
*: within the kernel we cannot say anything about the relation between $a$ and $b$
* $\forall c \not \in K, \exists a \in K: a \ S \ c$
*: each alternative $c$ outside of the kernel $K$ is worse than at least one alternative $a$ inside $K$


For the example above:
* $K = \{b, d, e\}$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/electree-graph-kernel1.png


Another example
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/electree-graph-kernel2.png


Remarks:
* If the graph has no cycles then the kernel is unique 
* Each cycle can be replaced by a single node (see [[Strongly Connected Components]])


The kernel $K$ of a set $A$ forms a set of preferred alternatives.



== Examples ==
=== Example 1 ===
{| class=&quot;wikitable&quot;
! || price || comfort || speed || aesthetic ||
|-
! 1 
| 300 || ex  || fast || good || 
|-
! 2 
| 250 || ex  || med  || good || 
|-
! 3 
| 250 || med || fast || good ||
|-
! 4 
| 200 || med || fast || med  ||
|-
! 5 
| 200 || med || med  || good ||
|-
! 7 
| 100 || poor || med || med  ||
|-
! $w$
| 5   || 4   || 3    || 3    || $W = \sum w = 15$
|}


==== Concordance ====
Perform pair-wise comparisons for all elements $A$ 
* let's compare (1) and (2) 
* concordance: $c(1, 2) = \cfrac{1}{15} (4 + 3 + 3) = \cfrac{2}{3}$

This way we compare each with each:

{|  class=&quot;wikitable&quot;
! || 1  || 2  || 3  || 4  || 5  || 6  || 7
|-
! 1 
| -  || 10 || 10 || 10 || 10 || 10 || 10
|-
! 2 
| 12 || -  || 12 || 7  || 10 || 7  || 10
|-
! 3 
| 11 || 11 || -  || 10 || 10 || 10 || 10
|-
! 4 
| 8  || 8  || 12 || -  || 12 || 12 || 10
|-
! 5 
| 8  || 11 || 12 || 12 || -  || 12 || 10
|-
! 6 
| 11 || 11 || 11 || 11 || 11 || -  || 10
|-
! 7 
| 5  || 8  || 5  || 8  || 8  || 9  || -
|}

(note that this is not normalized - need also to divide on 15)


==== Discordance ====
In this case we define discordance by enumerating cases that are forbidden 

The following tables shows what veto we define 

{| class=&quot;wikitable&quot;
! || price || comfort 
|-
! $a$ 
| 250 || poor
|-
! $b$ 
| 100 || excellent 
|}


==== Graph ====
So the establish the following relation $S$ and the following graph:

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/electree-ex1-graph.png

There are two kernels in this case:
* 2, 4, 7
*: https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/electree-ex1-graph-kernel1.png
* 2, 5, 7
*: https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/electree-ex1-graph-kernel2.png

Kernel:
* 6 is dominated - remove it
* same for 3 and 1
* since there's a cycle we have to decide between 4 and 5, and remove one of them
* when we put alternatives into a kernel, it doesn't mean they are the best, but it means it allows to apply the [[Dominance]] principle and remove dominated alternatives


=== Example 2 ===
* A company wants to rank 5 candidates $A,B,C,D,E$ for a promotion 
* Criteria:
** Reputation of diploma $D$
** Skills $K$
** Personality $P$
** Spoken Languages $L$
** Seniority $S$
* Apply ELECTRE with concordance threshold 0.6 and discordance 6 

The following evaluation table is obtained

{| class=&quot;wikitable&quot;
! || $A$ || $B$ || $C$ || $D$ || $E$ || Weight
|-
! $D$ 
| 7 || 11 || 15 || 11 || 16 || 15
|-
! $K$ 
| 12 || 18 || 6 || 8 || 10 || 15
|-
! $P$ 
| 13 || 13 || 14 || 19 || 10 || 15
|-
! $L$ 
| 18 || 16 || 19 || 13 || 19 || 25
|-
! $S$ 
| 10 || 20 || 16 || 14 || 20 || 20
|}

Total weight is $W = 15 + 15 + 15 + 25 + 20 = 100$


==== Concordance ====
Then we construct the concordance index by comparing alternatives pair-wise


For example, consider alternatives $A$ and $B$

{|  class=&quot;wikitable&quot;
! || $A$ vs $B$ || $B$ vs $A$ 
|- 
! $D$ 
|    || 15  
|- 
! $K$ 
|    || 15
|- 
! $P$ 
| 25 || 25
|- 
! $L$ 
| 25 || 
|- 
! $S$ 
|    || 20
|- 
| '''Total''' || 50 || 100
|- 
| '''Normalized''' || 0.5 || 0.75
|}

Repeating this for all pairs, construct the following table: 

{| class=&quot;wikitable&quot;
!  || $A$ || $B$ || $C$ || $D$ || $E$
|-
! $A$ 
| - || '''0.75''' || 0.15 || 0.4 || 0.4 
|-
! $B$ 
| 0.5 || - || 0.35 || '''0.75''' || '''0.6''' 
|-
! $C$ 
| '''0.85''' || '''0.65''' || - || '''0.6''' || 0.5 
|-
! $D$ 
| '''0.6''' || 0.25 || 0.4 || - || 0.25 
|-
! $E$ 
| '''0.6''' || '''0.6''' || '''0.75''' || '''0.75''' || - 
|}


'''Bold''' are alternatives that should be preferred provided that there's no discordance
* recall that $\tilde c = 0.6$ and we check all values that $\geqslant \tilde c$


==== Discordance ====
The discordance index is $\tilde d = 6$
* we don't normalize on $\delta$ here because our values are already normalized 


Let's compare $A$ with $B$ and $A$ with $C$:

{|  class=&quot;wikitable&quot;
! || $A$ vs $B$ || $B$ vs $A$ || $A$ vs $C$ || $C$ vs $A$ 
|- 
! $D$ 
|  7 || - || '''8''' || - 
|- 
! $K$ 
|  6 || - || - || '''6'''
|- 
! $P$ 
| 0 || 0 || 1 || -
|- 
! $L$ 
| - || '''2''' || 1 || -
|- 
! $S$ 
| '''10''' || - || 6 || -
|- 
| '''Max''' || ''10'' || 2 || ''8'' || ''6'' 
|- 
! Rel 
| $A \ J \ B$ || || $A \ J \ C$ || $C \ J \ A$
|}

* if a difference exceeds the threshold, the alternatives are incomparable 


==== Graph ====
Based on the Concordance and Discordance we define the outranking relation $S$
* this relation can be depicted as a graph
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/electree-ex2-graph.png



== Sources ==
* [[Decision Engineering (ULB)]]
* http://web.itu.edu.tr/~topcuil/ya/MDM08Outranking.pptx
* http://electre.no.sapo.pt/MElecI2.htm
* Multiple Criteria Decision Analysis: State of the Art Surveys, 2005 

[[Category:Multi-Criteria Decision Aid]]</text>
      <sha1>qkw64xpysphx9wr8gdx59tt7wmruv10</sha1>
    </revision>
  </page>
  <page>
    <title>Graph Kernel</title>
    <ns>0</ns>
    <id>301</id>
    <revision>
      <id>304</id>
      <timestamp>2014-01-14T18:03:59Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1028">== [[Graph]] Kernel ==
A ''kernel'' of a graph $K \subset V$ is ($V$ - all nodes of a graph)
* $\forall a \in K, \not \exists b: a \to b$
*: no alternative $a$ inside the kernel $K$ is better than any other alternative $b$ inside $K$
* $\forall c \not \in K, \exists a \in K: a \to c$
*: each alternative $c$ outside of the kernel $K$ is worse than at least one alternative $a$ inside $K$

For the example above:
* $K = \{b, d, e\}$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/electree-graph-kernel1.png

Remarks:
* If the graph has no cycles then the kernel is unique 
* Each cycle can be replaced by a single node (see [[Strongly Connected Components]])



== Usage ==
* [[ELECTRE]] methods of [[MCDA]].


== Links ==
* http://en.wikipedia.org/wiki/Graph_kernel
* http://jmlr.org/papers/volume11/vishwanathan10a/vishwanathan10a.pdf

== Sources ==
* [[Decision Engineering (ULB)]]
* http://web.itu.edu.tr/~topcuil/ya/MDM08Outranking.pptx
* http://electre.no.sapo.pt/MElecI2.htm


[[Category:Graphs]]</text>
      <sha1>kdyssigl763gjwk24d14e0xznrzwlow</sha1>
    </revision>
  </page>
  <page>
    <title>Rank Reversal</title>
    <ns>0</ns>
    <id>302</id>
    <revision>
      <id>305</id>
      <timestamp>2014-02-09T17:59:04Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1002">== Rank Reversal ==
Many pair-wise comparison [[MCDA]] methods (such as [[ELECTRE]] and [[PROMETHEE]]) suffer from rank reversal:
* the relative position of two alternatives may be influenced by the presence of a third one  
* i.e. [[Independence to Third Alternatives]] criterion is not satisfied

A position of two alternatives can be affected by 
* removing [[Non-Discriminating Criteria]] 
* removing / adding a copy of an alternative
* removing / adding a new criteria
* presence of a dominated alternative
* removing a dominated alternative

This may lead to:
* Risk of manipulation 


This issue occurs in:
* [[ELECTRE]]
* [[PROMETHEE]] both I and II (see [[PROMETHEE/Rank Reversal|Rank Reversal in PROMETHEE]])


== Links ==
* http://en.wikipedia.org/wiki/Rank_reversals_in_decision-making

== Sources ==
* [[Decision Engineering (ULB)]]
* An Introduction to Multicriteria Decision Aid: The PROMETHEE and GAIA Methods, Yves De Smet, Karim Lidouh, 2013


[[Category:Multi-Criteria Decision Aid]]</text>
      <sha1>4or4lyrh5k7m9jbi17t835a5rj8tnp7</sha1>
    </revision>
  </page>
  <page>
    <title>Non-Discriminating Criteria</title>
    <ns>0</ns>
    <id>303</id>
    <revision>
      <id>306</id>
      <timestamp>2014-01-14T18:05:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="912">== Non-Discriminating Criteria ==
In [[MCDA]] a criterion is non-discriminating if for all alternatives we have the same evaluation

For example,

{| class=&quot;wikitable&quot;
! || $f_1$ || $f_2$ || ... || $f_k$ || ... || $f_q$
|- 
!$a_1$ 
| $f_1(a_1)$ || $f_2(a_1)$ || ... || $\alpha$ || ... || $f_q(a_1)$
|- 
!$a_2$ 
| $f_1(a_2)$ || $f_2(a_2)$ || ... || $\alpha$ || ... || $f_q(a_2)$
|- 
!... 
| ... || ... || ... || ... || ... || ...
|- 
!$a_n$ 
| $f_1(a_n)$ || $f_2(a_n)$ || ... || $\alpha$ || ... || $f_q(a_n)$
|}


$f_k$ is non-discriminating criterion because for all alternatives it evaluates to $\alpha$
* this criteria is meaningless 
* we want to delete it
* but we must be careful: because it may lead to [[Rank Reversal]] for some [[MCDA]] methods
* for [[PROMETHEE]] it will not: we can safely remove such criteria 


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Multi-Criteria Decision Aid]]</text>
      <sha1>bbei61k4vbcwxw04mkh106tegjoqmky</sha1>
    </revision>
  </page>
  <page>
    <title>PROMETHEE</title>
    <ns>0</ns>
    <id>304</id>
    <revision>
      <id>307</id>
      <timestamp>2014-02-09T17:54:30Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13214">== PROMETHEE ==
This is a method from the family of outranking (i.e. based on pair-wise comparison) [[MCDA]] methods.

PROMETHEE stands for &lt;u&gt;P&lt;/u&gt;reference &lt;u&gt;R&lt;/u&gt;anking &lt;u&gt;O&lt;/u&gt;rganization &lt;u&gt;METH&lt;/u&gt;od for &lt;u&gt;E&lt;/u&gt;nrichment &lt;u&gt;E&lt;/u&gt;valuation

Notation:
* $A = \{a_1, ..., a_n\}$ - set of alternatives 
* $F = \{f_1, ..., f_q\}$ - set of criteria (assume we maximize everything)

Note that since we perform pair-wise comparisons, it may become computationally very expensive 


There are four steps:
# Compute Uni-Criterion Preferences 
# Compute Preference Matrix
# Compute Net-Flow Scores
# Rankings
#* Complete: PROMETHEE II
#* Partial: PROMETHEE I


Parameters for a problem (a decision maker needs to specify them)
* the type of preference function $P_k$ used for each criterion $f_k$
* weight $w_k$ for each criterion $f_k$


== Uni-Criterion Preferences ==
we calculate the differences in all criteria for all pairs of alternatives:
* $\forall a_i, a_j \in A: d_k(a_i, a_j) = f_k(a_i) - f_k(a_j)$
* since we assume that we maximize everything, the bigger the difference, the better the first alternative is

The resulting value should be normalized:
* we apply a (pre-defined for each criteria $f_k$) preference function $P_k$ to each difference
* $\pi_k = P_k \big[ d_k(a_i, a_j) \big]$
* this transforms the difference into the preference degree 

=== Preference Functions ===
There are 6 preference functions: 

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/promethee-pref-functions.png

Basic Shapes
* (a) usual preference function 
** as soon as see any difference, the preference is 1 
** no need to specify any parameters 
** this function is very sensitive 
* (b) $u$-shape function
** difference needs to exceed a certain threshold $q$
** (a) and (b) are typically used for qualitative scales 
* (c) $v$-shape 
** with strong preference threshold $p$
* (d) level 
* (e) linear
** same as (c) but with sensitivity threshold $q$ 
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/promethee-linear-pref.png
* (f) $v$-shape 

Choosing a shape is already a decision



== Preference Matrix ==
At this step we compute global preference degrees
* that is, for each pair $a_i, a_j$ compute:
* $\pi(a_i, a_j) = \sum_{k=1}^q w_k \cdot \pi_k (a_i, a_j)$
* global preference degree is a [[Weighted Sum Model|weighted sum]] of uni-criteria preferences


Consequences:
* $\pi(a_i, a_i) = 0$
** the preference of element $a$ with itself is always 0
** $\pi(a_i, a_i) = \sum_{k=1}^q w_k \cdot \pi_k (a_i, a_i) = \sum_{k=1}^q w_k \cdot P_k \big[ \underbrace{d_k(a_i, a_i)}_{= \ 0} \big] = 0$
* $\pi(a_i, a_j) \geqslant 0$
** the preference degree is always positive
** $\pi(a_i, a_j)$ is a weighed sum of $\pi_k$ which are always positive
** this is because the preference functions always return positive values
* $\pi(a_i, a_j) + \pi(a_j, a_i) \leqslant 1$
** '''todo'''



== Net Flow Scores ==
For each $a_i, a_j \in A$ we compute net flow scores
* $\Phi^+(a_i) = \cfrac{1}{n-1} \sum_{a_j \in A} \pi(a_i, a_j)$ 
** ''positive outranking net flow'' 
** &quot;strengths&quot; of an alternative, how an alternative outranks others 
** want to maximize it
* $\Phi^-(a_i) = \cfrac{1}{n-1} \sum_{a_j \in A} \pi(a_j, a_a)$
** ''negatives outranking net flow'' 
** &quot;weaknesses&quot; of an alternative, how an alternative is outranked by others
** want to minimize it

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/promethee-netflowscore.png

The values are normalized:
* $\Phi^+(a_i) \in [0, 1]$ and 
* $\Phi^-(a_i) \in [0, 1]$

The flow score is computed as difference between the positive flow and negative flow
* $\Phi(a_i) = \Phi^+(a_i) - \Phi^-(a_i) \in [-1, 1]$ and 

''Uni-criteria flow''
* flow computed with respect to only one criteria $f_k$
* $\Phi_k(a) = \cfrac{1}{n-1} \sum_{b \in A} [ P_k(a, b) - P_k(b, a) ]$




== Ranking ==
=== PROMETHEE I ===
[[Partial Order]] Ranking:
* ranking based only on $\Phi^+(a_i)$ and $\Phi^-(a_i)$ (not on the aggregated flow score)
* let $P^+$ denote the preference of $\Phi^+$
** $a_i \ P^+ \ a_j \iff \Phi^+(a_i) &gt; \Phi^+(a_j)$  (want to maximize $\Phi^+$)
* let $P^-$ denote the preference of $\Phi^-(a_i)$
** $a_i \ P^- \ a_j \iff \Phi^+(a_i) &lt; \Phi^+(a_j)$  (want to maximize $\Phi^-$)
* $a_i \ P \ a_j \iff a_i \ P^+ \ a_j \land a_i \ P^- \ a_j$
** i.e. $a_i$ is preferred to $a_j$ only in case of [[Unanimity]] between $\Phi^+$ and $\Phi^-$
* if there is no unanimity, $a \ J \ b$
** $a$ is not comparable to $b$
** in this case it's up to the decision maker to decide what to do with these alternatives


=== PROMETHEE II ===
This gives a completely ordered preference structure
* i.e. there's no $J$ relation


Define:
* preference as $a_i \ P \ a_j \iff \Phi(a_i) &gt; \Phi(a_j)$
* indifference as $a_i \ I \ a_j \iff \Phi(a_i) = \Phi(a_j)$

These relations are transitive and complete



== Properties ==
=== Justification ===
; The PROMETHEE property:
* the netflow score $\Phi(a_i)$ is a centered score $s_i$ ($\forall i$) that minimizes the following $Q$:
* $Q = \sum_{i=1}^n \sum_{j=1}^n \big[ (s_i - s_j) - (\pi_{ij} - \pi_{ji}) \big]^2 $
* i.e. $Q$ is the sum of squared deviation and we want to minimize it
* proof: [[PROMETHEE/Properties#The PROMETHEE Property]]


=== Property 1 ===
; $\Phi(a_i) \in [-1, 1]$
Easy to see that by the way we construct $\Phi(a_i)$


=== Property 2 ===
Want to show that  $\sum_{i = 1}^N \Phi(a_i) = 0$
* $N$ - the number of alternatives
* that can be shown by induction
* proof: [[PROMETHEE/Properties#Property 2]]


=== [[Preferential Independence]] ===
PROMETHEE respects the [[Preferential Independence]] hypothesis
* [[PROMETHEE/Properties#Preferential Independence]]


== [[Arrow's Impossibility Theorem]] ==
Recall that according to the theorem all 5 conditions cannot be satisfied at the same time. 
* [[Independence to Third Alternatives]], due to pair-wise comparisons is not respected (shown below in [[PROMETHEE/Rank Reversal]])
* but it satisfies all the rest
* The [[Monotonicity]] property is satisfied [[PROMETHEE/Properties#Monotonicity]]


=== [[Rank Reversal]] ===
A rank reversal happens if:
* $\pi_{ij} \geqslant \pi_{ji}$ but in spite of that $\Phi(a_i) \leqslant \Phi(a_j)$
* the main article: [[PROMETHEE/Rank Reversal]]



== GAIA ==
PROMETHEE gives you scores and you can compute complete and partial rankings
* GAIA is a tool for visualizing, complimentary to PROMETHEE 
* GAIA = Geometrical Analysis for Interactive Assistance

We can represent each alternative as a vector:
* we can represent an alternative as a vector of $q$ components:
** $[f_1(a_i), ..., f_q(a_i)]$
** but in this space we have different scales - and things are not easy to compare
* we can use the netflow score, which is a value in $[-1, 1]$
** $\Phi(a_i) = \sum_{k=1}^{q} w_k \cdot \phi_k(a_i)$
** where $\Phi_k(a_i) = \cfrac{1}{n-1} \sum_{a_j \ne a_i} \big[ \pi_k(a_i, a_j) - \pi_k(a_j, a_i) \big] $
* so we can represent every alternative $a_i$ as a vector $[\Phi_1(a_i), ..., \Phi_k(a_i)]$ in $q$ dimensional space.


But $q$ dimensional space is really hard to visualize 
* GAIA does that
* it applies [[Principal Component Analysis]] for projecting $q$-dim space to 2-dim space

$\delta$ 
* some information is lost during the projection, and the $\delta$ coefficient shows how much information is retained on the plane
* $\delta$ is the ratio between the projected variance and the initial variance 
* $\delta \geqslant 70\%$ is good


=== Example ===
Consider a &quot;Buying a new car&quot; example (from D-Sight [http://www.d-sight.com/learning-center/articles/buying-new-car])

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/gaia-new-car.png 
* points are alternatives
* lines with points at the end are criteria 
* the red stick is a ''decision stick'' - the projection of weights to the plain 


Based on a GAIA plane can make some observations:
* there are conflicting criteria: ones that point in the opposite directions 
* there are also criteria that are in synergy: they point in the same direction
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/gaia-new-car2.png
* some criteria are close to each other in 2-dim space - they also must be close in the $q$-dim space, so they should have similar profiles
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/gaia-new-car3.png
* it is also interesting to see the position of alternatives with respect to criteria: to project each as see which one is the best, worst, etc
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/gaia-new-car4.png
* and finally, the projection on the decision stick vector shows what are the best alternatives
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/gaia-new-car5.png



== Example: Plant Location Problem ==
=== Evaluation Table ===
First we establish the following evaluation table:

{| class=&quot;wikitable&quot;
! || # engineers || power || cost || maintenance || village || security 
|- 
! Italy 
| 75 || 90 || 600 || 5.4 || &lt;font color=&quot;blue&quot;&gt;8&lt;/font&gt; || 5
|- 
! Belgium 
| 65 || &lt;font color=&quot;red&quot;&gt;58&lt;/font&gt; || &lt;font color=&quot;blue&quot;&gt;200&lt;/font&gt; || &lt;font color=&quot;red&quot;&gt;9.7&lt;/font&gt; || &lt;font color=&quot;red&quot;&gt;1&lt;/font&gt; || &lt;font color=&quot;red&quot;&gt;1&lt;/font&gt;
|- 
! Germany 
| 83 || 60 || 400 || 7.2 || 4 || 7 
|- 
! Sweden 
| &lt;font color=&quot;blue&quot;&gt;40&lt;/font&gt; || 80 || &lt;font color=&quot;red&quot;&gt;1000&lt;/font&gt; || 7.5 || 7 || &lt;font color=&quot;blue&quot;&gt;10&lt;/font&gt;
|- 
! Austria 
| 52 || 72 || 600 || &lt;font color=&quot;blue&quot;&gt;2&lt;/font&gt; || 3 || 8
|- 
! France 
| &lt;font color=&quot;red&quot;&gt;94&lt;/font&gt; || &lt;font color=&quot;blue&quot;&gt;96&lt;/font&gt; || 700 | 3.6 || 5 || 6
|- 
!  
| min || max || min || min || max || max
|}

* &lt;font color=&quot;red&quot;&gt;red&lt;/font&gt; color - worst value in column
* &lt;font color=&quot;blue&quot;&gt;blue&lt;/font&gt; color - best value in column

=== Pair-wise Comparison ===
* start with 2 alternatives and consider only 1 criteria at a time
* for example, $G$ermany and $A$ustria:
* cost is better in $G$: 400 vs 600
** what does it mean? 
** need to normalize this difference to [0, 1] scale - to be able to qualify the difference

{|  class=&quot;wikitable&quot;
|-
! Unic. pref 
|  ||  || 0.25  ||  ||  ||  
|-
|  ||  ||  || -200  ||  ||  ||  
|-
! Germany 
| 83 || 60  || 400 || 7.2  || 4  || 7
|-
! || Engineers || Power || Cost || Maint. || Village || Security   
|-
! Austria  
| 52 || 72 || 600 || 2 || 3 || 8  
|-
|  || -31 || 12 ||  || -5.2 || -1 || 1 
|-
! Unic. pref 
| 1 || 0.75 ||  || 1 || 0.3  ||  0.63
|}


=== Global Preference Degree ===
Next step: compute global preference degree for all pairs of alternatives
* assuming a decision maker provides the weights
* eng: 0.1, pow: 0.2, cost: 0.2, maint: 0.1, village: 0.15, security: 0.15 (sum = 1)
* $\pi(A, G) = 1 \cdot 0.1 + 0.75 \cdot 02 + 1 \cdot 0.1 + 0.3 \cdot 0.15 + 0.63 \cdot 0.15 = 0.498$
* $\pi(G, A) = 0.25 \cdot 0.4 = 0.05$
* the closest the $\Pi$ value to 1, the move preferred one alternative to another is

We do this for all pairs and build a preference matrix 

{|  class=&quot;wikitable&quot;
! || Italy || Belgium || Germany || Sweden || Austria || France 
|-
! Italy 
| 0 || 0.28 || 0.23 || 0.24 || 0.09 || 0.22
|-
! Belgium
| 0.27 || 0 || 0.4 || 0.3 || 0.27 || 0.5
|-
! Germany
| 0.22 || 0.19 || 0 || 0.3 || 0.05 || 0.43
|-
! Sweden
| 0.43 || 0.55 || 0.33 || 0 || 0.25 || 0.25
|-
! Austria
| 0.46 || 0.55 || 0.49 || 0.34 || 0 || 0.46
|-
! France
| 0.23 || 0.4 || 0.26 || 0.39 || 0.12 || 0
|}


=== Net Flow Scores ===
Next we compute the positive and negative net flow scores:

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/promethee-plant-loc.png
* positive flow: strengths, has to be maximized
* negative flow: weaknesses, has to be minimized


Then we calculate if on average $G$ is better than the rest:
* $\Phi^+(G) = 0.238$ (avg of all $\Pi(G, X)$)
* $\Phi^-(G) = 0.334$ (avg of all $\Pi(X, G)$)
* the total score: $\Phi(G) = \Phi^+(G) - \Phi^-(G) = -0.1 \in [-1, 1]$


=== PROMETHEE II ranking ===
: ranking the alternatives based on their netflow scores

{|  class=&quot;wikitable&quot;
! rank || alternative || $\Phi(G)$ || $\Phi^+(G)$ || $\Phi^-(G)$
|-
| 1 || Austria || 0.302 || 0.458 || 0.156
|-
| 2 || Sweden || 0.049 || 0.363 || 0.314
|-
| 3 || Belgium || -0.041 || 0.347 || 0.397
|-
| 4 || Germany || -0.096 || 0.238 || 0.334
|-
| 5 || France || -0.099 || 0.274 || 0.373
|-
| 6 || Italy || -0.115 || 2.11 || 0.326
|}


https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/promethee-plant-loc-barplot.png

Note that this is a complete ranking:
* you can always say which alternative is better


=== PROMETHEE I ranking ===
{|   class=&quot;wikitable&quot;
! || $\Phi^+$ || $\Phi^-$
|-
! $a$ 
| 0.8 || 0.1
|-
! $b$ 
| 0.5 || 0.05
|-
! $c$ 
| 0.1 || 0.8
|}

for both $\Phi^+$ and $\Phi^-$ (applying the [[Unanimity]] principle)
* $a \ P \ c$
* $b \ P \ c$

Cannot say anything about $a$ and $c$
* for $\Phi^+$: $a \ P \ b$
* for $\Phi^-$: $b \ P \ a$

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/promethee-2-ex.png



== Sources ==
* [[Decision Engineering (ULB)]]
* An Introduction to Multicriteria Decision Aid: The PROMETHEE and GAIA Methods, Yves De Smet, Karim Lidouh, 2013

[[Category:Multi-Criteria Decision Aid]]</text>
      <sha1>p4kj5ucd0ua9h1i2rlbd80h96t49ev3</sha1>
    </revision>
  </page>
  <page>
    <title>Template:Draft</title>
    <ns>10</ns>
    <id>305</id>
    <revision>
      <id>308</id>
      <timestamp>2014-01-16T07:05:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="314">&lt;table class=&quot;metadata plainlinks stub&quot; style=&quot;background: transparent;margin: 0.5em auto;border: 1px solid #AAAAAA;&quot; &gt;
&lt;tr&gt;
  &lt;td&gt;[[File:Ambox_warning_blue_construction.svg|50px]]&lt;/td&gt;
  &lt;td&gt;This page is currently a draft. [{{fullurl:{{FULLPAGENAME}}|action=edit}} Edit it].&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
[[Category:Draft]]</text>
      <sha1>bkcga7slcglzr838fawtgvweg7e5lf4</sha1>
    </revision>
    <revision>
      <id>718</id>
      <parentid>308</parentid>
      <timestamp>2015-11-23T16:01:30Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="344">&lt;table class=&quot;metadata plainlinks stub&quot; style=&quot;background: transparent;margin: 0.5em auto;border: 1px solid #AAAAAA;&quot; &gt;
&lt;tr&gt;
  &lt;td&gt;https://habrastorage.org/files/9e3/3b1/908/9e33b1908f234cebb45c62d128008da2.png&lt;/td&gt;
  &lt;td&gt;This page is currently a draft. [{{fullurl:{{FULLPAGENAME}}|action=edit}} Edit it].&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
[[Category:Draft]]</text>
      <sha1>axv6eqlq6sac5l1upteqd08gro5wtf2</sha1>
    </revision>
  </page>
  <page>
    <title>Median Voter Theorem</title>
    <ns>0</ns>
    <id>306</id>
    <revision>
      <id>309</id>
      <timestamp>2015-07-05T16:04:15Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5424">== Allocation Problem ==
This is a problem of choosing the best position 
* to open a new shop
* etc

In [[Game Theory]] this problem is known as the ''Median Voter Theorem''.


== The Median Voter Theorem ==
=== 2 Candidates ===
Suppose we have two candidates $s_1$ and $s_2$
* each candidate thinks &quot;what is the best political position to take so the majority vote for me?&quot;
* so suppose the candidates put themselves somewhere between 0 and 1 (extreme left vs extreme right)
*: https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/gt/median-voter-1.png
* assumptions:
** voters are distributed uniformly 
** voters vote for the candidate that is closest to their opinion
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/gt/median-voter-2.png


Utilities 
* with this assumption we use the following utility functions:
** $u_1(s_1, s_2) = \cfrac{s_1 + s_2}{2}$
** $u_2(s_1, s_2) = 1 -  u_1(s_1, s_2) = 1 - \cfrac{s_1 + s_2}{2}$ - complimentary part of $u_1$


So there can be the following scenarios 
* $s_1 &lt; s_2$
* both take the same position 

Case 1: $s_1 &lt; s_2$
* not a [[Nash Equilibrium]]
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/gt/median-voter-3.png
* both players want to move: $p_1$ wants to move right and $p_2$ wants to move left
* so there exists another better strategy:
** $u_1(s_1 + \epsilon, s_2) &gt; u_1(s_1, s_2)$
** $p_1$ just moves a little bit to the right and this way gets more votes


Case 2: $s_1 = s_2 &lt; 0.5$
* this is not a Nash Equilibrium either
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/gt/median-voter-4.png
* since $s_1 = s_2$ they have the same utilities (the voters choose at random from whom to vote)
** $u_1(s_1, s_2) = u_2(s_1, s_2)$
* but this time again there's an incentive to deviate:
** $u_1(s_1 + \epsilon, s_2) &gt; u_1(s_1, s_2)$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/gt/median-voter-5.png


Case 3: $s_1 = s_2 = 0.5$
* this is a Nash Equilibrium!
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/gt/median-voter-6-ne.png
* no one has an incentive to deviate:
** if somebody moves, he gets lower payoff
** $u_1(s_1, s_2) &gt; u_1(s_1 - \epsilon, s_2)$


=== 3 Candidates ===
But there is no Nash Equilibria for three candidates 

Consider this
* there are 3 candidates $\{a, b, c\}$ who position themselves at the scale [0, 1]
* the positions of the candidates are $s_a, s_b, s_c$
* voters vote to the closest candidate to them
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/gt/median-voter3-1.png

We suppose (without loss of generality) that 
* $s_a \leqslant s_b \leqslant s_c$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/gt/median-voter3-2.png
* let $u_a, u_b, u_c$ be the utility functions of $a, b, c$ respectively

Utility functions

{| class=&quot;wikitable&quot;
| $s_a &lt; s_b &lt; s_c$
| https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/gt/median-voter3-cases-1-alldif.png
| $\left\{\begin{matrix}
u^{(1)}_a(s_a, s_b, s_c) = \cfrac{s_a + s_b}{2} \\ 
u^{(1)}_b(s_a, s_b, s_c) = 1 - \cfrac{s_b + s_c}{2} \\
u^{(1)}_c(s_a, s_b, s_c) = \cfrac{s_b + s_c}{2} - \cfrac{s_a + s_b}{2} \\ 
\end{matrix}\right.$
| $a$ may deviate: $u_a(s_a + \epsilon, s_b, s_c) &gt; u_a(s_a, s_b, s_c)$ 
|-
| $s_a &lt; s_b = s_c$
| https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/gt/median-voter3-cases-2-beqc.png
| $\left\{\begin{matrix}
u^{(2)}_a(s_a, s_b, s_c) = \cfrac{s_a + s_b}{2} \\ 
u^{(2)}_b(s_a, s_b, s_c) = \cfrac{1 - \cfrac{s_a + s_b}{2}}{2} \\
u^{(2)}_c(s_a, s_b, s_c) = u^{(2)}_b(s_a, s_b, s_c) \\ 
\end{matrix}\right.$
| $a$ may deviate: $u_a(s_a + \epsilon, s_b, s_c) &gt; u_a(s_a, s_b, s_c)$ 
|-
| $s_a = s_b &lt; s_c$
| https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/gt/median-voter3-cases-3-aeqb.png
| $\left\{\begin{matrix}
u^{(3)}_a(s_a, s_b, s_c) = \cfrac{s_b + s_c}{2 \cdot 2} \\ 
u^{(3)}_b(s_a, s_b, s_c) = u^{(3)}_a(s_a, s_b, s_c) \\
u^{(3)}_c(s_a, s_b, s_c) = 1 - \cfrac{s_b + s_c}{2} \\ 
\end{matrix}\right.$
| $c$ may deviate: $u_c(s_a, s_b, s_c - \epsilon) &gt; u_c(s_a, s_b, s_c)$ 
|-
| $s_a = s_b = s_c \ne 0.5$
| https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/gt/median-voter3-cases-5-shared-2.png
| $\left\{\begin{matrix}
u^{(4)}_a(s_a, s_b, s_c) = \cfrac{1}{3} \\ 
u^{(4)}_b(s_a, s_b, s_c) = \cfrac{1}{3} \\
u^{(4)}_c(s_a, s_b, s_c) = \cfrac{1}{3} \\ 
\end{matrix}\right.$
| $a$ may deviate: $u_a(s_a + \epsilon, s_b, s_c) &gt; u_a(s_a, s_b, s_c)$ 
|-
| $s_a = s_b = s_c = 0.5$
| https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/gt/median-voter3-cases-4-shared-1.png
| $\left\{\begin{matrix}
u^{(4)}_a(s_a, s_b, s_c) = \cfrac{1}{3} \\ 
u^{(4)}_b(s_a, s_b, s_c) = \cfrac{1}{3} \\
u^{(4)}_c(s_a, s_b, s_c) = \cfrac{1}{3} \\ 
\end{matrix}\right.$
| $a$ may deviate: $u_a(s_a + \epsilon, s_b, s_c) &gt; u_a(s_a, s_b, s_c)$ 
|}

So in all cases there is somebody who wants to deviate:
* No Nash Equilibria 


== Applications ==
This is the allocation problem: 
* suppose we want to find a location for a new store 
* clients that are closer will go to this store 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/gt/allocation-problem.png
* so they put it in the center 
* this is the reason why sometimes big grocery stores are located close to each other 


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Game Theory]]</text>
      <sha1>a8bjqc6pi9c41haxoafmixnp4w4p06h</sha1>
    </revision>
  </page>
  <page>
    <title>Allocation Problem</title>
    <ns>0</ns>
    <id>307</id>
    <redirect title="Median Voter Theorem" />
    <revision>
      <id>310</id>
      <timestamp>2014-01-16T07:03:16Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="34">#redirect [[Median Voter Theorem]]</text>
      <sha1>a6cj4d8sypeszoh60ksj5ewwp33dwmo</sha1>
    </revision>
  </page>
  <page>
    <title>Normal Form Game</title>
    <ns>0</ns>
    <id>308</id>
    <revision>
      <id>311</id>
      <timestamp>2014-01-16T07:35:48Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2725">== Normal Form Game ==
A ''Normal Form Game'' (also ''Matrix Form Game'' or ''Strategic Game'') if a type of games from the [[Game Theory]]
* main idea: the players move simultaneously
* compare to [[Extensive Form Game]]s where players move sequentially 


In these games:
* There is a finite number $n$ of [[Rational Behavior|rational]] players: $N = \{ 1, 2, ..., n \}$
* Each player $i$ has a finite set of actions $A_i$
* Also each player $i$ has a set of possible consequences $C$, in this case it's $C \equiv \mathbb{R}$
* The chosen alternatives form an ''action profile'' (or ''strategy profile'') $A: A_1 \times ... \times A_n$
* There's a consequence function $g_i: A \mapsto C$ that associates each alternative $a \in A_i$ with some consequence 
* The preferences of agents are modeled with an utility function $u_i: A \mapsto \mathbb{R}$


'''def:''' So a ''normal form game'' (or a ''strategic game'') is
* a tuple $\langle N, A, u \rangle$ where
* $N = \{ 1, 2, ..., n \}$ - set of all players 
* $A = \{A_1, ..., A_n\}$ - set of each players' actions 
* $u = \{u_1, ..., u_n\}$ - set of utility functions that expresses preferences

Utility Function (of payoff function) $u_i$
* $u_i: A_i \mapsto \mathbb{R}$
* each agent has a preference relation $S_i$ 
* agents are rational: therefore $\forall a,b \in A_i: u_i(a) \geqslant u_i(b) \Rightarrow a \ S_i \ b$
* in other words, if alternative $a$ gives a better payoff than $b$, $i$ will always prefer $a$ over $b$



=== Representation ===
These games are typically represented with a pay-off matrix
* columns/rows represent actions that players can take 
* each cell shows the outcome of game: it lists utilities that all players will receive 

For example, 
* consider this 2-player game, with two players $p_1$ and $p_2$
* each has two strategies: $A_1 = \{a, b\}, A_2 = \{x, y\}$
* the payoffs are shown in the cells of the matrix
{| class=&quot;wikitable&quot;
! $p_2 \to$ &lt;br&gt; $p_1 \downarrow$ || $x$ || $y$
|-
! $a$ 
| $[u_1(a,x), u_2(a,x)]$ || $[u_1(a,y), u_2(a,y)]$ 
|-
! $b$ 
| $[u_1(b,x), u_2(b,x)]$ || $[u_1(a,y), u_2(a,y)]$
|}

Another example
* 2 players, 3 strategies 
{|  class=&quot;wikitable&quot;
! $p_2 \to$ &lt;br&gt; $p_1 \downarrow$  || $L$ || $C$ || $R$ 
|- 
! $T$ 
| (1,0) || (1,3) || (3,0)
|- 
! $M$ 
| (0,2) || (0,1) || (3,0)
|- 
! $B$ 
| (0,2) || (2,4) || (5,3)
|}

* This game can be solved by [[Iterative Removal]]
* At the end the profile $(C, B)$ will be chosen


== Types ==
There are several types of normal form games:
* [[Pure Competition Game]]s
** [[Matching Pennies]]
* [[Cooperation Game]]s
** [[Coordination Game]]
** [[Battle of the Sexes]]

== Sources ==
* [[Game Theory (coursera)]]
* [[Decision Engineering (ULB)]]

[[Category:Game Theory]]</text>
      <sha1>l6nfvjh0n11c9x2nfw5frxkuh1667tt</sha1>
    </revision>
  </page>
  <page>
    <title>Extensive Form Game</title>
    <ns>0</ns>
    <id>309</id>
    <revision>
      <id>312</id>
      <timestamp>2015-07-05T16:33:39Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6345">{{draft}}

== Extensive Form Games ==
[[Normal Form Game]]s do not reflect time: 
* other players - your opponents - know that you will do, and all actions happen simultaneously


== Perfect-Information Game ==
&lt;math&gt;A&lt;/math&gt; - is a (finite) perfect-information game in extensive form

&lt;math&gt;A&lt;/math&gt; is defined by &lt;math&gt;(N, A, H, Z, \chi, \rho, \sigma, u)&lt;/math&gt;
* &lt;math&gt;N&lt;/math&gt; - a set of players
* &lt;math&gt;A&lt;/math&gt; - a set of actions
* &lt;math&gt;H&lt;/math&gt; - a set of non-terminal choice nodes
* &lt;math&gt;\chi&lt;/math&gt; - set of actions available for player in &lt;math&gt;h \in H&lt;/math&gt;
* &lt;math&gt;\rho&lt;/math&gt; - assigns to each &lt;math&gt;h \in H&lt;/math&gt; a player &lt;math&gt;i \in N&lt;/math&gt; who chooses an action &lt;math&gt;a&lt;/math&gt; in this &lt;math&gt;h&lt;/math&gt;
* &lt;math&gt;Z&lt;/math&gt; - terminal nodes, where a game ends
* &lt;math&gt;\sigma&lt;/math&gt; - defines a tree (how to get from node h \in H to next note \h_i \in H
* &lt;math&gt;u&lt;/math&gt; - utility function, defined &lt;math&gt;\forall z \in Z&lt;/math&gt;



=== The Sharing Game ===
* a brother and a sister decide how they want to share 2 dollars
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/gt/sharing-game.png
* $p_1$ is the brother, $p_2$ is the sister
* brother may suggest 2 dollars, 1 dollar and 0 dollars
* sister accepts or rejects
* if she accepts, she gets it, the brother gets the rest
* if she rejects, both get 0

Strategies
* the brother has 3 strategies
* the sister 8 - she may choose $2 \times 2 \times 2$ ways to behave


=== Strategies ===
A set of strategies consists of the cross product of all possible actions for all nodes
* these strategies are called the ''pure strategies''

Example
* &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/1ek4jlfnq051brasho90rph19h.png&quot; /&gt;
* for player 2 pure strategies are $(C, D) \times (E, F)$
* for player 1: $(A, B) \times (G, H)$
* each has 4 strategy

Mixed strategy
* same as for [[Normal Form Game]]
* but we define the probability distribution over the pure strategies

[[Nash Equilibrium]]
* in this case the best response notion is the same as for [[Normal Form Game]]s
* we want to maximize the [[Expected Utility]]
* so the Best Response is a mixed strategy that maximized the utility
* a strategy profile where each agent best-responds to every other agent is called a [[Nash Equilibrium]]


Translation to [[Normal Form Game]]
* Extensive form game can be converted into a Normal Form Game
* &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/39pgmt7kdnb8h42m0lgiu4vtvn.png&quot; /&gt;
* pure strategies for each agent:
* &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/2k9n1e39c3vu9f8pcci9arofpj.png&quot; /&gt;
* the result is called Induced Normal Form Game
** Although, this form is not compact
** and we can't always perform the reverse transformation


=== Subgame Perfection ===
* subgame of &lt;math&gt;G&lt;/math&gt; rooted at &lt;math&gt;H&lt;/math&gt;
** restriction of &lt;math&gt;G&lt;/math&gt; to the descendents of &lt;math&gt;H&lt;/math&gt;
** i.e. subtree
* subgames of &lt;math&gt;G&lt;/math&gt;
** all possible subgames of &lt;math&gt;G&lt;/math&gt;
** plus &lt;math&gt;G&lt;/math&gt; itself
* subgame perfect equilibrium
** definition
*** s is a subgame perfect equilibrium
*** if for any subgame &lt;math&gt;G'&lt;/math&gt; of &lt;math&gt;G&lt;/math&gt;
*** the restriction of &lt;math&gt;s&lt;/math&gt; to &lt;math&gt;G'&lt;/math&gt; is a NE of &lt;math&gt;G'&lt;/math&gt;
** rules out all non-credible threats
*** i.e. when player &lt;math&gt;i&lt;/math&gt; will never go down that edge
*** but is anyway threatened that if goes, &lt;math&gt;j&lt;/math&gt; will pick up bad route
** example
*** &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/7svpoqecaqa4qh8mhajuucdjkp.png&quot; /&gt;
*** (A, G), (F, G) is subgame perfect


=== Backward Induction ===
* a way of computing a subgame perfect equilibrium
* idea: find it in the bottom-most tree, and go up the tree
* function BackwardIndution
** if h \in Z
*** return u(z)
** best_util = -\inf
** foreach a \in \chi
*** util_at_child = BackwardInduction(\sigma (h, a))
*** if (util_at_child &gt; best_util)
**** best_util = util_at_chile
** return best_util
* so it propagates best utility up top


=== Example: Centipede Game ===
* &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/087nlskqe9e4cq3ov898pivqj0.png&quot; /&gt;
* start from the end:
* $p_1$ would go $D$ rather then $A$ (4 vs 3)
* $p_2$ would go $D$ (4 vs 3)
* $p_1$ would go $D$ (3 vs 2)
* $p_2$ would go $D$ (2 vs 1)
* $p_1$ would go $D$ (1 vs 0)
* so although going would be better, both prefer $D$


=== Example: Ultimatum Bargaining ===
* 10 units to be split between 2 players
* p1 offers &lt;math&gt;x \in {0, 1, ... 10}&lt;/math&gt; to pl2
* p2 accepts or rejects
* p1 gets 10-x, p2 gets x if pl1 accepts
* otherwise both get 0
* tree (pic)
** &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/4vibbavmd07prrup1j3ccgcm2e.png&quot; /&gt;
** so, p1 should offer &lt;math&gt;x &gt; 0&lt;/math&gt;, as p2 will accept any possible amount
** in fact
*** player may not act this way
*** p2 may expect payoff at least 5
*** subgame perfection doesn't always match the data


== Imperfect-Information ==
* poker
** moves are sequential
** but there is some uncertainty about moves
** hidden information!
* you sometimes don't see what others are doing, but it affects your payoff
* so we create equivalent classes for some choices
** 2 choices are in &lt;math&gt;I_1&lt;/math&gt;, two in &lt;math&gt;I_2&lt;/math&gt;, last three in &lt;math&gt;I_3&lt;/math&gt; &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/0jdsq2c5tfruo36bask4hagorr.png&quot; /&gt;
** for items in those classes set of possible actions is the same
** however payoffs may be different


; definition
* &lt;math&gt;A&lt;/math&gt; is defined by &lt;math&gt;(N, A, H, Z, \chi, \rho, \sigma, u, I)&lt;/math&gt;
* where &lt;math&gt;I = {I_1, ... I_n}&lt;/math&gt; - set of equivalent classes


* pure strategies
** product of all possible action of different equality classes
* example
** &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/6skvsiu0fg86o6ebin2p8apnji.png&quot; /&gt;
** $p_1$ has 4 pure strategies: $Ll, Rr, Lr, Rr$
* any normal form game can be represented this way
** Prisoners' Dilemma &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/3ddd4rn3pfhl7ttpg26htcu6en.png&quot; /&gt;


== Sources ==
* [[Game Theory (coursera)]]

[[Category:Game Theory]]</text>
      <sha1>gxfiq122vrs465yyafybfvgs83nts19</sha1>
    </revision>
  </page>
  <page>
    <title>Iterative Removal</title>
    <ns>0</ns>
    <id>310</id>
    <revision>
      <id>313</id>
      <timestamp>2014-01-16T07:28:18Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6231">== Iterative Removal ==
This is an application of the [[Dominance]] principle in the [[Game Theory]].

A game is called ''dominance solvable'' if it can be solved with Iterative Removal 


Iterated elimination or Iterative removal algorithm:
* for a game $G$ with set of strategies $A$  
* find a dominated strategy $a$ 
* let $A \leftarrow A - \{ a \}$ i.e. remove this strategy from the game
* repeat till there are no dominated strategies


== Properties ==
Note:
* removal of strictly dominated strategies is always good
* it preserves the [[Nash Equilibrium]] of the game
* however for weekly dominated strategies you should be more careful
* order of removal may matter


=== Property 1 ===
If a matrix game ([[Normal Form Game]]) can be solved by using iterative removal of strictly dominated strategies
* (1) then the found solution is a [[Nash Equilibrium]]
* (2) this equilibrium is unique

Recall that a profile $(s^*_1, s^*_2)$ is a Nash Equilibrium if 
* $u_1(s^*_1, s^*_2) \geqslant u_1(s_1, s^*_2), \forall s_1 \in S_1$
* $u_2(s^*_1, s^*_2) \geqslant u_2(s^*_1, s_2), \forall s_2 \in S_2$
* (i.e. we just fix one solution and see if somebody wants to deviate)


; Part 1: the found profile is a Nash Equilibrium
* (by contraction)
* suppose $(s^*_1, s^*_2)$ is not a Nash Equilibrium
* i.e. we assume the opposite of the definition (negate it)
** $\exists s_1 \in S_1: u_1(s_1, s^*_2) &gt; u_1(s^*_1, s^*_2)$ and 
** $\exists s_2 \in S_2: u_1(s^*_1, s_2) &gt; u_1(s^*_1, s^*_2)$ 
* since we ended up with $(s^*_1, s^*_2)$, the profile $(s_1, s_2)$ was removed during the iterative removal 
** it happened because either 
** (1) $p_1$ removed $s_1$ (the row was eliminated) or 
** (2) $p_2$ removed $s_2$ (the column was eliminated)
** https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/de/gt/dominance-gives-nash.png
* (1) suppose $p_1$ removed $s_1$
** he removed the whole row along with the profile $(s_1, s^*_2)$
** $\Rightarrow (s_1, s^*_2)$ was dominated by some other strategy profile, say $(s'_1, s^*_2)$
** but since we ended up with $(s^*_1, s^*_2)$ then 
*** either $s'_1 = s^*_1$ or
*** $u(s^*_1, s^*_2) &gt; (s'_1, s^*_2)$ and $(s'_1, s^*_2)$ was also removed 
** but we assumed that $u_1(s_1, s^*_2) &gt; u_1(s^*_1, s^*_2)$ 
** $\Rightarrow$ contradiction
* (2) is shown analogously to (1) 


; Part 2: the equilibrium is unique
* (by contradiction)
* assume it's not unique 
* i.e. there $\exists$ another NE $(\tilde{s}_1, \tilde{s}_2)$ which was removed during the iterative removal 
* again two cases: $(\tilde{s}_1, \tilde{s}_2)$ was removed in (1) a row by $p_1$, (2) in a column by $p_2$
* case 1: it was removed by $p_1$ in a row
** i.e. there was some other alternative that was better:
** $\exists s_1 \in S_1: u_1(s_1, \tilde{s}_2) &gt; u_1(\tilde{s}_1, \tilde{s}_2)$
** but it contradicts the definition of a Nash Equilibrium
* case 2: it was removed by $p_2$ in a column
** $\exists s_2 \in S_2: u_2(\tilde{s}_1, s_2) &gt; u_2(\tilde{s}_1, \tilde{s}_2)$
** this again contradicts the definition 

$\square$

This means we never can remove a NE by iterative removal.


== Examples ==
=== Example 1 ===
Consider this [[Normal Form Game]] with 2 players and with 3 actions each 

{| class=&quot;wikitable&quot;
! $p_2 \to$ &lt;br&gt; $p_1 \downarrow$  || $L$ || $C$ || $R$ 
|- 
! $T$ 
| (1,0) || (1,3) || (3,0)
|- 
! $M$ 
| (0,2) || (0,1) || (3,0)
|- 
! $B$ 
| (0,2) || (2,4) || (5,3)
|}


First we eliminate strategy $R$ for player $p_2$
* it's dominated by $C$

{| class=&quot;wikitable&quot;
! $p_2 \to$ &lt;br&gt; $p_1 \downarrow$  || $L$ || $C$ || $R$ 
|- 
! $T$ 
| (1,0) || (1,3) || &lt;font color=&quot;grey&quot;&gt;(3,0)&lt;/font&gt;
|- 
! $M$ 
| (0,2) || (0,1) || &lt;font color=&quot;grey&quot;&gt;(3,0)&lt;/font&gt;
|- 
! $B$ 
| (0,2) || (2,4) || &lt;font color=&quot;grey&quot;&gt;(5,3)&lt;/font&gt;
|}


Then we can remove $M$ for $p_1$
* it's dominated by $B$ 

{| class=&quot;wikitable&quot;
! $p_2 \to$ &lt;br&gt; $p_1 \downarrow$  || $L$ || $C$ || $R$ 
|- 
! $T$ 
| (1,0) || (1,3) || &lt;font color=&quot;grey&quot;&gt;(3,0)&lt;/font&gt;
|- 
! $M$ 
| &lt;font color=&quot;grey&quot;&gt;(0,2)&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;(0,1)&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;(3,0)&lt;/font&gt;
|- 
! $B$ 
| (0,2) || (2,4) || &lt;font color=&quot;grey&quot;&gt;(5,3)&lt;/font&gt;
|}

Next, remove $L$ - it's dominated by $C$

{| class=&quot;wikitable&quot;
! $p_2 \to$ &lt;br&gt; $p_1 \downarrow$  || $L$ || $C$ || $R$ 
|- 
! $T$ 
| &lt;font color=&quot;grey&quot;&gt;(1,0)&lt;/font&gt; || (1,3) || &lt;font color=&quot;grey&quot;&gt;(3,0)&lt;/font&gt;
|- 
! $M$ 
| &lt;font color=&quot;grey&quot;&gt;(0,2)&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;(0,1)&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;(3,0)&lt;/font&gt;
|- 
! $B$ 
| &lt;font color=&quot;grey&quot;&gt;(0,2)&lt;/font&gt; || (2,4) || &lt;font color=&quot;grey&quot;&gt;(5,3)&lt;/font&gt;
|}

And finally remove $T$

{| class=&quot;wikitable&quot;
! $p_2 \to$ &lt;br&gt; $p_1 \downarrow$  || $L$ || $C$ || $R$ 
|- 
! $T$ 
| &lt;font color=&quot;grey&quot;&gt;(1,0)&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;(1,3)&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;(3,0)&lt;/font&gt;
|- 
! $M$ 
| &lt;font color=&quot;grey&quot;&gt;(0,2)&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;(0,1)&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;(3,0)&lt;/font&gt;
|- 
! $B$ 
| &lt;font color=&quot;grey&quot;&gt;(0,2)&lt;/font&gt; || &lt;font color=&quot;blue&quot;&gt;(2,4)&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;(5,3)&lt;/font&gt;
|}

The action profile $(B, C)$ is the solution



=== Example 2 ===
Consider the following matrix game:

{|  class=&quot;wikitable&quot;
! || $C_1$ || $C_2$ || $C_3$
|- 
! $R_1$ 
| (1, 3) || (2, 4) || (1, 0)
|- 
! $R_2$ 
| (3, 3) || (5, 2) || (0, 1)
|- 
! $R_3$ 
| (2, 5) || (2, 0) || (1, 8)
|}

Remove strategies iteratively:
* $R_3 \ D \ R_2$ (where $D$ is the dominance relation)
* $C_2 \ D \ C_1$ 
* no other elimination can be made

{|  class=&quot;wikitable&quot;
! || $C_1$ || $C_2$ || $C_3$
|- 
! $R_1$ 
| &lt;font color=&quot;grey&quot;&gt;(1, 3)&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;(2, 4)&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;(1, 0)&lt;/font&gt;
|- 
! $R_2$ 
| (3, 3) || &lt;font color=&quot;grey&quot;&gt;(5, 2)&lt;/font&gt; || (0, 1)
|- 
! $R_3$ 
| (2, 5) || &lt;font color=&quot;grey&quot;&gt;(2, 0)&lt;/font&gt; || (1, 8)
|}

So we end with the following matrix: 

{| class=&quot;wikitable&quot;
! || $C_1$ || $C_3$
|-
! $R_2$ 
| (3, 3) || (0, 1)
|-
! $R_3$ 
| (2, 5) || (1, 8)
|}

Now apply the [[Nash Equilibrium]] rule
* $(R_3, C_1)$ - not an equilibrium, both players want to deviate 
* same for $(R_2, C_3)$
* the Nash Equilibria are $(R_2, C_1)$ and $(R_3, C_3)$ - they are stable and no one wants to deviate


== Sources ==
* [[Decision Engineering (ULB)]]
* [[Game Theory (coursera)]]

[[Category:Game Theory]]</text>
      <sha1>dh4ynti2w4p2qbh6ju6lpb84dk7dbri</sha1>
    </revision>
  </page>
  <page>
    <title>Nash Equilibrium</title>
    <ns>0</ns>
    <id>311</id>
    <revision>
      <id>314</id>
      <timestamp>2014-01-16T07:29:37Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3220">== Nash Equilibrium ==
This is an important concept of the [[Game Theory]]
* It assumes that the agents act rationally
* That it, he always wants to maximize the consequences
* and he will never take an action if there exists another action that has better consequences (for him)


=== Example ===
Consider a Beauty Context Game;
* each player says a number form 1 to 100
* the player who says the number that is closest to 2/3 of the average wins the prise
* ties are broken randomly
* Nash Equilibrium in this case is 1

Strategic reasoning:
* what will other players do?
* What should I do in response?
* Each player best responds to the others?

=== Main Ideas ===
* each player wants to maximize their payoff 
* so by the best reasoning, knowing what the others may take, they pick up an action that should be the best 
* The actions taken by all players form an ''action profile''

An action profile is a Nash Equilibrium if
* it is stable: nobody has an incentive to deviate from their action 


== [[Normal Form Game]]s ==
In a Normal Form Game a profile $a^* \in A$ is a Nash Equilibria if
* $ \forall a_i \in A: (a^*_{-i}, a^*_i) \ S_i \ (a^*{-i}, a_i):$
* $S_i$ is a preference relation of a player $i$
* $a_{-i}$ - all components except $i$

This needs to hold for all the players 


== Examples ==
=== [[Prisoner's Dilemma]] ===

{| class=&quot;wikitable&quot;
! || $C$ || $D$
|-
! $C$ 
| (-1, -1) || (0, -4)
|-
! $D$ 
| (-4, 0) || (-3, -3)
|}

Both prisoners choose $D$: 
* the $(D, D)$ is the Nash Equilibrium
* it is stable: nobody wants to deviate 

Consider the profile $(C, C)$
* it's not stable: $p_1$ wants to change his mind and choose $D$
* $p_2$ wants to do the same
* so they wind up in $(D, D)$
* if they never stabilize at some profile - there is no Nash Equilibria


=== [[Matching Pennies]] ===

{|  class=&quot;wikitable&quot;
! || Head || Tail
|- 
! Head 
| (1, -1) || (-1, 1) 
|- 
! Tail 
| (-1, 1) || (1, -1)
|}


In this game there's no [[Nash Equilibrium]]:
* if $p_2$ knows that $p_1$ plays $H$ he will play $H$
* then if $p_1$ knows that $p_2$ plays $H$, he will play $T$
* so there's always an incentive to deviate to other alternative


=== The [[Battle of the Sexes]] ===
In this case there are two equilibrium: $(B, B)$ and $(F, F)$

{|  class=&quot;wikitable&quot;
! wife $\to$ &lt;br&gt; husband $\downarrow$ || $B$ || $F$
|- 
! $B$ 
| &lt;font color=&quot;blue&quot;&gt;(2, 1)&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;(0, 0)&lt;/font&gt;
|- 
! $F$ 
| &lt;font color=&quot;grey&quot;&gt;(0, 0)&lt;/font&gt; || &lt;font color=&quot;blue&quot;&gt;(1, 2)&lt;/font&gt;
|}



== Correlated Equilibria ==
* consider a traffic game
** 2 cars are on crossing
** they can go or yield another car
** P1 rows, P2 cols
*** go
**** -10 -10
**** 1 0
*** wait
**** -1 -1
**** 0 1
** not stable, players may miscoordinate
** we place a traffic light
** so by putting a fair randomizing device that
tells players whether to go or wait
* the same can be applied to Battle of the Sexes
* benefits
** we avoid negative outcomes
** fairness is achieved
** the total sum can exceed the NE
* correlated equilibrium
** a randomized assignment of action recommendation to agents, such as nobody wants to deviate



== Sources ==
* [[Decision Engineering (ULB)]]
* [[Game Theory (coursera)]]

[[Category:Game Theory]]</text>
      <sha1>qge1fb3xknvlt37xxl2aur7gcltyatu</sha1>
    </revision>
  </page>
  <page>
    <title>Pure Competition Game</title>
    <ns>0</ns>
    <id>312</id>
    <revision>
      <id>315</id>
      <timestamp>2014-01-17T11:58:14Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1567">== Pure Competition Game ==
This is a type of game is the [[Game Theory]] where players have exactly opposite interests 
* In such games there should be precisely two players (otherwise they couldn't have the opposite interests)

So a pure competition game is where
* $a \in A, u_1(a) + u_2(a) = c$
* means that if somebody wins, another player loses exactly the amount the first player wins
* this is also called  constant sum game
* if $c$ = 0, a game is called a ''zero sum game'' 


== Zero Sum Games ==
=== Matching Pennies ===
This is a zero-sum game

Rules:
* $p_1$ wants to match, $p_2$ - to mismatch
* each player tosses a coin and record what they have: heads or tails
* if both have the same, $p_1$ wins, $p_2$ looses
* if both have different, $p_1$ looses, $p_2$ wins

Payoff matrix:

{| class=&quot;wikitable&quot;
! || Head || Tail
|- 
! Head 
| (1, -1) || (-1, 1) 
|- 
! Tail 
| (-1, 1) || (1, -1)
|}


In this game there's no [[Nash Equilibrium]]:
* if $p_2$ knows that $p_1$ plays $H$ he will play $H$
* then if $p_1$ knows that $p_2$ plays $H$, he will play $T$
* so there's always an incentive to deviate to other alternative



=== Rock Paper Scissors ===
Is a generalization of Matching Pennies to 3 alternatives

{|  class=&quot;wikitable&quot;
! || Rock || Paper || Scissors
|- 
! Rock     
| (0, 0) || (-1, 1) || (1, -1) 
|- 
! Paper    
| (1, -1) || (0, 0) || (-1, 1) 
|- 
! Scissors 
| (-1, 1) || (1, -1) || (0, 0) 
|}


== See also ==
* [[Cooperation Game]]

== Sources ==
* [[Game Theory (coursera)]]
* [[Decision Engineering (ULB)]]

[[Category:Game Theory]]</text>
      <sha1>gamry00krhlgjw5pgmn2qr2oxb5don4</sha1>
    </revision>
  </page>
  <page>
    <title>Cooperation Game</title>
    <ns>0</ns>
    <id>313</id>
    <revision>
      <id>316</id>
      <timestamp>2014-01-16T07:32:11Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1366">== Cooperation Games ==
Unlike [[Pure Competition Game]]s where players have opposite interests, here players have the same interests 
* $\forall a \in A, \forall i, j: u_i(a) = u_j(a)$


== Coordination Game ==
Which side of the road you drive on?
* suppose two players meet at a passage 
* they want to get through 
* both need to choose either to go left or right
* win-win situation only when they both pick the same side 
* otherwise both lose 

{|  class=&quot;wikitable&quot;
! || Left || Right
|-
! Left  
| (1, 1) || (0, 0)
|-
! Right 
| (0, 0) || (1, 1)
|}


== Battle of the Sexes ==
This is not only a cooperation game, but also a [[Pure Competition Game]]

Description:
* 2 players - a husband and a wife
* 2 options - ballet and football
* they want to go together
* but Husband prefers to go to football, and wife wants to see the ballet

{| class=&quot;wikitable&quot;
! wife $\to$ &lt;br&gt; husband $\downarrow$ || $B$ || $F$
|- 
! $B$ 
| &lt;font color=&quot;blue&quot;&gt;(2, 1)&lt;/font&gt; || &lt;font color=&quot;grey&quot;&gt;(0, 0)&lt;/font&gt;
|- 
! $F$ 
| &lt;font color=&quot;grey&quot;&gt;(0, 0)&lt;/font&gt; || &lt;font color=&quot;blue&quot;&gt;(1, 2)&lt;/font&gt;
|}

There are two [[Nash Equilibrium|Nash Equilibria]]:
* $(B, B)$ and $(F, F)$
* in both these cases nobody wants to deviate as they would get worse payoff
* consider $(B, F)$ - in this case both want to deviate 


== Sources ==
* [[Game Theory (coursera)]]

[[Category:Game Theory]]</text>
      <sha1>ozlc53aotu48t3yhbkc4ktefchn1542</sha1>
    </revision>
  </page>
  <page>
    <title>Matching Pennies</title>
    <ns>0</ns>
    <id>314</id>
    <redirect title="Pure Competition Game" />
    <revision>
      <id>317</id>
      <timestamp>2014-01-16T07:32:59Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="52">#redirect [[Pure Competition Game#Matching Pennies]]</text>
      <sha1>4e093oqopswxvvyp3fqg9gs4ybskfzs</sha1>
    </revision>
  </page>
  <page>
    <title>Coordination Game</title>
    <ns>0</ns>
    <id>315</id>
    <redirect title="Cooperation Game" />
    <revision>
      <id>318</id>
      <timestamp>2014-01-16T07:34:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="48">#redirect [[Cooperation Game#Coordination Game]]</text>
      <sha1>at4cyfefmcfxvh4max3u7jhb00xoeke</sha1>
    </revision>
  </page>
  <page>
    <title>Battle of the Sexes</title>
    <ns>0</ns>
    <id>316</id>
    <redirect title="Cooperation Game" />
    <revision>
      <id>319</id>
      <timestamp>2014-01-16T07:35:13Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="50">#redirect [[Cooperation Game#Battle of the Sexes]]</text>
      <sha1>q1zqdhw27by47cd8ouu7ya1dt8rt9rh</sha1>
    </revision>
  </page>
  <page>
    <title>Prisoner's Dilemma</title>
    <ns>0</ns>
    <id>317</id>
    <revision>
      <id>320</id>
      <timestamp>2014-01-16T07:39:50Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2736">== Prisoner's Dilemma ==
This is a game of [[Game Theory]]

The set up:
* There are two players $p_1$ and $p_2$
* both have committed a crime 
* they are caught by the police and kept in separate rooms - so they cannot communicate with each other
* they have two options: cooperate with the police and confess ($C$), or don't cooperate ($N$)
* for not cooperating: 1 year in prison
* for cooperating: the other goes to jail on 10 years and you are set free 
* but if both cooperate, each gets 5 years in prison

This can be depicted by a matrix: 

{| class=&quot;wikitable&quot;
! || $N$ || $C$
|-
! $N$ 
| (-1, -1) || (-10, 0)
|-
! $C$ 
| (0, -10) || (-5, -5)
|}

The best strategy - the [[Nash Equilibrium|Nash Equilibria]] is:
* for $p_2$: $C$ is always better: (0 &gt; -5)
* for $p_1$: the same 
* so both choose to play $(C, C)$ - the strictly dominating strategy
* but this strategy clearly is not better than $(N, N)$ - but the [[Dominance]] principle misses it
* which is why it's called a [[Game Theory]] paradox 


== Variations ==
=== TCP blackoff ===
Set up
* when TCP correctly implemented, it has &quot;backoff mechanism&quot;
* if data flow causes congestion, sender reduces speed, until a jam subsides
* defective implementation doesn't backoff

There are two strategies
* $C$ to use correct implementation
* $D$ to use defective one
* if both players use $C$, delay is 1
* if $p_1$ uses $D$, and $p_2$ uses $C$, then $p_1$ has no delays, but $p_2$ has 4ms of delays
* both players want to minimize the delay time

{| class=&quot;wikitable&quot;
! || $C$ || $D$ 
|-
! $C$ 
| (-1, -1) || (0, -4)
|-
! $D$ 
| (-4, 0) || (-3, -3)
|}

For both players the dominating strategy is $D$


=== Tickets Price ===
* Suppose we have two airline companies $P_1$ and $P_2$
* They are both thinking about about opening a new destination 
* Both consider two options: either make tickets cheap or make them expensive 
* Clearly if $p_1$ decides to sell cheap tickets while $p_2$ - to sell expensive tickets, everybody will buy from $p_1$

So we can depict it with the following pay-off matrix
* a cell represents consequences of the decision that both players take

{| class=&quot;wikitable&quot;
! $p_2 \to$ &lt;br/&gt; $p_1 \downarrow$ || 200 || 500 
|-
! 200 
| (50, 100) || (-100, 200)
|-
! 500 
| (150, -200) || (-10, -10)
|}

We see that:
* if both agree on cheap tickets - both will have profits
* if $p_2$ sells expensive tickets and $p_1$ cheap ones, all go to $p_1$ and $p_2$ will have losses
* the same with $p_1$ and $p_1$
* if both decide on expensive tickets - nobody will buy them and they both will experience losses


The profile (500, 500) is the Nash Equilibria



== Sources ==
* [[Decision Engineering (ULB)]]
* [[Game Theory (coursera)]]

[[Category:Game Theory]]</text>
      <sha1>k98f1869rgplnjvfd895sgdxzfse9jv</sha1>
    </revision>
  </page>
  <page>
    <title>Cournot Duopoly Model</title>
    <ns>0</ns>
    <id>318</id>
    <revision>
      <id>321</id>
      <timestamp>2014-01-16T07:40:49Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2940">== The Cournot Duopoly Model ==
This is a game from the [[Game Theory]] that models interaction between two firms that produce the same product. 


=== The Game ===
Set Up:
* there are two companies $p_1$ and $p_2$
* they produce the same product and have to decide how much they are going to produce 
** $q_1$ is the number of produced units for $c_1$
** $q_2$ is the number of produced units for $c_2$
** so the set of actions each firm can take is $\mathbb{N}$ - all positive numbers
* $q = q_1 + q_2$
* but the market has limits
** if both companies decide to produce too much, not everything will be sold
** and the price will go down
* let $p(q) = A - q$ be the price per unit, where $A$ is some constant
** this models that the more units you sell, the less money (per unit) you get
* for the firm $p_i$ the cost of producing one item is $c_i$
** $c_i &gt; 0$
** the total cost of producing is $c_i \cdot q_i$


The Game:
* the companies want to determine what's the best strategy for both 
* the actions here is the number of unit they want to produce 
* variables:
** $q = q_1 + q_2$ - total quantity
** $P(q) = A - q$ - the price
* the payoffs
** $\Pi_1(q_1, q_2) = -\underbrace{c_1 \cdot q_1}_\text{(1)} + \underbrace{q_1 \cdot P(q)}_\text{(2)} = q_1 \cdot (A - q_1 - q_2) - c_1 \cdot q_1$
** (1) - cost of producing 
** (2) - the gain
** note that the payoff of $p_1$ is affected by the choice of $p_2$ 
** $\Pi_2(q_1, q_2) = -c_2 \cdot q_2 + q_2 \cdot P(q) = q_2 \cdot (A - q_1 - q_2) - c_2 \cdot q_2$


We want to maximize the payoff
* the best strategy for $p_1$
** for $\Pi_1 - q_1$ is a variable and the rest are parameters 
** therefore to maximize the payoff we take a partial derivative with respect to $q_1$ and equal it to 0
** $\cfrac{\partial \Pi_1(q_1, q_2)}{\partial q_1} = 0$
** $\cfrac{\partial}{\partial q_1} \big(q_1 (A - q_1 - q_2 - c_1 q_1 \big) = A - q_1 - q_2 + (-q_1) - c_1 = 0$
** or $A - c_1 = q_2 + 2q_1$
* do the same for $p_2$
** $\cfrac{\partial \Pi_2(q_1, q_2)}{\partial q_2} = 0$
** or $A - c_2 = q_1 + 2 q_2$
* so assuming they cooperate and both want to find the best strategy, we have
** $
\left\{\begin{matrix}
A - c_1 = q_2 - 2q_1 \\ 
A - c_2 = q_1 + 2q_2
\end{matrix}\right.$
* now we can take express $q_1$ via $q_2$
** $q_1 = \cfrac{1}{2} (A - c_1 - q_2)$
** $2A - 2c_2 = A - c_1 - q_2 + 4q_2$
** $3q_2 = 2A - A - 2c_2 + c_1$
** $q_2 = \cfrac{1}{3} (A - 2c_1 + c_2)$
** this is the best strategy for $p_2$
* same for $p_1$
** $q_1 = \cfrac{1}{3} (A - 2c_1 + c_2)$
** this is the best strategy for $p_1$


This action profile is a [[Nash Equilibrium]] - no one will have an incentive to deviate 
* so applying this we can calculate the right number of items to produce



== Links ==
* http://www2.isye.gatech.edu/~pinar/teaching/isye6230-spring2004/duopoly-models-part1.pdf

== See also ==
* [[Bertrand Duopoly Model]]

== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Game Theory]]</text>
      <sha1>pdns2q6c874xciuw6xzbleaq35pqxf0</sha1>
    </revision>
  </page>
  <page>
    <title>Bertrand Duopoly Model</title>
    <ns>0</ns>
    <id>319</id>
    <revision>
      <id>322</id>
      <timestamp>2014-01-16T07:41:58Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2455">== The Bertrand Duopoly Model ==
This is a game from the [[Game Theory]] that models interaction between two firms that produce the same product. 

This model is similar to the [[Cournot Duopoly Model]].


=== The Model ===
Consider a market with two firms $1$ and $2$ that produce identical products
* let $q = A - p$ be the total quantity sold for the price $p$ and demand $A$ 
* if both firms have the same price, then each sells a half of the total 
* if one firm has a lower price, it sells everything 
* the marginal cost of a firm $i$ is $c_i$
* the restrictions are $c_1 &gt; 0, c_2 &gt; 0, c_1 \ne c_2$

The earned money of each firm:
* $\pi_1 = \left\{\begin{matrix}
A - p_1 &amp; \text{if } p_1 &lt; p_2 \\  
\cfrac{A - p_1}{2} &amp; \text{if } p_1 = p_2 \\
0 &amp;  \text{if } p_1 &gt; p_2
\end{matrix}\right.$
* $\pi_2 = \left\{\begin{matrix}
A - p_2 &amp; \text{if } p_2 &lt; p_1 \\  
\cfrac{A - p_2}{2} &amp; \text{if } p_2 = p_1 \\
0 &amp;  \text{if } p_2 &gt; p_1
\end{matrix}\right.$


But we need to take into account the cost of production.

So the utilities are:
* $u_1 = q_1 (p_1 - c_1)$ 
* $u_2 = q_2 (p_2 - c_2)$ 
* $p_1 - c_1$ are the marginal earns per product - so we multiply it on sold quantity
* each player wants $u_i \geqslant 0$ (i.e. $p_i \geqslant c_i$)


Consider the constraints 
* for player 1
** $p_1 \leqslant A$ can't exceed the maximal price (the demand)
** $p_1 \geqslant c_1$ can't be lower than the cost of production
** $\Rightarrow c_1 \leqslant p_1 \leqslant A$
* for player 2
** $c_2 \leqslant p_2 \leqslant A$
* $c_1 \ne c_2$

Therefore &quot;interesting&quot; values (ones that get profit) are:
* $p_1 \leqslant p_2$ for firm 1
** or $c_1 \leqslant p_1 \leqslant p_2$
* $p_2 \leqslant p_1$ for firm 1
** or $c_2 \leqslant p_2 \leqslant p_1$

Since $c_1 \ne c_2$ there could be two cases:
* $c_1 &lt; c_2$ - worst case for firm 2
** in order to increase their marginal utilities and take the whole market they will constantly lower the price 
** until eventually $c_2 = p_2$ (the utility is still not negative - so it's good)
** but firm 1 can continue to lower the price - and therefore it will get the whole market 
** i.e. $p_1 \leftarrow  c_2 - \epsilon, (\epsilon &gt; 0)$ makes 1 win the market
* the same for $c_2 &lt; c_1$ - worst case for firm 1
** firm 2 wins the market
* the only possible equilibrium in such case would be $c_1 = c_2$

 
== See also ==
* [[Cournot Duopoly Model]]

== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Game Theory]]</text>
      <sha1>1iuqs4xu1z1eaacn2s9b2gqyp984vim</sha1>
    </revision>
  </page>
  <page>
    <title>Mixed-Strategy Game</title>
    <ns>0</ns>
    <id>320</id>
    <revision>
      <id>323</id>
      <timestamp>2014-01-16T07:42:49Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3743">{{draft}}

== Mixed-Strategy ==

=== Randomization ===
* Not a good idea to play deterministic game
* so another player will always want to choose better results
* Idea: confuse them by playing randomly
* Consider the matching pennies: randomly picking actions is better

=== Pure vs mixed ===
* Pure strategy: only one action is played with positive probability
* Mixed strategy: more than one action is player with positive probability
* these actions are called the support of the mixed strategy

=== Expected payoff ===
* &lt;math&gt;u_i(s) = \sum_{a \in A} u_i(a) Pr(a | s)&lt;/math&gt; - sum over all cells of the game with each payoff multiplied by probability it happens 
* &lt;math&gt;Pr(a | s) = \prod_{j \in N} s_j(a_j)&lt;/math&gt;: probability it happens - product of each player's probability to select this cell


=== Best Response ===
* &lt;math&gt;s^*_i \in BR(s_{-i}) \iff \forall s_i \in S_i, u_i(s^*_i, s_{-i}) \geqslant u_i(s_i, s_{-i})&lt;/math&gt;: &lt;math&gt;s^*_i&lt;/math&gt; is a BR if it's as good as others or better
* &lt;math&gt;s = \{s_1, ..., s_n\}&lt;/math&gt; is a Nash Equilibrium if &lt;math&gt;\forall i, s_i \in BR(s_{-i})&lt;/math&gt;


=== Theorem (Nash) ===
* Every finite gave has a Hash Equilibrium
* Matching pennies - NE is to play randomly 50/50 
* Coordinating game - NE is to play randomly 50/50
* Prisoners' dilemma - only a pure strategy NE, no mixed one

=== Computing ===
* hard to compute
* easier when you can guess the support (pure strategies with positive probability)
* Indifference
** if P1 best-responds with a mixed strategy
** P2 must make him indifferent
** He himself plays mixed strategy, so it's the best response
** if he's not indifferent, he will play the same strategy, and over time his opponent will use it
** &lt;math&gt;u_1(A) = u_1(B)&lt;/math&gt;
utility when P1 plays A = P1 plays B
* Battle of the Sexes
** &lt;math&gt;2p+0(1-p) = 0p + 1(1-p)&lt;/math&gt;; &lt;math&gt;p = 1/3&lt;/math&gt;
** &lt;math&gt;q+0(1-q) = 0q+2(1-q)&lt;/math&gt;; &lt;math&gt;q = 2/3&lt;/math&gt;
** Thus, the mixed strategies &lt;math&gt;(2/3, 1/3)&lt;/math&gt; and &lt;math&gt;(1/3, 2/3)&lt;/math&gt; are NE

=== Interpreting ===
* What does it mean to play a mixed strategy?
* Randomize to confuse your opponent
** consider the matching pennies
* Randomize what uncertain about the others' actions
** consider the battle of the sexes

=== Examples ===
* Predator vs Prey
** a competition between 2 animals
** possible strategies for each: be active or passive
** predator\prey
*** prob
**** 
**** p
**** 1-p
*** Active
**** 2, -5
**** 3, -6
**** q
*** Passive
**** -1, 0
**** 3, -2
**** 1-q
** what p and q are the mixed strategy equilibrium?
** predator plays active with q (rows, 1rd), 
prey plays active with p (cols, 2nd)
** 

predator:

 {when plays active} 
 p {prey is active} * 2 {possible payoff}
 +
 (1 - p) {prey is passive} * 3 {possible payoff} 
 = 
 {when plays passive}
 p {prey is active} * 3 {possible payoff}
 +
 (1 - p) {prey is passive} * (-1) {possible payoff} 

=&gt;

 prey plays active with p = 4/5

** prey: &lt;math&gt;-5q-2(1-q) = -6q &lt;/math&gt;=&gt; &lt;math&gt;q = 2/3&lt;/math&gt;
* Kicker vs Goalie
** Soccer penalty kicks 
** usual
*** kicker\goalie
**** prob
***** 
***** 1/2
***** 1/2
**** Left
***** 0, 1
***** 1, 0
***** 1/2
**** Right
***** 0, 1
***** 1, 0
***** 1/2
*** equlibrium is to play 1/2
** kicker is weak on right
*** a kicker misses right every 4th time
*** kicker\goalie
**** prob
***** 
***** p
***** 1-p
**** Left
***** 0, 1
***** 1, 0
***** q
**** Right
***** 0, 1
***** .75, .25
***** 1-q
*** K plays L with q, G plays L with p
*** {L} &lt;math&gt;G: 0p+1(1-p) = 0.75p+0(1-p)&lt;/math&gt; {R}, &lt;math&gt;p = 4/7&lt;/math&gt;
*** {L} &lt;math&gt;K: q+0.25(1-q)  = 1-q;&lt;/math&gt; {R}, &lt;math&gt;q = 3/7&lt;/math&gt; 
*** result: Kicker kicks more to the Right!
*** because G has adjusted

== Sources ==
* [[Game Theory (coursera)]]

[[Category:Game Theory]]</text>
      <sha1>jnlrru5masn44bde8h0xpnnqzjj6am7</sha1>
    </revision>
  </page>
  <page>
    <title>Repeated Game</title>
    <ns>0</ns>
    <id>321</id>
    <revision>
      <id>324</id>
      <timestamp>2014-01-16T07:43:18Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5664">{{draft}}

== Repeated Games ==

=== Utility ===
* the sequence of utility is infinite
* how to write it?
** average reward
*** &lt;math&gt;\lim_{k \rightarrow \inf} \sum_{j-1}^{k} \fraq{r_j}{k}&lt;/math&gt;
** discounted utility
*** players care about future less than about present
*** &lt;math&gt;\beta&lt;/math&gt; - discount factor (&lt;math&gt;0 &lt; \beta &lt; 1&lt;/math&gt;)
*** future discounted reward: &lt;math&gt;\sum_{j=1}{\inf} \beta ^j r_j&lt;/math&gt;
*** &lt;math&gt;\beta&lt;/math&gt; can be seen as an &quot;interest rate&quot;
*** with probability &lt;math&gt;(1 - \beta)&lt;/math&gt; game may finish

=== Stochastic games ===
* generalization of repeated games
* informal visualization
** &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/5a33joqeuq1eap2r2sl78811pd.png&quot; /&gt;


=== Learning in Repeated Games ===
* all players learn as they go
* fictitious play (model-based learning)
** initially - method for computing a NE
** each player maintains explicit beliefs about the other players
** algorithm
*** initialize beliefs about opponent's strategy
*** each turn
**** play a BR to the assumed strategy
**** observe actual play and update beliefs
** consider matching pennies
*** won't converge to a specific value
*** but empirical frequencies will converge to a NA
* No-regret learning
** regret
*** regret of an agent is experienced at time t for not having played strategy s
*** &lt;math&gt;R^t(s) = \alpha ^t - \alpha^t (s)&lt;/math&gt;
*** &lt;math&gt;\alpha ^t&lt;/math&gt; - payoff player actually gets
*** &lt;math&gt;\alpha ^t(s)&lt;/math&gt; - payoff we would have received, if had played s
** no-regret rule
*** a learning rule exhibits no regret
*** if for any pure strategy of the agent s
*** &lt;math&gt;Pr[\lim \inf R^t(s)] \leqslant 0) = 1&lt;/math&gt;
*** (if player shows no regret)
** regret matching
*** look at the regrets you've experienced so far
*** and pick a pure strategy in proportion to this regret
*** &lt;math&gt;\sigma _i ^{t+ 1} = \freq{ R^t(s) }{ \sum _{ s' \in S_i } R^t (s')&lt;/math&gt;
*** sum in the denominator - sum of all regrets
*** value in the numerator - a particular regret
*** &lt;math&gt;\sigma_i ^{t + 1}&lt;/math&gt; - probability that agent &lt;math&gt;i&lt;/math&gt; plays &lt;math&gt;s&lt;/math&gt; at time &lt;math&gt;t+1&lt;/math&gt;
*** so it converges to equilibrium

=== Equilibrium of Inf. Repeated Games ===
* pure strategy
** action on every stage
** given you remember anything!
** history, etc
** so it's an infinite set
** example strategies for Prisoner's Dilemma
*** Tit-for-tat
**** start out cooperating
**** if opponent defects, defect next round
**** then go back to cooperation
*** Trigger
**** start out cooperating
**** if opponent defects, defect for ever
* idea
** we can characterize a set of payoffs that are achievable under equilibrium
** without having to enumerate the equilibria
** (the number of equilibria is infinite)
* definitions
** let &lt;math&gt;v_i = \min_{s_{-i} \in S_{-i}} \max _{s_i \in S_i}&lt;/math&gt;
** &lt;math&gt;v_i&lt;/math&gt; - minimax value
*** the amount of utility &lt;math&gt;i&lt;/math&gt; can get 
*** when &lt;math&gt;-i&lt;/math&gt; play a minmax strategy against him
*** so it's the value &lt;math&gt;i&lt;/math&gt; will get if others want to hurt him as much as they can
** enforceability
*** a payoff profile is enforceable if &lt;math&gt;r_i \geqslant v_i&lt;/math&gt;
*** i.e. if everybody's payoff is at least their minmax value
** feasibility
*** a payoff profile is feasible if
**** there exists rational non-negative values &lt;math&gt;\alpha_a&lt;/math&gt;
**** such that for all i we can express r_i as 
**** &lt;math&gt;\sum_{a \in A} \alpha_a u_i(a)&lt;/math&gt;
**** and &lt;math&gt;\sum_{a \in A} \alpha_a = 1&lt;/math&gt;
*** so it says that it is possible to have this payoff
* Folk theorem
** consider any n-player game &lt;math&gt;G&lt;/math&gt; and any payoff vector &lt;math&gt;(r_1, ..., r_n)&lt;/math&gt;
** first
*** if &lt;math&gt;r_i&lt;/math&gt; is the payoff of any NE of &lt;math&gt;G&lt;/math&gt;, then for player i it's enforceable
*** i.e. greater than or equal to his/her minimax value
** second
*** if r is both feasible and enforceable
*** then &lt;math&gt;r&lt;/math&gt; is the payoff in some NE of &lt;math&gt;G&lt;/math&gt;
** so, enforceability and feasibility - things you need to find NE
** as long as you meet these 2 conditions, you have a NE

=== Discounted Repeated Games ===
* motivation
** the future is uncertain
** we are often motivated by what happens today
** will people punish me if I misbehave today?
*** is it in their interest?
*** do I care about the future?
* discount factor
** stage game : &lt;math&gt;(N, A, u)&lt;/math&gt;
** Discount factor &lt;math&gt;\beta_1 ... \beta_n, \beta_i \in [0, 1]&lt;/math&gt;
** &lt;math&gt;\sum_t = \beta_i^t u_ (a^t)&lt;/math&gt;
* Histories
** Histories of length t
** &lt;math&gt;H^t = \{ h^t : h^t = (a^1, ..., a^t) \in A^t \}&lt;/math&gt;
** (what everybody did on t period of time)
** all histories: &lt;math&gt;H = \bigunion_t H^t&lt;/math&gt;
** Prisoner's Dilemma
*** &lt;math&gt;A_i = \{C, D\}&lt;/math&gt;
*** History: (C, C) (C, D) (D, D)
*** a strategy for period 4 would specify what a player would do after seing the history
* Subgame perfection
** subgame
*** subgame starts at a particular &lt;math&gt;t'&lt;/math&gt;
*** and contains everything that remains
** subgame perfection
*** take &lt;math&gt;t'&lt;/math&gt;
*** play NE
*** and NE will be for ever on
*** i.e. no matter that the history is, playing a NE would lead to a subgame perfection
* Prisoner's Dilemma
** game
*** C
**** 3,3
**** 0,5
*** D
**** 5,0
**** 1,1
** consider trigger strategy
** if cooperate, they will have
*** &lt;math&gt;3 + 3\beta + 3\beta^2 + ... = \frac{3}{1 - \beta}&lt;/math&gt;
** if defect
*** &lt;math&gt;5 + \beta + \beta^2 + ... = 5 + \beta \frac{1}{1 - \beta}&lt;/math&gt;
** difference (we want to sustain (C,C))
*** &lt;math&gt;\beta \frac{2}{1 - \beta} - 2 \geqslant 0&lt;/math&gt;
*** &lt;math&gt;\beta \geqslant 0.5&lt;/math&gt;

== Sources ==
* [[Game Theory (coursera)]]

[[Category:Game Theory]]</text>
      <sha1>b16e5q18wras49h6p72qhub9rd6omdc</sha1>
    </revision>
  </page>
  <page>
    <title>Coalitional Game</title>
    <ns>0</ns>
    <id>322</id>
    <revision>
      <id>325</id>
      <timestamp>2014-01-16T07:43:45Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5589">{{draft}}

== Coalitional Games ==

=== Coalitional Game Theory ===
* Applications
** politics, political parties
** companies
** marriage, building a house
** etc
* basic unit - a team
** the focus is on the group rather than on individuals
* Transferable utility
** we assign payoff to the whole coalition
** and player decide on themselves how to distribute it
* Coalitional Game with Transferable Utility
** a pair &lt;math&gt;(N, v)&lt;/math&gt; where
** &lt;math&gt;N&lt;/math&gt; - finite set of players
** &lt;math&gt;v: 2^N \mapsto R&lt;/math&gt;
*** utility function
*** associates with coalition rather with an individual
* questions
** which coalitions will form?
** how a coalition would divide payoffs among its members?
* Superadditive Coalitional Game
** a game &lt;math&gt;G = (N, v)&lt;/math&gt;
** if
*** for all pairs &lt;math&gt;(S, T) \subset N&lt;/math&gt;
*** &lt;math&gt;S \cap T = \emptyset&lt;/math&gt; (intersection) 
** then &lt;math&gt;v(S \cup T) \geqslant v(S) + v(T)&lt;/math&gt;
** if we form a coalition of &lt;math&gt;S&lt;/math&gt; and &lt;math&gt;T&lt;/math&gt;,
** then its payoff is at least as good as sum of their payoffs separately
** eg
*** &lt;math&gt;N = 3&lt;/math&gt;
*** &lt;math&gt;v(1) = v(2) = v(3) = 1&lt;/math&gt;
*** &lt;math&gt;v(1, 2) = 3&lt;/math&gt;, &lt;math&gt;v(1, 3) = 4&lt;/math&gt;, &lt;math&gt;v(2, 3) = 5&lt;/math&gt;
*** &lt;math&gt;v(1, 2, 3) = 7&lt;/math&gt; - greater than if acted on their own

=== The Shapley Value ===
* what if a &quot;fair&quot; way for a coalition to divide its payoff?
* how we define &quot;fairness&quot;?
* Shapley's idea: members receive payoffs proportional to their marginal contribution
* axioms of fairness
** symmetry
*** if 2 agents i and j, when contributed, give the same amount of payoff
*** give them the same amount of payoff
*** for each S which contains neither i not j
*** &lt;math&gt;v(S \cup \{i\}) = v(S \cup \{j\})&lt;/math&gt;
**** if we add &lt;math&gt;i&lt;/math&gt; or &lt;math&gt;j&lt;/math&gt;
**** we will get the same payoff
*** so they should receive the same amount of payment
** dummy player
*** &lt;math&gt;i&lt;/math&gt; is a dummy player if
*** for all &lt;math&gt;S: v(S \cup {i}) = v(S)&lt;/math&gt;
*** i.e. &lt;math&gt;i&lt;/math&gt; doesn't bring anything
*** therefore &lt;math&gt;i&lt;/math&gt; shouldn't receive anything
** additivity
*** if we can separate a game into 2 parts
*** we should be able to decompose payments  
*** &lt;math&gt;v = v_1 + v_2&lt;/math&gt;
* the Shapley value
** with all these axioms
** for game &lt;math&gt;G(N, v)&lt;/math&gt;
** the Shapley value is
** &lt;math&gt;\phi_i(N, v) = \frac{1}{N!} \sum_{S \in N\{i}} |S|! (|N| - |S| - 1)! [v(S \cup {i}] - v(S)] &lt;/math&gt;
** explanation
*** &lt;math&gt;\frac{1}{N!}&lt;/math&gt; - we average over all combinations
*** sum over all subsets without &lt;math&gt;i&lt;/math&gt;
*** &lt;math&gt;|S|! (|N| - |S| - 1)!&lt;/math&gt; - weighted by how many different ways we could come up with this calculation
**** &lt;math&gt;|S|!&lt;/math&gt; - ways the set S could be formed before i's addition
**** &lt;math&gt;(|N| - |S| - 1)!&lt;/math&gt; - ways the remaining players could be added
*** &lt;math&gt;[v(S \cup {i}] - v(S)]&lt;/math&gt;  - how much &lt;math&gt;i&lt;/math&gt; brings if added to the coalition
* theorem
** given a coalition game &lt;math&gt;(N, v)&lt;/math&gt;
** there is a unique payoff division
** &lt;math&gt;x(v) = \phi(N, v)&lt;/math&gt;
** that divides that payoff and satisfies 3 axioms
** it's the Shapley value

=== The Core ===
* voting game
** a parliament is made of 4 parties: A, B, C, D
** each has 45, 25, 15, 15 representatives
** they are to vote
** 51 should vote for a law to pass, otherwise all get nothing
** Shapley Value: (50, 16.67, 16.67, 16.67)
** But A and B can form a coalition and get more! (75, 25)
** so they have incentive to defect
* motivation
** The Shapley Value - how to divide in a fair way
** but it ignores the question of stability
** i.e. would agents be willing to form the grand coalition?
** or they would prefer to have smaller? (sometimes smaller is more attractive)
** Under what payment division would the agents want to form the grand coalition?
* core
** a payoff vector x is in the core of a coalition game &lt;math&gt;G = (N, v)&lt;/math&gt; iff
** &lt;math&gt;\forall S \subset N, \sum_{i \in S} x_i \geqslant v(S)&lt;/math&gt;
*** for every coalition they could form
*** the value they would get if form a grand coalition
*** &lt;math&gt;v(S)&lt;/math&gt; - if they deviate and don't form a GC
** the sum of payoffs to the agents in many subcoalition S
** is at least as good as the one they could earn on their own
** core may be empty and sometimes may not exist
** and it's not always unique
* Theorem
** simple game
*** a game &lt;math&gt;G = (N, v)&lt;/math&gt; is simple if
*** &lt;math&gt;\forall S \subset N, v(S) \in \{0, 1\}&lt;/math&gt;
*** for all coalitions they gain either 0 or 1
*** vote game is a simple game: they either get money (1) or no (0)
** veto player
*** a player &lt;math&gt;i&lt;/math&gt; is a veto player if 
*** &lt;math&gt;v(N - \{i\}) = 9&lt;/math&gt;
*** it's participation is needed if a coalition wants to produce any value
** in a simple game the core is empty if
** there is no veto player
* Convex game
** a game &lt;math&gt;G=(N, v)&lt;/math&gt; is convex if
** for all &lt;math&gt;(S, T) \subset N, v(S \cup T) \geqslant v(S) + v(T) - v(S \cap T)&lt;/math&gt;
** for all coalitions in &lt;math&gt;N&lt;/math&gt;, if they form a bigger coalition, they will achieve
* Airport game
** several cities want an airport
** options: 
** big regional airport and share costs vs own airports
** &lt;math&gt;N&lt;/math&gt; - set of cities
** sum of costs of building runways for each city in &lt;math&gt;S&lt;/math&gt; vs
** vs cost of the largest runway required by the cities in &lt;math&gt;S&lt;/math&gt;
** a convex game
* Theorems
** every convex game has a non-empty core
** in every convex game, the Shapley value is in the core
** (possible to do both stable and fair division)


== Sources ==
* [[Game Theory (coursera)]]

[[Category:Game Theory]]</text>
      <sha1>i2dqkv81dy724ryknookm5guuff5w0k</sha1>
    </revision>
  </page>
  <page>
    <title>Bayesian Game</title>
    <ns>0</ns>
    <id>323</id>
    <revision>
      <id>326</id>
      <timestamp>2014-01-16T07:44:19Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5997">{{draft}}

== Bayesian Games ==
=== Motivation ===
* auctions
** I'm not quite sure what are the utilities of other players
* usually everyone knows
** the number of players 
** the actions available to each player
** payoff associated with each action vector

=== Assumptions ===
* there are some games (not only one)
** all games have the same number of agents
** the same strategy space for each agent
** the only difference is in the payoff
* agents' beliefs are posterior
** obtained by conditioning a common prior on individual private signals
** common prior - what's possible
** individual private signals - beliefs that agents have

=== Bayesian game ===
* Definition 1: based on Information set
** Intuition
*** BG - a set of games that differ only in their payoffs
*** plus a common prior is defined over them
*** and a partition structure is defined over the games for each agent
** A BG is a tuple &lt;math&gt;(N, G, P, I)&lt;/math&gt; where
*** &lt;math&gt;N&lt;/math&gt; - a set of agents
*** G&lt;math&gt;&lt;/math&gt; set of games with N agents for each
**** if &lt;math&gt;g&lt;/math&gt; and &lt;math&gt;g' \in G&lt;/math&gt; for each agent &lt;math&gt;i \in N&lt;/math&gt;
**** the strategy space in &lt;math&gt;g&lt;/math&gt; is identical to the strategy space in &lt;math&gt;g'&lt;/math&gt;
**** (so games differ only in their utility functions)
*** &lt;math&gt;P \in \Pi (G)&lt;/math&gt; - a common prior over games
**** &lt;math&gt;\Pi(G)&lt;/math&gt; set of probability distribution over &lt;math&gt;G&lt;/math&gt;
**** (how likely each of these games is)
*** &lt;math&gt;I = (I_1, I_2, ..., I_N)&lt;/math&gt; is a set of partitions of &lt;math&gt;G&lt;/math&gt;, one for each agent
**** set of equivalence classes: some games are indistinguishable
** Example
*** 4 games
**** Matching Pennies
**** Prisoner's Dilemma
**** Coordination game
**** The Battle of the Sexes
*** equivalence classes
**** Player I
***** MP and PD
***** Coord and BoS
**** Player II
***** MP and Coord
***** PD and BoS
*** when playing, players don't know what game they're playing
*** only the equivalence class
* Definition 2: based on epistemic types
** directly represents uncertainly over utility function using the notion of epistemic type
** epistemic type - private information of an agent
** A BG is a tuple &lt;math&gt;(N, A, \Theta, p, u)&lt;/math&gt; where
*** &lt;math&gt;N&lt;/math&gt; - a set of agents
*** &lt;math&gt;A = (A_1, A_2, ..., A_n)&lt;/math&gt;
**** &lt;math&gt;A_i&lt;/math&gt; - set of actions available to &lt;math&gt;i&lt;/math&gt;
*** &lt;math&gt;\Theta = (\theta_1, ..., \theta_n)&lt;/math&gt;
**** &lt;math&gt;\theta_i&lt;/math&gt; - type space of player &lt;math&gt;i&lt;/math&gt;
*** &lt;math&gt;p: \theta \mapsto [0, 1]&lt;/math&gt;
**** the common prior over types
*** &lt;math&gt;u = (u_1, ..., u_n)&lt;/math&gt;
**** where &lt;math&gt;u_i = A * \theta \mapsto \mathbb{R}&lt;/math&gt;

=== Analysing Bayesian Games ===
* Bayesian (Nash) Equilibrium
** a plan of actions for each player as a function that maximizes each type's expected utility
** so it should be a best reply
** If I observe a certain type, what am I going to do?
** expecting over the actions of other players
*** what are the expected action distributions we're going to face
** expecting over the types of ther players
* Strategies
** given a Bayesian finite game &lt;math&gt;(N, A, \Theta, p, u)&lt;/math&gt;
** pure strategy
*** &lt;math&gt;s_i : \theta_i \mapsto A_i&lt;/math&gt;
**** for a type, what action you'll take?
*** a choice of a pure strategy for player i as a function of her type
** mixed strategy
*** &lt;math&gt;s_i : \theta_i \mapsto \Pi(A_i)&lt;/math&gt;
**** &lt;math&gt;\Pi(A_i)&lt;/math&gt; - probability distribution over actions of your type
*** a choice of x mixed action for player i as a function of his type
*** distribution over actions
**** &lt;math&gt;s_i(a_i | \Theta_i)&lt;/math&gt;
**** [what's the probability that action a_i will be chosen if they happen to be of type &lt;math&gt;\Theta_i&lt;/math&gt;]
**** the probability under mixed strategy &lt;math&gt;s_i&lt;/math&gt; that agent &lt;math&gt;i&lt;/math&gt; plays action &lt;math&gt;a_i&lt;/math&gt;, given that type is &lt;math&gt;\Theta_i&lt;/math&gt;
* types
** ex-ante
*** the agent knows nothing about anyone's actual type
** interim
*** agents know their own types, but don't know the types of each other
*** for player i with respect to type \theta_i and mixed strategy profile s
*** expected utility
**** &lt;math&gt;EU_i(s | \Theta_i) = \sum_{\theta_{-i} \in \Theta_{-i}} p (\theta_{-i} | \theta{i}) * \sum_{a \in A}(\prod_{j \in N} s_i(a_i | \theta_i) * u_i(a, \Theta_i, \Theta_{-i}))&lt;/math&gt;
**** &lt;math&gt;u_i(a, \Theta_i, \Theta_{-i})&lt;/math&gt; - utilities evaluated with respect to their types
**** &lt;math&gt;\prod_{j \in N} s_i(a_i | \theta_i)&lt;/math&gt;  - what other players will be doing
**** &lt;math&gt;\sum_{\theta_{-i) \in \Theta_{-i}} p (\theta_{-i} | \theta{i})&lt;/math&gt; - sum across all probabilities of types for others
**** &lt;math&gt;EU_i(s | \Theta_i)&lt;/math&gt; - what can i expect of he of type \Theta_i and follows s
** ex-post
*** averybody knows everything
*** expected utility
**** &lt;math&gt;EU_i (s) = \sum_{\theta_i \in \Theta_i} p(\theta_i) EU_i(s | \theta_i)&lt;/math&gt;
* Bayesian Equilibrium
** a mixed strategy profile s that satisfies
** &lt;math&gt;s_i \in \arg \max_{s'_i} EU_i(s'_i, s_{-i} | \Theta_i)&lt;/math&gt;
** each individual should choose the best response, maximizing the expected utility
** for each &lt;math&gt;i&lt;/math&gt; and &lt;math&gt;\theta_i \in \Theta_i&lt;/math&gt;
** summary
*** it explicitly models behavior in uncertain environment
*** players choose strategies to maximize their payoffs in response to others
*** accounting for
**** strategic uncertainty about how others will play
**** payoff uncertainty about the value of their actions
* A Sherif's Dilemma
** a sheriff faces an armed suspect and they each must (simultaneously) decide whether to shot or not
** a suspect is criminal with probability p and not a criminal with probability 1 - p
** the sheriff would rather shoot if suspect shoots, and not shoot otherwise
** the criminal would rather shoot even if the sheriff doesn't - he doesn't want to be caught
** the innocent would rather not shoot even if the sheriff does
** ==&gt; sheriff's best reply to shoot if &lt;math&gt;p &gt; 1/3&lt;/math&gt;


== Sources ==
* [[Game Theory (coursera)]]

[[Category:Game Theory]]</text>
      <sha1>4voweya1ev1rnm4denjtks28wvzb850</sha1>
    </revision>
  </page>
  <page>
    <title>Decision Analysis</title>
    <ns>0</ns>
    <id>324</id>
    <revision>
      <id>327</id>
      <timestamp>2014-05-12T09:11:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1984">== Decision Analysis ==
=== Decision Under Certainty  ===
Let
* $A$ be a finite set of alternatives (possible decisions)
* $X$ be a set of consequences (usually some financial metrics)
* $c: A \mapsto X$ a consequence function
** $c(a) \in X$ is a consequence of implementing action $a \in A$

Problem: 
* to compare alternatives and find the optimal one 
* on the basis of their consequences

* When $|A|$ is very large - need [[Optimization]] techniques
* When $x \in X$ is multi-dimensional, i.e. $x = (x_1, ..., x_m)$ need to apply [[Multi-Objective Optimization]] and/or [[MCDA]]

For these models we make a strong assumption:
* we can quantify the consequences of taking different actions with certainty


However this assumption is not always true
* we often can face situations when consequences $c(a)$ of taking a decision $a$ are not known with certainty 

There are two categories of decision analysis tools that help model this:
* [[Decision Under Risk]]
* [[Decision Under Uncertainty]]


=== [[Decision Under Uncertainty]] ===
* we are not able to asses the distribution, but we can list all possible scenarios

Methods
* [[Max Min Strategy]] - extreme pessimism 
* [[Max Max Strategy]] - extreme optimism
* [[Hurwitz's Index]] - between the extreme pessimism and the extreme optimism
* [[Min Max Regret Strategy]] - when we want to minimize the regret of a missed opportunity
* [[Laplace Rule]] - the principle of insufficient reasoning


=== [[Decision Under Risk]] ===
* $c(a)$ is not known with certainty, but we know the probability distribution on the set of $X$

[[Decision Tree (Decision Theory)|Decision Trees]]
* [[Expected Values for Lotteries]]
* [[Expected Utility Theory]]



== Links ==
* http://answers.mheducation.com/business/economics/business-economics/decisions-under-risk-and-uncertainty
* http://ids355.wikispaces.com/Ch.+5s+Decision+Making - Questions and Answers

== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Decision Engineering]]</text>
      <sha1>1m4bmkzcrw1lsiq4jdccgjkr5pyttn9</sha1>
    </revision>
  </page>
  <page>
    <title>Decision Under Risk</title>
    <ns>0</ns>
    <id>325</id>
    <revision>
      <id>328</id>
      <timestamp>2014-05-12T09:12:26Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="633">== Decision Under Risk ==
In contrast to [[Decision Under Uncertainty]] models, here we assume that we can assign probabilities to consequences 


[[Decision Tree (Decision Theory)|Decision Trees]] and simple lotteries are the main tool for expressing decision taking process and associated risk 

These lotteries are compared by the decision maker and he chooses the best option:
* [[Expected Values for Lotteries]] - limited approach
** susceptible to paradoxes such as [[Saint Petersburg Paradox]]
* [[Expected Utility Approach]] - more preferred 


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Decision Under Risk]]</text>
      <sha1>0ot38d1vrh4tzvprodgoz5l1drgtkuk</sha1>
    </revision>
  </page>
  <page>
    <title>Decision Tree (Decision Theory)</title>
    <ns>0</ns>
    <id>326</id>
    <revision>
      <id>329</id>
      <timestamp>2014-12-25T19:27:34Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1988">== Decision Tree ==
This is a tool for modeling decision taking process for [[Decision Under Risk]]


== Lotteries ==
Notation:
* $A$ - set of alternatives
* $X = \{x_1, ..., x_n)\}$ - a finite set of consequences
* could be $X \subseteq \mathbb{R}$ - e.g. money, etc


=== Simple Lotteries ===
A ''simple lottery'' $l$ on $X$ is
* a discrete [[Random Value]] on $X$
* $l = \{(x_1, p_1), (x_2, p_2), ..., (x_n, p_n) \}$
* $x_i$ is a consequence, $p_i$ is the probability that $x_i$ will happen
* this is a simple model: it depends only on one set of consequences 


Visual representation:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/ru/simple-lottery.png


=== Set of Lotteries  ===
But we can also have a lottery over lotteries 

A set of lotteries:
* simple lotteries on $X$
* first-order lotteries on simple lotteries
* second-order lotteries on first-order lotteries 
* etc

Notation
* Let $L(X)$ denote the set of all lotteries at all finite orders 
** $L(X)$ includes all lotteries that correspond to implementation of alternatives from $A$
* $l \in L(X)$ a lottery from $L(X)$ - can be simple or not
* $p_l(x)$ is the probability to face consequence $x$ in lottery $l$ 



== Decision Trees ==
Decision Trees have three kinds of nodes:
* decision nodes
** here the decision maker has to choose which action to implement
* chance nodes 
** at a chance node the Nature chooses a branch according to the probability distribution 
** this is a lottery of higher order
* terminal nodes 
** single lotteries out of $L(X)$


== Comparing Lotteries ==
To be able to decide on the decision nodes, a decision maker needs to be able to compare different lotteries 
* [[Expected Values for Lotteries]]
* [[Expected Utility Theory]]
* this way he may rank all possible alternatives (lotteries) of the decision nodes and take the best decision


== See Also ==
* [[Decision Tree Exercises]]

== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Decision Under Risk]]</text>
      <sha1>nqfjzrmqmpwkcin59oxt7dtugl95bhq</sha1>
    </revision>
  </page>
  <page>
    <title>Expected Values for Lotteries</title>
    <ns>0</ns>
    <id>327</id>
    <revision>
      <id>330</id>
      <timestamp>2014-05-12T09:13:06Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2102">== [[Expected Value]]s for Lotteries ==
[[Expected Value]] is one way to compare lotteries in [[Decision Tree (Decision Theory)|Decision Trees]]

Define :
* $EV(l) = \sum_{x \in X} x \cdot p_l(x)$
* $l_1 \ P \ l_2 \iff EV(l_1) &gt; EV(l_2)$ - the preference relation 
* $l_1 \ I \ l_2 \iff EV(l_1) = EV(l_2)$ - the indifference relation

So essentially this is the [[Weighted Sum Model]] where weights are probabilities 
* that helps to establish preferences between lotteries 


Advantages 
* simple 
* good use of information

Disadvantages
* limited to numerical consequences 
* no clear rationale 


=== Examples ===
==== Example 1 ====
Consider two lotteries 
* $l_1$ and $l_2$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/de/ru/lotteries-ev-preferences-1.png
* $l_1$ is a game when you can win 100 euro or lose 50
* $l_2$ is when you don't play a game
* how to choose whether to play or not (i.e. choose $l_1$ or $l_2$)
* calculate the expected utility: $E(l_1) = 25, E(l_2) = 0$
* so $l_1 \ P \ l_2$

But consider two other lotteries 
* $l_3$ and $l_4$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/de/ru/lotteries-ev-preferences-2.png
* this time you can win 100k euro or lose 50k
* according to expected value $E(l_3) = 20k &gt; E(l_4) = 0$
* so we should prefer $l_3$ to $l_4$ ($l_3 \ P \ l_4$)
* but the cost of losing is too big - many people cannot afford to play such game

Many people would say
* $l_1 \ P \ l_2$
* but $l_4 \ P \ l_3$

We clearly see that EV is not enough to make a decision


==== Example 2 ====
The [[Saint Petersburg Paradox]] also shows that EV is not a good measure 



== [[Expected Value]] + [[Variance]] ==
When we face such paradoxes we need to add some additional indicators 
* such as [[Variance]] - to quantify the risk


This is less simple: 
* now the problem is bi-objective 
* need to use [[Multi-Objective Optimization]] techniques


== Conclusions ==
We need to use a different approach
* [[Expected Utility Theory]]


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Decision Under Risk]]</text>
      <sha1>5i4e0o1fhr8gmf97n365ikfe7p1fqox</sha1>
    </revision>
  </page>
  <page>
    <title>Expected Utility Theory</title>
    <ns>0</ns>
    <id>328</id>
    <revision>
      <id>331</id>
      <timestamp>2015-07-05T16:24:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4907">== Expected Utility Theory ==
[[Expected Values for Lotteries|We see]] that using [[Expected Value]] is not enough to compare simple lotteries in [[Decision Tree (Decision Theory)|Decision Trees]]


So instead of calculating Expected Values based on (numerical) consequences, we
* replace the values of the consequences onto their utilities
* the utilities are provided by individuals - and therefore may vary from one individual to another
* the ''utility'' captures  how an individual things about certain risk 


=== Utility ===
* suppose we have a set of alternatives $A = \{a, b, c, \ ... \ \}$
* utility function $U_i$ of individual $i$ is a mapping $U_i: A \mapsto X$
** where $X$ is based on numerical scale (i.e. $X \equiv \mathbb{R}$)
* we use the [[Weighted Sum Model]] to establish the final aggregated value 

The preference and indifference relations are defined as follows:
* $\forall a,b \in A: a \ P \ b \iff U_i(a) &gt; U_i(b)$ - the preference relation
* $\forall a,b \in A: a \ I \ b \iff U_i(a) = U_i(b)$ - the indifference relation


=== Utilities for Lotteries ===
* for lotteries (as defined in [[Decision Tree (Decision Theory)|Decision Trees]]) we see the lotteries as alternatives
* probabilities are the weights 
* $X$ is a set of consequences for which the lotteries are defined 

The total utility:
* $U(l) = \sum_{x \in X} u(x) \cdot p_l(x)$
* where $u$ is the utility function $u: X \mapsto \mathbb{R}$ - it maps a consequence to some real number


=== Preference Relations ===
(see also [[Voting Theory Relations]] for the same ideas but in [[Voting Theory]])

So we define the relations as:
* $l_1 \ P \ l_2 \iff U(l_1) &gt; U(l_2)$ - the preference
* $l_1 \ I \ l_2 \iff U(l_1) = U(l_2)$ - the indifference

We also define the &quot;as good as&quot; relation as $S \equiv P \lor I$
* $l_1 \ S \ l_2 \iff l_1 \ P \ l_2 \lor l_1 \ I \ l_2$


Note that $S$ is transitive and consistent 
* $\forall l_1, l_2, l_3 \in L(x): l_1 \ S \ l_2 \land l_2 \ S \ l_3 \Rightarrow l_1 \ S \ l_3$

$S$ alone is enough:
* $l_1 \ P \ l_2 \iff \big[ l_1 \ S \ l_2 \big] \land \big[\overline{l_2 \ S \ l_1} \big]$
* $l_1 \ I \ l_2 \iff \big[ l_1 \ S \ l_2 \big] \land \big[l_2 \ S \ l_1 \big]$


=== Advantages ===
* it's simple
* takes individual preferences into account
* we are not restricted to numerical consequences 
* there is a clear rationale why it works - the Axioms (see below)



== Axioms ==
This is a link to [[Arrow's Impossibility Theorem]]:
* there are 5 axioms that need to be respected

=== Axiom 1: Ranking ===
When a decision maker compares two lotteries $l_1$ and $l_2$ 
* he always can say if he prefers one another or he's indifferent between them

I.e. 
* $\forall l_1, l_2 \in L(X): l_1 \ S \ l_2 \lor l_2 \ S \ l_1$


=== Axiom 2: Reduction ===
Suppose we have a high-order lottery $l$ over $\{l_1, ..., l_k\}$
* we can always simplify $l$ and make a simple lottery from it
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/ru/lotteries-simplification.png

Example:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/ru/lotteries-simplification-ex.png


=== Axiom 3: [[Monotonicity]] ===
for lotteries $l_1, l_2 \in L(X)$ over the same outcomes $\{x, y\} \subseteq X$
* if (1) outcome $x$ is better than $y$ and (2) $p &gt; q$ 
* then $l_1 \ P \ l_2$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/ru/lotteries-monotonicity.png


=== Axiom 4: Independence ===
for high-order lotteries $l^{(1)}, l^{(2)} \in L(X)$ 
* $l^{(1)}$ is over  set of lotteries $\{l_1, \ ... \ , l_k\} \subset L(X)$
* $l^{(2)}$ is over  set of lotteries $\{l'_1, \ ... \ , l_k\} \subset L(X)$
* (the sets are almost the same - they only differ in $l_1$ and $l'_1$)
* both $l^{(1)}, l^{(2)}$ have the same probability distributions over their sets

Independence:
* if $l_1 \ I \ l'_1$ then $l^{(1)} \ I \ l^{(2)}$ 

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/ru/lotteries-independence.png


=== Axiom 5: Continuity ===
$\forall x, y, z \in X$
* if $x \ P \ y \ P \ z$ then
* there $\exists p \in [0, 1]$ s.t.
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/ru/lotteries-continuity.png

I.e. 
* when something is given with certainty
* we can transform it to some lottery

Axiom 3 implies that $p$ is unique


== Theorems ==
=== Representation ===
Let $S$ be a preference relation on $X$
* $S$ satisfies the axioms 
* $\iff$ 
* $\exists u \ : \ X \mapsto \mathbb{R}$ for which $l_1 \ S \ l_2 \iff U(l_1) \geqslant U(l_2)$


== [[MCDA]] ==
This principle is also used in Multi-Criteria Decision Aiding:
* [[Multi-Attribute Utility Theory]]


== Links ==
* Axioms: http://www.intsci.ubc.ca/wiki/doku.php?id=courses:isci344:utility_theory_axioms
* The theorem: http://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Decision Under Risk]]</text>
      <sha1>b909ap6y2tdzt86dskgtfe3cga0ta01</sha1>
    </revision>
  </page>
  <page>
    <title>Decision Tree Exercises</title>
    <ns>0</ns>
    <id>329</id>
    <revision>
      <id>332</id>
      <timestamp>2015-07-05T16:18:58Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9394">== [[Decision Tree (Decision Theory)|Decision Tree]] Exercises ==
These are exercises given at [[Decision Engineering (ULB)]]


== Exercise 1: Football Team Campaign ==
An university thinks whether to hold a company to promote their football team
* The team has had winning seasons 60% of the time in the past 	
* if the team will have a winning season ($W$) then the university raise 3 mln usd
* if the team will have a losing season ($L$) then they lose 2 mln usd
* if no campaign is taken - there will be no losses
* they have to decide whether to take the campaign or not 


=== Take or Not? ===
We can create a simple lottery that describes the process:
* $W$ - win, $p(W) = 0.6$
* $L$ - lose, $p(L) = 1 - 0.6 = 0.4$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/ru/ex1-simple-lot1.png

Now we need to compare this lottery with another one:
* no campaign, no losses
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/ru/ex1-simple-lot2.png

How we compare these two lotteries?
* with [[Expected Values for Lotteries]]
* launch: $E(C) = 3 \cdot 0.6 + (-2) \cdot 0.4 = 1$
* not launch: $E(\overline{C}) = 0$
* based on expected value we decide to launch


=== [[Perfect Information]] ===
Suppose we hired an Oracle - someone who knows for sure what is going to happen
* how much we want to pay for such an Oracle?

Oracle
* based on past statistics we assume that the oracle will say that
** team loses ($OL$) 40% of time
** them wins ($OW$) 60% of time
* Oracle is always right: 
** if he tells that the team will win ($OW$) it wins, and never loses
** $p(W \mid OW) = 1, p(L \mid OW) = 0$ 
** the same with losing: 
** $p(W \mid OL) = 0, p(L \mid OL) = 1$


So we get this perfect information tree
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/ru/ex1-decision-tree1.png

Now we can calculate the expected gain from having the perfect information:
* $E(PI) = 0.6 \cdot 1 \cdot 3 + 0.6 \cdot 1 \cdot (-2) +  0.4 \cdot 0 \cdot 0 + 0.4 \cdot 1 \cdot 0$
* $E(PI) = 1.8$
* so we may pay him as much as 1.8 - as long as we are not losing, it's good


=== An Expert Consultation ===
But suppose we hire a human being who makes mistakes to help us to predict the outcome
* the consultancy of a football guru costs 0.1 
* we have some statistics about the guru:
** in the past his predictions for winning seasons was correct 75% of time
** for losing seasons - 80% of time

Model:
* we know the statistics about him:
** $p(GW \mid W) = 0.75$ - the probability of the guru saying that the team wins when it indeed wins
** $p(GL \mid L) = 0.8$  - the probability of the guru saying that the team loses when it indeed loses
* we don't know the probabilities
** but we can calculate them 

Here's our decision tree:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/ru/ex1-decision-tree2.png
* need to calculate the probabilities 

Calculating the probabilities
* $p(GW)$
** $p(GW \land \underbrace{[W \lor L]}_\text{true}) = p([GW \land W] \lor [GW \land L]) = ...$
** the events $[GW \land W]$ and $[GW \land L]$ are independent, so can do the following
** $... = p(GW \land W) + p(GW \land L) = ...$ 
** $... = p(GW \mid W) \cdot p(W) + p(GW \mid L) \cdot p(L) = ...$
** now we know all the values - so put them there
** $... = 0.75 \cdot 0.6 + 0.2 \cdot 0.4 = {\color{blue}{0.53}} $
* $p(GL)$
** $p(GL) = 1 - p(GW) = 0.47$
* $p(W \mid GW)$ and $p(L \mid GW)$
** $p(W \mid GW) = \cfrac{p(W \land GW)}{p(GW)} = \cfrac{p(GW \mid W) p(W)}{p(GW)} = ...$
** $... = \cfrac{0.75 \cdot 0.6}{0.53} = 0.8491$
** $p(L \mid GW) = 1 - p(W \mid GW) = 1 - 0.8491 = 0.1509$
* no need to compute $p(W \mid GL)$ and $p(L \mid GL)$ 
** since in this case we don't take any action
** and the outcome in both cases is 0


Now we can compute the expected value:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/ru/ex1-decision-tree3.png
* $E(C) = 3 \cdot 0.8491 - 2 \cdot 0.1509 = 2.2455$
* $E(G) = 0.53 \cdot 2.2455 = 1.1901$
* so this is the expected outcome if we pay the guru
* it costs 0.1 so it's reasonable to pay him
* the net value is then $1.1901 - 0.1 = 1.0901$



== Exercise 2: Sell Now or Later ==
A raider acquired a textile company along with its plant. There are 3 alternatives: 
* $E$: expand the plant and produce the materials for military (with little foreign competition $G$)
* $Q$: maintain the status quo - continue as it is (heavy foreign competition $P$)
* $S$: sell the plant now 

So the model is:
* alternatives are $E, Q, S$
* the states of nature is $G, P$ - good and poor competitive conditions 

The evaluation table (in $10^5$ USD):

{| class=&quot;wikitable&quot;
! Decision || Good Conditions || Poor Conditions
|- 
! $E$ 
| 8 || 5
|- 
! $M$ 
| 13 || -1.5 
|- 
! $S$ 
| 3.2 || 3.2
|}


=== [[Decision Under Uncertainty]] ===
If we are totally uncertain about the outcomes, we may apply the methods from [[Decision Under Uncertainty]]


==== [[Max Min Strategy|Maximin]] and [[Max Max Strategy|Maximax]] ====
{| class=&quot;wikitable&quot;
! $c$ || $G$ || $P$ || max || min
|- 
! $E$ 
| 8  || 5    || 8  || &lt;font color=&quot;blue&quot;&gt;5&lt;/font&gt;
|- 
! $M$ 
| 13 || -1.5 || &lt;font color=&quot;blue&quot;&gt;13&lt;/font&gt; || -1.5
|- 
! $S$ 
| 3.2 || 3.2 || 3.2 || 3.2
|-
| ||  ||     ||  13 || 5
|}

For maximin we take $E$, for maximax we take $M$


==== [[Min Max Regret Strategy|Minimax Regret]] ====
We build the following regret table:

{| class=&quot;wikitable&quot;
! $R$ || $G$ || $P$ || max
|- 
! $E$ 
| 5 || 0 || &lt;font color=&quot;blue&quot;&gt;5&lt;/font&gt;
|- 
! $M$ 
| 0 || 6.5 || 6.5
|- 
! $S$ 
| 9.8 || 1.8 || 9.8
|}

The option that minimizes the regret is $E$


==== [[Hurwitz's Index]] ====
Suppose $\alpha = 0.7$ ($1 - \alpha = 0.3$)
* $\alpha$ in this case refers to the pessimistic (min) condition
* usually we put more weight on the min

{| class=&quot;wikitable&quot;
! $c$ || $G$ || $P$ || max || min || index
|- 
! $E$ 
| 8  || 5    || 8  || 5 || 0.3 * 8 + 0.7 * 5 = &lt;font color=&quot;blue&quot;&gt;5.9&lt;/font&gt;
|- 
! $M$ 
| 13 || -1.5 || 13 || -1.5 || 0.3 * 13 + 0.7 * (-1.5) = 2.89
|- 
! $S$ 
| 3.2 || 3.2 || 3.2 || 3.2 || 0.3 * 3.2 + 0.7 * 3.2 = 3.2
|}


In this case $E$ is the best option

==== [[Laplace Rule]] ====
We assign equal probabilities to the outcomes
* $p(G) = p(P) = 0.5$

{| class=&quot;wikitable&quot;
! $c$ || $G$ || $P$ || index
|- 
! $E$ 
| 8  || 5    || 0.5 * 8 + 0.5 * 5 = &lt;font color=&quot;blue&quot;&gt;6.5&lt;/font&gt;
|- 
! $M$ 
| 13 || -1.5 || 0.5 * 13 + 0.5 * (-1.5) = 5.75
|- 
! $S$ 
| 3.2 || 3.2 || 0.5 * 3.2 + 0.5 * 3.2 = 3.2
|}


Again $E$ is the best option


=== [[Decision Under Risk]] ===
Assume now that we can estimate the probability of each state of nature
* $p(G) = 0.7$ and $p(P) = 0.3$

==== [[Expected Value]] ====
* $E(E) = 0.7 \cdot 8 + 0.3 \cdot 5 = 7.1$
* $E(M) = 0.7 \cdot 13 + 0.3 \cdot (-1.5) = {\color{blue}{8.65}}$
* $E(S) = 0.7 \cdot 3.2 + 0.3 \cdot 3.2 = 3.2$

We want to maximize it, so
* we take $M$ 


==== [[Expected Opportunity Lost]] ====
This is the same, but we calculate [[Expected Value]] on the Regret Table:
* in this case we want to minimize the regret

Expected Values
* $E(E) = 0.7 \cdot 5 + 0.3 \cdot 0 = 3.5$
* $E(M) = 0.7 \cdot 0 + 0.3 \cdot 6.5 = {\color{blue}{1.95}}$
* $E(S) = 0.7 \cdot 9.8 + 0.3 \cdot 1.8 = 7.4$

We want to minimize it, so
* we take $M$


=== [[Perfect Information]] ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/ru/ex2-decision-tree1.png

Suppose we have the perfect information
* so if we know that $G$ happens, we choose $M$ 
* if $P$ happens - we choose $E$

Then the expected value of the perfect information is
* $EV(PF) = 0.7 \cdot 13 + 0.3 \cdot 5 = 1.06$


=== [[Decision Tree (Decision Theory)]] ===
Now suppose that we hire a consultant
* he will report whether to wait for $G$ or $P$
* $RP$ report says to wait for $P$, $RG$ - report says to wait for $G$

We know that the consultant has not always been right:
* $p(RG \mid G) = 0.7$ - in 70% he reported good conditions when conditions indeed were good
* $p(RP \mid P) = 0.8$ - in 80% he reported bad conditions when conditions were indeed bad
* can infer that $p(RP \mid G) = 0.3$ and $p(RG \mid P) = 0.2$
* recall that $p(G) = 0.7$ and $p(P) = 0.3$

So we need to determine the posterior probabilities 
* (by using [[Conditional Probability]] rules)
* $p(RG) = p(G) \cdot p(RG \mid G) + p(P) \cdot p(RG \mid P) = 0.7 \cdot 0.7 + 0.3 \cdot 0.2 = 0.55$
* $p(RP) = 1 - p(RG) = 0.45$
* $p(G \mid PG) = \cfrac{ p(G) \cdot p(RG  \mid  G) }{ p(RG) } = \cfrac{0.7 \cdot 0.7}{0.55} = 0.89$
* $p(P \mid PG) = 1 - 0.89 = 0.11$
* $p(P \mid RP) = \cfrac{ p(P) \cdot p(RP \mid P) }{ p(RP) } = \cfrac{ 0.3 \cdot 0.8}{0.45} = 0.53$
* $p(G \mid RP) = 1 - p(P|RP) = 0.47$

We create a decision tree based on that
* note that if report is good, then the best is to take $M$ (it dominates all the other alternatives)
* the same for bad: $E$ dominates all the other
* therefore we need to include only there alternatives 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/ru/ex2-decision-tree2.png


Now we can calculate the expected value when hiring a consultant
* $E(M) = 0.89 \cdot 13 - 0.11 \cdot 1.5 = 11.405$
* $E(N) = 0.47 \cdot 8 + 0.53 \cdot 5 = 6.41$
* $E(\text{total}) = 0.55 \cdot 11.405 + 0.45 \cdot 6.41 = 9.157$
* this value is what you'll earn on average when hiring a consultant 


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Decision Under Uncertainty]]
[[Category:Decision Under Risk]]</text>
      <sha1>6ihf328cfm9qdyevxzrcu5ra4lq4mug</sha1>
    </revision>
  </page>
  <page>
    <title>Decision Under Uncertainty</title>
    <ns>0</ns>
    <id>330</id>
    <revision>
      <id>333</id>
      <timestamp>2014-01-17T11:49:54Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4306">== Decision Under Uncertainty ==
This is a tool to model [[Decision Analysis]] problems. Unlike [[Decision Under Risk]], here we cannot obtain the probability distribution of possible consequences, can only list the scenarios. 


; Decision Under Uncertainty
* it is impossible to determine with certainty the consequences of implementing an alternative - there are no probabilities 
* ''Nature'' decides what will happen 
** we make a decision and then the Nature decides what is going to happen based on the decision
** this is like a [[Game Theory|two-player game]], where consequences of my actions are based on what the Nature decides to do 



=== The Model ===
Based on that we define the following model:
* $A$ is a set of alternatives
** $a \in A$ is a decision that you may take
* $E$ is a set of states of nature 
** $e \in E$ is a decision that the Nature can take and influence the consequences of at least one alternative $a \in A$
* $X$ is a set of consequences
* $c: A \times E \mapsto X$
** $c(a, e)$ is the consequence of implementing $a$ when the Nature decides to do $e$


=== Decision Table ===
A finite case is usually modeled with a decision table:
* $A$ and $E$ are both finite
* $c(a_i, e_j$ - the consequence of implementing $a_i$ when $e_j$ happens

{| class=&quot;wikitable&quot;
! $c$ || $e_1$ || $e_2 $ || $...$ || $e_n$ 
|- 
! $a_1$ 
| $c(a_1, e_1)$ || $c(a_1, e_2)$ || $...$ || $c(a_1, e_n)$
|- 
! $a_2$ 
| $c(a_2, e_1)$ || $c(a_2, e_2)$ || $...$ || $c(a_2, e_n)$
|- 
! $...$ 
| $...$ || $...$ || ... || $...$
|- 
! $a_n$ 
| $c(a_n, e_1)$ || $c(a_n, e_2)$ || $...$ || $c(a_n, e_n)$
|}

Filling this table in is already very difficult (the same is in [[MCDA]] problems)


== [[Dominance]] ==
Using the dominance principle we can remove a set of actions from $A$
* we can always remove the actions that are dominated 
* the definition is exactly the same as for [[Normal Form Game]]s 
* $a \ D \ b$ - $a$ dominates $b$

; $a \in A$ is ''efficient''
* if $a$ is not dominated by any other alternative

$A^*$ is a set of efficient solutions
* when $A$ and $E$ are finite, can define them $A^*$ as 
* $A^* = \{ a \in A \ | \ \forall  b: \overline{b \ D \ a} \}$
* i.e. $A^*$ is a set of alternatives that are not dominated by any other 
* $A^*$ is always not empty


Problems with Using the Dominance Principle 
* dominated solutions are sometimes also good


== Examples ==
=== Example 1: The Omelet Problem ===
The Game:
* you want to cook an omelet and you have only 6 eggs 
* but you know that the last egg may be bad 
* so there are 2 states of nature: 
** the egg is good ($e_g$) or 
** the egg is bad ($e_b$)
* and we can implement the following actions: 
** put the egg into the omelet without checking it ($a_b$)
** throw the egg away without checking it ($a_t$)
** check the egg: use an additional bowl for it ($a_c$)

{| class=&quot;wikitable&quot;
! $c$ || $e_g$ || $e_b$
|-
! $a_b$ 
| O with 6 eggs || No O
|-
! $a_t$ 
| O with 5 eggs || O with 5 eggs
|-
! $a_c$ 
| O with 6 eggs &lt;br&gt; + a bowl to wash || O with 5 eggs &lt;br&gt; + a bowl to wash
|}

Notes:
* We don't know anything about the probability - just scenarios 
* no way to add additional information


=== Example 2 ===
In this case the consequences are real numbers: 
* $X \equiv \mathbb{R}$
* this is usually the case in such models

{| class=&quot;wikitable&quot;
! $c$ || $e_1$ || $e_2$ || $e_3$ 
|-
! $a_1$ 
| 40 || 70 || -20
|-
! $a_2$ 
| -10 || 40 || 100
|-
! $a_3$ 
| 20 || 40 || -5
|}


== Methods ==
How to make a choice?
* [[Max Min Strategy]] - extreme pessimism 
* [[Max Max Strategy]] - extreme optimism
* [[Hurwitz's Index]] - between the extreme pessimism and the extreme optimism
* [[Min Max Regret Strategy]] - when we want to minimize the regret of a missed opportunity
* [[Laplace Rule]] - the principle of insufficient reasoning


Note that these methods, like in [[Voting Theory]] (see [[Voting Theory Examples]])

{| class=&quot;wikitable&quot;
! $c$ || $e_1$ || $e_2$ || $e_3$ || $e_4$ 
|-
! $a$ 
| 2 || 2 || 0 || 1
|-
! $b$ 
| 1 || 1 || 1 || 1
|-
! $c$ 
| 0 || 4 || 0 || 0
|-
! $d$ 
| 1 || 3 || 0 || 0
|}

Note that in this case all the methods will give different results 
* MinMax - $b$
* MaxMax - $c$
* Laplace - $a$ 
* Savage - $d$


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Decision Under Uncertainty]]</text>
      <sha1>a5nzzla2rdbqps2gt95ako7z153c7fo</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Decision Under Uncertainty</title>
    <ns>14</ns>
    <id>331</id>
    <revision>
      <id>334</id>
      <timestamp>2014-01-17T11:50:17Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="33">[[Category:Decision Engineering]]</text>
      <sha1>ove3cyvlj6kmp2jvatn2y3g0z9phxws</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Decision Under Risk</title>
    <ns>14</ns>
    <id>332</id>
    <revision>
      <id>335</id>
      <timestamp>2014-01-17T11:50:34Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="33">[[Category:Decision Engineering]]</text>
      <sha1>ove3cyvlj6kmp2jvatn2y3g0z9phxws</sha1>
    </revision>
  </page>
  <page>
    <title>Max Min Strategy</title>
    <ns>0</ns>
    <id>333</id>
    <revision>
      <id>336</id>
      <timestamp>2014-01-17T11:51:52Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2718">== Max Min Strategy ==
How to choose an alternative? 
* in [[Game Theory]]
* in [[Decision Under Uncertainty]]


Idea: Extreme Pessimism
* Base your choice on the worst situation that can happen 
* and maximize the consequences in the worst case
* $\max_{a \in A} \min_{e \in E} c(a, e)$


In other words:
* We don't know what will be the state of nature (or the strategy played by the other player)
* But since we're pessimistic, we choose the worst outcome 
* and we want to select the alternatives that are best in the worst case



=== Example 1: [[Decision Under Uncertainty]] ===
Consider the following example:

{| class=&quot;wikitable&quot;
! $c$ || $e_1$ || $e_2$ || $e_3$ || min ||
|-
! $a_1$ 
| 40 || 70 || -20 || -20  || worst case for $a_1$
|-
! $a_2$ 
| -10 || 40 || 100 || -10 || worst case for $a_2$
|-
! $a_3$ 
| 20 || 40 || -5 || 5 || worst case for $a_3$
|-
| || ||    ||  max:  || 5 || $\to a_3$
|}


In the &quot;min&quot; column shows the worst cases for all alternatives
* now we select the maximal value from them 
* and base our decision on it


=== Advantages and Disadvantages ===
Downsides
* bad use of information
** we have a lot of information in the table, but not using only one value from each row
** and the choice is based only on one value
* no compensation between different consequences 
** see an example below 

No Compensation

{| class=&quot;wikitable&quot;
! $c$ || $e_1$ || $e_2$ || ... || $e_{1000}$ || min
|-
! $a$ 
| -100 || 1000 || 1000 || ... || 1000 || -100
|-
! $b$ 
| -99 || -99 || -99 || ... || -99 || -99
|-
!     
|     ||     ||     ||     ||     || '''-99'''  
|}

In this case we choose $b$ 
* although it's clear that $a$ is better at everything 
* it's only a little little bit worse at $e_1$


Advantages:
* no need for rich scale:
** enough to have only an ordinal scale 
** only need to rank the alternatives and take the worst/the best


== Max Min and Min Max ==
; maxmin strategy
* strategy that maximizes player's worst-case payoff
* when others want to cause the greatest harm
* i.e. it maximizes the minimal outcome
* maximin value - guaranteed minimal payoff

; minmax strategy
* of player &lt;math&gt;i&lt;/math&gt; against player &lt;math&gt;-i&lt;/math&gt;
* one that minimizes the maximal value of &lt;math&gt;-i&lt;/math&gt;

; minimax theorem
* in any finite 2-players zero-sum game
* each player receives a payoff that is equal to both
* his minimax and his maximin value
* 0 is a saddle point
* &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/1luv6hbhnsqr0a8bblsdadplgd.png&quot; /&gt;
* ''saddle point'' - where minimax = maximin


== Sources ==
* [[Decision Engineering (ULB)]]
* [[Game Theory (coursera)]]

[[Category:Decision Under Uncertainty]]
[[Category:Game Theory]]</text>
      <sha1>rv5dfa2wc5jiikhukz1r9ejo8idy5nz</sha1>
    </revision>
  </page>
  <page>
    <title>Max Max Strategy</title>
    <ns>0</ns>
    <id>334</id>
    <revision>
      <id>337</id>
      <timestamp>2014-01-17T11:52:49Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1014">== Max Max ==
How to choose an alternative? 
* in [[Game Theory]]
* in [[Decision Under Uncertainty]]


Idea: Extreme Optimism
* the opposite of [[Max Min Strategy]]
* Base your choice on the best situation that can happen 
* and maximize the consequences in the best case
* $\max_{a \in A} \max_{e \in E} c(a, e)$


=== Example: [[Decision Under Uncertainty]] ===
{| class=&quot;wikitable&quot;
! $c$ || $e_1$ || $e_2$ || $e_3$ || max ||
|-
! $a_1$ 
| 40 || 70 || -20 || 70  || best case for $a_1$
|-
! $a_2$ 
| -10 || 40 || 100 || &lt;font color=&quot;red&quot;&gt;100&lt;/font&gt; || best case for $a_2$
|-
! $a_3$ 
| 20 || 40 || -5 || 40 || best case for $a_3$
|-
| || ||    ||  max  || 100 || $\to a_2$
|}


=== Advantages and Disadvantages ===
Same as for [[Max Min Strategy]]

Downsides
* bad use of information
* no compensation between different consequences 

Advantages:
* no need for rich scale, ordinal scale is enough


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Decision Under Uncertainty]]
[[Category:Game Theory]]</text>
      <sha1>fj85fdt8pwtwf8rzunbok0p469krxu4</sha1>
    </revision>
  </page>
  <page>
    <title>Hurwitz's Index</title>
    <ns>0</ns>
    <id>335</id>
    <revision>
      <id>338</id>
      <timestamp>2014-01-17T11:53:10Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1186">== Hurwitz's Index ==
How to choose an alternative? 
* in [[Game Theory]]
* in [[Decision Under Uncertainty]]


Idea: in-between the extreme pessimism and extreme optimism
* this is a &quot;compromise&quot; between [[Max Min Strategy]] and [[Max Max Strategy]]


Coefficient of Pessimism:
* define $\alpha \in [0, 1]$ as the coefficient of pessimism
* then choose the solution $a \in A$ that is the closest to 
* $\max_{a \in A} \big[ \alpha \cdot \min_{e \in E} c(a, e) + (1 - \alpha) \cdot \max_{e \in E} c (a, e)  \big]$  


=== Example: ===
$\alpha = 0.5$

{| class=&quot;wikitable&quot;
! $c$ || $e_1$ || $e_2$ || $e_3$ || $\alpha =0.5$ ||
|-
! $a_1$ 
| 40 || 70 || -20 || (-20 + 70) / 2 || 25
|-
! $a_2$ 
| -10 || 40 || 100 || (-10 + 100) / 2 || 45
|-
! $a_3$ 
| 20 || 40 || -5 || (-5 + 40) / 2 || 17.5
|-
| || ||    ||  max:  || 45 || $\to a_2$
|}


== Downsides ==
* bad use of information
** we combine two approaches ([[Max Min Strategy]] and [[Max Max Strategy]]) that both suffer from bad use of information
* now the scale matters - since we multiply by $\alpha$
* how to determine and justify $\alpha$?


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Decision Under Uncertainty]]</text>
      <sha1>tczz98s6v66y664uxfqivbvonbrcfse</sha1>
    </revision>
  </page>
  <page>
    <title>Min Max Regret Strategy</title>
    <ns>0</ns>
    <id>336</id>
    <revision>
      <id>339</id>
      <timestamp>2014-01-17T11:53:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3090">== Min Max Regret Strategy ==
How to choose an alternative? 
* in [[Game Theory]]
* in [[Decision Under Uncertainty]]

This principle is also called the Savage's Opportunity Loss principle. 


Idea:
* instead of calculating the maximal gain (like in [[Max Max Strategy]]) or maximal loss ([[Max Min Strategy]]) we calculate the regret
* use this measure to decide which option to choose
* we don't want to experience a lot of regret, so we will minimize the maximal regret we have 
* so it's similar to  [[Max Min Strategy]], but instead of utility we use regret


Regret
** ''regret'' is a measure that shows how we regret choosing some alternative $a$ to another alternative $a^*$ after $e \in E$ happens
* imagine that $e$ happens and the best alternative in this case is $a^*$
* but we chose $a$
* so our regret is $c(e, a^*) - c(e, a)$
* it we chose $a^*$ then our regret is 0


So define regret as 
: $R(a, c) = max_{b \in A} \big[ c(b, e) - c(a, e) \big]$


We choose such $a \in A$ that:
* $\min_{a \in A} \max_{e \in E} R(a, e)$


Remarks
* it must be meaningful to make differences for calculating regret
* so the scale should be numerical, not ordinal 


=== Example ===
Suppose we have the following matrix:

{| class=&quot;wikitable&quot;
! $c$ || $e_1$ || $e_2$ || $e_3$
|-
! $a_1$ 
| 40 || 70 || -20
|-
! $a_2$ 
| -10 || 40 || 100
|-
! $a_3$ 
| 20 || 40 || -5
|}


* if $e_1$ happens, the regret of choosing $a_1$ is 0 
** $a_1$ is the best for $e_1$
* if $e_1$ happens, the regret of choosing $a_2$ is 50
**  40-(-10) = 50 
** the best value for $e_1$ is the value for $a_1$, which is 40

So this way we compute a regret matrix:

{| class=&quot;wikitable&quot;
! $R$ || $e_1$ || $e_2$ || $e_3$ || max 
|-
! $a_1$ 
| 0 || 0 || 120 || 120
|-
! $a_2$ 
| 50 || 30 || 0 || &lt;font color=&quot;blue&quot;&gt;50&lt;/font&gt;
|-
! $a_3$ 
| 20 || 30 || 105 || 105
|}


In this case the alternative $a_2$ minimizes the maximal possible regret, so we choose it 


== Manipulation ==
This method does not satisfy the principle of [[Independence to Third Alternatives]] from the [[Voting Theory]]
* adding or removing alternatives may alter the choice in unpredicted ways

Example 

{|
|
  {|  class=&quot;wikitable&quot;
   ! $c$ || $e_1$ || $e_2$
   |-
   ! $a_1$
   | 8 || 0
   |-
   ! $a_2$
   | 2 || 4
  |}
|
  {|  class=&quot;wikitable&quot;
   ! $R$ || $e_1$ || $e_2$ || max
   |-
   ! $a_1$
   | 0 || 4 || &lt;font color=&quot;blue&quot;&gt;4&lt;/font&gt;
   |-
   ! $a_2$
   | 6 || 0 || 6
  |} 
|}

Now $a_1$ wins - so we choose it


But what if we add a third alternative?

{|
|
  {|  class=&quot;wikitable&quot;
   ! $c$ || $e_1$ || $e_2$
   |-
   ! $a_1$
   | 8 || 0
   |-
   ! $a_2$
   | 2 || 4
   |-
   ! $a_3$
   | 1 || 7
  |}
|
  {|  class=&quot;wikitable&quot;
   ! $R$ || $e_1$ || $e_2$ || max
   |-
   ! $a_1$
   | 0 || 7 || 7
   |-
   ! $a_2$
   | 6 || 3 || &lt;font color=&quot;blue&quot;&gt;6&lt;/font&gt;
   |-
   ! $a_3$
   | 7 || 0 || 7
  |} 
|}

But now $a_2$ wins!


== [[Expected Opportunity Lost]] ==
Similar idea:
* we calculate the expected value on the regret table


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Decision Under Uncertainty]]
[[Category:Game Theory]]</text>
      <sha1>bdwkhzhjl9dqmkjuwx2ytvb9pt33m8a</sha1>
    </revision>
  </page>
  <page>
    <title>Laplace Rule</title>
    <ns>0</ns>
    <id>337</id>
    <revision>
      <id>340</id>
      <timestamp>2014-01-17T11:55:00Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2031">== Laplace Rule ==
How to choose an alternative in [[Decision Under Uncertainty]]? The Laplace Rule, also called the Principle of Insufficient Reasoning, helps to do that.


=== Main idea ===
* (using notation from [[Decision Under Uncertainty]])
* since there is no way to assess probabilities in [[Decision Under Uncertainty]] models - assume the uniform distribution
* so each state of nature $e \in E$ is expected to happen with probability $1 / |E|$
* and we compute the expected values of the consequences based on these probabilities


So,
* choose $a \in A$ that solves the following:
* $\max_{a \in A} \sum_{e \in E} \cfrac{1}{|E|} c(a, e)$


=== Example ===
Consider this matrix:

{| class=&quot;wikitable&quot;
! $c$ || $e_1$ || $e_2$ || $e_4$ || 
|-
! $a_1$ 
| 40 || 70 || -20 || 90/3
|-
! $a_2$ 
| -10 || 40 || 100 || &lt;font color=&quot;blue&quot;&gt;130/3&lt;/font&gt;
|-
! $a_3$ 
| 20 || 40 || -5 || 55/3
|}


So we choose $a_2$ because it gives the best result on average


=== Remarks ===
* it must be meaningful to make a linear combination of the consequences 
** i.e. the scale should be numerical
* the principle should be used with caution
** you either become the king of Belgium or not - are these events equally likely?

=== Manipulation ===
can manipulate the results by adding new alternatives 
* ([[Independence to Third Alternatives]] is not satisfied)

Suppose we have two scenarios:
* $E$ and $\overline{E}$
** by the principle we have $P(E) = P(\overline{E}) = 0.5$
* suppose we modify an alternative by adding something that is always true
** $\overline{E} \equiv \overline{E} \land (R \lor \overline{R})$
** then we can distribute the OR and have $[\overline{E} \land R] \lor [\overline{E} \land \overline{R}]$
* so now we have 3 alternatives:
** $E$, $\overline{E} \land R$ and $\overline{E} \land \overline{R}$
** and now $P(E) = P(\overline{E} \land R) = P(\overline{E} \land \overline{R}) = 1/3$
* i.e. we've manipulated the results



== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Decision Under Uncertainty]]</text>
      <sha1>ear5vapp6tf200m7s7gz25o36y0gh79</sha1>
    </revision>
  </page>
  <page>
    <title>Saint Petersburg Paradox</title>
    <ns>0</ns>
    <id>338</id>
    <revision>
      <id>341</id>
      <timestamp>2014-01-17T11:56:11Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1009">== Saint Petersburg Paradox ==
Consider the following game:
* a &quot;banker&quot; $B$ plays with a &quot;player&quot; $P$
* $P$ must pay some fixed sum to enter the game
* $B$ flips a coin until TAILS appear - then the game stops 
* $B$ pays $2^n$ euro to $P$ if the game stops on $n$th toss

How much a rational should be willing to pay to play the game?
* [[Expected Value]] could be a good model to estimate the costs for entering the game 

{| class=&quot;wikitable&quot;
! Seq || Gain || Prob
|-
| $T$ || $2^1$ || $0.5$
|-
| $HT$ || $2^1$ || $0.5^2$
|-
| $HHT$ || $2^2$ || $0.5^3$
|-
| ... || ... || ...
|-
| $\underbrace{H..H}_{n}T$ || $2^n$ || $0.5^n$
|}

Let's calculate the expected value
* $EV = 2 \cdot \cfrac{1}{2} + 2^2 \cdot \cfrac{1}{2^2} + 2^3 \cdot \cfrac{1}{2^3} + ... = \infty$
* so the expected value is $\infty$ with just 50% chance to win only 2 euro
* clearly this is not good enough to model such situation


== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Decision Under Risk]]
[[Category:Probability]]</text>
      <sha1>kclcp32wjzct0mrhosb8jiob2byqhpm</sha1>
    </revision>
  </page>
  <page>
    <title>Zero Sum Game</title>
    <ns>0</ns>
    <id>339</id>
    <redirect title="Pure Competition Game" />
    <revision>
      <id>342</id>
      <timestamp>2014-01-17T11:57:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="50">#redirect [[Pure Competition Game#Zero Sum Games]]</text>
      <sha1>n2r3h26jztelihyvz4dpriim1f55wbu</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Game Theory</title>
    <ns>14</ns>
    <id>340</id>
    <revision>
      <id>343</id>
      <timestamp>2014-01-18T12:03:45Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="33">[[Category:Decision Engineering]]</text>
      <sha1>ove3cyvlj6kmp2jvatn2y3g0z9phxws</sha1>
    </revision>
  </page>
  <page>
    <title>Active Databases</title>
    <ns>0</ns>
    <id>341</id>
    <revision>
      <id>344</id>
      <timestamp>2015-07-05T16:15:03Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7773">== Active Databases ==
In contrast to passive databases, in active databases, execution of actions can be triggered in response to some monitored events 
* database updates and inserts 
* points in time
* etc


== Triggers ==
Usually there are some rules in such databases that react on the external events

=== Event - Condition - Action ===
* when an event occurs 
* if a condition holds 
* then an action is performed 


Example
* event: customer has not paid 3 invoices at the due date
* condition: the credit limit is less than 20k euros 
* cancel all current orders of this customer


=== Rule Triggers ===
These rules are usually expressed via triggers in databases 

* a trigger may cause another trigger to fire 
rollback - abort the transaction that caused the triggered event 


=== Applications ===
Rules usually express various aspects of application semantics and are typically used for maintaining [[Consistency (databases)]]
* static constrains 
** referential integrity
** value constraints 
* business rules
* historical data 
** like all data about complete orders should be moved to a [[Data Warehouse]]
* Management of Derived Data

==== Management of Derived Data ====
An important application of triggers in [[Active Databases]]

This includes:
* materialized attributes
* [[View Materialization|materialized views]]
* [[Replication|replicated]] data


Derived Data:
* ''Views'': a query on the database that can be used as a relation in other queries 
* ''Derived attributes'': values that are computed from other values 

There are two strategies for derived data
* virtually supported - computed on demand (virtual tables)
* [[View Materialization|materialized]] - stored in a database and must be recomputed whenever the source data changes 


=== Semantics ===
Triggers are usually a part of transaction 

Levels of granularity
* statement-level
** executed once per statement 
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/ad-statement-level.png
* row-level (or tuple-level)
** a rule is triggered line-by-line
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/ad-granularity.png

Triggering types:
* Before triggers
** executed before the modification of a row
** in some databases (DB2) cannot modify the DB
* After triggers
** executed after the modification
* Instead-Of triggers
** when action on one table is replaced on different action
** typically used for managing derived data


Execution mode:
* deferred 
** all triggered rules are put in a conflict set 
** once a transaction finishes, the triggers are executed 
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/ad-deferred-ex.png
* immediate 
** just after the modification


== Oracle ==
It supports 
* both row-level and row-level
* both before triggers and after triggers

Rule processing algorithm
# execute the statement-level before triggers
# for each row affected by the triggering statement
## execute the row-level before triggers
## execute the modification of the row, check constraints and assertions
## execute the row-level after triggers
# perform statement-level assertion checking
# execute statement-level after trigger


* the modification may trigger another rules 
** then the execution of the current statement is suspended
** the maximum number of active triggers in a chain is 32
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/ad-execution-oracle.png

Partial rollback
* it's possible to rollback only one statement instead of the whole transaction 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/ad-perstatement-rollback.png


== MS SQL Server Triggers ==
The execution of triggers is immediate in MS SQL 
* triggers are executed after an instruction (not after each row or each transaction)

Types:
* After: after the instruction takes place
* Instead Of: executes some custom code instead of the instruction


=== Syntax ===
&lt;pre&gt;CREATE TABLE &lt;name&gt;
ON &lt;table&gt;
{AFTER | INSTEAD OF} &lt;list of events&gt;
as 
&lt;transact-SQL code&gt;&lt;/pre&gt;


Special tables that can be used inside triggers: 
* &lt;code&gt;Inserted&lt;/code&gt; - new or updated rows of the triggered transaction
* &lt;code&gt;Deleted&lt;/code&gt; - deleted rows (or rows with old state for updates) of the triggered transaction


=== Examples ===
==== Example 1 ====
consider the following schema:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/ad-example-schema.png 

Constraint:
* PhD Students must work in the same laboratory as their supervisors

Events that may violate this constraint:
* (a) insert into &lt;code&gt;PhDStudent&lt;/code&gt;
* (b) update of &lt;code&gt;Laboratory&lt;/code&gt; or &lt;code&gt;Supervisor&lt;/code&gt; in &lt;code&gt;PhDStudent&lt;/code&gt;
* (c) update of &lt;code&gt;Laboratory&lt;/code&gt; in &lt;code&gt;Professor&lt;/code&gt;
* (d) delete from &lt;code&gt;Professor&lt;/code&gt;


Events (a) and (b):

&lt;pre&gt;create trigger StudSameLabAsSuperv_PhDStud_InsUpd_Abort
-- EVENT
on PhDStudent
after insert, update
as
-- CONDITION
if exists (
     select * from Inserted I, Professor P
      where P.ProfNo = I.Supervisor
        -- and not the same laboratory
        and P.Laboratory &lt;&gt; I.Laboratory)
begin
-- ACTION
    raiserror 13000 'Constraint Violation:
              A PhD student must work in the same
              laboratory as his/her supervisor'
    rollback
end
&lt;/pre&gt;


Event (c) 
&lt;pre&gt;create trigger StudSameLabAsSuperv_Prof_Upd_Abort
on Professor
after update
as
if exists (
    -- if there exists a student who is supervised
    -- by professor who works in different lab
    select * from Inserted I, PhDStudent S
     where I.ProfNo = S.Supervisor
       and I.Laboratory &lt;&gt; S.Laboratory)
begin
    raiserror 13000 'Constraint Violation:
              A PhD student must work in the same
              laboratory as his/her supervisor'
    rollback
end&lt;/pre&gt;


Event (d)
* A DBMS system will not allow this if there's a foreign key


==== Example 2 ====
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/ad-example-schema-2.png

; The age of employees must be greater than 18
* this can be done with &lt;code&gt;CHECK&lt;/code&gt; constraint

&lt;pre&gt;alter table Employee
add constraint employee_Age18
check (dateadd(year, 18, BDate) &lt;= getdate())
&lt;/pre&gt;


; The attribute &lt;code&gt;Department.NbrEmployees&lt;/code&gt; is derived from &lt;code&gt;Employee.DNo&lt;/code&gt;
* can recalculate everything
* or update incrementally

&lt;pre&gt;create trigger DeptNbrEmp_Employee_InsUpdDel_Derive
on Employee
after insert, update, delete
as
begin
  update Department D
  set    NbrEmployees = (select Count(*)
                         from   Employee E
                         where  E.DNo = D.DNumber)
  where  D.DNumber in (select distinct I.DNo
                       from   Inserted I)
      or D.DNumber in (select distinct D.DNo
                       from   Deleted D)
end&lt;/pre&gt;

Incremental version

&lt;pre&gt;create trigger derived_Department_NbrEmployees_Employee
on Employee
after insert, update, delete
as
begin
  update Department
  set  NbrEmployees = NbrEmployees
      + (select count(*) from Inserted I
         where  DNumber = I.DNo) 
      - (select count(*) from Deleted D
         where  DNumber = D.DNo)
  where  DNumber in (select DNo from Inserted)
      or DNumber in (select DNo from Deleted)
end&lt;/pre&gt;


Now also need to ensure that no one can modify this attribute

&lt;pre&gt;create trigger derived_Department_NbrEmployees_Department
on Department
after insert, update
as
if exists (select *
   from   Inserted
   where  NbrEmployees &lt;&gt; 
     (select count(*) from  Employee E
      where E.DNo = DNumber))
begin
  raiserror 13008 'Constraint Violation: 
        The attribute Department.NbrEmployees is a derived attribute from Employee.DNo'
  rollback
end  
&lt;/pre&gt;


== Sources ==
* [[Advanced Databases (ULB)]]

[[Category:Databases]]</text>
      <sha1>95tjhb5ez26re8o6a7aok5yxi3oda0t</sha1>
    </revision>
  </page>
  <page>
    <title>Replication</title>
    <ns>0</ns>
    <id>342</id>
    <revision>
      <id>345</id>
      <timestamp>2014-01-19T15:42:19Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2603">== Replication ==
Replication is a process of updating the same information stored in [[Distributed Databases]]
* so all servers have the up-to-date information

Strategies
* synchronized copies 
** costly, often unnecessary
** use [[Two-Phase Commit]] or similar strategies
** i.e. need asynchronous techniques for this 


== Asynchronous Replication ==
=== Asymmetric Replication ===
Main idea:
* one primary copy where all changes are performed
* several secondary copies that do not accept writes - only reads 
* secondary copies are updated asynchronously with the primary one 

Modules
* capture module: monitors changes made to the primary copy
* application module: propagates changes to the secondary copies


=== Symmetric Replication ===
* all copies accept updates 
* each can have both capture and application modules
* but simultaneous updates may cause loss of [[Consistency (databases)|consistency]]
** i.e. the copies may be inconsistent during some period of time 
* this leans to another notion of consistency: [[Eventual Consistency]]


Examples
* withdrawal in an ATM 
** not instant - it takes some time for changes to propagate to every database 
** so it's not consistent during some period of time until changes are eventually propagated
** https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/adb/ad-replication-2.png
* suppose we have a network
** and in for one server the net goes down
** this branch still continue working with database: updates are performed locally
** when the network is restored, the changes are propagated
** https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/adb/ad-replication.png


== Ways of Replicating ==
=== Replication with Triggers ===
In [[Active Databases]] this can be done with triggers
* so we accumulate positive and negative changes into &lt;code&gt;PosDelta&lt;/code&gt; and &lt;code&gt;NegDelta&lt;/code&gt;
* then these deltas are applied to the secondary copies 


&lt;pre&gt;CREATE RULE Capture1 ON Primary
WHEN INSERTED
THEN INSERT INTO PosDelta (SELECT * FROM INSERTED)

CREATE RULE Capture2 ON Primary
WHEN DELETED
THEN INSERT INTO NegDelta (SELECT * FROM DELETED)

CREATE RULE Capture3 ON Primary
WHEN UPDATED
THEN INSERT INTO PosDelta (SELECT * FROM INSERTED);
	INSERT INTO NegDelta (SELECT * FROM DELETED);
&lt;/pre&gt;



=== Replication with Logs ===
[[Redo Logging]] or [[Undo/Redo Logging]] mechanisms can be used to do that
* keep track on all committed changes
* eventually apply them to the secondary copies


== Sources ==
* [[Advanced Databases (ULB)]]

[[Category:Distributed Systems]]
[[Category:Databases]]</text>
      <sha1>19rxiu6ty9kel9duk7boc0dzm54ya3r</sha1>
    </revision>
  </page>
  <page>
    <title>View Materialization</title>
    <ns>0</ns>
    <id>343</id>
    <revision>
      <id>346</id>
      <timestamp>2015-04-19T11:19:54Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="373">{{stub}}

== View Materialization ==


== Keeping Up-to-Date ==
Usually is done with [[Active Databases|triggers]]

Two basic strategies:
* refresh - drop and re-create again 
** simple, but expensive 
* incremental 
** compute positive and negative changes and apply to the view
** can be very complex


== Sources ==
* [[Advanced Databases (ULB)]]

[[Category:Databases]]</text>
      <sha1>s01te2spwneu7szo03f5o5f1huq8dus</sha1>
    </revision>
  </page>
  <page>
    <title>Temporal Databases</title>
    <ns>0</ns>
    <id>344</id>
    <revision>
      <id>347</id>
      <timestamp>2014-01-20T13:33:03Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="736">== Temporal Databases ==
There are many applications that need temporal aspects in many domains. 

Usually they are used for:
* versioning
* specifying some periods of time
* etc


=== Time and Facts ===
Valid time of a fact:
* when the fact is (was, will be) true in the modeled reality
* independent of the transaction time 
* can be past, present, future
* (link to [[Slowly Changing Dimensions]])?

Transaction time of a fact:
* when the fact was recorded in a database



=== Temporal ER Diagrams ===
Conceptual Modeling of Temporal aspects: 
* [[Temporal Entity-Relationship Model]]


=== Querying ===
How to query a temporal database?
* [[Sequenced Queries]]


== Sources ==
* [[Advanced Databases (ULB)]]

[[Category:Databases]]</text>
      <sha1>jo26r7easz5gj92a15foh14s4wnny0n</sha1>
    </revision>
  </page>
  <page>
    <title>Temporal Entity-Relationship Model</title>
    <ns>0</ns>
    <id>345</id>
    <revision>
      <id>348</id>
      <timestamp>2015-07-05T16:08:38Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4538">== Temporal Entity-Relationship Model ==
This is an extension of [[Entity-Relationship Model|ER-Diagrams]] to [[Temporal Databases]]. 

Example:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-er-temp-ex1.png
* temporality can be added to attributes, entities and relationships


== Translation to [[Relational Databases|Relational]] Schema ==
=== Entities and Lifecycles ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-er-temp-entity.png

If an entity is temporal, we create an additional table EntityLifecycle
* where we keep all changes 
* a lifecycle shows the state at some period of time of this entity

&lt;code&gt;Employee&lt;/code&gt;
{| class=&quot;wikitable&quot;
! Name || BirthDate || Address || Salary || Projects
|-
| Peter || 8/9/64 || Rue de la Paix || 5000 || {MADS, HELIOS}
|}

&lt;code&gt;EmployeeLifecycle&lt;/code&gt;
{| class=&quot;wikitable&quot;
! Name || FromDate || ToDate || Status
|-
| Peter || 7/94 || 6/96 || Active
|-
| Peter || 7/96 || 6/97 || Suspended
|-
| Peter || 7/97 || 6/98 || Active
|}


Note that there could be several type of lifecycle tables
* Continuous (not intermittent)
* Discontinuous (can be intermittent and after a while continued)
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-continious.png


=== Temporal Attributes ===
Translating attributes
* If there's a clock then we keep the history of all changes to this attribute
* If not - the attribute is not temporal and we keep only the current version


https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-er-temp-atr.png
* Each temporal attribute is modeled with a separate table


&lt;code&gt;Employee&lt;/code&gt;
{|  class=&quot;wikitable&quot;
! Name || BirthDate
|- 
| Peter || 8/9/64
|}

&lt;code&gt;EmployeeLifecycle&lt;/code&gt;
{|  class=&quot;wikitable&quot;
! Name || FromDate || ToDate
|- 
| Peter || 7/94 || 7/98
|}

&lt;code&gt;EmployeeAddress&lt;/code&gt;
{|  class=&quot;wikitable&quot;
! Name || Address || FromTime || ToTime 
|- 
| Peter || Bd St Germain || 1/85 || 12/87
|- 
| Peter || Bd St Michel || 1/88 || 12/94
|- 
| Peter || Rue de la Paix || 1/95 || now
|}

&lt;code&gt;EmployeeSalary&lt;/code&gt;
{| class=&quot;wikitable&quot;
! Name || Salary || FromTime || ToTime
|- 
| Peter || 4000 || 7/94 || 7/95
|- 
| Peter || 5000 || 8/95 || now
|}

&lt;code&gt;EmployeeProjects&lt;/code&gt;
{| class=&quot;wikitable&quot;
! Name || Projects || FromTime || ToTime
|- 
| Peter || {MADS} || 7/94 || 8/95
|- 
| Peter || {MADS, HELIOS} || 9/95 || now
|}


https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-er-temp-atr2.png
* there's a clock for the &lt;code&gt;manager&lt;/code&gt; - so it's temporal
* when updating &lt;code&gt;manager&lt;/code&gt; - adding an element to the manager history
* when updating &lt;code&gt;project.name&lt;/code&gt; - just update the name 
* when updating the &lt;code&gt;project&lt;/code&gt; - just update the name, but start a new history for manager


=== Generalization ===
Temporality is inherited

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-er-temp-inheritance1.png
* Temporary and &lt;code&gt;Permanent&lt;/code&gt; are implicitly temporal
* they inherit temporality from &lt;code&gt;Employee&lt;/code&gt; but use the lifecycle of &lt;code&gt;Employee&lt;/code&gt; (don't have their own)

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-er-temp-inheritance2.png
* but in this case &lt;code&gt;Student&lt;/code&gt; and &lt;code&gt;Faculty&lt;/code&gt; have their own lifecycles 


=== Relationships ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-er-temp-rel.png
* note that the one-to-many relationship is temporal
* and it has a temporal attribute

&lt;code&gt;Employee&lt;/code&gt;
{| class=&quot;wikitable&quot;
! Name || BirthDate || Address
|-
| John || 3/7/55 || Bd Haussman
|-
| Peter || 8/10/64 || Rue de la Paix
|}

&lt;code&gt;WorksOn&lt;/code&gt;
{| class=&quot;wikitable&quot;
! Employee || Project || Hours 
|-
| John || HELIOS 
| 
  {| class=&quot;wikitable&quot;
   | 30 || x/x/x || x/x/x  
   |}
|-
| John || MADS 
| 
  {| class=&quot;wikitable&quot;
   | 25 || x/x/x || x/x/x  
   |-
   | 35 || x/x/x || x/x/x  
   |}
|-
| Peter || MADS 
| 
  {| class=&quot;wikitable&quot;
   | 25 || x/x/x || x/x/x  
   |-
   | 35 || x/x/x || x/x/x  
   |}
|}

&lt;code&gt;Project&lt;/code&gt;
{| class=&quot;wikitable&quot;
! Name || Manager || Budget
|-
| MADS || Christine || 5000
|-
| HELIOS || Yves || 6000
|}

* lifecycles for &lt;code&gt;Employee&lt;/code&gt;, &lt;code&gt;WorksOn&lt;/code&gt; and &lt;code&gt;Project&lt;/code&gt; are not shown here
* if &lt;code&gt;WorksOn&lt;/code&gt; wasn't temporal, it wouldn't have a lifecycle
* same for &lt;code&gt;Employee&lt;/code&gt; and &lt;code&gt;Project&lt;/code&gt;


== Sources ==
* [[Advanced Databases (ULB)]]

[[Category:Relational Databases]]
[[Category:Databases]]</text>
      <sha1>43lsaumke8jvprfcux2rmfxdr85dd25</sha1>
    </revision>
  </page>
  <page>
    <title>Entity-Relationship Model</title>
    <ns>0</ns>
    <id>346</id>
    <revision>
      <id>349</id>
      <timestamp>2015-07-05T16:10:15Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6465">== Entity-Relationship Model ==
An entity–relationship model (ER model) is a [[Data Model]] for describing a [[Database]] in an abstract way at a conceptual level. 

A database can be modeled as 
* a collection of entities plus
* the relationships between the entities 


=== Definitions ===
''Entity'' is an object that exists and is distinguishable from other objects
* e.g. a company, an event, a person
* entities have attributes 

An ''entity set'' is a set of entities of the same type that share the same properties 
* set of all people, companies, events

A ''relationship'' is an association between several entities 
* for example &quot;student&quot; entity -- advisor (relationship) -- &quot;instructor&quot; entity

A relationship set is a set of relations between two specific entities 
* e.g. (studentId, instructorId) $\in$ advisor


An entity is represented by a set of ''attributes'' 
* an attribute is a descriptive property that all members of this entity set have 
* e.g. &lt;code&gt;instructor=(ID, name, street, city, salary)&lt;/code&gt;
* &lt;code&gt;course=(ID, title, credits)&lt;/code&gt;

''Domain'' is a set of permitted values for each attribute


Types of attributes:
* simple or composite 
* single-valued or multi-valued
* derived (computed from other values)
** e.g. age given the date of birth
* composite attributes consist of other attributes (that also in turn may be composite)


; Keys
A ''super key'' of an entity set is a set of one or more attributes 
* these attributes must uniquely identity each entity

A ''candidate key'' of an entity set is a minimal possible super key
* e.g. id of an instructor
* although there could be several candidate keys, one must be selected to be a ''primary key'' 

''Relationships primary keys''
* The combination of primary keys for entities that participate in a relationship form a primary key for that relationship
* e.g. (s_id, i_id) is a superkey for advisor



== E-R Diagrams ==
=== Basic Notation ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/er-example1.png
* rectangles represent entity sets 
** attributes are listed inside
** primary key attributes are underlined 
* diamonds represent relationship sets 
** a relationship set may have attributes 

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/er-example2.png
* complex attributes are shown with indent 
* &lt;code&gt;{}&lt;/code&gt; is used to show multivalued attributes 
* &lt;code&gt;()&lt;/code&gt; shows that an attribute is derived


https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/er-example-3.png
* directed line shows relationship with cardinality &quot;one&quot;
* undirected line - cardinality &quot;many&quot;
* alternatively, we can use cardinality limits 


https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/er-example-4.png
* this is called &quot;total participation&quot;
** indicated by a double line 
** means: every entity set participates in at least one relationship
* opposite is &quot;partial participation&quot;
** some entities may not participate in any relationship


=== Weak Entity Sets ===
An entity set that does not have a primary key is a ''weak entity set''
* the existence of a weak entity set depends of ''identifying entity set''
* it must relate to the identifying entity set via a total one-to-many relationship set

''Discriminator (or partial key)'' of a weak entity set
* this is the set of attributes that distinguishes an entity among another entities 

So the primary key of such entities is formed by:
* the primary key of the strong entity (on which the weak one depends)
* the discriminator of the weak entity

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/er-example-5.png
* discriminator is underlined with a dashed line
* identifying relationship is shown with a double diamond
* in this case the primary key for section is (&lt;code&gt;course_id, sec_id, semester, year&lt;/code&gt;)

Note:
* the primary key of the strong entity set should not be stored explicitly with the weak entity set
* if &lt;code&gt;course_id&lt;/code&gt; was stored in the weak entity, section then should be a strong entity
* a weak entity cannot exist without an owner [stackoverflow.com/questions/4741967]
** example: a ROOM can only exist in a BUILDING
** a TIRE, on the other hand, can be a strong entity because it can exist without a car 
** QUESTION is strong - it always exists, but ANSWER is weak - there have to be a QUESTION for an ANSWER


Example:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/er-example-7.png


== Reduction to [[Relational Databases|Relational]] Schema ==
Entity sets and relationship sets can be expressed as relational schemas
* attributes of each schema typically correspond to attributes of entities and relationships 

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/er-example-6.png 

Translation
* strong entity becomes a schema with the same attributes
** student(&lt;u&gt;ID&lt;/u&gt;, name, tot_credit)
* weak entity becomes a table that includes a column for the PK pf the identifying entity set 
** section(&lt;u&gt;course_id, sec_id, sem, year&lt;/u&gt;)
* a many-2-many relationship set is represented as a schema with 
** attributes for all the primary keys of all participating entities + 
** descriptive attributes of the relationship set 
* many-2-one and one-2-many relationship sets can be represented by adding extra attribute to the &quot;many&quot; side
* instead of creating a schema for relationship set &lt;code&gt;inst_dept&lt;/code&gt; we add an attribute &lt;code&gt;dept_name&lt;/code&gt; to the schema for instructor
* for one-to-one relationship any side can be chosen to act as the &quot;many&quot; side
** that is, an extra attribute is added to either side of the schema
* if participation is partial on the &quot;many&quot; side
** extra attributes may point to &lt;code&gt;NULL&lt;/code&gt; values



== Exercises ==
=== Exercise 1 ===
Car insurance company
* each customer has one or more cars 
* each car is associated with zero or more accidents 
* each insurance policy covers one or more cars and has one or more premium payments associated with a car 
* each payment is for particular period of time and has a due date and the date when payment is received


https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/er-example-8.png



== Sources ==
* Database Systems Concept, slides for chapter 7 [http://codex.cs.yale.edu/avi/db-book/db6/slide-dir/index.html]: Most of the figures are taken from there
* [[Data Warehousing (ULB)]]

[[Category:Relational Databases]]
[[Category:Databases]]</text>
      <sha1>7etpijzsmwxg6b7p8vpi0tz2uv4j2p2</sha1>
    </revision>
  </page>
  <page>
    <title>Sequenced Queries</title>
    <ns>0</ns>
    <id>347</id>
    <revision>
      <id>350</id>
      <timestamp>2015-07-05T16:26:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14789">== Sequenced Queries ==
[[Temporal Databases]] provide mechanisms to store and manipulate time-varying information. But how to query it?


=== Valid Time Tables ===
A valid time table is a table with 
* attributes that specify a period when the information in these tables were valid
* in SQL92 it's usually modeled with 2 date attributes &lt;code&gt;from&lt;/code&gt; and &lt;code&gt;to&lt;/code&gt;

For example,
* &lt;code&gt;Employee(SSN, FirstName, LastName, BirthDate)&lt;/code&gt;
* &lt;code&gt;Position(PCN, JobTitle)&lt;/code&gt;
* &lt;code&gt;Incumbents(SSN, PCN, FromDate, ToDate)&lt;/code&gt;
* &lt;code&gt;Salary(SSN, Amount, FromDate, ToDate)&lt;/code&gt;
* &lt;code&gt;Incumbents&lt;/code&gt; and &lt;code&gt;Salary&lt;/code&gt; are valid-time tables 


==== Example ====
Consider this table:

Incumbents
{| class=&quot;wikitable&quot;
! SSN || PCN || FromDate || ToDate
|-
| 111223333 || 900225 || 1996-01-01 || 1996-06-01
|-
| 111223333 || 900225 || 1996-06-01 || 1996-08-01
|-
| 111223333 || 900225 || 1996-08-01 || 1996-10-01
|-
| 111223333 || 900225 || 1996-10-01 || 3000-01-01
|-
| 111223333 || 900225 || 1997-01-01 || 3000-01-01
|}

This is a valid time table:
* it has attributes from and to that show when this information is valid
* special date &lt;code&gt;3000-01-01&lt;/code&gt; is used to show &quot;currently valid&quot; (i.e. till now)
* Closed-open periods are typically used:
** it makes it easier to merge in SQL: just do $T_1.\text{to} = T_2.\text{from}$


=== Type of Queries ===
On Valid-Time tables we can query for:
* current state: now 
* time-sliced: valid at some point of time
* sequenced: applied to each point in time
* non-sequenced: applied to all points in time, completely ignoring temporal aspects


== Temporal Keys and Constraints ==
Consider this table again:

Incumbents
{| class=&quot;wikitable&quot;
! SSN || PCN || FromDate || ToDate
|-
| 111223333 || 900225 || 1996-01-01 || 1996-06-01
|-
| 111223333 || 900225 || 1996-06-01 || 1996-08-01
|}

What are keys that we can use to uniquely identify a record in this table?
* candidate keys: 
** &lt;code&gt;(SSN, PCN, FromDate)&lt;/code&gt;
** &lt;code&gt;(SSN, PCN, ToDate)&lt;/code&gt;
** &lt;code&gt;(SSN, PCN, FromDate, ToDate)&lt;/code&gt;

But we want to enforce the following constraint:
* An employee can have only one position at a point of time
* none of these keys can enforce such a constraint 

=== Sequenced Primary Key ===
This can only be enforced with [[Active Databases|triggers]]


{|
|
&lt;pre&gt;
CREATE TRIGGER Seq_Primary_Key ON Incumbents
FOR INSERT, UPDATE
AS 
IF EXISTS
(SELECT * FROM Incumbents AS I1
 -- (1) no overlap
 WHERE 1 &lt;
     (SELECT COUNT(I2.SSN)
      FROM Incumbents AS I2
      WHERE I1.SSN = I2.SSN AND I1.PCN = I2.PCN -- &lt;= the key
        AND I1.FromDate &lt; I2.ToDate
        AND I2.FromDate &lt; I1.ToDate))
OR EXISTS
 -- no NULL
    (SELECT * FROM Incumbents AS I
     WHERE I.SSN IS NULL
       OR I.PCN IS NULL) 
BEGIN 
  RAISERROR('Violation of sequenced primary key constraint',1,2)
  rollback transaction 
END
&lt;/pre&gt;
|
We look for intervals with the same key 
&lt;br&gt;
that overlap with each over
&lt;br&gt;
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-sequenced-key.png
&lt;br&gt;
also we don't allow &lt;code&gt;NULL&lt;/code&gt;s
|}


=== Other Constraints ===
And there are other constraints that we want to enforce:
* No Duplicates 
* Referential Integrity (introducing sequenced foreign keys)
* The history must be contiguous (no gaps)



== Queries ==
=== Coalescing ===
Consider this table: 
* &lt;code&gt;Employee(Name, Salary, Title, BirthDate, FromDate, ToDate)&lt;/code&gt;
* each time the salary or title change, the time of the change is captured and new record with this change is added 
* so we can see the entire history of changes 

{|  class=&quot;wikitable&quot;
! Name || Salary || Title || BirthDate || FromDate || ToDate
|- 
| John || 60.000 || Assistant || 9/9/60 || 1/1/95 || 1/6/95
|- 
| John || 70.000 || Assistant || 9/9/60 || 1/6/95 || 1/10/95
|- 
| John || 70.000 || Lecturer || 9/9/60 || 1/10/95 || 1/2/96
|- 
| John || 70.000 || Professor || 9/9/60 || 1/2/96 || 1/1/97
|} 

We see how the salary grows and how John changes his title

Now consider these queries:
* show John's current salary
* show the history of John's salary changes
sequenced queries 


The first query is easy:

&lt;pre&gt;SELECT Salary
  FROM Employee 
 WHERE Name = 'John' AND
       FromDate &lt;= now() AND
       now() &lt;= ToDate
&lt;/pre&gt;


But it's not easy to do the second one 

Main idea:
* find intervals that overlap or adjacent and merge them 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-coalecsing-ex1.png
* if we have 5 periods
** (title A, salary X), (title B, salary X), (title B, salary Y), (title C, salary Y), (title D, salary Y)
* we want to extract only periods with equal salary and get (salary X) and (salary Y)


==== Imperative Version ====
Idea:
* create a temporary table and modify the timestaps of intervals there 
* for period $T_1$ find a period $T_2$ for which
** they have the same salary
** they are adjacent or overlap
*** $T_1$ starts before $T_2$ starts
*** $T_2$ starts when $T_1$ has not finished yet
*** $T_2$ finishes after $T_1$ finishes 
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-coalecsing-imperative-idea.png
* if there exists such $T_2$ then update the finish time of $T_1$ to $T_2$
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-coalecsing-imperative-idea2.png

&lt;pre&gt;
CREATE TABLE Temp(Salary, FromDate, ToDate) AS
SELECT Salary, FromDate, ToDate FROM Employee
WHERE Name = 'John' 
repeat
  UPDATE TEMP T1
  SET (T1.ToDate) =
    (SELECT MAX(T2.ToDate)
     FROM TEMP AS T2
     WHERE T1.Salary = T2.Salary
       AND T1.FromDate &lt; T2.FromDate
       AND T1.ToDate &gt;= T2.FromDate
       AND T1.ToDate &lt; T2.ToDate) WHERE EXISTS
    (SELECT *
     FROM TEMP AS T2
     WHERE T1.Salary = T2.Salary
       AND T1.FromDate &lt; T2.FromDate
       AND T1.ToDate &gt;= T2.FromDate
       AND T1.ToDate &lt; T2.ToDate) 
until no tuples updated
&lt;/pre&gt;

This is how it looks like after each pass:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-coalecsing-imperative-pre-result.png
* we see that it there are intervals that are no longer needed 
* so we remove intervals that are not maximal


Removal of non-maximal intervals 
* for interval $T_1$ find interval $T_2$ such that 
** it has the same salary 
** $T_2$ includes $T_1$:
*** $T_2$ start after $T_1$ and
*** $T_2$ finish earlier than $T_1$
*** td-coalecsing-imperative-remove-min.png
* if there exists such $T_2$ then remove $T_1$


&lt;pre&gt;
DELETE FROM Temp T1
WHERE EXISTS (
  SELECT * FROM Temp AS T2
  WHERE T1.Salary = T2.Salary AND
       ((T1.FromDate &gt; T2.FromDate  AND T1.ToDate &lt;= T2.ToDate) OR
        (T1.FromDate &gt;= T2.FromDate AND T1.ToDate &lt;  T2.ToDate))
&lt;/pre&gt;


==== Declarative Version in SQL ====
Algorithm:

Let $E$ be a database with John's history
* for salary $x$ we need to find $f, l \in E$ such that
* $f$ is the first period with salary $x$ and $l$ last period with $x$
* and the interval between $f$ and $l$ is continuous:
** for all $t \in E$ with salary $x$ that inside $[f, l)$
** there's $t_1 \in E$ that starts before $t$ and finishes before $t$ finishes
* to ensure that $f,l$ are indeed the bounds of the interval we try to find $t_2 \in E$ such that
** it either starts before $f$ or finishes after $l$ 
** if we find such $t_2$ - $[f, l)$ is not maximal and we need to try another pair of $f,l$


More formally this looks like this:
: find $f, l \in E$ such that 
: $f.\text{from} &lt; l.\text{to} \land f.\text{salary} = l.\text{salary} \land$
:: $\forall t \in E$
:: $t.\text{salary} = f.\text{salary} \land f.\text{from} &lt; t.\text{from} \land t.\text{from} &lt; l.\text{to}: $
::: $\exists t_1 \in E: t_1.\text{salary} = f.\text{salary} \land $
:::: $t_1.\text{from} &lt; t.\text{from} \land f.\text{from} \leqslant t1.\text{to}$
:: $\land$
:: $\lnot \exists t_2 \in E $
::: $t_1.\text{salary} = f.\text{salary} \land$
::: $\Big[ (t_2.\text{from} &lt; f.\text{from} \land f.\text{from} \leqslant t_2.\text{to}) \lor $
::: $\ (t_2.\text{from} \leqslant l.\text{to} \land l.\text{to} &lt; t_2.\text{to}) \Big]$


Let's see how it looks like graphically 

{| class=&quot;wikitable&quot;
| find $f, l \in E$ such that ||
|-
| $f.\text{from} &lt; l.\text{to} \land$ || https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-coalescing-dec-1.png
|-
| $f.\text{salary} = l.\text{salary} \land $ || 
|-
| $\forall t \in E$  || 
|-
| $\ \  t.\text{salary} = f.\text{salary} \land$ ||
|-
| $\ \  f.\text{from} &lt; t.\text{from} \land t.\text{from} &lt; l.\text{to} \land$ || https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-coalescing-dec-2.png
|-
| $\ \ \exists t_1 \in E:$ || for all such $t$ there exists $t_1$
|-
| $\ \ \ \ t_1.\text{salary} = f.\text{salary} \land$ ||
|-
| $\ \ \ \ t_1.\text{from} &lt; t.\text{from} \land f.\text{from} \leqslant t1.\text{to}$ || https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-coalescing-dec-3.png
|-
| $\land$ || 
|- 
| $\lnot \exists t_2 \in E $ ||
|-
| $\ \ t_1.\text{salary} = f.\text{salary} \land$ ||
|-
| $\ \ \Big[ (t_2.\text{from} &lt; f.\text{from} \land f.\text{from} \leqslant t_2.\text{to}) \lor \\ \ \ \ (t_2.\text{from} \leqslant l.\text{to} \land l.\text{to} &lt; t_2.\text{to}) \Big]$ || https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-coalescing-dec-4.png
|}


https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-coalescing-dec-5.png


But there's no $\forall$ operator in SQL:
* so need to replace the condition $\forall t ... \exists t_1$ onto $\not \exists t ... \not \exists t_1$


Here's a SQL version:

&lt;pre&gt;
CREATE VIEW Temp(Salary, FromDate, ToDate) AS
SELECT Salary, FromDate, ToDate
FROM Employee
WHERE Name = 'John';

SELECT DISTINCT F.Salary, F.FromDate, L.ToDate
FROM Temp AS F, Temp AS L 
WHERE F.FromDate &lt; L.ToDate
AND F.Salary = L.Salary
-- SUBQUERY 1: ensure continuity
AND NOT EXISTS 
  (SELECT * FROM Temp AS T
   WHERE T.Salary = F.Salary
     AND F.FromDate &lt; T.FromDate
     AND T.FromDate &lt; L.ToDate
     AND NOT EXISTS
       (SELECT * FROM Temp AS T1
        WHERE T1.Salary = F.Salary
          AND T1.FromDate &lt; T.FromDate
          AND T.FromDate &lt;= T1.ToDate))
-- SUBQUERY 2: make sure it's maximal
AND NOT EXISTS
  (SELECT * FROM Temp AS T2
   WHERE T2.Salary = F.Salary
     AND ((T2.FromDate &lt; F.FromDate AND F.FromDate &lt;= T2.ToDate)
       OR (T2.FromDate &lt;= L.ToDate AND L.ToDate &lt; T2.ToDate)));
&lt;/pre&gt;



=== Temporal Join ===
Alternative solution:
* the schema before had two independent attributed we want to capture 
* can't we reorganize the schema - split the information about changes in salary and title?


So we split and have this schema:
* &lt;code&gt;Employee(Name, BirthDate)&lt;/code&gt;
* &lt;code&gt;EmployeeSal(Name, Salary, FromDate, ToDate)&lt;/code&gt;
* &lt;code&gt;EmployeeTitle(Name, Title, FromDate, ToDate)&lt;/code&gt;

Showing the history of changes in John's salary is easy now:

&lt;pre&gt;SELECT Salary, FromDate, ToDate
FROM EmployeeSal
WHERE Name = 'John'&lt;/pre&gt;


However how we now obtain a table of salary and title intervals? 
* we need a temporal join


EmployeeSal
{| class=&quot;wikitable&quot;
! Name || Salary || FromDate || ToDate
|-
| John || 60.000 || 1/1/95 || 1/6/95
|-
| John || 70.000 || 1/6/95 || 1/1/97
|}


EmployeeTitle
{| class=&quot;wikitable&quot;
! Name || Title || FromDate || ToDate
|-
| John || Assistant || 1/1/95 || 1/10/95
|-
| John || Lecturer || 1/10/95 || 1/2/96
|-
| John || Professor || 1/2/96 || 1/1/97
|}


EmployeeSal $\Join$ EmployeeTitle
{|  class=&quot;wikitable&quot;
! Name || Salary || Title || FromDate || ToDate
|- 
| John || 60.000 || Assistant || 1/1/95 || 1/6/95
|- 
| John || 70.000 || Assistant || 1/6/95 || 1/10/95
|- 
| John || 70.000 || Lecturer || 1/10/95 || 1/2/96
|- 
| John || 70.000 || Professor || 1/2/96 || 1/1/97
|}


The idea:
* to find overlapping intervals and join on them 
* there are 4 possible ways in which intervals can overlap
* so we need to try all of them 

{|
|
&lt;pre&gt;
-- (1)
SELECT S.Name, Salary, Title, S.FromDate, S.ToDate
FROM EmployeeSal S, EmployeeTitle T
WHERE S.Name = T.Name
  AND T.FromDate &lt;= S.FromDate
  AND S.ToDate &lt;= T.ToDate
UNION ALL
-- (2)
SELECT S.Name, Salary, Title, S.FromDate, T.ToDate
FROM EmployeeSal S, EmployeeTitle T
WHERE S.Name = T.Name
  AND S.FromDate &gt; T.FromDate
  AND T.ToDate &lt; S.ToDate
  AND S.FromDate &lt; T.ToDate
UNION ALL
-- (3)
SELECT S.Name, Salary, Title, T.FromDate, S.ToDate
FROM EmployeeSal S, EmployeeTitle T
WHERE S.Name = T.Name
  AND T.FromDate &gt; S.FromDate
  AND S.ToDate &lt; T.ToDate
  AND T.FromDate &lt; S.ToDate
UNION ALL
-- (4)
SELECT S.Name, Salary, Title, T.FromDate, T.ToDate
FROM EmployeeSal S, EmployeeTitle T
WHERE S.Name = T.Name
  AND T.FromDate &gt;= S.FromDate
  AND T.ToDate &lt;= S.ToDate
&lt;/pre&gt;
|
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-temporal-join-idea.png
|}


=== Aggregation Functions ===
Suppose we want to apply some aggregation function to each period in the valid time table

Example:
* compute the maximal salary for each period 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-aggregations.png

This is done in 3 steps:
* compute all possible periods
* compute the maximal salary for these periods 
* coalesce the periods with the same salary


Step 1:
&lt;pre&gt;
-- all moments of time when there was some change 
CREATE VIEW SalChanges(Day) as
SELECT DISTINCT FromDate
FROM Salary
UNION
SELECT DISTINCT ToDate
FROM Salary;

-- now we construct periods from these moments
CREATE VIEW SalPeriods(FromDate, ToDate) as
SELECT P1.Day, P2.Day
FROM SalChanges P1, SalChanges P2
WHERE P1.Day &lt; P2.Day
  AND NOT EXISTS
    (SELECT * FROM SalChanges P3
     WHERE P1.Day &lt; P3.Day
       AND P3.Day &lt; P2.Day);
&lt;/pre&gt;

Step 2:
&lt;pre&gt;
CREATE VIEW TempMax(MaxSalary, FromDate, ToDate) as
SELECT MAX(E.Amount), I.FromDate, I.ToDate
FROM Salary E, SalPeriods I
WHERE E.FromDate &lt;= I.FromDate
  AND I.ToDate &lt;= E.ToDate
GROUP BY I.FromDate, I.ToDate;
&lt;/pre&gt;


Step 3 
* coalesce these intervals 


'''Count''' is a little bit different
* we need to identify gaps in the history and put there zeros
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/adb/td-aggregations-count.png

Step 2 for count
&lt;pre&gt;
CREATE VIEW TempCount(NbEmp, FromDate, ToDate) as
SELECT COUNT(*), P.FromDate, P.ToDate
FROM Salary S, SalPeriods P
WHERE S.FromDate &lt;= P.FromDate
  AND P.ToDate &lt;= S.ToDate
GROUP BY P.FromDate, P.ToDate

UNION ALL

SELECT 0, P.FromDate, P.ToDate
FROM SalPeriods P
WHERE NOT EXISTS
    (SELECT * FROM Salary S
     WHERE S.FromDate &lt;= P.FromDate
       AND P.ToDate &lt;= S.ToDate);
&lt;/pre&gt;


== Links ==
* Exercises from the [[Advanced Databases (ULB)|ADB]] course: [https://www.dropbox.com/s/es8a430fhgg55ow/202-temporal_exercices.pdf]


== Sources ==
* [[Advanced Databases (ULB)]]

[[Category:Relational Databases]]
[[Category:Databases]]</text>
      <sha1>jzd16u8ioo66j3qcktzavl2199otoos</sha1>
    </revision>
  </page>
  <page>
    <title>Business Process Management</title>
    <ns>0</ns>
    <id>348</id>
    <revision>
      <id>351</id>
      <timestamp>2014-02-02T12:54:45Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1848">== Business Process Management ==
a ''business process'' consists of a set of activities that are performed in coordination in an organization and technical environment
* these process jointly implement some ''business goal''
* (Weske, 2007)

Motivation:
* [[Enterprise System Architecture]] - why BPM systems are needed



=== Example: IT4BI ===
Consider a process of IT4BI admission

Activities:
* Receive an application
* Assign an identifier
* Evaluate an application
* Request for more information
* Select candidates
* Communicate the results 
* Send rankings to the European Commission
* Send invitations - for visas
* Admission to the University
* and many others

This is a business process 


=== BPM: Managing Business Processes ===
How to model BPs?
* [[Petri Nets]] and [[Workflow Nets]] - basis, originally for modeling concurrent systems
* [[YAWL]] - academic 
* [[BPMN]] - the de-facto standard


=== BPM Lifecycle ===
BPM is more than just modeling: 
* [[Process Mining]] - to discover existing processes in a company 
* Process Analysis - in the model correct or not, is the process consistent with the model? (see [[Process Conformance]]) 
* Process Enacting - putting a model into software
* Process Monitoring - how much time each task takes?
* Process Simulation - after creating a model we try to see what would happen if we used it


https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/bpm/bpm-lifecycle.png

$(1) \to (2) \to (3) \to (4) \to (1)$
* is a BPM lifecycle


=== [[Process Mining]] ===
Process Mining is about discovering the existent process and creating a model from it

There are several process mining algorithms. For example,
* [[Alpha Algorithm]]
* [[Genetic Process Miner]]
* and others 


== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Business Process Management]]</text>
      <sha1>oki94gsxps001xpdrgfu649jt40p6ds</sha1>
    </revision>
  </page>
  <page>
    <title>Enterprise System Architecture</title>
    <ns>0</ns>
    <id>349</id>
    <revision>
      <id>352</id>
      <timestamp>2015-07-05T16:11:37Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2848">== Enterprise System Architecture ==
This is a motivation why workflow management systems are needed

== Evolution of Integration ==
=== No Integration ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/esa-no-integration.png

There are 3 systems:
* HR: human resources 
* POM: purchase order management
* WM: warehouse management 

No integration:
* a change in one DB is not propagated to others (automatically)
* this has to be maintained 
* suppose an address changes in HR, but the rest don't know about it
* $\Rightarrow$ [[Consistency (databases)|inconsistency]]


=== Central ERP System ===
This is also called 2-tier client-server architecture 

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/esa-central-erp.png
* there's a central ERP system that explicitly integrates all the data into one source 
* but there are performance issues
* and what if the ERP server goes down?


=== Application Integration ===
There are several ways to integrate different application

==== Point-To-Point ====
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/esa-central-p2p.png
* every system communicated with all other systems 
* $N^2$ connections for $N$ systems - a lot!


==== Message-Oriented Middleware ====
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/esa-mom.png
* each client connects to the Integration Application 
* IA dispatches the messages to the receivers 
* this approach takes away the burden of implementing all the connectors
* but it's still point-to-point: all must know about others
* $\cfrac{N \cdot (N - 1)}{2}$ connections in this scheme


==== Application Integration ====
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/esa-central-hub.png
* now there's a hub: a centralized integration middleware: it orchestrates the flow
* the hub acts as a message broker: it defines the rules for communication and transformation
* system no longer need to know about each other 
* it's similar to emailing: no need to know about the received: where is he, whether he can read now or not, etc

The differences between it and central ERP:
* in the central ERP there's one single DB
* here each application has it's own database 


=== Workflow Management Systems ===
There are three kind of workflow management systems:
* hard-coded workflows (process and organization specific)
* custom-made (with some generic wokrkflow but still organization specific)
* generic software with embedded workflow functionality 
** workflow components of one particular type of systems, say ERP
* generic software focused on workflow
** how we can connect different components from different manufactures
** allows great flexibility 



== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Business Process Management]]
[[Category:Software Design]]</text>
      <sha1>7v0jt2sw8pqexv12clgyuzrulfepq62</sha1>
    </revision>
  </page>
  <page>
    <title>Petri Nets</title>
    <ns>0</ns>
    <id>350</id>
    <revision>
      <id>353</id>
      <timestamp>2014-02-01T22:49:24Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7744">== Petri Nets ==
Petri nets is a technique for description and analysis of concurrent systems
* very expressive graphical notation
* mathematically formal
* this is an extension of [[Automata Theory]] to concurrency
* it's a basis and inspiration of many workflow systems in [[BPM]]


== Definition ==
=== Petri Net ===
Informally:
* a petri net consists of ''places'' (circles) and ''transitions'' (squares: activities)
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-simplest.png
* ''places'' can be input/output of transitions
* places represent the states of a system 
* ''transition'' represent state changes

A ''petri net'' is a tuple $(P, T, F)$ where
* $P$ is a finite set of places 
* $T$ is a finite set of transitions
* $F \subseteq (P \times T \cup T \times P)$ is a flow relation
** i.e. this is a set of edges from elements of $P$ to $T$ and from elements of $T$ to $P$
** https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-simplest.png
** in this case: $F = \{(p_1, t_1), (t_1, p_2)\}$


Every place can contain one or more ''tokens'' 
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-tokens.png
* a ''token'' is a piece of work that needs to be processed


Notation:
* $\bullet p$ is a set of all transactions that put tokens to $p$
** $\bullet p = \{ t \in T \ | \ (t, p) \in F \}$
* $p \bullet$ is a set of all transactions that take tokens from $p$
** $p \bullet = \{ t \in T \ | \ (p, t) \in F \}$
* $\bullet t$ is a set of all input places of $t$ 
** $\bullet t = \{ p \in P \ | \ (t, p) \in F \}$
* $t \bullet$ is a set of all output places of $t$
** $t \bullet = \{ p \in P \ | \ (p, t) \in F \}$


Example:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-formal-def-ex.png
* $\bullet p_3 = \{ t_1 \}$
* $p_3 \bullet = \{ t_3 \}$
* $\bullet t_4 = \{ p_4, p_5 \}$
* $t_4 \bullet = \{ p_6 \}$


=== Marking ===
A ''marking'' is a state of the net
* shows the distribution of tokens across all places
* transition change the state of a bet by ''firing'' 
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-active-transition.png
* for a transition $t_1$ in all its input places must be a token
* when $t_1$ fires, it takes exactly one token from each input place and puts exactly one token to each its output place
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-active-transition-fired.png
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-active-transition1.png


Formally,
* a ''marking'' $M$ of a petri net $N = (P, T, F)$ is a function
* $M: P \mapsto {0, 1, 2, ...}$
* that associates each $p \in P$ with some number: the number of tokens in $p$ 


Example:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-marking.png
* the marking is $\{(p_1, 1), (p_2, 2), (p_3, 0)\}$

Comparisons 
* $M \geqslant M' \iff \forall p \in P: M(p) \geqslant M'(p)$
* $M &gt; M' \iff M \geqslant M' \land M \neq M'$


=== Enabled Transitions ===
A place is ''enabled'' if there is at least one token in all its input places 
* transitions change the status of a petri net by firing
* only enabled transitions may fire 


'''def'''
* a transition is enabled in a marking $M$ $\iff$
* $\forall p \in \bullet t: M(p) &gt; 0$


note that $t$ is active only when there's a token in all input places 
* consider this example:
* suppose input tokens correspond to required documents for a visa
* and output token corresponds to an issued visa
* all documents are required: if one is missing - no visa
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-active-missing.png

Example:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-enabled.png
* $t_1$ is enabled: $\bullet t_1 = \{p_1, p_2\}$ and $M(p_1) = M(p_2) = 1$
* $t_2$ is enabled: $\bullet t_2 = \{p_2\}, M(p_2) = 1$
* $t_3$ is not enabled: $\bullet t_3 = \{p_4\}, M(p_4) = 0$


=== Firing a Transition ===
A marking $M'$ results from firing an enabled transition $t$ in marking $M$
* $M \to^t M'$ s.t.:
* $\forall p \not \in \bullet t \cup t \bullet:  {\color{blue}{M'(p) = M(p)}}$ 
** i.e. for all $p$ that are not connected with $t$ 
* $\forall p \in \bullet t \cap t \bullet:  {\color{blue}{M'(p) = M(p)}}$ 
** i.e. for all $p$ that are both input and output place for $t$
* $\forall p, p \in \bullet t \land p \not \in t \bullet:  {\color{blue}{M'(p) = M(p) - 1}}$
** $t$ removes a single token from all its input places
* $\forall p, p \not \in \bullet t \land p \in t \bullet:  {\color{blue}{M'(p) = M(p) + 1}}$ 
** $t$ puts a single token to all its output places


Notation:
* $M \to M' \iff M \to^t M'$ for some transition $t$
** it reads: $M'$ can be obtained from $M$ by firing some transition (we don't care which one)
* $M \to^* M' \iff M \to^{t_1} M_1 \to^{t_2} M_2 \to^{t_3} ... \to^{t_n} M'$
** it reads: $M'$ can be obtained from $M$ by firing a sequence of transitions (we don't care which transitions exactly)


=== Examples ===
==== Example 1 ====
https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-firing-ex.png
* marking $M$, before firing $t_1$:
** $t_1$ is enabled 
* $t_1$ fires: $M \to^{t_1} M'$
* marking $M'$, after firing $t_1$:
** $t_1$ is no longer enabled
** there is no token in one of its input places


==== Example 2: Candy Storage ====
https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-candy-machine.png
* the candy storage is initially loaded with 4 candies
* when a coin is inserted, it can be either accepted or rejected
* if coin is accepted, a candy is given 
* each time a candy is disposed, we request for a new candy
* note that there are manual actions: insert coin, refill; the rest is automatic
** there's no way to distinguish these actions 
** for example, refill may take a while - it doesn't necessarily have to be immediate


==== Example 3: Dining Philosophers ====
It can be seen here: 
* http://www.informatik.uni-hamburg.de/TGI/PetriNets/introductions/aalst/philosopher4.swf
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-philosophers.png


== [[Workflow Nets]] ==
{{Main | Workflow Nets}}

Typically a ''workflow net'' is a special type of a petri net with
* clear start point 
* clear end point
* good for expressing workflows

== Soundness ==
{{Main | Workflow Soundness}}


== Typical Structures ==
=== Parallel Execution: And ===
https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-parallel-ex.png

Sequences:
* $A,B,C,D$
* $A,C,B,D$

This construction is called AND and consists of two parts:
* AND-split and
* AND-join

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-and.png


=== Race Condition: XOR ===
https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-race-cond.png

Sequences:
* $A,B,D$
* $A,C,D$
* but not $A,B,C,D$ - can never have it

When there's one input place for two and more transitions, they are in the ''race condition'': 
* only one transition can take the token 

Alternatively, there could be some other condition
* based on which the transitions decide either to take a token or not


== Links ==
* Examples of petri nets: http://www.informatik.uni-hamburg.de/TGI/PetriNets/introductions/aalst/


== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Petri Nets]]
[[Category:Business Process Management]]
[[Category:Concurrency]]</text>
      <sha1>d8tuylx182zba8s2uikl9m2cytazalu</sha1>
    </revision>
  </page>
  <page>
    <title>Workflow Nets</title>
    <ns>0</ns>
    <id>351</id>
    <revision>
      <id>354</id>
      <timestamp>2015-07-05T16:27:44Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1593">== Workflow Nets ==
By workflow nets here we refer to [[Petri Nets|petri-net-based]] workflows. 

So, a ''workflow net'' is a special type of a petri net that is suitable for expressing workflows 

In a workflow net:
* there's a clear start: 
** the unique dedicated ''input place'' $i$ s.t.
** $\bullet i = \varnothing$
** i.e. no transition can put a token to $i$
* there's a clear end:
** the unique dedicated ''output place'' $o$ s.t.
** $o \bullet = \varnothing$
** i.e. no transitions should consume tokens from $o$
* every other transition and place are on the path from $i$ to $o$ 

Markings:
* initial marking $M_0$: 
** $M_0(i) = 1, \forall p \ne i: M_0(p) = 0$


=== Examples ===
Not workflow nets
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/workflow-nets-notwf.png
* (1): no start, no end
* (2): $b$ is not connected to the end
* (3): $d$ is also not on the path from $i$ to $o$

Workflow net:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/workflow-nets-ex.png
* all workflow net properties are satisfied



== Soundness ==
{{Main | Workflow Soundness}}

There are situations that we want to avoid:
* unboundness 
* livelocks and deadlocks
* dead transitions

For that we define the following properties
* Option To Complete 
* Proper Termination
* No Dead Transitions


== [[Workflow Patterns]] ==
{{ Main | Workflow Nets/Workflow Patterns }}


== Housing Agency Assignment ==
* [[Housing Agency Workflow]]


== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Petri Nets]]
[[Category:Business Process Management]]</text>
      <sha1>hhe1pazlpvg99keegyokpv03n4zb38k</sha1>
    </revision>
  </page>
  <page>
    <title>Reachability Graph</title>
    <ns>0</ns>
    <id>352</id>
    <revision>
      <id>355</id>
      <timestamp>2015-07-05T16:13:45Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2032">== Reachability Graph ==
This is a way of representing the states of [[Petri Nets]]


A marking $M$ is reachable from the initial marking $M_0$ 
* $\iff M_0 \to^* M$
* i.e. there exists a firing sequence that brings us from the initial state of a petri net to a state that corresponds to $M_0$


In a ''reachability graph'' of a petri net $N = (P, T, F)$
* nodes correspond to reachable markings 
* edges correspond to the relation $\to$

There can be several notations for markings:
* first one: $(n_1, n_2, ..., n_m)$ corresponds to the number of elements in the places $(p_1, ..., p_m)$ respectively
* second one: $[p_1^{n_1}, ..., p_m^{n_m}]$ where $n_i$ is the number of times $p_i$ appears
** if $p_i$ appears zero times, we don't show it in the marking

Consider this example:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/workflow-nets-reachability.png
* so a reachability graph shows all possible states (markings) that you can reach by triggering transitions that are enabled
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/workflow-nets-reachability2.png  
* the graph above is the reachability graph with different notation

There are some desirable properties for the [[Workflow Nets]]
* we want to be able to decide on them 
* reachability graphs can be used for that 


=== [[Coverability Graph]] ===
This is a similar notion for expressing states of Workflow Nets
* but unlike Reachability Graph it can be finite for unbounded nets 
* yet in many cases less expressive



== Examples ==
=== Example 1 ===
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/workflow-nets-livelock2-rg.png 
* it is a reachability graph for 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/workflow-nets-livelock2.png
* we see that two nodes are not connected: it's clearly a problem


== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Petri Nets]]
[[Category:Graphs]]
[[Category:Business Process Management]]
[[Category:Graphs]]</text>
      <sha1>83o83yuiujq09hu84orvjzcenoqw0o3</sha1>
    </revision>
  </page>
  <page>
    <title>Workflow Patterns</title>
    <ns>0</ns>
    <id>353</id>
    <revision>
      <id>356</id>
      <timestamp>2014-01-29T07:51:25Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1973">== Workflow Patterns ==
Workflow patterns help to express the constructions common to workflows
* http://www.workflowpatterns.com/
* here we consider control flow patterns: http://www.workflowpatterns.com/patterns/control/index.php


== Basic Control Flow Patterns ==
=== Sequence ===
First task $A$, then task $B$ [http://www.workflowpatterns.com/patterns/control/basic/wcp1.php]:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-sequence.png

=== Parallel Split  ===
Tasks $b$ and $c$ are processed in parallel [http://www.workflowpatterns.com/patterns/control/basic/wcp2.php]
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-par-split.png


=== Synchronization ===
Do $d$ only after both $b$ and $c$ are completed [http://www.workflowpatterns.com/patterns/control/basic/wcp3.php]
* this is a synchronization between two parallel processes 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-synch.png


=== Exclusive Choice ===
after $a$, do $b$ or $c$ [http://www.workflowpatterns.com/patterns/control/basic/wcp4.php]
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-xor.png


=== Simple Merge ===
perform $d$ after $b$ or $c$ finishes [http://www.workflowpatterns.com/patterns/control/basic/wcp5.php]
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-xor-merge.png


== Advanced Branching and Synchronization Patterns ==
* Multiple Choice 
* Synchronized Merge 
* Multi Merge 
* [[Discriminator Pattern]]
* Arbitrary Cycles


== Termination Patterns ==
* Implicit Termination



== State-Based Patterns ==
* [[Deferred Choice]]
* Interleaved Parallel Routing
* [[Milestone Pattern]]


== Cancellation and Force Completion Patterns ==
* [[Cancellation Regions|Cancellation Region]]
* Cancel Activity
* Cancel Case


== Sources ==
* [[Business Process Management (ULB)]]


[[Category:Business Process Management]]</text>
      <sha1>s3b38cayapc331t75730cu2vu3fu791</sha1>
    </revision>
  </page>
  <page>
    <title>Discriminator Pattern</title>
    <ns>0</ns>
    <id>354</id>
    <revision>
      <id>357</id>
      <timestamp>2014-01-29T07:52:04Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2417">== Discriminator Pattern ==
This is a Control flow pattern in [[Workflow Patterns]]. 


Suppose that
* two processes are running in parallel 
* merge is activated when one of them ends 
* the result of the other is just ignored

=== Examples ===
Example 1:
* to speed up a query we send it to two databases 
* once the first answer arrives we proceed 
* and just ignore the second answer 



== Types ==
There are 6 kinds of Discriminator pattern [http://www.workflowpatterns.com/patterns/control/index.php]:
* the Structured Discriminator (WCP9), 
* the Blocking Discriminator (WCP28), 
* the Cancelling Discriminator (WCP29), 
* the Structured Partial Join (WCP30),
* the Blocking Partial Join (WCP31) and 
* the Cancelling Partial Join (WCP32).


=== Canceling Discriminator ===
This is a discriminator that cancels the other process [http://www.workflowpatterns.com/patterns/control/new/wcp29.php]

In [[YAWL]] this is achieved:
* with one Parallel Split (AND-Split)
* a [[Cancellation Regions|Cancellation Region]] for the two processes 
* one Simple Merge (XOR-Join) that is also the cancel task for the cancellation region

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-dicr-canc.png


What if we don't want to interrupt the 2nd activity?
* for example, in a hospital we want to do two tests 
* we start treating the patient as soon as the first result arrives
* but we cannot discard the results of the second result
* so we do the full analysis when we have both results 

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-dicr-non-canc1.png
* this way we start treatment as soon as possible
* but start the full diagnosis only when the second arrive


We may as well add a timing constrain
* we wait for the result only for 24 hours 
* and then do the diagnosis based only on partial information

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-dicr-timer.png

if $A$ has finish, but $B$ hasn't
* case 1:
** timeout task times out
** then it fires and takes token from $B$
** and also puts a token to the input place for full diagnosis
** full diagnosis can start
* case 2:
** timeout starts to count down 
** but $B$ finishes
** full diagnosis starts 
** it takes the token from the timeout task so it is no longer enabled




== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Business Process Management]]</text>
      <sha1>nwibl9dcxqaq7znbgmzieztw9lqsvgz</sha1>
    </revision>
  </page>
  <page>
    <title>Workflow Soundness</title>
    <ns>0</ns>
    <id>355</id>
    <revision>
      <id>358</id>
      <timestamp>2015-07-05T16:07:57Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8281">== Workflow Soundness ==
Soundness is a notion of correctness of workflow nets
* for [[Petri Nets]] and [[Workflow Nets]]
* for [[YAWL]]

These properties are usually checked with [[Reachability Graph]]s


== Situations to Avoid ==
=== Unboundness ===
''Unboundness'' means:
* there is no bound on the number of tokens that a place can hold
* this always means a problem


=== Improper Termination ===
A workflow net satisfies ''proper completion'' when
* if there's a token in the output place, then there are no tokens in other places
* if this property is not satisfied, then the problem is called ''improper termination''


https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/workflow-nets-unbounded.png
* firing sequences:
** $s \to a \to b \to a \to d$
** $s \to a \to c \to a \to d$
* there are remaining tokens after the flow ends
** it means: it stopped, but there is still some work to do
** clearly it's a problem


Example:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/workflow-nets-problem.png
* there are paths that lead to proper termination:
** card $\to$ charge $\to$ skip $\to$ finish
** transfer $\to$  receive payment $\to$ NA $\to$ repay
* but there are problematic firing sequences
** card $\to$ charge $\to$ NA $\to$ no repay $\to$ finish
** at the step of no-repay both repay and no repay are available
** after firing no repay there's one token left in the network
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/workflow-nets-problem-il.png



=== Deadlocks and Livelocks ===
Both livelock and deadlock mean that
* there's a situation when you cannot reach the end


Deadlock
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/workflow-nets-deadlock.png
* once you fire $a$ nothing is enabled
* but the workflow in not complete: there's no token in the output place
* in this case we don't have matching joins - that leads to a deadlock


Livelock 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/workflow-nets-livelock.png
* $C$ and $D$ can fire forever: they're always enabled
* but the workflow will never reach the end


=== Dead Transitions ===
A dead transition
* is a transition that can never fire

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/workflow-nets-dead-transition.png
* in this case $F$ never gets activated
* this workflow can finish successfully
* the only fix - to remove the dead transition


== [[Petri Nets]] ==
For Petri Nets that represent infinite processes there is a notion of correctness of there nets:
* liveness
* boundness
* deadlock-free

Used notation:
* [[Reachability Graph]]


=== Liveness ===
In a ''live'' petri net there are no dead transitions
* a dead transition is a transition that can never fire in any marking reachable from the initial marking 

a petri net $N$ with initial marking $M_0$ is live $\iff$
* $\forall M: M_0 \to^* M, \forall t: \exists M \to^* M'$ in which $t$ is enabled

It reads: 
* for any marking $M$ reachable from the initial marking $M_0$
* and for every transition $t \in T$
* there exists a marking $M'$ reachable from $M$ s.t.
* $t$ is enabled in $M'$ 


In other words: 
* no matter what happens, for any $t$ there exists a marking $M'$ reachable from the current state $M$ 
* such that $t$ is enabled in it



==== Example ====
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-liveness.png
* the example on the left is live: no matter what happens the process continues
* the net on the right is not live: after firing $ccc$ nothing is active anymore


==== Example 2 ====
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-liveness2.png
* this network is deadlock-free
* [[Reachability Graph]]: https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-liveness2-rg.png
* so whatever we do there are always active transitions 
* but we cannot escape marking $[p_2]$, and $a$ is no longer live
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-liveness3.png
* but if we add another transition $c$ it becomes live:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-liveness3-rg.png


So liveness means:
* no matter what happens, every transition $t$ should be able to fire at some point in future


=== Boundness ===
A petri net $N$ with initial marking $M_0$ is $k$-''bounded'' iff
* $\forall M: M_0 \to^* M, \forall p \in P: M(p) \leqslant k$
* there never can appear more than $k$ tokens in any $p \in P$ in any reachable marking $M$ 

5-bounded net:
* each $p$ can hold no more than 5 tokens


1-bounded net is called ''safe''


==== Example ====
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-live-unbound.png
* in this net $a$ can fire infinitely many number of times 
* so this net is not bounded 
* but it's always live: there exists matchings for which $a$ and $b$ can fire


==== Example 2 ====
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-unboundness.png
* not bounded: can put as many matchings as we want


=== Deadlock Free ===
a petri net $N$ with initial marking $M_0$ is ''deadlock-free'' iff
* $\forall M: M_0 \to^* M \ \exists M': M \to M'$
* for any reachable marking $M$ there exists another marking $M'$ that can be reached from $M$
* i.e. every reachable marking enables some transition $t \in T$


https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-deadlock.png
* after $b$ fires nothing can fire anymore
* $a$ needs tokens from two its input places, but there's only one token 



== [[Workflow Nets]] Soundness ==
With workflow nets
* we can decide many things statically, before enacting the workflow
* there are some desirable properties that help to avoid these problems

A ''workflow net'' is sound $\iff$ it has
* the option to complete
* proper completion
* no dead transitions 


Notation:
* $M_0 = [i]$ initial marking 
* $[o]$ - final marking
* also notation from [[Petri Nets]] and [[Reachability Graph]]
* given a petri net $N = (P, T, F)$


=== Option to Complete ===
$\forall M, M_0 \to^* M: \exists M', M \to^* M': M' \geqslant [o]$
* for all $M$ reachable from the initial marking 
* it should be possible to reach the final marking from $M$ 


Example:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/workflow-nets-no-otc.png
* deadlock = no option to complete 
* marking $[o]$ is not reachable from $[i]$


Livelock Example:
* consider the net with a livelock
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/workflow-nets-livelock2.png
* the following is its reachability graph 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/workflow-nets-livelock2-rg.png 
* we see that two nodes are not connected: it's clearly a problem


=== Proper Completion ===
$M_0 \to ^* M \land M \geqslant [o] \Rightarrow M \equiv [o]$
* when $M$ is reachable from the initial marking 
* and it's great or equal to the final marking
* for proper completion to hold $M$ should be equal to $[o]$ 


=== No Dead Transitions ===
$\forall t \in T, \exists M: M_0 \to^* M$ and $t$ in enabled in $M$
* for all possible transitions there should exists at least one marking $M$ in which $t$ is enabled



=== [[Petri Nets|Petri Net]] Soundness ===
A sound workflow net can never be live:
* it should be able to reach the final state
* and nothing should be able to fire from that state 


A workflow net $N = (P, T, F)$ is sound iff
* a petri net $N' = (P, T \cup \{ \alpha \}, F \cup \{ (o, \alpha), (\alpha, i) \} )$ is sound

So we just connect $o$ and $i$ via some transition $\alpha$ 
* and check Petri Net soundness 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-soundness.png


Relation:
* if $N$ doesn't have the proper completion property, $N'$ will not be bounded
* if there's a deadlock in $N$, 
** there exists a firing sequence in $N'$ s.t. 
** it brings you to some state where you cannot reach $o$
** i.e. $N'$ is not live
* dead transitions: same notion in both $N$ and $N'$


== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Business Process Management]]</text>
      <sha1>3eyvul39oezd6ln6f6wz0nbgkemw0ca</sha1>
    </revision>
  </page>
  <page>
    <title>Workflow Nets/Workflow Patterns</title>
    <ns>0</ns>
    <id>356</id>
    <revision>
      <id>359</id>
      <timestamp>2015-07-05T16:28:52Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2098">{{stub}}

== [[Workflow Patterns]] in Workflow Nets ==

=== Sequence ===
First task $a$, then task $b$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-sequence.png


=== Parallel Split  ===
Tasks $b$ and $c$ are processed in parallel
* this construction is also called &quot;AND-split&quot;
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-par-split.png


=== Synchronization ===
Do $d$ only after both $b$ and $c$ are completed 
* this is a synchronization between two parallel processes 
* this construction is also called &quot;AND-join&quot;
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-synch.png


=== Parallel Routing ===
A combination of Parallel Split and Synchronization
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-parallel-ex.png


=== Exclusive Choice ===
after $a$, do $b$ or $c$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-xor.png
* choice in this case depends on the results of the activity $a$
* here both '''doA''' and '''doB''' will be active, but we want to fire only one of them, based on the activity $a$ 


=== Simple Merge ===
perform $d$ after $b$ or $c$ finishes
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-xor-merge.png


=== Alternative Routing ===
a combination of Exclusive Choice and Simple Merge
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-alt-routing.png


=== [[Deferred Choice]] ===
When the choice is deferred to the point when we execute something 
* for Petri Nets, visually looks identical to Exclusive Choice
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-deferred-choice.png


Deferred Choice vs Exclusive Choice
* in Exclusive Choice after execution of $a$ you already know what activity to run
* but for the deferred choice there's a race condition between the activities 


== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Business Process Management]]
[[Category:Petri Nets]]</text>
      <sha1>paphw63uvnwzej1ftm0whd3mrry1u73</sha1>
    </revision>
  </page>
  <page>
    <title>YAWL</title>
    <ns>0</ns>
    <id>357</id>
    <revision>
      <id>360</id>
      <timestamp>2014-02-01T22:54:23Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9392">== YAWL ==
YAWL is a graphical notation for expressing workflows, similar to [[Workflow Nets]] based on [[Petri Nets]], but with more expressive syntax.
* YAWL is based on [[Workflow Patterns]]
* but it's developed in academic environment


It is possible to express the following constructions:
* choices
* timeouts
* etc

== Basic Syntax ==
Syntax in YAWL looks similar to [[Petri Nets]]
* but there is syntactic sugar that makes it easier and more expressive
* and there also is some relaxation of the rules

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-and-xor.png

=== AND ===
AND-split:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-and-split.png

AND-join
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-and-join.png
* note that the semantics of the AND-join in YAWL is the same: 
* both places need to have tokens for $d$ to fire

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-and.png


=== XOR ===
XOR-split
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-xor-split.png
* need to put some code to the XOR-split node: so it will decide which way to follow
* (don't confuse with [[Deferred Choice]])

XOR-join
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-xor-join.png
* semantics is the same: $d$ can fire if there's a token in either place

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-xor.png



=== Loops ===
While-loop
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-while-loop.png
* based on the condition in the XOR-split it either continues or stops
* it was not possible to express that in [[Workflow Nets]]


Repeat-loop
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-repeat-loop.png
* until the condition in the XOR-split is not satisfied, $B$ will not be enabled


=== Start and Stop ===
There's also a special notation for start and stop places
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-start-stop.png


=== Transitions ===
Transitions in YAWL can be connected directly, without a place within them
* but there still is an implicit invisible place between such transactions
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-transitions.png
* if there's a place between transitions, it means that one is done, but the other has not started


Transitions in YAWL are no longer atomic 
* in YAWL now you cannot assume that they fire immediately: they may need some time to do the task
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-transitions-2.png
* so in essence, one transition in YAWL correspond to two transitions in a Petri Net and one place between them



=== Exercise ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-ex-seq.png
* what are the valid firing sequences? what activities can be performed in parallel?
* first, let's explicitly show the invisible places and name all the places
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-ex-seq2.png
* now we can build some kind of a [[Reachability Graph]] (here we don't consider places inside the transactions)
* but in this case, unlike in [[Petri Nets]], firing one transition can lead to several states 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-ex-seq2-rg.png
* in this example firing $B$ may bring to 3 different states, depending on what arch it will take
* we see that this network in not [[Workflow Soundness|sound]]:
** it has no option to complete in several cases
** it has improper termination 
* the highlighted edges lead to the final state 
** thus the valid firing sequences are:
** $ABCD$
** $ABCEFG$
** $ABCFEG$
** $ABCFEG$
** $ABCCEFG$
** $ABCCFEG$
** note that, for instance, $ABCCEFG$ may correspond to two different paths in the reachability graph 
* based on that it's clear that $E$ and $F$ can run in parallel


== Advanced Syntax ==
=== Cancellation Regions ===
{{ Main | Cancellation Regions}}


=== OR-Split and OR-Join ===
==== OR-Split ====
OR-split is similar to XOR-split
* but instead of taking one route, it can take many 

Example
* suppose we're buying a flight ticket and offered 2 additional options: hotel and car
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-or-split.png
* the branches to active depend on what exactly you have selected
* and the OR-split should be programmed to route in the needed directions
* the system can fire many tokens, but there's one restriction: there must be at least one token

Note that
* OR-split is just syntactic sugar 
* it can be expressed with AND-splits and XOR-splits
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-or-split-with-and-xor.png


==== OR-Join ====
OR-Join is used to synchronize many incoming branches

It has the &quot;bus driver&quot; semantics
* OR-Join is activated only when all tokens are ready to be consumed
* a bus driver will wait for people to jump in when he sees that people are still coming


We should handle OR-joins 
* this semantics can be computationally quite expensive
* some decision properties may suddenly become unavailable
* if complicates the model


Example
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-or-join.png
* if there are still tokens to arrive, the OR-join will wait for them 
* once everybody is ready - it fires

Consider the following net:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-or-join-dilemma.png
* in this example none of the OR-joins can fire
* there hypothetically can be more tokens to arrive
* so they are waiting
* no [[Workflow Soundness|Option to Complete]]


==== Examples ====
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-or-join-ex.png
* case (a):
** $C$ is enabled: it's a XOR join
** and $D$ is enabled: it's not possible to get a token from another branch
* case (b):
** $C$ is working, but it can be started again: it's enabled since there's another token
** $D$ is not enabled: it will be only when $C$ finishes its work
* case (c): 
** $A$ is already running 
** $C$ is enabled (here it's the same situation as in the case (a))
** but $D$ is not enabled: there's in a token inside $A$, which may arrive from the branch below
* case (d):
** $C$ enabled 
** but $D$ is not enabled: there's a token before $C$ that may arrive 


=== Sub-Nets ===
To increase readability it's possible to fold some activities to one 
* this concept is called a ''sub-net''
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-subnets.png
* a subnet must also be a valid net - with its own start and stop places 



== Data ==
It is possible to store some variables in the YAWL engine
* to keep the results of execution, etc

Data can be stored at different levels (i.e. scopes)
* process level - global
* case level - related to this particular case 
** i.e. data for each case is different
* task level - most local 

We don't need to transfer data from activity to activity
* there's a single data storage that will keep it
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-datastorage.png


== Timers ==
'''TODO'''


== Resource Perspective ==
'''TODO'''


== YAWL Option to Complete ==
YAWL's option to complete is different from the [[Workflow Soundness|option to complete]] property of [[Workflow Nets]]

YAWL-OTC:
* for every reachable marking $M$ we can reach the final marking $[o]$
* so this is a combination of Option to Complete and Proper Termination
* unfortunately YAWL-OTC is not always decidable, therefore it's sometimes still better to use the definition of the Option to (improperly) Complete 


== Examples ==
=== Housing Agency Net ===
* [[Housing Agency Workflow]]


=== Example 2: Travel Agency ===
To organize a trip
* the customer request is registered
* then an employee looks for opportunities 
* the customer is contacted to find out whether he is still 
interested and whether more alternatives are desired
* if the customer selects a trip, then the trip is booked. 
* in parallel (optionally) one or two types of insurance are prepared
* two weeks before the start date the documents are sent to the customer
* it is possible that the customer cancels the trip at any time before the start date

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-travel-agency.png

It is also possible to use OR-join for choosing the insurances:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-travel-agency-orjoin.png


=== Example 3: Homework Submission ===
An exercise for modeling from the resource perspective:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-assignment-submission.png


=== Example 4: Four Dining Philosophers ===
The same net as in [[Petri Nets]]:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-dining-philosophers.png



== Links ==
* http://www.yawlfoundation.org/yawlbook/downloads.html
* http://yawlfoundation.org/yawldocs/GettingStartedWithYAWL.pdf

== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Business Process Management]]</text>
      <sha1>4goe7rr0szpqmbd731h02mlq4mvk2oh</sha1>
    </revision>
  </page>
  <page>
    <title>Cancellation Regions</title>
    <ns>0</ns>
    <id>358</id>
    <revision>
      <id>361</id>
      <timestamp>2014-02-01T23:00:32Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4737">== Cancellation Regions ==
Consider the following scenario:
* at each point of time the user may decide to cancel the order 
* this is very difficult to express with plain [[Workflow Nets]]
* therefore in [[YAWL]] there is a special syntactic construction for that

=== Motivation ===
* at the beginning we have the following
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-cr-motiv1.png
* now we need to be able to cancel the task at the bottom:
* we add a special cancel task for this that takes the token and puts it directly to the final place
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-cr-motiv2.png
* then we add more such cancel tasks
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-cr-motiv3.png
* so it quickly becomes cluttered and unreadable


=== Syntax ===
A ''cancellation region'' consists of
* a number of tasks and places 
* transitions between tasks - recall that in YAWL they contain &quot;hidden&quot; places
* the cancellation task


Semantics
* upon completion of the cancellation task all tokens in the cancellation region are removed
* so it guarantees the [[Workflow Soundness|proper completion]] property:
* it makes sure the unneeded tokes are removed and no other activity within the Cancellation Region is performed


Syntax:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-cr-syntax.png
* if there was something in the cancellation region when the cancellation task was activated
* it will be removed


=== Usage Pattern ===
Typical Pattern of Usage:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-cr-pattern.png
* there's a cancellation place before the cancellation task
* when the job inside the cancellation region is done, '''close case''' takes a token away from this place
* so the cancel task is no longer active 
* but if the cancel task fires, it takes the token from the cancellation regions and finishes the case


=== [[Workflow Soundness]] ===
In [[Workflow Nets]] unboundness always means unsoundness 
* but with cancellation regions it's no longer the case 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-cr-unboundness.png
* but [[Reachability Graph]] can no longer be used to decide on soundness: it's infinitely large now
* for that we use [[Coverability Graph]]


== Examples ==
=== Booking ===
* a flight, hotel and car can be booked in parallel. 
* if booking of all three succeeds the payment follows. 
* otherwise task cancel is executed
* cancel is delayed until all three bookings succeed/fail
* if something is already booked, nothing is reverted: it remains booked


We model it the following way:
* each option can either fail of succeed, therefore for each we have two possible output places
* the waiting is modeled with OR-Join which, because of its Bus-Driver semantics, will wait for all possible tokens to come: we connect it with all fail places
* the OR-join is the cancellation task that will put the tokens out of succeeded places on activation
* if we used XOR-join instead of OR-join, then it would fire once there's at least one token in any of the failed places
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-cr-booking-1.png



Consider a slightly different scenario:
* cancel is not delayed until everything fails/succeeds
* if there are booking tasks that have not started yet, they are canceled as well 


The model above is changed a little bit:
* now we use XOR-join: one there's a token, it fires
* and the cancellation region is expanded to include everything after the AND-split
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-cr-booking-2.png

Note that in this case the cancel task is itself a part of the cancellation region
* it's to ensure that all tokens are removed and cancel can never fire twice

Assume it wasn't the part of the CR
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-cr-booking-3-nocr.png
* suppose booking of hotel and car failed 
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-cr-booking-3-2tok.png
** if one is fired first, then this will remove the remaining token
** but what if both tokens are already allocated and now are in the cancel task:
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-cr-booking-3-2tok2.png
** it processes one token and outputs it
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-cr-booking-3-2tok3.png
** but now it can fire the second time!


== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Business Process Management]]</text>
      <sha1>mufdtb2lal94qlzzx5gode7dwj59lhq</sha1>
    </revision>
  </page>
  <page>
    <title>Coverability Graph</title>
    <ns>0</ns>
    <id>359</id>
    <revision>
      <id>362</id>
      <timestamp>2014-02-01T22:59:43Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2295">== Coverability Graph ==
This is a way of representing states of workflows, similar to [[Reachability Graph]]


=== Motivation ===
Consider the following [[YAWL]] flow:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-cr-unboundness.png.
* because of the [[Cancellation Regions]] the [[Reachability Graph]] of this workflow becomes infinitely large
* it is possible to know when we need to stop expanding it?
** if there was no Cancellation Region, it would be enough just to repeat it 2 times to see that there's no proper termination
** but in this case we don't know when to stop 
* $\Rightarrow$ can no longer use it for checking for [[Workflow Soundness]]


However there is a concept of Coverability Graphs that are 
* computationally less expensive
* can still be used to decide on some properties


=== Coverability ===
Let's consider the following [[Petri Nets|Petri Net]]:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-coverability-ex.png
* how we can represent $\infty$ many nodes in this reachability graph? 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-coverability-ex-reach.png
* note that marking $[p_1, p_3] &lt; [p_1]$ - strictly larger 
** thus with marking $[p_1, p_3]$ the petri net can do all the same as $[p_1]$ plus a little bit more
* so if it's possible to get from one marking $M_1$ to another marking $M_2$ s.t. $M_2$ covers $M_1$ completely - then we have a loop 


''Coverability'':
* marking $M$ is ''coverable'' by $M'$ $\iff$
* there $\exists$ a marking $M'$ s.t. $M \to^* M'$ and $M \leqslant M'$


Let's construct the coverability graph for this example
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-coverability-ex-reach2.png
* look at all the nodes that you can reach
* if you notice some marking that covers another marking, add a loop to the coverability graph
* &lt;img src=&quot;https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-coverability-ex-с.png&quot; /&gt;
* note that this graph is finite 
* and we can see that in this graph we do have the option to complete 


== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Petri Nets]]
[[Category:Graphs]]
[[Category:Business Process Management]]</text>
      <sha1>cc5lzl114uvel5pf8boqlbb2woyae4g</sha1>
    </revision>
  </page>
  <page>
    <title>BPM</title>
    <ns>0</ns>
    <id>360</id>
    <redirect title="Business Process Management" />
    <revision>
      <id>363</id>
      <timestamp>2014-02-01T23:03:06Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="41">#Redirect [[Business Process Management]]</text>
      <sha1>mrl5vdn9dztmfqr2ifumqzvpoqlgo99</sha1>
    </revision>
  </page>
  <page>
    <title>BPMN</title>
    <ns>0</ns>
    <id>361</id>
    <revision>
      <id>364</id>
      <timestamp>2014-02-01T23:18:03Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6419">== BPMN ==
BPMN - Business Process Modeling Notation 
* This is a graphical language for describing business processes for [[BPM]]
* BPMN 2.0 is de-facto the industrial standard for [[BPM]]
* executable via [[BPeL]] or there are tools that natively support execution of BPM


== Control Flow Syntax ==
Differences with [[YAWL]] and [[Workflow Nets]]
* no such things as places in BPML


=== Activities ===
Activities are things that are performed as a part of the process 

They can be:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/bpmn/bpmn-activities.png
* task: a single business action
* look: an action that repeats over time
* sub-process that contains other process inside
* and all other things 


=== Gateways ===
Gateways are needed for routing purposes

There are the following gateways
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/bpmn/bpmn-gateways.png
* AND-split and AND-join
* XOR-split and XOR-join
* Event-based (which is [[Deferred Choice]])
* OR-split and OR-join (same semantics as in [[YAWL]])


Note that activities can be connected to multiple activities without any gateways 
* but these gateways are implicitly assumed in this case 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/bpmn/bpmn-activities-impl-gateways.png
* so be careful with the following construction:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/bpmn/bpmn-activities-impl-gateways-careful1.png
* because it will implicitly assumed to be something like the following
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/bpmn/bpmn-activities-impl-gateways-careful2.png


=== Events ===
Events represent actions that take place 
* when the flow starts and ends
* when something happens on the way from start to end 
* it is also possible to add some decorations to express meaning of some events

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/bpmn/bpmn-events.png


During the flow some exceptions can occur

There are 2 types of events for that:
* &quot;throw&quot; events
* &quot;catch&quot; events


Exceptions:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/bpmn/bpmn-exceptions.png
* something inside a subflow can throw an exception
* and there are &quot;guarding&quot; listeners that are triggered when such exceptions are thrown


Consider this example:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/bpmn/bpmn-exceptions-ex.png
* there's one throwing event that interrupts the flow 
** ''throwing event''
** produces some events 
** these events are interrupting: the flow ends with such event
* and this exception is caught outside of the subflow and handled 
** ''catching event''
** listens for certain events
* we also have ''non-interrupting'' events - border events 
** they are activated when something happens outside of the flow


Also note that in this example there are two blocking intermediate events
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/bpmn/bpmn-events-receive.png
* these events stop the flow and resume when a message is received
* note that in this case such events keep tokens inside
* so we need a concept of [[Cancellation Regions]] to be able to terminate all subprocess 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/bpmn/bpmn-events-bullseye.png terminates all the processes and stops the flow 


Here's a list of decorations for events:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/bpmn/bpmn-events-all.png



=== Pools and Lines ===
Different organizations and different actors withing the organization are represented with 
* pools for organizations
* lines withing the pools for actors
* that makes it possible to show visually who is in charge of what


If a task is on a line that belongs to some actor,
* he is responsible for executing it


External actors
* it is advisable to model external actors - actors that do not execute the business process themselves (clients, etc) - with &quot;empty&quot; pools
* this way the interaction with them can be clearly seen
* it is good because such actors do not perform any actions, but they generate &quot;incoming events&quot;
* and we don't have any illusion that we have control over what the external actors 
* we interact with them only with messages 


Example:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/bpmn/bpmn-external.png
* a student is an external actor: they generate events but do not execute any business process themselves
* student is &quot;abstract&quot; - there are no actions in this pool


== Approach for Building a Model ==
# Decide: when does process start/end
# Enumerate main activities &amp; possible end-states
# Create top-level BPMN diagram
# Expand top-level activities to sub-processes
# Add pools for external parties &amp; message flow (business context)
# Repeat 4-5 for sub-processes

Walk-through example:
* [https://www.evernote.com/shard/s344/sh/7e4b0db5-002c-4d67-a813-6a8b8d54070b/11743304157d0e41b60ca0ed6c172ac5 Car Dealer Example] (With pictures taken during the lecture)


== Examples ==
Example 1: 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/bpmn/bpmn-ex1.png


Example 2:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/bpmn/bpmn-exceptions-ex.png


Example 3:
* booking a trip
* [[YAWL]] diagram:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-travel-agency.png
* converting it to BPMN:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/bpmn/bpmn-insurance-ex.png



== Links ==
* Lecture notes from Evernote: [https://www.evernote.com/shard/s344/sh/9de02c1b-f96f-41ff-9095-13ae608be099/e1e4dd29c665b5f2a6f21c45ea90a467] 
* BPMN 2.0 reference card [http://www.chellar.com/AnalysisFu/images/ccp/BPMN_Poster.pdf]
* [https://dl.dropboxusercontent.com/u/5119252/BPM/2013/Exercises%20BPMN.pdf Exercises 1] [https://dl.dropboxusercontent.com/u/5119252/BPM/2013/Solution%20BPMN.pdf Solutions 1]
* [https://dl.dropboxusercontent.com/u/5119252/BPM/2013/BPMN%20Modeling.pdf Exercises 2] [https://dl.dropboxusercontent.com/u/5119252/BPM/2013/Solutions%20BPMN%20Modeling.pdf Solutions 2] ([https://www.evernote.com/shard/s344/sh/5c34000b-89aa-4277-93e9-54ac3ba77e98/79ca7457df8ba7aac3766ac2656d9235 in-class notes])



== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Business Process Management]]</text>
      <sha1>d2c0cwqby0iodqpldck1nw9633hlqb2</sha1>
    </revision>
  </page>
  <page>
    <title>Deferred Choice</title>
    <ns>0</ns>
    <id>362</id>
    <revision>
      <id>365</id>
      <timestamp>2014-02-02T07:59:52Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1737">== Deferred Choice ==
Deferred Choice is a [[Workflow Patterns|workflow pattern]]. It it used to express a situation when the action you're going to take is not known till the point of executing it.

So, ''Deferred choice'': When the choice is deferred to the point when we execute something 
* for Petri Nets, visually looks identical to Exclusive Choice
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-deferred-choice.png


Deferred Choice vs Exclusive Choice
* in Exclusive Choice after execution of $a$ you already know what activity to run
* but for the deferred choice there's a race condition between the activities 


=== Example ===
Consider a flight:
* you can either print ticket at home or check in at reception
* based on this the following procedures are different
* it's a deferred choice: the company doesn't know which option you chose


== [[YAWL]] ==
In YAWL it's possible to tell the difference between XOR-split and Deferred choice

Consider this:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-deferred-choice.png
* we start with deferred choice: 
** both actions are enabled, and both are offered to the user 
** and the user decides what to do next
* but XOR-split is different
** based on some variables that were set before it (itself, not the user!) chooses the route
** for example, if variable &lt;code&gt;dosomething&lt;/code&gt; is set to true, we follow the top branch


== [[BPMN]] ==
In BMPN the deferred choice is represented by a special-purpose gateway
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/bpmn/bpmn-deferred-choice.png


== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Business Process Management]]</text>
      <sha1>55wsqdo9rfp3rs914djjg5mgmg8ic71</sha1>
    </revision>
  </page>
  <page>
    <title>Housing Agency Workflow</title>
    <ns>0</ns>
    <id>363</id>
    <revision>
      <id>366</id>
      <timestamp>2014-02-02T08:04:13Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3726">== Housing Agency Workflow ==
This is an exercise to build a [[Workflow Nets|Workflow Net]]

=== Description ===
Housing Agency

Registration
* potential tenants indicate their interests: 
** certain &lt;u&gt;criteria&lt;/u&gt;: price, size, location, etc
* the interests are entered into some database

Offer
* after the registration, the agency &lt;u&gt;sends an offer&lt;/u&gt; when a suitable apartment is found
* customer decides to &lt;u&gt;accept&lt;/u&gt; or &lt;u&gt;decline&lt;/u&gt; the offer 
* if he declines, the agency &lt;u&gt;continues to look&lt;/u&gt; for another flat
* if the customer doesn't respond in 2 weeks, it's assumed he has declined the offer
* if the customer declines two offers in a row, &lt;u&gt;the process ends&lt;/u&gt; automatically

Contract
* if the customer accepts the offer, he has to &lt;u&gt;sign a contract&lt;/u&gt;
* after signing he has to send the signed copy
* and pay 1000 USD deposit 
* once it's done, the tenants receive the keys


Payments
* they pay of the monthly basis
* every two months the finance department  &lt;u&gt;checks the payment history&lt;/u&gt;
* if everything is alright - no further action is needed
* if not, then a &lt;u&gt;warning is sent&lt;/u&gt;
* then the payment is checked 2 months later: if there are still problems, the &lt;u&gt;eviction process starts&lt;/u&gt;
* and then the process ends

Annual inspection
* the flat is checked annually 
* ok - no actions needed
* if problems (damages) - &lt;u&gt;tenants have to solve&lt;/u&gt; them in 4 weeks
* second inspection: if the problems solved - no actions are needed
* if not, the &lt;u&gt;damage must be paid&lt;/u&gt; by the tenants
* if payment is not received in 3 weeks, the &lt;u&gt;eviction process starts&lt;/u&gt;
* and the process ends


== [[Workflow Nets|Workflow Net]] Model ==
To model this in [[Petri Nets]], [http://www.pneditor.org/ PNEditor] was used 

Obtained model:

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-housing-agency.png

Bad sides of the model:
* lack of parallelism
* the model is too restrictive


== [[YAWL]] Model ==
The main flow:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-housing-agency1.png
* there are 2 [[Cancellation Regions]]
* note that for &quot;initiate eviction process&quot; this activity is also included to the cancellation regions of itself (for the reasons described in [[Cancellation Regions]])


Initiate Renting flow:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-housing-agency3.png

Check Payment flow
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-housing-agency4.png

Annual Check flow:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-housing-agency2.png

In this model:
* the issue with the lack of parallelism was fixed


== Re-discovering the Model ==
Using the [[Alpha Algorithm|$\alpha^+$ algorithm]]


Steps
* first of all, the transitions were renamed to letters
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-housing-agency-ren.png
* to obtain the possible sequences  we construct the following graph:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-housing-agency-firing.png
* then we execute [[Breadth-First Search]] restricting the traversal of each node to 2 visits
* and get a log with the following possible firing sequences: http://pastebin.com/kSyhR9uK
* then the [[Alpha Algorithm|$\alpha^+$ algorithm]] is applied to these sequences using [http://www.processmining.org/discontinued/emit EMiT] 
* and the following workflow net is rediscovered:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pn/petri-net-housing-agency-redisc.png



== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Business Process Management]]</text>
      <sha1>172ejwerly00d9604rwaiz3c3tkoyt5</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Petri Nets</title>
    <ns>14</ns>
    <id>364</id>
    <revision>
      <id>367</id>
      <timestamp>2014-02-02T10:57:21Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="40">[[Category:Business Process Management]]</text>
      <sha1>oele71ix1tan6de80vqvhgxpk5crhqs</sha1>
    </revision>
  </page>
  <page>
    <title>Dot Graph Examples</title>
    <ns>0</ns>
    <id>365</id>
    <revision>
      <id>368</id>
      <timestamp>2014-02-02T11:01:18Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2021">== Dot Graph Examples ==

=== Triangle ===
A triangle with large margins

&lt;pre&gt;
digraph A {

  rankdir=LR;
  center=true; margin=1; 
  nodesep=1.5; ranksep=0.5;

  node [shape=point,  height=&quot;.2&quot;, width=&quot;.2&quot;];

  a [xlabel=&quot;a&quot;];
  b [xlabel=&quot;b&quot;];
  c [xlabel=&quot;c&quot;];
  a -&gt; b -&gt; c;
  a -&gt; c;
}
&lt;/pre&gt;

http://i.stack.imgur.com/ibImr.png


=== Label + XLabel ===
&lt;pre&gt;
digraph A {

  rankdir=LR;
  center=true; margin=1; 
  nodesep=1.5; ranksep=1.5;

  node [height=&quot;0.5&quot;, width=&quot;0.5&quot;, fixedsize=true];
  
  X [xlabel=100];
  Y [xlabel=150];
  I1 [xlabel=150];
  I2 [xlabel=100];
  {X, Y}-&gt;{I1, I2};

}
&lt;/pre&gt;

http://habrastorage.org/files/380/2a0/b41/3802a0b414354ad58397d8a0ebfd0771.png


=== Edges with Opposite Direction ===
Source: [http://stackoverflow.com/a/4671684/861423]

&lt;pre&gt;
digraph A {
  rankdir=LR;
  center=true; margin=1; 

  node [height=&quot;0.33&quot;, width=&quot;0.33&quot;, fixedsize=true];

  b-&gt;a-&gt;d-&gt;g;
  a-&gt;e-&gt;h;
  e-&gt;g;
  d-&gt;{c,f};

  c-&gt;e [dir=&quot;back&quot;];
  g-&gt;h [dir=&quot;back&quot;];

  b,d,e [style=filled, fillcolor=red, peripheries=2];

  {rank=same; f;g;h;}
  {rank=same; d;e;c;}
  {rank=same; a;b;}
}
&lt;/pre&gt;

http://habrastorage.org/files/ddb/cf5/f66/ddbcf5f668c94490a91a563fcfcd3515.png


=== Neato Example ===
&lt;pre&gt;
graph G {
  nodesep=1.5;
  center=true; margin=1; 
  node [color=black, shape=rectangle, style=&quot;filled&quot;, fillcolor=skyblue];
  edge [len=2];
  a;b;c;d;e;
  a--{b,c,d,e};
  b--{c,d,e};
  c--{d,e};
  d--e;
}
&lt;/pre&gt;

http://habrastorage.org/files/4aa/a61/9d5/4aaa619d5eb6433a812eee3759c82efa.png


=== Double Edge ===
Source: [http://stackoverflow.com/questions/6219933/how-does-one-define-double-lines-for-edge-and-node-shapes-in-graphviz-dot]

&lt;pre&gt;
digraph G {
  rankdir=LR;
  nodesep=0.7; ranksep=1;
  node [shape=none, fixedsize=true, width=0.3];

  a-&gt;b-&gt;d;
  a-&gt;c-&gt;d;
  b-&gt;c [color=&quot;black:white:black&quot;,dir=none];
  a-&gt;e-&gt;d;
  c-&gt;e [style=invis];
  {rank=same;b;c;e;}
}
&lt;/pre&gt;

http://habrastorage.org/files/f84/5d8/269/f845d826920c4289ae0376767482c798.png


[[Category:Dot]]
[[Category:Snippets]]</text>
      <sha1>hkcb2k20cu4yurfkucgikgmzokc5fsi</sha1>
    </revision>
    <revision>
      <id>750</id>
      <parentid>368</parentid>
      <timestamp>2016-03-25T20:16:20Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2367">== Running from Command Line ==

Output to &lt;code&gt;png&lt;/code&gt; using &lt;code&gt;twopi&lt;/code&gt;

 dot -Ktwopi -Tpng graph1.gv -o graph1.png

Other algorithms (Layout Commands)
* &lt;code&gt;dot&lt;/code&gt;
* &lt;code&gt;fdp&lt;/code&gt;
* &lt;code&gt;neato&lt;/code&gt;
* &lt;code&gt;osage&lt;/code&gt;
* &lt;code&gt;sfdp&lt;/code&gt;
* &lt;code&gt;twopi&lt;/code&gt;

Not working on Windows:
* &lt;code&gt;circo&lt;/code&gt;

== Dot Graph Examples ==
=== Triangle ===
A triangle with large margins

 digraph A {
   rankdir=LR;
   center=true; margin=1; 
   nodesep=1.5; ranksep=0.5;
 
   node [shape=point,  height=&quot;.2&quot;, width=&quot;.2&quot;];
 
   a [xlabel=&quot;a&quot;];
   b [xlabel=&quot;b&quot;];
   c [xlabel=&quot;c&quot;];
   a -&gt; b -&gt; c;
   a -&gt; c;
 }

http://i.stack.imgur.com/ibImr.png


=== Label + XLabel ===
 digraph A {
   rankdir=LR;
   center=true; margin=1; 
   nodesep=1.5; ranksep=1.5;
 
   node [height=&quot;0.5&quot;, width=&quot;0.5&quot;, fixedsize=true];
   
   X [xlabel=100];
   Y [xlabel=150];
   I1 [xlabel=150];
   I2 [xlabel=100];
   {X, Y}-&gt;{I1, I2};
 }

http://habrastorage.org/files/380/2a0/b41/3802a0b414354ad58397d8a0ebfd0771.png


=== Edges with Opposite Direction ===
Source: [http://stackoverflow.com/a/4671684/861423]

 digraph A {
   rankdir=LR;
   center=true; margin=1; 
   
   node [height=&quot;0.33&quot;, width=&quot;0.33&quot;, fixedsize=true];
   
   b-&gt;a-&gt;d-&gt;g;
   a-&gt;e-&gt;h;
   e-&gt;g;
   d-&gt;{c,f};
   
   c-&gt;e [dir=&quot;back&quot;];
   g-&gt;h [dir=&quot;back&quot;];
   
   b,d,e [style=filled, fillcolor=red, peripheries=2];
   
   {rank=same; f;g;h;}
   {rank=same; d;e;c;}
   {rank=same; a;b;}
 }

http://habrastorage.org/files/ddb/cf5/f66/ddbcf5f668c94490a91a563fcfcd3515.png


=== Neato Example ===

 graph G {
   nodesep=1.5;
   center=true; margin=1; 
   node [color=black, shape=rectangle, style=&quot;filled&quot;, fillcolor=skyblue];
   edge [len=2];
   a;b;c;d;e;
   a--{b,c,d,e};
   b--{c,d,e};
   c--{d,e};
   d--e;
 }

http://habrastorage.org/files/4aa/a61/9d5/4aaa619d5eb6433a812eee3759c82efa.png


=== Double Edge ===
Source: [http://stackoverflow.com/questions/6219933/how-does-one-define-double-lines-for-edge-and-node-shapes-in-graphviz-dot]

 digraph G {
   rankdir=LR;
   nodesep=0.7; ranksep=1;
   node [shape=none, fixedsize=true, width=0.3];
   
   a-&gt;b-&gt;d;
   a-&gt;c-&gt;d;
   b-&gt;c [color=&quot;black:white:black&quot;,dir=none];
   a-&gt;e-&gt;d;
   c-&gt;e [style=invis];
   {rank=same;b;c;e;}
 }

http://habrastorage.org/files/f84/5d8/269/f845d826920c4289ae0376767482c798.png


[[Category:Dot]]
[[Category:Snippets]]</text>
      <sha1>cqxs2ghyfwpunziwslx2r1ss0bn5j6d</sha1>
    </revision>
  </page>
  <page>
    <title>Milestone Pattern</title>
    <ns>0</ns>
    <id>366</id>
    <revision>
      <id>369</id>
      <timestamp>2014-02-02T12:40:21Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="439">{{stub}}

== Milestone Pattern ==
This is a State-based [[Workflow Patterns|Workflow Pattern]]

Consider the following example:
* at the airport, you can check in only 24h before the flight 
* so we need to trigger this process only when appropriate

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/yawl/yawl-milestone.png



== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Business Process Management]]</text>
      <sha1>6ghsz5slrsdhxrz7ua9cemih41q92qe</sha1>
    </revision>
  </page>
  <page>
    <title>Region-Based Process Miner</title>
    <ns>0</ns>
    <id>367</id>
    <revision>
      <id>370</id>
      <timestamp>2015-07-05T09:45:15Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12235">== Region-Based Process Miner ==
This is a state-based approach to [[Process Mining]]
* as opposed to the [[Alpha Algorithm]], which is footprint-based


=== Motivation ===
Consider the following Petri Net:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-reg-based-petrinet-ex.png
* here's its [[Reachability Graph]]:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-reg-based-rg.png

Suppose that for each place $p_i$ we identify the set of nodes $R_i$ in the graph (i.e. the set of markings) where $p_i$ has a token:
* $p_1: R_1 \equiv \{[p_1]\}$
* $p_2: R_2 \equiv \{[p_2, p_3], [p_2, p_5]\}$
* $p_3: R_3 \equiv \{[p_2, p_3], [p_3, p_4]\}$
* $p_4: R_4 \equiv \{[p_3, p_4], [p_4, p_5]\}$
* $p_5: R_5 \equiv \{[p_2, p_5], [p_4, p_5]\}$
* $p_6: R_6 \equiv \{[p_6]\}$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-reg-based-regions.png

If we look carefully, we see that: 
* for place $p_2$ in the region $R_2$
** $a$ brings us into the region $R_2$ and $b$ takes us out this region
** meanwhile transitions $c$ and $d$ are always either completely inside $R_2$ or completely outside $R_2$
* for $p_4$ in $R_4$
** $b$ brings in, $e$ takes out
** again $c$ and $d$ do not cross the boundaries of $R_4$ 

We can notice the same patterns for all the regions 
* there are transitions that bring in and there are transitions that take out from the region
* and such transitions are connected with a place 
* there also are transitions that keep us inside the region


=== Transition System ===
But usually we do not know where are the tokens, we may know only that there are some states:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-reg-based-trans.png
* this is called a ''transition system'': we know the states, but don't know which places have tokens
* yet we still can use this idea to recognize the structural properties 
* and try to reconstruct the original model 

How? 
* create a transition system from logs
* find groups of nodes -- ''regions'' -- in the transition system
* add places to capture the behavior 


== Creating a Transition System ==
How to create a transition system?
* solution: an educated guess. 

A state may depend on:
* (1) actions taken so far, and the number of times they were executed
* (2) actions we will do in the future
* (1) and (2)

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-trans-traces.png


So there are many way of &quot;learning&quot; the transition system 
* this is about guessing and trial and errors 
* and a little bit of knowledge of the domain is also helpful to choose the right abstraction


=== Past Without Abstraction ===
Sometimes also called &quot;prefix [[Automata|automaton]]&quot;
* to define the state we look at what we've seen so far
* we don't make any abstractions:
** i.e. the sequence $\langle a, b \rangle \ne \langle b, a \rangle $

Algo:
* at the beginning the path-so-far is empty 
* after $a$ fires, you add it to the sequences of the seen events 

For log $L = [abcd, acbd, acd]$ we have:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-past-wo-abstraction.png

Downsides:
* not generalizing at all
* end up with one path for each trace
* want to &quot;abstract&quot; from this: want states to join after a while


=== Future Without Abstraction ===
Based on things that you will see in the logs 
* some states can be merged with this approach 

For log $L = [abcd, acbd, acd]$ we have:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-future-wo-abstraction.png

Better
* we see that it can generalize a bit
* i.e. recognize the same suffixes of different trances and join them 


=== Past with Multiset Abstraction ===
Now we add some abstraction:
* order in which we have seen the traces in not important anymore
* two states are considered to be the same if all activities we've seen so far fired equal number of times 
* i.e. the traces-so-far form a multiset 
* and $[a, b, c] \equiv [a, c, b]$
* this works well for [[Petri Nets]] as long as there are no transitions with the same name


For log $L = [abcd, acbd, acd]$ we have:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-past-multiset.png


=== Only Last Event Matters ===
Another abstraction: 
* we keep only one most recently seen event 
* so it's a [[Markov Chain]] with memory of 1
* and what you can do next depends only on what you've just seen 

For log $L = [abcd, acbd, acd]$ we have:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-1lr.png


=== Only Next Event Matters ===
Analogously, 
* but here we care only about the next event


For log $L = [abcd, acbd, acd]$ we have:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-1next.png

Note:
* we see that firing $a$ can bring us to 3 different states 
* not deterministic!
* you'll never see such thing in a [[Reachability Graph]] of a [[Petri Nets|Petri Net]]
* most likely wrong abstraction


=== Examples ===
Consider this log: $L_2 = [abcd, abcdce, acbe, acdbce, acbdce]$
* for each trace in the log we try build a branch in the transition system


==== Past with Set Abstraction ====
$L_2 = [abcd, abcdce, acbe, acdbce, acbdce]$

{| class=&quot;wikitable&quot;
! $abcd$ 
| https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-ex1-1.png
|-
! $abcd$
| https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-ex1-2.png
|-
! $acbe$
| https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-ex1-3.png
|-
! $acdbce$
| https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-ex1-4.png
|-
! $acbdce$
| https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-ex1-5.png
|}

But because of the set abstraction we must have lost some information:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-ex1-6.png
* there's a self-loop that keeps us in the same state 
* so there may be something wrong - we must make sure such things are expected
* in this log it's clear that it's not the case (we never see anything like $...cc...$, $...ccc...$, etc)
* so it allows too much behavior that we don't see in the logs 


=== Conclusions ===
We see that it may be very hard to select the right way of constructing the transition system
* we need to try and see 
** select an abstraction
** construct the transition system from it
** try to extract a petri net
** evaluate quality
** see if it makes sense
* some domain knowledge is always helpful 


== Theory of Regions ==
=== Regions ===
a region $R$ is a set of states of a transition system $T$ s.t.
* if a transition $t$ exits $R$, then all arcs labeled with $t$ must exist $R$
* if $t$ enters $R$, then all arcs labeled with $t$ must enter
* all other transitions $t$ must not cross the boundaries of $R$


==== Example 1 ====
Consider this transition system:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-ex2.png

Identify the following regions:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-ex2-1.png
* (1): noting enters, only $a$ leaves: $a$ is connected to the input place $i$
* (2): $b$ enters, $e$ leaves, others don't cross the boundary: collect $b$ and $e$ via a place
* (3): $a$ enters, $b$ leaves: connect them via a place 
* (4): connect $e$ to the output place $o$
* so we have:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-ex2-2.png

Next, find two mode regions:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-ex2-3.png
* (5): $a$ enters, $d$ leaves, connect them
* (6): $d$ enters, $e$ leaves, connect them
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-ex2-4.png

And finally:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-ex2-5.png
* (7) $a$ enters, $c$ leaves
* (8) $c$ enters, $e$ leaves
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-ex2-6.png

So the discovered network is:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-ex2-7.png

Examples of not regions:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-ex2-8.png
* this is not a region: $c$ is both inside the region and exists it
* the same for $b$ and $d$ 
* it it corresponded to a place, it would be a very strange place:
** sometimes when a token is in $c$ it cold fire, but it would keep the token
** and sometimes it would consume the token 


==== Example 2 ====
For example, consider the following transition system:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-reg-based-trans-ex.png
* we see that there are 7 transitions: $A,B,C,D,E,F,G$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-reg-based-trans-ex1.png 

how to connect them? 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-reg-based-trans-ex2.png
** nothing enters this region
** transitions $A$ and $B$ leave the region
** so we must connect the input place with these transitions
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-reg-based-trans-ex3.png
** for this region, $B$ enters, $E$ leaves
** so we connect $B$ and $E$ with a place
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-reg-based-trans-ex4.png
** $A$ and $D$ enter; $C$ leave
** so we add one place, and connect $A$ and $D$ to it, and the place to $C$ 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-reg-based-trans-ex5.png
** analogously we connect $A$ and $D$ via a place
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-reg-based-trans-ex6.png
** $C$ enters the region, $G$ and $F$ leave
** we connect $C$ to a place, and the place to $G$ and $F$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-reg-based-trans-ex7.png
** connect $D$ and $F$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-reg-based-trans-ex8.png
** and finally, $F$ and $E$ are connected to the final place


=== Minimal Regions ===
It's important to have regions as minimal as possible 
* otherwise a region may correspond to several places 

Regions
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/ts-ex2.png
* all nodes together form a region
* all nodes except for the first and last one - also form a region
** enter by doing $a$, exit by doing $e$
* but we want to find minimal ''non-trivial'' regions

''Trivial'' regions
* empty region (nothing takes in, nothing takes out - a region as well)
* all nodes together

All other regions:
* combination of two or more minimal regions


=== Properties ===
Let $S$ be a set of all states of a transition system
* trivial regions: $S$, $\varnothing$
* compliments: if $R$ is a region, then $S - R$ is also a region
* but the complimentary region is not necessarily minimal


=== Basic Algorithm ===
Compute $S^*$ - the set of all minimal regions
* for each $R \in S^*$ generate a place:
* add arcs between
** post-region of $R$ (transitions that leave $R$) - output for that place
** pre-region of $R$ (transitions that enter $R$) - input for that place
* add a token to each place that correspond to initial regions

The result - is the minimal saturated net


== Limits ==
=== Loops of Length 1 ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-reg-based-lim.png
* in this example $b$ can fire $\infty$ number of times 
* but you cannot detect it - $b$ cannot be a pre-region and a post-region at the same time 
* there are mechanisms to overcome this problem - like in the [[Alpha Algorithm|$\alpha^+$ algorithm]]


=== Susceptibility to Noise ===
Suppose by mistake instead of $b$ you have $bb$
* that can completely spoil your logs
* so first we need to pre-process logs to make sure there are no noise 
* or we can weaker the &quot;region&quot; condition - assume that it's enough to have transitions completely inside or outside only in 99% of cases 
** and allow crossing in 1% 



== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Business Process Management]]
[[Category:Process Mining]]</text>
      <sha1>1g74ixf0vhrb8m8ad7as8kljagjg4og</sha1>
    </revision>
  </page>
  <page>
    <title>Minimal Cut</title>
    <ns>0</ns>
    <id>368</id>
    <redirect title="Minimal Cut Problem" />
    <revision>
      <id>371</id>
      <timestamp>2014-02-08T12:28:25Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="33">#Redirect [[Minimal Cut Problem]]</text>
      <sha1>nhx9mlpizk1p3sk2j5aspsr9hu1nvo9</sha1>
    </revision>
  </page>
  <page>
    <title>Process Mining</title>
    <ns>0</ns>
    <id>369</id>
    <revision>
      <id>372</id>
      <timestamp>2015-07-05T16:21:06Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3887">== Process Mining ==
Suppose we have a log of our process, but do not have the model of this process
* the ''process mining'' is a way to find a process from the logs
* the model can be a [[Workflow Nets|Workflow Net]], [[YAWL]] or [[BPMN]] model. 


=== Definitions ===
A process mining algorithm is a function that
* maps an event log $L$ to some workflow model
* ideally the model should be sound 

play-in = process discovery 
* event logs $\to$ workflow model
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/process-discovery.png


the ''ability to rediscover''
* is a property of a process mining algorithm to discover a model of some process 
* from logs that have been generated from this model 
* i.e. in case of [[Petri Nets]], if $N$ is the original model and $N'$ is the discovered model, then $N \equiv N'$


=== Some Notes ===
Usually, first a [[Petri Net]] model is discovered
* and then this model is converted to [[YAWL]] or [[BPMN]]
* because Petri Nets are simpler 


== Measures ==
There are four conflicting criteria
* Fitness
** the discovered network should allow the behavior seen in the logs
* Precision
** the discovered network should not allow the behavior not seen in the logs
** too precise $\to$ bad generalization
* Generalization
** the discovered model should generalize the behavior seen in the logs
* Simplicity
** it should be as simple as possible
** too simple $\to$ low fitness

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-criteria.png
* The main challenge of [[Process Mining]] is that all these criteria are conflicting:
* It's really hard to simultaneously satisfy all of them
* this makes [[Process Mining]] to be a [[Multi-Objective Optimization]] problem


=== Fitness ===
Can we replay the log?
* we try to replay each sequences from the logs 
* so for each we see if this sequences is allowed
* if each sequence can be replayed - 100% fitness
* special notion for fitness is also defined for the [[Genetic Process Miner]]


=== Precision ===
Do we underfit the log?
* play out the model, capture logs 
* see what's generated and compare to the original logs
* is it far? (need to have some distance measure)

if produced logs $\subseteq$ original logs
* then we have 100% precision


=== Generalization ===
Do we overfit the log? 
* very hard to measure 


=== Simplicity ===
The simpler the model - the better
* may add some penalty for each added place 
* (the more places we add, the more complex the model becomes)


=== Examples ===
==== The Flower Model ====
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-flower.png
* this model in at the one end of spectrum
* very simple
* good fitness: every possible trace can be reproduced
* generalization: allows a lot of behavior
* but precision is very low: it allows a lot of behavior not seen in the logs


==== The Enumerating Model ====
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/pm-enum.png
* another end of the spectrum
* behavior only seen in the logs: not more, not less
* good fitness and good precision
* no generalization at all
* no simplicity


=== Conclusions ===
So [[Process Mining]] is difficult
* it's a [[Multi-Objective Optimization]] problem
* there are no negative examples
* the search space is too complex 
* logs typically show only a fraction of possible behavior 



== Algorithms ==
These algorithms let you find a [[Petri Nets|Petri Net]] from logs
* [[Alpha Algorithm|$\alpha$ and $\alpha^+$ algorithms]] - simple, but tend to overfit, very susceptible to noise in logs
* [[Region-Based Process Miner]] - state-based approach, still susceptible to noise
* [[Genetic Process Miner]] - good performance, much less susceptible to noise


== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Business Process Management]]
[[Category:Process Mining]]</text>
      <sha1>b05hnuh6ll95lcu8vuu36cgoviatcht</sha1>
    </revision>
  </page>
  <page>
    <title>Petri Net</title>
    <ns>0</ns>
    <id>370</id>
    <redirect title="Petri Nets" />
    <revision>
      <id>373</id>
      <timestamp>2014-02-08T14:48:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24">#Redirect [[Petri Nets]]</text>
      <sha1>4vt7gzyijg4nfqtma1qqmq578v3tv15</sha1>
    </revision>
  </page>
  <page>
    <title>Genetic Process Miner</title>
    <ns>0</ns>
    <id>371</id>
    <revision>
      <id>374</id>
      <timestamp>2014-02-08T14:53:55Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5581">== Genetic Process Miner ==
This is an algorithm from the family of [[Genetic Algorithms]] for [[Process Mining|mining business processes]]
* it's much more resilient to noise 
* allows for incremental improvement 
* can be combined with other approaches 


=== Overview ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/gm-overview.png
* first we create the initial population
** can just randomly create some [[Petri Nets]], randomly adding places 
** or by applying [[Alpha Algorithm]] or [[Region-Based Process Miner]]
* at each step we compute fitness for all the instances of a population
* elitism - process of keeping the best ones
* then all &quot;survived&quot; instances are considered as &quot;parents&quot;
** cross-over - process of combining different petri nets (these petri-nets are already good solutions)
** mutation adding some random changes for diversifying


=== Cross-Over ===
Cross-over
* a process of producing a &quot;child&quot; by two parental instances 
* selecting parents
** completely at random
** using fitness to quicker converge to optima
** note that we should not always select only &quot;the best&quot; - we need diversity


How to create a petri net from two other petri nets?
* suppose we have two parental petri nets:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/gm-crossover-p.png
* we may find some ''minimal cut'', cut the parents and make children from then 
** minimal cut is the minimal number of transitions to remove s.t. the net becomes completely disconnected 
** the same as in the [[Graph]] Theory: [[Minimal Cut]]
* in this example: 
** can cut in $(e, f)$ because in both cases 
** from $e$ it goes to $g,h$  and on the left you have $a,b,c,d$ 
** so it's ideal 
* we take $(e, f)$ out and get two disconnected components 
** combine left and right parts of the petri nets to form children 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/gm-crossover-c.png


=== Mutation ===
Examples of mutations:
* remove or add a place
* add an arc


=== Parameters ===
So there are quite a few parameters that we have to provide:
* objective function we want to optimize (below)
* the way we do the cross-over
* how do you select parents?
* the way we do the mutations
* elitism - top 10%, certain threshold, etc
* how large the population should be
* how many generations you'll run before termination
* when we kill some instances?


Change one parameter
* $\Rightarrow$ different solution in the end

Also 
* a lot of randomness is involved 
* it may be computationally expensive



== Cost Function: Fitness ==
=== Trace Level Fitness ===
Define ''trace-level fitness'' as: 
* $\text{fitness}(\sigma, N) = \cfrac{1}{2} \left( 1 - \cfrac{m}{c} \right) + \cfrac{1}{2} \left( 1 - \cfrac{r}{p} \right)$
* $m$ - # of missing tokens
* $c$ - # of consumed tokens
* $r$ - # of tokens left over when something reaches the output place
* $p$ - # of produced tokens


=== Example 1 ===
Consider this example:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/gm-fit-ex1.png
* logtrace: $\sigma_1 = \langle abeg \rangle$
* $m = 0, c = 0, r = 0, p = 1$ 
** $p = 1$ because there's a token in the input place
* $a$ fires - it generates 2 tokens 
** $p \leftarrow p + 2 = 3$
** $c \leftarrow c + 1 = 1$
* $b$ fires, produces one token, consumes one token
** $p \leftarrow p + 1 = 4$
** $c \leftarrow c + 1 = 2$
* $e$ needs to fire
** but it cannot: one token is missing, so we add it and fire $e$
** $p \leftarrow p + 1 = 5$
** $c \leftarrow c + 2 = 4$
** $m \leftarrow m + 1 = 1$
* $g$ fires and we're done
** $p \leftarrow p + 1 = 6$
** $c \leftarrow c + 1 = 5$
* but there's one remaining token that was left over after firing $a$ 
** $r \leftarrow r + 1 = 1$
* and finally we remove one token from the output place
** $c \leftarrow c + 1 = 6$
* $\text{fitness}(\sigma_1, N_1) = \cfrac{1}{2} \left( 1 - \cfrac{1}{6} \right) + \cfrac{1}{2} \left( 1 - \cfrac{1}{6} \right) = \cfrac{5}{6}$


=== Example 2 ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/gm-fit-ex2.png
* logtrace: $\sigma_2 = \langle adceh \rangle$
* $p = 1, c = 0, m = 0, r = 0$
* $a$ fires, produces 1, consumes 1
** $p \leftarrow 2, c \leftarrow 1$
* $d$ needs to fire
** but there's no token in the place before $d$, so we need to put it there
** $m \leftarrow 1$
** $d$ fires: $p \leftarrow 3, c \leftarrow 2$
* $c$ fires
** $p \leftarrow 4, c \leftarrow 3$
** note that $c$ and $d$ were executed in order different from the order that the model can produce
* $e$ fires 
** $p \leftarrow 5, c \leftarrow 4$
* $h$ fires
** $p \leftarrow 6, c \leftarrow 5$
* we're done
** one token is left: $r \leftarrow 1$
** taking the last token from $c$: $c \leftarrow 6$
* $\text{fitness}(\sigma_2, N_2) = \cfrac{1}{2} \left( 1 - \cfrac{1}{6} \right) + \cfrac{1}{2} \left( 1 - \cfrac{1}{6} \right) = \cfrac{5}{6}$


=== Log Level Fitness ===
Log-level fitness is 
* fitness, calculated for each trace and aggregated 
* $\text{fitness}(L, N) = \cfrac{1}{2} \left( 1 - \cfrac{\sum_{\sigma \in L} L(\sigma) \times m_{N, \sigma}}{\sum_{\sigma \in L} L(\sigma) \times c_{N, \sigma} } \right)
+ \cfrac{1}{2} \left( 1 - \cfrac{\sum_{\sigma \in L} L(\sigma) \times r_{N, \sigma}}{\sum_{\sigma \in L} L(\sigma) \times p_{N, \sigma} } \right)$
* $L(\sigma)$ how many times the trace $\sigma$ occurred in log $L$



== Links ==
* http://www.processmining.org/blogs/pub2006/genetic_process_mining

== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Business Process Management]]
[[Category:Process Mining]]</text>
      <sha1>dpahudu7z9xdq30gsqnjsacktqe6kva</sha1>
    </revision>
    <revision>
      <id>822</id>
      <parentid>374</parentid>
      <timestamp>2018-06-05T11:24:42Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5592">== Genetic Process Miner ==
This is an algorithm from the family of [[Genetic Algorithms]] for [[Process Mining|mining business processes]]
* it's much more resilient to noise 
* allows for incremental improvement 
* can be combined with other approaches 


=== Overview ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/gm-overview.png
* first we create the initial population
** can just randomly create some [[Petri Nets]], randomly adding places 
** or by applying [[Alpha Algorithm]] or [[Region-Based Process Miner]]
* at each step we compute fitness for all the instances of a population
* elitism - process of keeping the best ones
* then all &quot;survived&quot; instances are considered as &quot;parents&quot;
** cross-over - process of combining different petri nets (these petri-nets are already good solutions)
** mutation adding some random changes for diversifying


=== Cross-Over ===
Cross-over
* a process of producing a &quot;child&quot; by two parental instances 
* selecting parents
** completely at random
** using fitness to quicker converge to optima
** note that we should not always select only &quot;the best&quot; - we need diversity


How to create a petri net from two other petri nets?
* suppose we have two parental petri nets:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/gm-crossover-p.png
* we may find some ''minimal cut'', cut the parents and make children from then 
** minimal cut is the minimal number of transitions to remove s.t. the net becomes completely disconnected 
** the same as in the [[Graph]] Theory: [[Minimal Cut]]
* in this example: 
** can cut in $(e, f)$ because in both cases 
** from $e$ it goes to $g,h$  and on the left you have $a,b,c,d$ 
** so it's ideal 
* we take $(e, f)$ out and get two disconnected components 
** combine left and right parts of the petri nets to form children 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/gm-crossover-c.png


=== Mutation ===
Examples of mutations:
* remove or add a place
* add an arc


=== Parameters ===
So there are quite a few parameters that we have to provide:
* objective function we want to optimize (below)
* the way we do the cross-over
* how do you select parents?
* the way we do the mutations
* elitism - top 10%, certain threshold, etc
* how large the population should be
* how many generations you'll run before termination
* when we kill some instances?


Change one parameter
* $\Rightarrow$ different solution in the end

Also 
* a lot of randomness is involved 
* it may be computationally expensive



== Cost Function: Fitness ==
=== Trace Level Fitness ===
Define ''trace-level fitness'' as: 
* $\text{fitness}(\sigma, N) = \cfrac{1}{2} \left( 1 - \cfrac{m}{c} \right) + \cfrac{1}{2} \left( 1 - \cfrac{r}{p} \right)$
* $m$ - # of missing tokens
* $c$ - # of consumed tokens
* $r$ - # of tokens left over when something reaches the output place
* $p$ - # of produced tokens


=== Example 1 ===
Consider this example:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/gm-fit-ex1.png
* logtrace: $\sigma_1 = \langle abeg \rangle$
* $m = 0, c = 0, r = 0, p = 1$ 
** $p = 1$ because there's a token in the input place
* $a$ fires - it generates 2 tokens 
** $p \leftarrow p + 2 = 3$
** $c \leftarrow c + 1 = 1$
* $b$ fires, produces one token, consumes one token
** $p \leftarrow p + 1 = 4$
** $c \leftarrow c + 1 = 2$
* $e$ needs to fire
** but it cannot: one token is missing, so we add it and fire $e$
** $p \leftarrow p + 1 = 5$
** $c \leftarrow c + 2 = 4$
** $m \leftarrow m + 1 = 1$
* $g$ fires and we're done
** $p \leftarrow p + 1 = 6$
** $c \leftarrow c + 1 = 5$
* but there's one remaining token that was left over after firing $a$ 
** $r \leftarrow r + 1 = 1$
* and finally we remove one token from the output place
** $c \leftarrow c + 1 = 6$
* $\text{fitness}(\sigma_1, N_1) = \cfrac{1}{2} \left( 1 - \cfrac{1}{6} \right) + \cfrac{1}{2} \left( 1 - \cfrac{1}{6} \right) = \cfrac{5}{6}$


=== Example 2 ===
https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/gm-fit-ex2.png
* logtrace: $\sigma_2 = \langle adceh \rangle$
* $p = 1, c = 0, m = 0, r = 0$
* $a$ fires, produces 1, consumes 1
** $p \leftarrow 2, c \leftarrow 1$
* $d$ needs to fire
** but there's no token in the place before $d$, so we need to put it there
** $m \leftarrow 1$
** $d$ fires: $p \leftarrow 3, c \leftarrow 2$
* $c$ fires
** $p \leftarrow 4, c \leftarrow 3$
** note that $c$ and $d$ were executed in order different from the order that the model can produce
* $e$ fires 
** $p \leftarrow 5, c \leftarrow 4$
* $h$ fires
** $p \leftarrow 6, c \leftarrow 5$
* we're done
** one token is left: $r \leftarrow 1$
** taking the last token from $c$: $c \leftarrow 6$
* $\text{fitness}(\sigma_2, N_2) = \cfrac{1}{2} \left( 1 - \cfrac{1}{6} \right) + \cfrac{1}{2} \left( 1 - \cfrac{1}{6} \right) = \cfrac{5}{6}$


=== Log Level Fitness ===
Log-level fitness is 
* fitness, calculated for each trace and aggregated 
* &lt;math&gt;\text{fitness}(L, N) = \cfrac{1}{2} \left( 1 - \cfrac{\sum_{\sigma \in L} L(\sigma) \times m_{N, \sigma}}{\sum_{\sigma \in L} L(\sigma) \times c_{N, \sigma} } \right)
+ \cfrac{1}{2} \left( 1 - \cfrac{\sum_{\sigma \in L} L(\sigma) \times r_{N, \sigma}}{\sum_{\sigma \in L} L(\sigma) \times p_{N, \sigma} } \right)&lt;/math&gt;
* $L(\sigma)$ how many times the trace $\sigma$ occurred in log $L$



== Links ==
* http://www.processmining.org/blogs/pub2006/genetic_process_mining

== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Business Process Management]]
[[Category:Process Mining]]</text>
      <sha1>5v0gos1hsmhvbf4uxmd73mrn0yy96gn</sha1>
    </revision>
  </page>
  <page>
    <title>Genetic Algorithms</title>
    <ns>0</ns>
    <id>372</id>
    <revision>
      <id>375</id>
      <timestamp>2014-02-08T14:58:20Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="646">{{stub}}

== Genetic Algorithms ==
This is a group of algorithms that aim at solving [[Optimization]] problems with ideas borrowed from biology (evolutions)

General idea:
* start with a population of potential solutions 
* score each solution
* select the best (only the best &quot;survive&quot;)
* perform some random mutations (permutations, etc)
* combine the solutions in hope to get a better one (cross-over)
* repeat for several generations 



== Applications ==
This model is successfully applied in many domains:
* in [[Process Mining]]: [[Genetic Process Miner]]


== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Optimization]]</text>
      <sha1>jp0z3rbzwcoojtbmfkl57d79ntz8s9e</sha1>
    </revision>
  </page>
  <page>
    <title>Process Conformance</title>
    <ns>0</ns>
    <id>373</id>
    <revision>
      <id>376</id>
      <timestamp>2014-02-08T15:03:01Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1898">== Workflow Conformance Checking ==
This procedure gives the answer on the following questions
* does our model conform to what actually happens? 
* does what actually happens conform to the model?
* should we change our workflow to better fit the reality?


So it's 
* what actually happens vs
* what we think happens

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/conformance-checking.png


=== Play In ===
Suppose we have some logs that were captured during the process execution
* we can '''play in''' these sequences of actions on the model 
* and see if any of them fails 
* if yes - then we have no conformance 

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/play-in.png

This is very helpful in
* finding tasks that are not automated and performed outside of the engine
* (sometimes we turn off the workflow engine and add some exceptional cases manually)
* are there lots of these exceptions? then we should add them to the model 


=== Simulation (Play Out) ===
We can try to simulate the execution of our model 
* to see what can change if we add or remove something
* are there any bottlenecks that have appeared after the change?

To do this we need to define the environment of execution
* need to have the process itself
* for each activity
** times and priorities 
** statistics on how often a certain branch is followed
* frequency of incoming cases 
* the number of resources that can handle the cases


So given the statistics
* a some kind of random walk process is executed
* it basically traverses the [[Reachability Graph]] of a model
* and emulates the delays, etc

https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/bpm/pm/play-out.png

After the execution we can see:
* avg execution time
* resource utilization
* etc


== Sources ==
* [[Business Process Management (ULB)]]

[[Category:Business Process Management]]</text>
      <sha1>jdpl0anwut3fcztworhufjgrwqdpajk</sha1>
    </revision>
  </page>
  <page>
    <title>Inventory Management</title>
    <ns>0</ns>
    <id>374</id>
    <revision>
      <id>377</id>
      <timestamp>2014-02-09T12:51:06Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8250">== Inventory Management ==
The idea behind all these Inventory Management models is to 
* help to decide when to order new goods to replenish the stocks 


=== Wilson Model (EOQ Model) === 
EOQ = Economic Order Quantity model
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/im/em-basic-eoq.png
* This is the simplest model
** we start with some level of stock
** every day the stock decreases at the same number $\lambda$ (the ''demand'' is constant)
** when where are no goods, we do re-stocking
** another assumption: no waiting time, the stock is refilled immediately 
* variables of the model
** $n$ - the number of items ordered at once 
* we need to find the optimal solution: variables $n$
** if $n$ is big, we'll have one strategy (a)
** if $n$ is small, we'll have another (b)
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/im/em-basic-eoq-var.png
* parameters of the model:
** $c_f$ - fixed cost of ordering (and delivering) goods 
** $c_s$ - storage cost per day per item 
** $\lambda$ - the demand, # of items sold every day
** $T = \cfrac{n}{\lambda}$ - time to empty the stock ($n$ is divisible by $\lambda$)
* What is the optimal value of $n$? 


Costs:
* '''daily order cost''': how much we pay on average ''per day'' for ordering items
** it's the cost of ordering divided by $T$ - time to empty the stock
** $\text{doc}(n) = \cfrac{c_f}{T} = c_f \cdot \cfrac{\lambda}{n}$
* '''daily storage cost''': how much we pay on average ''per day'' for keeping items
** this is the total # of items we store divided by $T$
** total # of items is the square of our triangle 
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/im/em-basic-eoq-dailycos.png
** $\text{dsc}(n) = \underbrace{{\color{red}{S_{\triangle}}} \cdot \cfrac{1}{T}}_\text{avg items per day} \cdot c_s$
** $\text{dsc}(n) = {\color{red}{\cfrac{n \cdot T}{2}}} \cdot \cfrac{1}{T} \cdot c_s = \cfrac{n}{2} \cdot c_s$
* total cost:
** $\Gamma(n) = \text{doc}(n) + \text{dsc}(n) = c_f \cdot \cfrac{\lambda}{n} + \cfrac{n}{2} \cdot c_s$


Optimization 
* to optimize the cost w.r.t. $n$ we calculate the derivative $\Gamma'(n)$
* $\Gamma'(n) = - \cfrac{\lambda \cdot c_f}{n^2} + \cfrac{c_s}{2} = 0$
* $ \cfrac{n^2}{c_f \cdot \lambda} = \cfrac{2}{c_s} $
* $\tilde{n} = \sqrt{\cfrac{2 \cdot c_f \cdot \lambda}{c_s} }$



=== EOQ with Gradual Replenishment ===
Now consider a model where stock is not replenished immediately:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/im/em-grad.png
* new parameters:
** $V$ - speed of filling the stock, items per day ($V &gt; \lambda$)
** so the order is fulfilled in $\cfrac{n}{V}$ days

Calculations
* period $T$
** the peak is reached in $\frac{n}{V}$ days
** but at this day $\frac{n}{V} \cdot \lambda$ items were already sold (a)
** so the height of the peak is $(n - \frac{n}{V} \cdot \lambda)$ items 
** to sell these items up we need $[n - \frac{n}{V} \cdot \lambda] / \lambda$ days (b)
** the total period $T$ is: (a) time to reach the peak + (b) time till the end
** $T = {\color{grey}{(a)}} \ \cfrac{n}{V} +  {\color{grey}{(b)}} \  \cfrac{n}{\lambda} - \cfrac{n}{V}$
** $T = \cfrac{n}{\lambda}$
* '''daily order cost'''
** the same as before
** $\text{doc}(n) = \cfrac{c_f}{T} = c_f \cdot \cfrac{\lambda}{n}$
* '''daily storage cost'''
** this is the total # of items we store divided by $T$
** total # of items is the square of our triangle 
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/im/em-basic-stcost.png
** the peak is $n - \cfrac{n}{V} \cdot \lambda = n \cdot \cfrac{V - \lambda}{V}$
** $S_{\triangle} = T \cdot \cfrac{V - \lambda}{V} \cdot {n}{2}$
** $\text{dsc}(n) = c_s \cdot \cfrac{S_{\triangle}}{T} = c_s \cdot \cfrac{V - \lambda}{V} \cdot \cfrac{n}{2}$
* total cost:
** $\Gamma(n) = \text{doc}(n) + \text{dsc}(n) = c_f \cdot \cfrac{\lambda}{n} + c_s \cdot \cfrac{V - \lambda}{V} \cdot \cfrac{n}{2}$


Optimization
* to optimize the cost w.r.t. $n$ we calculate the derivative $\Gamma'(n)$
* $\Gamma'(n) = - \cfrac{\lambda \cdot c_f}{n^2} + c_s \cdot \cfrac{V - \lambda}{2 \cdot V} = 0$
* $\cfrac{c_t \cdot \lambda}{n^2} = \cfrac{c_s (V - \lambda)}{2 V} $
** $\cfrac{n^2}{c_t \cdot \lambda} = \cfrac{2 V}{c_s (V - \lambda)} $
** $n^2 = 2V \cdot \cfrac{c_t \cdot \lambda}{c_s (V - \lambda)} $
* $\tilde{n} = \sqrt{2V \cdot \cfrac{c_t}{c_s} \cdot \cfrac{\lambda}{V - \lambda} }$


=== EOQ with Planned Storage ===
Suppose now there's a delay with refilling: $T_s$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/im/em-plst.png
** refill itself happens immediately, but there's some delay before it can happen 
** so customers come and say that &quot;we will buy these items when you have them&quot; 
** which is why the number of items can go down 0 - they are still sold
* variables
** $n$ - number of items in one order
** $p$ - number of items that we sell in advance 
** so now we have two variables!
* parameters 
** $\lambda$ - demand
** $c_s$ - cost of storing
** $c_f$ - cost of ordering
** $c_p$ - cost of postponing the refill for each item that is delayed
** $T_s$ - time span with positive amount of goods
** $T_p$ - time span with negative amount of goods (they have not yet arrived yet)
** so $T_p$ - delay before refilling the stock


Calculations 
* $T = T_s + T_p$ - the whole period (i.e. time between two orders)
** $T_s = \cfrac{n - p}{\lambda}$ - # of days before no items left
** $T_p = \cfrac{p}{\lambda}$ - # of days before the next refill
** $T = \cfrac{n - p}{\lambda} + \cfrac{p}{\lambda} = \cfrac{n}{\lambda}$
* '''daily order cost'''
** the same as before
** $\text{doc}(n) = \cfrac{c_f}{T} = c_f \cdot \cfrac{\lambda}{n}$
* '''daily storage cost'''
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/im/em-plst-sim-triangles.png
** the store items only during $T_s$, when we at $T_p$ there's nothing to store
** $S_{\color{blue}{\blacktriangle}} = \cfrac{(n - p) \cdot T_s}{2}$ 
** $\text{dsc}(n, p) = S_{\color{blue}{\blacktriangle}} \cdot \cfrac{1}{T}$
** note that since the blue triangle and the big orange triangle are similar $\cfrac{T_s}{T} = \cfrac{n-p}{n}$
** so we have $\text{dsc}(n, p) = c_s \cdot S_{\color{blue}{\blacktriangle}} \cdot \cfrac{1}{T} = c_s \cdot \cfrac{(n - p) \cdot {\color{blue}{T_s}}}{2} \cdot {\color{blue}{\cfrac{1}{T}}} = c_s \cdot \cfrac{(n - p)^2}{2n}$
* '''daily postponing cost'''
** the average cost of postponing per day 
** this is the square of the red triangle
** $S_{\color{red}{\blacktriangle}} = \cfrac{p \cdot T_p}{2}$
** $\text{dpc}(n, p) = S_{\color{red}{\blacktriangle}} \cdot \cfrac{1}{T}$
** since the red triangle and the big orange one are similar, $\cfrac{T_p}{T} = \cfrac{p}{n}$
** so we have $\text{dpc}(n, p) = S_{\color{red}{\blacktriangle}} \cdot \cfrac{1}{T} = c_p \cdot \cfrac{p \cdot {\color{red}{T_p}}}{2} \cdot {\color{red}{\cfrac{1}{T}}} = c_p \cdot \cfrac{p^2}{2n}$
* the total cost is the sum of all these costs:
** $\Gamma(n, p) = \text{doc}(n) + \text{dst}(n, p) + \text{dpc}(n, p) = c_f \cdot \cfrac{\lambda}{n} + c_s \cdot \cfrac{(n - p)^2}{2n} + c_p \cdot \cfrac{p^2}{2n}$


Optimization 
* we need to optimize $\Gamma(n, p)$ w.r.t. both $n$ and $p$
* $\cfrac{\partial \Gamma(n, p)}{\partial p} = - c_s \cdot \cfrac{n - p}{n} + c_p \cdot \cfrac{p}{n} = 0$
** $-c_s \cdot n + c_s \cdot p + c_p \cdot p = 0$
** $p \cdot (c_s + c_p) = n \cdot c_p $
** $\tilde{p} = \cfrac{c_s}{c_s + c_p} \cdot \tilde{n} $
* $\cfrac{\partial \Gamma(n, p)}{\partial n} = - c_f \cdot \cfrac{\lambda}{n^2} + \cfrac{c_s}{2} \cdot \cfrac{n^2 - p^2}{n_2} - c_p \cdot \cfrac{p^2}{2n^2} = 0$
** $- 2 \lambda c_f + (n^2 - p^2) c_s - p^2 c_p = 0$
** $- 2 \lambda c_f + n^2 c_s - p^2 c_s - p^2 c_p = 0$
** $- 2 \lambda c_f + n^2 c_s - p^2 (c_s + c_p) = 0$ (replace $p$ with the value of $\tilde{p}$)
** $- 2 \lambda c_f + n^2 c_s - \cfrac{c^2_s}{c_s + c_p} \cdot n^2 = 0$
** $c_s n^2 \left(1 - \cfrac{c_s}{c_s + c_p}\right) = 2 \lambda c_f$
** $c_s n^2 \cfrac{c_p}{c_s + c_p} = 2 \lambda c_f$
** $n^2 = \cfrac{2 \lambda c_f}{c_s} \cdot  \cfrac{c_s + c_p}{c_p}$
** $\tilde{n} = \sqrt{\cfrac{2 \lambda c_f}{c_s} \cdot  \cfrac{c_s + c_p}{c_p}}$



== Sources ==
* [[Decision Engineering (ULB)]]

[[Category:Decision Engineering]]</text>
      <sha1>65zm6xykc429pyc6w1gd5gkdb72d4b2</sha1>
    </revision>
  </page>
  <page>
    <title>PROMETHEE/Properties</title>
    <ns>0</ns>
    <id>375</id>
    <revision>
      <id>378</id>
      <timestamp>2014-02-09T17:55:35Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9305">== [[PROMETHEE]]/Properties ==
=== The PROMETHEE Property ===
Note that this pair-wise gives us [[Valued Preference]] Graph
* https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/promethee-valued-pref.png
* this is local information, but we want to get the global final rankings


Suppose that $S$ is some method for computing global scores
* $s_i = S(a_i)$ and $s_j = S(a_j)$ 
* we use these scores to establish the global ranking

We expect that the following constraint is satisfied:
* $\pi_{ij} - \pi_{ji} = \pi(a_i, a_j) - \pi(a_j, a_i) \approx s_i - s_j$
* the difference between alternatives should be reflected in the global scores 
* and the difference in global scores should be as close as possible to the initial differences


; The PROMETHEE property:
* the netflow score $\Phi(a_i)$ is a centered score $s_i$ ($\forall i$) that minimizes the following $Q$:
* $Q = \sum_{i=1}^n \sum_{j=1}^n \big[ (s_i - s_j) - (\pi_{ij} - \pi_{ji}) \big]^2 $
* i.e. $Q$ is the sum of squared deviation and we want to minimize it


Proof ([[La Grange Optimization]])
* let $L(s_1, ..., s_n, \lambda)$ be the function we want to minimize
** $L(s_1, ..., s_n, \lambda) = \sum_{i=1}^n \sum_{j=1}^n \big[ (s_i - s_j) - (\pi_{ij} - \pi_{ji}) \big]^2 - \lambda \cdot \sum_{i=1}^n s_i$
** note that due to symmetry when we fix all variables expect a certain $s_i$ we can rewrite the double sum as twice the single sum:
** $L |_{s_i} = 2 \cdot \sum_{j=1,i \ne j}^n \big[ (s_i - s_j) - (\pi_{ij} - \pi_{ji}) \big]^2 - \lambda \cdot \sum_{i=1}^n s_i$
* to optimize we take all partial derivatives plus the Lagrangian and equal them to 0:
** $\forall s_i: \cfrac{\partial L(s_1, ..., s_n, \lambda)}{\partial s_i} = 0$
** $\forall s_i: \cfrac{\partial L(s_1, ..., s_n, \lambda)}{\partial \lambda} = 0$
* optimization:
** $\cfrac{\partial L}{\partial s_i} = 4 \cdot \sum_{j \ne i} \big[ (s_i - s_j) - (\pi_{ij} - \pi_{ji}) \big] - \lambda = ...$ (open the brackets for the sum)
** $... = 4 \cdot \left[ \sum_{j \ne i} s_i - \sum_{j \ne i} s_j - \sum_{j \ne i} (\pi_{ij} - \pi_{ji}) \right] - \lambda = ...$ 
** $... = 4 \cdot \left[ (n - 1) \cdot s_i - \sum_{j \ne i} s_j - \sum_{j \ne i} (\pi_{ij} - \pi_{ji}) \right] - \lambda = ...$  (by property $\sum_i s_i = 0$, $s_i = \sum_{j \ne i} s_j$ ) 
** $... = 4 \cdot \left[ ns_i - \sum_{j \ne i} (\pi_{ij} - \pi_{ji}) \right] - \lambda = 0$
* therefore
** $s_i = \cfrac{1}{n} \cdot \sum_{j \ne i} (\pi_{ij} - \pi_{ji}) = \cfrac{n-1}{n} \Phi(a_i)$
** i.e. the scores $s_i$ that satisfy the desired property are directly proportional to the netflow scores
** this is a justification why calculating netflow scores is a good idea


=== Property 1 ===
; $\Phi(a_i) \in [-1, 1]$
Easy to see that by the way we construct $\Phi(a_i)$


=== Property 2 ===
Want to show that  $\sum_{i = 1}^N \Phi(a_i) = 0$
* $N$ - the number of alternatives
* Let's show this property by induction


; Proof (by induction)


Basis: $N = 2$
* $\Phi(a_1) + \Phi(a_2) = \cfrac{1}{1} [\pi (a_1, a_2) - \pi (a_2, a_1) ] + \cfrac{1}{1} [\pi (a_2, a_1) - \pi (a_1, a_2) ] = 0$


Hypothesis: 
* Assume it holds for $N = k$


Induction step: Show that it also holds for $N = k + 1$
* $\sum_{i = 0}^{k+1} \Phi (a_i) = ...$  (expand $\Phi$)
* $... \sum_{i = 0}^{k + 1} \left[ \cfrac{1}{k} \sum_{j = 1}^{k + 1} [ \pi(a_i, a_j) - \pi(a_j, a_i) ] \right] = \ ... $ 
** take one element of the outer sum outside
** note that we don't care about the case when $i=j$ since the difference $\pi(a_i, a_i) - \pi(a_1, a_i)$ is always 0 
* $... \ = \cfrac{1}{k} \sum_{i = 1}^{{\color{blue}{k}}} \sum_{j = 1}^{k + 1} [ \pi(a_i, a_j) - \pi(a_j, a_i) ] + \cfrac{1}{k} \sum_{j=1}^{k+1} [ \pi(a_{k+1}, a_j) - \pi(a_j, a_{k+1}) ] = \ ...$ 
** now take all $k+1$th elements outside of that sum as well
* $...\  = \cfrac{1}{k} \sum_{i = 1}^{k} \sum_{j = 1}^{{\color{blue}{k}}} [ \pi(a_i, a_j) - \pi(a_j, a_i) ] + \ ... $
** $ ... \ + \cfrac{1}{k} \sum_{j=1}^{k+1} [ \pi(a_{k+1}, a_j) - \pi(a_j, a_{k+1}) ] + \cfrac{1}{k} \sum_{i=1}^{k+1} [ \pi(a_i, a_{k+1}) - \pi(a_{k+1}, a_i) ] = \ ...$
* $... \ = \cfrac{k-1}{k} \underbrace{ \left[ \cfrac{1}{k-1} \sum_{i = 1}^{k} \sum_{j = 1}^{k} [ \pi(a_i, a_j) - \pi(a_j, a_i) ] \right]  }_\text{= 0 by ind. hypothesis} + \ ... $
** $... \ + \underbrace{\left[ \cfrac{1}{k} \sum_{j=1}^{k+1} [ \pi(a_{k+1}, a_j) - \pi(a_j, a_{k+1}) ] + \cfrac{1}{k} \sum_{i=1}^{k+1} [ \pi(a_i, a_{k+1}) - \pi(a_{k+1}, a_i) ] \right] }_\text{= 0} = \ ...$
* $... \ = 0$



== [[Preferential Independence]] ==
PROMETHEE respects the [[Preferential Independence]] hypothesis

Suppose we 
* divided the set of criteria $G$ into $J$ and $\overline{J}$ and 
* have alternatives $a,b,c,d \in A$ for which the following holds 
* $(*)
\left\{\begin{matrix}
  g_i(a) = g_i(b), \forall i \not \in J \\ 
  g_i(c) = g_i(d), \forall i \not \in J \\ 
  g_i(a) = g_i(a), \forall i \in J \\
  g_i(b) = g_i(d), \forall i \in J
\end{matrix}\right. $


Now we show that $J$ is preferentially independent, i.e. $a \ P \ c \iff b \ P \ d$
* compute the netflow score for $a$:
** $\Phi(a) = \sum_{j = 1}^q w_i \cdot \Phi_j(a) = ...$ 
** since we have two subsets of criteria, we can rewrite it as following:
** $... = \underbrace{\sum_{j \in J} w_j \Phi_j(a)}_\text{(1)} + \sum_{j \not \in J} w_j \Phi_j(a) = ...$
** for (1) because of (*) we can replace each $\Phi_j(a)$ with $\Phi_j(b)$
** $... = \sum_{j \in J} w_j \Phi_j(b) + \sum_{j \not \in J} w_j \Phi_j(a)$
* can do the same for $c$:
** $\Phi(c) = \sum_{j = 1}^q w_i \cdot \Phi_j(c) = \underbrace{\sum_{j \in J} w_j \Phi_j(c)}_\text{(2)} + \underbrace{\sum_{j \not \in J} w_j \Phi_j(c)}_\text{(3)} = ...$ 
** because of (*) for (2) we can replace $\Phi_j(c)$ with $\Phi_j(d)$ and for (3) $\Phi_j(d)$ with $\Phi_j(a)$
** $... = \sum_{j \in J} w_j \Phi_j(d) + \sum_{j \not \in J} w_j \Phi_j(a)$
* $a \ P \ c \Rightarrow \Phi(a) &gt; \Phi(c)$
** thus $\sum_{j \in J} w_j \Phi_j(b) + {\color{red}{\sum_{j \not \in J} w_j \Phi_j(a)}} &gt;  \sum_{j \in J} w_j \Phi_j(d) + {\color{red}{\sum_{j \not \in J} w_j \Phi_j(a)}}$
** we cross out the red parts and have the following:
** $\sum_{j \in J} w_j \Phi_j(b) &gt; \sum_{j \in J} w_j \Phi_j(d)$
** now add $\sum_{j \not \in J} w_j \Phi(b)$ to both parts:
** $\sum_{j \in J} w_j \Phi_j(b) + {\color{blue}{\sum_{j \not \in J} w_j \Phi(b)}} &gt; \sum_{j \in J} w_j \Phi_j(d) + {\color{blue}{\sum_{j \not \in J} w_j \Phi(b)}}$
** since $g_j(b) = g_j(d) \forall j \not \in J$, we have replace $b$ to $d$ on the right side
** $\sum_{j \in J} w_j \Phi_j(b) + \sum_{j \not \in J} w_j \Phi(b) &gt; \sum_{j \in J} w_j \Phi_j(d) + \sum_{j \not \in J} w_j {\color{blue}{\Phi(d)}}$
* thus $b \ P \ d$


== [[Arrow's Impossibility Theorem]] ==
=== [[Monotonicity]] ===
The Monotonicity property is satisfied 

Let's show that
* $A = \{a, ..., a_i, ..., a_n\}$ - set of alternatives, $F = \{f_1, ..., f_q\}$ - set of criteria
* let $A'$ be a set $A' = \{a, ..., a'_i, ..., a_n\}$ where for $a'_i$:
** $f_k(a'_i) &gt; f_k(a_i)$ for some $f_k \in F$
** $f_i (a'_i) = f_i (a_i)$ for all other criteria $f_j \in F, f_i \ne f_k$
** i.e. $a'_i$, compared to $a_i$, improved its positions only in one criteria
* let $\Phi'(a)$ be a netflow score for $a \in A'$
** here we have:
** $\pi_j (a'_i, b) = \pi_j (a_i, b)$ and $\pi_j (b, a'_i) = \pi_j (b, a_i)$ for all $j \ne k$
** since $f_k(a'_i) &gt; f_k(a_i)$ we have $\pi_k (a'_i, b) \geqslant \pi_k(a_i, b)$ and $\pi_k (b, a'_i) \leqslant \pi_k(b, a_i)$
* calculate $\Phi'(a'_i)$: 
** $\Phi'(a'_i) = \cfrac{1}{n - 1} \sum_{b \in A'} [ \pi(a'_i, b) - \pi(b, a'_i) ] = \ ...$
** $... \ = \cfrac{1}{n - 1} \sum_{b \in A'} \left[ \sum_{j=1}^q w_j [ \pi_j(a'_i, b) - \pi_j(b, a'_i) ]  \right] = \ ...$ (now let's take the item with $\pi_k$ out of the sum)
** $... \ = \cfrac{1}{n - 1} \sum_{b \in A'} \left[ \sum_{j=1, j \ne k}^q w_j [ \pi_j(a'_i, b) - \pi_j(b, a'_i) ] + w_k {\color{blue}{[  \pi_k(a'_i, b) - \pi_k(b, a'_i) ]}} \right] = \ ...$
** consider $\pi_k(a'_i, b) - \pi_k(b, a'_i)$ alone:
*** $\pi_k (a'_i, b) \geqslant \pi_k(a_i, b)$ and $\pi_k (b, a'_i) \leqslant \pi_k(b, a_i)$
*** $\Rightarrow  \pi_k(a'_i, b) - \pi_k(b, a'_i) \geqslant \pi_k(a_i, b) - \pi_k(b, a_i)$
** that means that $\Phi'(a'_i) \geqslant \Phi(a_i)$ 
* similarly, $\forall a \in A, a \ne a_i: \Phi'(a) \leqslant \Phi(a)$
** $\Phi'(a) = \cfrac{1}{n - 1} \sum_{b \in A'} [ \pi(a'_i, b) - \pi(b, a'_i) ] = \ ...$
** there's $a'_i$ somewhere in $b \in A'$ - let's take it away from the sum
** $... = \cfrac{1}{n - 1} \sum_{b \in A', b \ne a'_i} [ \pi(a'_i, b) - \pi(b, a'_i) ] + \cfrac{1}{n-1} [ {\color{blue}{\pi(a, a_i) - \pi(a_i, a)}} ] $
** the blue part is expanded to $\sum_{j = 1}^q w_j [ \pi_j(a, a'_i) - \pi_j(a'_i, a) ]$
** we know that for one of these $j$ there's $k$, move it from the sum
** consider $\pi_k(a, a'_i) - \pi_k(a'_i, a)$ alone:
*** $\pi_k(a, a'_i) \leqslant  \pi_k(a, a_i)$ and  $\pi_k(a'_i, a) \geqslant  \pi_k(a_i, a)$
*** thus $\pi_k(a, a'_i) - \pi_k(a'_i, a) \leqslant \pi_k(a, a_i) - \pi_k(a_i, a)$
** that shows that $\Phi'(a) \leqslant \Phi(a)$

So we see that [[Monotonicity]] is satisfied


== Sources ==
* [[Decision Engineering (ULB)]]
* An Introduction to Multicriteria Decision Aid: The PROMETHEE and GAIA Methods, Yves De Smet, Karim Lidouh, 2013

[[Category:Multi-Criteria Decision Aid]]</text>
      <sha1>70mwyao05bls9o6a5xco7lb1km8imwl</sha1>
    </revision>
  </page>
  <page>
    <title>PROMETHEE/Rank Reversal</title>
    <ns>0</ns>
    <id>376</id>
    <revision>
      <id>379</id>
      <timestamp>2014-02-09T17:57:34Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5030">== [[Rank Reversal]] in [[PROMETHEE]] ==
Can be caused by 
* removing [[Non-Discriminating Criteria]]
* [[Dominance|Dominated]] criteria 


=== Removing [[Non-Discriminating Criteria]] ===
A criterion $f_k$ is non-discriminating it for all alternatives it evaluates to some value $\alpha$

Notation:
* $f_k$ is a non-discriminating criteria that evaluates to 0: $\forall a_i \in A: f_k(a_i) = 0$
* $\Phi(a_i)$ - original netflow score, $\Phi'(a_i)$ netflow score of an evaluation table without $f_k$
* $\Phi_j(a_i)$ - the netflow score of evaluation of criteria $j$
* we want to show that $\Phi(a_i) &gt; \Phi(a_j) \iff \Phi'(a_i) &gt; \Phi'(a_j)$


In PROMETHEE removal of such criteria doesn't lead to Rank Reversal:
* let $W_k = \sum_{j \ne k} w_j$ and $w'_j = \cfrac{w_j}{W_k}$ - we normalized the weights so when we remove the $w_k$, the rest still sum up to 1
* $\Phi(a_i) = \sum_{j=1}^q w_j \cdot \Phi_j(a_i) = \sum_{j \ne k} w_j \cdot \Phi_j(a_i) = ...$ (we removed the term that is always 0)
* $... = W_k  \sum_{j \ne k} \cfrac{w_j}{W_k} \Phi_j(a_i) = W_k  \sum_{j \ne k} w'_j \Phi_j(a_i) = ... $ (we multiplied and divided by a non-negative normalization factor)
* $... = W_k \cdot \Phi'_(a_i)$
* so we know that when removing $f_k$, all netflow scores will change on the same non-negative value
* therefore, $\Phi(a_i) &gt; \Phi(a_j) \iff \Phi'(a_i) &gt; \Phi'(a_j)$

$\square$


=== [[Dominance|Dominated]] Criteria ===
Suppose an alternative $a_i \in A$ dominates $a_j \in A$:
* $\forall k: f_k(a_i) \geqslant f_k(a_j) \land \exists k': f_{k'}(a_i) &gt; f_{k'}(a_j)$
* so $a_i$ has better or the same score as $a_j$:
* $\Phi(a_i) = \cfrac{1}{n-1} \sum_{k=1}^q w_k \sum_{b \in A} [ \pi_k (a_i, b) - \pi_k (b, a_i) ] \geqslant \Phi(a_j) = \cfrac{1}{n-1} \sum_{k=1}^q w_k \sum_{b \in A} [ \pi_k (a_j, b) - \pi_k (b, a_j) ]$
* compare to some other alternative $b$
** preference $a_i$ over $b$ is bigger than preference $a_j$ over $b$
** preference $b$ over $a_1$ is less than preference $b$ over $a_j$
* it means that 
** $\Phi(a_i) \geqslant \Phi(a_j)$ with whatever $b$  
** https://raw.github.com/alexeygrigorev/wiki-figures/master/ulb/de/mcda/promethee-rankreversal-dominance.png

So a dominated alternative $b$ can never have a score higher score than the alternative $a$ that dominates $b$


=== General Rank Reversal Analysis ===
* let $A_y = A - {y}$ - all alternatives except $y$
* and $\Phi_y(a)$ - a net flow score over $A_y$, i.e. calculated after $y$ is removed


RR is not possible if 
* $[\Phi(a) - \Phi(b)] \cdot [\Phi_y(a) - \Phi_y(b)] &gt; 0$ i.e. both parts are either positive or negative
* i.e. if something is better (worse), it should remain better (worse) when we remove $y$


RR is possible when $\Phi(a) - \Phi(b) &gt; \cfrac{2}{n - 1}$
* $\Phi_y(a) = \cfrac{1}{n-2} \sum_{x \in A_y} [ \pi(a, x) - \pi(x, a) ]$
* $\Phi(a) = \cfrac{1}{n-1} \sum_{x \in A} [ \pi(a, x) - \pi(x, a) ] = ...$
** move the item with $y$ out of the sum
** $... \cfrac{n - 2}{{\color{red}{n - 2}}} \cfrac{{\color{red}{1}}}{n - 1} \sum_{x \in A, x \ne y} [ \pi(a, x) - \pi(x, a) ] + \cfrac{1}{n - 1} [ \pi(a, y) - \pi(y, a) ] = ...$
** $... = \cfrac{n - 2}{n - 1} \Phi_y(a) +  \cfrac{1}{n - 1} [ \pi(a, y) - \pi(y, a) ]$
* Thus we can express $\Phi_y(a)$ via $\Phi(a)$:
** $\Phi_y(a) = \cfrac{n - 2}{n - 1} - \cfrac{1}{n - 2} \cdot [ \pi(a, y) - \pi(y, a) ]$
* Assume $\Phi_y(a) - \Phi_y(b) &gt; 0$, i.e. $a$ is ranked higher than $b$ after removing $y$
** $\Phi_y(a) - \Phi_y(b) = \cfrac{n - 2}{n - 1} [\Phi(a) - \Phi(b)] - \cfrac{1}{n - 2} [ \pi(a, y) - \pi(y, a) - (\pi(b, y) - \pi(y, b) ) ]$
* for RR not happen it should hold that $\Phi - \Phi_y &gt; 0$
** i.e. $a$ was also ranked higher than $b$ before removing $y$
** thus, $\Phi_y(a) - \Phi_y(b) = \cfrac{n - 2}{n - 1} [\Phi(a) - \Phi(b)] - \cfrac{1}{n - 2} [ \pi(a, y) - \pi(y, a) - (\pi(b, y) - \pi(y, b) ) ] &gt; 0$
** or $\cfrac{n - 1}{n - 2} [ \Phi(a) - \Phi(b) ] &gt; \cfrac{1}{n - 2} [ \pi(a, y) - \pi(y, a) - (\pi(b, y) - \pi(y, b) ) ]$ 
** $\Rightarrow \Phi(a) - \Phi(b) &gt; \cfrac{ \pi(a, y) - \pi(y, a) - (\pi(b, y) - \pi(y, b) ) }{n - 1}$
* suppose we take the most pessimistic position
** we remove such $y$ that maximizes this sum:
** $\Phi(a) - \Phi(b) &gt; \cfrac{ \max_y [ \pi(a, y) - \pi(y, a) - (\pi(b, y) - \pi(y, b) ) ] }{n - 1}$
** the most pessimistic values are $\pi(a, y) = 1, \pi(y, a) = 0,  \pi(b, y) = 0, \pi(y, b) = 1$
** i.e. $\Phi(a) - \Phi(b) &gt; \cfrac{2}{n - 1}$


Thus, [[Rank Reversal]] can happen only when $\Phi(a) - \Phi(b) &gt; \cfrac{2}{n - 1}$


In other words
* this happens only when two alternatives have very close net flow scores
* i.e. they are almost the same: the difference $\frac{2}{n - 1}$ is quite small, especially for larger $n$


== Links ==
* Paper: Verly, De Smet, Some considerations about rank reversal occurrences in the PROMETHEE method. 

== Sources ==
* [[Decision Engineering (ULB)]]
* An Introduction to Multicriteria Decision Aid: The PROMETHEE and GAIA Methods, Yves De Smet, Karim Lidouh, 2013

[[Category:Multi-Criteria Decision Aid]]</text>
      <sha1>o2bpchh7ztjx1yuxb1yyj20s3g16tv1</sha1>
    </revision>
  </page>
  <page>
    <title>Automata (coursera)</title>
    <ns>0</ns>
    <id>377</id>
    <revision>
      <id>380</id>
      <timestamp>2014-02-17T18:54:04Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="370">== Automata (coursera) ==
=== Course Content ===
[[Automata Theory]]
* discipline that studies formal systems 


[[Regular Languages]] 
* [[Deterministic Finite Automata]]
* [[Non-Deterministic Finite Automata]]
* [[Regular Expressions]]



== Stuff ==
* Course page: https://www.coursera.org/course/automata
* Notes: (add link)

[[Category:Notes]]
[[Category:Coursera]]</text>
      <sha1>q23zqh9sxnghb6n8rm48rp5acgar09s</sha1>
    </revision>
  </page>
  <page>
    <title>Deterministic Finite Automata</title>
    <ns>0</ns>
    <id>378</id>
    <revision>
      <id>381</id>
      <timestamp>2015-07-05T11:36:48Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6533">== Deterministic Finite Automata ==
Deterministic Finite Automata (DFA) are [[Automata]] that defile [[Regular Languages]]


=== [[Formal Languages]] ===
A ''language'' $L$ is a subset of all possible words $\Sigma^*$ formed by symbols of alphabet $\Sigma$
* English, French
* words with equal number of 1's and 0's 
* and so on


=== Informal Introduction ===
A ''finite automata'' is a formal system 
* it can be viewed as a [[graph]] or table
* it remembers only &lt;u&gt;finite&lt;/u&gt; amount of information
* it has only &lt;u&gt;finite&lt;/u&gt; number of states
* states chance in response to some input: characters or events 
* rules that tell how the state changes are called ''transitions''

Usage:
* design and verification of circuits and communication protocols
* text-processing applications ([[Regular Expressions]])
* very important for creating compilers 


=== Definition ===
A ''Deterministic Finite Automaton'' (DFA) is a tuple $A = \langle Q, \Sigma, \delta, q_o, F \rangle$
* $Q$ is a finite set of states
* $\Sigma$  a finite input alphabet
* $\delta$ a transition function
* $q_0 \in Q$ - the start state
* $F \subseteq Q$ - the final (or &quot;accepting&quot;) states 


== Transition Function ==
''Transition function'' $\delta$
* a function $\delta(q, a)$ that takes
* the current state of $q \in Q$ of $A$ 
* the current input symbol $a \in \Sigma$
* and returns the next state where $A$ goes
* $\delta$ defines a total relation: $\forall q, a \ \exists p: \delta(q, a) = p$ 
* for DFA there for each pair $(q, a)$ there exists exactly one state $p$ (for deterministic behavior)


A ''dead state'':
* a state that is not final, but there's no way to escape it
* on every input symbol there's a transition to itself 
* once you get there, it's not possible to leave it


=== Extended Transition Function ===
Extended Transition Function $\delta$ (sometimes $\hat{\delta}$) is
* a function that takes $q$ and a '''word''' $w$ (of any length, including 0)
* and tells where the automaton $A$ gets to after applying this word $w$
* i.e. it follows the path from $q$ by arcs labeled by symbols from $w$ in order 


Inductive definition of extended $\delta$:
* basis
** $\delta(q, \epsilon) = q$
** if you're in state $q$ and see no symbols, you stay in the state $q$ 
* induction 
** $\delta(q, w.a) = \delta(\delta(q, w), a)$
** $w$ is string, $a$ is symbol, $.$ is concatenation
** state we end up after seeing $wa$ is state $q'$ after seeing $w$ plus $\delta(q', a) $

A ''run'' of a string $w = a_1 . \ ... \ . a_n$ on automaton $A$ 
* is the sequence of state changes that $A$ makes while executing $w$ 



=== Representation: Graph ===
It is possible to represent automata as [[Graphs]]
* nodes = states of automaton
* arcs $(p, q)$  represent transitions, they are labeled by symbols that lead from $p$ to $q$ 
* arrow labeled with &quot;start&quot; denotes the start state 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/transition-ex.png  $\iff$ $\delta(p,a) = \delta(p,b) = q$


==== Example 1 ====
* recognizing if a word ends with &quot;ing&quot;
* https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/automaton-ing.png
* &quot;nothing&quot; represents a state where we've made no progress towards &quot;ing&quot;
** $i$ in input - go to &quot;saw i&quot;, otherwise stay 
* &quot;saw i&quot; means that $i$ was the last seen symbol
** see $n$ - made progress towards &quot;ing&quot; and go to &quot;saw in&quot;
** saw another $i$ - say here (maybe the word is &quot;skiing&quot;)
* &quot;saw in&quot; 
** go to &quot;saw ing&quot; on $g$ 
** return on other symbols
* &quot;saw ing&quot; - nothing in the input - we won
** something: return either to &quot;saw i&quot; or &quot;nothing&quot;


==== Example 2 ====
* $\Sigma = \{0, 1\} $
* recognizes strings with no 11
* https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/automaton-no11.png
* $C$ is a dead state: once saw 11 - we are not going to accept this string



==== Example 3: Tennis ====
Rules:
* Match consists of 3-5 sets, a set of 6 or more games
* one person servers throughout a whole game 
* to win, a player must score at least 4 points, but win by at least 2 points 

Symbols:
* $s$ = &quot;server wins a point&quot;
* $o$ = &quot;opponent wins a point&quot;

https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/tennis-example-1.png

Game:
* it starts from the '''love''' state: both players have 0-0
* at each state, depending on who wins, we transition from one state to another
* note: for &quot;15-all&quot; - we don't know how exactly we got there, but it doesn't matter 
* final states are when somebody wins
* &quot;deuce&quot; - when there's a tie
** note that it remembers that there's a tie, 
** but it doesn't remember how many points have been played
** after this state you have to win by 2 points 
** advantage-in, advantage-out - the names of these intermediate states between deuce and winning


Consider this sequences of points:
* $sosososososs$
* we'll obtain the following run:
* https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/tennis-example-2.png


=== Representation: Table ===
It is also possible to represent an automaton with a table
* $\to$ indicates start
* $*$ indicates final states 
* rows are states
* columns are input symbols 
* the cells shows transitions

{| 
| https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/automaton-no11.png $\Huge \equiv \ $
| 
  {| class=&quot;wikitable&quot;
   | || 
   ! || 0 || 1
   |-
   ! $\to$ || $*$ || A
   | A || B
   |-
   | 
   ! $*$  || B 
   | A || C
   |-
   | || 
   ! C 
   | C || C
   |}
|}


== [[Formal Languages|Language]] of DFA ==
Automata define [[Formal Languages]]
* if $A$ is an automaton, $L(A)$ is its language
* for a DFA $A$, $L(A)$ is a set of strings that lead from the start state $q_0$ to one of the final states $F$ 
* formally: $L(A) = \{ \forall w : \delta{q_0, w} \in F \}$
* languages defined by Finite Automata are called [[Regular Languages]]


== [[Non-Deterministic Finite Automata]] ==
In Non-Deterministic Finite Automata (NFAs) one input can lead to multiple states
* additionally there can be $\epsilon$-transitions that can taken spontaneously without any input character
* it is possible to convert one representation to another
** thus they all define the same class of [[Formal Languages]]: [[Regular Languages]]
* Non-Determinism and $\epsilon$-transitions give additional power 
** NFAs are easier to design than DFAs 
* but only DFAs can be implemented in practice
** Computers are always deterministic!



== Sources ==
* [[Automata (coursera)]]
* [[XML and Web Technologies (UFRT)]]

[[Category:Automata]]</text>
      <sha1>nd6u7gav11c36ku53sj7y3cyt42hrqk</sha1>
    </revision>
  </page>
  <page>
    <title>Non-Deterministic Finite Automata</title>
    <ns>0</ns>
    <id>379</id>
    <revision>
      <id>382</id>
      <timestamp>2015-07-05T11:31:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16253">== Non-Deterministic Finite Automata ==
[[Automata]] that are ''non-deterministic'' (NFA) can be in several states at once 
* from a state $q$ on input $a$ it can go to several different states 
** this is &quot;non-determinism&quot;
** [[Deterministic Finite Automata]] can go only to one state in such situations
* so there are several transitions that are labeled $a$ 
* this is why it's called non-deterministic 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/transition-non-det.png
* it also has one start state and several final states 
* it accepts a sequence if any of the choices lead to one of the final states
* so when there are choices where to go, a NFA tries all


=== Definition ===
Formally, a Non-Deterministic Finite Automata $A$ is a tuple $A = \langle Q, \Sigma, \delta, q_0, F \rangle$
* $Q$ is a set of states
* $\Sigma$ - input alphabet 
* $\delta$ - transition functions (returns a set of transitions)
* $q_0 \in Q$ - the start state 
* $F \subseteq Q$ - the final states 


A string $w$ is accepted if
* $\exists p \in \delta(q_0, w): p \in F$


The ''language'' $L(A)$ of $A$
* is the set of all strings it accepts
* languages defined by NDA are also [[Regular Languages]]



=== Transition Function ===
Unlike in [[Deterministic Finite Automata|DFA]]s, $\delta(q, a)$ returns &lt;u&gt;a set&lt;/u&gt; of states 
* $\delta(q, a) = \{ p_1, ..., p_m \} $
* and it can return an empty set $\varnothing$ if there's nothing to go next


Extension to strings (i.e. Extended $\delta$) is a bit more complex than for DFA
* basis:
** $\delta(q, \epsilon) = \{ q \}$
** the only state you can reach on empty input is the state $A$ is in
* induction
** $\delta(q, w . a) = \bigcup_{p \in \delta(q, w)} \delta(p, a)$
** i.e. union of all $\delta(p, a)$ for all $p$ reachable with a word $w$  
** https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/nfa-ext-delta.png


=== Example 1 ===
{|
| https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/nfa-ex.png
|
  {| class=&quot;wikitable&quot;
  ! || || 0 || 1
  |-
  ! $\to$ || $q$ 
  | $ \{ p, q \} $ || $ \{ q \} $
  |-
  | 
  ! $p$ 
  | dead || $\{ k \}$
  |-
  |
  ! $k$
  | dead || dead
  |- 
  |
  ! dead 
  | dead || dead
  |}
|}

* in $q$ on 0 it can stay in $q$ or go to $p$ 


Suppose the word is $w = 0001$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/nfa-ex-run.png
* the only possible run is $qqqpk$


But since NDA are non-deterministic 
* we know it will always make a good choice
* so we don't need &quot;dead&quot; transitions - we can just reject strings when there's nothing to go next 
* and we can have something like the following 

{|
| https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/nfa-ex-empty-trans.png
|
 {| class=&quot;wikitable&quot;
  ! || || 0 || 1
  |-
  ! $\to$ || $q$ 
  | $ \{ p, q \} $ || $ \{ q \} $
  |-
  | 
  ! $p$ 
  | $\varnothing$ || $\{ k \}$
  |-
  |
  ! $k$
  | $\varnothing$ || $\varnothing$
  |}
|}


the alphabets of these two automata are the same 




=== Example 2 ===
* consider this chessboard of size 3 $\times$ 3
* https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/dna-ex1-cb.png
* states = squares of the chessboard
** $Q = \{1, 2, 3, 4, 5, 6, 7, 8, 9\}$
* $\Sigma = \{ r, b \}$
** $r$ - &quot;red&quot; move: you move to any adjacent red square
** $w$ - &quot;black&quot; move: you move to any adjacent black square 
* start state - left upper corner
** $q_0 = 1$
* final state - lower right corner 
** $F = \{ 9\}$

Consider this sequence: $rbb$
* there are many possible ways to execute this sequence
* try each 
* https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/dna-ex1-cb-run.png
* we see that the final state is reached - so this sequence is accepted


== DFA vs NFA ==
[[Deterministic Finite Automata|DFA]] is NFA without non-determinism 
* so a DFA $A_D$ can easily be turned into an NFA $A_N$ that accepts the same language
* if $\delta_D(q, a) = p$ then let $A_N$ have $\delta_N(q, a) = \{ p \} $
* and $L(A_D) \equiv L(A_N)$


But also for any NFA $A_N$ there exists DFA $A_D$ s.t.
* $L(A_N) \equiv L(A_D)$
* thus, NFAs also define [[Regular Languages]]
* can show that by ''subset construction''


=== Subset Construction ===
Problem statement:
* Given NFA $A_N = \langle Q, \Sigma, \delta_N, q_0, F \rangle$ 
* construct DFA $A_D = \langle 2^Q, \Sigma, \delta_D, \{ q_0 \}, F' \rangle$ where 
** $2^Q$ is a powerset of $Q$ - set of all subsets from $Q$ 
** input alphabet $\Sigma$
** transition function $\delta_D$
** start state $\{ q_0 \}$
** finals states $F' = \{ q_F \ | \ q_F \in 2^Q: \exists q \in F \}$
*** all possible subsets of $Q$ that contain at least one state from the set of final states $F$ from NFA $A_N$
* such that $L(A_N) \equiv L(A_D)$

Note:
* states of $A_D$ have names that look like set of states (e.g. $\{g_0\}$ or $ \{q_1, q_2, q5\} $)
* however they are single objects
** this is just a naming convention to show that one state in $A_N$ may correspond to multiple states of the NFA
* so an expression like $\{p, q\}$ must be understood by DFA as a single symbol, not as a set


Next, we define the transition function $\delta_D$ as
* $\delta_D( \underbrace{\{q_1, ..., q_k\}}_\text{a state of DFA} , a) = \bigcup_{i = 1}^k \delta_N (q_i, a)$
* so for a state $\{q_1, ..., q_k\}$ in $A_D$ for all $q_i$ from this state 
** we take a union over possible next states from $A_N$


Problem:
* the number of states in DFA is exponential to $| Q |$
* so it may also be very expensive to transform NFA to DFA
* it gets very hard to visualize


==== Example ====
Recall the chessboard NFA 

{| 
| https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/dna-ex1-cb.png
| 
  {| class=&quot;wikitable&quot;
  | || State
  ! $r$ || $b$
  |-
  | $\to$ || 1 || $\{ 2,4 \}$ || $\{ 5 \}$
  |-
  | || 2 || $\{ 4,6 \}$ || $\{ 1,3,5 \}$
  |-
  | || 3 || $\{ 2,6 \}$ || $\{ 5 \}$
  |-
  | || 4 || $\{ 2,8 \}$ || $\{ 1,5,6 \}$
  |-
  | || 5 || $\{ 2,4,6,8 \}$ || $\{ 1,3,7,9 \}$
  |-
  | || 6 || $\{ 2,8 \}$ || $\{ 3,5,9 \}$
  |-
  | || 7 || $\{ 4,8 \}$ || $\{ 5 \}$
  |-
  | || 8 || $\{ 4,6 \}$ || $\{ 5,7,9 \}$
  |-
  | $*$ || 9 || $\{ 6,9 \}$ || $\{ 5 \}$
  |}
|}


Let's construct a DFA for it
* we'll do a ''lazy'' construction of DFA states:
** that is, instead of generating all elements of $A^Q$ we will add only needed ones on the go


{| class=&quot;wikitable&quot;
| ||  State
! $r$ || $b$
|-
| $\to$
! $\{ 1 \}$ 
| $\{ 2,4 \}$  || $\{ 5 \}$ 
|-
|
! $\{ 2,4 \}$ 
| $\{ 2,4,6,8 \}$  || $\{ 1,3,5,7 \}$ 
|-
|
! $\{ 5 \}$ 
| $\{ 2,4,6,8 \}$  || $\{ 1,3,7,9 \}$ 
|-
|
! $\{ 2,4,6,8 \}$ 
| $\{ 2,4,6,8 \}$  || $\{ 1,3,5,7,9 \}$ 
|-
|
! $\{ 1,3,5,7 \}$ 
| $\{ 2,4,6,8 \}$  || $\{ 1,3,5,7,9 \}$ 
|-
| $*$
! $\{ 1,3,7,9 \}$ 
| $\{ 2,4,6,8 \}$  || $\{ 5 \}$ 
|-
| $*$
! $\{ 1,3,5,7,9 \}$ 
| $\{ 2,4,6,8 \}$  || $\{ 1,3,5,7,9 \}$ 
|}


The way of doing it:
* in NFA, on $r$ from state 2 we can get to $\{ 4,6 \}$, from 4 - to $\{ 2,8 \}$
** so for the DFA, on $r$ from state $ \{ 2,4 \} $ we can go to state $\{ 4,6 \} \cup \{ 2,8 \} \equiv \{ 2,4,6,8 \}$
** we see if there's already such state in the table - it no, we create it, otherwise use the existent one

Note that in this case it has even fewer states than the original one
* but it's rarely the case 



=== Proof of Equivalence ===
$\forall w: w \in L(A_N) \iff w \in L(A_D)$

Here we can show that 
* $\forall w: \delta_N(q_0, w) \equiv \delta_D( \{q_0\}, w)$
* i.e. for any word $w$ we get to the same state 
* (recall that $\delta_N(q_0, w)$ returns a set, and $\delta_D( \{q_0\}, w)$ returns a state which also can be seen as a set)


Proof by induction on $| w |$
* IH: $\delta_N(q_0, w) \equiv \delta_D( \{q_0\}, w)$
* basis: $w = \epsilon$
** $\delta_N(q_0, \epsilon) \equiv \delta_D( \{q_0\}, \epsilon) \equiv \{q_0\}$
* induction step
** let $w = x.a$, the IH holds for $x$ (by induction)
** let $S = \delta_N(q_0, x) \equiv \delta_D( \{q_0\}, x)$
** and let $T$ be $T = \bigcup_{p \in S} \delta_N (p, a)$
** https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/nfa-subset-construction-eq.png
** then by construction of $A_D$ we see that 
*** $\delta_N(q_0, w) \equiv \delta_D( \{q_0\}, w) \equiv T$
*** (refer to Subset Construction and the extension rule of NDA)

$\square$



== $\epsilon$-Transitions ==
We can allow state-to-state transitions on empty input $\epsilon$
* these transitions are done spontaneously, without looking at the input string
* but still with these transitions we can accept only [[Regular Languages]]


=== NFAs with $\epsilon$-Transitions ===
Consider this example
* the arcs labeled with $\epsilon$ can be followed at any time without taking anything from the input sequence 
* in a transition table  we have an additional column for $\epsilon$-transitions
* but $\epsilon$ is not an input symbol, and $\epsilon \not \in \Sigma$


{|
|  https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/nfa-epsilon-trans-ex.png
|
 {| class=&quot;wikitable&quot;
  !  || || 0 || 1 || $\epsilon$
  |-
  | $\to$
  ! $A$ 
  | $\{ E \}$ || $\{ B \}$ || $\varnothing$
  |-
  | 
  ! $B$ 
  | $\varnothing$ || $\{ C \}$ || $\{ D \} $
  |-
  | 
  ! $C$ 
  | $\varnothing$ || $\{ D \}$ || $\varnothing$
  |-
  | $*$
  ! $D$ 
  | $\varnothing$ || $\varnothing$ || $\varnothing$
  |-
  | 
  ! $E$ 
  | $\{ F \}$ || $\varnothing$ || $\{ B,C \} $
  |-
  | 
  ! $F$ 
  | $\{ D \}$ || $\varnothing$ || $\varnothing$
  |}
|}


Have a look on $E$:
* there are two $\epsilon$-transitions to $B$ and $C$
* so it can go to $B$ spontaneously and then to $D$ 
* on input 1 it can to $B$ and there to $C$ 
* or to $C$ and there to $D$
* so there are quite a few nodes that are directly reachable from $E$ 
* this leads us to the notion of ''closure'' of $E$ 


=== Closure of States ===
The closure of a state $q$, denoted $\text{CL}(q)$, is 
* the set of all states that you can get from $q$
* following only $\epsilon$-transitions

https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/nfa-epsilon-trans-ex.png
* in this example, $CL(E) = \{ B, C, D, E \}$
** from $E$ you can get to $B$ and $C$, and from $B$ to $D$
* for $A$ there are no $\epsilon$-transitions, so $\text{CL}(A) = \{ A\} $
** (on $\epsilon$ you can stay in $A$)


The closure $\text{CL}(S)$ of a set of states $S = \{ q_1, ..., q_k \}$
* is the union of closures of each $q_i$
* $\text{CL}(S) = \bigcup_{q_i \in S} \text{CL}(q_i)$


=== Extended $\delta$ ===
Intuition:
* $\hat{\delta}(q_0, w)$ is the set of states that you can reach from the initial state $q_0$ following a path labeled $w$ 
* remember that $\epsilon$ are invisible, so in $w$  there are only real input seen by the automaton
* but spontaneously at any moment whenever possible it can follow an $\epsilon$ transition

Definition of $\hat{\delta}(q_0, w)$
* basis: $\hat{\delta}(q_0, w) = \text{CL}(q_0)$
* induction: input is $w = x.a$
** $\hat{\delta}(q_0, x) = S$ set of states reachable with $x$
** $\forall p \in S$ take the union of $\text{CL}(\delta(p, a))$
** so $\hat{\delta}(q_0, x.a) = \bigcup_{p \in \hat{\delta}(q_0, x)} \text{CL}(\delta(p, a))$


Illustration
* suppose $x \equiv bc$
* https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/nfa-epsilon-ext-delta.png
* we start from $q_0$
** then follow all $\epsilon$-transitions
** then follow $b$
** then again all $\epsilon$-transitions
** then $c$ 
** and again $\epsilon$-transitions
* let $S$ be the set of reachable states from $q_0$ on word $x$
** i.e. $S \equiv \hat{\delta}(q_0, x) \equiv \hat{\delta}(q_0, bc)$
* now from $S$ we fire all $a$ transitions (no $\epsilon$ yet)
* and then we take the closure of this set $S$


Example
* https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/nfa-epsilon-trans-ex.png
* $\hat\delta(A, \epsilon) = \text{CL}(A) = \{ A \} $ (the basis rule)
* $\hat\delta(A, 0) = \text{CL}(\{ E \}) = \{ B,C,D,E \} $
** the only place we can get from $A$ on 0 is $\{ E \}$
** but we close on $E$ and get to $\{ B,C,D \} $
* $\hat\delta(A, 01) = \text{CL}(\{ C,D \}) = \{ C,D \} $
** on 0 we can get to $\{ B,C,D,E \} $
** but only in $\{ B,C \} $ we can have 1 
** and from $\{ B,C \} $ we can get only to $\{ C,D \} $


=== Language of $\epsilon$-NFA ===
The language of $\epsilon$-NFA is 
* the set of strings $w$ s.t. $\hat\delta(q_0, w) \cap F \not \equiv \varnothing$
* i.e. it's possible to get on $w$ to at least one of the final states from $F$ 
* languages defined by $\epsilon$-NFAs are also [[Regular Languages]]


=== Equivalence of NFA and $\epsilon$-NFA ===
* Every NFA is an $\epsilon$-NFA, but without $\epsilon$-transitions
** $\Rightarrow$ $\forall$ NFA $A_N$ there $\exists$ $\epsilon$-NFA $A_\epsilon$ that accepts the same language
** $L(A_N) \equiv L(A_\epsilon)$
* but showing the other way - that $\forall A_\epsilon \ \exists A_N: L(A_\epsilon) \equiv L(A_N)$ - is harder
** we need to remove $\epsilon$-transitions


Algorithm
* given $\epsilon$-NFA $A_\epsilon = \langle Q, \Sigma, q_0, F, \delta_\epsilon \rangle$
* and an &quot;ordinary&quot; NFA $A_N = \langle Q, \Sigma, q_0, F', \delta_N \rangle$
* compute $\delta_N(q, a)$ as 
** let $S = \text{CL}(q)$
** and $\delta_N(q, a) = \bigcup_{p \in S} \delta_\epsilon(p, a)$
** all states that can be reaches from $q$ on $a$ and $\epsilon$ in $A_\epsilon$ (or, from $\text{CL}(q)$) in the $A_N$ can be reached only on $a$
* and define $F'$ as 
** it's a set of states $q$ s.t. $\text{CL}(q) \cap F \not \equiv \varnothing$
** if the $\epsilon$-NFA can get to a final state by following an $\epsilon$-transitions, we make such state final in the NFA as well
* https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/nfa-remove-eps.png


These construction gives an equivalent NFA
* on $w$ the NFA $A_N$ will enter the same set of states that $A_\epsilon$ would enter on $w$
* so by induction on $| w |$ need to show that $\text{CL}( \delta_N (q_0, w) ) = \hat\delta(q_0, w)$



=== Example ===
Consider again this $\epsilon$-NFA:

{|
| https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/nfa-epsilon-trans-ex.png
|
  {| class=&quot;wikitable&quot;
  !  || || 0 || 1 || $\epsilon$
  |-
  | $\to$
  ! $A$ 
  | $\{ E \}$ || $\{ B \}$ || $\varnothing$
  |-
  | 
  ! $B$ 
  | $\varnothing$ || $\{ C \}$ || $\{ D \} $
  |-
  | 
  ! $C$ 
  | $\varnothing$ || $\{ D \}$ || $\varnothing$
  |-
  | $*$
  ! $D$ 
  | $\varnothing$ || $\varnothing$ || $\varnothing$
  |-
  | 
  ! $E$ 
  | $\{ F \}$ || $\varnothing$ || $\{ B,C \} $
  |-
  | 
  ! $F$ 
  | $\{ D \}$ || $\varnothing$ || $\varnothing$
  |}
|}


The equivalent NFA without $\epsilon$-transitions is the following:

{|
| https://raw.github.com/alexeygrigorev/wiki-figures/master/crs/automata/nfa-epsilon-trans-ex-noeps.png
|
  {| class=&quot;wikitable&quot;
  !  || || 0 || 1
  |-
  | $\to$
  ! $A$ 
  | $\{ E \}$ || $\{ B \}$ 
  |-
  | ${\color{blue}{*}}$
  ! $B$ 
  | $\varnothing$ || $\{ C \}$
  |-
  | 
  ! $C$ 
  | $\varnothing$ || $\{ D \}$
  |-
  | $*$
  ! $D$ 
  | $\varnothing$ || $\varnothing$ 
  |-
  | ${\color{blue}{*}}$
  ! $E$ 
  | $\{ F \}$ || $\{ C, D \}$
  |-
  | 
  ! $F$ 
  | $\{ D \}$ || $\varnothing$
  |}
|}


Transformation
* Here are two interesting closures:
** $\text{CL}(B) = \{ B, D\}$
** $\text{CL}(E) = \{ B,C,D, E\}$
* first, we need to change the transition on 1 from $E$
** $\text{CL}(E) = \{ B,C,D, E\}$
** where we can get from these states on 1?
** to $\{ C,D \}$
** so we put this set for $E$  on 1
* Translation on 0 from $E$ doesn't change
** we don't have any transitions on 0 from $\{ B,C,D, E\}$
** only $\{ F \}$, which is already there
* Since closures of $B$ and $E$ contain the final state $D$, they also become final



== Summary ==
* it's possible to construct equivalent [[Deterministic Finite Automata|DFA]] NFA and $\epsilon$-NFA
** it's also possible to convert $\epsilon$-NFAs to [[Regular Expressions]]
** all accept the same class of languages: [[Regular Languages]]
* Non-Determinism and $\epsilon$-transitions give additional power 
** NFAs are easier to design than DFAs 
* but only DFAs can be implemented in practice
** Computers are always deterministic!


== Sources ==
* [[Automata (coursera)]]
* [[XML and Web Technologies (UFRT)]]

[[Category:Automata]]</text>
      <sha1>g9dcw1g10lr5v3rdrsr064jh4f1e9mx</sha1>
    </revision>
  </page>
  <page>
    <title>Semantic Web for the Working Ontologist (book)</title>
    <ns>0</ns>
    <id>380</id>
    <revision>
      <id>383</id>
      <timestamp>2014-07-28T17:14:49Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="597">== Semantic Web for the Working Ontologist ==
* by Allemang D., Hendler J.
* Second Edition
* Book is about creating [[Ontologies]] - domain model

=== Main Things ===
* [[Semantic Web]]: Semantic Modeling and main concepts
* [[Semantic Web Application Architecture]]
* [[RDF]]: Resource Description Framework
* [[SPARQL]] for querying RDF
* [[RDFS]]: Schema for RDF
* [[RDFS-Plus]]: Extension to have more inference capabilities
* [[OWL]]: powerful language for modeling [[Ontologies]]


=== Summary ===
* [[RDFS and OWL Summary]]


[[Category:Semantic Web]]
[[Category:Books]]
[[Category:Notes]]</text>
      <sha1>hbiow284kisjmmnnlsqo932sida4shv</sha1>
    </revision>
  </page>
  <page>
    <title>XML and Web Technologies (UFRT)</title>
    <ns>0</ns>
    <id>381</id>
    <revision>
      <id>384</id>
      <timestamp>2014-05-07T18:31:30Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="662">== Content ==
=== [[XML]] ===
* XML as a [[Semi-Structured Data Model]]
* XML schemas: [[DTD]] and [[XML Schema]]
* [[XPath]] for Querying XML
* [[XSLT]] for Transforming XML


=== [[Automata Theory]] ===
* [[Tree Automata]]


=== [[Semantic Web]] and [[Ontologies]] ===
* [[RDF]] and [[RDFS]]
* [[RDFS-Plus]] and [[OWL]]


=== BI Seminar Project ===
* [[Data Integration]] and [[Mediator (Data Integration)]]
* [[GAV Mediation]]
* [[LAV Mediation]]
** [[Bucket Algorithm (Data Integration)|Bucket Algorithm]]
** [[Minicon Algorithm]]
** [[Inverse-Rules Algorithm]]
* [[Ontology Based Data Access]]


[[Category:IT4BI]]
[[Category:XML]]
[[Category:Semantic Web]]</text>
      <sha1>dfzhq3361bco0tnty7ae7mui4zxhsh0</sha1>
    </revision>
  </page>
  <page>
    <title>RDF</title>
    <ns>0</ns>
    <id>382</id>
    <revision>
      <id>385</id>
      <timestamp>2014-05-06T20:51:27Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5220">== Motivation ==
Data integration
* suppose we have a distributed database across many servers
* each row is some entity, a column represents some property of this entity, and the cell contains a value described by this property
* inside a cell we can refer to another entity, and the meaning of the relationship is described by the name of the column
* so each cell of this database can be seen as a triple &lt;code&gt;row column value&lt;/code&gt;
** row = resource/subject
** column = predicate
** value = object
* since the database is distributed, how to know if a resource on one server is the same resource from another?
** describe resources with a global ID - URI (uniform resource identifier_
* this is the main idea of RDF


== RDF ==
RDF - resource description framework, a way to represent knowledge for the [[Semantic Web]]
* knowledge representation based on triples $\langle \text{subject}, \ \text{predicate}, \ \text{object} \rangle$
* the triples can form a graph
** nodes - resources
** edges - predicates
** both represented with URIs

[[Descriptive Logic]]
* there's a strong link between RDF and logic
* a set of RED triples can be interpreted as a conjunction of positive literals


=== Namespaces ===
one word can have several meaning
* e.g. Washington - state, city, person
* how to tell them apart?
* use namespaces

namespaces are typically URIs (like in [[XML]])
* e.g. 
** &lt;code&gt;http://www.example.com/states#Washington&lt;/code&gt;
** &lt;code&gt;http://www.example.com/cities#Washington&lt;/code&gt;
** &lt;code&gt;http://www.example.com/people#Washington&lt;/code&gt;
* and as in XML, it's possible to use '''qnames''' - URI abbreviations for local use
** qnames have 2 parts: namespace and id
** &lt;code&gt;states&lt;/code&gt; - &lt;code&gt;http://www.example.com/states#&lt;/code&gt;
** so use &lt;code&gt;states:Washington&lt;/code&gt; to refer to Washington state
* default namespace in this case is empty
** use &lt;code&gt;:Washington&lt;/code&gt; for thins in the default namespace

Default namespaces in RDF
* &lt;code&gt;xsd:&lt;/code&gt; for primitive XML types
* &lt;code&gt;rdf:&lt;/code&gt; for default things in rdf
* &lt;code&gt;rdfs:&lt;/code&gt; for [[RDFS]]
* &lt;code&gt;owl:&lt;/code&gt; for [[OWL]]



=== Examples ===
==== Example 1 ====
* suppose we have these statements
** &lt;code&gt;doc.html&lt;/code&gt; is written by Fabien
** &lt;code&gt;doc.html&lt;/code&gt; is about music 
* so we have these tripes
** &lt;code&gt;doc.html isWrittenBy fabien&lt;/code&gt;
** &lt;code&gt;doc.html about music&lt;/code&gt; 
* it can be represented by the following graph
** https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/rdf-ex1.png
** every edge in this graph is an RDF triple


==== Example 2: Modeling with RDF ====
* suppose you need to make an RDF statement from the following sentence:
** &quot;a flower which is red and has a round shape&quot;
* In RDF triples it can be
** &lt;code&gt;flower color red&lt;/code&gt;
** &lt;code&gt;flower shape round&lt;/code&gt;
* first, you need to find some definition of a flower
** ideally it should be some resource you trust
** e.g. http://botanie.example.org/type/fleur
* then you look for relations and their definitions
** has color - http://concept.example.org/couleur
** has shape - http://concept.example.org/forme
* finally, you find appropriate instances for colors and shape
** http://colors.example.org/rouge - red
** http://shapes.example.org/ronde - round
* so you have (shortened)
** &lt;code&gt;:fleur :couleur :rouge&lt;/code&gt;
** &lt;code&gt;:fleur :forme :ronde&lt;/code&gt;
* graphically, it's 
** https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/rdf-ex2.png


=== Types and Properties ===
&lt;code&gt;rdf:type&lt;/code&gt; predicate provides basic typing system
* e.g. &lt;code&gt;geo:Washington rdf:type geo:USState&lt;/code&gt;


=== Blank Nodes ===
RDF allows resources to have no id at all
* Sometimes we know that something exists
* And even know something about it 
* but don't know its identity

For example, 
* we know that Shakespeare had a mistress, but we don't know her
* and that she was the source of the inspiration for one of his works
* try to model as follows

&lt;pre&gt;
&quot;unknown&quot; rdf:type bio:Woman
&quot;unknown&quot; bio:livedIn geo:England
lit:Sonnet79 lit:hasInspiration &quot;unknown&quot;
&lt;/pre&gt;

We should interpret it as 
* there exists a woman who lived in England and is the source of inspiration for &quot;Sonnet 79&quot;
* so blank nodes interpreted as existential variables 

In Turtle it's 
* &lt;code&gt;lit:Sonnet78 lit:hasInspiration [a bio:Woman; bio:livedIn geo:England]&lt;/code&gt;



== [[Semantic Web]] ==
RDF is a basis for the Semantic Web 
* [[RDFS]] is schema for RDF that allows some basic inference
* [[RDFS-Plus]] extension of RDFS, and subset of [[OWL]]
* [[OWL]] - Web Ontologies Language 

All of them use RDF to express the language constructs

=== Querying ===
* [[SPARQL]] is used for querying RDF graphs


== RDF Serialization ==
Default is triplets - not very compact and user friendly
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/rdf-tripples.png
* need different representation

There are several:
* [[RDF/XML]]
* [[Turtle]]


== See Also ==
* [[Semantic Web]]
* [[RDFS]], [[OWL]]
* [[Ontologies]]

== Sources ==
* [[Semantic Web for the Working Ontologist (book)]]
* [[XML and Web Technologies (UFRT)]]

[[Category:Semantic Web]]
[[Category:Data Models]]</text>
      <sha1>c5e4z3d2h3j2eq9164nhxldmuh5vyig</sha1>
    </revision>
  </page>
  <page>
    <title>SPARQL</title>
    <ns>0</ns>
    <id>383</id>
    <revision>
      <id>386</id>
      <timestamp>2014-05-02T17:46:02Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11873">== SPARQL ==
In [[Semantic Web]], SPARQL is a query language for getting information from [[RDF]] graphs
* SPARQL = SPARQL Protocol and RDF Query Language
* matches graph patterns - so also a graph matching language 
* it's a variant of [[Turtle]] adapted for querying
* variables denoted by &lt;code&gt;?&lt;/code&gt;

Formal foundation
* e.g. [[SQL]] is based on [[Relational Algebra]]
* SPARQL is based on Predicate Calculus
** [[First Order Logic]]
** in most cases can be expressed as [[Conjunctive Query|Conjunctive Queries]]


=== Versions ===
SPARQL 1.0
* Basic Things

SPARQL 1.1
* Aggregations
* Negations
* Nested Queries 
* Transitive Properties 


=== Query Types ===
There are 4 types
* SELECT query
*: results are in a table format.
* CONSTRUCT query
*: results are translated into valid RDF
* ASK query
*: Just TRUE/FALSE 
* DESCRIBE query
*: results are RDF graphs

All of them take &lt;code&gt;WHERE&lt;/code&gt; clause


== Structure of a query ==
Generally, each query follows this structure
* Prefix declarations, for abbreviating URIs
** &lt;code&gt;PREFIX foo: http://example.com/resources/...&lt;/code&gt;
* Dataset definition, stating what RDF graph to query
** &lt;code&gt;FROM ... &lt;/code&gt;
* Result clause, identifying what information to return from the query
** &lt;code&gt;SELECT ... &lt;/code&gt;, &lt;code&gt;ASK ...&lt;/code&gt;, &lt;code&gt;CONSTRUCT ...&lt;/code&gt; or &lt;code&gt;DESCRIBE ...&lt;/code&gt;
* Query pattern, specifying what to query for, in the underlying dataset
** &lt;code&gt;WHERE { ... } &lt;/code&gt;
* Query modifiers, slicing, ordering, and otherwise rearranging query results
** &lt;code&gt;ORDER BY&lt;/code&gt;, etc


Formally,
* A SPARQL query is a tuple $\langle P, G, D, S, R \rangle$: 
* $P$ stands for the prefix declarations ection 
* $G$ is a graph pattern (pattern of the query) 
* $D$ is a set of RDF data (&quot;dataset&quot; : database) 
* $S$ is a &quot;result transformer&quot;: Projection,  Distinct, Order, Limit, Offset 
* $R$ is the type of the result: SELECT, CONSTRUCT, DESCRIBE, ASK 


== Select Queries ==
=== Example 1 ===
An example with prefix

{|
 |

&lt;pre&gt;
PREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt; 
SELECT ?name WHERE { 
  ?x foaf:name ?name
} 
&lt;/pre&gt;

 |

result $\to$

 |

   {| class=&quot;wikitable&quot;
    ! name
    |-
    | Bob
    |- 
    | Alice
    |}
 |}


=== Example 2 ===
Consider this RDF graph [http://cs-www.cs.yale.edu/homes/dna/papers/sw-graph-scale.pdf]
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/rdf-graph-ex3-sparql.png

&lt;pre&gt;
SELECT ?player ?club
WHERE {
  ?player :position :striker .
  ?player :playsFor ?club .
  ?club :region :Barcelona 
}
&lt;/pre&gt;


the query itself is also a graph
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/rdf-graph-ex3-q.png
* now we match this graph with the data graph
* this query will select only Messi, because he's a striker 


In SQL it would be 

&lt;pre&gt;
SELECT
  A.subject, A.object
FROM
  triples AS A, triples AS B, triples AS C
WHERE
  B.predicate = &quot;position&quot; AND B.object = &quot;striker&quot;
  AND B.subject = A.subject AND A.predicate = &quot;playsFor&quot;
  AND A.object = C.subject AND C.predicate = &quot;region&quot;
  AND C.object = &quot;Barcelona&quot;;
&lt;/pre&gt;


Also, this query can be translated to the following [[Conjunctive Query]]
* $\text{query}(p, c) \equiv \text{Position}(p, \text{``striker''}), \text{PlaysFor}(p, c), Region(c, \text{``Barcelona''})$


=== Querying for Property ===
Can also query for a predicate 
* e.g. what do we know about James Dean? 

&lt;pre&gt;
SELECT ?property ?value 
WHERE {
  :JamesDean ?property ?value
}
&lt;/pre&gt;

Also can use &lt;code&gt;DISTICNT&lt;/code&gt; keyword

&lt;pre&gt;
SELECT DISTINCT ?property 
WHERE {
  :JamesDean ?property ?value
}
&lt;/pre&gt;

Suppose we want to know anything about a class &lt;code&gt;Actor&lt;/code&gt;

&lt;pre&gt;
SELECT DISTINCT ?property 
WHERE 
  q0 a :Actor . 
  ?q0 ?property ?object .
}
&lt;/pre&gt;


== Where part ==
In this part matching happens 
* Generally, the same idea as in [[Conjunctive Query|Conjunctive Queries]]
* There are ''existential variables'' (not from the head of the query)
** they are matched with some data in the database and assigned some value
* as saw, here a graph is constructed and matched with 


=== Filter: Value constraints ===
Boolean tests - not graph patterns
* Logical: &lt;code&gt;!&lt;/code&gt;, &lt;code&gt;&amp;&amp;&lt;/code&gt;, &lt;code&gt;||&lt;/code&gt; 
* Arithmetic: &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;*&lt;/code&gt;, &lt;code&gt;/&lt;/code&gt; 
* Comparison: &lt;code&gt;=&lt;/code&gt;, &lt;code&gt;!=&lt;/code&gt;, &lt;code&gt;&gt;&lt;/code&gt;, &lt;code&gt;&lt;&lt;/code&gt;, ... 
* SPARQL tests: &lt;code&gt;isURI&lt;/code&gt;, &lt;code&gt;isBlank&lt;/code&gt;, &lt;code&gt;isLiteral&lt;/code&gt;, &lt;code&gt;bound&lt;/code&gt;
* SPARQL accessors: &lt;code&gt;str&lt;/code&gt;, &lt;code&gt;lang&lt;/code&gt;, &lt;code&gt;datatype&lt;/code&gt;
* Other: &lt;code&gt;sameTerm&lt;/code&gt;, &lt;code&gt;langMatches&lt;/code&gt;, &lt;code&gt;regex&lt;/code&gt; ...


Examples: 

&lt;pre&gt;
PREFIX dc: &lt;http://purl.org/dc/elements/1.1/&gt; 
PREFIX ns: &lt;http://example.org/ns#&gt; 
SELECT ?title ?price 
WHERE { 
  ?x ns:price ?price . 
  FILTER ?price &lt; 30 . 
  ?x dc:title ?title . 
} 
&lt;/pre&gt;


&lt;pre&gt;
SELECT ?actor 
WHERE { 
  ?actor :playedIn :Giant . 
  ?actor :diedOn ?deathdate . 
  FILTER(?deathdate &gt; &quot;1961-11-24&quot;^^xsd:date)
}
&lt;/pre&gt;


We can also have several filters
&lt;pre&gt;
SELECT ?person 
WHERE{
  ?person a :Person . 
  ?person :bornOn ?birthday . 
  FILTER(?birthday &gt; &quot;Jan 1, 1960&quot;^^xsd:date) 
  FILTER(?birthday &lt; &quot;Dec 31, 1969&quot;^^xsd:date)
}
&lt;/pre&gt;


=== Optional ===
When we don't want a query to fail if there is no data for something

Example:
* if price exists, filter on it; otherwise just include it

&lt;pre&gt;
PREFIX dc: &lt;http://purl.org/dc/elements/1.1/&gt; 
PREFIX ns: &lt;http://example.org/ns#&gt; 
SELECT ?title ?price 
WHERE { 
  ?x dc:title ?title . 
  OPTIONAL { 
    ?x ns:price?price . 
     FILTER ?price &lt; 30 
  }
}
&lt;/pre&gt;

Also, can have several optionals 

&lt;pre&gt;
PREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt; 
SELECT ?name ?mbox ?hpage
WHERE { 
  ?x foaf:name?name . 
  OPTIONAL { ?x foaf:mbox ?mbox } . 
  OPTIONAL { ?x foaf:homepage ?hpage} 
} 
&lt;/pre&gt;


=== Union ===
&lt;pre&gt;
PREFIX dc10: &lt;http://purl.org/dc/elements/1.0/&gt; 
PREFIX dc11: &lt;http://purl.org/dc/elements/1.1/&gt; 
SELECT ?x ?y 
WHERE {
  { ?book dc10:title ?x } 
  UNION
  { ?book dc11:title ?y } 
}
&lt;/pre&gt;

Can have several unions:

&lt;pre&gt;
CONSTRUCT { ?s :hasParent ?o } 
WHERE { 
  { ?s :hasMother ?o } 
  UNION
  { ?s :hasFather ?o } 
  UNION
  { ?o :hasSon ?s } 
  UNION 
  { ?o :hasDaughter ?s }
} 
&lt;/pre&gt;



=== Negation (SPARQL 1.1) ===
Negation is achieved with a keyword &lt;code&gt;UNSAID&lt;/code&gt;
* it introduces a subgraph 
* the overall graph pattern will match if the UNSAID pattern does not match.

This query will return all actors with no &lt;code&gt;:diedOn&lt;/code&gt; record who played in &quot;Giant&quot;
&lt;pre&gt;
SELECT ?actor 
WHERE {
  ?actor :playedIn :Giant . 
  UNSAID { ?actor :diedOn ?deathdate .} 
} 
&lt;/pre&gt;


=== Transitive Queries ===
Suppose we want to select Joe's children
* and then children of his children

&lt;pre&gt;
SELECT ?member 
WHERE { ?member :hasParent :Joe } 

SELECT ?member 
WHERE {
  ?c :hasParent :Joe . 
  ?member :hasParent ?c .
} 
&lt;/pre&gt;

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/sparql-transitive-1.png

But what if we want to follow &lt;code&gt;:hasParent&lt;/code&gt; as long as it's there?
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/sparql-transitive-2.png
* use &lt;code&gt;*&lt;/code&gt; for that (only SPARQL 1.1)

&lt;pre&gt;
SELECT ?member 
WHERE { ?member :hasParent* :Joe .}
&lt;/pre&gt;

But in this case it will also include &lt;code&gt;:Joe&lt;/code&gt;
* i.e. it includes zero-length chains as well
* to avoid it, use &lt;code&gt;+&lt;/code&gt; instead (like in [[Regular Expressions]])

&lt;pre&gt;
SELECT ?member 
WHERE { ?member :hasParent+ :Joe .}
&lt;/pre&gt;


=== Ordering (SPARQL 1.1) ===
&lt;pre&gt;
SELECT ?title ?date 
WHERE {
  :JamesDean :playedIn ?movie. 
  ?movie rdfs:label ?title . 
  ?movie dc:date ?date . 
} ORDER BY ?date

-- with limit
SELECT ?title 
WHERE {
  :JamesDean :playedIn ?m. 
  ?m rdfs:label ?title . 
  ?m dc:date ?date . 
} ORDER BY ?date 
LIMIT1 

-- inverse order
SELECT ?last 
WHERE { 
  ?who :playedIn :RebelWithoutaCause .
  ?who rdfs:label ?last . 
  ?who :diedOn ?date
} ORDER BY DESC(?date) 
LIMIT 1 
&lt;/pre&gt;


=== Aggregating and Grouping (SPARQL 1.1) ===
&lt;pre&gt;
SELECT (COUNT(?movie) AS ?howmany) 
WHERE {:JamesDean ?playedIn ?movie .}

SELECT (SUM (?val) AS ?total)
WHERE {
  ?s a :Sale . 
  ?s :amount ?val 
}

SELECT ?year (SUM (?val) AS ?total)
WHERE {
  ?s a :Sale . 
  ?s :amount ?val . 
  ?s :year ?year 
} GROUP BY ?year


SELECT ?year ?company (SUM(?val) AS ?total) 
WHERE {
  ?s a :Sale . 
  ?s :amount ?val . 
  ?s :year ?year . 
  ?s :company ?company . 
} GROUP BY ?year ?company 

-- with filtering 
SELECT ?year ?company (SUM(?val) AS ?total) 
WHERE {
  ?s a :Sale . 
  ?s :amount ?val . 
  ?s :year ?year . 
  ?s :company ?company . 
} GROUP BY ?year ?company HAVING (?total &gt; 5000) 
&lt;/pre&gt;


=== Subqueries (SPARQL 1.1) ===
&lt;pre&gt;
SELECT ?company 
WHERE { 
  {
    SELECT ?company ((SUM(?val)) AS ?total09) 
    WHERE { 
      ?s a :Sale . 
      ?s :amount ?val . 
      ?s :company ?company . 
      ?s :year 2009 . 
    } GROUP BY ?company 
  } . 
  {
    SELECT ?company ((SUM(?val)) AS?total10) 
    WHERE { 
      ?s a :Sale . 
      ?s :amount ?val . 
      ?s :company ?company . 
      ?s :year 2010 .
    } GROUP BY ?company 
  } . 
  FILTER(?total10 &gt; ?total09) . 
} 
&lt;/pre&gt;


== Other Types of Queries ==
=== Yes/No Queries ===
Use when we need just TRUE/FALSE

Example: do we have any &lt;code&gt;:diedOn&lt;/code&gt; record for &lt;code&gt;:ElizabethTaylor&lt;/code&gt;?
&lt;pre&gt;ASK WHERE {:ElizabethTaylor :diedOn ?any}&lt;/pre&gt;

Or can use negation for that:
* e.g. is &lt;code&gt;:ElizabethTaylor&lt;/code&gt; still alive?
&lt;pre&gt;ASK WHERE { UNSAID {:ElizabethTaylor :diedOn ?any} }&lt;/pre&gt;


=== &lt;code&gt;CONSTRUCT&lt;/code&gt; Queries ===
&quot;Select&quot; queries 
* are run on a RDF graph, but return a table
* have no closure property 
* want to construct a valid RDF graph from the result 

&lt;pre&gt;
CONSTRUCT {
  ?d rdf:type :Director . 
  ?d rdfs:label ?name . 
}
WHERE {
  ?any :directedBy ?d . 
  ?d rdfs:label ?name . 
} 
&lt;/pre&gt;

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/sparql-construct-ex1.png


Can use these queries for 
* insert it back into this RDF store / another RDF store
* serialize to [[XML/RDF]]


==== Rules ====
Construct queries provide a convenient way of specifying rules
* based on patterns found in your RDF graph - i.e. facts stored in the database 

Examples:
* from the previous example: if something is directed by &lt;code&gt;?d&lt;/code&gt;, then &lt;code&gt;?d&lt;/code&gt; must be a &lt;code&gt;:Director&lt;/code&gt;
* these rules say &quot;whenever you see this, conclude that&quot;
* can be used to express inference rules in [[Inference in Semantic Web]]

Types of Rules
* completeness rules
** John's father is Joe $\to$ Joe's son is John
* logical rules 
** Socrates is a man, all men are mortal $\to$ Socrates is mortal
* definitions
** Ted's sister is Maria's mother $\to$ Ted is Maria's uncle 
* business rules 
** customers spent &gt; 5000 USD are preferred customers 

&lt;pre&gt;
CONSTRUCT{ ?q1 :hasSon :q2 .} 
WHERE {
  ?q2 a :Man . 
  ?q2 :hasFather ?q1
} 

CONSTRUCT { ?q1 a :Mortal } 
WHERE { ?q1 a :Man } 

CONSTRUCT { ?q1 :hasUncle ?q2 } 
WHERE {
  ?q2 :hasSibling ?parent . 
  ?q2 a :Man . 
  ?q1 :hasParent ?parent 
} 

CONSTRUCT { ?c a :PreferredCustomer } 
WHERE {
  ?c :totalBusiness ?tb . 
  FILTER(?tb &gt; 5000) 
} 
&lt;/pre&gt;


== Protocol ==
SPARQL is not only a query language, but also a protocol
* so a query engine can be a web service 

SPARQL endpoints
* received SPARQL queries and send a response - web services
* http://dbpedia.org/sparql


== Implementations ==
* Jena [http://jena.apache.org/] 
* Sesame [http://www.openrdf.org/]
* Many others: http://en.wikipedia.org/wiki/SPARQL#SPARQL_implementations


== Sources ==
* [[Semantic Web for the Working Ontologist (book)]]
* [[XML and Web Technologies (UFRT)]]
* http://en.wikipedia.org/wiki/SPARQL

[[Category:Semantic Web]]
[[Category:Query Languages]]</text>
      <sha1>obkg4m859riizjd3n2npzkeuojkzglv</sha1>
    </revision>
  </page>
  <page>
    <title>Turtle</title>
    <ns>0</ns>
    <id>384</id>
    <revision>
      <id>387</id>
      <timestamp>2014-05-02T17:47:19Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1145">== Turtle ==
* a way of representing [[RDF]] 
* more compact than [[RDF/XML]]
* used in [[SPARQL]]


=== Syntax ===
uses qnames - binds them to global URIs
&lt;pre&gt;
@prefix mfg: &lt;http://www.example.com/manufacturing#&gt;
@prefix rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns#
&lt;/pre&gt;


triples are expressed in the following way, with dot separating triples
* &lt;code&gt;mfg:Product1 rdf:type mfg:Product .&lt;/code&gt;


&lt;code&gt;a&lt;/code&gt; is a shortcut for &lt;code&gt;rdf:type&lt;/code&gt;
* so it can read in more natural English 
* Product1 is a Product
* &lt;code&gt;mfg:Product1 a mfg:Product .&lt;/code&gt;


When we describe the same subject, can use &quot;;&quot;:
* &lt;code&gt;mfg:Product1 rdf:type mfg:Product; mfg:productId &quot;...&quot; .&lt;/code&gt;


When we have same subject and same predicate, just use spaces
* &lt;code&gt;lit:Shakespeare b:hasChild b:Susanne b:Judith b:Hamlet .&lt;/code&gt;


Blank nodes:
* &lt;code&gt;[a bio:Woman; bio:livedIn geo:England]&lt;/code&gt;
* can be used as a subject:
* &lt;code&gt;lit:Sonnet78 lit:hasInspiration [a bio:Woman; bio:livedIn geo:England]&lt;/code&gt;


== Sources ==
* [[Semantic Web for the Working Ontologist (book)]]
* [[XML and Web Technologies (UFRT)]]

[[Category:Semantic Web]]</text>
      <sha1>mdzsqvolv20td4qqrqiyl5fsqmaqjmb</sha1>
    </revision>
  </page>
  <page>
    <title>RDFS and OWL Summary</title>
    <ns>0</ns>
    <id>385</id>
    <revision>
      <id>388</id>
      <timestamp>2014-05-03T08:32:29Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3065">Summary from [[RDFS]], [[RDFS-Plus]] and [[OWL]]


== [[RDFS]] ==
=== Fundamental concepts ===
* &lt;code&gt;rdfs:subClassOf&lt;/code&gt; - Members of subclass are also member of superclass.
* &lt;code&gt;rdfs:subPropertyOf&lt;/code&gt; - Relations described by subproperty also hold for superproperty.
* &lt;code&gt;rdfs:domain&lt;/code&gt; - The subject of a triple is classified into the domain of the predicate.
* &lt;code&gt;rdfs:range&lt;/code&gt; - The object of a triple is classified into the range of the predicate.


=== Annotation properties ===
* &lt;code&gt;rdfs:label&lt;/code&gt; - No inferential semantics, printable name.
* &lt;code&gt;rdfs:comment&lt;/code&gt; - No inferential semantics, information for readers of the model.


== [[OWL]] ==
=== Equality ===
* &lt;code&gt;owl:equivalentClass&lt;/code&gt; - Members of each class are also members of the other.
* &lt;code&gt;owl:equivalentProperty&lt;/code&gt; - Relations that hold for each property also hold for the other.
* &lt;code&gt;owl:sameAs&lt;/code&gt; - All statements about one instance hold for the other.


=== Property characteristics ===
* &lt;code&gt;owl:inverseOf&lt;/code&gt; - Exchange subject and object.
* &lt;code&gt;owl:TransitiveProperty&lt;/code&gt; - Chains of relationships collapse into a single relationship.
* &lt;code&gt;owl:SymmetricProperty&lt;/code&gt; - A property that is its own inverse.
* &lt;code&gt;owl:FunctionalProperty&lt;/code&gt; - Only one value allowed (as object).
* &lt;code&gt;owl:InverseFunctionalProperty&lt;/code&gt; - Only one value allowed (as subject).
* &lt;code&gt;owl:ObjectProperty&lt;/code&gt; - Property can have resource as object.
* &lt;code&gt;owl:DatatypeProperty&lt;/code&gt; - Property can have data value as object


=== Restrictions ===
* &lt;code&gt;owl:Restriction&lt;/code&gt; - describes classes by restricting the values allowed for certain properties.
* &lt;code&gt;owl:hasValue&lt;/code&gt; - refers to a single value for a property.
* &lt;code&gt;owl:someValuesFrom&lt;/code&gt; - refers to a set from which some value for a property must come.
* &lt;code&gt;owl:allValuesFrom&lt;/code&gt; - refers to a set from which all values for a property must come.
* &lt;code&gt;owl:onProperty&lt;/code&gt; - A link from a restriction to the property it restricts.


=== Restrictions - set operations ===
* Each of these is used to create a new class, based on the specified set
* &lt;code&gt;owl:unionOf&lt;/code&gt;, &lt;code&gt;owl:intersectionOf&lt;/code&gt;,  &lt;code&gt;owl:complementOf&lt;/code&gt;
* &lt;code&gt;owl:oneOf&lt;/code&gt; - Specifies that a class consists just of the listed members.
* &lt;code&gt;owl:differentFrom&lt;/code&gt; - Specifies that one individual is not &lt;code&gt;owl:sameAs&lt;/code&gt; another. 
** This is particularly useful when making counting arguments.
* &lt;code&gt;owl:disjointWith&lt;/code&gt; Specifies that two classes cannot share a member. 
** This is often used as a sort of wholesale version of &lt;code&gt;owl:differentFrom&lt;/code&gt;.
* &lt;code&gt;owl:cardinality&lt;/code&gt;, &lt;code&gt;owl:minCardinality&lt;/code&gt;, &lt;code&gt;owl:maxCardinality&lt;/code&gt; 
** specifies information about the number of distinct values for some property. 


== See Also ==
* [[RDFS]], [[RDFS-Plus]], [[OWL]]
* [[Semantic Web]]
* [[Inference in Semantic Web]]



== Sources ==
* [[Semantic Web for the Working Ontologist (book)]]

[[Category:Semantic Web]]</text>
      <sha1>9rc8q8hrny4bbim8r9o4dcsusz456lt</sha1>
    </revision>
  </page>
  <page>
    <title>XML</title>
    <ns>0</ns>
    <id>386</id>
    <revision>
      <id>389</id>
      <timestamp>2014-05-03T08:37:24Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6968">== XML ==
XML is a [[Semi-Structured Data Model]] for many applications

XML 
* it is a superset of HTML
* XML is a generic data format
* for machine-to-machine communication and data exchange 
* especially widely used for [[Data Integration]]
* there are ways to impose some constraints via schema: [[DTD]], [[XML Schema]]
* there are many tools


== Representations ==
=== [[Tree]] Representation ===
In XML Trees,
* values are always at the leaf level 
* all other nodes contain information about these nodes 

Examples:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/semi-structured-ex1.png
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/semi-structured-ex2.png


Object-oriented model of these trees:
* DOM  or [[Document Object Model]]


=== Serialized Form ===
The following are the serialized forms of these trees:
&lt;pre&gt;
&lt;r&gt;
  &lt;name&gt;Alan&lt;/name&gt;
  &lt;tel&gt;32190&lt;/tel&gt;
  &lt;email&gt;alan@aol.ru&lt;/email&gt;
&lt;/r&gt;
&lt;/pre&gt;

&lt;pre&gt;
&lt;r&gt;
  &lt;name&gt;
    &lt;first&gt;Alan&lt;/first&gt;
    &lt;last&gt;Black&lt;/last&gt;
  &lt;/name&gt;
  &lt;tel&gt;32190&lt;/tel&gt;
  &lt;email&gt;alan@aol.ru&lt;/email&gt;
&lt;/r&gt;
&lt;/pre&gt;

So this the serialized form is
* it's a textual, linear representation of the tree


=== Examples === 
&lt;pre&gt;&lt;document /&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;document&gt; Hello World! &lt;/document&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;document&gt;
  &lt;salutation&gt; Hello World! &lt;/salutation&gt;
&lt;/document&gt;
&lt;/pre&gt;

&lt;pre&gt;&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; ?&gt;
&lt;document&gt;
  &lt;salutation color=&quot;blue&quot;&gt; Hello World! &lt;/salutation&gt;
&lt;/document&gt;
&lt;/pre&gt;

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/xml-trees-ex.png


Bigger Example:

&lt;pre&gt;
&lt;solar_system&gt;
  &lt;star&gt;
    &lt;name&gt;Sun&lt;/name&gt;
    &lt;spectral_type&gt;G2&lt;/spectral_type&gt;
    &lt;age unit=&quot;billions years&quot;&gt;5&lt;/age&gt;
  &lt;/star&gt;
  &lt;planet type=&quot;telluric&quot;&gt;
    &lt;name&gt;Earth&lt;/name&gt;
    &lt;distance unit=&quot;km&quot;&gt;149600000&lt;/distance&gt;
    &lt;mass unit=&quot;kg&quot;&gt;5.98e24&lt;/mass&gt;
    &lt;diameter unit=&quot;km&quot;&gt;12756&lt;/diameter&gt;
    &lt;satellite number=&quot;1&quot;/&gt;
  &lt;/planet&gt;
  &lt;planet ring=&quot;yes&quot; type=&quot;gaseous&quot;&gt;
    &lt;name&gt;Saturn&lt;/name&gt;
    &lt;distance unit=&quot;UA&quot;&gt;5.2&lt;/distance&gt;
    &lt;mass unit=&quot;Earth mass&quot;&gt;95&lt;/mass&gt;
    &lt;diameter unit=&quot;Earth diameter&quot;&gt;9.4&lt;/diameter&gt;
    &lt;satellite number=&quot;18&quot;/&gt;
  &lt;/planet&gt;
  &lt;planet ring=&quot;yes&quot; type=&quot;gaseous&quot;&gt;
    &lt;name&gt;Uranus&lt;/name&gt;
    &lt;distance unit=&quot;UA&quot;&gt;19.2&lt;/distance&gt;
    &lt;mass unit=&quot;Earth mass&quot;&gt;14.5&lt;/mass&gt;
    &lt;diameter unit=&quot;Earth diameter&quot;&gt;4&lt;/diameter&gt;
    &lt;satellite number=&quot;15&quot;/&gt;
  &lt;/planet&gt;
&lt;/solar_system&gt;
&lt;/pre&gt;

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/xml-solar-system.png
* note that digits under nodes signify the positions 
* ''positions'' is a way of identifying nodes 
* to denote the position of the root we use $\epsilon$



== Working with XML ==
=== Parsing ===
For applications 
* typically an application parses a serialized form and produces a tree 
* it works with it: accesses parts of the document, reorganizes it, etc
* after finishing, it serializes it back to XML 

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/xml-apps.png


Parsers 
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/xml-apps-2.png
* a parser takes a serialized form an produces a tree form (for example, [[DOM]])
* validation
** first of all it checks if the document is well-formed
** using schemas, the parser checks if the document is valid


=== Schemas ===
Schemas are used to
* specify constraints for XML documents: order of elements, structure, data types
* augment documents: default values, white space processing, etc
* give some semantics to the documents you want to design
* to reuse and document your decisions 
* designing contracts for web services 

There are 3 ways of doing it:
* [[DTD]] - based
* [[XML Schema]]
* Relax NG

Schemas are build on top of [[Tree Automata]] and [[Regular Expressions]] theory
* Validation of a document = a run of a tree automaton


=== Attributes vs Elements ===
Consider the following XML documents :
&lt;pre&gt;
&lt;university&gt;
  &lt;teacher subject=&quot;math&quot; students=&quot;180&quot;&gt;M. Durant&lt;/teacher&gt;
  &lt;teacher subject=&quot;CS&quot; students=&quot;130&quot;&gt;M. Smith&lt;/teacher&gt;
  &lt;teacher subject=&quot;CS&quot; students=&quot;150&quot;&gt;Mme. Martin&lt;/teacher&gt;
&lt;/university&gt;
&lt;/pre&gt;

&lt;pre&gt;
&lt;university&gt;
  &lt;teacher&gt;
    &lt;name&gt;M. Durant&lt;/name&gt;
    &lt;subject&gt;Math&lt;/subject&gt;
    &lt;students&gt;180&lt;/students&gt;
  &lt;/teacher&gt;
  &lt;teacher&gt;
    &lt;name&gt;M. Smith&lt;/name&gt;
    &lt;subject&gt;CS&lt;/subject&gt;
    &lt;students&gt;130&lt;/students&gt;
  &lt;/teacher&gt;
  &lt;teacher&gt;
    &lt;name&gt;Mme. Martin&lt;/name&gt;
    &lt;subject&gt;Math&lt;/subject&gt;
    &lt;students&gt;150&lt;/students&gt;
  &lt;/teacher&gt;
&lt;/university&gt;
&lt;/pre&gt;

Which representation is better? 
* it depends 
* attributes should rather be used for metadata (like units of measure, etc)
* also attributes must be used only for simple types - not for complex values!

&lt;pre&gt;&lt;note date=&quot;10/01/2008&quot; /&gt;&lt;/pre&gt;

Better:
&lt;pre&gt;
&lt;note&gt;
  &lt;date&gt;
    &lt;day&gt;10&lt;/day&gt;
    &lt;month&gt;01&lt;/month&gt;
    &lt;year&gt;2008&lt;/year&gt;
  &lt;/date&gt;
&lt;/note&gt;
&lt;/pre&gt;


=== Namespaces ===
Suppose we have two tags with the same name, but different meaning

For example, consider a tag &lt;code&gt;&lt;title&gt;&lt;/code&gt;
* it can be an HTML title 
* a description of a book
* the title of a person

How to avoid naming conflicts? 
* use namespaces: add prefixes to the names 
* this way it's possible to give unique names 
* each namespace prefix is uniquely identified with some URI

{|
 |

&lt;pre&gt;
&lt;h:table&gt;
  &lt;h:tr&gt;
    &lt;h:td&gt;Apples&lt;/h:td&gt;
    &lt;h:td&gt;Bananas&lt;/h:td&gt;
  &lt;/h:tr&gt;
&lt;/h:table&gt;
&lt;/pre&gt;

 |

&lt;pre&gt;
&lt;t:table&gt;
  &lt;t:name&gt;African Coffee&lt;/t:name&gt;
  &lt;t:width&gt;80&lt;/t:width&gt;
  &lt;t:lenght&gt;120&lt;/t:lenght&gt;
&lt;/t:table&gt;
&lt;/pre&gt;

|}

&lt;pre&gt;
&lt;root&gt;
  &lt;h:table xmlns:h=&quot;http://www.w3.org/TR/html4/&quot;&gt;
    &lt;h:tr&gt;
      &lt;h:td&gt;Apples&lt;/h:td&gt;
      &lt;h:td&gt;Bananas&lt;/h:td&gt;
    &lt;/h:tr&gt;
  &lt;/h:table&gt;
  &lt;t:table xmlns:t=&quot;http://www.foo.fr/furniture&quot;&gt;
    &lt;t:name&gt;African Coffee&lt;/t:name&gt;
    &lt;t:width&gt;80&lt;/t:width&gt;
    &lt;t:lenght&gt;120&lt;/t:lenght&gt;
  &lt;/t:table&gt;
&lt;/root&gt;
&lt;/pre&gt;
* Note that in this case &lt;code&gt;h&lt;/code&gt; is defined in the element prefixed with &lt;code&gt;h:&lt;/code&gt; it is possible


Default namespace
* for some element we can define a default namespace
* so we don't have to prefix anything down the tree: the default namespace is assumed
* another element down the tree can redefine the default namespace for all its children


&lt;pre&gt;
&lt;chapter xmlns=&quot;http://www.mydescription.com&quot;&gt;
  &lt;paragraph&gt;
  ...
  &lt;/paragraph&gt;
&lt;/chapter&gt;
&lt;/pre&gt;

&lt;pre&gt;
&lt;chapter xmlns=&quot;http://www.mydescription.com/&quot;&gt;
  &lt;paragraph xmlns=&quot;http://www.foo.fr/&quot;&gt;
  ...
  &lt;/paragraph&gt;
&lt;/chapter&gt;
&lt;/pre&gt;


Several namespaces
* it's also possible to attach several namespaces to one element

&lt;pre&gt;
&lt;root xmlns:h=&quot;http://www.w3.org/TR/html4/&quot; xmlns:t=&quot;http://www.foo.fr/furniture&quot;&gt;
  &lt;h:table&gt;
    &lt;h:tr&gt;
      &lt;h:td&gt;Apples&lt;/h:td&gt;
      &lt;h:td&gt;Bananas&lt;/h:td&gt;
    &lt;/h:tr&gt;
  &lt;/h:table&gt;
  &lt;t:table&gt;
    &lt;t:name&gt;African Coffee&lt;/t:name&gt;
    &lt;t:width&gt;80&lt;/t:width&gt;
    &lt;t:lenght&gt;120&lt;/t:lenght&gt;
  &lt;/t:table&gt;
&lt;/root&gt;
&lt;/pre&gt;


== Sources ==
* [[XML and Web Technologies (UFRT)]]

[[Category:XML]]</text>
      <sha1>harnp8dblif0eomzzlohuce1yesiq84</sha1>
    </revision>
  </page>
  <page>
    <title>Semi-Structured Data Model</title>
    <ns>0</ns>
    <id>387</id>
    <revision>
      <id>390</id>
      <timestamp>2014-05-03T08:38:05Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1574">== Semi-Structured [[Data Model]] ==
This is a [[Data Model]] that is based on [[Graphs]] 
* for representing both regular and irregular data


Main Ideas:
* Data is Self-Describing
* Flexible Data Typing
* Serialized Forms


=== Data is Self-Describing ===
The content comes with it's own description
* (In contract to [[Relational Data Model]] where the schema and the data are stored separately)

Starting point: 
* associations list: a collection of key-value pairs

For example, a record:
* &lt;code&gt;name : Alan, &lt;/code&gt;
* &lt;code&gt;tel : 32190, &lt;/code&gt;
* &lt;code&gt;email : alan@aol.ru&lt;/code&gt;

But values themselves can be collections
* &lt;code&gt;name : &lt;/code&gt;
** &lt;code&gt;first : Alan,&lt;/code&gt;
** &lt;code&gt;last : Black &lt;/code&gt;
* &lt;code&gt;tel : 32190, &lt;/code&gt;
* &lt;code&gt;tel : 32191,&lt;/code&gt;
* &lt;code&gt;email : alan@aol.ru&lt;/code&gt;


And some labels may repeat


Graphical representation
* can graphically represent as [[Tree]]s
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/semi-structured-ex1.png
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/semi-structured-ex2.png
* the [[XML]] Data Model adopts this representation


=== Flexible Data Typing ===
* there can be no typing at all
* but data may be typed


=== There's a serialized form ===
* The serialized representation of a such graph 
* [[XML]]
* JSON 
* etc


== Links ==
* http://en.wikipedia.org/wiki/Semi-structured_data
* http://www.dcs.bbk.ac.uk/~ptw/teaching/ssd/notes.html

== Sources ==
* [[XML and Web Technologies (UFRT)]]

[[Category:XML]]
[[Category:Data Models]]</text>
      <sha1>gaxa5ea940g47vl4isw5lavvgez2xx6</sha1>
    </revision>
  </page>
  <page>
    <title>Relational Data Model</title>
    <ns>0</ns>
    <id>388</id>
    <redirect title="Relational Databases" />
    <revision>
      <id>391</id>
      <timestamp>2014-05-03T08:39:13Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="56">#REDIRECT [[Relational Databases#Relational Data Model]]</text>
      <sha1>kb1fchfbex5rwf8urfxyz4yq6t5n53w</sha1>
    </revision>
  </page>
  <page>
    <title>XML Schema</title>
    <ns>0</ns>
    <id>389</id>
    <revision>
      <id>392</id>
      <timestamp>2014-05-03T08:41:36Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7644">== XML Schema ==
This is a better alternative to [[DTD]] for validating [[XML]] documents 
* it is XML itself
* it can express complex types
* it supports namespaces



== Types ==
=== Predefined Primitives ===
There are a lot of predefined primitives


{| class=&quot;wikitable&quot;
! Type ||  Example of Value
|-
| &lt;code&gt;string&lt;/code&gt; || &lt;code&gt;any Unicode string &lt;/code&gt;
|-
| &lt;code&gt;boolean&lt;/code&gt; || &lt;code&gt;true, false, 1, 0 &lt;/code&gt;
|-
| &lt;code&gt;decimal&lt;/code&gt; || &lt;code&gt;3.1415 &lt;/code&gt;
|-
| &lt;code&gt;float&lt;/code&gt; || &lt;code&gt;6.02214199E23 &lt;/code&gt;
|-
| &lt;code&gt;double&lt;/code&gt; || &lt;code&gt;42E970 &lt;/code&gt;
|-
| &lt;code&gt;dateTime&lt;/code&gt; || &lt;code&gt;2004-09-26T16:29:00-05:00 &lt;/code&gt;
|-
| &lt;code&gt;time&lt;/code&gt; || &lt;code&gt;16:29:00-05:00 &lt;/code&gt;
|-
| &lt;code&gt;date&lt;/code&gt; || &lt;code&gt;2004-09-26 &lt;/code&gt;
|-
| &lt;code&gt;hexBinary&lt;/code&gt; || &lt;code&gt;48656c6c6f0a &lt;/code&gt;
|-
| &lt;code&gt;base64Binary&lt;/code&gt; || &lt;code&gt;SGVsbG8K &lt;/code&gt;
|-
| &lt;code&gt;anyURI&lt;/code&gt; || &lt;code&gt;http://0agr.ru/wiki/ &lt;/code&gt;
|-
| &lt;code&gt;QName&lt;/code&gt; || &lt;code&gt;rcp:recipe, recipe &lt;/code&gt;
|}



&lt;pre&gt;
&lt;simpleType name=&quot;integerList&quot;&gt; 
  &lt;list itemType=&quot;integer&quot;/&gt; 
&lt;/simpleType&gt; 
&lt;/pre&gt;


=== Simple Types: Constrains ===
We also can add additional constraints with so-called facets
{|

* &lt;code&gt;length &lt;/code&gt;
* &lt;code&gt;minLength &lt;/code&gt;
* &lt;code&gt;maxLength &lt;/code&gt;
* &lt;code&gt;pattern &lt;/code&gt;
* &lt;code&gt;enumeration &lt;/code&gt;
* &lt;code&gt;whiteSpace&lt;/code&gt;

|

* &lt;code&gt;maxInclusive &lt;/code&gt;
* &lt;code&gt;maxExclusive &lt;/code&gt;
* &lt;code&gt;minInclusive &lt;/code&gt;
* &lt;code&gt;minExclusive &lt;/code&gt;
* &lt;code&gt;totalDigits &lt;/code&gt;
* &lt;code&gt;fractionDigits &lt;/code&gt;

|}


&lt;pre&gt;
&lt;simpleType name=&quot;score_from_0_to_100&quot;&gt; 
  &lt;restrictionbase=&quot;integer&quot;&gt; 
    &lt;minInclusivevalue=&quot;0&quot;/&gt; 
    &lt;maxInclusivevalue=&quot;100&quot;/&gt; 
  &lt;/restriction&gt; 
&lt;/simpleType&gt; 

&lt;simpleType name=&quot;percentage&quot;&gt; 
  &lt;restriction base=&quot;string&quot;&gt; 
    &lt;patternvalue=&quot;([0-9]|[1-9][0-9]|100)%&quot;/&gt; 
  &lt;/restriction&gt; 
&lt;/simpleType&gt;
&lt;/pre&gt;


So as you see it's also possible to use [[Regular Expressions]]
* to define constraints, etc


=== Derived Simple Types ===
We can derive a simple type from two simple types:

&lt;pre&gt;
&lt;simpleType name=&quot;boolean_or_decimal&quot;&gt; 
  &lt;union&gt; 
    &lt;simpleType&gt; 
  &lt;restriction base=&quot;boolean&quot;/&gt; 
  &lt;/simpleType&gt; 
  &lt;simpleType&gt; 
    &lt;restriction base=&quot;decimal&quot;/&gt; 
  &lt;/simpleType&gt; 
  &lt;/union&gt; 
&lt;/simpleType&gt; 
&lt;/pre&gt;

There are some built-in derived types
* normalizedString 
* unsignedLong 
* ... 


=== Complex Types ===
Elements:
* reference to already defined element: &lt;code&gt;&lt;element ref=&quot;name&quot; /&gt; &lt;/code&gt;


We can use [[Regular Expressions]] for restricting sequences of tags we can have:

{| class=&quot;wikitable&quot;
|-
| Concatenation  || &lt;code&gt;&lt;sequence&gt; ...&lt;/sequence&gt; &lt;/code&gt;
|-
| Union    || &lt;code&gt;&lt;choice&gt; ...&lt;/choice&gt; &lt;/code&gt;
|-
| All   || &lt;code&gt;&lt;all&gt; ...&lt;/all&gt;&lt;/code&gt;
|-
| Element wildcard || &lt;code&gt;&lt;any /&gt; &lt;/code&gt;
|-
| ? || minOccurs=&quot;0&quot; maxOccurs=&quot;1&quot;
|-
| + || minOccurs=&quot;1&quot; maxOccurs=&quot;unbounded&quot;
|- 
| * || minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;
|}


Attributes
* also can refer to already defined attributes
** &lt;code&gt;&lt;attribute ref=&quot;r:class&quot;/&gt;&lt;/code&gt;

=== Extensions ===
Suppose we want to have an integer with a parameter
* we can extend from integer and add an attribute

&lt;pre&gt;
&lt;complexType name=&quot;category&quot;&gt; 
  &lt;simpleContent&gt; 
    &lt;extension base=&quot;integer&quot;&gt; 
      &lt;attribute ref=&quot;r:class&quot;/&gt;
    &lt;/extension&gt; 
  &lt;/simpleContent&gt; 
&lt;/complexType&gt; 
&lt;/pre&gt;


Same way we can extend one more time
* and add another attribute

&lt;pre&gt;
&lt;complexType name=&quot;extended_category&quot;&gt; 
  &lt;simpleContent&gt; 
    &lt;extension base=&quot;n:category&quot;&gt; 
      &lt;attribute ref=&quot;r:kind&quot;/&gt; 
    &lt;/extension&gt; 
  &lt;/simpleContent&gt; 
&lt;/complexType&gt; 
&lt;/pre&gt;


Also we can restrict some class
* adding a restriction is a little bit different from extension 

&lt;pre&gt;
&lt;complexType name=&quot;restricted_category&quot;&gt; 
  &lt;simpleContent&gt; 
    &lt;restriction base=&quot;n:category&quot;&gt; 
      &lt;totalDigits value=&quot;3&quot;/&gt; 
      &lt;attribute ref=&quot;r:class&quot; use=&quot;required&quot;/&gt; 
    &lt;/restriction&gt; 
  &lt;/simpleContent&gt; 
&lt;/complexType&gt;
&lt;/pre&gt;


=== Local vs Global Declaration ===
Usually we define an element and reference it
* this is called ''global declaration''

However it's possible to describe an element with an anonymous type
&lt;pre&gt;
&lt;element name=&quot;card&quot;&gt; 
  &lt;complexType&gt; 
    &lt;sequence&gt; 
      &lt;element name=&quot;name&quot; type=&quot;string&quot;/&gt; 
      ... 
    &lt;/sequence&gt; 
  &lt;/complexType&gt; 
&lt;/element&gt;
&lt;/pre&gt;

Note that it can cause some problems
* locally defined elements must belong to the namespace - but they don't
* they are ''unqualified'' by default (no namespace is associated)
* such elements belong to the element they're associated with
* so we have to set &lt;code&gt;elementFormDefault=&quot;qualified&quot;&lt;/code&gt;
* some links: [http://stackoverflow.com/questions/1463138/what-does-elementformdefault-do-for-xml-when-is-it-used] and [http://www.w3.org/TR/xmlschema-0/#NS]


== Examples ==
=== Solar System ===
Consider the following XML:

&lt;pre&gt;
&lt;solar_system&gt;
  &lt;star&gt;
    &lt;name&gt;Sun&lt;/name&gt;
    &lt;spectral_type&gt;G2&lt;/spectral_type&gt;
    &lt;age unit=&quot;billions years&quot;&gt;5&lt;/age&gt;
  &lt;/star&gt;
  &lt;planet type=&quot;telluric&quot;&gt;
    &lt;name&gt;Earth&lt;/name&gt;
    &lt;distance unit=&quot;km&quot;&gt;149600000&lt;/distance&gt;
    &lt;mass unit=&quot;kg&quot;&gt;5.98e24&lt;/mass&gt;
    &lt;diameter unit=&quot;km&quot;&gt;12756&lt;/diameter&gt;
    &lt;satellite number=&quot;1&quot;/&gt;
  &lt;/planet&gt;
  &lt;planet ring=&quot;yes&quot; type=&quot;gaseous&quot;&gt;
    &lt;name&gt;Saturn&lt;/name&gt;
    &lt;distance unit=&quot;UA&quot;&gt;5.2&lt;/distance&gt;
    &lt;mass unit=&quot;Earth mass&quot;&gt;95&lt;/mass&gt;
    &lt;diameter unit=&quot;Earth diameter&quot;&gt;9.4&lt;/diameter&gt;
    &lt;satellite number=&quot;18&quot;/&gt;
  &lt;/planet&gt;
  &lt;planet ring=&quot;yes&quot; type=&quot;gaseous&quot;&gt;
    &lt;name&gt;Uranus&lt;/name&gt;
    &lt;distance unit=&quot;UA&quot;&gt;19.2&lt;/distance&gt;
    &lt;mass unit=&quot;Earth mass&quot;&gt;14.5&lt;/mass&gt;
    &lt;diameter unit=&quot;Earth diameter&quot;&gt;4&lt;/diameter&gt;
    &lt;satellite number=&quot;15&quot;/&gt;
  &lt;/planet&gt;
&lt;/solar_system&gt;
&lt;/pre&gt;


Here's the XML schema for it

&lt;pre&gt;
&lt;xs:schema xmlns:xs=&quot;http://www.w3.org/2001/XMLSchema&quot; elementFormDefault=&quot;qualified&quot; 
  targetNamespace=&quot;http://foo.fr/solar_system&quot; xmlns:s=&quot;http://foo.fr/solar_system&quot;&gt;

  &lt;xs:element name=&quot;solar_system&quot;&gt;
    &lt;xs:complexType&gt;
      &lt;xs:sequence&gt;
        &lt;xs:element ref=&quot;s:star&quot;/&gt;
        &lt;xs:element maxOccurs=&quot;unbounded&quot; ref=&quot;s:planet&quot;/&gt;
      &lt;/xs:sequence&gt;
    &lt;/xs:complexType&gt;
  &lt;/xs:element&gt;

  &lt;xs:element name=&quot;star&quot;&gt;
    &lt;xs:complexType&gt;
      &lt;xs:sequence&gt;
        &lt;xs:element name=&quot;name&quot; type=&quot;xs:NCName&quot;/&gt;
        &lt;xs:element name=&quot;spectral_type&quot; type=&quot;xs:NCName&quot;/&gt;
        &lt;xs:element name=&quot;age&quot; type=&quot;s:measure_type&quot;/&gt;
      &lt;/xs:sequence&gt;
    &lt;/xs:complexType&gt;
  &lt;/xs:element&gt;
  &lt;xs:element name=&quot;planet&quot;&gt;
    &lt;xs:complexType&gt;
      &lt;xs:sequence&gt;
        &lt;xs:element name=&quot;name&quot; type=&quot;xs:NCName&quot;/&gt;
        &lt;xs:element name=&quot;distance&quot; type=&quot;s:measure_type&quot;/&gt;
        &lt;xs:element name=&quot;mass&quot; type=&quot;s:measure_type&quot;/&gt;
        &lt;xs:element name=&quot;diameter&quot; type=&quot;s:measure_type&quot;/&gt;
        &lt;xs:element ref=&quot;s:satellite&quot;/&gt;
      &lt;/xs:sequence&gt;
      &lt;xs:attribute name=&quot;ring&quot; type=&quot;xs:NCName&quot;/&gt;
      &lt;xs:attribute name=&quot;type&quot; use=&quot;required&quot; type=&quot;xs:NCName&quot;/&gt;
    &lt;/xs:complexType&gt;
  &lt;/xs:element&gt;

  &lt;xs:complexType name=&quot;measure_type&quot;&gt;
    &lt;xs:simpleContent&gt;
      &lt;xs:extension base=&quot;xs:float&quot;&gt;
        &lt;xs:attribute name=&quot;unit&quot; use=&quot;required&quot; type=&quot;xs:NCName&quot;/&gt;
      &lt;/xs:extension&gt;
    &lt;/xs:simpleContent&gt;
  &lt;/xs:complexType&gt;
  &lt;xs:element name=&quot;satellite&quot;&gt;
    &lt;xs:complexType&gt;
      &lt;xs:attribute name=&quot;number&quot; use=&quot;required&quot; type=&quot;xs:integer&quot;/&gt;
    &lt;/xs:complexType&gt;
  &lt;/xs:element&gt;
  
&lt;/xs:schema&gt;
&lt;/pre&gt;


Note the usage of &lt;code&gt;xs:NCName&lt;/code&gt;
* it is like string but doesn't allow certain characters 
* see more here: [http://stackoverflow.com/questions/1631396/what-is-an-xsncname-type-and-when-should-it-be-used]


== See Also ==
* [[XML]]
* [[DTD]]
* [[Tree Automata]]


== Sources ==
* [[XML and Web Technologies (UFRT)]]

[[Category:XML]]</text>
      <sha1>9uu8q5e47b2mxn50psfxcegn260um0q</sha1>
    </revision>
  </page>
  <page>
    <title>DTD</title>
    <ns>0</ns>
    <id>390</id>
    <revision>
      <id>393</id>
      <timestamp>2014-05-03T08:45:26Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4477">== DTD ==
DTD, or Document Type Definition, is a language for defining schemas for [[XML]]
* to validate the content of XML documents
* it uses [[Regular Expressions]] for validation
* it is an integral part of XML specification


=== Regular Expression ===
The following defines the valid content of &lt;code&gt;table&lt;/code&gt; element in XTML
* &lt;code&gt;caption? ( col* | colgroup* ) thead? tfoot? ( tbody+ | tr+ )&lt;/code&gt;
* with this expression, the following is a minimal possible word that matches it
* &lt;code&gt;tbody tr&lt;/code&gt;


== Schema Definition ==
=== Declaration ===
To declare schema
* add &lt;code&gt;&lt;!DOCTYPE {name} SYSTEM &quot;http://{uri}.dtd&quot;&gt;&lt;/code&gt; to the beginning of an XML document

&lt;?xml version=&quot;1.1&quot;?&gt; 
&lt;!DOCTYPE collection SYSTEM &quot;http://foo.fr/example.dtd&quot;&gt;
&lt;collection&gt; 
... 
&lt;/collection&gt; 


=== !ELEMENT ===
The declaration for elements (tags or titles in our XML documents) is the following 
* &lt;!ELEMENT {name} {content_mode}&gt; where
* name - a name of some tag from the document
* content_mode &lt;code&gt;EMPTY&lt;/code&gt;, &lt;code&gt;ANY&lt;/code&gt; or 
* &lt;code&gt;#PCDATA&lt;/code&gt; &quot;parsed character data&quot;, only one text element is allowed in the content
* some regular expression over the tag names


Example:
* &lt;code&gt;&lt;!ELEMENT table (caption?,(col*|colgroup*),thead?,tfoot?,(tbody+|tr+)) &gt;&lt;/code&gt;
* colon (&lt;code&gt;,&lt;/code&gt;) is used to express concatenation, pipe (&lt;code&gt;|&lt;/code&gt;) - to express union



=== &lt;code&gt;!ATTLIST&lt;/code&gt; ===
Also we need to declare attributes for elements
* syntax: &lt;code&gt;&lt;!ATTLIST {tag} {attribute} {type} {#REQUIRED|#IMPLIED}&gt;&lt;/code&gt; 


&lt;pre&gt;
&lt;!ATTLIST input maxlength CDATA #REQUIRED 
                tabindex CDATA #IMPLIED&gt;
&lt;/pre&gt;
* &lt;code&gt;#IMPLIED&lt;/code&gt; = optional, &lt;code&gt;#REQUIRED&lt;/code&gt;  = not optional
* CDATA: any value

&lt;pre&gt;&lt;!ATTLIST p align (left|center|right|justify) #IMPLIED&gt;&lt;/pre&gt;
* here we enumerate possible values of attributes
* for optional attributes can also put the default value 

&lt;pre&gt;&lt;!ATTLIST form method (get|post) &quot;get&quot;&gt;&lt;/pre&gt;
* the default value of this attribute is &lt;code&gt;get&lt;/code&gt;


== Example ==
=== Solar System ===
Consider the following XML:

&lt;pre&gt;
&lt;solar_system&gt;
  &lt;star&gt;
    &lt;name&gt;Sun&lt;/name&gt;
    &lt;spectral_type&gt;G2&lt;/spectral_type&gt;
    &lt;age unit=&quot;billions years&quot;&gt;5&lt;/age&gt;
  &lt;/star&gt;
  &lt;planet type=&quot;telluric&quot;&gt;
    &lt;name&gt;Earth&lt;/name&gt;
    &lt;distance unit=&quot;km&quot;&gt;149600000&lt;/distance&gt;
    &lt;mass unit=&quot;kg&quot;&gt;5.98e24&lt;/mass&gt;
    &lt;diameter unit=&quot;km&quot;&gt;12756&lt;/diameter&gt;
    &lt;satellite number=&quot;1&quot;/&gt;
  &lt;/planet&gt;
  &lt;planet ring=&quot;yes&quot; type=&quot;gaseous&quot;&gt;
    &lt;name&gt;Saturn&lt;/name&gt;
    &lt;distance unit=&quot;UA&quot;&gt;5.2&lt;/distance&gt;
    &lt;mass unit=&quot;Earth mass&quot;&gt;95&lt;/mass&gt;
    &lt;diameter unit=&quot;Earth diameter&quot;&gt;9.4&lt;/diameter&gt;
    &lt;satellite number=&quot;18&quot;/&gt;
  &lt;/planet&gt;
  &lt;planet ring=&quot;yes&quot; type=&quot;gaseous&quot;&gt;
    &lt;name&gt;Uranus&lt;/name&gt;
    &lt;distance unit=&quot;UA&quot;&gt;19.2&lt;/distance&gt;
    &lt;mass unit=&quot;Earth mass&quot;&gt;14.5&lt;/mass&gt;
    &lt;diameter unit=&quot;Earth diameter&quot;&gt;4&lt;/diameter&gt;
    &lt;satellite number=&quot;15&quot;/&gt;
  &lt;/planet&gt;
&lt;/solar_system&gt;
&lt;/pre&gt;


DTD-schema for this examples is:
&lt;pre&gt;
&lt;!ELEMENT solar_system (star,planet+)&gt;

&lt;!ELEMENT star (name,spectral_type,age)&gt;

&lt;!ELEMENT name (#PCDATA)&gt;
&lt;!ELEMENT spectral_type (#PCDATA)&gt;
&lt;!ELEMENT age (#PCDATA)&gt;
&lt;!ATTLIST age unit CDATA #REQUIRED&gt;

&lt;!ELEMENT planet (name,distance,mass,diameter,satellite?)&gt;
&lt;!ATTLIST planet ring CDATA #IMPLIED&gt;
&lt;!ATTLIST planet type CDATA #REQUIRED&gt;

&lt;!ELEMENT distance (#PCDATA)&gt;
&lt;!ATTLIST distance unit CDATA #REQUIRED&gt;

&lt;!ELEMENT mass (#PCDATA)&gt;
&lt;!ATTLIST mass unit CDATA #REQUIRED&gt;

&lt;!ELEMENT diameter (#PCDATA)&gt;
&lt;!ATTLIST diameter unit CDATA #REQUIRED&gt;

&lt;!ELEMENT satellite EMPTY&gt;
&lt;!ATTLIST satellite number CDATA #REQUIRED&gt;
&lt;/pre&gt;

Note the limitation:
* we cannot have two different &lt;code&gt;name&lt;/code&gt; elements
* i.e. can have only one definition per one name


For example, the following is not possible to validate with DTD

&lt;pre&gt;
&lt;planet&gt;
  &lt;name language=&quot;English&quot;&gt;Earth&lt;/name&gt;
&lt;/planet&gt;

&lt;star&gt;
  &lt;name&gt;Sum&lt;/name&gt;
&lt;/star&gt;
&lt;/pre&gt;


== Limitations ==
* Specification of attribute values is too limited 
* Element and attribute declarations are context insensitive 
* Character data cannot be combined with the regular expression content model 
* It does not itself use an XML syntax 
* No support for namespaces 


=== [[XML Schema]] ===
* More expressive 
* XML itself
* support namespaces
* many other things


== Links ==
* http://en.wikipedia.org/wiki/Document_type_definition

== See Also ==
* [[Tree Automata]]
* [[XML]]
* [[XML Schema]]

== Sources ==
* [[XML and Web Technologies (UFRT)]]

[[Category:XML]]</text>
      <sha1>511cs13pplfz89nckxamtdkndb0zcwb</sha1>
    </revision>
  </page>
  <page>
    <title>Tree</title>
    <ns>0</ns>
    <id>391</id>
    <revision>
      <id>394</id>
      <timestamp>2014-05-03T08:46:13Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="786">== Trees ==
A Tree $T$ is a [[Graph]] that:


https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/trees.png

Trees can be
* Ranked or Unranked
* Ordered or Unordered


=== Ranked Trees ===
A tree is ''ranked'' if you know in advance how many children a node has
* Binary Trees are trees with rank 2 (see [[Binary Search Trees]])
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/trees-bin.png

A tree is unranked if you don't know in advance the number of children



=== Ordered Trees ===
A tree is ''ordered''  if the order of children matters

For example, 
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/trees-order.png

== Sources ==
* [[XML and Web Technologies (UFRT)]]

[[Category:Graphs]]</text>
      <sha1>78waeew8vuc3gl940gtdhbtnem40beg</sha1>
    </revision>
  </page>
  <page>
    <title>Conjunctive Query/Translation</title>
    <ns>0</ns>
    <id>392</id>
    <revision>
      <id>395</id>
      <timestamp>2014-05-03T11:19:57Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4185">== [[Conjunctive Query]] Translation ==
This describes translation algorithms from [[Relational Algebra]] to [[Conjunctive Query|Conjunctive Queries]] and vise-versa


== Translation to [[Conjunctive Query|Conjunctive Queries]] ==
We can translate a [[Relational Algebra]] expression that is in [[Select-Project-Join Expressions|Select-Project-Join]] form into CQ. Note that it is not possible to translate any other form to it
* for SQL, first [[Translating SQL to Relational Algebra|translate SQL to TA]]
* then find the minimal possible [[Select-Project-Join Expressions|SPJ Expression]]
* translate it as suggested below 


=== Translation by Example ===
Suppose we have the following logical query plan:

$
\pi_{
  \begin{subarray}{l}
    R_1.A, \\
    S_1.B \\
  \end{subarray}
}
\sigma_{
  \begin{subarray}{l}
    {\color{grey}{(1)}} \ R_1.A = R_2.A \ \land \\
    {\color{grey}{(2)}} \ R_2.B = 4 \ \land \\
    {\color{grey}{(3)}} \ R_2.A = R_3.A \ \land \\
    {\color{grey}{(4)}} \ R_3.B = S_1.B \ \land \\
    {\color{grey}{(5)}} \ S_1.C = S_2.C \ \land \\
    {\color{grey}{(6)}} \ S_2.B = 4
  \end{subarray}
}
\big(
\rho_{R_1}(R) \times \rho_{R_2}(R) \times \rho_{R_3}(R) \times \rho_{S_1}(S) \times \rho_{S_2}(S) 
\big)$

We proceed as follows
* step 1: 
: for each relation we create an atom in body with distinct variables 
* step 2:
: for all the conditions of the selection part we replace the variables that participate in equations by the same symbol

in this case
* step 1:
** $
\begin{array}{l l}
Q(x_{R_1.A}, y_{S_1.B}) \leftarrow &amp; 
  R(x_{R_1.A}, y_{R_1.B}), \\
&amp; R(x_{R_2.A}, y_{R_1.B}), \\
&amp; R(x_{R_3.A}, y_{R_3.B}), \\
&amp; R(y_{S_1.B}, z_{S_1.C}), \\
&amp; R(y_{S_2.B}, z_{S_2.C}) \\
\end{array}
$
** in the head we put what we want to see in the output, i.e. the variables specified in the projection
** variable names like $x_{R_1.A}$ are helpful to keep track of the original names, however it could be anything
** this query now computes $\rho_{R_1}(R) \times \rho_{R_2}(R) \times \rho_{R_3}(R) \times \rho_{S_1}(S) \times \rho_{S_2}(S)$
* step 2
*: we restrict the query so it outputs only the tuples that match the selection condition
*: for that for every equality we replace all the occurrence of variables in that inequality to the same variable 
** the name does not matter
** for constants we put the value of a constant
** $
\begin{array}{l l}
Q(x_{R_1.A}, y_{S_1.B}) \leftarrow &amp; 
  R(x_{R_1.A} {\color{grey}{|^{(1)}}}, y_{R_1.B}), \\
&amp; R(x_{R_1.A} {\color{grey}{|^{(1,3)}}}, 4 {\color{grey}{|^{(2)}}}), \\
&amp; R(x_{R_1.A} {\color{grey}{|^{(3)}}}, y_{R_3.B} {\color{grey}{|^{(4)}}}), \\
&amp; R(y_{R_3.B} {\color{grey}{|^{(4)}}}, z_{S_1.C} {\color{grey}{|^{(5)}}}), \\
&amp; R(4 {\color{grey}{|^{(6)}}}, z_{S_1.C} {\color{grey}{|^{(5)}}}) \\
\end{array}
$
*** here ${\color{grey}{|^{(i)}}}$ shows what part of the condition was used to do the replacement
* now this is equivalent to the RA expression


== Translation from [[Conjunctive Query|Conjunctive Queries]] ==
Translation from CQ back to [[Relational Algebra]] is straightforward 
* the number of elements being joined is equal to the number of atoms
** i.e. the number of joins is (# of atoms) - 1
* we then add the selection
** with an equality condition for each variable name (if repeated 2 or more times)
** and for each constant
* finally, only the variables in the head get projected
* of course, we need to know the relational schema to be able to do that 
** note that in CQ we use positions to denote attributes

=== Example ===
Given: $Q(t) \leftarrow \text{MovieStar}({\color{red}{n}}, a, g, {\color{blue}{1940}}), \text{StarsIn}(t, y, {\color{red}{n}})$

We translate it as 
* $\pi_\text{S.movieTitle}
\sigma_{
  \begin{subarray}{l}
    \text{M.name = S.starName }  \land \\
    \text{M.birthDate = 1940} \\
  \end{subarray}
}
\big(
\rho_M(\text{MovieStar}) \times \rho_S(\text{StarsIn})
\big)$


== See Also ==
* [[Conjunctive Query]]

== Sources ==
* [[Database Systems Architecture (ULB)]]
* Database Systems Architecture lecture notes #2 by S. Vansummeren [https://dl.dropboxusercontent.com/sh/r0zvy3zaycbevx8/U0XnqCSwGZ/lect2-notes-conjunctive.pdf]


[[Category:Relational Databases]]</text>
      <sha1>11romi8tuv0w39v8x5s5cbvm6v5watg</sha1>
    </revision>
  </page>
  <page>
    <title>Conjunctive Query/Homomorphism</title>
    <ns>0</ns>
    <id>393</id>
    <revision>
      <id>396</id>
      <timestamp>2014-05-03T11:20:58Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3207">== Conjunctive Query Homomorphism ==
'''def''': a ''homomorphism'' of a [[Conjunctive Query]] $Q_2$ to a Conjunctive Query $Q_1$ is 
* a function $h$ that maps each variable in $Q_2$ to either
** a variable from $Q_1$ or
** a constant form $Q_1$
* s.t. 
** $h(\text{head}_2) = \text{head}_1$
** $h(\text{body}_2) \subseteq \text{body}_1$
** i.e. the values returned by queries are always the same, and body of one query is a subset of the other's query body


== Examples ==
=== Example 1 ===
Given
* relation $R(A, B)$ 
* 3 queries
** $Q_0(x) \leftarrow R(x, 33)$ ($Q_0 \equiv \pi_A \sigma_{B = 33}(R)$)
** $Q_1(x) \leftarrow R(x, x)$ ($Q_1 \equiv \pi_A \sigma_{A = B}(R)$)
** $Q_2(x) \leftarrow R(x, y)$ ($Q_0 \equiv \pi_A (R)$)

We can see that 
* $Q_0 \subseteq Q_2$ (obvious from the RA expressions: $Q_0$ just restricts $Q_2$)
* and $Q_1 \subseteq Q_2$ (same reasoning)


Homomorphisms 
* $x \mapsto x, y \mapsto 33$ is a homomorphism of $Q_2$ to $Q_0$
* $x \mapsto x, y \mapsto x$ is a homomorphism of $Q_2$ to $Q_0$
* there is no homomorphism from $Q_0$ to $Q_2$  or from $Q_0$ to $Q_1$:
** there's a constant in $Q_0$ that occurs neither in $Q_1$ nor in $Q_2$
** (i.e. for any $h$ there's no atom of the form $R(h(x), 33)$ in the body of $Q_1$ or $Q_2$)
* there is no homomorphism from $Q_1$ to $Q_2$
** for any $h(x), h(y)$, there is no atom of the form $R(h(x), h(y))$ in the body of $Q_2$


=== Example 2 ===
Example from before:
* $A(x, y) \leftarrow R(x, w), G(w, z), R(z, y)$
* $B(x, w) \leftarrow R(x, w), G(w, w), R(w, y)$

There is a homomorphism $h$ from $A$ to $B$
* $h: x \mapsto x, y \mapsto y, w \mapsto w, z \mapsto w$

But there is no homomorphism $h$ from $B$ to $A$
* such $h$ would have to map $G(w, w)$ to $G(w, z)$
* which would imply $w \mapsto w$ and w $\mapsto z$ at the same time
* but it's not possible since $h$ must be a function


=== Example 3 ===
Given two queries
* $C_1(x) \leftarrow R(x, y), R(y, z), R(z, w)$
* $C_2(x) \leftarrow R(x, y), R(y, x)$

There's a homomorphism from $C_1$ to $C_2$:
* $h: x \mapsto x, y \mapsto y, z \mapsto x, w \mapsto y$
* i.e.
** for head $x \mapsto x$
** for the 1st atom of $C_1$: $y \mapsto y$ (maps to 1st atom of $C_2$)
** for the 2nd atom of $C_1$: $z \mapsto x$ (maps to 2nd atom of $C_2$)
** for the 3rd atom of $C_1$: $w \mapsto y$ (maps again to 1st atom of $C_2$)

But there's no homomorphism from $C_2$ to $C_1$
* suppose it existed
* it would assign $x \mapsto x$ to map head of $C_2$ to head of $C_1$
* in this case $R(h(x), h(y)) = R(x, h(y))$ must occur in the body of $C_1$
** $\to$ the 1st atom of $C_2$ would be mapped to 1st atom of $C_1$
** $\to$ $h$ must map $y \mapsto y$
* analogously, 2nd atom of $C_2$ must be mapped to 2nd atom of $C_1$
** $h$ must map $x \mapsto z$
** but it cannot because we have already established $x \mapsto x$
* since $h$ must be a function, there is no homomorphism from $C_2$ to $C_1$


== See Also ==
* [[Conjunctive Query]]

== Sources ==
* [[Database Systems Architecture (ULB)]]
* Database Systems Architecture lecture notes #2 by S. Vansummeren [https://dl.dropboxusercontent.com/sh/r0zvy3zaycbevx8/U0XnqCSwGZ/lect2-notes-conjunctive.pdf]


[[Category:Relational Databases]]</text>
      <sha1>d373sabrbza8xm2xg5tpimj3s8dmmwt</sha1>
    </revision>
  </page>
  <page>
    <title>Conjunctive Query/Containment Exercise</title>
    <ns>0</ns>
    <id>394</id>
    <revision>
      <id>397</id>
      <timestamp>2014-05-03T11:21:30Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7618">== Exercises ==
These are exercises for containment of [[Conjunctive Query|Conjunctive Queries]]


=== Exercise 1 ===
Given the queries 
* $Q_1(x, y) \leftarrow Q(x, a), Q(a, b), Q(b, y)$
* $Q_2(x, y) \leftarrow Q(x, a), Q(a, b), Q(b, c), Q(c, y)$
* $Q_3(x, y) \leftarrow Q(x, a), Q(a, 1), Q(1, b), Q(b, y)$
* $Q_4(x, y) \leftarrow Q(x, y), Q(y, x)$

Find all pairs $(Q_i, Q_j)$ s.t. $Q_i \subseteq Q_j$. Are there any equivalent queries? 


$Q_1 \subseteq Q_2$?

Informal reasoning:
* For $Q_1$ path $x \to a \to b \to y$ is of length 3;
* For $Q_2$ path $x \to a \to b \to c \to y$ is of length 4.
* $\Rightarrow$ containment doesn't hold. Let's show that formally.


Formal reasoning:
* $
D_{Q_1} = 
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; C_b \\
  C_b &amp; C_c \\
  C_c &amp; C_y \\
  \hline
\end{array}$
** note that instead of creating a database with the body of $Q_1$, we created constant that correspond to the variables (to avoid confusion)
* Evaluate $Q_2(D_{Q_1})$:
* $Q_2(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, b)}_{(2)}, \underbrace{Q(b, c)}_{(3)}, \underbrace{Q(c, y)}_{(4)}$
* Let's build a candidate substitution. We want this substitution to be a matching.
** First we map the head of $Q_2$ to associated constants: $x \mapsto C_x, y \mapsto C_y$ (because we want $(C_x, C_y)$ be in $Q_2(D_{Q_1})$)
** Then we evaluate (1) atom $Q(x, a)$ and map $a \mapsto C_a$ 
** For (2) we map $b \mapsto C_b$, for (3) $c \mapsto C_y$, but for (4) we cannot find a tuple $(C_y, ?)$ in $D_{Q_2}$ with $C_y$ in the first position. 
** Therefore this substitution is not a matching.
* We have constructed a counter-example $\Rightarrow$ $Q_1 \not \subseteq Q_2$


$Q_2 \subseteq Q_1$?
* $
D_{Q_2} = 
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; C_b \\
  C_b &amp; C_y \\
  \hline
\end{array}$
* Evaluate $Q_1(D_{Q_2})$
* $Q_1(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, b)}_{(2)}, \underbrace{Q(b, y)}_{(3)}$
* For head we map $x \mapsto C_x$, $y \mapsto C_y$, for (1): $a \mapsto C_a$, for (2) $b \mapsto C_b$, for (3) we would have to map $y \mapsto C_c$, but we cannot do it since we already have mapped $y \mapsto C_y$.
* Therefore, this candidate substitution is not a function and $Q_2 \not \subseteq Q_1$


$Q_1 \subseteq Q_3$?
* $
D_{Q_1} = 
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; C_b \\
  C_b &amp; C_c \\
  C_c &amp; C_y \\
  \hline
\end{array}
$
* We evaluate $Q_3(D_{Q_1})$
* $Q_3(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, 1)}_{(2)}, \underbrace{Q(1, b)}_{(3)}, \underbrace{Q(b, y)}_{(4)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) $a \mapsto C_a$, but for (2) there's no tuple $(C_a, 1)$ in $D_{Q_1}$ so we cannot find a matching.
* Therefore $Q_1 \not \subseteq Q_3$


$Q_3 \subseteq Q_1$?
* $
D_{Q_3} =
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; 1 \\
  1 &amp; C_b \\
  C_b &amp; C_y \\
  \hline
\end{array}
$
* We evaluate $Q_1(D_{Q_3})$
* $Q_1(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, b)}_{(2)}, \underbrace{Q(b, y)}_{(3)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) $a \mapsto C_a$, for (2) $b \mapsto C_1$, but for (3) we would have to map $y \mapsto C_b$, and we already established $y \mapsto C_y$
* Therefore $Q_3 \not \subseteq Q_1$


$Q_1 \subseteq Q_4$?
* $
D_{Q_1} = 
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; C_b \\
  C_b &amp; C_c \\
  C_c &amp; C_y \\
  \hline
\end{array}
$
* Evaluate $Q_4(D_{Q_1})$
* $Q_4(x, y) \leftarrow \underbrace{Q(x, y)}_{(1)}, \underbrace{Q(y, x)}_{(2)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, and for (1) we would have to map $y \mapsto C_a$, but we already established $y \mapsto C_y$.
* Therefore $Q_1 \not \subseteq Q_4$


$Q_4 \subseteq Q_1$?
* $
D_{Q_4} =
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_y \\
  C_y &amp; C_x \\
  \hline
\end{array}$
* Evaluate $Q_1(D_{Q_4})$
* $Q_1(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, b)}_{(2)}, \underbrace{Q(b, y)}_{(3)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) $a \mapsto C_y$, for (2) $b \mapsto C_x$ and atom (3) matches tuple $(C_x, C_y)$.
* Our candidate substitution $x \mapsto C_x, y \mapsto C_y, a \mapsto C_y, b \mapsto C_x$ is a matching and therefore $Q_4 \subseteq Q_1$.


$Q_2 \subseteq Q_3$?
* $
D_{Q_2} = 
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; C_b \\
  C_b &amp; C_y \\
  \hline
\end{array}$
* Evaluate $Q_3(D_{Q_2})$
* $Q_3(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, 1)}_{(2)}, \underbrace{Q(1, b)}_{(3)}, \underbrace{Q(b, y)}_{(4)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) $a \mapsto C_a$, but for (2) there's no tuple $(C_a, 1)$ in $D_{Q_2}$, so there's no matching. 
* $\Rightarrow Q_2 \not \subseteq Q_3$


$Q_3 \subseteq Q_2$?
* $
D_{Q_3} =
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; 1 \\
  1 &amp; C_b \\
  C_b &amp; C_y \\
  \hline
\end{array}$
* Evaluate $Q_2(D_{Q_3})$
* $Q_2(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, b)}_{(2)}, \underbrace{Q(b, c)}_{(3)}, \underbrace{Q(c, y)}_{(4)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) $a \mapsto C_a$, for (2), $b \mapsto 1$, for (3) $c \mapsto C_b$, and atom (4) matches tuple $(C_b, C_y)$
* Our candidate substitution $x \mapsto C_x, y \mapsto C_y, a \mapsto C_a, b \mapsto 1, c \mapsto C_b$ is a matching and therefore $Q_3 \subseteq Q_2$.


$Q_2 \subseteq Q_4$?
* $
D_{Q_2} = 
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; C_b \\
  C_b &amp; C_y \\
  \hline
\end{array}$
* Evaluate $Q_4(D_{Q_2})$
* $Q_4(x, y) \leftarrow \underbrace{Q(x, y)}_{(1)}, \underbrace{Q(y, x)}_{(2)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) we would have to map  $y \mapsto C_a$, but we've already established $y \mapsto C_y$.
* $Q_2 \not \subseteq Q_4$


$Q_4 \subseteq Q_2$?
* $
D_{Q_4} =
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_y \\
  C_y &amp; C_x \\
  \hline
\end{array}$
* Evaluate $Q_2(D_{Q_4})$
* $Q_2(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, b)}_{(2)}, \underbrace{Q(b, c)}_{(3)}, \underbrace{Q(c, y)}_{(4)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) $a \mapsto C_y$, for (2) $b \mapsto C_x$, for (3) $c \mapsto C_y$, but for (4) there's no tuple $(C_y, C_y)$ in $D_{Q_4}$.
* Therefore $Q_4 \not \subseteq Q_2$


$Q_3 \subseteq Q_4$?
* $
D_{Q_3} =
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; 1 \\
  1 &amp; C_b \\
  C_b &amp; C_y \\
  \hline
\end{array}$
* Evaluate $Q_4(D_{Q_3})$
* $Q_4(x, y) \leftarrow \underbrace{Q(x, y)}_{(1)}, \underbrace{Q(y, x)}_{(2)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) we would have to map  $y \mapsto C_a$, but we've already established $y \mapsto C_y$.
* $Q_3 \not \subseteq Q_4$


$Q_4 \subseteq Q_3$?
* $
D_{Q_4} =
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_y \\
  C_y &amp; C_x \\
  \hline
\end{array}$
* Evaluate $Q_3(D_{Q_4})$
* $Q_3(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, 1)}_{(2)}, \underbrace{Q(1, b)}_{(3)}, \underbrace{Q(b, y)}_{(4)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) $a \mapsto C_y$, but for (2) there's no tuple $(C_y, 1)$ in $D_{Q_4}$.
* $Q_4 \not \subseteq Q_3$


'''Recap''':  $Q_4 \subseteq Q_1$, $Q_3 \subseteq Q_2$, no equivalent queries 


== See Also ==
* [[Conjunctive Query]]

== Sources ==
* [[Database Systems Architecture (ULB)]]
* Database Systems Architecture lecture notes #2 by S. Vansummeren [https://dl.dropboxusercontent.com/sh/r0zvy3zaycbevx8/U0XnqCSwGZ/lect2-notes-conjunctive.pdf]


[[Category:Exercises]]
[[Category:Relational Databases]]</text>
      <sha1>srsebnjteuvks314oh9pzhjd877aiyy</sha1>
    </revision>
    <revision>
      <id>687</id>
      <parentid>397</parentid>
      <timestamp>2015-11-23T12:38:15Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7740">== Exercises ==
These are exercises for containment of [[Conjunctive Query|Conjunctive Queries]]


=== Exercise 1 ===
Given the queries 
* $Q_1(x, y) \leftarrow Q(x, a), Q(a, b), Q(b, y)$
* $Q_2(x, y) \leftarrow Q(x, a), Q(a, b), Q(b, c), Q(c, y)$
* $Q_3(x, y) \leftarrow Q(x, a), Q(a, 1), Q(1, b), Q(b, y)$
* $Q_4(x, y) \leftarrow Q(x, y), Q(y, x)$

Find all pairs $(Q_i, Q_j)$ s.t. $Q_i \subseteq Q_j$. Are there any equivalent queries? 


$Q_1 \subseteq Q_2$?

Informal reasoning:
* For $Q_1$ path $x \to a \to b \to y$ is of length 3;
* For $Q_2$ path $x \to a \to b \to c \to y$ is of length 4.
* $\Rightarrow$ containment doesn't hold. Let's show that formally.


Formal reasoning:
* &lt;math&gt;
D_{Q_1} = 
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; C_b \\
  C_b &amp; C_c \\
  C_c &amp; C_y \\
  \hline
\end{array}&lt;/math&gt;
** note that instead of creating a database with the body of $Q_1$, we created constant that correspond to the variables (to avoid confusion)
* Evaluate $Q_2(D_{Q_1})$:
* $Q_2(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, b)}_{(2)}, \underbrace{Q(b, c)}_{(3)}, \underbrace{Q(c, y)}_{(4)}$
* Let's build a candidate substitution. We want this substitution to be a matching.
** First we map the head of $Q_2$ to associated constants: $x \mapsto C_x, y \mapsto C_y$ (because we want $(C_x, C_y)$ be in $Q_2(D_{Q_1})$)
** Then we evaluate (1) atom $Q(x, a)$ and map $a \mapsto C_a$ 
** For (2) we map $b \mapsto C_b$, for (3) $c \mapsto C_y$, but for (4) we cannot find a tuple $(C_y, ?)$ in $D_{Q_2}$ with $C_y$ in the first position. 
** Therefore this substitution is not a matching.
* We have constructed a counter-example $\Rightarrow$ $Q_1 \not \subseteq Q_2$


$Q_2 \subseteq Q_1$?
* &lt;math&gt;
D_{Q_2} = 
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; C_b \\
  C_b &amp; C_y \\
  \hline
\end{array}&lt;/math&gt;
* Evaluate $Q_1(D_{Q_2})$
* $Q_1(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, b)}_{(2)}, \underbrace{Q(b, y)}_{(3)}$
* For head we map $x \mapsto C_x$, $y \mapsto C_y$, for (1): $a \mapsto C_a$, for (2) $b \mapsto C_b$, for (3) we would have to map $y \mapsto C_c$, but we cannot do it since we already have mapped $y \mapsto C_y$.
* Therefore, this candidate substitution is not a function and $Q_2 \not \subseteq Q_1$


$Q_1 \subseteq Q_3$?
* &lt;math&gt;
D_{Q_1} = 
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; C_b \\
  C_b &amp; C_c \\
  C_c &amp; C_y \\
  \hline
\end{array}&lt;/math&gt;
* We evaluate $Q_3(D_{Q_1})$
* $Q_3(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, 1)}_{(2)}, \underbrace{Q(1, b)}_{(3)}, \underbrace{Q(b, y)}_{(4)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) $a \mapsto C_a$, but for (2) there's no tuple $(C_a, 1)$ in $D_{Q_1}$ so we cannot find a matching.
* Therefore $Q_1 \not \subseteq Q_3$


$Q_3 \subseteq Q_1$?
* &lt;math&gt;
D_{Q_3} =
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; 1 \\
  1 &amp; C_b \\
  C_b &amp; C_y \\
  \hline
\end{array}&lt;/math&gt;
* We evaluate $Q_1(D_{Q_3})$
* $Q_1(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, b)}_{(2)}, \underbrace{Q(b, y)}_{(3)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) $a \mapsto C_a$, for (2) $b \mapsto C_1$, but for (3) we would have to map $y \mapsto C_b$, and we already established $y \mapsto C_y$
* Therefore $Q_3 \not \subseteq Q_1$


$Q_1 \subseteq Q_4$?
* &lt;math&gt;
D_{Q_1} = 
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; C_b \\
  C_b &amp; C_c \\
  C_c &amp; C_y \\
  \hline
\end{array}&lt;/math&gt;
* Evaluate $Q_4(D_{Q_1})$
* $Q_4(x, y) \leftarrow \underbrace{Q(x, y)}_{(1)}, \underbrace{Q(y, x)}_{(2)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, and for (1) we would have to map $y \mapsto C_a$, but we already established $y \mapsto C_y$.
* Therefore $Q_1 \not \subseteq Q_4$


$Q_4 \subseteq Q_1$?
* &lt;math&gt;D_{Q_4} =
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_y \\
  C_y &amp; C_x \\
  \hline
\end{array}&lt;/math&gt;
* Evaluate $Q_1(D_{Q_4})$
* $Q_1(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, b)}_{(2)}, \underbrace{Q(b, y)}_{(3)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) $a \mapsto C_y$, for (2) $b \mapsto C_x$ and atom (3) matches tuple $(C_x, C_y)$.
* Our candidate substitution $x \mapsto C_x, y \mapsto C_y, a \mapsto C_y, b \mapsto C_x$ is a matching and therefore $Q_4 \subseteq Q_1$.


$Q_2 \subseteq Q_3$?
* &lt;math&gt;D_{Q_2} = 
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; C_b \\
  C_b &amp; C_y \\
  \hline
\end{array}&lt;/math&gt;
* Evaluate $Q_3(D_{Q_2})$
* $Q_3(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, 1)}_{(2)}, \underbrace{Q(1, b)}_{(3)}, \underbrace{Q(b, y)}_{(4)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) $a \mapsto C_a$, but for (2) there's no tuple $(C_a, 1)$ in $D_{Q_2}$, so there's no matching. 
* $\Rightarrow Q_2 \not \subseteq Q_3$


$Q_3 \subseteq Q_2$?
* &lt;math&gt;D_{Q_3} =
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; 1 \\
  1 &amp; C_b \\
  C_b &amp; C_y \\
  \hline
\end{array}&lt;/math&gt;
* Evaluate $Q_2(D_{Q_3})$
* $Q_2(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, b)}_{(2)}, \underbrace{Q(b, c)}_{(3)}, \underbrace{Q(c, y)}_{(4)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) $a \mapsto C_a$, for (2), $b \mapsto 1$, for (3) $c \mapsto C_b$, and atom (4) matches tuple $(C_b, C_y)$
* Our candidate substitution $x \mapsto C_x, y \mapsto C_y, a \mapsto C_a, b \mapsto 1, c \mapsto C_b$ is a matching and therefore $Q_3 \subseteq Q_2$.


$Q_2 \subseteq Q_4$?
* &lt;math&gt;D_{Q_2} = 
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; C_b \\
  C_b &amp; C_y \\
  \hline
\end{array}&lt;/math&gt;
* Evaluate $Q_4(D_{Q_2})$
* $Q_4(x, y) \leftarrow \underbrace{Q(x, y)}_{(1)}, \underbrace{Q(y, x)}_{(2)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) we would have to map  $y \mapsto C_a$, but we've already established $y \mapsto C_y$.
* $Q_2 \not \subseteq Q_4$


$Q_4 \subseteq Q_2$?
* &lt;math&gt;D_{Q_4} =
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_y \\
  C_y &amp; C_x \\
  \hline
\end{array}&lt;/math&gt;
* Evaluate $Q_2(D_{Q_4})$
* $Q_2(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, b)}_{(2)}, \underbrace{Q(b, c)}_{(3)}, \underbrace{Q(c, y)}_{(4)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) $a \mapsto C_y$, for (2) $b \mapsto C_x$, for (3) $c \mapsto C_y$, but for (4) there's no tuple $(C_y, C_y)$ in $D_{Q_4}$.
* Therefore $Q_4 \not \subseteq Q_2$


$Q_3 \subseteq Q_4$?
* &lt;math&gt;D_{Q_3} =
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_a \\
  C_a &amp; 1 \\
  1 &amp; C_b \\
  C_b &amp; C_y \\
  \hline
\end{array}&lt;/math&gt;
* Evaluate $Q_4(D_{Q_3})$
* $Q_4(x, y) \leftarrow \underbrace{Q(x, y)}_{(1)}, \underbrace{Q(y, x)}_{(2)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) we would have to map  $y \mapsto C_a$, but we've already established $y \mapsto C_y$.
* $Q_3 \not \subseteq Q_4$


$Q_4 \subseteq Q_3$?
* &lt;math&gt;D_{Q_4} =
\begin{array}{ | l l | }
  \hline
  C_x &amp; C_y \\
  C_y &amp; C_x \\
  \hline
\end{array}&lt;/math&gt;
* Evaluate $Q_3(D_{Q_4})$
* $Q_3(x, y) \leftarrow \underbrace{Q(x, a)}_{(1)}, \underbrace{Q(a, 1)}_{(2)}, \underbrace{Q(1, b)}_{(3)}, \underbrace{Q(b, y)}_{(4)}$
* For head we have $x \mapsto C_x$, $y \mapsto C_y$, for (1) $a \mapsto C_y$, but for (2) there's no tuple $(C_y, 1)$ in $D_{Q_4}$.
* $Q_4 \not \subseteq Q_3$


'''Recap''':  $Q_4 \subseteq Q_1$, $Q_3 \subseteq Q_2$, no equivalent queries 


== See Also ==
* [[Conjunctive Query]]

== Sources ==
* [[Database Systems Architecture (ULB)]]
* Database Systems Architecture lecture notes #2 by S. Vansummeren [https://dl.dropboxusercontent.com/sh/r0zvy3zaycbevx8/U0XnqCSwGZ/lect2-notes-conjunctive.pdf]


[[Category:Exercises]]
[[Category:Relational Databases]]</text>
      <sha1>nfreo3qbzgd2x89oxtm6h4ix2hjy845</sha1>
    </revision>
  </page>
  <page>
    <title>Data Integration</title>
    <ns>0</ns>
    <id>395</id>
    <revision>
      <id>398</id>
      <timestamp>2014-05-09T19:48:39Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1259">== Data Integration ==
Goal of Data Integration - provide uniform access to heterogeneous data sources in some domain. 


== Main approaches ==
=== [[Data Warehousing]] ===
* data from all data sources are federated into one main warehouse (using [[ETL]]s)
* the queries are issued to this federated storage
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/architecture-dwh.png


=== [[Mediator (Data Integration)|Mediator]] ===
* data remains in the data sources 
* sometimes called &quot;virtual data integration&quot;
* better for the Web - there are many DBs, and we would like to find something, no matter what DB provides it
** so it can be a preferred approach for [[OBDA|Ontology Based Data Access]]
* also better if you want to access &quot;fresh&quot; data
* but way harder to implement - need to transform data during the query time 
** need to use [[Ontologies]] for that, no [[ETL]]s
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/architecture-mediator.png


== See Also ==
* [[Data Transformation]]
* [[ETL]]
* [[Data Warehousing]]

== Links ==
* http://en.wikipedia.org/wiki/Data_integration

== Source ==
* Web Data Management book [http://webdam.inria.fr/Jorge]

[[Category:Data Integration]]</text>
      <sha1>gktd462lelqrcm27vvh0l8zx60bhj94</sha1>
    </revision>
    <revision>
      <id>692</id>
      <parentid>398</parentid>
      <timestamp>2015-11-23T12:44:52Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1255">== Data Integration ==
Goal of Data Integration - provide uniform access to heterogeneous data sources in some domain. 


== Main approaches ==
=== [[Data Warehousing]] ===
* data from all data sources are federated into one main warehouse (using [[ETL]]s)
* the queries are issued to this federated storage
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/architecture-dwh.png


=== [[Mediator (Data Integration)|Mediator]] ===
* data remains in the data sources 
* sometimes called &quot;virtual data integration&quot;
* better for the Web - there are many DBs, and we would like to find something, no matter what DB provides it
** so it can be a preferred approach for [[Ontology Based Data Access]]
* also better if you want to access &quot;fresh&quot; data
* but way harder to implement - need to transform data during the query time 
** need to use [[Ontologies]] for that, no [[ETL]]s
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/architecture-mediator.png


== See Also ==
* [[Data Transformation]]
* [[ETL]]
* [[Data Warehousing]]

== Links ==
* http://en.wikipedia.org/wiki/Data_integration

== Source ==
* [[Web Data Management (book)]]

[[Category:Semantic Web]]
[[Category:Data Integration]]</text>
      <sha1>5olvohll8yfs9uyu6e18oi48dnr4ggq</sha1>
    </revision>
  </page>
  <page>
    <title>GAV Mediation</title>
    <ns>0</ns>
    <id>396</id>
    <revision>
      <id>399</id>
      <timestamp>2014-05-04T10:10:59Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4831">== GAV Mediation ==
There are two main approached for [[Mediator (Data Integration)|Mediating]] in [[Data Integration]] 
* [[GAV Mediation]] - defining global relations in terms of local
* [[LAV Mediation]] - defining local relations in terms of global


GAV - Global-as-View Mediation
* global is constrained by views of the local relations
* See some notation in [[Mediator (Data Integration)]]


== GAV Mapping ==
A GAV mapping is an expression of the form 
* $R(x_1, ..., x_n) \supseteq Q(x_1, ..., x_n)$
* where $Q(x_1, ..., x_n)$ is a [[Conjunctive Query]] of the same arity as $R$
* since $Q(x_1, ..., x_n) \leftarrow A_1(...), \ ..., \ A_k(...)$, can rewrite as $R(x_1, ..., x_n) \supseteq A_1(...), \ ..., \ A_k(...)$
* so a mapping is some query over some source relations, also called a ''view''


[[First Order Logic|FOL]] Semantics of this mapping
* $\forall \ x_1, ..., x_n \ \exists \ y_1, ..., y_m \ : \ A_1(...), \ ..., \ A_k(...) \Rightarrow R(x_1, ..., x_n)$
* $x_1, ..., x_n$ - distinguished variables,
* $y_1, ..., y_n$ - existential variables


=== GAV Mapping Example ===
Data sources:
* S1.Catalogue(nomUniv, programme). - programs in French universities
* S2.Erasmus(student, course, univ). - European Erasmus students 
* S3.CampusFr(student, program, university). - foreign students in France
* S4.Mundus(program, course). - international master programs

Global Schema:
* MasterStudent(studentName), 
* University(uniName),
* MasterProgram(title), 
* MasterCourse(code),
* EnrolledIn(studentName,title), 
* RegisteredTo(studentName, uniName).


The GAV mapping for the global schema is the following
* MasterStudent(N) $\supseteq$ S2.Erasmus(N, C, U), S4.Mundus(P, C)
* MasterStudent(N) $\supseteq$ S3.CampusFr(N, P, U), S4.Mundus(P, C)
* University(U) $\supseteq$ S1.Catalogue(U, P)
* University(U) $\supseteq$ S2.Erasmus(N, C, U)
* University(U) $\supseteq$ S3.CampusFr(N, P, U)
* MasterProgram(T) $\supseteq$ S4.Mundus(T, C)
* MasterCourse(C) $\supseteq$ S4.Mundus(T, C)
* EnrolledIn(N, T) $\supseteq$ S2.Erasmus(N, C, U), S4.Mundus(T, C)
* EnrolledIn(N, T) $\supseteq$ S3.CampusFr(N, T, U), S4.Mundus(T, C)
* RegisteredTo(N, U) $\supseteq$ S3.CampusFr(N, T, U)
* left side: global; right side: local



== Query Answering ==
To evaluate a query
* for answering some query against the global schema, need to find the relevant data sources 
* then we issue queries for each data source and combine the result


'''GAV Unfolding''' (informal)
* for each atom $A_i(...)$ of the query
* if this atom can be matched to a head of some mapping $R_j(...)$
* replace the atom $A_i(...)$ by the body of the mapping $R_j(...)$


=== Illustration ===
Illustration by example
* Consider this query:
* $Q(x) \leftarrow \underbrace{\text{RegistersTo}(s, x)}_\text{(1)}, \underbrace{\text{MasterStudent}(s)}_\text{(2)}$
* for $\text{(1)}$, one mapping can be found, for $\text{(2)}$ - two mappings
* so we can have two unfoldings:
** $Q_1(x) \leftarrow S_3.\text{CampusFr}(s,v_1,x), S_2.\text{Erasmus}(s,v_2,v_3), S_4.\text{Mundus}(v_4,v_2)$
** $Q_2(x) \leftarrow S_3.\text{CampusFr}(s,v_5,x), S_3.\text{CampusFr}(s,v_6,v_7), S_4.\text{Mundus}(v_6,v_8)$
* note that $Q_2$ can be simplified (by removing a redundant join)
** so we have the following two rewritings:
** $R_1(x) \leftarrow S_3.\text{CampusFr}(s,v_1,x), S_2.\text{Erasmus}(s,v_2,v_3), S_4.\text{Mundus}(v_4,v_2)$
** $R_2(x) \leftarrow S_3.\text{CampusFr}(s,v_6,v_7), S_4.\text{Mundus}(v_6,v_8)$
* the final result: $R_1(x) \cup R_2(x)$


=== GAV Unfolding ===
'''def''': ''GAV Query unfolding'' (or ''GAV rewriting'')
* let $Q(\vec{x}) \leftarrow G_1(\vec{z}_1), \ ..., \ G_n(\vec{z}_n)$ be a query over global schema 
* $\forall \ G_i \ \exists$ GAV mapping $G_i \supseteq q_i(\vec{x}_i, \vec{y}_i)$
** where in $q_i(\vec{x}, \vec{y})$: $\vec{x}$ - distinguished variables, $\vec{y}$ - existential  
* ''an unfolding'' of $Q(\vec{x})$ is a query $U$ that is obtained by
* replacing each conjunct $G_i(\vec{z}_i)$ by $q_i \big( \Psi_i(\vec{x}, \vec{y}) \big)$
* $\Psi_i(\vec{x}, \vec{y})$ maps 
** variables $\vec{x}$ of $q_i$ to $\vec{z}$ and 
** existential variables $\vec{y}$ to some new variables (needed to avoid naming conflicts - and therefore unnecessary constraints)


Simplification
* each unfolding then simplified (redundant joins/conjuncts are removed)
* and obtain rewritings


== Main Limitations of GAV Mediation ==
* Adding and removing data sources is costly 
** it may require revising all the mappings 
* for Web, servers may come and go 
* so another approach is needed
* thus, for [[Semantic Web]], [[LAV Mediation]] is more preferred


== See Also ==
* [[Data Integration]]
* [[Mediator (Data Integration)]]
* [[LAV Mediation]]

== Source ==
* Web Data Management book [http://webdam.inria.fr/Jorge]

[[Category:Data Integration]]</text>
      <sha1>1r0x1kq7nqxuwgejumixyrmika1gzll</sha1>
    </revision>
    <revision>
      <id>695</id>
      <parentid>399</parentid>
      <timestamp>2015-11-23T12:47:30Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>/* Source */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4806">== GAV Mediation ==
There are two main approached for [[Mediator (Data Integration)|Mediating]] in [[Data Integration]] 
* [[GAV Mediation]] - defining global relations in terms of local
* [[LAV Mediation]] - defining local relations in terms of global


GAV - Global-as-View Mediation
* global is constrained by views of the local relations
* See some notation in [[Mediator (Data Integration)]]


== GAV Mapping ==
A GAV mapping is an expression of the form 
* $R(x_1, ..., x_n) \supseteq Q(x_1, ..., x_n)$
* where $Q(x_1, ..., x_n)$ is a [[Conjunctive Query]] of the same arity as $R$
* since $Q(x_1, ..., x_n) \leftarrow A_1(...), \ ..., \ A_k(...)$, can rewrite as $R(x_1, ..., x_n) \supseteq A_1(...), \ ..., \ A_k(...)$
* so a mapping is some query over some source relations, also called a ''view''


[[First Order Logic|FOL]] Semantics of this mapping
* $\forall \ x_1, ..., x_n \ \exists \ y_1, ..., y_m \ : \ A_1(...), \ ..., \ A_k(...) \Rightarrow R(x_1, ..., x_n)$
* $x_1, ..., x_n$ - distinguished variables,
* $y_1, ..., y_n$ - existential variables


=== GAV Mapping Example ===
Data sources:
* S1.Catalogue(nomUniv, programme). - programs in French universities
* S2.Erasmus(student, course, univ). - European Erasmus students 
* S3.CampusFr(student, program, university). - foreign students in France
* S4.Mundus(program, course). - international master programs

Global Schema:
* MasterStudent(studentName), 
* University(uniName),
* MasterProgram(title), 
* MasterCourse(code),
* EnrolledIn(studentName,title), 
* RegisteredTo(studentName, uniName).


The GAV mapping for the global schema is the following
* MasterStudent(N) $\supseteq$ S2.Erasmus(N, C, U), S4.Mundus(P, C)
* MasterStudent(N) $\supseteq$ S3.CampusFr(N, P, U), S4.Mundus(P, C)
* University(U) $\supseteq$ S1.Catalogue(U, P)
* University(U) $\supseteq$ S2.Erasmus(N, C, U)
* University(U) $\supseteq$ S3.CampusFr(N, P, U)
* MasterProgram(T) $\supseteq$ S4.Mundus(T, C)
* MasterCourse(C) $\supseteq$ S4.Mundus(T, C)
* EnrolledIn(N, T) $\supseteq$ S2.Erasmus(N, C, U), S4.Mundus(T, C)
* EnrolledIn(N, T) $\supseteq$ S3.CampusFr(N, T, U), S4.Mundus(T, C)
* RegisteredTo(N, U) $\supseteq$ S3.CampusFr(N, T, U)
* left side: global; right side: local



== Query Answering ==
To evaluate a query
* for answering some query against the global schema, need to find the relevant data sources 
* then we issue queries for each data source and combine the result


'''GAV Unfolding''' (informal)
* for each atom $A_i(...)$ of the query
* if this atom can be matched to a head of some mapping $R_j(...)$
* replace the atom $A_i(...)$ by the body of the mapping $R_j(...)$


=== Illustration ===
Illustration by example
* Consider this query:
* $Q(x) \leftarrow \underbrace{\text{RegistersTo}(s, x)}_\text{(1)}, \underbrace{\text{MasterStudent}(s)}_\text{(2)}$
* for $\text{(1)}$, one mapping can be found, for $\text{(2)}$ - two mappings
* so we can have two unfoldings:
** $Q_1(x) \leftarrow S_3.\text{CampusFr}(s,v_1,x), S_2.\text{Erasmus}(s,v_2,v_3), S_4.\text{Mundus}(v_4,v_2)$
** $Q_2(x) \leftarrow S_3.\text{CampusFr}(s,v_5,x), S_3.\text{CampusFr}(s,v_6,v_7), S_4.\text{Mundus}(v_6,v_8)$
* note that $Q_2$ can be simplified (by removing a redundant join)
** so we have the following two rewritings:
** $R_1(x) \leftarrow S_3.\text{CampusFr}(s,v_1,x), S_2.\text{Erasmus}(s,v_2,v_3), S_4.\text{Mundus}(v_4,v_2)$
** $R_2(x) \leftarrow S_3.\text{CampusFr}(s,v_6,v_7), S_4.\text{Mundus}(v_6,v_8)$
* the final result: $R_1(x) \cup R_2(x)$


=== GAV Unfolding ===
'''def''': ''GAV Query unfolding'' (or ''GAV rewriting'')
* let $Q(\vec{x}) \leftarrow G_1(\vec{z}_1), \ ..., \ G_n(\vec{z}_n)$ be a query over global schema 
* $\forall \ G_i \ \exists$ GAV mapping $G_i \supseteq q_i(\vec{x}_i, \vec{y}_i)$
** where in $q_i(\vec{x}, \vec{y})$: $\vec{x}$ - distinguished variables, $\vec{y}$ - existential  
* ''an unfolding'' of $Q(\vec{x})$ is a query $U$ that is obtained by
* replacing each conjunct $G_i(\vec{z}_i)$ by $q_i \big( \Psi_i(\vec{x}, \vec{y}) \big)$
* $\Psi_i(\vec{x}, \vec{y})$ maps 
** variables $\vec{x}$ of $q_i$ to $\vec{z}$ and 
** existential variables $\vec{y}$ to some new variables (needed to avoid naming conflicts - and therefore unnecessary constraints)


Simplification
* each unfolding then simplified (redundant joins/conjuncts are removed)
* and obtain rewritings


== Main Limitations of GAV Mediation ==
* Adding and removing data sources is costly 
** it may require revising all the mappings 
* for Web, servers may come and go 
* so another approach is needed
* thus, for [[Semantic Web]], [[LAV Mediation]] is more preferred


== See Also ==
* [[Data Integration]]
* [[Mediator (Data Integration)]]
* [[LAV Mediation]]

== Source ==
* [[Web Data Management (book)]]

[[Category:Data Integration]]</text>
      <sha1>5t9oputqtudpkbjcrpj6cyv9bmb1dtu</sha1>
    </revision>
  </page>
  <page>
    <title>Mediator (Data Integration)</title>
    <ns>0</ns>
    <id>397</id>
    <revision>
      <id>400</id>
      <timestamp>2014-05-04T19:57:03Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3164">== Mediator ==
This is an approach to [[Data Integration]] (opposite to [[Data Warehousing]])
* data remains in the data sources (so it's sometimes called &quot;virtual data integration&quot;)
* also better if you want to access &quot;fresh&quot; data
* but way harder to implement - need to transform data during the query time 
** need to use [[Ontologies]] for that, no [[ETL]]s
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/architecture-mediator.png


=== Architecture ===
Global Schema
* start by designing a global (''mediated'') schema - an unique entry point for all the queries 
* need to have semantic mappings between the mediated schema and data sources


Querying:
* user queries the global schema
* based on the mappings, queries are converted to local queries for the data sources 
* all queries are executed
* then the results are combined (e.g. using some [[Ontologies]] - which is why this approach is useful for [[OBDA]])


== Semantic Mapping ==
Let $S_1, ..., S_n$ be ''local schemas''
* assume that each $S_i$ has only one relation, also denoted $S_i$
* these $S_1, ..., S_n$ are ''local relations''

''Global schema'' $G$ 
* consists of ''global relations'' $G_1, ..., G_m$

Goal of ''Semantic Mappings'':
* specify ''mappings'' between $\{ S_i \}$ and $\{ G_i \}$ - relationships between local and global schemas
* examples of such relationships:
** $G_1 \equiv S_1$ - equality
** $G_2 \equiv S_1 \cup S_2$
** $G_3 \equiv S_1 \Join S_3$
* so global $G_j$ can be seen as &lt;u&gt;views&lt;/u&gt; of local relationships (example of [[GAV Mediation]])


But better to use containment instead of equality
* to be able to express the usage of multiple sources
* example ([[GAV Mediation]])
** $G_3 \supseteq S_1 \Join S_3$
** $G_3 \supseteq \sigma_{A = \text{yes}} ( S_4 )$
* example ([[LAV Mediation]])
** $S_4 \subseteq G_1 \Join G_3$


Notation
* $v(S_1, ..., S_n)$ - local view (a view/query built on local schemas)
* $v(G_1, ..., G_m)$ - global view (on global schemas)


== Mediation Approaches ==
=== [[GAV Mediation]] - Global-as-View ===
global is constrained by views of the local relations

GAV are mappings of the following form
* $v_i(S_1, ..., S_n) \subseteq G_i$
* or, equivalently, $G_i \supseteq v_i(S_1, ..., S_n)$


=== [[LAV Mediation]] - Local-as-View ===
* contribution of each data source $S_i$ is specified independently of other data source 
* typical for [[Semantic Web]] based systems 

GAV are mappings of the following form
* $S_i \subseteq v_i(G_1, ..., G_m)$


Main algorithms for query rewriting in LAV Meditation:
* [[Bucket Algorithm (Data Integration)|Bucket Algorithm]]
* [[Minicon Algorithm]]
* [[Inverse-Rules Algorithm]]

Discussion
* all these algorithms have the same complexity
* but in experiments (from the book) show that Minicon outperforms others
* no algorithm handles additional knowledge (ontologies)


Ontology Based Data Access
* Typically LAV is used along with [[OBDA]]
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/semantic-web-data-access.png


== Sources ==
* Web Data Management book [http://webdam.inria.fr/Jorge]

[[Category:Data Integration]]</text>
      <sha1>7so0xezrtanmqs1r7hcurhhcbwsd6hs</sha1>
    </revision>
    <revision>
      <id>694</id>
      <parentid>400</parentid>
      <timestamp>2015-11-23T12:46:49Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3139">== Mediator ==
This is an approach to [[Data Integration]] (opposite to [[Data Warehousing]])
* data remains in the data sources (so it's sometimes called &quot;virtual data integration&quot;)
* also better if you want to access &quot;fresh&quot; data
* but way harder to implement - need to transform data during the query time 
** need to use [[Ontologies]] for that, no [[ETL]]s
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/architecture-mediator.png


=== Architecture ===
Global Schema
* start by designing a global (''mediated'') schema - an unique entry point for all the queries 
* need to have semantic mappings between the mediated schema and data sources


Querying:
* user queries the global schema
* based on the mappings, queries are converted to local queries for the data sources 
* all queries are executed
* then the results are combined (e.g. using some [[Ontologies]] - which is why this approach is useful for [[OBDA]])


== Semantic Mapping ==
Let $S_1, ..., S_n$ be ''local schemas''
* assume that each $S_i$ has only one relation, also denoted $S_i$
* these $S_1, ..., S_n$ are ''local relations''

''Global schema'' $G$ 
* consists of ''global relations'' $G_1, ..., G_m$

Goal of ''Semantic Mappings'':
* specify ''mappings'' between $\{ S_i \}$ and $\{ G_i \}$ - relationships between local and global schemas
* examples of such relationships:
** $G_1 \equiv S_1$ - equality
** $G_2 \equiv S_1 \cup S_2$
** $G_3 \equiv S_1 \Join S_3$
* so global $G_j$ can be seen as &lt;u&gt;views&lt;/u&gt; of local relationships (example of [[GAV Mediation]])


But better to use containment instead of equality
* to be able to express the usage of multiple sources
* example ([[GAV Mediation]])
** $G_3 \supseteq S_1 \Join S_3$
** $G_3 \supseteq \sigma_{A = \text{yes}} ( S_4 )$
* example ([[LAV Mediation]])
** $S_4 \subseteq G_1 \Join G_3$


Notation
* $v(S_1, ..., S_n)$ - local view (a view/query built on local schemas)
* $v(G_1, ..., G_m)$ - global view (on global schemas)


== Mediation Approaches ==
=== [[GAV Mediation]] - Global-as-View ===
global is constrained by views of the local relations

GAV are mappings of the following form
* $v_i(S_1, ..., S_n) \subseteq G_i$
* or, equivalently, $G_i \supseteq v_i(S_1, ..., S_n)$


=== [[LAV Mediation]] - Local-as-View ===
* contribution of each data source $S_i$ is specified independently of other data source 
* typical for [[Semantic Web]] based systems 

GAV are mappings of the following form
* $S_i \subseteq v_i(G_1, ..., G_m)$


Main algorithms for query rewriting in LAV Meditation:
* [[Bucket Algorithm (Data Integration)|Bucket Algorithm]]
* [[Minicon Algorithm]]
* [[Inverse-Rules Algorithm]]

Discussion
* all these algorithms have the same complexity
* but in experiments (from the book) show that Minicon outperforms others
* no algorithm handles additional knowledge (ontologies)


Ontology Based Data Access
* Typically LAV is used along with [[OBDA]]
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/semantic-web-data-access.png


== Sources ==
* [[Web Data Management (book)]]

[[Category:Data Integration]]</text>
      <sha1>8u9r6hcxnosx4keuwx6v1eylwz5glnq</sha1>
    </revision>
  </page>
  <page>
    <title>LAV Mediation</title>
    <ns>0</ns>
    <id>398</id>
    <revision>
      <id>401</id>
      <timestamp>2014-05-04T20:02:38Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3603">== LAV Mediation ==
There are two main approached for [[Mediator (Data Integration)|Mediating]] in [[Data Integration]] 
* [[GAV Mediation]] - defining global relations in terms of local
* [[LAV Mediation]] - defining local relations in terms of global


LAV - Local-as-View Mediation
* local relations are defined as views (queries) over global relations
* goal: define the global schema in such a way that individual definitions don't change when new data sources are added or old are removed 
* See some notation in [[Mediator (Data Integration)]]


== LAV Mapping ==
''LAV Mapping ''
* mapping $S \subseteq Q$ for some [[Conjunctive Query]] $Q(\vec{x}) \leftarrow A_1(\vec{u}_1), \ ..., \ A_k(\vec{u}_k)$ over the global relations 
* this gives loose-coupling between global and local schemas


[[First Order Logic|FOL]] Semantics:
* $\forall x_1, ..., x_n  \Big[ S(x_1, ..., x_n) \Rightarrow \exists \ y_1, ..., y_m \ : \ A_1(\vec{u}_1) \ \land \ ... \ \land \ A_k(\vec{u}_k) \Big]$
* $S(x_1, ..., x_n)$ - head of a view
* $y_1, ..., y_m$ - existential variables
* $A_1(\vec{u}_1) \ \land \ ... \ \land \ A_k(\vec{u}_k)$ - body


=== Example ===
Suppose we have this global schema
* Student(studentName), 
* EuropeanStudent(studentName),
* University(uniName), 
* NonEuropeanStudent(studentName),
* FrenchUniversity(uniName), 
* EuropeanUniversity(uniName),
* NonEuropeanUniversity(uniName), 
* Program(title),
* MasterProgram(title), 
* EnrolledInProgram(studentName, title),
* Course(code), 
* EnrolledInCourse(studentName, code),
* PartOf(code, title), 
* RegisteredTo(studentName, uniName),
* OfferedBy(title, uniName).


Data sources from the previous examples
* S1.Catalogue(nomUniv, programme). - programs in French universities
* S2.Erasmus(student, course, univ). - European Erasmus students 
* S3.CampusFr(student, program, university). - foreign students in France
* S4.Mundus(program, course). - international master programs


LAV Mappings:
* $m_1$: S1.Catalogue(U, P) $\subseteq$ FrenchUniversity(U), Program(P), OfferedBy(P, U), OfferedBy(P', U), MasterProgram(P')
* $m_2$: S2.Erasmus(S, C, U) $\subseteq$ Student(S), EnrolledInCourse(S, C), PartOf(C, P), OfferedBy(P, U), EuropeanUniversity(U), EuropeanUniversity(U') RegisteredTo(S, U'), U $\neq$ U'
* $m_3$: S3.CampusFr(S, P, U) $\subseteq$ NonEuropeanStudent(S), Program(P), EnrolledInProgram(S, P), OfferedBy(P, U), FrenchUniversity(U), RegisteredTo(S, U) 
* $m_4$: S4.Mundus(P, C) $\subseteq$ MasterProgram(P), OfferedBy(P, U), OfferedBy(P, U'), EuropeanUniversity(U), NonEuropeanUniversity(U'), PartOf(C, P)


So,
* LAV mapping can be seen as a description of the data source in terms of the global schema
* for example, Erasmus students ($m_2$) are
** European students
** enrolled in an European university
** that European university is different from their home university
** they remain registered in their home university

Loose-Coupling
* This gives loose-coupling between local and global relations 
* which is important when participating data sources change frequently 


== Query Answering ==
suppose we're interested in Master students 
* define the following query
* $\text{MasterStudent}(E) \leftarrow \text{Student}(E), \text{EnrolledInProgram}(E, M), \text{MasterProgram}(M).$
* how to find which data sources to query?
* rewriting process is more complex, than for GAV

Algorithms to do that
* [[Bucket Algorithm (Data Integration)|Bucket Algorithm]]
* [[Minicon Algorithm]]
* [[Inverse-Rules Algorithm]]


== Sources ==
* Web Data Management book [http://webdam.inria.fr/Jorge]

[[Category:Data Integration]]</text>
      <sha1>8nva18181ysnlt6mhdn0avfdpf5gl81</sha1>
    </revision>
    <revision>
      <id>696</id>
      <parentid>401</parentid>
      <timestamp>2015-11-23T12:48:01Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>/* Sources */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3578">== LAV Mediation ==
There are two main approached for [[Mediator (Data Integration)|Mediating]] in [[Data Integration]] 
* [[GAV Mediation]] - defining global relations in terms of local
* [[LAV Mediation]] - defining local relations in terms of global


LAV - Local-as-View Mediation
* local relations are defined as views (queries) over global relations
* goal: define the global schema in such a way that individual definitions don't change when new data sources are added or old are removed 
* See some notation in [[Mediator (Data Integration)]]


== LAV Mapping ==
''LAV Mapping ''
* mapping $S \subseteq Q$ for some [[Conjunctive Query]] $Q(\vec{x}) \leftarrow A_1(\vec{u}_1), \ ..., \ A_k(\vec{u}_k)$ over the global relations 
* this gives loose-coupling between global and local schemas


[[First Order Logic|FOL]] Semantics:
* $\forall x_1, ..., x_n  \Big[ S(x_1, ..., x_n) \Rightarrow \exists \ y_1, ..., y_m \ : \ A_1(\vec{u}_1) \ \land \ ... \ \land \ A_k(\vec{u}_k) \Big]$
* $S(x_1, ..., x_n)$ - head of a view
* $y_1, ..., y_m$ - existential variables
* $A_1(\vec{u}_1) \ \land \ ... \ \land \ A_k(\vec{u}_k)$ - body


=== Example ===
Suppose we have this global schema
* Student(studentName), 
* EuropeanStudent(studentName),
* University(uniName), 
* NonEuropeanStudent(studentName),
* FrenchUniversity(uniName), 
* EuropeanUniversity(uniName),
* NonEuropeanUniversity(uniName), 
* Program(title),
* MasterProgram(title), 
* EnrolledInProgram(studentName, title),
* Course(code), 
* EnrolledInCourse(studentName, code),
* PartOf(code, title), 
* RegisteredTo(studentName, uniName),
* OfferedBy(title, uniName).


Data sources from the previous examples
* S1.Catalogue(nomUniv, programme). - programs in French universities
* S2.Erasmus(student, course, univ). - European Erasmus students 
* S3.CampusFr(student, program, university). - foreign students in France
* S4.Mundus(program, course). - international master programs


LAV Mappings:
* $m_1$: S1.Catalogue(U, P) $\subseteq$ FrenchUniversity(U), Program(P), OfferedBy(P, U), OfferedBy(P', U), MasterProgram(P')
* $m_2$: S2.Erasmus(S, C, U) $\subseteq$ Student(S), EnrolledInCourse(S, C), PartOf(C, P), OfferedBy(P, U), EuropeanUniversity(U), EuropeanUniversity(U') RegisteredTo(S, U'), U $\neq$ U'
* $m_3$: S3.CampusFr(S, P, U) $\subseteq$ NonEuropeanStudent(S), Program(P), EnrolledInProgram(S, P), OfferedBy(P, U), FrenchUniversity(U), RegisteredTo(S, U) 
* $m_4$: S4.Mundus(P, C) $\subseteq$ MasterProgram(P), OfferedBy(P, U), OfferedBy(P, U'), EuropeanUniversity(U), NonEuropeanUniversity(U'), PartOf(C, P)


So,
* LAV mapping can be seen as a description of the data source in terms of the global schema
* for example, Erasmus students ($m_2$) are
** European students
** enrolled in an European university
** that European university is different from their home university
** they remain registered in their home university

Loose-Coupling
* This gives loose-coupling between local and global relations 
* which is important when participating data sources change frequently 


== Query Answering ==
suppose we're interested in Master students 
* define the following query
* $\text{MasterStudent}(E) \leftarrow \text{Student}(E), \text{EnrolledInProgram}(E, M), \text{MasterProgram}(M).$
* how to find which data sources to query?
* rewriting process is more complex, than for GAV

Algorithms to do that
* [[Bucket Algorithm (Data Integration)|Bucket Algorithm]]
* [[Minicon Algorithm]]
* [[Inverse-Rules Algorithm]]


== Sources ==
* [[Web Data Management (book)]]

[[Category:Data Integration]]</text>
      <sha1>0kcqa3pmtyj33i2kpy411by2r0mvpvg</sha1>
    </revision>
  </page>
  <page>
    <title>Bucket Algorithm (Data Integration)</title>
    <ns>0</ns>
    <id>399</id>
    <revision>
      <id>402</id>
      <timestamp>2014-05-04T20:15:59Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8760">== Bucket Algorithm ==
This is an approach for query rewriting used in [[LAV Mediation]]

=== Overview ===
3 steps
* determine local relations relevant to the query:
** for each atom $G$ from the body of the global query $Q$ 
** construct it's bucket - which groups the view atoms from which $G$ can be inferred
* create candidate rewritings - by combining atoms within the same bucket
* verification step
** for each candidate, check if it's valid


== Bucket Creation ==
* let $G$ be a query atom 
* all atoms in $\text{bucket}(G)$ are
** heads of mappings that have some atom $G^*$ in their bodies
** s.t. $G$ can be inferred from $G^*$ (i.e. matched)

A atom $G$ of global query $Q$ is ''satisfied by local data'' if
* $G$ can be matched to an atom $R_j$ in the body of some mapping $M_i$ and
* the head of this mapping $M_i$ can be matched to the fact from the data sources

A matching between $G$ and atom $R_j$ of some mapping $M_i$ says
* that the corresponding data source $S_i$ provides relevant information for query $Q$


Need some extra constraints to guarantee that $G$ can be logically inferred:
* the $\text{Bucket}(G)$ contains a view atom $V$ only if 
* and atom in the body of $V$ can be matched with $G$ by a variable mapping s.t.
* the variables mapped to the distinguished variables of $G$ are also distinguished variables in that view $V$ that defined the mapping


=== Bucket Creation Example ===
Consider this LAV mapping:
* $M_1$: S1.Catalogue(U, P) $\subseteq$ FrenchUniversity(U), Program(P), OfferedBy(P, U), OfferedBy(P', U), MasterProgram(P')
* $M_2$: S2.Erasmus(S, C, U) $\subseteq$ Student(S), EnrolledInCourse(S, C), PartOf(C, P), OfferedBy(P, U), EuropeanUniversity(U), EuropeanUniversity(U') RegisteredTo(S, U'), U $\neq$ U'
* $M_3$: S3.CampusFr(S, P, U) $\subseteq$ NonEuropeanStudent(S), Program(P), EnrolledInProgram(S, P), OfferedBy(P, U), FrenchUniversity(U), RegisteredTo(S, U) 
* $M_4$: S4.Mundus(P, C) $\subseteq$ MasterProgram(P), OfferedBy(P, U), OfferedBy(P, U'), EuropeanUniversity(U), NonEuropeanUniversity(U'), PartOf(C, P)


Global Query:

$Q(x) \leftarrow \underbrace{\text{RegisteredTo}(s, x)}_\text{(1)}, \underbrace{\text{EnrolledInProgram}(s, p)}_\text{(2)}, \underbrace{\text{MasterProgram}(p)}_\text{(3)}.$

Consider an atom $G \equiv (1)$
* variable $x$ is distinguished here
* we can find two mappings $M_2$ and $M_3$: some body atom in them can be matched with $G$


For example, $M_3$ 
* $G$ matches to $\text{RegisteredTo}(S, U)$
** mapping is $S \mapsto s, U \mapsto x$
** $U$ is distinguished in $M_3$
** therefore, applying this mapping to the head of $M_3$ enforces the matching of $G$ and $\text{RegisteredTo}(S, U)$
** $P$ is not present there, so mapping it to some fresh variable $v_1$: $P \mapsto v_1$
* so, $S_3.\text{CampusFr}(s, v_1, x) \ \land \ \text{FOL}(M_3) \vDash \ \exists s: \text{RegisteredTo}(s, x) $
** where
** $\text{FOL}(M_3)$ logical meaning of $M_3$ (in the [[First Order Logic]] form)
** $\vDash$ means &quot;enforces&quot;
* and $S_3.\text{CampusFr}(s, v_1, x)$ is added to $\text{Bucket}(G)$
** note mapping $P \mapsto v_1$ in $S_3.\text{CampusFr}(S, P, U)$


Consider mapping $M_2$
* match between $G \equiv (1)$ and $\text{RegisteredTo}(S, U')$
* mapping $S \mapsto s, U' \mapsto x$
* but $U'$ is qualified existentially in this view
* i.e. this mapping doesn't enforce matching of $G$ and $\text{RegisteredTo}(S, U')$
* so, $S_2.\text{Erasmus}(s, v_2, v_3) \ \land \ \text{FOL}(M_2) \not \vDash \exists \ s : \text{RegisteredTo}(s, x)$


why?
* $\text{FOL}(M_2) \equiv \forall S, C, U \ \Big[ S_2.\text{Erasmus}(S, C, U) \ \Rightarrow \ \exists \ P, U' \ : \ \text{EuropeanStudent}(S)$ $\ \land \ \text{EnrolledInCourse}(S,C) \ \land \
\text{PartOf}(C,P)$ $\ \land \ \text{OfferedBy}(P,U)
\ \land \ \text{EuropeanUniversity}(U)$ $\ \land \ \text{RegisteredTo}(S, U') \ \land \ U \neq U' \Big]$
* so, from fact $S_2.\text{Erasmus}(s, v_2, v_3)$ it follows that $\exists \ s, U' \ : \ \text{RegisteredTo}(s,U')$
* $\exists \ s \ : \ \text{RegisteredTo}(s, x)$, where $x$ is fixed is strictly weaker
* but it can't be satisfied, so  $\exists \ s, U' \ : \ \text{RegisteredTo}(s,U')$ also isn't


=== Bucket Algorithm ===
Bucket($G$, $Q$, $M$):
* Input: 
** An atom $G(u_1, ... , u_m)$ of the query $G$ 
** a set of LAV mappings $M$
* Output: 
** The set of view atoms from which $G$ can be inferred
* $\text{Bucket}(G) \leftarrow \varnothing$
* for each LAV mapping $S(\vec{x}) \subseteq Q(\vec{x}, \vec{y})$ from $M$
** if $\exists$ atom $G(z_1, ..., z_m) \in Q(\vec{x}, \vec{y})$ s.t. 
*** $\forall z_i: z_i \mapsto u_i$ and $z_i$ is distinguished in $G$ and $u_i$ is distinguished in $Q$
** let $\Psi$ be the mapping $\forall z_i: z_i \mapsto u_i$
*** extend $\Psi$ by mapping the head variables $x_i \in \vec{x}$ s.t. $x_i \not \in \{ z_1, ..., z_m \}$ to new fresh variables:
*** $\forall x_i \in \vec{x} \ \land \ x_i \not \in \{ z_1, ..., z_m \} \ : \ x_i \mapsto v_k $ where $k$ is some counter
** add $S \big( \Psi(\vec{x}) \big)$ to $\text{Bucket}(G)$:
*** $\text{Bucket}(G) \leftarrow \text{Bucket}(G) \cup S \big( \Psi(\vec{x}) \big)$
* return $\text{Bucket}(G)$


Theorem: 
* let $G(u_1, ..., u_m) \in Q$ be an atom of the query $Q$ 
* let $\vec{u}$ be a (possible empty) set of existential variables from $\{ u_1, ..., u_m \}$
* let $m$ be a LAV mapping $S(\vec{x}) \subseteq Q(\vec{x}, \vec{y})$
* then
* $S(\vec{v}), \text{FOL}(m) \ \vDash \ \exists \ \vec{u} \ : \ G(u_1, ..., u_m)$ iff
* $\exists H \in \text{Bucket}(G)$ s.t. $H \equiv S(\vec{x})$ up to renaming fresh variables


Example
* query $Q(x) \leftarrow \underbrace{\text{RegisteredTo}(s, x)}_\text{(1)}, \underbrace{\text{EnrolledInProgram}(s, p)}_\text{(2)}, \underbrace{\text{MasterProgram}(p)}_\text{(3)}.$
* the following buckets are obtained
*# for $\text{RegisteredTo}(s, x) \ (1)$
*#* $S_3.\text{CampusFr}(s, v_1, x)$
*# for $\text{EnrolledInProgram}(s, p) \ (2)$
*#* $S_3.\text{CampusFr}(s, p, v_2)$
*# for $\text{MasterProgram}(p) \ (3)$
*#* $S_1.\text{Catalogue}(v_3, v_4)$
*#* $S_4.\text{Mundus}(p, v_5)$


== Constructing Candidate Rewritings ==
Obtain candidates 
* by combining the view atoms to each bucket

=== Validation ===
* it's possible that a candidate is not a valid rewriting of a query
* by the Thm we know only that 
** each candidate rewriting entails each atom of the query &lt;u&gt;in isolation&lt;/u&gt;
** i.e. without taking into account the possible bindings of existential variables within the query


''Expanding'' a rewriting $R$: 
* for each atom $A$ from the body of rewriting $R$ 
** replace $A$ by the corresponding LAV mapping for $A$ 
** new existential variables are introduced - to avoid naming conflicts
* the result - the expansion of $R$: $\text{Exp} \big[ R(...) \big]$


Validation Algo:
* for a rewriting $R$ find $\text{Exp} \big[ R(...) \big]$
* check for containment: $\text{Exp} \big[ R(...) \big] \subseteq Q(...)$ where $Q$ is the global query (see [[Conjunctive Query#Containement|CQ Containment]])
* if $\text{Exp} \big[ R(...) \big] \subseteq Q(...)$, then $R$ is a valid rewriting


=== Validation Example ===
We obtained these rewritings:
* $r_1(x) \leftarrow S_3.\text{CampusFr}(s,v_1,x), S_3.\text{CampusFr}(s,p,v_2), S_1.\text{Catalogue}(v_3,v_4)$
* $r_2(x) \leftarrow S_3.\text{CampusFr}(s,v_1,x), S_3.\text{CampusFr}(s,p,v_2), S_4.\text{Mundus}(p,v_5)$


Validation
* $r_1$ is not a valid rewriting of $Q$
* expand $r_1$:
** $
\begin{array}{l l}
\text{Exp} \big[ r_1(x) \big] \leftarrow &amp; \text{NonEuropeanStudent}(s), \text{Program}(v_1), \\
&amp; \text{EnrolledInProgram}(s,v_1), \text{OfferedBy}(v_1,x), \\
&amp; \text{FrenchUniversity}(x), \text{RegisteredTo}(s,x), \\
&amp; \text{Program}(p), \text{EnrolledInProgram}(s,p), \\
&amp; \text{OfferedBy}(p,v_2), \text{FrenchUniversity}(v_2), \\
&amp; \text{RegisteredTo}(s,v_2), \text{FrenchUniversity}(v_3), \\
&amp; \text{Program}(v_4), \text{OfferedBy}(v_4,v_3), \\
&amp; \text{OfferedBy}(v_5,v_3), \text{MasterProgram}(v_5) \\
\end{array}
$
* Now check the containment:
* the following is the canonical database $D_{r_1(x)}$ for $\text{Exp} \big[ r_1(x) \big]$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/lav-bucket-validation-candb.png
* evaluation of $Q$ on this canonical database is empty: $Q\big( D_{r_1(x)} \big) \equiv \varnothing$ 
** no way to assign variables $s$ and $p$ 
* so it's not a valid rewriting
* but $r_2$ is a valid rewriting


== Final Result ==
The final result is
* the union of all valid rewritings



== See Also ==
* [[Data Integration]]
* [[Mediator (Data Integration)]]
* [[GAV Mediation]]
* [[Minicon Algorithm]]
* [[Inverse-Rules Algorithm]]

== Sources ==
* Web Data Management book [http://webdam.inria.fr/Jorge]

[[Category:Data Integration]]</text>
      <sha1>8b1jnvni5xti1u66n6p0ex6rw1xug51</sha1>
    </revision>
    <revision>
      <id>697</id>
      <parentid>402</parentid>
      <timestamp>2015-11-23T13:10:05Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8776">== Bucket Algorithm ==
This is an approach for query rewriting used in [[LAV Mediation]]

=== Overview ===
3 steps
* determine local relations relevant to the query:
** for each atom $G$ from the body of the global query $Q$ 
** construct it's bucket - which groups the view atoms from which $G$ can be inferred
* create candidate rewritings - by combining atoms within the same bucket
* verification step
** for each candidate, check if it's valid


== Bucket Creation ==
* let $G$ be a query atom 
* all atoms in $\text{bucket}(G)$ are
** heads of mappings that have some atom $G^*$ in their bodies
** s.t. $G$ can be inferred from $G^*$ (i.e. matched)

A atom $G$ of global query $Q$ is ''satisfied by local data'' if
* $G$ can be matched to an atom $R_j$ in the body of some mapping $M_i$ and
* the head of this mapping $M_i$ can be matched to the fact from the data sources

A matching between $G$ and atom $R_j$ of some mapping $M_i$ says
* that the corresponding data source $S_i$ provides relevant information for query $Q$


Need some extra constraints to guarantee that $G$ can be logically inferred:
* the $\text{Bucket}(G)$ contains a view atom $V$ only if 
* and atom in the body of $V$ can be matched with $G$ by a variable mapping s.t.
* the variables mapped to the distinguished variables of $G$ are also distinguished variables in that view $V$ that defined the mapping


=== Bucket Creation Example ===
Consider this LAV mapping:
* $M_1$: S1.Catalogue(U, P) $\subseteq$ FrenchUniversity(U), Program(P), OfferedBy(P, U), OfferedBy(P', U), MasterProgram(P')
* $M_2$: S2.Erasmus(S, C, U) $\subseteq$ Student(S), EnrolledInCourse(S, C), PartOf(C, P), OfferedBy(P, U), EuropeanUniversity(U), EuropeanUniversity(U') RegisteredTo(S, U'), U $\neq$ U'
* $M_3$: S3.CampusFr(S, P, U) $\subseteq$ NonEuropeanStudent(S), Program(P), EnrolledInProgram(S, P), OfferedBy(P, U), FrenchUniversity(U), RegisteredTo(S, U) 
* $M_4$: S4.Mundus(P, C) $\subseteq$ MasterProgram(P), OfferedBy(P, U), OfferedBy(P, U'), EuropeanUniversity(U), NonEuropeanUniversity(U'), PartOf(C, P)


Global Query:

$Q(x) \leftarrow \underbrace{\text{RegisteredTo}(s, x)}_\text{(1)}, \underbrace{\text{EnrolledInProgram}(s, p)}_\text{(2)}, \underbrace{\text{MasterProgram}(p)}_\text{(3)}.$

Consider an atom $G \equiv (1)$
* variable $x$ is distinguished here
* we can find two mappings $M_2$ and $M_3$: some body atom in them can be matched with $G$


For example, $M_3$ 
* $G$ matches to $\text{RegisteredTo}(S, U)$
** mapping is $S \mapsto s, U \mapsto x$
** $U$ is distinguished in $M_3$
** therefore, applying this mapping to the head of $M_3$ enforces the matching of $G$ and $\text{RegisteredTo}(S, U)$
** $P$ is not present there, so mapping it to some fresh variable $v_1$: $P \mapsto v_1$
* so, $S_3.\text{CampusFr}(s, v_1, x) \ \land \ \text{FOL}(M_3) \vDash \ \exists s: \text{RegisteredTo}(s, x) $
** where
** $\text{FOL}(M_3)$ logical meaning of $M_3$ (in the [[First Order Logic]] form)
** $\vDash$ means &quot;enforces&quot;
* and $S_3.\text{CampusFr}(s, v_1, x)$ is added to $\text{Bucket}(G)$
** note mapping $P \mapsto v_1$ in $S_3.\text{CampusFr}(S, P, U)$


Consider mapping $M_2$
* match between $G \equiv (1)$ and $\text{RegisteredTo}(S, U')$
* mapping $S \mapsto s, U' \mapsto x$
* but $U'$ is qualified existentially in this view
* i.e. this mapping doesn't enforce matching of $G$ and $\text{RegisteredTo}(S, U')$
* so, $S_2.\text{Erasmus}(s, v_2, v_3) \ \land \ \text{FOL}(M_2) \not \vDash \exists \ s : \text{RegisteredTo}(s, x)$


why?
* &lt;math&gt;\text{FOL}(M_2) \equiv \forall S, C, U \ \Big[ S_2.\text{Erasmus}(S, C, U) \ \Rightarrow \ \exists \ P, U' \ : \ \text{EuropeanStudent}(S)&lt;/math&gt; &lt;math&gt;\ \land \ \text{EnrolledInCourse}(S,C) \ \land \
\text{PartOf}(C,P)&lt;/math&gt; &lt;math&gt;\ \land \ \text{OfferedBy}(P,U)
\ \land \ \text{EuropeanUniversity}(U)$ $\ \land \ \text{RegisteredTo}(S, U') \ \land \ U \neq U' \Big]&lt;/math&gt;
* so, from fact $S_2.\text{Erasmus}(s, v_2, v_3)$ it follows that $\exists \ s, U' \ : \ \text{RegisteredTo}(s,U')$
* $\exists \ s \ : \ \text{RegisteredTo}(s, x)$, where $x$ is fixed is strictly weaker
* but it can't be satisfied, so  $\exists \ s, U' \ : \ \text{RegisteredTo}(s,U')$ also isn't


=== Bucket Algorithm ===
Bucket($G$, $Q$, $M$):
* Input: 
** An atom $G(u_1, ... , u_m)$ of the query $G$ 
** a set of LAV mappings $M$
* Output: 
** The set of view atoms from which $G$ can be inferred
* $\text{Bucket}(G) \leftarrow \varnothing$
* for each LAV mapping $S(\vec{x}) \subseteq Q(\vec{x}, \vec{y})$ from $M$
** if $\exists$ atom $G(z_1, ..., z_m) \in Q(\vec{x}, \vec{y})$ s.t. 
*** $\forall z_i: z_i \mapsto u_i$ and $z_i$ is distinguished in $G$ and $u_i$ is distinguished in $Q$
** let $\Psi$ be the mapping $\forall z_i: z_i \mapsto u_i$
*** extend $\Psi$ by mapping the head variables $x_i \in \vec{x}$ s.t. $x_i \not \in \{ z_1, ..., z_m \}$ to new fresh variables:
*** $\forall x_i \in \vec{x} \ \land \ x_i \not \in \{ z_1, ..., z_m \} \ : \ x_i \mapsto v_k $ where $k$ is some counter
** add $S \big( \Psi(\vec{x}) \big)$ to $\text{Bucket}(G)$:
*** $\text{Bucket}(G) \leftarrow \text{Bucket}(G) \cup S \big( \Psi(\vec{x}) \big)$
* return $\text{Bucket}(G)$


Theorem: 
* let $G(u_1, ..., u_m) \in Q$ be an atom of the query $Q$ 
* let $\vec{u}$ be a (possible empty) set of existential variables from $\{ u_1, ..., u_m \}$
* let $m$ be a LAV mapping $S(\vec{x}) \subseteq Q(\vec{x}, \vec{y})$
* then
* $S(\vec{v}), \text{FOL}(m) \ \vDash \ \exists \ \vec{u} \ : \ G(u_1, ..., u_m)$ iff
* $\exists H \in \text{Bucket}(G)$ s.t. $H \equiv S(\vec{x})$ up to renaming fresh variables


Example
* query $Q(x) \leftarrow \underbrace{\text{RegisteredTo}(s, x)}_\text{(1)}, \underbrace{\text{EnrolledInProgram}(s, p)}_\text{(2)}, \underbrace{\text{MasterProgram}(p)}_\text{(3)}.$
* the following buckets are obtained
*# for $\text{RegisteredTo}(s, x) \ (1)$
*#* $S_3.\text{CampusFr}(s, v_1, x)$
*# for $\text{EnrolledInProgram}(s, p) \ (2)$
*#* $S_3.\text{CampusFr}(s, p, v_2)$
*# for $\text{MasterProgram}(p) \ (3)$
*#* $S_1.\text{Catalogue}(v_3, v_4)$
*#* $S_4.\text{Mundus}(p, v_5)$


== Constructing Candidate Rewritings ==
Obtain candidates 
* by combining the view atoms to each bucket

=== Validation ===
* it's possible that a candidate is not a valid rewriting of a query
* by the Thm we know only that 
** each candidate rewriting entails each atom of the query &lt;u&gt;in isolation&lt;/u&gt;
** i.e. without taking into account the possible bindings of existential variables within the query


''Expanding'' a rewriting $R$: 
* for each atom $A$ from the body of rewriting $R$ 
** replace $A$ by the corresponding LAV mapping for $A$ 
** new existential variables are introduced - to avoid naming conflicts
* the result - the expansion of $R$: $\text{Exp} \big[ R(...) \big]$


Validation Algo:
* for a rewriting $R$ find $\text{Exp} \big[ R(...) \big]$
* check for containment: $\text{Exp} \big[ R(...) \big] \subseteq Q(...)$ where $Q$ is the global query (see [[Conjunctive Query#Containement|CQ Containment]])
* if $\text{Exp} \big[ R(...) \big] \subseteq Q(...)$, then $R$ is a valid rewriting


=== Validation Example ===
We obtained these rewritings:
* $r_1(x) \leftarrow S_3.\text{CampusFr}(s,v_1,x), S_3.\text{CampusFr}(s,p,v_2), S_1.\text{Catalogue}(v_3,v_4)$
* $r_2(x) \leftarrow S_3.\text{CampusFr}(s,v_1,x), S_3.\text{CampusFr}(s,p,v_2), S_4.\text{Mundus}(p,v_5)$


Validation
* $r_1$ is not a valid rewriting of $Q$
* expand $r_1$:
** &lt;math&gt;\begin{array}{l l}
\text{Exp} \big[ r_1(x) \big] \leftarrow &amp; \text{NonEuropeanStudent}(s), \text{Program}(v_1), \\
&amp; \text{EnrolledInProgram}(s,v_1), \text{OfferedBy}(v_1,x), \\
&amp; \text{FrenchUniversity}(x), \text{RegisteredTo}(s,x), \\
&amp; \text{Program}(p), \text{EnrolledInProgram}(s,p), \\
&amp; \text{OfferedBy}(p,v_2), \text{FrenchUniversity}(v_2), \\
&amp; \text{RegisteredTo}(s,v_2), \text{FrenchUniversity}(v_3), \\
&amp; \text{Program}(v_4), \text{OfferedBy}(v_4,v_3), \\
&amp; \text{OfferedBy}(v_5,v_3), \text{MasterProgram}(v_5) \\
\end{array}&lt;/math&gt;
* Now check the containment:
* the following is the canonical database $D_{r_1(x)}$ for $\text{Exp} \big[ r_1(x) \big]$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/lav-bucket-validation-candb.png
* evaluation of $Q$ on this canonical database is empty: $Q\big( D_{r_1(x)} \big) \equiv \varnothing$ 
** no way to assign variables $s$ and $p$ 
* so it's not a valid rewriting
* but $r_2$ is a valid rewriting


== Final Result ==
The final result is
* the union of all valid rewritings


== See Also ==
* [[Data Integration]]
* [[Mediator (Data Integration)]]
* [[GAV Mediation]]
* [[Minicon Algorithm]]
* [[Inverse-Rules Algorithm]]

== Sources ==
* [[Web Data Management (book)]]

[[Category:Data Integration]]</text>
      <sha1>doicezfgr3r58py0oesjeqmyncxqa5e</sha1>
    </revision>
  </page>
  <page>
    <title>Minicon Algorithm</title>
    <ns>0</ns>
    <id>400</id>
    <revision>
      <id>403</id>
      <timestamp>2014-05-04T20:19:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3992">== Minicon Algorithm ==
This is an approach for query rewriting used in [[LAV Mediation]]

=== Overview ===
An optimized version of the [[Bucket Algorithm (Data Integration)|Bucket Algorithm]]
* avoids the last step: verification
* idea: not to put atoms that will generate invalid rewritings 
* an atom can be useless if its binding of variables doesn't match the bindings of other occurrences of this variable
** recall ([[Bucket Algorithm (Data Integration)#Validation Example]] - this is the reason why $r_1$ didn't validate)


So, steps are
* creating MCDs (corresponds to the Bucket creation step)
* combining MCDs (the second step)
* where MCDs are ''Minicon Descriptions'' - instead of buckets


=== Example ===
The algorithm will be explained by this example

Consider this global query
* $Q(x) \leftarrow U(y,z), R(x,z), T(z,y), R(y',x)$


And two LAV mappings
* $V_1(u,v) \subseteq T(w,u), U(v,w), R(v,u)$
* $V_2(u,v,v') \subseteq T(w,u), U(v,w), R(v',w)$


== Step 1: Creating MCDs ==
In this step
* for each atom $A_i$ of the query $Q$
* for each LAV mapping $V_i$ 
* determine the relevance of $V_i$ w.r.t. rewriting $A_i$ 


=== Illustration of Step 1 ===
Consider first atom $U(y, z)$ of $Q$:


Vs [[Bucket Algorithm (Data Integration)|Bucket]]:
* Bucket would put $V_1(v_1, y)$ to $\text{Bucket} \Big( U(y, z) \Big)$
* because we have mapping $v \mapsto y, w \mapsto z \ \ (*)$
* $(*)$ allows the match between atom $U(y, z)$ and atom $U(v, w)$ from the body of $V_1(v_1, y)$ 

But here we don't consider $U(v, w) \in V_1(v_1, y)$ in isolation
* since $w$ there is existential and $w \mapsto z$
** need to check that $(*)$ covers all &lt;u&gt;query&lt;/u&gt; atoms ($\in Q$) that involve $z$
* i.e. also need to check query atoms $R(x, {\color{blue}{z}})$ and $T({\color{blue}{z}}, y)$
* it's the only way to enforce that all occurrences of $z$ are mapped to the same variable $w$

For this example ($U(y, z)$ vs $V_1(u, v)$)
* can we map $R(x, z) \in Q \mapsto R(_, w) \in V_1$? (i.e. try to expand $(*)$)
* no we can't: there doesn't exist such atom in $V_1$
* so no MCD is created from $V_1$


Now try to match $U(y, z)$ with $V_2(u, v, v')$
* we can match $U(y, z) \in Q$ to $U(v, w) \in V_2(u, v, v')$
* mapping is $v \mapsto y, w \mapsto z \ \ (**)$
* ${\color{blue}{z}}$ is existential, so check query atoms $R(x, {\color{blue}{z}})$ and $T({\color{blue}{z}}, y)$
** $R(v', w) \mapsto R(x, {\color{blue}{z}})$ by adding $v' \mapsto x$
** $T(w, u)  \mapsto T({\color{blue}{z}}, y)$ by adding $u \mapsto y$
* so an MCD is created for $V_2(u, v, v')$ 
* $\text{MCD}_1 = \Big( V_2(u, v, v'), \{1,2,3\} \Big)$
** we also write the positions of the query atoms that this MCD covers ($\{1,2,3\}$) 
* since $\text{MCD}_1$ covers $\{1,2,3\}$, only atoms in $\{4\}$ remain uncovered, so need to cover them


Consider 4th query atom $R(y', x)$
* for $V_1$ we match with atom $R(v, u)$
** mapping $v \mapsto y', u \mapsto x$
** $x$ is a distinguished variable in $Q$, and $u$ is a distinguished variable in $V_1$ 
** existential variable $y'$ has only single occurrence, so we can add it
* so we have the following MCD:
** $\text{MCD}_2 = \Big(  V_1(x, y'), \{ 4 \} \Big)$
* for $R(v', w) \in V_2$ no MCD is created
** mapping $v' \mapsto y', w \mapsto x$
** but $w$ is existential in $V_2$, and $x$ is distinguished in $Q$
** so no MCD



== Step 2: Combining MCDs ==
Combining step
* At this step we combine MCDs that cover mutually disjoint subsets of the atoms of query $Q$
** (these subsets should together cover the entire $Q$)
* this way we obtain rewritings of the query $Q$ 
* the rewriting are guaranteed to be valid - so no checking 

So, a rewriting for $Q(x)$ is 
* $R(x) \leftarrow V_2(y, y, x), V_1(x, y')$


== See Also ==
* [[Data Integration]]
* [[Mediator (Data Integration)]]
* [[GAV Mediation]]
* [[Bucket Algorithm (Data Integration)]]
* [[Inverse-Rules Algorithm]]


== Sources ==
* Web Data Management book [http://webdam.inria.fr/Jorge]

[[Category:Data Integration]]</text>
      <sha1>hm2fouelylfczst3slc0g8eczmkuyqj</sha1>
    </revision>
    <revision>
      <id>698</id>
      <parentid>403</parentid>
      <timestamp>2015-11-23T13:10:33Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>/* Sources */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3967">== Minicon Algorithm ==
This is an approach for query rewriting used in [[LAV Mediation]]

=== Overview ===
An optimized version of the [[Bucket Algorithm (Data Integration)|Bucket Algorithm]]
* avoids the last step: verification
* idea: not to put atoms that will generate invalid rewritings 
* an atom can be useless if its binding of variables doesn't match the bindings of other occurrences of this variable
** recall ([[Bucket Algorithm (Data Integration)#Validation Example]] - this is the reason why $r_1$ didn't validate)


So, steps are
* creating MCDs (corresponds to the Bucket creation step)
* combining MCDs (the second step)
* where MCDs are ''Minicon Descriptions'' - instead of buckets


=== Example ===
The algorithm will be explained by this example

Consider this global query
* $Q(x) \leftarrow U(y,z), R(x,z), T(z,y), R(y',x)$


And two LAV mappings
* $V_1(u,v) \subseteq T(w,u), U(v,w), R(v,u)$
* $V_2(u,v,v') \subseteq T(w,u), U(v,w), R(v',w)$


== Step 1: Creating MCDs ==
In this step
* for each atom $A_i$ of the query $Q$
* for each LAV mapping $V_i$ 
* determine the relevance of $V_i$ w.r.t. rewriting $A_i$ 


=== Illustration of Step 1 ===
Consider first atom $U(y, z)$ of $Q$:


Vs [[Bucket Algorithm (Data Integration)|Bucket]]:
* Bucket would put $V_1(v_1, y)$ to $\text{Bucket} \Big( U(y, z) \Big)$
* because we have mapping $v \mapsto y, w \mapsto z \ \ (*)$
* $(*)$ allows the match between atom $U(y, z)$ and atom $U(v, w)$ from the body of $V_1(v_1, y)$ 

But here we don't consider $U(v, w) \in V_1(v_1, y)$ in isolation
* since $w$ there is existential and $w \mapsto z$
** need to check that $(*)$ covers all &lt;u&gt;query&lt;/u&gt; atoms ($\in Q$) that involve $z$
* i.e. also need to check query atoms $R(x, {\color{blue}{z}})$ and $T({\color{blue}{z}}, y)$
* it's the only way to enforce that all occurrences of $z$ are mapped to the same variable $w$

For this example ($U(y, z)$ vs $V_1(u, v)$)
* can we map $R(x, z) \in Q \mapsto R(_, w) \in V_1$? (i.e. try to expand $(*)$)
* no we can't: there doesn't exist such atom in $V_1$
* so no MCD is created from $V_1$


Now try to match $U(y, z)$ with $V_2(u, v, v')$
* we can match $U(y, z) \in Q$ to $U(v, w) \in V_2(u, v, v')$
* mapping is $v \mapsto y, w \mapsto z \ \ (**)$
* ${\color{blue}{z}}$ is existential, so check query atoms $R(x, {\color{blue}{z}})$ and $T({\color{blue}{z}}, y)$
** $R(v', w) \mapsto R(x, {\color{blue}{z}})$ by adding $v' \mapsto x$
** $T(w, u)  \mapsto T({\color{blue}{z}}, y)$ by adding $u \mapsto y$
* so an MCD is created for $V_2(u, v, v')$ 
* $\text{MCD}_1 = \Big( V_2(u, v, v'), \{1,2,3\} \Big)$
** we also write the positions of the query atoms that this MCD covers ($\{1,2,3\}$) 
* since $\text{MCD}_1$ covers $\{1,2,3\}$, only atoms in $\{4\}$ remain uncovered, so need to cover them


Consider 4th query atom $R(y', x)$
* for $V_1$ we match with atom $R(v, u)$
** mapping $v \mapsto y', u \mapsto x$
** $x$ is a distinguished variable in $Q$, and $u$ is a distinguished variable in $V_1$ 
** existential variable $y'$ has only single occurrence, so we can add it
* so we have the following MCD:
** $\text{MCD}_2 = \Big(  V_1(x, y'), \{ 4 \} \Big)$
* for $R(v', w) \in V_2$ no MCD is created
** mapping $v' \mapsto y', w \mapsto x$
** but $w$ is existential in $V_2$, and $x$ is distinguished in $Q$
** so no MCD



== Step 2: Combining MCDs ==
Combining step
* At this step we combine MCDs that cover mutually disjoint subsets of the atoms of query $Q$
** (these subsets should together cover the entire $Q$)
* this way we obtain rewritings of the query $Q$ 
* the rewriting are guaranteed to be valid - so no checking 

So, a rewriting for $Q(x)$ is 
* $R(x) \leftarrow V_2(y, y, x), V_1(x, y')$


== See Also ==
* [[Data Integration]]
* [[Mediator (Data Integration)]]
* [[GAV Mediation]]
* [[Bucket Algorithm (Data Integration)]]
* [[Inverse-Rules Algorithm]]


== Sources ==
* [[Web Data Management (book)]]

[[Category:Data Integration]]</text>
      <sha1>cxt4nnsnvt0p986vx838fzoxut4wlpv</sha1>
    </revision>
  </page>
  <page>
    <title>Inverse-Rules Algorithm</title>
    <ns>0</ns>
    <id>401</id>
    <revision>
      <id>404</id>
      <timestamp>2014-05-04T20:26:36Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9882">== Inverse-Rules Algorithm ==
This is an approach for query rewriting used in [[LAV Mediation]]
* radically different from [[Bucket Algorithm (Data Integration)|Bucket]] and [[Minicon Algorithm|Minicon]]
* idea: transform [[LAV Mediation|LAV mappings]] to [[GAV Mediation|GAV mappings]] (called ''inverse rules'')
* to do that, use query unfolding instead of query rewriting


=== Overview ===
Steps:
* constructing ''inverse rules'' from a set of LAV mappings
* unfolding a global query to obtain local queries 


Important thing:
* 1st step of the algorithm is independent from queries 
* it only needs to consider a set of LAV mappings 


One LAV Mapping is replaced by several GAV Mappings 
* one for each atom in the body of the rule 
* but need to keep bindings between different occurrences of the same existential variables in the body
* done by using [[First Order Logic]] function - [[Skolem Function]]


=== Illustraction by Example ===
Here we will use the following example to illustrate the algorithm

Global query:
* $Q(x) \leftarrow U(y,z), R(x,z), T(z,y), R(y',x)$

And two LAV mappings:
* $V_1(u,v) \subseteq T(w,u), U(v,w), R(v,u)$
* $V_2(u,v,v') \subseteq T(w,u), U(v,w), R(v',w)$


== [[Skolem Function]] ==
=== Logical Intuition ===
For $V_1$, [[First Order Logic|FOL]] meaning is 
* $\forall \ u, v \Big[ V_1(u, v) \Rightarrow \exists \ w \ : \ T(w, u) \land U(v, w) \land R(v, u)  \Big]$
* suppose a tuple $(a, b)$ belongs to the data source that backs $V_1$
** so we have a fact $V_1(a, b)$
* from this fact $V_1(a, b)$ can infer that $R(b, a)$ 
** $V_1(a, b) \Rightarrow R(b, a)$
** (all conjuncts have to be true for a statement to be true, so it means the last conjuncts holds true)
* so $b$ can be an answer to a global query Q(x) = $R(x, y)$


But we can infer other things as well
* e.g. $V_1(a, b) \Rightarrow \exists \ d_1 \ : \ T(d_1, a) \land U(b, d_1)$ 
* where $d_1$ is some constant
** we don't know its value, but we know it exists (since it's existentially qualified) and 
** it depends on constants $a$ and $b$
* so we can denote this dependency as $d_1 = f_1(a, b)$


[[Skolem Function]]
* the symbol $f_1(u, v)$ is a Skolem Function of arity 2
** $f_1(u, v)$ denotes that there exists some constant that depends on values of $u$ and $v$
* given two distinct Skolem terms, e.g. $f_1(1, 2)$ and $f_1(2, v_3)$ we never can say if they belong to the same constant or not


== Creating Inverse Rules ==
So we can create these GAV mappings and their FOL translations 

=== Example 1 ===
Inverse Rules of the 1st LAV mapping:
* $V_1(u,v) \subseteq T(w,u), U(v,w), R(v,u)$


{| class=&quot;wikitable&quot;
! Rule || Mapping || FOL 
|-
| $\text{IN}_{1,1}$ || $V_1(u,v) \subseteq T \big(f_1(u,v), u \big)$ || $\forall \ u, v \Big[ V_1(u,v) \Rightarrow T \big( f_1(u, v), u \big) \Big]$
|-
| $\text{IN}_{1,2}$ || $V_1(u,v) \subseteq U \big(v, f_1(u,v) \big)$ || $\forall \ u, v \Big[ V_1(u,v) \Rightarrow U \big(v, f_1(u, v) \big) \Big]$
|- 
| $\text{IN}_{1,3}$ || $V_1(u,v) \subseteq R \big(v, u \big)$ || $\forall \ u, v \Big[ V_1(u,v) \Rightarrow R \big(v, u \big) \Big]$
|}



=== Algorithm ===
Algorithm for creating the inverse rules
* for each LAV mapping $M_i$ with $n_i$ atoms 
** create $n_i$ GAV mappings (i.e. inverse rules)
** for each existential variable introduce a Skolem function of all distinguished variables


=== Example 2 ===
For example, for the second mapping the result is 
* mapping: $V_2(u,v,v') \subseteq T(w,u), U(v,w), R(v',w)$
* $\text{IN}_{2,1} \ : \ V_2(u,v,v') \subseteq T \big(f_2(u,v,v'), u \big)$
* $\text{IN}_{2,2} \ : \ V_2(u,v,v') \subseteq U \big(v, f_2(u,v,v') \big)$
* $\text{IN}_{2,3} \ : \ V_2(u,v,v') \subseteq R \big(v', f_2(u,v,v') \big)$

So, for each existentially qualified variable we define some Skolem function
* this is a function of all distinguished variables
* for $V_2$ we define $w = f_2(u,v,v')$


== Step 2: Query Unfolding ==
Query Unfolding
* The process of unfolding query is different from [[GAV Mediation]]
* Reason = Skolem terms


=== GAV vs Inverse-Rules ===
Before (in [[GAV Mediation]])
* for each query atom $G_i(x_1, ..., x_m)$
** match with some GAV mapping atom of the form $G_i(z_1, ..., z_m)$ 
** with mapping $\forall i: \ x_i \mapsto z_i$
* here each atom is unfolded &lt;u&gt;in isolation&lt;/u&gt;
* but here it doesn't work: we have Skolen Functions

Now:
* need ''unification'' of atoms with functions
* more complex than simple unfolding
* may require substitution of some variables with function terms - Skolem terms


=== Unification Algorithm ===
Unification
* let $\sigma$ be an empty set of substitutions
* let $PR$ be a partial rewriting of $Q$, $PR \leftarrow Q$
* For each atom $G_i(...) \in Q$ (in turn)
** unify $G_i \in Q$ with some atom $V_j \subseteq G_i$ from the set of rules
*** backtrack when we have a Skolem term in $V_j$
** $\sigma_i$ - the substitution that made this unification possible
** in $PR$, replace $G_i$ with the head $V_j$ of $G_i$
** apply obtained $\sigma_i$ to the partial rewriting $PR$: $PR \leftarrow \sigma_i(PR)$
** keep all mappings from $\sigma_i$: $\sigma \leftarrow \sigma \cup \sigma_i$ 
* let $R$ be a rewriting of $Q$: $R \leftarrow PR$
* return $R$



=== Example ===
Consider this query
* $Q(x) \leftarrow \underbrace{U(y,z)}_\text{(1)}, \underbrace{R(x,z)}_\text{(2)}, \underbrace{T(z,y)}_\text{(3)}, \underbrace{R(y',x)}_\text{(4)}$


Inverse Rules:
* $\text{IN}_{1,1} \ : \ V_1(u,v)    \subseteq T \big(f_1(u,v), u \big)$
* $\text{IN}_{1,2} \ : \ V_1(u,v)    \subseteq U \big(v, f_1(u,v) \big)$
* $\text{IN}_{1,3} \ : \ V_1(u,v)    \subseteq R \big(v, u \big)$
* $\text{IN}_{2,1} \ : \ V_2(u,v,v') \subseteq T \big(f_2(u,v,v'), u \big)$
* $\text{IN}_{2,2} \ : \ V_2(u,v,v') \subseteq U \big(v, f_2(u,v,v') \big)$
* $\text{IN}_{2,3} \ : \ V_2(u,v,v') \subseteq R \big(v', f_2(u,v,v') \big)$


Now try to unify each atom of $Q$ with some atom from the rules
* we use ''most general unifier'' (''mgu'')


Atom 1: $U(y, z)$
* $U(y, z)$ can be ''unified'' with $U \big(v, f_1(u,v) \big)$ (from $\text{IN}_{1,2}$)
* the mgu is a substitution $\sigma = \{ y \mapsto v_1, v \mapsto v_1, z \mapsto f_1(v_2,v_1), u \mapsto v_2 \}$
* $v_1$ and $v_2$ are new fresh variables to avoid conflicts
* $y$ and $v$ map to the same variable $v_1$ because they are at the same position
* substitution $\sigma$ is called a ''unifier'' of two expressions and $U \big(v, f_1(u,v) \big)$
* it's a unifier because applying $\sigma$ results in identical expressions:
** $\sigma \Big( U(y, z) \Big) \equiv \sigma \Big( U \big(v, f_1(u,v) \big) \Big) \equiv U \big(v_1, f_1(v_2, v_1) \big)$
* apply $\sigma$ to the rest of atoms in $Q$ and unfold the first query atom of $Q$
** the head of $U \big(v, f_1(u,v) \big)$ is $V_1(u,v)$
** because of the substitution $v \mapsto v_1, u \mapsto v_2$ it becomes $V_1 \big( v_2, v_1 \big)$
** the remaining atoms are $R(x,z), T(z,y), R(y',x)$, and by substitution we obtain 
*** $R \big(x, z \big) \to R \big(x, f_1(v_2,v_1) \big)$ 
*** $T \big(z, y \big) \to T \big(f_1(v_2,v_1), v_1 \big)$
*** $R \big(y',x \big) \to R \big(y', x \big)$
* so we have:
** $PR_1(x) \leftarrow  V_1 \big( v_2, v_1 \big), R \big(x, f_1(v_2,v_1) \big), T \big(f_1(v_2,v_1),v_1 \big), R \big(y',x \big).$


Atom 2: $R(x, z) \to R \big(x, f_1(v_2,v_1) \big)$
* (taking into account the substitutions made in previous iterations)
* $R(x,z)$ can be unified with $\ V_1(u,v) \subseteq R \big(v, u \big)$ ($\text{IN}_{1,3}$)
* unfolding of atom $(2)$ gives us the following partial rewriting
** $PR_2(x) \leftarrow  V_1 \big( v_2, v_1 \big), V_1 \big( f_1(v_2,v_1), x \big), T \big(f_1(v_2,v_1), v1 \big), R \big(y', x \big)$
* note that now we have a Skolem term in the matched head
** so it's useless to continue unfolding 
** there's no way to match $V_1 \big( f_1(v_2,v_1), x \big)$ with any fact in our data source 
** because we don't know what is the constant resulting from $f_1(v_2,v_1)$, we know only that it exists
* so, we backtrack to atom 1 


Atom 1: $U(y, z)$
* now try to unfold it using $\text{IN}_{2,2}$
* with substitution 
** $\sigma_1^{(2)} = \{ y \mapsto v_1, v \mapsto v_1, z \mapsto f_2(v_2,v_1,v_3), u \mapsto v_2, v' \mapsto v3  \}$
* using this $\sigma_1^{(2)}$ we obtain the following partial rewriting
* $PR'_1(x) \leftarrow V_2 \big(v_2,v_1,v_3 \big), R \big(x,f_2(v_2,v_1,v_3) \big), T \big(f_2(v_2,v_1,v_3),v_1 \big), R \big(y',x \big)$


Atom 2: $R \big(x, z \big) \to R \big(x, f_2(v_2,v_1,v_3) \big)$ 
* try to use $\text{IN}_{2,3}$
* with substitution
** $\sigma_2^{(2)} = \{ v' \mapsto x, v_3 \mapsto x, u \mapsto v_2, v \mapsto v_1 \}$
* $PR'_2(x) \leftarrow V_2 \big(v_2,v_1,v_3 \big), \underbrace{V_2 \big(v_2,v_1,x \big)}_{\color{blue}{\text{redundant}}}, T \big(f_2(v_2,v_1,v_3),v_1 \big), R \big(y',x \big)$
** $PR'_2(x) \leftarrow V_2 \big(v_2,v_1,v_3 \big), T \big(f_2(v_2,v_1,v_3),v_1 \big), R \big(y',x \big)$


Atom 3: $T(z,y) \to T \big(f_2(u,v,v'),u \big)$
* need to match with $T \big( f_2(v_2,v_1,x), v_1 \big)$ from $\text{IN}_{2,3}$
* substitution $\{ v_2 \mapsto v_3, u \mapsto v_3, v_1 \mapsto v_3, v \mapsto v_3, v' \mapsto x \}$
* so we have this partial rewriting 
** $PR'_3(x) \leftarrow V_2(v_2,v_1,x), V_2(v_3,v_3,x), R(y',x)$
** first atom is redundant, so have $PR'_3(x) \leftarrow  V_2(v_3,v_3,x), R(y',x)$


Atom 4: $R(y',x)$
* match with $R \big(v, u \big)$ from $\text{IN}_{1,3}$
* and have $RP'_4(x) \leftarrow  V_2(v_3,v_3,x), V_1(y', x)$


So, final rewriting 
* $R_1(x) \leftarrow  V_2(v_3,v_3,x), V_1(y', x)$


== Advantages ==
Main advantage
* producing inverse rules is independent from processing queries 



== See Also ==
* [[Data Integration]]
* [[Mediator (Data Integration)]]
* [[GAV Mediation]]
* [[Bucket Algorithm (Data Integration)]]
* [[Minicon Algorithm]]

== Sources ==
* Web Data Management book [http://webdam.inria.fr/Jorge]

[[Category:Data Integration]]</text>
      <sha1>2abnhnhv14apyd2cddsyhqg89edj3p1</sha1>
    </revision>
    <revision>
      <id>699</id>
      <parentid>404</parentid>
      <timestamp>2015-11-23T13:11:02Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>/* Sources */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9857">== Inverse-Rules Algorithm ==
This is an approach for query rewriting used in [[LAV Mediation]]
* radically different from [[Bucket Algorithm (Data Integration)|Bucket]] and [[Minicon Algorithm|Minicon]]
* idea: transform [[LAV Mediation|LAV mappings]] to [[GAV Mediation|GAV mappings]] (called ''inverse rules'')
* to do that, use query unfolding instead of query rewriting


=== Overview ===
Steps:
* constructing ''inverse rules'' from a set of LAV mappings
* unfolding a global query to obtain local queries 


Important thing:
* 1st step of the algorithm is independent from queries 
* it only needs to consider a set of LAV mappings 


One LAV Mapping is replaced by several GAV Mappings 
* one for each atom in the body of the rule 
* but need to keep bindings between different occurrences of the same existential variables in the body
* done by using [[First Order Logic]] function - [[Skolem Function]]


=== Illustraction by Example ===
Here we will use the following example to illustrate the algorithm

Global query:
* $Q(x) \leftarrow U(y,z), R(x,z), T(z,y), R(y',x)$

And two LAV mappings:
* $V_1(u,v) \subseteq T(w,u), U(v,w), R(v,u)$
* $V_2(u,v,v') \subseteq T(w,u), U(v,w), R(v',w)$


== [[Skolem Function]] ==
=== Logical Intuition ===
For $V_1$, [[First Order Logic|FOL]] meaning is 
* $\forall \ u, v \Big[ V_1(u, v) \Rightarrow \exists \ w \ : \ T(w, u) \land U(v, w) \land R(v, u)  \Big]$
* suppose a tuple $(a, b)$ belongs to the data source that backs $V_1$
** so we have a fact $V_1(a, b)$
* from this fact $V_1(a, b)$ can infer that $R(b, a)$ 
** $V_1(a, b) \Rightarrow R(b, a)$
** (all conjuncts have to be true for a statement to be true, so it means the last conjuncts holds true)
* so $b$ can be an answer to a global query Q(x) = $R(x, y)$


But we can infer other things as well
* e.g. $V_1(a, b) \Rightarrow \exists \ d_1 \ : \ T(d_1, a) \land U(b, d_1)$ 
* where $d_1$ is some constant
** we don't know its value, but we know it exists (since it's existentially qualified) and 
** it depends on constants $a$ and $b$
* so we can denote this dependency as $d_1 = f_1(a, b)$


[[Skolem Function]]
* the symbol $f_1(u, v)$ is a Skolem Function of arity 2
** $f_1(u, v)$ denotes that there exists some constant that depends on values of $u$ and $v$
* given two distinct Skolem terms, e.g. $f_1(1, 2)$ and $f_1(2, v_3)$ we never can say if they belong to the same constant or not


== Creating Inverse Rules ==
So we can create these GAV mappings and their FOL translations 

=== Example 1 ===
Inverse Rules of the 1st LAV mapping:
* $V_1(u,v) \subseteq T(w,u), U(v,w), R(v,u)$


{| class=&quot;wikitable&quot;
! Rule || Mapping || FOL 
|-
| $\text{IN}_{1,1}$ || $V_1(u,v) \subseteq T \big(f_1(u,v), u \big)$ || $\forall \ u, v \Big[ V_1(u,v) \Rightarrow T \big( f_1(u, v), u \big) \Big]$
|-
| $\text{IN}_{1,2}$ || $V_1(u,v) \subseteq U \big(v, f_1(u,v) \big)$ || $\forall \ u, v \Big[ V_1(u,v) \Rightarrow U \big(v, f_1(u, v) \big) \Big]$
|- 
| $\text{IN}_{1,3}$ || $V_1(u,v) \subseteq R \big(v, u \big)$ || $\forall \ u, v \Big[ V_1(u,v) \Rightarrow R \big(v, u \big) \Big]$
|}



=== Algorithm ===
Algorithm for creating the inverse rules
* for each LAV mapping $M_i$ with $n_i$ atoms 
** create $n_i$ GAV mappings (i.e. inverse rules)
** for each existential variable introduce a Skolem function of all distinguished variables


=== Example 2 ===
For example, for the second mapping the result is 
* mapping: $V_2(u,v,v') \subseteq T(w,u), U(v,w), R(v',w)$
* $\text{IN}_{2,1} \ : \ V_2(u,v,v') \subseteq T \big(f_2(u,v,v'), u \big)$
* $\text{IN}_{2,2} \ : \ V_2(u,v,v') \subseteq U \big(v, f_2(u,v,v') \big)$
* $\text{IN}_{2,3} \ : \ V_2(u,v,v') \subseteq R \big(v', f_2(u,v,v') \big)$

So, for each existentially qualified variable we define some Skolem function
* this is a function of all distinguished variables
* for $V_2$ we define $w = f_2(u,v,v')$


== Step 2: Query Unfolding ==
Query Unfolding
* The process of unfolding query is different from [[GAV Mediation]]
* Reason = Skolem terms


=== GAV vs Inverse-Rules ===
Before (in [[GAV Mediation]])
* for each query atom $G_i(x_1, ..., x_m)$
** match with some GAV mapping atom of the form $G_i(z_1, ..., z_m)$ 
** with mapping $\forall i: \ x_i \mapsto z_i$
* here each atom is unfolded &lt;u&gt;in isolation&lt;/u&gt;
* but here it doesn't work: we have Skolen Functions

Now:
* need ''unification'' of atoms with functions
* more complex than simple unfolding
* may require substitution of some variables with function terms - Skolem terms


=== Unification Algorithm ===
Unification
* let $\sigma$ be an empty set of substitutions
* let $PR$ be a partial rewriting of $Q$, $PR \leftarrow Q$
* For each atom $G_i(...) \in Q$ (in turn)
** unify $G_i \in Q$ with some atom $V_j \subseteq G_i$ from the set of rules
*** backtrack when we have a Skolem term in $V_j$
** $\sigma_i$ - the substitution that made this unification possible
** in $PR$, replace $G_i$ with the head $V_j$ of $G_i$
** apply obtained $\sigma_i$ to the partial rewriting $PR$: $PR \leftarrow \sigma_i(PR)$
** keep all mappings from $\sigma_i$: $\sigma \leftarrow \sigma \cup \sigma_i$ 
* let $R$ be a rewriting of $Q$: $R \leftarrow PR$
* return $R$



=== Example ===
Consider this query
* $Q(x) \leftarrow \underbrace{U(y,z)}_\text{(1)}, \underbrace{R(x,z)}_\text{(2)}, \underbrace{T(z,y)}_\text{(3)}, \underbrace{R(y',x)}_\text{(4)}$


Inverse Rules:
* $\text{IN}_{1,1} \ : \ V_1(u,v)    \subseteq T \big(f_1(u,v), u \big)$
* $\text{IN}_{1,2} \ : \ V_1(u,v)    \subseteq U \big(v, f_1(u,v) \big)$
* $\text{IN}_{1,3} \ : \ V_1(u,v)    \subseteq R \big(v, u \big)$
* $\text{IN}_{2,1} \ : \ V_2(u,v,v') \subseteq T \big(f_2(u,v,v'), u \big)$
* $\text{IN}_{2,2} \ : \ V_2(u,v,v') \subseteq U \big(v, f_2(u,v,v') \big)$
* $\text{IN}_{2,3} \ : \ V_2(u,v,v') \subseteq R \big(v', f_2(u,v,v') \big)$


Now try to unify each atom of $Q$ with some atom from the rules
* we use ''most general unifier'' (''mgu'')


Atom 1: $U(y, z)$
* $U(y, z)$ can be ''unified'' with $U \big(v, f_1(u,v) \big)$ (from $\text{IN}_{1,2}$)
* the mgu is a substitution $\sigma = \{ y \mapsto v_1, v \mapsto v_1, z \mapsto f_1(v_2,v_1), u \mapsto v_2 \}$
* $v_1$ and $v_2$ are new fresh variables to avoid conflicts
* $y$ and $v$ map to the same variable $v_1$ because they are at the same position
* substitution $\sigma$ is called a ''unifier'' of two expressions and $U \big(v, f_1(u,v) \big)$
* it's a unifier because applying $\sigma$ results in identical expressions:
** $\sigma \Big( U(y, z) \Big) \equiv \sigma \Big( U \big(v, f_1(u,v) \big) \Big) \equiv U \big(v_1, f_1(v_2, v_1) \big)$
* apply $\sigma$ to the rest of atoms in $Q$ and unfold the first query atom of $Q$
** the head of $U \big(v, f_1(u,v) \big)$ is $V_1(u,v)$
** because of the substitution $v \mapsto v_1, u \mapsto v_2$ it becomes $V_1 \big( v_2, v_1 \big)$
** the remaining atoms are $R(x,z), T(z,y), R(y',x)$, and by substitution we obtain 
*** $R \big(x, z \big) \to R \big(x, f_1(v_2,v_1) \big)$ 
*** $T \big(z, y \big) \to T \big(f_1(v_2,v_1), v_1 \big)$
*** $R \big(y',x \big) \to R \big(y', x \big)$
* so we have:
** $PR_1(x) \leftarrow  V_1 \big( v_2, v_1 \big), R \big(x, f_1(v_2,v_1) \big), T \big(f_1(v_2,v_1),v_1 \big), R \big(y',x \big).$


Atom 2: $R(x, z) \to R \big(x, f_1(v_2,v_1) \big)$
* (taking into account the substitutions made in previous iterations)
* $R(x,z)$ can be unified with $\ V_1(u,v) \subseteq R \big(v, u \big)$ ($\text{IN}_{1,3}$)
* unfolding of atom $(2)$ gives us the following partial rewriting
** $PR_2(x) \leftarrow  V_1 \big( v_2, v_1 \big), V_1 \big( f_1(v_2,v_1), x \big), T \big(f_1(v_2,v_1), v1 \big), R \big(y', x \big)$
* note that now we have a Skolem term in the matched head
** so it's useless to continue unfolding 
** there's no way to match $V_1 \big( f_1(v_2,v_1), x \big)$ with any fact in our data source 
** because we don't know what is the constant resulting from $f_1(v_2,v_1)$, we know only that it exists
* so, we backtrack to atom 1 


Atom 1: $U(y, z)$
* now try to unfold it using $\text{IN}_{2,2}$
* with substitution 
** $\sigma_1^{(2)} = \{ y \mapsto v_1, v \mapsto v_1, z \mapsto f_2(v_2,v_1,v_3), u \mapsto v_2, v' \mapsto v3  \}$
* using this $\sigma_1^{(2)}$ we obtain the following partial rewriting
* $PR'_1(x) \leftarrow V_2 \big(v_2,v_1,v_3 \big), R \big(x,f_2(v_2,v_1,v_3) \big), T \big(f_2(v_2,v_1,v_3),v_1 \big), R \big(y',x \big)$


Atom 2: $R \big(x, z \big) \to R \big(x, f_2(v_2,v_1,v_3) \big)$ 
* try to use $\text{IN}_{2,3}$
* with substitution
** $\sigma_2^{(2)} = \{ v' \mapsto x, v_3 \mapsto x, u \mapsto v_2, v \mapsto v_1 \}$
* $PR'_2(x) \leftarrow V_2 \big(v_2,v_1,v_3 \big), \underbrace{V_2 \big(v_2,v_1,x \big)}_{\color{blue}{\text{redundant}}}, T \big(f_2(v_2,v_1,v_3),v_1 \big), R \big(y',x \big)$
** $PR'_2(x) \leftarrow V_2 \big(v_2,v_1,v_3 \big), T \big(f_2(v_2,v_1,v_3),v_1 \big), R \big(y',x \big)$


Atom 3: $T(z,y) \to T \big(f_2(u,v,v'),u \big)$
* need to match with $T \big( f_2(v_2,v_1,x), v_1 \big)$ from $\text{IN}_{2,3}$
* substitution $\{ v_2 \mapsto v_3, u \mapsto v_3, v_1 \mapsto v_3, v \mapsto v_3, v' \mapsto x \}$
* so we have this partial rewriting 
** $PR'_3(x) \leftarrow V_2(v_2,v_1,x), V_2(v_3,v_3,x), R(y',x)$
** first atom is redundant, so have $PR'_3(x) \leftarrow  V_2(v_3,v_3,x), R(y',x)$


Atom 4: $R(y',x)$
* match with $R \big(v, u \big)$ from $\text{IN}_{1,3}$
* and have $RP'_4(x) \leftarrow  V_2(v_3,v_3,x), V_1(y', x)$


So, final rewriting 
* $R_1(x) \leftarrow  V_2(v_3,v_3,x), V_1(y', x)$


== Advantages ==
Main advantage
* producing inverse rules is independent from processing queries 



== See Also ==
* [[Data Integration]]
* [[Mediator (Data Integration)]]
* [[GAV Mediation]]
* [[Bucket Algorithm (Data Integration)]]
* [[Minicon Algorithm]]

== Sources ==
* [[Web Data Management (book)]]

[[Category:Data Integration]]</text>
      <sha1>d9l4kuyryk2rsaqih9zi1mk1ihgahnx</sha1>
    </revision>
  </page>
  <page>
    <title>Skolem Function</title>
    <ns>0</ns>
    <id>402</id>
    <revision>
      <id>405</id>
      <timestamp>2014-05-04T20:37:41Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1352">== Skolem Function ==
=== Intuition ===
Suppose, we have the following [[Conjunctive Query]]:
* $Q(u,v) \leftarrow T(w,u), U(v,w), R(v,u)$
* For this query, [[First Order Logic|FOL]] meaning is 
* $\forall \ u, v \Big[ Q(u, v) \Rightarrow \exists \ w \ : \ T(w, u) \land U(v, w) \land R(v, u)  \Big]$

Now consider that we have a tuple $(a, b)$ 
* $(a, b)$ belongs to the data source that backs $V_1$
** so we have a fact $Q(a, b)$
* from this fact $Q(a, b)$ can infer that $R(b, a)$ 
** $Q(a, b) \Rightarrow R(b, a)$
** (all conjuncts have to be true for a statement to be true, so it means the last conjuncts holds true)


But we can infer other things as well
* e.g. $Q(a, b) \Rightarrow \exists \ d_1 \ : \ T(d_1, a) \land U(b, d_1)$ 
* where $d_1$ is some constant
** we don't know its value, but we know it exists (since it's existentially qualified) and 
** it depends on constants $a$ and $b$
* so we can denote this dependency as $d_1 = f_1(a, b)$


''Skolem Function''
* the symbol $f_1(u, v)$ is a Skolem Function of arity 2
** $f_1(u, v)$ denotes that there exists some constant that depends on values of $u$ and $v$
* given two distinct Skolem terms, e.g. $f_1(1, 2)$ and $f_1(2, v_3)$ we never can say if they belong to the same constant or not


== Sources ==
* Web Data Management book [http://webdam.inria.fr/Jorge]

[[Category:Logic]]</text>
      <sha1>r73a7dcnj0uplz2wn54q29hb7ci2re8</sha1>
    </revision>
    <revision>
      <id>688</id>
      <parentid>405</parentid>
      <timestamp>2015-11-23T12:39:18Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1329">== Skolem Function ==
=== Intuition ===
Suppose, we have the following [[Conjunctive Query]]:
* $Q(u,v) \leftarrow T(w,u), U(v,w), R(v,u)$
* For this query, [[First Order Logic|FOL]] meaning is 
* $\forall \ u, v \ \Big[ Q(u, v) \Rightarrow \exists \ w \ : \ T(w, u) \land U(v, w) \land R(v, u)  \Big]$

Now consider that we have a tuple $(a, b)$ 
* $(a, b)$ belongs to the data source that backs $V_1$
** so we have a fact $Q(a, b)$
* from this fact $Q(a, b)$ can infer that $R(b, a)$ 
** $Q(a, b) \Rightarrow R(b, a)$
** (all conjuncts have to be true for a statement to be true, so it means the last conjuncts holds true)


But we can infer other things as well
* e.g. $Q(a, b) \Rightarrow \exists \ d_1 \ : \ T(d_1, a) \land U(b, d_1)$ 
* where $d_1$ is some constant
** we don't know its value, but we know it exists (since it's existentially qualified) and 
** it depends on constants $a$ and $b$
* so we can denote this dependency as $d_1 = f_1(a, b)$


''Skolem Function''
* the symbol $f_1(u, v)$ is a Skolem Function of arity 2
** $f_1(u, v)$ denotes that there exists some constant that depends on values of $u$ and $v$
* given two distinct Skolem terms, e.g. $f_1(1, 2)$ and $f_1(2, v_3)$ we never can say if they belong to the same constant or not


== Sources ==
* [[Web Data Management (book)]]

[[Category:Logic]]</text>
      <sha1>hcaow080sk2bkmwq647gsgdjtlvx2ud</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Business Process Management</title>
    <ns>14</ns>
    <id>403</id>
    <revision>
      <id>406</id>
      <timestamp>2014-05-06T18:40:56Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="34">[[Category:Business Intelligence]]</text>
      <sha1>9r3wjma2zu5p73h6yj14g3t1w5ww3bl</sha1>
    </revision>
  </page>
  <page>
    <title>Ontologies</title>
    <ns>0</ns>
    <id>404</id>
    <revision>
      <id>407</id>
      <timestamp>2014-05-06T20:52:13Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1888">== Ontologies ==
Ontologies are semantic models in [[Semantic Web]]
* an ontology is some knowledge about concepts of some domain and the relations between them
* or, an ontology is a formal description that provides a user some (shared) understanding about a domain


Ontologies for Semantic Web:
* should be understandable by machines
* should allow [[Inference in Semantic Web|reasoning]]
* [[RDFS]] + [[OWL]] for describing ontologies on top of RDF graphs
* Tbox in [[Descriptive Logic]] as the formal foundation for inferencing
* in [[OWL]] there's a special property: &lt;code&gt;SOME_URI a owl:Ontology&lt;/code&gt;


Useful for 
* organizing data in distributed and flexible way
* enhancing [[Information Retrieval]] by exploiting some additional information from ontologies
* [[Data Integration]] via [[Ontology Based Data Access]]


Types:
* upper ontologies - general things in abstract manner
* domain ontologies 
* lightweight ontologies for web



== Popular Ontologies ==
=== FOAF ===
FOAF - friend of a friend (uses [[RDFS-Plus]])
* a format for describing people and their relationships
* also, about organizations

=== SKOS ===
SKOS  (uses [[RDFS-Plus]])
* Simple Knowledge Organization System
* e.g. controlled vocabularies, taxonomies, thesauri - defines relationships between terms
* in a distributed and linkable way

=== Others ===
* GR: Good Relations - for business to make descriptions of their offers (uses [[OWL]])
* QUDT - Quantity/Units/Dimensions/Types - for aligning data coming from multiple source  (uses [[OWL]])



== See Also ==
* [[First Order Logic]]
* [[Descriptive Logic]]
* [[RDFS]], [[RDFS-Plus]], [[OWL]]

== Sources ==
* [[Semantic Web for the Working Ontologist (book)]]
* [[XML and Web Technologies (UFRT)]]
* Web Data Management, Manolescu, Ioana, et al. [http://webdam.inria.fr/Jorge/]


[[Category:Semantic Web]]
[[Category:Knowledge Representation]]</text>
      <sha1>02fh8ueaai6fs27up37bqeeuxuu5ime</sha1>
    </revision>
    <revision>
      <id>689</id>
      <parentid>407</parentid>
      <timestamp>2015-11-23T12:39:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1840">== Ontologies ==
Ontologies are semantic models in [[Semantic Web]]
* an ontology is some knowledge about concepts of some domain and the relations between them
* or, an ontology is a formal description that provides a user some (shared) understanding about a domain


Ontologies for Semantic Web:
* should be understandable by machines
* should allow [[Inference in Semantic Web|reasoning]]
* [[RDFS]] + [[OWL]] for describing ontologies on top of RDF graphs
* Tbox in [[Descriptive Logic]] as the formal foundation for inferencing
* in [[OWL]] there's a special property: &lt;code&gt;SOME_URI a owl:Ontology&lt;/code&gt;


Useful for 
* organizing data in distributed and flexible way
* enhancing [[Information Retrieval]] by exploiting some additional information from ontologies
* [[Data Integration]] via [[Ontology Based Data Access]]


Types:
* upper ontologies - general things in abstract manner
* domain ontologies 
* lightweight ontologies for web



== Popular Ontologies ==
=== FOAF ===
FOAF - friend of a friend (uses [[RDFS-Plus]])
* a format for describing people and their relationships
* also, about organizations

=== SKOS ===
SKOS  (uses [[RDFS-Plus]])
* Simple Knowledge Organization System
* e.g. controlled vocabularies, taxonomies, thesauri - defines relationships between terms
* in a distributed and linkable way

=== Others ===
* GR: Good Relations - for business to make descriptions of their offers (uses [[OWL]])
* QUDT - Quantity/Units/Dimensions/Types - for aligning data coming from multiple source  (uses [[OWL]])



== See Also ==
* [[First Order Logic]]
* [[Descriptive Logic]]
* [[RDFS]], [[RDFS-Plus]], [[OWL]]

== Sources ==
* [[Semantic Web for the Working Ontologist (book)]]
* [[XML and Web Technologies (UFRT)]]
* [[Web Data Management (book)]]

[[Category:Semantic Web]]
[[Category:Knowledge Representation]]</text>
      <sha1>dqa1ygpnsvl9o4lx7ps431eqmldjg6d</sha1>
    </revision>
  </page>
  <page>
    <title>First Order Logic</title>
    <ns>0</ns>
    <id>405</id>
    <revision>
      <id>408</id>
      <timestamp>2014-05-06T20:38:56Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="890">{{stub}}

== First Order Logic ==
First Order Logic (FOL)
* Logic is the foundation of [[Knowledge Representation]]
* inferences expressed in logical statements are basis for [[Knowledge Discovery]]
* languages like [[OWL]] - can be viewed as a specialization of FOL


=== Inference ===
In FOL, inference is generally [[Decidability|undecidable]]
* there is a subset of FOL, called [[Descriptive Logic]], where it becomes tractable

* [[First Order Logic|FOL]] give formal definitions of RDFS and OWL statements 
** Classes - unary predicates
** Properties - binary predicates
* [[Descriptive Logic|DL]] is a subset of FOL where many interesting properties are decidable 



== See Also ==
* [[Conjunctive Query]]
* [[Descriptive Logic]]

== Sources ==
* Web Data Management, Manolescu, Ioana, et al. [http://webdam.inria.fr/Jorge/]

[[Category:Logic]]
[[Category:Knowledge Representation]]</text>
      <sha1>15qozsliz0lywlr9qbcoe72vy3nybzy</sha1>
    </revision>
  </page>
  <page>
    <title>Descriptive Logic</title>
    <ns>0</ns>
    <id>406</id>
    <revision>
      <id>409</id>
      <timestamp>2014-05-06T20:40:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4852">== Descriptive Logic ==
Descriptive Logic (DL)
* Formal basis for [[OWL]]
* [[First Order Logic|FOL]] give formal definitions of RDFS and OWL statements 
** Classes - unary predicates
** Properties - binary predicates
* but inference in FOL is not decidable
* [[Descriptive Logic|DL]] is a subset of FOL where many interesting properties are decidable 
* so it allows reasoning 
* exactly what needed for [[Ontologies]]


Mapping between [[OWL]], FOL and DL: 
* see [[Semantic Web Logic]]


== DL Knowledge Base ==
A DL knowledge base consists of:
* ''intentional'' part (''TBox'', $T$) - ontology: classes and concepts
* ''assertional'' part (''ABox'', $A$) - data
* So a ''DL KB'' is a tuple $\langle T, A\rangle$


In [[Semantic Web]] knowledge base is
* TBox: [[Ontologies]] in [[RDFS]] and [[OWL]]
* ABox: Data in [[RDF]]-graphs


=== TBox ===
TBox defines the ontology that serves as conceptual view over the data in the ABox


Terminology
* Classes = ''Concepts'' ($B, C, ...$)
* Properties = ''Roles'' ($R, E, ...$)


A TBox $T$ is a set of terminological axioms
* in form of inclusion and equivalences between
** concepts: $B \sqsubseteq C$ or $B \equiv C$
** roles: $R \sqsubseteq E$ or $R \equiv E$

=== ABox ===
an ABox - set of assertions that 
* state ''membership'' of ''individuals'' to concepts 
** $C(a)$
* and ''role membership'' for pairs
** $R(a, b)$


=== Constructing a DL Knowledge Base ===
&quot;Ingridients&quot;: 
* a vocabulary $\langle C, R, O \rangle$:
** set $C$ of atomic concepts ($A, B, ...$)
** set $R$ of atomic roles ($P, Q, ...$)
** and set $O$ of individuals ($a, b, c, ...$)
* a set of constructs for building complex concept and roles from atomic ones 
* a language of axioms for stating the constraints on the vocabulary
** used to express domain constraints 


=== Constructs and Axioms ===
''Conjunction'' construct $\sqcap$
* $\text{Student} \sqcap \text{Researcher}$
* this is a ''complex'' concept build from atomic concepts $\text{Student}$ and $\text{Researcher}$


''Inclusion'' $\sqsubseteq$ and ''equivalence'' $\equiv$ axioms
* We can relate any concepts (atomic and complex) to atomic concepts 
* e.g. 
** $\text{PhDStudent} \sqsubseteq \text{Student} \sqcap \text{Researcher}$
** $\text{PhDStudent} \equiv \text{Student} \sqcap \text{Researcher}$


Restriction constructs 
* ''value restriction'': $\forall \ R.C$ (&lt;code&gt;owl:allValuesFrom&lt;/code&gt;)
* ''existential restriction'': $\exists \ R.C$ (&lt;code&gt;owl:someValuesFrom&lt;/code&gt;)


Examples
* $\text{MathStudent} \equiv \text{Student} \ \sqcap \ \forall \text{RegisteredTo} . \text{MathCourse}$
** a math student is a student is he's a student and registered to math courses only
* $\text{MathStudent} \equiv \text{Student} \ \sqcap \ \exists \text{RegisteredTo} . \text{MathCourse}$
** a math student is a student is he's a student and registered to at least one math course


''Inclusion'' axiom  $\sqsubseteq$
* expresses relation between concepts / roles
* left side: more specific, right side: more general
* e.g.
** $\text{MathCourse} \sqsubseteq \text{Course}$ (concepts)
** $\text{LateRegisteredTo} \sqsubseteq \text{RegisteredTo}$ (roles)


=== General Inclusion Axioms ===
General Inclusion Axioms (CGIs)
* inclusions between complex concepts

Example
* $\exists \text{TeachesTo} . \text{UndergraduateStudent} \sqsubseteq \text{Professor} \sqcup \text{Lecturer} $
* only professor or lecturer may teach undergraduate students 
* in [[OWL]] it will be the following

&lt;pre&gt;
_:a rdfs:subClassOf owl:Restriction
_:a owl:onProperty :TeachesTo
_:a owl:someValuesFrom :Undergraduate 
_:b owl:unionOf (:Professor :Lecturer)
_:a rdfs:subClassOf _:b
&lt;/pre&gt;

&lt;code&gt;_:a&lt;/code&gt; and &lt;code&gt;_:b&lt;/code&gt; are just blank no-name nodes


== DL-Lite ==
In DL, reasoning is not always tractable
* but there's a trade-off between expressiveness and tracability
* DL-Lite $\subset$ DL
* [[Conjunctive Query|Conjunctive Queries]] can be run over such DL-Lite KBs 
** and thus, some [[SPARQL]]


Allowed:
* Constructs:
** unqualified existential restriction on roles, inverse of roles ($\exists R$ and $\exists R^-$)
** negation on roles
* Axioms in TBox
** $B \sqsubseteq C$ and $B \sqsubseteq \lnot C$
** where $B$ and $C$ are atomic concepts or existential restrictions
* negation allowed only in the right side of inclusion statements 

Also, there are two families of DL-Lite:

=== DL-Lite${}_R$ ===
* allow role inclusion statements 
** $P \sqsubseteq Q$ or $P \sqsubseteq \lnot Q$ 
** where $P$ and $Q$ are atomic or inversion of atomic roles


=== DL-Lite${}_F$ ===
* allow functional statements on roles
** $(\text{funct} P)$ or $(\text{funct} P^-)$



== See Also ==
* [[First Order Logic]]
* [[RDFS]] and [[OWL]]

== Sources ==
* Web Data Management, Manolescu, Ioana, et al. [http://webdam.inria.fr/Jorge/]

[[Category:Logic]]
[[Category:Knowledge Representation]]</text>
      <sha1>a6jt8fpd7d2i22ptnsl0gprd37qn57b</sha1>
    </revision>
  </page>
  <page>
    <title>RDFS</title>
    <ns>0</ns>
    <id>407</id>
    <revision>
      <id>410</id>
      <timestamp>2014-05-06T20:41:14Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5819">== RDFS ==
Is a schema language for [[RDF]]
* roughly, [[RDF]] is for defining graphs, RDFS - for defining sets 
* RDFS tells how to use the graph structure - gives some semantics to the used vocabulary
** how items and their properties are related
* also provides some basic [[Inference in Semantic Web|inferencing capabilities]] (for Knowledge Discovery)
** [[Inference in Semantic Web|Inference]] rules are nice to show with [[SPARQL]] CONSTRUCT queries
** RDFS statements can be interpreted as [[First Order Logic|FOL]] statements 
** for logical semantics behind there expressions see [[Semantic Web Logic]]
* RDFS is expressed using [[RDF]] triples 


RDFS &quot;extends&quot; RDF
* in the sense that it gives some meaning to the triples 



== Basic Constructs ==
=== &lt;code&gt;rdfs:Class&lt;/code&gt; ===
A set is identified in RDFS with &lt;code&gt;rdfs:Class&lt;/code&gt;
* note the use of &lt;code&gt;rdfs:&lt;/code&gt; namespace

&lt;pre&gt;
:AllStarPlayer rdf:type rdfs:Class. 
:MajorLeaguePlayer rdf:type rdfs:Class. 
:Surgeon rdf:type rdfs:Class. 
:Staff rdf:type rdfs:Class. 
:Physician rdf:type rdfs-subproperty:Class. 
&lt;/pre&gt;


=== &lt;code&gt;rdfs:subClassOf&lt;/code&gt; ===
Suppose we have the following assertions
* &lt;code&gt;:Apple rdfs:subClassOf :Fruit&lt;/code&gt;
* &lt;code&gt;:RedDelicions a :Apple&lt;/code&gt;
* can infer that &lt;code&gt;:RedDelicions a :Fruit&lt;/code&gt;

The inference rule is 
&lt;pre&gt;
CONSTRUCT { ?r rdf:type ?B } 
WHERE {
  ?A rdfs:subClassOf ?B .
  ?r rdf:type ?A
} 
&lt;/pre&gt;


=== &lt;code&gt;rdfs:subPropertyOf&lt;/code&gt; ===
Example:
* relation &quot;brother&quot; is more specific than &quot;sibling&quot;
* if smb is my brother, he also is my sibling
* so &lt;code&gt;:brother rdfs:subPropertyOf :sibling&lt;/code&gt;

The inference rule is 
&lt;pre&gt;
CONSTRUCT { ?x ?r ?y } 
WHERE {
  ?x ?q ?y . 
  ?q rdfs:subPropertyOf ?r
}
&lt;/pre&gt;

Another example
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/rdfs-subproperty.png


=== &lt;code&gt;rdfs:domain&lt;/code&gt; and &lt;code&gt;rdfs:range&lt;/code&gt; ===
Typing data by usage (also - ''implicit'' typing)
* as opposed to the ''explicit'' typing &lt;code&gt;rdf:type&lt;/code&gt;
* &lt;code&gt;rdfs:domain&lt;/code&gt; - set of values for which a property is defined (subject)
* &lt;code&gt;rdfs:range&lt;/code&gt; - set of values it can take (object)

Can define them as 
&lt;pre&gt;
CONSTRUCT {?y rdf:type ?D .} 
WHERE {
  ?P rdfs:range ?D . 
  ?x ?P ?y .
} 

CONSTRUCT {?x rdf:type ?D .} 
WHERE {
  ?P rdfs:domain ?D . 
  ?x ?P ?y .
} &lt;/pre&gt;

'''NB''': 
* there's no notion of incorrect/inconsistent inference in RDFS
* it doesn't signalize an error if a property isn't used consistently with the declaration
* RDFS will [[Inference in Semantic Web|infer]] the type to make this property consistent 
* this declaration is quite aggressive - even with one triple it can result in surprising inferences


=== Example ===
Suppose we have the following schema
* &lt;code&gt;:MarriedWoman rdfs:subClassOf :Woman.&lt;/code&gt;
* &lt;code&gt;:hasMaidenName rdfs:domain :MarriedWoman.&lt;/code&gt;
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/rdfs-ex-dom.png

And the following assertions: 
* &lt;code&gt;:Karen :hasMaidenName &quot;Stephens&quot;.&lt;/code&gt;

Inference:
* Even if we don't know that &lt;code&gt;:Karen&lt;/code&gt; is a &lt;code&gt;:Woman&lt;/code&gt;, we can infer that she's married
* infer that &lt;code&gt;:Karen rdf:type :MarriedWoman&lt;/code&gt; based on &lt;code&gt;rdfs:domain&lt;/code&gt;
* infer that &lt;code&gt;:Karen rdf:type :Woman&lt;/code&gt; based on &lt;code&gt;rdfs:subClassOf&lt;/code&gt;


== Modeling with RDFS ==
There are some basic modeling patterns that can be used in RDFS

=== Intersection ===
$C \equiv A \cap B$
* &lt;code&gt;:C rdfs:subClassOf :A&lt;/code&gt;
* &lt;code&gt;:C rdfs:subClassOf :B&lt;/code&gt;
* need to be a subclass of both $A$ and $B$ to be in $C$


=== Union ===
$C \equiv A \cup B$
* &lt;code&gt;:A rdfs:subClassOf :C&lt;/code&gt;
* &lt;code&gt;:B rdfs:subClassOf :C&lt;/code&gt;
* $x \in C$ when $x$ is a subclass of $A$, or subclass of $B$ (or both)


=== Properties ===
Intersection and Union can also be used for properties, e.g.
* Intersection
** &lt;code&gt;:R rdfs:subPropertyOf :P . &lt;/code&gt;
** &lt;code&gt;:R rdfs:subPropertyOf :Q .&lt;/code&gt;
* Union
** &lt;code&gt;:P rdfs:subPropertyOf :R . &lt;/code&gt;
** &lt;code&gt;:Q rdfs:subPropertyOf :R .&lt;/code&gt;


=== Example: ''Terminology reconciliation'' ===
* A military plane needs to determine if it can attach something or not
* it has 2 sources of data
** &quot;never-target&quot; list: schools, churches, hospitals
** &quot;off-limit airspace&quot;: no-fly zones
* a target is off-limit if it belongs to one of these classes 
** solution: use union
** &lt;code&gt;fc:Civilian rdfs:subClassOf cc:OffLimitTarget&lt;/code&gt;
** &lt;code&gt;space:NoFlyZone rdfs:subClassOf cc:OffLimitTarget&lt;/code&gt;


=== Example 2: Property union ===
* if &lt;code&gt;:A rdfs:label &quot;something&quot;&lt;/code&gt;, then &quot;something&quot; is a printable name of &lt;code&gt;:A&lt;/code&gt;
* it's more readable than URIs
* but suppose that in our data source we don't have it, but have something else with some textual information
** &lt;code&gt;:person1 :personName &quot;James Dean&quot;&lt;/code&gt;
** &lt;code&gt;:movie1 :movieTitle &quot;Giant&quot;&lt;/code&gt;
* we want to use these properties as labels
* solution: use property union:
** &lt;code&gt;:personName rdfs:subPropertyOf rdfs:label&lt;/code&gt;
** &lt;code&gt;:movieTitle rdfs:subPropertyOf rdfs:label&lt;/code&gt;


== Non-modeling Properties in RDFS ==
There are properties that aren't used for inference, but just for description
* &lt;code&gt;rdfs:label&lt;/code&gt; - text representation
* &lt;code&gt;rdfs:seeAlso&lt;/code&gt;  - cross referencing
* &lt;code&gt;rdfs:isDefinedBy&lt;/code&gt; - primary source/description of a resource
* &lt;code&gt;rdfs:comment&lt;/code&gt; - a comment


== See Also ==
* [[RDFS and OWL summary]]
* [[Semantic Web]]
* [[Inference in Semantic Web]]
* [[RDFS-Plus]] - a subset of [[OWL]] and an extension of [[RDFS]] with more inferencing capabilities
* [[OWL]] 
* [[Semantic Web Logics]]


== Sources ==
* [[Semantic Web for the Working Ontologist (book)]]
* [[XML and Web Technologies (UFRT)]]

[[Category:Semantic Web]]</text>
      <sha1>cv8aib2ugehrsy480yerv48fn43x0d1</sha1>
    </revision>
  </page>
  <page>
    <title>RDFS-Plus</title>
    <ns>0</ns>
    <id>408</id>
    <revision>
      <id>411</id>
      <timestamp>2014-05-06T20:43:07Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6978">== RDFS-Plus ==
In [[Semantic Web]] [[RDFS-Plus]] is an extension of [[RDFS]], and a subset of [[OWL]]
* even though the namespace is [[OWL]], it's considered as a subset 
* [[Inference in Semantic Web|Inference]] rules are shown with [[SPARQL]] CONSTRUCT queries
* for logical semantics behind there expressions see [[Semantic Web Logic]]
* DL-Lite something


== Basic Constructs ==
=== &lt;code&gt;owl:inverseOf&lt;/code&gt;: Inverse ===
Example
* suppose we have &lt;code&gt;:hasParent&lt;/code&gt; - then the inverse is &lt;code&gt;:hasChild&lt;/code&gt;
* the construction &lt;code&gt;owl:inverseOf&lt;/code&gt; makes this relation explicit

In math, 
* inverse of $f$ is $f^{-1}$: 
* if $f(x) = y$, then $f^{-1}(y) = x$
* the same idea is in RDFS-Plus

&lt;pre&gt;
CONSTRUCT { ?y ?q ?x }
WHERE {
  ?p owl:inverseOf ?q .
  ?x ?p ?y .
}
&lt;/pre&gt;


Example:
* &lt;code&gt;lit:Shakespeare lit:wrote lit:Macbeth &lt;/code&gt;
* we know that &lt;code&gt;lit:wrote owl:inverseOf lit:writtenBy&lt;/code&gt;
* so, can infer that &lt;code&gt;lit:Macbeth lit:writtenBy lit:Shakespeare&lt;/code&gt;


=== &lt;code&gt;owl:SymmetricProperty&lt;/code&gt;: Symmetric Properties ===
* in real life, a relation &quot;married&quot; is both-way: 
** if $A$ is married on $B$, then $B$ is married on $A$
* suppose we have this assertion: &lt;code&gt;bio:Anne bio:married lit:Shakespeare&lt;/code&gt;
* consider this query
** &lt;code&gt;SELECT ?who WHERE { ?lit:Shakespeare bio:married ?who }&lt;/code&gt;
** it returns no answer! 
* now state that married is both-way: it's inverse of itself
** &lt;code&gt;bio:married owl:inverseOf bio:married&lt;/code&gt;
** now that query returns something 
* this is an example of a &lt;code&gt;owl:SymmetricProperty&lt;/code&gt;
** so instead of &lt;code&gt;owl:inverseOf&lt;/code&gt; can say
** &lt;code&gt;bio:married rdf:type owl:SymmetricType&lt;/code&gt;

&lt;pre&gt;
CONSTRUCT { ?p owl:inverseOf ?p. } 
WHERE { ?p a owl:SymmetricProperty . }
&lt;/pre&gt;


Also, can be useful to say that &lt;code&gt;owl:inverseOf&lt;/code&gt; is symmetric
* &lt;code&gt;owl:inverseOf rdf:type owl:SymmetricProperty&lt;/code&gt;
* now the following hold:
** $:P_1$ &lt;code&gt;owl:inverseOf&lt;/code&gt; $:P_2 \Rightarrow$
** $:P_2$ &lt;code&gt;owl:inverseOf&lt;/code&gt; $:P_1$


=== &lt;code&gt;owl:TransitiveProperty&lt;/code&gt;: Transitivity ===
In math:
* $R$ is transitive if
* $a \ R \ b \land b \ R \ c \Rightarrow a \ R \ c$

In RDFS-plus, &lt;code&gt;owl:TransitiveProperty&lt;/code&gt; is used for that:
* &lt;code&gt;:P rdf:type owl:TransitiveProperty&lt;/code&gt;

Meaning:
&lt;pre&gt;
CONSTRUCT { ?x ?p ?z .} 
WHERE {
  ?x ?p ?y . 
  ?y ?p ?x . 
  ?p a owl:TransitiveProperty . 
} 
&lt;/pre&gt;

Note that for longer chains like $a \to b \to ... \to q$ the rule also holds


=== &lt;code&gt;owl:equivalentClass&lt;/code&gt;: Equivalence ===
Identity
* URIs give the global notion of identity
* but what if we merging two different sources that have the same concept, but under different URIs? 
* i.e. we want to say that $:A \equiv :B$
* use [[RDFS]]:
** &lt;code&gt;:A rdfs:subClassOf :B&lt;/code&gt; $\land$ &lt;code&gt;:B rdfs:subClassOf :A&lt;/code&gt;
* semantically same effect is achieved with &lt;code&gt;owl:equivalentClass&lt;/code&gt;

&lt;pre&gt;
CONSTRUCT { ?r rdf:type ?b .} 
WHERE { 
  ?a owl:equivalentClass ?b . 
  ?r rdf:type ?a . 
}

CONSTRUCT { ?r rdf:type ?a .} 
WHERE { 
  ?a owl:equivalentClass ?b . 
  ?r rdf:type ?b . 
} 
&lt;/pre&gt;

Note that we need to have 2 CONSTRUCT statements 
* because &lt;code&gt;owl:equivalentClass&lt;/code&gt; is symmetric
* but instead of repeating twice can say that 
** &lt;code&gt;owl:equivalentClass rdf:type owl:SymmetricProperty&lt;/code&gt;
* can add the following and have no need to state anything
** &lt;code&gt;owl:equivalentClass rdfs:subPropertyOf rdfs:subClassOf&lt;/code&gt;


=== &lt;code&gt;owl:sameAs&lt;/code&gt;: Same Individuals ===
Suppose in 3 namespaces we have 3 different ways of describing a person
* how we can say that in all these 3 cases something/somebody is the same resource? 
* e.g. &lt;code&gt;pr:WilliamShakspere owl:sameAs lit:Shakespeare&lt;/code&gt;

it's defined by 3 rules:
&lt;pre&gt;
-- when it's a subject
CONSTRUCT { ?s ?p ?x. } 
WHERE {
  ?s ?p ?y.
  ?x owl:sameAs ?y .
}

-- when it's an object
CONSTRUCT { ?x ?p ?o. } 
WHERE {
  ?y ?p ?o .
  ?x owl:sameAs ?y .
}

-- when it's a predicate
CONSTRUCT {?s ?x ?o. } 
WHERE {
  ?s ?y ?o .
  ?x owl:sameAs ?y .
} 
&lt;/pre&gt;

To avoid adding 3 more rules
* say that it's symmetric:
* &lt;code&gt;owl:sameAs rdf:type owl:SymmetricProperty&lt;/code&gt;


== Sameness: Functional Properties ==
=== &lt;code&gt;owl:FucntionalProperty&lt;/code&gt; ===
Functional - of functions (in math)
* a property is functional if
* for some input value there could be only one output value

Examples (from RL):
* &lt;code&gt;hasMother&lt;/code&gt; - can have only one biological mother
* &lt;code&gt;hasBirthplace&lt;/code&gt; 
* &lt;code&gt;birthdate&lt;/code&gt;

In RDFS-plus use &lt;code&gt;owl:FucntionalProperty&lt;/code&gt; to describe that
* a property can give only one value for one particular entry
&lt;pre&gt;
CONSTRUCT { ?a owl:sameAs ?b . } 
WHERE {
  ?p rdf:type owl:FunctionalProperty .
  ?x ?p ?a . 
  ?x ?p ?b . 
} 
&lt;/pre&gt;

Note the semantics
* if $x^2 = a \land x^2 = b \Rightarrow a = b$
* so if some resources participate in a functional property
* we conclude that these resources refer to the same entity (i.e. they are the same)


=== &lt;code&gt;owl:InverseFunctionalProperty&lt;/code&gt; ===
Inverse of &lt;code&gt;owl:FucntionalProperty&lt;/code&gt;
* a single value of an inverse functional property cannot be shared by two entities 
* instead it infers that these two entities are the same
* and it doesn't signalize any errors!
* examples: SSN, driver license,  etc - anything that can be an ID number

&lt;pre&gt;
CONSTRUCT { ?a owl:sameAs ?b . } 
WHERE {
  ?p rdf:type owl:InverseFunctionalProperty .
  ?a ?p ?x . 
  ?b ?p ?x . 
}&lt;/pre&gt;


=== Examples ===
Student ID
* a student has an identity 
* this ID # belongs only to one person 
* so have this in the schema
** &lt;code&gt;:hasIdentityNo rdfs:domain :Student .&lt;/code&gt;
** &lt;code&gt;:hasIdentityNo rdfs:range xsd:Integer .&lt;/code&gt;
* now ensure the uniqueness 
** &lt;code&gt;:hasIdentityNo rdf:type owl:FunctionalProperty .&lt;/code&gt;
** &lt;code&gt;:hasIdentityNo rdf:type owl:InverseFunctionalProperty .&lt;/code&gt;

=== Summary ===
Functional Only
* &lt;code&gt;hasMotheris&lt;/code&gt; a functional property only. 
* Someone has exactly one mother, but many people can share the same mother.

Inverse Functional Only
* &lt;code&gt;hasDiary&lt;/code&gt; is an inverse functional property only
* A person may have many diaries, but a diary is authored by one person only

Both Functional and Inverse Functional
* SSN, Student #, etc


== Other Constructs ==
=== &lt;code&gt;owl:DatatypeProperty&lt;/code&gt; and &lt;code&gt;owl:ObjectPropery&lt;/code&gt; ===
In [[RDF]], subjects and objects are resource
* they can be either another resources or some data items 

Examples:
* &lt;code&gt;uni:studentId a owl:DatatypeProperty&lt;/code&gt;
* &lt;code&gt;bio:married a owl:ObjectProperty&lt;/code&gt;

=== &lt;code&gt;owl:Class&lt;/code&gt; ===
&lt;code&gt;owl:Class rdfs:subClassOf rdfs:Class . &lt;/code&gt;


== See Also ==
* [[RDFS and OWL Summary]]
* [[Semantic Web]]
* [[RDFS]] and [[OWL]]
* [[Inference in Semantic Web]]
* [[Semantic Web Logics]]


== Sources ==
* [[Semantic Web for the Working Ontologist (book)]]
* [[XML and Web Technologies (UFRT)]]

[[Category:Semantic Web]]</text>
      <sha1>il4ipgaylp9dl5k4strv5n80nnz6jj7</sha1>
    </revision>
  </page>
  <page>
    <title>OWL</title>
    <ns>0</ns>
    <id>409</id>
    <revision>
      <id>412</id>
      <timestamp>2014-05-06T20:45:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8769">== OWL ==
OWL - Web Ontology Language

Several languages 
* OWL-Full - No limits, but some things can be undecidable
* OWL-DL - [[Descriptive Logic]]
* OWL-Lite - [[RDFS-Plus]], DL-Lite
* for logical semantics behind there expressions see [[Semantic Web Logic]]



== &lt;code&gt;owl:Restriction&lt;/code&gt;: Restrictions ==
Allows to describe classes in terms of other things we already modeled 
* a Restriction in OWL is a Class defined by describing the individuals it contains
* &lt;code&gt;owl:Restriction rdfs:subClassOf owl:Class&lt;/code&gt;


=== Kinds of Restrictions ===
* &lt;code&gt;owl:someValuesFrom&lt;/code&gt;
** all individuals form which at least one value of the property $P$ comes from some class $C$ 
** e.g. &lt;code&gt;:AllStarPlayer&lt;/code&gt; is a &lt;code&gt;:Player&lt;/code&gt; for which at least one value of &lt;code&gt;:playsFor&lt;/code&gt; comes from the class &lt;code&gt;:AllStarTeam&lt;/code&gt;
** &lt;code&gt;[a owl:Restiction; owl:onProperty :playsFor; owl:someValuesFrom :AllStarTeam]&lt;/code&gt;
** if at least one team of this guy is of the class &lt;code&gt;:AllStarTeam&lt;/code&gt; $\Rightarrow$ he is an &lt;code&gt;:AllStarPlayer&lt;/code&gt;
* &lt;code&gt;owl:allValuesFrom&lt;/code&gt; 
** individuals for which all values of property $P$ come from class $C$
** if there are any members, they all must have the same property
* &lt;code&gt;owl:hasValue&lt;/code&gt;
** all individuals that have some specific value $a$ for the property $P$ 
** e.g. :JapanTeams - the set of all baseball &lt;code&gt;:Team&lt;/code&gt;s &lt;code&gt;:from :Japan&lt;/code&gt; 
** e.g. Suppose we have a property &lt;code&gt;:orbitsAround&lt;/code&gt;
*** then everything that &lt;code&gt;:orbitsAround :TheSun&lt;/code&gt; belongs to the &lt;code&gt;:SolarSystem&lt;/code&gt;
*** &lt;code&gt;[a owl:Restriction; owl:onProperty :orbitsAround; owl:hasValue :TheSun]&lt;/code&gt;

Best way to use these restrictions:
* &lt;code&gt;rdfs:subClassOf&lt;/code&gt;
* &lt;code&gt;owl:equivalentClass&lt;/code&gt;


=== Example: Questionnaire ===
* a questionnaire contains a number of questions 
* each question has some possible answers
* in contrast to a quiz there is no &quot;right&quot; answer
* the selection of some answers precludes other questions

Schema (namespace &lt;code&gt;q&lt;/code&gt;):
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/owl-rest-quest1.png

&lt;pre&gt;
q:optionOf a owl:ObjectProperty; 
    rdfs:domain q:Answer; 
    rdfs:range q:Question; 
    owl:inverseOf q:hasOption. 
q:hasOption a owl:ObjectProperty. 
q:answerText a owl:DatatypeProperty; 
    rdfs:domain q:Answer; 
    rdfs:range xsd:string. 
q:questionText a owl:FunctionalProperty, owl:DatatypeProperty;
    rdfs:domain q:Question; 
    rdfs:range xsd:string. 
q:Answer a owl:Class. 
q:Question a owl:Class. 
&lt;/pre&gt;


Data (namespace &lt;code&gt;d&lt;/code&gt;): 
&lt;pre&gt;
d:WhatProblem a q:Question; 
    q:hasOption d:STV, d:SInternet, d:SBoth; 
    q:questionText &quot;What system are you having trouble with?&quot;.
    d:STV a q:Answer; 
    q:answerText &quot;Cable TV&quot;. 
d:SInternet a q:Answer; 
    q:answerText &quot;High-speed Internet&quot;. 
d:SBoth a q:Answer;
    q:answerText &quot;Both&quot;. 
    d:TVsymptom a q:Question; 
    q:questionText &quot;What television symptoms are you having?&quot;;
    q:hasOption d:TVSnothing, d:TVSnosound, d:TVStiling, d:TVSreception.
d:TVSnothing a q:Answer; 
    q:answerText &quot;No Picture&quot;. 
d:TVSnosound a q:Answer; 
    q:answerText &quot;No Sound&quot;. 
d:TVStiling a q:Answer; 
    q:answerText &quot;Tiling&quot;. 
    d:TVSreception a q:Answer; 
    q:answerText &quot;Bad reception&quot;. 
&lt;/pre&gt;


==== &lt;code&gt;owl:someValuesFrom&lt;/code&gt;: Answered questions ====
For each question need to know what's selected 
* for that first define a special property &lt;code&gt;q:hasSelectedOption&lt;/code&gt;:
** &lt;code&gt;q:hasSelectedOption a owl:ObjectProperty; rdfs:subPropertyOf q:hasOption.&lt;/code&gt;
* suppose that for &lt;code&gt;d:WhatProblem&lt;/code&gt; the selected option is &lt;code&gt;d:STV&lt;/code&gt;
** &lt;code&gt;d:WhatProblem q:hasSelectedOption d:STV&lt;/code&gt;
* a question is answered if it has a selected option (e.g. &lt;code&gt;d:WhatProblem&lt;/code&gt; is answered)

&lt;pre&gt;
q:AnsweredQuestion owl:equivalentClass 
    [a owl:Resrtiction; 
       owl:onProperty q:hasSelectedOption;
       owl:someValuesFrom q:Answer].
&lt;/pre&gt;


==== &lt;code&gt;owl:allValuesFrom&lt;/code&gt;: Next Questions ====
Next questions should depend of what's been asked and answered
* first, define all answers that were selected 
* &lt;code&gt;q:SelectedAnswer a owl:Class; rdfs:subClassOf q:Answer&lt;/code&gt;
* to make sure that any option that was selected will appear in this class: 
** &lt;code&gt;q:SelectedAnswer rdfs:range q:SelectedAnswer&lt;/code&gt;
** e.g. &lt;code&gt;d:WhatProblem q:hasSelectedOption d:STV&lt;/code&gt; $\Rightarrow$
** &lt;code&gt;d:STV a q:SelectedAnswer&lt;/code&gt;

now define questions that can be asked: &lt;code&gt;q:EnabledQuestion a owl:Class&lt;/code&gt;
* when some answer is selected, we want to infer that some dependent questions become enabled
* each answer potentially makes some other questions enabled
* define property &lt;code&gt;q:enablesCandidate&lt;/code&gt; for that

&lt;pre&gt;
q:enablesCandidate a owl:ObjectProperty;
    rdfs:domain q:Asnwer;
    rdfs:range q:Question.

d:STV q:enablesCandidate d:TVsymptom. 
d:SBoth q:enablesCandidate d:TVsymptom. 
&lt;/pre&gt;

Restriction:
* we want that only answers that were selected enforce this property
* so use &lt;code&gt;owl:allValuesFrom&lt;/code&gt; and &lt;code&gt;rdfs:subClassOf&lt;/code&gt;

&lt;pre&gt;
q:SelectedAnswer rdfs:subClassOf [a owl:Restriction; 
    owl:onProperty q:enablesCandidate; 
    owl:allValuesFrom q:EnabledQuestion] 
&lt;/pre&gt;


Inference example
* assume &lt;code&gt;d:STV&lt;/code&gt; is selected: &lt;code&gt;d:STV a q:SelectedAnswer&lt;/code&gt;
* infer that &lt;code&gt;d:STV a [a owl:Restriction; owl:onProperty q:enablesCandidate; owl:allValuesFrom q:EnabledQuestion]&lt;/code&gt;
* any individuals related to it by &lt;code&gt;q:enablesCandidate&lt;/code&gt; must be members of &lt;code&gt;q:EnabledQuestion&lt;/code&gt;
* since &lt;code&gt;d:STV q:enablesCandidate d:TVsymptom&lt;/code&gt; infer that &lt;code&gt;d:TVsymptom a q:EnabledQuestion&lt;/code&gt;


== Sets and Counting ==
=== Union and Intersection ===
* &lt;code&gt;U a owl:Class; owl:unionOf (ns:A ns:B ...) .&lt;/code&gt;
* &lt;code&gt;I a owl:Class; owl:intersectionOf (ns:A ns:B ...) .&lt;/code&gt;

Example:
* suppose we want to know what are enabled high-priority questions
&lt;pre&gt;
q:CandidateQuestions owl:equivalentClass [
    a owl:Class;
      owl:intersectionOf(q:EnabledQuestion q:HighPriorityQuestion)]
&lt;/pre&gt;


=== Set Enumeration: Closing the World ===
Recall the Open World Assumption (see [[Semantic Web#Main Assumptions]])
* we can't be sure that if we don't have a record about some fact then it doesn't exist: 
* it can exist, but maybe we just don't know about it
* sometimes we need to &quot;close the world&quot;: assume we know everything

&lt;code&gt;owl:oneOf&lt;/code&gt;
* we assume that we can enumerate all the elements of some class 
* so we put a limit on the AAA slogan: now nobody can say something additional about this topic
* so handle it with care
* Example:
&lt;pre&gt;
ss:SolarPlanet rdf:type owl:Class; 
    owl:oneOf (ss:Mercury ss:Venus  ss:Earth  ss:Mars
               ss:Jupiter ss:Saturn ss:Uranus ss:Neptune).
&lt;/pre&gt;


=== Cardinality Restrictions ===
* to express constants on the # of individuals who can participate in some restriction class
* for example, a baseball team can have only 9 players 

&lt;pre&gt;
[a owl:Restriction;
   owl:onProperty :hasPlayer;
   owl:cardinality 9]
&lt;/pre&gt;

Also can use:
* &lt;code&gt;owl:minCardinality&lt;/code&gt; - lower bound
* &lt;code&gt;owl:maxCardinality&lt;/code&gt; - upper bound


=== Set Compliment ===
&lt;code&gt;ex:ClassA owl:complimentOf ex:ClassB&lt;/code&gt;
* ''compliment'' - another class whose members are things that don't belong to this ''complimented'' class
* $A = \Omega - B$

But it includes &lt;u&gt;everything&lt;/u&gt; that is not in the complimented class
* e.g. &lt;code&gt;bb:MinorLeaguePlayer owl:complimentOf bb:MajorLeaguePlayer&lt;/code&gt;
* this will include everything else in the universe: players, managers, fans, planets, etc
* solution: combine with intersection

&lt;pre&gt;
bb:MinorLeaguePlayer owl:intersectionOf (
    [a owl:Class; owl:complimentOf bb:MajorLeaguePlayer]
    bb:Player)
&lt;/pre&gt;
* so &lt;code&gt;bb:MinorLeaguePlayer&lt;/code&gt;s are &lt;code&gt;bb:Player&lt;/code&gt;s who's not in Major League


=== Disjoint Sets ===
&lt;code&gt;:Man owl:disjointSet :Woman&lt;/code&gt;
* &lt;code&gt;:Irene a :Woman &lt;/code&gt;
* &lt;code&gt;:Ralph a :Man&lt;/code&gt;
* infer that &lt;code&gt;:Irene owl:differentFRom :Ralph&lt;/code&gt;


== Links ==
Protégé 
* http://protege.stanford.edu/download/download.html
* useful tool for building OWL models
* good tutorial: http://owl.cs.manchester.ac.uk/tutorials/protegeowltutorial/


== See Also ==
* [[RDFS and OWL Summary]]
* [[Semantic Web]]
* [[RDF]]
* [[RDFS]]
* [[RDFS-Plus]] - a subset of OWL and an extension of [[RDFS]] with more inferencing capabilities
* [[Inference in Semantic Web]]
* [[Semantic Web Logics]]

== Sources ==
* [[Semantic Web for the Working Ontologist (book)]]
* [[XML and Web Technologies (UFRT)]]

[[Category:Semantic Web]]
[[Category:Knowledge Representation]]</text>
      <sha1>1d1y93wt7oo94jn4i6vzhkkn9ih4pwt</sha1>
    </revision>
  </page>
  <page>
    <title>Inference in Semantic Web</title>
    <ns>0</ns>
    <id>410</id>
    <revision>
      <id>413</id>
      <timestamp>2014-05-06T20:45:52Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2884">== Inferencing in [[Semantic Web]] ==
In [[Semantic Web]], using [[RDFS]] and [[OWL]] many things can be inferred based on facts that are stored in the [[RDF]] triple store
* This is used for [[Knowledge Discovery]] in Semantic Web
* All [[RDF]] statements or RDFS and OWL can be translated to [[First Order Logic]] and [[Descriptive Logic]] to facilitate inferencing
** see [[Semantic Web Logics]]


Inferencing - a systematic process of adding new tuples to an RDF graph based on some patterns (rules)
* ''asserted triples'' - RDF triples provided by some data source
* ''inferred triples'' - new triples added by inference rules
* ''inference rules'' - systematic patterns that define how and what to infer
* ''inference engine'' - engine that does the inference


=== Motivating Example ===
Suppose you have a [[SPARQL]] query on your [[RDF]] graph 
* you look for &lt;code&gt;:RedDelicious&lt;/code&gt; apples
* you are doing it in the &lt;code&gt;:Fruit&lt;/code&gt; section 
* but the result is empty, because &lt;code&gt;:RedDelicious&lt;/code&gt; is an &lt;code&gt;:Apple&lt;/code&gt;, not a &lt;code&gt;:Fruit&lt;/code&gt;
** i.e. &lt;code&gt;:RedDelicious a :Apple&lt;/code&gt;
** and &lt;code&gt;:Apple :subClassOf :Fruit&lt;/code&gt;

Possible solution:
* use [[SPARQL#Transitive Queries]]

&lt;pre&gt;
SELECT ?item 
WHERE {
  ?class :subClassOf* :Fruit . 
  ?item a ?class . 
} 
&lt;/pre&gt;


But users will have to do it each time 
* alternatives? 
* can have rules if $X$ subclass of $Y$, then $\forall x \in X: x \in Y$
* ''inferencing'' - given some information we can determine related information - and consider that it's also stored in our database 
* so here we'd infer that if &lt;code&gt;:RedDelicious&lt;/code&gt; is an &lt;code&gt;:Apple&lt;/code&gt;, it's also a &lt;code&gt;:Fruit&lt;/code&gt;
* &lt;code&gt;:Fruit&lt;/code&gt; is broader than &lt;code&gt;:Apple&lt;/code&gt;, so &lt;code&gt;:Fruit&lt;/code&gt; is a subclass of &lt;code&gt;:Apple&lt;/code&gt;


=== Inferencing  ===
The motivating example illustrates the ''type propagation rule''
* this is a part of the [[RDFS]] language: &lt;code&gt;rdfs:subClassOf&lt;/code&gt; relation
* rule: $X$ &lt;code&gt;rdfs:subClassOf&lt;/code&gt; $Y \Rightarrow $ every member of $X$ is also a member of $Y$

Reference rules of [[RDFS]]/[[OWL]] can be expressed using [[SPARQL]] Construct queries:
* this is a good way of describing rules

&lt;pre&gt;
CONSTRUCT { ?r rdf:type ?B } 
WHERE {
  ?A rdfs:subClassOf ?B 
  ?r rdf:type ?A
} 
&lt;/pre&gt;


== Implementation Details ==
When the inference happens? 
* Cached Inference: 
** inferred triples are stored along with asserted
** risk an explosion of the triple store
** also, change management is important - how to propagate changes and deletes
** for deletes - same inferred tuple can be due to several facts, so need to be careful when deleting
* Just-In-Time Inference
** To respond to queries only 
** no inferred triples retained


== Sources ==
* [[Semantic Web for the Working Ontologist (book)]]
* [[XML and Web Technologies (UFRT)]]

[[Category:Semantic Web]]</text>
      <sha1>91hj33au57lix6iukyxc1yzh7s5qy8g</sha1>
    </revision>
  </page>
  <page>
    <title>Semantic Web Logics</title>
    <ns>0</ns>
    <id>411</id>
    <revision>
      <id>414</id>
      <timestamp>2014-05-06T20:50:29Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3427">== Semantic Web Logics ==
In [[Semantic Web]], there are formal models behind [[Inference in Semantic Web|reasoning]]
* [[First Order Logic|FOL]] give formal definitions of RDFS and OWL statements 
** Classes - unary predicates
** Properties - binary predicates
* [[Descriptive Logic|DL]] is a subset of FOL where many interesting properties are decidable 



== Formal Definitions ==
Observe that these statements all have the same general form:
* $\forall \ ... \ (... \ \exists \ ...)$


=== [[RDFS]] ===
{| class=&quot;wikitable&quot;
! [[RDFS]] statements || [[First Order Logic|FOL]] translation || [[Descriptive Logic|DL]] notation
|-
| &lt;code&gt;i rdf:type C&lt;/code&gt; || $C(i)$ || $i \ : \ C$ or $C(i)$
|-
| &lt;code&gt;i P j&lt;/code&gt; || $P(i, j)$ || $i \ P \ j$ or $P(i, j)$
|-
| &lt;code&gt;C rdfs:subClassOf D&lt;/code&gt; || $\forall X \ \big( C(X) \ \exists \ D(X) \big)$ || $C \sqsubseteq D$
|-
| &lt;code&gt;P rdfs:subPropertyOf R&lt;/code&gt; || $\forall X, Y \ \big( P(X, Y) \ \exists \ R(X, Y) \big)$ || $P \sqsubseteq R$
|-
| &lt;code&gt;P rdfs:domain C&lt;/code&gt; || $\forall X, Y \ \big( P(X, Y) \ \exists \ C(X) \big)$ || $\exists P \sqsubseteq C$
|-
| &lt;code&gt;P rdfs:range D&lt;/code&gt; || $\forall X, Y \ \big( P(X, Y) \ \exists \ D(Y) \big)$ || $\exists P^- \sqsubseteq D$
|}


=== [[RDFS-Plus]] === 
{| class=&quot;wikitable&quot;
! [[RDFS-Plus]] || [[First Order Logic|FOL]] || [[Descriptive Logic|DL]]
|-
| &lt;code&gt;P rdf:type owl:FunctionalProperty&lt;/code&gt; || $\forall X, Y, Z \ \big( P(X, Y ) \land P(X, Z) \Rightarrow Y = Z \big)$ || $(\text{funct} P)$ or $\exists P \sqsubseteq (\leqslant 1 P)$
|- 
| &lt;code&gt;P rdf:type owl:InverseFunctionalProperty&lt;/code&gt; || $\forall X, Y, Z \ \big( P(X, Y) \land P(Z, Y) \Rightarrow X = Z)$ || $(\text{funct} P^− )$ or $\exists P^− (\leqslant 1 P^− )$
|- 
| &lt;code&gt;P owl:inverseOf Q&lt;/code&gt; || $\forall X, Y \ \big(P(X, Y) \Leftrightarrow Q(Y, X) \big)$ || $P \equiv Q^−$
|- 
| &lt;code&gt;P rdf:type owl:SymmetricProperty&lt;/code&gt; || $\forall X, Y \ \big(P(X, Y) \Rightarrow P(Y, X) \big)$ || $P \sqsubseteq P^−$
|}


=== [[OWL]] === 
Restrictions 

{| class=&quot;wikitable&quot;
! [[OWL]] || [[First Order Logic|FOL]] || [[Descriptive Logic|DL]]
|-
| &lt;code&gt;owl:onProperty P; owl:allValuesFrom C&lt;/code&gt; || $\forall Y \ \big(P(X, Y) \Rightarrow C(Y) \big)$ || $\forall  P.C$
|-
| &lt;code&gt;owl:onProperty P; owl:someValuesFrom C&lt;/code&gt; || $\exists Y \ \big( P(X, Y) \land C(Y) \big)$ || $\exists P.C$
|-
| &lt;code&gt;owl:onProperty P; owl:minCardinality n&lt;/code&gt; || $\exists Y_1 ... Y_n \  \big(P(X, Y_1) \land ... \land P(X, Y_n) \land [\forall i, j, i \ne j: Y_i \ne Y_j ]\big)$ || $(\geqslant n P)$ 
|-
| &lt;code&gt;owl:maxCardinality n&lt;/code&gt; || (too complex) || $(\leqslant n P)$
|}

Sets 
{| class=&quot;wikitable&quot;
! [[OWL]] || [[First Order Logic|FOL]] || [[Descriptive Logic|DL]]
|-
| &lt;code&gt;C owl:disjointWith D&lt;/code&gt; || $\forall X \ \big( C(X) \Rightarrow \lnot D(X) \big)$ || $C \sqsubseteq \lnot D$
|-
| &lt;code&gt;owl:intersectionOf (C, D...)&lt;/code&gt; || $C(X) \land D(X) \land ...$ || $C \sqcap D \ \sqcap \ ...$
|-
| &lt;code&gt;owl:unionOf ( C, D...)&lt;/code&gt; || $C(X) \lor D(X) \lor ...$ || $C \sqcup D \ \sqcup \ ...$
|-
| &lt;code&gt;owl:oneOf (e, f ...)&lt;/code&gt; || $X = e \lor X = f \ \lor ...$ || $\text{OneOf} \{e, f, ...\}$
|}


== See Also ==
* [[First Order Logic]]
* [[Descriptive Logic]]
* [[RDFS]], [[RDFS-Plus]], [[OWL]]

== Sources ==
* Web Data Management, Manolescu, Ioana, et al. [http://webdam.inria.fr/Jorge/]

[[Category:Logic]]
[[Category:Semantic Web]]</text>
      <sha1>pk1kgmgw27pvy8ix12lkffp61gi4c6r</sha1>
    </revision>
  </page>
  <page>
    <title>Semantic Web Application Architecture</title>
    <ns>0</ns>
    <id>412</id>
    <revision>
      <id>415</id>
      <timestamp>2014-05-07T18:33:30Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1629">== [[Semantic Web]] Application Architecture ==
How to use [[Semantic Web]] in your application?

Main tools:
* [[RDF]] parsers, serializers and converters 
* RDF Store (sometimes called ''Triple Store'')
* RDF Query Engine

=== Parsers &amp; Serializers ===
Parser
* RDF can be in [[XML/RDF]] or [[Turtle]] format
* Parser converts in into an [[RDF]] graph

Serializer
* does the opposite: from a graph it creates a serialized version of it


=== RDF Converters ===
Sometimes the data source is not in RDF form
* e.g. relational databases, spreadsheets 
* but also can be microformats - special attributes in HTML tags  (business cards or events)
* or RDFa - same idea, embed RDF into HTML attributes
** to have machine-processable HTML data


=== RDF Store ===
This is a database
* tuned for storing and retrieving triples 
* also should have an ability to merge information from multiple data sources (unlike [[Relational Databases]])


=== RDF Query Engine ===
Closely related to [[#RDF Store]]
* [[SPARQL]]: runs structured queries on the store to retrieve data
* SPARQL is not only a query language, but also a protocol
* so a query engine can be a web service 

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/rdf-app.png



== Libraries ==
* Sesame [http://openrdf.org] - RDF Store and QE
* SimpleNLG [https://code.google.com/p/simplenlg/] - translates RDF statements into English
** NLG - Natural Language Generation

== Sources ==
* [[Semantic Web for the Working Ontologist (book)]]
* Web Data Management, Manolescu, Ioana, et al. [http://webdam.inria.fr/Jorge/]

[[Category:Semantic Web]]</text>
      <sha1>svjm9s55xhtwq6ir7m83d3ocj9vliiw</sha1>
    </revision>
    <revision>
      <id>690</id>
      <parentid>415</parentid>
      <timestamp>2015-11-23T12:40:23Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>/* Sources */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1582">== [[Semantic Web]] Application Architecture ==
How to use [[Semantic Web]] in your application?

Main tools:
* [[RDF]] parsers, serializers and converters 
* RDF Store (sometimes called ''Triple Store'')
* RDF Query Engine

=== Parsers &amp; Serializers ===
Parser
* RDF can be in [[XML/RDF]] or [[Turtle]] format
* Parser converts in into an [[RDF]] graph

Serializer
* does the opposite: from a graph it creates a serialized version of it


=== RDF Converters ===
Sometimes the data source is not in RDF form
* e.g. relational databases, spreadsheets 
* but also can be microformats - special attributes in HTML tags  (business cards or events)
* or RDFa - same idea, embed RDF into HTML attributes
** to have machine-processable HTML data


=== RDF Store ===
This is a database
* tuned for storing and retrieving triples 
* also should have an ability to merge information from multiple data sources (unlike [[Relational Databases]])


=== RDF Query Engine ===
Closely related to [[#RDF Store]]
* [[SPARQL]]: runs structured queries on the store to retrieve data
* SPARQL is not only a query language, but also a protocol
* so a query engine can be a web service 

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/rdf-app.png



== Libraries ==
* Sesame [http://openrdf.org] - RDF Store and QE
* SimpleNLG [https://code.google.com/p/simplenlg/] - translates RDF statements into English
** NLG - Natural Language Generation

== Sources ==
* [[Semantic Web for the Working Ontologist (book)]]
* [[Web Data Management (book)]]

[[Category:Semantic Web]]</text>
      <sha1>bxlwt42n3e5jsg9dbokm79rl6ylabm6</sha1>
    </revision>
  </page>
  <page>
    <title>Ontology Based Data Access</title>
    <ns>0</ns>
    <id>413</id>
    <revision>
      <id>416</id>
      <timestamp>2014-05-07T18:42:08Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8444">== Ontology Based Data Access ==
For querying ontologies 
* typically using [[SPARQL]] 
* keep data in a db (or a [[Semantic Web Application Architecture|triple store]]), but access it via ontologies 
* as a bonus, have inference capabilities during query answering, since it's based on [[First Order Logic|Logic]]
* also useful for [[Data Integration]] 


== Query Answering ==
Difference: Ontologies and traditional [[Database]]s
* In DBMS all facts are explicit, but in [[Semantic Web]], there are [[Inference in Semantic Web|inferred]] tuples
* Constraints: can't violate in RDBMs, additional facts are inferred in SW to satisfy the constraints 


Use [[SPARQL]] for querying ontologies
* it can be translated to [[First Order Logic]] expression and [[Conjunctive Query|Conjunctive Queries]]

Example:
&lt;pre&gt;
SELECT ?x WHERE {
  ?x :EnrolledIn ?y .
  ?z :Leads ?y .
  ?z rdf:type :Professor .
}
&lt;/pre&gt;

Translation:
* [[First Order Logic|FOL]]: $Q(x) \equiv \forall x \ \exists \ y, z \ : \ \text{EnrolledIn}(x, y) \land \text{Leads}(z, y) \land \text{Professor}(z)$
* [[Conjunctive Query|CQ]]: $Q(x) \leftarrow \text{EnrolledIn}(x, y), \text{Leads}(z, y), \text{Professor}(z)$


=== Inference Approaches ===
But since the ontologies are backed by some storage,
* need to make sure that inference happens
* otherwise we will just query facts not backed by TBox of our ontology


==== Main Approaches ====
''Cached Inference'' 
* inferred triples are stored along with asserted
* risk an explosion of the triple store
* also, change management is important - how to propagate changes and deletes
* for deletes - same inferred tuple can be due to several facts, so need to be careful when deleting


''Just-In-Time Inference''
* To respond to queries only 
* no inferred triples retained


Compromise
* can be materialization of some inferences tuples 


=== Just-In-Time Inference ===
Query
* (for ABox and TBox, see [[Descriptive Logic]]) 
* using both ABox (facts - RDF graph) and TBox (rules - Ontology) 
* a triple is in an answer set either
** because it's in the ABox
** or it's a consequence of some fact from ABox inferred by the TBox

Note:
* FOL $\equiv$ [[SQL]] - undecidable for some things we want to have
* so need to have a trade off: CQs ([[Select-Project-Join Expressions]] in [[Relational Algebra]])


So, Answer set evaluation:
* consists of two phases
* query reformulation (rewriting)
** translate the original query $q$ into a set of queries $Q$
** reasoning happens here: Only TBox is accessed 
** algorithm for rewriting: [[#Perfect Rewriting]]
* query execution 
** for each $q_i \in \{ q \} \cap Q$
** execute $q_i$ against the ABox
** (simply evaluating $q$ will give us an incomplete result)

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/rewriting.png


==== Example ====
Consider this query $Q(x)$:
* $Q(x) \leftarrow \text{EnrolledIn}(x, y), \text{Leads}(z, y), \text{Professor}(z)$ can become:

Set of rules (FOL notation)
* $\text{AcademicStaff} (X) \Rightarrow \text{Staff} (X)$
* $\text{Professor}(X) \Rightarrow \text{AcademicStaff} (X)$
* $\text{Lecturer}(X) \Rightarrow \text{AcademicStaff} (X)$
* $\text{PhDStudent}(X) \Rightarrow \text{Lecturer}(X)$
* $\text{PhDStudent}(X) \Rightarrow \text{Student}(X)$
* $\text{TeachesIn}(X, Y) \Rightarrow \text{AcademicStaff}(X)$
* $\text{TeachesIn}(X, Y) \Rightarrow \text{Course}(Y)$
* $\text{ResponsibleOf} (X, Y) \Rightarrow \text{Professor}(X)$
* $\text{ResponsibleOf} (X, Y) \Rightarrow \text{Course}(Y)$
* $\text{TeachesTo}(X, Y) \Rightarrow \text{AcademicStaff} (X)$
* $\text{TeachesTo}(X, Y) \Rightarrow \text{Student}(Y)$
* $\text{Leads}(X, Y) \Rightarrow \text{AdministrativeStaff} (X)$
* $\text{Leads}(X, Y) \Rightarrow \text{Dept}(Y)$
* $\text{RegisteredIn}(X, Y) \Rightarrow \text{Student}(X)$
* $\text{RegisteredIn}(X, Y) \Rightarrow \text{Course}(Y)$
* $\text{ResponsibleOf}(X, Y) \Rightarrow \text{TeachesIn}(X, Y)$
* $\text{Professor}(X) \Rightarrow \exists Y \ : \ \text{TeachesIn}(X, Y)$
* $\text{Course}(X) \Rightarrow \exists Y \ : \ \text{RegisteredIn}(Y, X)$
* $\text{Student}(X) \Rightarrow \lnot \text{Staff} (X)$

The following are reformulations of $Q(x)$
* $q_{1}(x) \leftarrow \text{ResponsibleOf}(x,y), \text{RegisteredIn}(z,y), \text{Student}(z)$
* $q_{2}(x) \leftarrow \text{TeachesIn}(x,y), \text{RegisteredIn}(z,y), \text{PhDStudent}(z)$
* $q_{3}(x) \leftarrow \text{TeachesIn}(x,y), \text{RegisteredIn}(z,y), \text{TeachesTo}(_,z)$
* $q_{4}(x) \leftarrow \text{TeachesIn}(x,y), \text{RegisteredIn}(_,y)$
* $q_{5}(x) \leftarrow \text{ResponsibleOf}(x,y), \text{RegisteredIn}(z,y), \text{PhDStudent}(z) $
* $q_{6}(x) \leftarrow \text{ResponsibleOf}(x,y), \text{RegisteredIn}(z,y), \text{TeachesTo}(_,z)$
* $q_{7}(x) \leftarrow \text{ResponsibleOf}(x,y), \text{RegisteredIn}(_,y)$
* $q_{8}(x) \leftarrow \text{ResponsibleOf}(x,y), \text{RegisteredIn}(z,y), \text{PhDStudent}(z)$
* $q_{9}(x) \leftarrow \text{ResponsibleOf}(x,y), \text{RegisteredIn}(z,y), \text{TeachesTo}(_,z)$
* $q_{10}(x) \leftarrow \text{ResponsibleOf}(x,y), \text{RegisteredIn}(_,y)$
* $q_{11}(x) \leftarrow \text{TeachesIn}(x,y), Course(y)$
* $q_{12}(x) \leftarrow \text{TeachesIn}(x,_)$
* $q_{13}(x) \leftarrow \text{ResponsibleOf}(x,_)$
* $q_{14}(x) \leftarrow \text{Professor}(x)$

And the result is 
* union of all queries:
* $q^*(x) \leftarrow q(x) \cup q_1(x) \cup ... \cup q_{14}(x)$


==== Algorithm ====
Evaluating a query
* given a (Union of) CQs q and [[Descriptive Logic|DL]] ontology $O = \langle T, A \rangle$
* compute the perfect rewriting of $q$ over $T$
* evaluate over $A$ 


Computing the Perfect Rewriting
* start from $q$ 
* iteratively get $q'$ and collect a union of queries $\text{PR}$
* unify an atom of $q$ using inclusion
* unity an atom on $q'$ to obtain more specific CQ to expand further


Reference: 
* Web Data Management book, section 9.4
* &quot;Answering queries through DL-LITE ontologies&quot;
* 9.4.3 Answer set evaluation
* PerfectRef algorithm - page 170


== ODBA Architecture ==
https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/semantic-web-data-access.png

There are 3 main components
* [[Ontologies|Ontology]] - unified conceptual view of managed information
* Data Sources - external, possible heterogeneous
* Mappings - map data from DS to ontology


=== Formalization ===
A OBDA is $O = \langle T, S, M \rangle$ where
* $T$ - is a [[Descriptive Logic|DL]] Tbox
* $S$ - (federated) database that represents the sources
* $M$ - mapping assertions 
** each of the form $\Phi(\vec{x}) \mapsto \Psi(\vec{x})$
** $\Phi(\vec{x})$ - [[First Order Logic|FOL]] query over $S$, returns facts - values for $\vec{x}$
** $\Psi(\vec{x})$ - FOL over $T$
** so mappings from $M$ translates queries over $S$ to queries over $T$


=== Mappings ===
Mappings set $M$
* $M$ is crucial in OBDA
* it encodes how to use data from $S$ to populate elements of $T$

Mappings:
* each mapping $m \in M$ of the form $m: \Phi(\vec{x}) \mapsto \Psi(\vec{x})$
* $\Phi(\vec{x})$ - [[First Order Logic|FOL]] query over $S$, returns facts - values for $\vec{x}$
* $\Psi(\vec{x})$ - FOL over $T$
* so mappings from $M$ translates queries over $S$ to queries over $T$


Virtual Data Layer (VDL) - virtual ABox
* $S$ and $M$ define a VDL $V = M(S)$
* so, queries are answered using $T$ and $V$ 
* but we don't materialize data in $V$ - it's virtual 
* and information in $T$ and $M$ is used to translate queries over $T$ into queries over $S$
* queries over $V$ are answered in the same way: 



== ODBC in Practice ==
=== ONTOP ===
ONTOP: http://ontop.inf.unibz.it
* implements ODBA for databases in Java as a protege plugin
* Demo Video https://www.youtube.com/watch?v=KHtlARfex4c
* Download: http://ontop.inf.unibz.it/?page_id=179

ONTOP:
* Translates [[SPARQL]] to [[SQL]]
* Can work as a SPARQL endpoint
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/ontop.png
* Quest [http://ontop.inf.unibz.it/?page_id=7] is a component that does the translation


== Source ==
* Web Data Management book [http://webdam.inria.fr/Jorge]
* [[XML and Web Technologies (UFRT)]]
* [[Semantic Web for the Working Ontologist (book)]]
* Ontology-Based Data Access: From Theory to Practice (presentation) [https://www.inf.unibz.it/~calvanese/presentations/BDA-2012-obda-calvanese.pdf]
* ONTOP Demo Video [https://www.youtube.com/watch?v=KHtlARfex4c]

[[Category:Semantic Web]]</text>
      <sha1>1f7uh6552hixbeh0v1vjkyr02yuybai</sha1>
    </revision>
    <revision>
      <id>691</id>
      <parentid>416</parentid>
      <timestamp>2015-11-23T12:43:22Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8442">== Ontology Based Data Access ==
For querying ontologies 
* typically using [[SPARQL]] 
* keep data in a db (or a [[Semantic Web Application Architecture|triple store]]), but access it via ontologies 
* as a bonus, have inference capabilities during query answering, since it's based on [[First Order Logic|Logic]]
* also useful for [[Data Integration]] 


== Query Answering ==
Difference: Ontologies and traditional [[Database]]s
* In DBMS all facts are explicit, but in [[Semantic Web]], there are [[Inference in Semantic Web|inferred]] tuples
* Constraints: can't violate in RDBMs, additional facts are inferred in SW to satisfy the constraints 


Use [[SPARQL]] for querying ontologies
* it can be translated to [[First Order Logic]] expression and [[Conjunctive Query|Conjunctive Queries]]

Example:
&lt;pre&gt;
SELECT ?x WHERE {
  ?x :EnrolledIn ?y .
  ?z :Leads ?y .
  ?z rdf:type :Professor .
}
&lt;/pre&gt;

Translation:
* [[First Order Logic|FOL]]: $Q(x) \equiv \forall x \ \exists \ y, z \ : \ \text{EnrolledIn}(x, y) \land \text{Leads}(z, y) \land \text{Professor}(z)$
* [[Conjunctive Query|CQ]]: $Q(x) \leftarrow \text{EnrolledIn}(x, y), \text{Leads}(z, y), \text{Professor}(z)$


=== Inference Approaches ===
But since the ontologies are backed by some storage,
* need to make sure that inference happens
* otherwise we will just query facts not backed by TBox of our ontology


==== Main Approaches ====
''Cached Inference'' 
* inferred triples are stored along with asserted
* risk an explosion of the triple store
* also, change management is important - how to propagate changes and deletes
* for deletes - same inferred tuple can be due to several facts, so need to be careful when deleting


''Just-In-Time Inference''
* To respond to queries only 
* no inferred triples retained


Compromise
* can be materialization of some inferences tuples 


=== Just-In-Time Inference ===
Query
* (for ABox and TBox, see [[Descriptive Logic]]) 
* using both ABox (facts - RDF graph) and TBox (rules - Ontology) 
* a triple is in an answer set either
** because it's in the ABox
** or it's a consequence of some fact from ABox inferred by the TBox

Note:
* FOL $\equiv$ [[SQL]] - undecidable for some things we want to have
* so need to have a trade off: CQs ([[Select-Project-Join Expressions]] in [[Relational Algebra]])


So, Answer set evaluation:
* consists of two phases
* query reformulation (rewriting)
** translate the original query $q$ into a set of queries $Q$
** reasoning happens here: Only TBox is accessed 
** algorithm for rewriting: [[#Perfect Rewriting]]
* query execution 
** for each $q_i \in \{ q \} \cap Q$
** execute $q_i$ against the ABox
** (simply evaluating $q$ will give us an incomplete result)

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/rewriting.png


==== Example ====
Consider this query $Q(x)$:
* $Q(x) \leftarrow \text{EnrolledIn}(x, y), \text{Leads}(z, y), \text{Professor}(z)$ can become:

Set of rules (FOL notation)
* $\text{AcademicStaff} (X) \Rightarrow \text{Staff} (X)$
* $\text{Professor}(X) \Rightarrow \text{AcademicStaff} (X)$
* $\text{Lecturer}(X) \Rightarrow \text{AcademicStaff} (X)$
* $\text{PhDStudent}(X) \Rightarrow \text{Lecturer}(X)$
* $\text{PhDStudent}(X) \Rightarrow \text{Student}(X)$
* $\text{TeachesIn}(X, Y) \Rightarrow \text{AcademicStaff}(X)$
* $\text{TeachesIn}(X, Y) \Rightarrow \text{Course}(Y)$
* $\text{ResponsibleOf} (X, Y) \Rightarrow \text{Professor}(X)$
* $\text{ResponsibleOf} (X, Y) \Rightarrow \text{Course}(Y)$
* $\text{TeachesTo}(X, Y) \Rightarrow \text{AcademicStaff} (X)$
* $\text{TeachesTo}(X, Y) \Rightarrow \text{Student}(Y)$
* $\text{Leads}(X, Y) \Rightarrow \text{AdministrativeStaff} (X)$
* $\text{Leads}(X, Y) \Rightarrow \text{Dept}(Y)$
* $\text{RegisteredIn}(X, Y) \Rightarrow \text{Student}(X)$
* $\text{RegisteredIn}(X, Y) \Rightarrow \text{Course}(Y)$
* $\text{ResponsibleOf}(X, Y) \Rightarrow \text{TeachesIn}(X, Y)$
* $\text{Professor}(X) \Rightarrow \exists Y \ : \ \text{TeachesIn}(X, Y)$
* $\text{Course}(X) \Rightarrow \exists Y \ : \ \text{RegisteredIn}(Y, X)$
* $\text{Student}(X) \Rightarrow \lnot \text{Staff} (X)$

The following are reformulations of $Q(x)$
* $q_{1}(x) \leftarrow \text{ResponsibleOf}(x,y), \text{RegisteredIn}(z,y), \text{Student}(z)$
* $q_{2}(x) \leftarrow \text{TeachesIn}(x,y), \text{RegisteredIn}(z,y), \text{PhDStudent}(z)$
* $q_{3}(x) \leftarrow \text{TeachesIn}(x,y), \text{RegisteredIn}(z,y), \text{TeachesTo}(_,z)$
* $q_{4}(x) \leftarrow \text{TeachesIn}(x,y), \text{RegisteredIn}(_,y)$
* $q_{5}(x) \leftarrow \text{ResponsibleOf}(x,y), \text{RegisteredIn}(z,y), \text{PhDStudent}(z) $
* $q_{6}(x) \leftarrow \text{ResponsibleOf}(x,y), \text{RegisteredIn}(z,y), \text{TeachesTo}(_,z)$
* $q_{7}(x) \leftarrow \text{ResponsibleOf}(x,y), \text{RegisteredIn}(_,y)$
* $q_{8}(x) \leftarrow \text{ResponsibleOf}(x,y), \text{RegisteredIn}(z,y), \text{PhDStudent}(z)$
* $q_{9}(x) \leftarrow \text{ResponsibleOf}(x,y), \text{RegisteredIn}(z,y), \text{TeachesTo}(_,z)$
* $q_{10}(x) \leftarrow \text{ResponsibleOf}(x,y), \text{RegisteredIn}(_,y)$
* $q_{11}(x) \leftarrow \text{TeachesIn}(x,y), Course(y)$
* $q_{12}(x) \leftarrow \text{TeachesIn}(x,_)$
* $q_{13}(x) \leftarrow \text{ResponsibleOf}(x,_)$
* $q_{14}(x) \leftarrow \text{Professor}(x)$

And the result is 
* union of all queries:
* $q^*(x) \leftarrow q(x) \cup q_1(x) \cup ... \cup q_{14}(x)$


==== Algorithm ====
Evaluating a query
* given a (Union of) CQs q and [[Descriptive Logic|DL]] ontology $O = \langle T, A \rangle$
* compute the perfect rewriting of $q$ over $T$
* evaluate over $A$ 


Computing the Perfect Rewriting
* start from $q$ 
* iteratively get $q'$ and collect a union of queries $\text{PR}$
* unify an atom of $q$ using inclusion
* unity an atom on $q'$ to obtain more specific CQ to expand further


Reference: 
* Web Data Management book, section 9.4
* &quot;Answering queries through DL-LITE ontologies&quot;
* 9.4.3 Answer set evaluation
* PerfectRef algorithm - page 170


== ODBA Architecture ==
https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/semantic-web-data-access.png

There are 3 main components
* [[Ontologies|Ontology]] - unified conceptual view of managed information
* Data Sources - external, possible heterogeneous
* Mappings - map data from DS to ontology


=== Formalization ===
A OBDA is $O = \langle T, S, M \rangle$ where
* $T$ - is a [[Descriptive Logic|DL]] Tbox
* $S$ - (federated) database that represents the sources
* $M$ - mapping assertions 
** each of the form $\Phi(\vec{x}) \mapsto \Psi(\vec{x})$
** $\Phi(\vec{x})$ - [[First Order Logic|FOL]] query over $S$, returns facts - values for $\vec{x}$
** $\Psi(\vec{x})$ - FOL over $T$
** so mappings from $M$ translates queries over $S$ to queries over $T$


=== Mappings ===
Mappings set $M$
* $M$ is crucial in OBDA
* it encodes how to use data from $S$ to populate elements of $T$

Mappings:
* each mapping $m \in M$ of the form $m: \Phi(\vec{x}) \mapsto \Psi(\vec{x})$
* $\Phi(\vec{x})$ - [[First Order Logic|FOL]] query over $S$, returns facts - values for $\vec{x}$
* $\Psi(\vec{x})$ - FOL over $T$
* so mappings from $M$ translates queries over $S$ to queries over $T$


Virtual Data Layer (VDL) - virtual ABox
* $S$ and $M$ define a VDL $V = M(S)$
* so, queries are answered using $T$ and $V$ 
* but we don't materialize data in $V$ - it's virtual 
* and information in $T$ and $M$ is used to translate queries over $T$ into queries over $S$
* queries over $V$ are answered in the same way: 



== ODBA in Practice ==
=== ONTOP ===
ONTOP: http://ontop.inf.unibz.it
* implements ODBA for databases in Java as a protege plugin
* Demo Video https://www.youtube.com/watch?v=KHtlARfex4c
* Download: http://ontop.inf.unibz.it/?page_id=179

ONTOP:
* Translates [[SPARQL]] to [[SQL]]
* Can work as a SPARQL endpoint
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/xml/sw/ontop.png
* Quest [http://ontop.inf.unibz.it/?page_id=7] is a component that does the translation


== Source ==
* [[Web Data Management (book)]]
* [[XML and Web Technologies (UFRT)]]
* [[Semantic Web for the Working Ontologist (book)]]
* Ontology-Based Data Access: From Theory to Practice (presentation) [https://www.inf.unibz.it/~calvanese/presentations/BDA-2012-obda-calvanese.pdf]
* ONTOP Demo Video [https://www.youtube.com/watch?v=KHtlARfex4c]

[[Category:Semantic Web]]
[[Category:Databases]]</text>
      <sha1>tbydctgqklnfvkxbff73eqdkgqa5y0e</sha1>
    </revision>
  </page>
  <page>
    <title>Distribution</title>
    <ns>0</ns>
    <id>414</id>
    <redirect title="Distributions" />
    <revision>
      <id>417</id>
      <timestamp>2014-05-09T10:10:40Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27">#REDIRECT [[Distributions]]</text>
      <sha1>6u900lpeq3gdkox83o32sqyge20c8ut</sha1>
    </revision>
  </page>
  <page>
    <title>Distribution Function</title>
    <ns>0</ns>
    <id>415</id>
    <revision>
      <id>418</id>
      <timestamp>2014-05-09T10:11:03Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1644">{{stub}}

== (Cumulative) [[Distribution]] Function ==
A ''distribution function'' $F_X(x)$ (''Функция распределения'') 
* is a function that defines the [[Probability]] of a [[Random Variable]] $X$ having values less than $x$
* i.e. $F_X(x) = P(X &lt; x)$
* this, $F_X(x)$ defines the probability of $X$ taking value on the left of $x$
* for continuous - the area under the [[Probability Density Function]] from $-\infty$ to $x$
* it describes the [[Distribution]] of $X$


== Properties ==
=== Property 1: Sum of Probabilities ===
$0 \leqslant F(x) \leqslant 1$

=== Property 2: Monotonicity ===
$F_X(x)$ - monotonic non-increasing function (неубывающая)
* $\Rightarrow$ $P(a \leqslant X \leqslant b) = F_X(a) - F_X(b)$

=== Property 3 ===
if $\text{Dom}(X) = (a, b)$ (continuous)
* $F_X(x) = 0$ when $x &lt; a$
* $F_X(x) = 1$ when $x \geqslant b$


== Probability Density Function ==
A ''density'' of $F_X(x)$ is a function $f_X(x)$ s.t.
* $f_X(x) = F_X'(x)$

The probability that $X$ will take some value from interval $(a, b)$
* $P(a &lt; X &lt; b) = \int_a^b f_X(x) dx$

The cumulate distribution function $F_X(x)$ can be found by taking an integral of $f_X(x)$
* $F_X(x) = \int_{-\infty}^x f_X(x) dx$


== Sources ==
* Гмурман В.Е., Теория вероятностей и математическая статистика -- 9-е издание. М.: Высш. шк., 2003.
* http://en.wikipedia.org/wiki/Probability_distribution
* http://en.wikipedia.org/wiki/Cumulative_distribution_function
* http://en.wikipedia.org/wiki/Probability_density_function


[[Category:Probability]]
[[Category:Distributions]]</text>
      <sha1>5d4s6mekupcgdycmlzopflqzd4zm22w</sha1>
    </revision>
  </page>
  <page>
    <title>Template:TODO</title>
    <ns>10</ns>
    <id>416</id>
    <revision>
      <id>419</id>
      <timestamp>2014-05-10T08:35:55Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="37">'''TODO: {{{1}}}''' [[Category:TODO]]</text>
      <sha1>qhuwvy4eo9reertmoifwi2bbbe1e16m</sha1>
    </revision>
  </page>
  <page>
    <title>Category:TODO</title>
    <ns>14</ns>
    <id>417</id>
    <revision>
      <id>420</id>
      <timestamp>2014-05-10T08:36:47Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20">[[Category:Special]]</text>
      <sha1>ahwl2hj66q38xrcm8rca5hpr10tzxbq</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Stubs</title>
    <ns>14</ns>
    <id>418</id>
    <revision>
      <id>421</id>
      <timestamp>2014-05-10T08:37:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20">[[Category:Special]]</text>
      <sha1>ahwl2hj66q38xrcm8rca5hpr10tzxbq</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Draft</title>
    <ns>14</ns>
    <id>419</id>
    <revision>
      <id>422</id>
      <timestamp>2014-05-10T08:37:35Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20">[[Category:Special]]</text>
      <sha1>ahwl2hj66q38xrcm8rca5hpr10tzxbq</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Special</title>
    <ns>14</ns>
    <id>420</id>
    <revision>
      <id>423</id>
      <timestamp>2014-05-10T08:38:00Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16">Service category</text>
      <sha1>iaj3qsjx56p34pl78rbk5a26bcufaf8</sha1>
    </revision>
  </page>
  <page>
    <title>Data Analysis (coursera)</title>
    <ns>0</ns>
    <id>421</id>
    <revision>
      <id>424</id>
      <timestamp>2015-04-19T08:45:40Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1701">== Data Analysis (coursera) ==

Covered Topics:
* [[Data Analysis]]
* [[Simulation Basics in R]]
* [[Exploratory Data Analysis]]
* [[Cluster Analysis]]


== Links ==
=== Notes ===
Data Analysis notes by [http://rpubs.com/Felix Felix Y.H. Fan]
* https://www.google.com/search?q=%3C%3C+Data+Analysis+%3E%3E+Note+site:rpubs.com
* [http://rpubs.com/Felix/7647 Part 1]: Representing Data, [[Exploratory Data Analysis]], [[Cluster Analysis]], [[Principal Component Analysis]] and [[Singular Value Decomposition]]
* [http://rpubs.com/Felix/6705 Part 2]: [[Cluster Analysis|Clustering Example]]
* [http://rpubs.com/Felix/6706 Part 3]: [[Method of Least Squares]] and [[Linear Regression]]
* [http://rpubs.com/Felix/6708 Part 4]: [[Statistical Tests of Significance]], $P$-values
* [http://rpubs.com/Felix/6709 Part 5]: [[Multivariate Linear Regression]], regression with categorical variables
* [http://rpubs.com/Felix/7449 Part 6]: [[ANOVA]], [[Logistic Regression]], [[Poisson Regression]], [[Model Checking]], [[Model Selection]]
* [http://rpubs.com/Felix/7592 Part 7]: [[Cross-Validation]], [[Error Metrics]], predicting with linear regression and trees (decision trees)
* [http://rpubs.com/Felix/7645 Part 8]: [[Smoothing]], (Lowess (loess) ), regression with splines 
* [http://rpubs.com/Felix/7624 Part 9]: [[Bootstrap]], [[Bagging]] (Bootstrap Aggregating), [[Ensemble Learning|Ensemble Models]] (combining predictors), [[SVM]]
* [http://rpubs.com/Felix/7646 Part 10]: Multiple testing, family-wise error rate (FWER), false discovery rate (FDR),  Simulation for model checking


[[Category:Data Analysis]]
[[Category:Data Mining]]
[[Category:Machine Learning]]
[[Category:Coursera]]
[[Category:Notes]]</text>
      <sha1>kmicm67h86yzrgpqwf645ci063nzgnu</sha1>
    </revision>
  </page>
  <page>
    <title>Bar Chart</title>
    <ns>0</ns>
    <id>422</id>
    <revision>
      <id>425</id>
      <timestamp>2014-07-18T04:45:14Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2224">== Bar Chart ==
Bar Chart, or Bar Plot or Bar Graph 
* This is a [[Plot]] that can be useful for [[Exploratory Data Analysis]]
* It's a graphical representation of Frequency Tables
** It shows the values of your data set with bars
** height of the bar is proportional to the value it represents
** so the variables you plot must be [[Quantitative Variables]]


=== In [[R]] ===
To create a bar chart in R
* use &lt;code&gt;barplot&lt;/code&gt; command

&lt;pre&gt;
r = dnorm(seq(from=-3, to=3, length=15), mean=0, sd=1)
barplot(r, col=&quot;red&quot;)
&lt;/pre&gt;

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/barplot-normal.png


== Multivariate Analysis ==
Bar Charts can also be used for comparing values of two and more variables
* typically, they are graphical representation of [[Contingency Tables]]

There are the following types of bar charts:
* Side-by-side bar chart
** bars are put near each other
* Stacked (Segmented) bar chart
** shows more information than other types - the total size, the proportion, etc
* Proportional stacked bar chart
** standardized version of the stacked bar chart
** makes it easier to see the [[Joint Distribution]] of variables


In R
&lt;pre&gt;
library(openintro)
data(email)

# stacked
t = table(email$spam, email$number)
pal = c('yellow2', 'skyblue2')
barplot(t, col=pal, beside=F)

# proportional
t.prop = rbind(t[1,] / colSums(t),
               t[2,] / colSums(t))
pal = c('yellow2', 'skyblue2')
barplot(t.prop, col=pal, beside=F)

# side-by-side
barplot(t, col=pal, beside=T)
&lt;/pre&gt;

http://habrastorage.org/files/9c4/269/82b/9c426982b95f4067bd7bca7f6d8cdca0.png
http://habrastorage.org/files/859/98f/418/85998f4188884e8b8904dfaab16a3067.png
http://habrastorage.org/files/568/10c/d55/56810cd554124b3e90a5febbe4ee8ffd.png


=== [[Mosaic Plot]]s ===
They can represent the information about the distribution better than proportional bar charts
* they use areas to represent the distribution
* e.g. http://habrastorage.org/files/14f/ab1/399/14fab1399fb444f58e33a7032a6bef82.png


== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[Data Analysis (coursera)]]
* [[OpenIntro Statistics (book)]]
* http://en.wikipedia.org/wiki/Bar_chart

[[Category:Plots]]
[[Category:R]]</text>
      <sha1>54eup7h3qz68fem3as8ars74oovc84y</sha1>
    </revision>
  </page>
  <page>
    <title>Box Plot</title>
    <ns>0</ns>
    <id>423</id>
    <revision>
      <id>426</id>
      <timestamp>2014-07-18T05:10:36Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2903">== Box Plot ==
Box Plot
* This is a [[Plot]] that can be useful for [[Exploratory Data Analysis]]
* This plot is a visualization of [[Summary Statistics]]
* it's &quot;a convenient way of graphically depicting groups of numerical data through their quartiles&quot;


General idea:
* What is [[Distribution]] of data? 
** is it compact? symmetric?
* Are there [[Outliers]]?


https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/boxplot.png
* IQR = Q3 - Q1 - the length of the box
* whiskers (fences) capture data outside of the box


&lt;pre&gt;
boxplot(..., range=0, ...)
boxplot(..., horizontal=T, ...) // horizontal boxplot
&lt;/pre&gt;

&lt;code&gt;range=0&lt;/code&gt; means that it will show usual box plot.


=== Modified Box Plot ===
''Modified box plot'' can be used to show [[Outliers]]

* IQR (''Inter Quartile Range'') - difference between 3rd and 1st quartile 
* ''Inner fences'' - the values that are 1.5 times the IQR beyond the 1st and 3rd quartile 
* Lower inner fence = 1st quartile - (1.5 x IQR)
* Upper inner fence = 3rd quartile + (1.5 x IQR)
* observations beyond the whiskers (fences) are outliers and marked with dots 


https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/boxplot-modified.png

In R
* by default &lt;code&gt;boxplot&lt;/code&gt; shows modified box plot
* &lt;code&gt;IQR(data)&lt;/code&gt; shows the IQR


== [[Bivariate Analysis]] ==
We can calculate [[Summary Statistics|all 5 number]] values for all quantitative variables associated with a specific category.
* And for each category get a box plot 
* With box plots, we also can see how two values interact 
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/boxplot-bivariate.png


=== R ===
&lt;pre&gt;boxplot(d$a ~ as.factor(d$f))&lt;/pre&gt;
* it will show separate boxplot of values in $a$ for each values of $f$ 
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/boxplot-bivariate-r.png

&lt;pre&gt;
boxplot(d$a ~ as.factor(d$f), col=c(&quot;blue&quot;,&quot;orange&quot;), names=c(&quot;yes&quot;,&quot;no&quot;), varwidth=T)
&lt;/pre&gt;
* if we want to show how much data is there for each factor, 
* we can make the with of the boxes proportional to the volume of data
* using &lt;code&gt;varwidth=T&lt;/code&gt;
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/boxplot-bivariate-r2.png


== Box Plot with Other [[Plot]]s ==
Box plots are nice to combine with other plots
* for example, with a [[Scatter Plot]] 
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/b/openintrostat/scatter-plot-with-boxplot.png [http://www.statmethods.net/advgraphs/layout.html]
* [[R Visualization Snippets#Scatter Plot and Box Plots|This]] is the R snipped to produce this figure


== See Also ==
* [[R Visualization Snippets]]

== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[Data Analysis (coursera)]]
* http://en.wikipedia.org/wiki/Box_plot

[[Category:Plots]]
[[Category:R]]</text>
      <sha1>eyl67z1evvipyg9midz0ee452c9halh</sha1>
    </revision>
  </page>
  <page>
    <title>Cumulative Distribution Function</title>
    <ns>0</ns>
    <id>424</id>
    <redirect title="Distribution Function" />
    <revision>
      <id>427</id>
      <timestamp>2014-05-10T15:44:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="35">#REDIRECT [[Distribution Function]]</text>
      <sha1>isthwtoen3enp4d2wuylgcbzabw81z8</sha1>
    </revision>
  </page>
  <page>
    <title>Probability Density Function</title>
    <ns>0</ns>
    <id>425</id>
    <redirect title="Distribution Function" />
    <revision>
      <id>428</id>
      <timestamp>2014-05-10T15:45:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="64">#REDIRECT [[Distribution Function#Probability Density Function]]</text>
      <sha1>83nctfjuqd8xzff0zio7g0el5yjk8zx</sha1>
    </revision>
  </page>
  <page>
    <title>Histogram</title>
    <ns>0</ns>
    <id>426</id>
    <revision>
      <id>429</id>
      <timestamp>2014-05-10T15:46:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1962">== Histogram ==
''Histogram'' is a graphical representation of the [[Distribution]] of data
* Bins: the intervals used in a histogram. The data must be separated into mutually exclusive and exhaustive bins
* Cutpoints: the values that define the beginning and the end of the bins
* Frequency: the count of the number of the data values in each bin
* The peaks in the distribution are called ''modes''
* so the variables you plot must be [[Quantitative Variables]]

[[Probability Density Function]]
* with histogram you estimate the [[Probability Density Function]] of the underlying variable 
* Alternative - [[Density Plot]] that use [[Kernel]]s to smooth the plots 


&lt;pre&gt;hist(d$age, col=&quot;blue&quot;)&lt;/pre&gt;
* Params
** &lt;code&gt;breaks=100&lt;/code&gt; - how many bars in the histogram
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/hist-one.png
* here we have 19 bins, and two modes 



== [[Bivariate Analysis]] ==
It can also be useful for [[Exploratory Data Analysis]] of two variables 

Consider this example
* we have two classes of customers: $A$ and $B$
* and we want to build a model that can distinguish them
* so we can create a histogram that shows the distribution of age w.r.t. to class attribute
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/hist-bivariate.png
* can see that age and class are not independent: there is strong correlation between them:
** if age is lower then some value (say 30), all belong to class $A$ 
** if greater than other value - all always belong to class $B$ 
* can learn that just using a simple histogram 


== Cumulative Histogram ==
Usual histogram estimates the [[Probability Density Function]]
* Cumulative Histogram will show the [[Cumulative Distribution Function]]


== See Also ==
* [[Density Plot]]

== Sources ==
* [[Data Analysis (coursera)]]
* [[Data Mining (UFRT)]]
* [[Statistics: Making Sense of Data (coursera)]]

[[Category:Plots]]
[[Category:R]]</text>
      <sha1>tqevxxo27flg5qnxkea91txfbrxobuw</sha1>
    </revision>
  </page>
  <page>
    <title>Density Plot</title>
    <ns>0</ns>
    <id>427</id>
    <revision>
      <id>430</id>
      <timestamp>2014-05-10T15:54:36Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1267">== Density Plot ==
It's like a [[Histogram]], but smoothed out
* The smooting is done with [[Kernel]]s 
* So it's an estimation of the [[Probability Density Function]] of the underlying variable


=== With [[Histogram]] === 
&lt;pre&gt;
hist(pData$AGEP, breaks=12, col=&quot;red&quot;, prob=T)
dens = density(pData$AGEP, adjust=2) 
lines(dens, col=&quot;blue&quot;, lwd=2)
&lt;/pre&gt;
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/density-hist.png [http://stackoverflow.com/q/1497539/861423]


=== Without Histogram ===
&lt;pre&gt;
dens = density(pData$AGEP)
plot(dens, lwd=3, col=&quot;blue&quot;)
&lt;/pre&gt;

* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/density-plots.png


== Bivariate Analysis ==
* this plot can also be used with two variables
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/density-2vars.png
* it is more convenient than Histograms for doing that 
* since it uses plot, not bars

&lt;pre&gt;
densM = density(pData$AGEP[which(pData$SEX==1)])
densF = density(pData$AGEP[which(pData$SEX==2)])
plot(densM, lwd=3, col=&quot;blue&quot;)
lines(densF, lwd=3, col=&quot;orange&quot;)
&lt;/pre&gt;


== Links ==
* http://en.wikipedia.org/wiki/Density_estimation

== Sources ==
* [[Data Analysis (coursera)]]

[[Category:Plots]]
[[Category:R]]</text>
      <sha1>1cthglco7n6izbt8hfq75s8k6qm1plx</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Plots</title>
    <ns>14</ns>
    <id>428</id>
    <revision>
      <id>431</id>
      <timestamp>2014-05-10T15:55:04Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="26">[[Category:Visualization]]</text>
      <sha1>52gw8lell86r94u6bv43b2jjyepuw3l</sha1>
    </revision>
  </page>
  <page>
    <title>Scatter Plot</title>
    <ns>0</ns>
    <id>429</id>
    <revision>
      <id>432</id>
      <timestamp>2014-05-10T15:59:45Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1605">== Scatter Plot ==
This is a [[Plot]] that can be useful for [[Exploratory Data Analysis|initial]] [[Data Analysis|analysis of the data]]
* it uses Cartesian coordinates to visualize relationships between variables
* So, useful for [[Bivariate Analysis]]

&lt;pre&gt;plot(pData$JWMNP, pData$WAGP, pch=19, col=&quot;blue&quot;)&lt;/pre&gt;
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/scatter-plot-1.png



== Tips and Tricks ==
=== More Variables ===
What if we want to include one more variable?
* use color coding
* e.g. can encode sex in color

&lt;pre&gt;plot(pData$JWMNP, pData$WAGP, pch=19, col=pData$SEX, cex=0.5)&lt;/pre&gt;
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/scatter-plot-2.png


=== Lots of Data ===
How to visualize when there are many data points in your data?

&lt;pre&gt;
x = rnorm(10000)
y = rnorm(10000)
plot(x, y, pch=19)
&lt;/pre&gt;

* not very visible
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/scatter-plot-a1.png


==== [[Sampling]] ====
Sample you data
* and plot just the part

&lt;pre&gt;
sampledValues = sample(1:10000, size=1000, replace=F)
plot(x[sampledValues], y[sampledValues], pch=19)
&lt;/pre&gt;

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/scatter-plot-a2.png


==== Showing Density ====
* how to show the density of some area?
* &lt;code&gt;smoothScatter(x, y)&lt;/code&gt;
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/smooth-scatter.png


== Sources ==
* [[Data Analysis (coursera)]]
* http://en.wikipedia.org/wiki/Scatter_plot

[[Category:Plots]]
[[Category:R]]</text>
      <sha1>6dk7nl9fez2mwq2dcqzo533ywag7e8w</sha1>
    </revision>
  </page>
  <page>
    <title>Plots</title>
    <ns>0</ns>
    <id>430</id>
    <revision>
      <id>433</id>
      <timestamp>2015-04-19T10:51:56Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="603">== Plots ==
Graphical means of communicating results in [[Statistics]] and [[Data Analysis]]
* especially useful for [[Exploratory Data Analysis]]


== Plots ==
Why plots?
* To understand data
* Discover patterns 
* Communicate Results 

Types
* [[Bar Chart]]s
* [[Mosaic Plot]]s
* [[Box Plot]]s
* [[Pie Chart]]s
* [[Histogram]]s
* [[Density Plot]]s
* [[Scatter Plot]]s
* [[Dot Plot]]s
* [[Q-Q Plot]]s

== See Also ==
* [[R Visualization Snippets]]


== Sources ==
* [[Data Analysis (coursera)]]
* [[OpenIntro Statistics (book)]]

[[Category:Plots]]
[[Category:Visualization]]
[[Category:Data Analysis]]</text>
      <sha1>pr1z5ejym646hfhuiyx8vaujyj6txgi</sha1>
    </revision>
  </page>
  <page>
    <title>Simulation Basics in R</title>
    <ns>0</ns>
    <id>431</id>
    <revision>
      <id>434</id>
      <timestamp>2015-04-19T11:01:42Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3738">== Simulation in R ==

=== [[Distributions]] ===
{| class=&quot;wikitable&quot;
! Name || [[Distribution Function|Function]] || [[Probability Density Function|Density]]
|-
| || &lt;code&gt;rbeta&lt;/code&gt; || &lt;code&gt;dbeta&lt;/code&gt;
|-
| [[Binomial Distribution]] || &lt;code&gt;rbinom&lt;/code&gt; || &lt;code&gt;dbinom&lt;/code&gt;
|-
| || &lt;code&gt;rcauchy&lt;/code&gt; || &lt;code&gt;dcauchy&lt;/code&gt;
|-
| || &lt;code&gt;rchisq&lt;/code&gt; || &lt;code&gt;dchisq&lt;/code&gt;
|-
| || &lt;code&gt;rexp&lt;/code&gt; || &lt;code&gt;dexp&lt;/code&gt;
|-
| || &lt;code&gt;rf&lt;/code&gt; || &lt;code&gt;df&lt;/code&gt;
|-
| || &lt;code&gt;rgamma&lt;/code&gt; || &lt;code&gt;dgamma&lt;/code&gt;
|-
| || &lt;code&gt;rgeom&lt;/code&gt; || &lt;code&gt;dgeom&lt;/code&gt;
|-
| || &lt;code&gt;rhyper&lt;/code&gt; || &lt;code&gt;dhyper&lt;/code&gt;
|-
| || &lt;code&gt;rlogis&lt;/code&gt; || &lt;code&gt;dlogis&lt;/code&gt;
|-
| || &lt;code&gt;rlnorm&lt;/code&gt; || &lt;code&gt;dlnorm&lt;/code&gt;
|-
| || &lt;code&gt;rnbinom&lt;/code&gt; || &lt;code&gt;dnbinom&lt;/code&gt;
|-
| [[Normal Distribution]] || &lt;code&gt;rnorm&lt;/code&gt; || &lt;code&gt;dnorm&lt;/code&gt;
|-
| || &lt;code&gt;rpois&lt;/code&gt; || &lt;code&gt;dpois&lt;/code&gt;
|-
| || &lt;code&gt;rt&lt;/code&gt; || &lt;code&gt;dt&lt;/code&gt;
|-
| [[Uniform Distribution]] || &lt;code&gt;runif&lt;/code&gt; || &lt;code&gt;dunif&lt;/code&gt;
|-
| || &lt;code&gt;rweibull&lt;/code&gt; || &lt;code&gt;dweibull&lt;/code&gt;
|}


=== r&lt;code&gt;name&lt;/code&gt;: [[Distribution Function]] ===
Generates 10 random values from [[Normal Distribution]]
* with standard deviation 3 and mean 188


&lt;pre&gt;
heights = rnorm(10, mean=188, sd=3)
&gt; 186.0 191.2 187.6 187.9 186.6 187.2 187.2 189.5 190.8 186.4
&lt;/pre&gt;


Generates 10 random values from [[Binomial Distribution]]
* flipping a coin 10 times:
* of 10 independent experiments with probability 0.5

&lt;pre&gt;
coinFlips = rbinom(10,size=10,prob=0.5)
&gt; 3 4 6 5 7 6 5 8 5 6
&lt;/pre&gt;


=== d&lt;code&gt;name&lt;/code&gt;: [[Probability Density Function]] ===
Calculates the density of some probability distribution
&lt;pre&gt;
x = seq(from=-5, to=5, length=10)
normalDensity = dnorm(x, mean=0, sd=1)
round(normalDensity, 2)
[1] 0.00 0.00 0.01 0.10 0.34 0.34 0.10 0.01 0.00 0.00
&lt;/pre&gt;

same with 15 :
&lt;pre&gt;
x = seq(from=-3, to=3, length=15)
normalDensity = dnorm(x, mean=0, sd=1)
r = round(normalDensity, 2)
bp = barplot(r)
xspline(x=bp, y=r, lwd=2, shape=1, border=&quot;blue&quot;)
text(x=bp, y=r+0.03, labels=as.character(r), xpd=TRUE, cex=0.7)
&lt;/pre&gt;
Code [http://stackoverflow.com/a/14264451/861423] [https://stat.ethz.ch/pipermail/r-help/2003-November/041967.html]

So we can see that it generates the values of the density function
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/normal-density.png 
* may be useful for [[Statistical Tests of Significance]]


Same for the Binomial distribution:

&lt;pre&gt;
x = seq(0,10,by=1)
binomialDensity = dbinom(x,size=10,prob=0.5)
round(binomialDensity,2)
&lt;/pre&gt;



== [[Sampling]] ==
Function &lt;code&gt;sample&lt;/code&gt; draws a random sample 
* &lt;code&gt;function(x, size, replace= FALSE, prob = NULL) &lt;/code&gt;
* &lt;code&gt;replace = T&lt;/code&gt; for sampling with replacement

&lt;pre&gt;
s = seq(0, 20)
&gt; 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20
sample(s, size=10)
&gt; 8  4 11 12 20  7 19 18  1 14
sample(s, size=10, replace=T)
&gt; 6 17 18  7  2  9 18  0  7  5
&lt;/pre&gt;
Note that 7 and 18 are selected twice for the sample with replacement


The sample can be draw with specified probability 
* e.g. suppose we want to sample with normal distribution


&lt;pre&gt;
dnorm(seq(-3, 3, length=length(s)))
sample(s, size=10, replace=T, prob=n)
&gt; 9  7 11 11  1 13 11 14  5  6 
&lt;/pre&gt;

* note that 11 gets selected 3 times,
* because the probability of selecting it is quite high: 0.3989


== Reproducibility ==
When we experiment, we typically want to reproduce it later
* so it's important to generate the same &quot;random&quot; data
* for that we can set the seed for PRG
* &lt;code&gt;set.seed(12345)&lt;/code&gt;


== Source ==
* [[Data Analysis (coursera)]]

[[Category:Statistics]]
[[Category:R]]
[[Category:Distributions]]
[[Category:Simulations]]</text>
      <sha1>2wde4yzjdifbttbz1vyxpcek9z1f0eg</sha1>
    </revision>
    <revision>
      <id>673</id>
      <parentid>434</parentid>
      <timestamp>2015-11-18T07:23:47Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5164">== Simulation in R ==

=== [[Distributions]] ===
{| class=&quot;wikitable&quot;
! Name || [[Random Number Generator|RNG]] || [[Probability Density Function|PDF]] || [[Cumulative Distribution Function|CDF]]
|-
| [[Beta Distribution]] || &lt;code&gt;rbeta&lt;/code&gt; || &lt;code&gt;dbeta&lt;/code&gt; || &lt;code&gt;pbeta&lt;/code&gt;
|-
| [[Binomial Distribution]] || &lt;code&gt;rbinom&lt;/code&gt; || &lt;code&gt;dbinom&lt;/code&gt; || &lt;code&gt;pbinom&lt;/code&gt;
|-
| [[Cauchy Distribution]] || &lt;code&gt;rcauchy&lt;/code&gt; || &lt;code&gt;dcauchy&lt;/code&gt; || &lt;code&gt;pcauchy&lt;/code&gt;
|-
| [[Chi-Squared Distribution|$\chi^2$ Distribution]] || &lt;code&gt;rchisq&lt;/code&gt; || &lt;code&gt;dchisq&lt;/code&gt; || &lt;code&gt;pchisq&lt;/code&gt;
|-
| [[Exponential Distribution]] || &lt;code&gt;rexp&lt;/code&gt; || &lt;code&gt;dexp&lt;/code&gt; || &lt;code&gt;pexp&lt;/code&gt;
|-
| [[F Distribution]] || &lt;code&gt;rf&lt;/code&gt; || &lt;code&gt;df&lt;/code&gt; || &lt;code&gt;pf&lt;/code&gt;
|-
| [[Gamma Distribution]] || &lt;code&gt;rgamma&lt;/code&gt; || &lt;code&gt;dgamma&lt;/code&gt; || &lt;code&gt;pgamma&lt;/code&gt;
|-
| [[Geometric Distribution]] || &lt;code&gt;rgeom&lt;/code&gt; || &lt;code&gt;dgeom&lt;/code&gt; || &lt;code&gt;pgeom&lt;/code&gt;
|-
| [[Hypergeometric Distribution]] || &lt;code&gt;rhyper&lt;/code&gt; || &lt;code&gt;dhyper&lt;/code&gt; || &lt;code&gt;phyper&lt;/code&gt;
|-
| [[Logistic Distribution]] || &lt;code&gt;rlogis&lt;/code&gt; || &lt;code&gt;dlogis&lt;/code&gt; || &lt;code&gt;plogis&lt;/code&gt;
|-
| [[Log Normal Distribution]] || &lt;code&gt;rlnorm&lt;/code&gt; || &lt;code&gt;dlnorm&lt;/code&gt; || &lt;code&gt;plnorm&lt;/code&gt;
|-
| [[Negative Binomial Distribution]] || &lt;code&gt;rnbinom&lt;/code&gt; || &lt;code&gt;dnbinom&lt;/code&gt; || &lt;code&gt;pnbinom&lt;/code&gt;
|-
| [[Normal Distribution]] || &lt;code&gt;rnorm&lt;/code&gt; || &lt;code&gt;dnorm&lt;/code&gt; || &lt;code&gt;pnorm&lt;/code&gt;
|-
| [[Poisson Distribution]] || &lt;code&gt;rpois&lt;/code&gt; || &lt;code&gt;dpois&lt;/code&gt; || &lt;code&gt;ppois&lt;/code&gt;
|-
| [[t Distribution|$t$ Distribution]] || &lt;code&gt;rt&lt;/code&gt; || &lt;code&gt;dt&lt;/code&gt; || &lt;code&gt;pt&lt;/code&gt;
|-
| [[Uniform Distribution]] || &lt;code&gt;runif&lt;/code&gt; || &lt;code&gt;dunif&lt;/code&gt; || &lt;code&gt;punif&lt;/code&gt;
|-
| [[Weibull Distribution]] || &lt;code&gt;rweibull&lt;/code&gt; || &lt;code&gt;dweibull&lt;/code&gt; || &lt;code&gt;pweibull&lt;/code&gt;
|}


=== r&lt;code&gt;name&lt;/code&gt;: [[Random Number Generator]] ===
Example 1
* Generate 10 random values from [[Normal Distribution]]
* with standard deviation 3 and mean 188

&lt;pre&gt;
heights = rnorm(10, mean=188, sd=3)
&gt; 186.0 191.2 187.6 187.9 186.6 187.2 187.2 189.5 190.8 186.4
&lt;/pre&gt;


Example 2
* Generates 10 random values from [[Binomial Distribution]]
* flipping a coin 10 times = 10 independent experiments with probability 0.5

&lt;pre&gt;
coinFlips = rbinom(10, size=10, prob=0.5)
&gt; 3 4 6 5 7 6 5 8 5 6
&lt;/pre&gt;


=== d&lt;code&gt;name&lt;/code&gt;: [[Probability Density Function]] ===
Calculates the density of some probability distribution
&lt;pre&gt;
x = seq(from=-5, to=5, length=10)
normalDensity = dnorm(x, mean=0, sd=1)
round(normalDensity, 2)
[1] 0.00 0.00 0.01 0.10 0.34 0.34 0.10 0.01 0.00 0.00
&lt;/pre&gt;

Same with 15 :
&lt;pre&gt;
x = seq(from=-3, to=3, length=15)
normalDensity = dnorm(x, mean=0, sd=1)
r = round(normalDensity, 2)
bp = barplot(r)
xspline(x=bp, y=r, lwd=2, shape=1, border=&quot;blue&quot;)
text(x=bp, y=r+0.03, labels=as.character(r), xpd=TRUE, cex=0.7)
&lt;/pre&gt;
Code [http://stackoverflow.com/a/14264451/861423] [https://stat.ethz.ch/pipermail/r-help/2003-November/041967.html]

So we can see that it generates the values of the density function
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/normal-density.png 
* may be useful for [[Statistical Tests of Significance]]


Same for the Binomial distribution:

&lt;pre&gt;
x = seq(0, 10, by=1)
binomialDensity = dbinom(x, size=10, prob=0.5)
round(binomialDensity,2)
&lt;/pre&gt;


=== p&lt;code&gt;name&lt;/code&gt;: [[Cumulative Distribution Function]] ===
When you need to know what is the probability of $X \geqslant x$ for some $x$. 

For example, you're doing an [[F-Test|$F$-Test]] 
* you obtained $F = 3.446$
* $F$ statistic follows the [[F Distribution|$F$ Distribution]]: $F \sim F(\text{df1}, \text{df2})$
* so you can calculate the $p$-value:

 1 - pf(3.446, df1=1, df2=85)


== [[Sampling]] ==
Function &lt;code&gt;sample&lt;/code&gt; draws a random sample 
* &lt;code&gt;function(x, size, replace=FALSE, prob=NULL) &lt;/code&gt;
* &lt;code&gt;replace=T&lt;/code&gt; for sampling with replacement

&lt;pre&gt;
s = seq(0, 20)
&gt; 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20
sample(s, size=10)
&gt; 8  4 11 12 20  7 19 18  1 14
sample(s, size=10, replace=T)
&gt; 6 17 18  7  2  9 18  0  7  5
&lt;/pre&gt;
Note that 7 and 18 are selected twice for the sample with replacement


The sample can be draw with specified probability 
* e.g. suppose we want to sample with normal distribution


&lt;pre&gt;
dnorm(seq(-3, 3, length=length(s)))
sample(s, size=10, replace=T, prob=n)
&gt; 9  7 11 11  1 13 11 14  5  6 
&lt;/pre&gt;

* note that 11 gets selected 3 times,
* because the probability of selecting it is quite high: 0.3989


=== [[Bootstrapping]] ===
It is very useful for [[Bootstrapping]]

 reps = 1000
 n = length(data)
 sampl = sample(data, size=n)
 bs = replicate(reps, mean(sample(sampl, size=n, replace=T)))



== Reproducibility ==
When we experiment, we typically want to reproduce it later
* so it's important to generate the same &quot;random&quot; data
* for that we can set the seed for PRG
* &lt;code&gt;set.seed(12345)&lt;/code&gt;


== Source ==
* [[Data Analysis (coursera)]]

[[Category:Statistics]]
[[Category:R]]
[[Category:Distributions]]
[[Category:Simulations]]</text>
      <sha1>5i1ewmzeqrfu3fwochxbmmkqi7dlz28</sha1>
    </revision>
  </page>
  <page>
    <title>Normalization</title>
    <ns>0</ns>
    <id>432</id>
    <redirect title="Feature Normalization" />
    <revision>
      <id>435</id>
      <timestamp>2014-05-10T16:37:51Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="54">#перенаправление [[Data Normalization]]</text>
      <sha1>i8rmp0e1siu8pz77dh9r8p7meww3voq</sha1>
    </revision>
    <revision>
      <id>701</id>
      <parentid>435</parentid>
      <timestamp>2015-11-23T13:32:30Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Redirected page to [[Feature Normalization]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="35">#REDIRECT [[Feature Normalization]]</text>
      <sha1>hjvibnq48frsh31oounip1warbupgmd</sha1>
    </revision>
  </page>
  <page>
    <title>Data Mining (UFRT)</title>
    <ns>0</ns>
    <id>433</id>
    <revision>
      <id>436</id>
      <timestamp>2015-04-19T08:00:59Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1477">Taught by
* Giacometti Arnaud
* Soulet Arnaud
* Li Dominique


=== [[Data Mining]] ===
[[CRISP-DM|Data Mining Process]]

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/datamining-process.png


Data Understanding 
* [[Univariate Analysis]] - to analyze how variable values behave in isolation
* [[Bivariate Analysis]] - to analyze how two variables interact
* [[Exploratory Data Analysis]] - to analyze data mostly using [[Plots]]

Data Preparation
* [[Data Cleaning]]
* [[Data Transformation]]
* [[Data Reduction]]


Data Modeling
* [[Decision Tree (Data Mining)]]
** [[Cost-Complexity Pruning]]
** [[Information Gain]]  


Evaluation
* [[Evaluation of Binary Classifiers]]
* [[Cost Matrix]]
* Evaluation of Ranking Models: [[Rank Correlation]]
* [[True Error of Model]]
* [[Comparing Learning Algorithms]]
* [[ROC Analysis]]
* [[Cumulative Gain Chart]]



=== Types of Data Mining ===
=== [[Rule Mining]] ===
[[Local Pattern Discovery]]
* [[Frequent Pattern Mining]]
** [[Apriori]] and [[Eclat]] algorithms for that 
* [[Association Rule Mining]]
* [[Constraint-Based Pattern Mining]]

Sequence Mining:
* [[Sequential Pattern Mining]]

=== Others ===
* [[Graph Mining]] and Social Network Mining
* [[Cluster Analysis]]


=== Past Exams ===
* [https://docs.google.com/document/d/1oCsc1BPzG_ubal_tSoKEF-dWq79wCxvUDE8Ht2WnrJQ/pub IT4BI 2013 KDDM Exam] 


[[Category:Data Mining]]
[[Category:Machine Learning]]
[[Category:IT4BI]]
[[Category:Notes]]</text>
      <sha1>t3agpjcn1jmzvp70kswo95802r9fnqp</sha1>
    </revision>
  </page>
  <page>
    <title>Data Sources</title>
    <ns>0</ns>
    <id>434</id>
    <revision>
      <id>437</id>
      <timestamp>2014-05-11T20:50:16Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="982">== Data Sources ==
Good sources for [[Data Analysis]] and [[Data Mining]]

Open Government Data
* http://www.data.gov/ USA
* http://www.data.gouv.fr/ France
* http://data.gov.uk/ UK

Other sources:
* http://www.gapminder.org/ Public Health
* http://www.asdfree.com/ US surveys data
* http://www.infochimps.com/marketplace
* http://www.kaggle.com/


Football:
* {{TODO|share from yadisk/dropbox}}


=== Links with Links ===
Also: Data Repositories
* http://bitly.com/bundles/hmason/1 Hilary Mason's research data
* http://snap.stanford.edu/data/ Stanford Large Network Dataset Collection
* http://archive.ics.uci.edu/ml/ UCI Machine Learning Repository
* http://www.kdnuggets.com/datasets/index.html Datasets for Data Mining and Data Science
* http://lib.stat.cmu.edu/datasets/
* http://www.ncbi.nlm.nih.gov/geo/ a public functional genomics data repository
* http://arxiv.org/help/bulk_data - data from arxiv 


== Source ==
* [[Data Analysis (coursera)]]

[[Category:Ссылки]]</text>
      <sha1>0t7x3vgru6so5lqsq0g8lm2hfwsw86s</sha1>
    </revision>
  </page>
  <page>
    <title>Summarizing Data</title>
    <ns>0</ns>
    <id>435</id>
    <revision>
      <id>438</id>
      <timestamp>2014-05-11T20:50:59Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1458">== Summarizing Data ==
Before we do any [[Data Analysis]], need to see if data is good 

Why?
* Data too big to look at 
* Need to find problems before analyzing


Problems:
* Missing values
* Values outside of expected ranges
* Values that seem to be in the wrong units
* Mislabeled variables/columns
* Variables that are the wrong class


== Summarizing Data in R ==
[[Summary Statistics]]
* &lt;code&gt;summary(x)&lt;/code&gt; - summarizes all quantitative and qualitative  variables
* &lt;code&gt;quantile(x)&lt;/code&gt; - range of variables

&lt;code&gt;sapply(x[1, ], class)&lt;/code&gt;
* calls &lt;code&gt;class&lt;/code&gt; for every element of the 1st row
* tells if data was loaded properly

&lt;code&gt;names(x)&lt;/code&gt;
* columns' names

Sizes:
* &lt;code&gt;dim(x)&lt;/code&gt; - size of the dataset
* same as &lt;code&gt;nrow(x)&lt;/code&gt; and &lt;code&gt;ncol(x)&lt;/code&gt;
* length(x) and unique(x)

tables
* &lt;code&gt;table(x)&lt;/code&gt; - unique + counter
* &lt;code&gt;table(x, y)&lt;/code&gt; - two-dimensional table


logical tests
* any(x &gt; 10) - are there any TRUEs?
* all(x &gt; 10) - are all trues?
* which(x &gt; 10) - which elements are TRUEs?
* which(is.na(x)) - which are NAs
* use &lt;code&gt;!&lt;/code&gt; not, &lt;code&gt;&amp;&lt;/code&gt; and, &lt;code&gt;|&lt;/code&gt; or: 
** &lt;code&gt;which(!is.na(x) &amp; x &gt; 10)&lt;/code&gt;
* &lt;code&gt;sum(is.na(x))&lt;/code&gt; - how many NAs


summarizing by columns or rows
* &lt;code&gt;rowSums&lt;/code&gt;, &lt;code&gt;rowMeans&lt;/code&gt;
* &lt;code&gt;colSums&lt;/code&gt;, &lt;code&gt;colMeans&lt;/code&gt;


== Source ==
* [[Data Analysis (coursera)]]

[[Category:R]]
[[Category:Data Analysis]]</text>
      <sha1>o3o14qwssh8sej4nf1xjh5kck6cg1lo</sha1>
    </revision>
  </page>
  <page>
    <title>Univariate Analysis</title>
    <ns>0</ns>
    <id>436</id>
    <revision>
      <id>439</id>
      <timestamp>2014-05-11T20:53:52Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="830">== Univariate Analysis ==
Analysis (mostly [[Exploratory Data Analysis|exploratory]]) of one variable
* order of magnitude of this variable
* are there missing values?
* [[Outliers]] and extreme values?


In order to analyze one variable 
* Calculate [[Summary Statistics]]
* Also can calculate [[Mean]] and [[Standard Deviation]]
* Use [[Histogram]]s to learn about data [[Distribution]]


Results can be used for
* deciding how to [[Data Discretization|discretize]] this variable 
* [[Handling Missing Values]]
* [[Noise Handling (Data Mining)]]


== Visualization ==
[[Plots]] that can be useful:
* [[Bar Chart]]s
* [[Box Plot]]s for visualizing [[Summary Statistics]]
* [[Histogram]]s and [[Density Plot]]s


== Sources ==
* [[Data Mining (UFRT)]]
* http://en.wikipedia.org/wiki/Univariate_analysis

[[Category:Data Analysis]]</text>
      <sha1>32azceyb05kwjv6j1sf6rc9ihziwywx</sha1>
    </revision>
  </page>
  <page>
    <title>Bivariate Analysis</title>
    <ns>0</ns>
    <id>437</id>
    <revision>
      <id>440</id>
      <timestamp>2015-04-19T11:12:21Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2257">== Bivariate Analysis ==
Analyzes relationships between two variables 

Recall that there are the following [[Types of Variables]]
* [[Categorical Variables]] - values that can be organized into categories (not numerical)
* [[Quantitative Variables]] -  with numerical values for which arithmetic operation make sense

So there can be the following combinations:
* Quantitative vs Quantitative
* Quantitative vs Categorical
* Categorical vs Categorical

=== Independence ===
typically most interesting question is:
* &quot;Are these variables independent&quot;?
* if they are dependent and correlated, then one variable can be redundant
* and can be [[Data Reduction|removed]]


== Quantitative vs Quantitative ==
If two variables are numeric:
* plot a [[Scatter Plot]]
* try to fit a [[Linear Regression|regression line]] 
* and find [[Correlation]] between them 
* or [[Data Discretization|Discretize]] one of them and do [[#Quantitative vs Categorical]] analysis


== Quantitative vs Categorical ==
If one is numeric, and another is categorical:
* Visualize one variable w.r.t. another
** typically group values of numerical variable by the values of categorical
** [[Box Plot#Bivariate Analysis]]
** [[Bar Chart#Bivariate Analysis]]
** [[Histogram#Bivariate Analysis]]
** [[Density Plot#Bivariate Analysis]]
* Can do [[One-Way ANOVA F-Test]] to see if there is any dependence between the variables


== Categorical vs Categorical ==
To compare two categorical variables
* start from building a [[Contingency Table]] to show relative frequencies of values
** ''Marginal distribution'' - distribution of only one of the variables in a contingency table
** ''Conditional Distribution'' - distribution within a fixed value of a second variable
** so it's simple to see if there's any correlation between the two variables just using this matrix
* run some Tests of Independence:
** [[Chi-square Test of Independence]]
** and [[Cramer's Coefficient]]


== Links ==
* http://en.wikipedia.org/wiki/Bivariate_analysis
* [http://dept.stat.lsa.umich.edu/~kshedden/Courses/Stat401/Notes/401-bivariate-slides.pdf Introduction to Bivariate Analysis (slides)]

== Sources ==
* [[Data Mining (UFRT)]]
* [[Statistics: Making Sense of Data (coursera)]]

[[Category:Data Analysis]]</text>
      <sha1>eeomzk9axfl99in5kgptweud3p5gjno</sha1>
    </revision>
  </page>
  <page>
    <title>Data Cleaning</title>
    <ns>0</ns>
    <id>438</id>
    <revision>
      <id>441</id>
      <timestamp>2014-05-11T21:47:34Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1039">== Data Cleaning ==
There can be several problems with data 
* Missing values - NAs, NULLs, empty or blank values
* Outliers - extreme values
* Noise in data - modifications of the original value, hard to detect
* Duplicates 


== Main Problems and Tools ==
=== [[Handling Missing Values]] ===
There are several approaches
* radical: ignore row/column
* fill with default value or mean 
* build a [[Machine Learning]] model to predict missing values


=== Outliers Detection ===
Outliers are extreme values in the data
* can influence your models, e.g. [[Linear Regression]]
* so it's a good idea to detect them
* use [[Anomaly Detection]] techniques for that


=== [[Noise Handling (Data Mining)|Handling Noise]] ===
noise - modification of an original value
* very hard to detect - because noisy data looks like real data


=== [[Duplicate Detection]] ===
Duplicate Data: major issue when you merge data from different sources


== See Also ==
* [[Data Transformation]]

== Sources ==
* [[Data Mining (UFRT)]]

[[Category:Data Cleaning]]</text>
      <sha1>3gsmlb8zfud240vm0vx2qrgiwcviolu</sha1>
    </revision>
  </page>
  <page>
    <title>Handling Missing Values</title>
    <ns>0</ns>
    <id>439</id>
    <revision>
      <id>442</id>
      <timestamp>2014-05-11T21:48:14Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="648">== Handling Missing Values ==
Missing Values 

Reasons for missing values 
* Information is not collected (age of a person) 
* Attributes may be not applicable to all cases (income of a child) 


Handling
* radical
** eliminate the variable (column)
** eliminate the object (row)
* fix
** use some constant to fill in the missing values
* estimate 
** replace with the [[Mean]] value
** predict - build some [[Machine Learning]] model to predict missing values 


== Sources ==
* [[Data Mining (UFRT)]]
* http://www.developerzen.com/2009/08/14/data-mining-handling-missing-values-the-database/

[[Category:Data Cleaning]]
[[Category:Data Analysis]]</text>
      <sha1>b5nh19br5hnpk9uumasceph55z3ta47</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Data Cleaning</title>
    <ns>14</ns>
    <id>440</id>
    <revision>
      <id>443</id>
      <timestamp>2014-05-11T21:48:44Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="26">[[Category:Data Analysis]]</text>
      <sha1>by84o9j9axrdb25mr6e2havt9web9vs</sha1>
    </revision>
  </page>
  <page>
    <title>Decision Tree</title>
    <ns>0</ns>
    <id>441</id>
    <revision>
      <id>444</id>
      <timestamp>2014-05-12T09:19:04Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="569">There are two types of Decision Trees:
* [[Decision Tree (Decision Theory)]]
* [[Decision Tree (Data Mining)]]


In [[Decision Analysis]], [[Decision Tree (Decision Theory)|decision trees]] are used 
* to visually and explicitly represent decisions and decision making. 


In [[Data Mining]], 
* a [[Decision Tree (Data Mining)|decision tree]] describes data but not decisions; 
* and the resulting classification tree can be an input for decision making


== Sources ==
* http://en.wikipedia.org/wiki/Decision_tree_learning
* http://en.wikipedia.org/wiki/Decision_tree</text>
      <sha1>seyqcjiqpmqhmyim3orn7keyovcahmx</sha1>
    </revision>
  </page>
  <page>
    <title>CRISP-DM</title>
    <ns>0</ns>
    <id>442</id>
    <revision>
      <id>445</id>
      <timestamp>2014-05-12T09:27:15Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2398">== Data Mining Process ==
CRISP-DM [http://en.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining]
* CRISP-DM (CRoss Industry Standard Process for Data Mining)
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/datamining-process.png
* there are 6 steps 

CRISP-DM: four levels of abstraction 
* Phases 
** Example: Data Preparation 
* Generic Tasks 
** A stable, general and complete set of tasks 
** Example: [[Data Cleaning ]]
* Specialized Task
** A specific task that belongs to a generic task 
** Example: Missing Value Handling 
* Process Instance 
** How a specific task is carried out?
** Example: The mean value for numeric attributes and the most frequent for categorical attributes


=== Business Understanding ===
Main Objectives 
* Define the success criteria 
* Forms of output?
* How to integrate the output with existing technologies?


=== Data Understanding ===
Main Objectives 
* Collect the data
** What are the data sources? 
** a lot of links at [[Data Sources]]
* [[Summarizing Data]]: First Look at the Data
* [[Exploratory Data Analysis]]
** building simple data [[Plots]] ([[Histogram]]s, etc)
** to help to understand the [[Distribution]] of data
* [[Univariate Analysis]] - to analyze how variable values behave in isolation
* [[Bivariate Analysis]] - to analyze how two variables interact


=== Data Preparation ===
Need to prepare data so it can be processed by Models
* [[Data Cleaning]] - [[Handling Noise]], [[Anomaly Detection]], [[Duplicate Detection]], etc
* [[Data Transformation]] - [[Data Normalization]], [[Data Discretization]]
* [[Data Reduction]]


=== Modeling ===
Prediction Tasks 
* models to predict unknown or future values
* Classification Models: predict a categorical value
* Regression Models: predict a continuous value

Description Tasks
* Goal: find patterns / clusters that describe a data set 
* [[Cluster Analysis]]: find clusters in data
* Extraction of local patterns: find local properties in a data set 


=== Evaluation ===
Main Questions 
* How to evaluate a method? - [[Error Analysis]]
* How to compare different models that solve same problem? - [[Cross-Validation]] and 

Objective Measures:
* Error rate of a classifier - [[Error Metrics]]
* Conference of associative rules 

Subjective Measures:
* [[Visualization]]


== Sources ==
* [[Data Mining (UFRT)]]

[[Category:Data Mining]]</text>
      <sha1>fvo6o1ypct6nky76cdiaytkwycqymux</sha1>
    </revision>
  </page>
  <page>
    <title>Data Transformation</title>
    <ns>0</ns>
    <id>443</id>
    <revision>
      <id>446</id>
      <timestamp>2014-05-12T09:27:57Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1074">== Data Transformation ==
Main Tasks 
* [[Data Normalization]] to normalize all data values to the same scale
* [[Data Discretization]] to convert numerical attributes to categorical
* Aggregation - to pre-aggregate the data so it's on the needed level of granularity
* Generalization 


== [[Data Warehousing]] ==
Data Transformation is the first part of [[ETL]]
* also you typically [[Data Integration|integrate data]] from different sources
* so also need to apply some transformations

=== Data Aggregation ===
With [[OLAP]] operations (in the context of a data cube) 
* Use the highest level / smallest representation which is enough to solve the task
* Example: use the total number of products sold by category and month, rather by product-id and day


=== Data Generalization ===
By replacing low-level values by higher level abstractions 
* By replacing a complete postal address of a customer by a zip-code 
* By replacing the age of a customer by a value in { young, middleaged, senior } 


== Sources ==
* [[Data Mining (UFRT)]]

[[Category:Data Transformation]]</text>
      <sha1>kr2pyh417gf6nw9qdbgxim6tgt03c2a</sha1>
    </revision>
  </page>
  <page>
    <title>Data Discretization</title>
    <ns>0</ns>
    <id>444</id>
    <revision>
      <id>447</id>
      <timestamp>2014-05-12T09:28:42Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1261">== Data Discretization ==
What if we want to [[Data Transformation|transform]] a continuous attribute to a categorical?


== Equal-Width Partitioning ==
Also called ''distance partitioning''
* want to divide $X = (x_1, ..., x_m)$ into $N$ equal intervals
* let $A = \min X$ and $B = \max X$
* width: $W = \cfrac{B - A}{N}$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/discretization-equal-width.png
* suppose that in one such partition you have all your data
* you'll lose a lot of information
* so it's sensible to [[Outliers]]


== Equal-Depth Partitioning ==
Also called ''frequency partitioning'' 
* Divides $X$ into $N$ intervals, 
* with each interval containing approximately same number of samples
* not sensible to outliers
* distribution of values is taken into account
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/discretization-equal-depth.png


== Entropy-Based Discretization ==
Uses entropy to find the best way to split your data 
* find the value $\alpha$ that maximizes the [[Information Gain]]
* split by $\alpha$
* repeat recursively until have $N$ intervals or no information gain is possible



== Sources ==
* [[Data Mining (UFRT)]]

[[Category:Data Transformation]]</text>
      <sha1>6x52yglhtu2qvmygvdckukryaxnurri</sha1>
    </revision>
  </page>
  <page>
    <title>Data Reduction</title>
    <ns>0</ns>
    <id>445</id>
    <revision>
      <id>448</id>
      <timestamp>2014-05-12T09:32:56Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="759">== Data Reduction ==
In [[Machine Learning]] and [[Data Mining]]
* How to speed up computation for our model?


There are two approaches: 
* reducing the number of rows 
* reducing the number of columns 


=== Rows ===
The main approach is to randomly select a subset of the dataset 
* [[Sampling]]


=== Columns ===
Main approach: remove dependent variables
* [[Correlation]] coefficient for two [[Quantitative Variables]]
* [[Chi-square Test of Independence]] for two [[Categorical Variables]]
* [[One-Way ANOVA F-Test]] for quantitative vs categorical case


Other techniques:
* [[Principal Component Analysis]] and [[Singular Value Decomposition]]


== See Also ==
* [[Bivariate Analysis]]

== Sources ==
* [[Data Mining (UFRT)]]

[[Category:Data Mining]]</text>
      <sha1>rbxq93kx97iapae9vylkl3ti1jdm9ne</sha1>
    </revision>
  </page>
  <page>
    <title>One-Way ANOVA F-Test</title>
    <ns>0</ns>
    <id>446</id>
    <revision>
      <id>449</id>
      <timestamp>2014-08-01T09:48:15Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10498">== One-Way [[ANOVA]] [[F-Test]] ==
Simplest [[ANOVA]]
* are the means of several groups equal?
* it's a [[Statistical Test]]
* And it generalizes the [[t-tests]]


It's an $F$-Test
* We assume that we have [[Normal Distribution]]
* and the resulting value follows the [[F-Distribution|$F$-Distribution]]

It's a parametric test of Variance:
* it's parametric because it's based on Normality hypothesis 


=== Comparing Means ===
Comparing means of several groups
* We can compare means of two groups using [[t-tests#Two-Sample t-test|Two-Sample $t$-test]]
* But sometimes we want to compare means across many groups

First idea: do Pairwise comparison
* but we may find the difference just by chance, even when there's no difference - because there'll be too many comparisons
* need to do some correction 


=== Test Of Independence ===
One-Way ANOVA can be used to analyze the relationships between two variables
* numerical and categorical 
* we group the numerical one by associated categories
* and find the means of each category
* then we test if the means are the same 
* if yes - these two variables are independent



=== Post-ANOVA Comparison ===
suppose we reject $H_0$
* we may wonder, which groups are different? 
* to find out, can use the following tests:
* [[Pairwise t-test|Pairwise $t$-test]] note that in this case we need to reduce [[Family-Wise Error Rate]] e.g. with [[Bonferroni Correction]]
* [[Tukey HSD Test]]



== The One-Way ANOVA Test ==
ANOVA: compare many means in a single hypothesis 
* are the means of several groups equal?
* so it generalizes the $t$-test to more than two groups
* used in [[Bivariate Analysis]] to test if a numerical and categorical variables are independent


ANOVA:
* assessing the variability of the group mean relative to variability among individual observations
* the questions answered: &quot;is the variability on the sample means so large that it seems unlikely to be entirely due to chance?&quot;


General Idea:
* &lt;u&gt;simultaneously&lt;/u&gt; consider many groups
* evaluate if the sample means differ more than we'd expect from natural variation


=== Assumptions ===
* observations are independent
* data within each group is distributed normally
* variability across the groups is approximately equal


=== ANOVA Test ===
* $H_0: \mu_1 = \mu_2 = ... = \mu_k$
* $H_A:$ at least one $\mu_i$ is different from the rest


Estimating variability:
* this variability is called ''MSG'': '''mean square between groups''' 
* $\text{df}_G = k - 1$ for $k$ groups 


* let $\bar{x}$ be the sample mean across all groups
* $\text{MSG} = \cfrac{1}{\text{df}_G} \cdot \text{SSG} = \cfrac{1}{k - 1} \sum_{i=1}^k n_i (\bar{x}_i - \bar{x})^2$
* $\text{SSG}$ - sum of squares between groups 
* $n_i$ - sample size of group $i$

this gives us a base point, and we compare it with $\text{MSE}$:


$\text{MSE}$: mean square error (pooled variance estimate)

* $\text{df}_E = n - k$
* $\text{SST} = \sum_{i=1}^n (x_i - \bar{x})^2$
* sum of squares total 
* this is calculated over all observations in the data set 

* $\text{SSE}  = \text{SST} - \text{SSG} = (n_1 - 1) \cdot s^2_1 + (n_2 - 1) \cdot s^2_2 + ... + (n_k - 1) \cdot s^2_k$
* $s^2_i$ - sample variance of residuals in the group
sum of squared error
standardized form of $\text{SSE}$: $\text{MSE} = 1 / \text{df}_E \text{SSE}$


if $H_0$ is true then differences are due to chance and MSG and MSE should be approximately equal 

Then we can calculate the test statistics
$F = \cfrac{\text{MSG}}{\text{MSE}}$


* $\text{MSG}$ = between the group variability
* $\text{MSE}$ = withing the group variability 

$F$ is a $F$ statistics that follows $F$-distribution 
it has 2 associated parameters: $\text{df}_1$ and $\text{df}_2 $
for ANOVA it's $\text{df}_G$ and $\text{df}_E$

the larger $\text{MSG}$ relative to $\text{MSE}$, the larger $F$ is, and the stronger evidence against $H_0$


We use upper tail to compute the $p$-value 


=== Test (From [[Data Mining (UFRT)]]) ===
Given
* $X$ with $k$ possible values $x_1, ..., x_k$ - categorical variable (e.g. Job)
* and $Y$ - continuous variable (e.g. Age)

Let
* $\mu = \text{mean}(Y)$: [[Mean]] value of $Y$ 
* $\mu_k$: mean value of $Y$ for tuples such that $X = x_k$
* $N_k$ : number of records such that that $X = x_k$
* $N = \sum_k N_k$ : total number of records

Define: 
* Interclass [[Variance]]: $\text{Inter} = \cfrac{1}{K-1} \cdot \sum_k N_k \cdot (\mu_k - \mu)^2$
** total variance
* Intraclass [[Variance]]: $\text{Intra} = \cfrac{1}{N-K} \cdot \sum_k \sum_{j : X = x_k} ( y_j - \mu_k )^2$
** variance inside each group

Test
* to evaluate the correlation between $X$ and $Y$ calculate $F = \cfrac{\text{Inter}}{\text{Intra}}$
* the null hypothesis $H_0$: all means $\mu_k$ are equal (i.e. assume independence), 
* under $H_0$ $F$-ratio follows $F_{K-1,N-K}$: [[F-distribution|$F$-distribution]] with $K-1,N-K$ degrees of freedom
* if independent, all the means should be the same for all classes and $F$ should be 0



== Examples ==
=== Example 1: Baseball ===
Batting Performance 

we have 4 categories of baseball players:
* outfielders: $\text{OF}$
* infielders: $\text{IF}$
* jilter: $\text{DH}$
* catcher: $\text{C}$

Is there any difference in performance? (using on-base percentage &lt;code&gt;OBP&lt;/code&gt; to measure it)


Test:
* $H_0: \mu_\text{OF} = \mu_\text{IF} = \mu_\text{DH} = \mu_\text{C}$
* $H_A$: at least one is different

we approximate each $\mu$ by $\bar{x}$


{| class=&quot;wikitable&quot;
! || OF || IF || DH || C
|+ Summary statistics (source: table 5.27, [[OpenIntro Statistics (book)|OpenIntro]])
|-
! Sample size ($n_i$) 
| 120 || 154 || 14 || 39
|-
! Sample mean ($\bar{x}_i$) 
| 0.334 || 0.332 || 0.348 || 0.323
|-
! Sample SD ($s_i$) 
| 0.029 || 0.037 || 0.036 || 0.045
|}


http://habrastorage.org/files/05a/241/ce5/05a241ce52204838a53ad13554c3372d.png
(source: fig 5.28, [[OpenIntro Statistics (book)|OpenIntro]])


We see that DH and C look really different. Why don't we just check if $\mu_\text{DH} = \mu_\text{C}$?
* the primary issue: we're inspecting the data before doing the check 
* this is called [[Data Snooping]] (or Data Fishing)
* naturally we'd pick up the groups with largest differences and run the formal test
* but it would lead to [[Type I Errors]]
* it's also called Prosecutor's Fallacy


Calculate: 
* $\text{MSG} = 0.00252$
* $\text{MSE} = 0.00121$
* $k = 4$ groups, $\text{df_G} = 4 - 1 = 3$
* $n = n_1 + n_2 + n_3 + n_4 = 327$, $\text{df}_E = n - k = 323$
* $F = \cfrac{MSG}{MSE} = \cfrac{0.00252}{0.00121} \approx 1.994$


P-value
* $p$-value is 0.115 &gt; 0.05
* http://habrastorage.org/files/08a/9f7/d43/08a9f7d43c8c4d94a17e1512b49294f4.png
* so we fail to reject $H_0$ at the significance level $\alpha=0.05$


=== Example 2: Statistics Class ===
We have high demand for a course, so run it several times in one semester 
* e.g. it's run 3 times: scores of each run are sets $A, B, C$
* are these significant differences? 

Test:
* $H_0: \mu_A = \mu_B = \mu_C$
* $H_A:$ scores may vary on average

http://habrastorage.org/files/b24/e9f/d27/b24e9fd275934951b45bc6114662b2db.png


{| class=&quot;wikitable&quot;
! Group || $n$ || Min. || Mean || Max. || Std
|-
| $A$ || 58 || 44 || 75.10 || 100 || 13.86867
|-
| $B$ || 55 || 38 || 71.96 || 100 || 13.77056
|-
| $C$ || 51 || 45 || 78.94 || 100 || 13.12008
|}


We run ANOVA tests and obtain the following summary table:

{| class=&quot;wikitable&quot;
|-
! || Df || Sum Sq || Mean Sq || $F$ value || $Pr(&gt;F)$
|-
| lecture || 2 || 1290.11 || 645.06 || 3.48 || 0.0330
|-
| Residuals || 161 || 29810.13 || 185.16 || || 
|}


The $p$-value is greater than $\alpha=0.05$, so we reject $H_0$


&lt;pre&gt;
library(openintro)
data(classData)

by(classData$m1, classData$lecture, summary)
by(classData$m1, classData$lecture, sd)
by(classData$m1, classData$lecture, length)


boxplot(classData$m1 ~ classData$lecture, col='skyblue', axes=F)
axis(side=2)
axis(side=1, at=1:3, labels=c('A', 'B', 'C'))


oneway.test(classData$m1 ~ classData$lecture, var.equal=T)
# or
aov1 = aov(classData$m1 ~ classData$lecture)
summary(aov1)
&lt;/pre&gt;


Post-ANOVA processing: use $t$-test to pairwise compare $A,B,C$
* With [[Bonferroni Correction]], $\alpha^* = \alpha / 3 = 0.05 / 3 = 0.017$
* $A$ vs $B$: $p$-value is 0.228, don't reject
* $A$ vs $C$: $p$-value is 0.148, don't reject
* $B$ vs $C$: $p$-value is 0.01, reject


In R:
&lt;pre&gt;
pairwise.t.test(classData$m1, classData$lecture,
                alternative='two.sided', p.adjust.method='bonferroni')
&lt;/pre&gt;

Or 
&lt;pre&gt;
TukeyHSD(aov1)
&lt;/pre&gt;



=== Example 3: Donuts ===
Example from [http://courses.statistics.com/software/R/R1way.htm]
* study of donuts: the relationship between the amount of absorbed fat vs the type of fat
* is there any relationship?

The data:

{| class=&quot;wikitable&quot;
! Fat1 || Fat2 || Fat3 || Fat4
|-
| 164 || 178 || 175 || 155
|-
| 172 || 191 || 193 || 166
|-
| 168 || 197 || 178 || 149
|-
| 177 || 182 || 171 || 164
|-
| 156 || 185 || 163 || 170
|-
| 195 || 177 || 176 || 168
|}

http://habrastorage.org/files/f46/d8c/e0d/f46d8ce0d0e14e4795e96c2ca69760a1.png


We run ANOVA analysis and get the following:
* $F = 5.4063$, 
* num $\text{df} = 3$, denom $\text{df} = 20$, 
* $p\text{-value} = 0.006876$


&lt;pre&gt;
file = 'http://courses.statistics.com/software/data/donuts.txt'
donuts = read.table(file, header=T)
donuts = stack(donuts)
donuts

boxplot(donuts$values ~ donuts$ind)
oneway.test(donuts$values ~ donuts$ind, var.equal=TRUE)
# p\text{-value} is small, we reject the hypothesis of equal absorption. 
&lt;/pre&gt;


Same, done in steps:

&lt;pre&gt;
groups = 4
# total variance
df.g = groups - 1
tot.mean = mean(donuts$values)

group.mean = tapply(donuts$values, donuts$ind, mean)
n = tapply(donuts$values, donuts$ind, length)

inter = sum(n * (group.mean - tot.mean) ^ 2) / df.g

# variance inside each group
df.e = length(donuts$values) - groups
intra.1 = tapply(donuts$values, donuts$ind, FUN=function(data) {
  m = mean(data)
  sum( (data - m)^ 2)
})
intra = sum(intra.1) / df.e

F.stat = inter/intra
F.stat

p = 1 - pf(F.stat, df1=df.g, df2=df.e)
p
&lt;/pre&gt;

http://habrastorage.org/files/27f/dce/c86/27fdcec86c774679a8146a1ba4147b41.png

&lt;pre&gt;
x = seq(0, 6, 0.05)
y = df(x, df1=df.g, df2=df.e)
plot(x, y, type='l')

abline(v=F.stat)
&lt;/pre&gt;



== Links ==
* Good example: http://en.wikipedia.org/wiki/F_test#One-way_ANOVA_example


== Sources ==
* [[OpenIntro Statistics (book)]]
* [[Data Mining (UFRT)]]
* http://en.wikipedia.org/wiki/Analysis_of_variance

[[Category:Statistical Tests]]
[[Category:Statistics]]
[[Category:R]]</text>
      <sha1>161setr0j3p37f2ir71pbmb6wlzed9i</sha1>
    </revision>
  </page>
  <page>
    <title>ANOVA</title>
    <ns>0</ns>
    <id>447</id>
    <revision>
      <id>450</id>
      <timestamp>2015-04-19T11:10:05Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1717">{{draft}}{{stub}}

== ANOVA ==
ANOVA is ANalysis Of VAriance
* it's a set of statistical models 
* they are used to analyze differences between group means and their associated procedures
** e.g. variation among and between groups 


== Types ==
=== [[One-Way ANOVA F-Test]] ===
Goal: compare many means in a single hypothesis 
* instead of doing pairwise [[t-tests|$t$-test]], do ANOVA
* but you can still perform [[t-tests|$t$-test]] or [[Tukey HSD Test]] as post-ANOVA analysis
* also, a good way of checking independence between two variables: numerical and categorical 

Some authors argue that the ANOVA step is in fact unnecessary and we could perform the Tukey HSD test alone. Nevertheless, the ANOVA + Tukey approach is considered standard is most books.


=== Not Normal? ===
If not Normal, use these non-parametric tests
* [[Wilcoxon-Mann-Whiney Test]] if the class variable is binary 
* [[Kruskal-Wallis Test]] for any nominal variable 


== Links ==
* http://www.marketingdistillery.com/2014/08/10/multiple-abn-tests-in-marketing-with-anova-and-r/
* Book with chapters about ANOVA [http://vassarstats.net/textbook/toc.html]
** Conceptual Introduction to the Analysis of Variance [http://vassarstats.net/textbook/ch13pt1.html]
** ONE-way analysis for independent samples [http://vassarstats.net/textbook/ch14pt1.html] [http://vassarstats.net/textbook/ch14pt2.html]
** The Kruskal-Wallis Test for 3 or More Independent Samples [http://vassarstats.net/textbook/ch14a.html]
* http://www.personality-project.org/r/r.anova.html


== Sources ==
* [[Data Mining (UFRT)]]
* [[OpenIntro Statistics (book)]]
* http://en.wikipedia.org/wiki/Analysis_of_variance

[[Category:Statistical Tests]]
[[Category:Statistics]]</text>
      <sha1>ijlw3qh5dlg5tf3evjn90hhlooejaqu</sha1>
    </revision>
  </page>
  <page>
    <title>Chi-Squared Test of Independence</title>
    <ns>0</ns>
    <id>448</id>
    <revision>
      <id>451</id>
      <timestamp>2014-08-09T20:25:37Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9830">== Chi-Squared Test of Independence ==
This is one of [[Chi-Squared Tests|$\chi^2$ tests]]
* one-way table tests - for testing [[Frequency Tables]], [[Chi-Squared Goodness of Fit Test]]
* two-way table tests - for testing [[Contingency Tables]], this one


=== $\chi^2$ Test of Independence ===
This is a [[Hypothesis Testing|Statistical Test]] to say if two attributes are dependent or not 
* this is used only for descriptive attributes


Setup
* sample of size $N$
* two categorical variables $A$ with $n$ modalities and $B$ with $m$ modalities
* $\text{dom}(A) = \{ a_1, ..., a_n \}$ and $\text{dom}(B) = \{ b_1, ..., b_m \}$
* we can represent the counts as a [[Contingency Table]]
* at each cell $(i, j)$ we denote the observed count as $O_{ij}$
* also, for each row $i$ we calculate the &quot;row total&quot; $r_i = \sum_{j=1}^{m} O_{ij}$
* and for each column $j$ - &quot;column total&quot; $c_j = \sum_{i=1}^{n} O_{ij}$
* $E_{ij}$ are values that we expect to see if $A$ and $B$ are independent


&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;
{| class=&quot;wikitable&quot;
|+ Observed Values
! || $a_1$ || $a_2$ || ... || $a_n$ || row total
|-
! $b_1$
| $O_{11}$ || $O_{21}$ || ... || $O_{n1}$ || $r_1$
|-
! $b_2$
| $O_{12}$ || $O_{22}$ || ... || $O_{n2}$ || $r_2$
|-
! ...
| ... || ... || ... || ... ||
|-
! $b_m$
| $O_{1m}$ || $O_{2m}$ || ... || $O_{nm}$ || $r_m$
|-
! col total 
| $c_1$ || $c_2$ || ... || $c_n$ || $N$ 
|}
&lt;/td&gt;
&lt;td&gt;
{| class=&quot;wikitable&quot;
|+ Expected Values
! || $a_1$ || $a_2$ || ... || $a_n$ || row total
|-
! $b_1$
| $E_{11}$ || $E_{21}$ || ... || $E_{n1}$ || $r_1$
|-
! $b_2$
| $E_{12}$ || $E_{22}$ || ... || $E_{n2}$ || $r_2$
|-
! ...
| ... || ... || ... || ... ||
|-
! $b_m$
| $E_{1m}$ || $E_{2m}$ || ... || $E_{nm}$ || $r_m$
|-
! col total 
| $c_1$ || $c_2$ || ... || $c_n$ || $N$ 
|}
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;


=== Test ===
We want to check if these values are independent, and perform a test for that
* $H_0$: $A$ and $B$ are independent
* $H_A$: $A$ and $B$ are not independent 


We conclude that $A$ and $B$ are not independent (i.e. reject $H_0$ if we observe very large differences from the expected values


=== Expected Counts Calculation ===
Calculate
* $E_{ij}$ for a cell $(i, j)$ as 
* $E_{ij} = \cfrac{\text{row $j$ total}}{\text{table total}} \cdot \text{column $i$ total}$

or, in vectorized form, 
* $[ r_1 \ r_2 \ ...  \ r_n ] \times \left[\begin{matrix} c_1 \\ \vdots \\ c_m \end{matrix} \right] \times \cfrac{1}{N}$ 
* with $n$ rows and $m$ columns



=== $X^2$-statistics Calculation ===
Statistics
* assuming independence, we would expect that the values in the cells are distributed uniformly with small deviations because of sampling variability
* so we calculate the expected values under $H_0$ and check how far the observed values are from them 
* we use the standardized squared difference for that and calculate $X^2$ statistics that under $H_0$ follows [[Chi-Squared Distribution|$\chi^2$ distribution]] with $\text{df} = (n - 1) \cdot (m - 1)$


$X^2 = \sum_i \sum_j \cfrac{ (O_{ij} - E_{ij})^2 }{ E_{ij} }$


Apart from checking the $p$-value, we typically also check the $1-\alpha$ percentile of $\chi^2$ with $\text{df} = (n - 1) \cdot (m - 1)$


=== Size Matters ===
In examples we can see if the size increases, $H_0$ rejected
* so it's sensitive to the size 
* see also here on the sample size [http://stats.stackexchange.com/questions/108911/why-does-frequentist-hypothesis-testing-become-biased-towards-rejecting-the-null/]


== Cramer's $V$ ==
[[Cramer's Coefficient]] is a [[Correlation]] measure for two categorical variables that doesn't depend on the size like this test 



== Examples ==
=== Example: Gender vs City === 
Consider this dataset
* $\text{Dom}(X) = \{ x_1 = \text{female}, x_2 = \text{male} \}$ (Gender)
* $\text{Dom}(Y) = \{ y_1 = \text{Blois}, y_2 = \text{Tours} \}$ (City)
* $O_{12}$ - # of examples that are $x_1$ (female) and $y_2$ (Tours)
* $E_{12}$ - # of customers that are $x_1$ (female) times # of customers that $y_2$ (live in Tours) divided by the total # of customers 

If $X$ and $Y$ are independent
* $\forall i, j : O_{ij} \approx E_{ij}$ should hold
* and $X^2 \approx 0$


==== Small Data Set ====
Suppose we have the following data set
* this is our observed values

And let us also build a ideal independent data set
* here we're assuming that all the values are totally independent 
* idea: if independent, should have exactly the same # of male and female in Blois, 
* and same # of male/female in Tours 

&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;
{| class=&quot;wikitable&quot;
|+ Observed Counts
! || Male || Female || Total 
|-
! Blois 
| 55 || 45 || 100 
|-
! Tours 
| 20 || 30 || 50 
|-
| Total || 75 || 75 || 150 
|}
&lt;/td&gt;
&lt;td&gt;
{| class=&quot;wikitable&quot;
|+ Expected Counts
! || Male || Female || Total 
|-
! Blois 
| 50 || 50 || 100 
|-
! Tours 
| 25 || 25 || 50 
|-
| Total || 75 || 75 || 150 
|}
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;


Test
* To compute the value, subtract actual from ideal  
* $X^2 = \cfrac{(55-50)^2}{50} + \cfrac{(45-50)^2}{50}+\cfrac{(20-25)^2}{25}+\cfrac{(30-25)^2}{25} = 3$
* with $\text{df}=2$, 95th percentile is 5.99, which is bigger than 3
* also, $p$-value is 0.08 &lt; 0.05
* $\Rightarrow$ the independence hypothesis $H_0$ is not rejected with confidence of 95% (they're probably independent)


R:
&lt;pre&gt;
tbl = matrix(data=c(55, 45, 20, 30), nrow=2, ncol=2, byrow=T)
dimnames(tbl) = list(City=c('B', 'T'), Gender=c('M', 'F'))

chi2 = chisq.test(tbl, correct=F)
c(chi2$statistic, chi2$p.value)
&lt;/pre&gt;


==== Bigger Data Set ====
Now assume that we have the same dataset
* but everything is multiplied by 10 

&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;
{| class=&quot;wikitable&quot;
! || Male || Female || Total 
|+ Observed values 
|-
! Blois 
| 550 || 450 || 1000 
|-
! Tours 
| 200 || 300 || 500 
|-
| Total || 750 || 750 || 1500 
|}
&lt;/td&gt;

&lt;td&gt;
{| class=&quot;wikitable&quot;
|+ Values if independent
! || Male || Female || Total 
|-
! Blois 
| 500 || 500 || 1000 
|-
! Tours 
| 250 || 250 || 500 
|-
| Total || 750 || 750 || 1500 
|}
&lt;td&gt;
&lt;/tr&gt;
&lt;/table&gt;


Test
* since values grow, the differences between actual and ideal also grow
* and therefore the square of differences also gets bigger
* $X^2 = \cfrac{(550-500)^2}{500} \cfrac{(450-500)^2}{500}+\cfrac{(200-250)^2}{250}+\cfrac{(300-250)^2}{250} = 30$
* with $\text{df} = 2$, 95th percentile is 5.99
* it's less than 30
* and $p$ value is $\approx 10^{-8}$
* $\Rightarrow$ the independence hypothesis is rejected with a confidence of 95%


&lt;pre&gt;
tbl = matrix(data=c(55, 45, 20, 30) * 10, nrow=2, ncol=2, byrow=T)
dimnames(tbl) = list(City=c('B', 'T'), Gender=c('M', 'F'))

chi2 = chisq.test(tbl, correct=F)
c(chi2$statistic, chi2$p.value)
&lt;/pre&gt;

So we see that the sample size matters
* possible solution is to use [[Cramer's Coefficient]] that tells how much two variables correlate



=== Example: Search Algorithm ===
Suppose a search engine wants to test new search algorithms 
* e.g. sample of 10k queries
* 5k are served with the old algorithm
* 2.5k are served with &lt;code&gt;test1&lt;/code&gt; algorithm
* 2.5k are served with &lt;code&gt;test2&lt;/code&gt; algorithm


Test:
* goal to see if there's any difference in the performance
* $H_0$: algorithms perform equally well
* $H_A$: they perform differently


How do we quantify the quality?
* can view it as interaction with the system in the following way
* success: user clicked on at least one of the provided links and didn't try a new search
* failure: user performed a new search


So we record the outcomes 

{| class=&quot;wikitable&quot;
|+ observed outcomes
! || current || test 1 || test 2 || total
|-
! success 
| 3511 || 1749 || 1818 || 7078
|-
! failure 
| 1489 || 751 || 682 || 2922
|-
| || 5000 || 2500 || 2500 || 10000
|}


The combinations are binned into a two-way table 

Expected counts 
* Proportion of users who are satisfied with the search is 7078/10000 = 0.7078
* So we expect that 70.78% in 5000 of the current algorithm will also be satisfied
* which gives us expected count of 3539 
* i.e. if there is no differences between the groups, 3539 users of the current algorithm group will not perform a new search 


{| class=&quot;wikitable&quot;
|+ observed and (expected) outcomes
! || current || test 1 || test 2 || total
|-
! success 
| 3511 (3539) || 1749 (1769.5) || 1818 (1769.5)  || 7078
|-
! failure 
| 1489 (1461) || 751 (730.5) || 682 (730.5) || 2922
|-
| || 5000 || 2500 || 2500 || 10000
|}


Now we can compute the $X^2$ test statistics 
* $X^2 = \cfrac{( 3511 - 3539 )^2}{ 3539 } + \cfrac{( 1489 - 1461 )^2}{ 1461 } + \cfrac{( 1749 - 1769.5 )^2}{ 1769.5 } + \cfrac{( 751 - 730.5 )^2}{ 730.5 } +  \cfrac{( 1818 - 1769.5 )^2}{ 1769.5 } + \cfrac{( 682 - 730.5 )^2}{ 730.5 } = 6.12$
* under $H_0$ it follows $\chi^2$ distribution with $\text{df} = (3 - 1) \cdot (2 - 1)$
* the $p$ value is $p=0.047$, which is less than $\alpha = 0.05$ so we can reject $H_0$ 
* http://habrastorage.org/files/2b5/c8f/c6e/2b5c8fc6e4f5414fa115c7e1ffd00375.png
* also, it makes sense to have a look at expected $X^2$ for $\alpha = 0.05$, which is  $X^2_{\text{exp}} = 5.99$, and $X^2_{\text{exp}} &lt; X^2$


R:
&lt;pre&gt;
obs = matrix(c(3511, 1749, 1818, 1489, 751, 682), nrow=2, ncol=3, byrow=T)
dimnames(obs) = list(outcome=c('click', 'new search'),
                     algorithm=c('current', 'test 1', 'test 2'))

tot = sum(obs)
row.tot = rowSums(obs)
col.tot = colSums(obs)

exp = row.tot %*% t(col.tot) / tot
dimnames(exp) = dimnames(obs)

x2 = sum( (obs - exp)^2 / exp )

df = prod(dim(obs) - 1)
pchisq(x2, df=df, lower.tail=F)
qchisq(p=0.95, df=df)
&lt;/pre&gt;

Or we can use &lt;code&gt;chisq.test&lt;/code&gt; function
&lt;pre&gt;
test = chisq.test(obs, correct=F)
test$expected
c('p-value'=test$p.value, test$statistic)
&lt;/pre&gt;


== Links ==
* http://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test#Test_of_independence

== Sources ==
* [[OpenIntro Statistics (book)]]
* [[Data Mining (UFRT)]]

[[Category:Statistics]]
[[Category:Statistical Tests]]
[[Category:R]]</text>
      <sha1>28hfp3gpwum4d0c35ph7yj850r5aooc</sha1>
    </revision>
  </page>
  <page>
    <title>Outliers</title>
    <ns>0</ns>
    <id>449</id>
    <revision>
      <id>452</id>
      <timestamp>2014-05-12T09:44:03Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1028">== Outliers ==
* Outliers: refers to objects with characteristic different from most of the other objects

Can detect by
* [[Summary Statistics]] 
* [[Box Plot]]s
* Other visualization techniques - [[Plot]]s
* more advanced approaches like [[Anomaly Detection]]

== Visualization ==
=== Modified [[Box Plot]] ===
Modified box plot
* is a variation of the box plot
* can be used to find outliers 
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/da/boxplot-modified.png

=== [[Scatter Plot]] ===
Also if we just draw the values, it'll be possible to see the outliers 
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/outliers-regression.png


== Models and Outliers ==
Some Statistical, [[Machine Learning|ML]] and [[Data Mining|DM]] models are sensible to outliers
* e.g. [[Linear Regression]]
* it's important to detect them and only after build a model


== Sources ==
* [[Data Mining (UFRT)]]
* [[Statistics: Making Sense of Data (coursera)]]

[[Category:Statistics]]</text>
      <sha1>tmrvnrpf93iag32bkyuiaqvvqyfso3w</sha1>
    </revision>
  </page>
  <page>
    <title>Noise Handling (Data Mining)</title>
    <ns>0</ns>
    <id>450</id>
    <revision>
      <id>453</id>
      <timestamp>2014-05-12T09:45:39Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="906">== Noise Handling (Data Mining) ==
Noise - a modification of the original value
* Typically very hard to detect
* Unlike [[Outliers]], that are noticeable different from all other values
* Noisy data looks like real data 


Reasons for Noise:
* Faulty data collection instruments 
* people don't want to put data and put some garbage 
* e.g. age - 40 - true or false?
* Data entry or transmission problems 


=== Detecting and Handling ===
There are several techniques 
* [[Cluster Analysis]] build clusters and then see if there are values that shouldn't belong to this cluster
* Build some model, and then run it on the original data set 
** misclassified instances can be due to noise - are there strange? 
** https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/noise-regression.png


== Sources ==
* [[Data Mining (UFRT)]]

[[Category:Data Analysis]]
[[Category:Data Mining]]</text>
      <sha1>azn3efs0vkmdzsbw6fvd7vsiugwqwxf</sha1>
    </revision>
  </page>
  <page>
    <title>Information Gain</title>
    <ns>0</ns>
    <id>451</id>
    <revision>
      <id>454</id>
      <timestamp>2014-06-08T19:54:43Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3844">== Information Gain ==
The expected information gain is 
* the change in entropy when going
* from a prior state 
* to anther new state


== Entropy ==
=== Information ===
Consider two sequence of coin flips
* HHTHTTH...
* TTHHTTH...

How much information do we get after flipping each coin?
* information: $I(X) = - \log_2 p(X)$
* need a measure of unpredictability in a sequence of events
* [[Expected Value]] of information - 
** $\text{Entropy}(X) = E[I(X)] = \sum_x p(x) \cdot I(x) =  - \sum_x p(x) \cdot \log_2 p(x)$


E.g.
* coin: $P(H) = P(T) =  0.5$
** $I(X) = - \sum_i p(i) \log_2 p(i) = - (0.5 \log_2 0.5 + 0.5 \log_2 0.5) = 1$
* dice: $p(i) = 1/6$
** $I(X) = - \sum_i p(i) \log_2 p(i) = - 6 \cdot (\frac{1}{6} \log_2 \frac{1}{6}) \approx 2.58$
** more unpredictable than a coin
* weighted dice: $p(1) = ... = p(5) = 0.1$ and $p(6) = 0.5$
** $I(X) = - 5 \cdot (0.1 \log_2 0.1) - 0.5 \log_2 0.5 \approx 2.16$
** &lt;u&gt;less&lt;/u&gt; unpredictable than a fair dice


=== Entropy Function ===
Given $m$ classes, the entropy of signal $S$ is 
* $I(S) = - \sum_{i=1}^{m} p_i \log_2 (p_i)$
* where $p_i$ is probability of seeing class $C_i$ in $S$
* $S_i$ - set of all records of class $i$


== Split in Halves ==
=== Entropy for Two Classes ===
For two classes:
* If records in $S$ belong to classes $C_1$ or $C_2$
* Let $p_1 = ( |S_1| / |S| ) = p$ and $p_2 = ( |S_2 | / |S| ) = 1 - p$
* Then, $E[I(S)] = -p \cdot \log_2 (p) - (1 - p) \cdot \log_2 (1-p) $
** expected value of entropy with two subsets 


Entropy is maximal when $p_1 = p_2 = 0.5$
* when $p_1 = 0$ and $p_2 = 1$ (or vise versa), there's no entropy

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/entropy.png


=== Splitting ===
Suppose we want to split a set $S$ into two parts $S_1$ and $S_2$
* we compute the entropy before splitting
* and compute the entropy after splitting at some point $\alpha$
* the ''information gain'' of splitting is the entropy before minus the expected entropy after 

$I(S, \alpha) = I(S) - E[I(\{S_1, S_2\})] = I(S) - p_1 \cdot I(S_1) - p_2 \cdot I(S_2)$
* where $p_1 = \cfrac{|S_1|}{|S|}$ and $p_2 = \cfrac{|S_2|}{|S|}$
* and $S_1, S_2$ are subsets of $S$ s.t. $S_1 \equiv \{ s \ : \ s &lt; \alpha \}$ and $S_2 = S - S_1$
* note that I(S) is a constant and doesn't depend on $\alpha$


=== Best Splitting ===
What is the best  $\alpha$:
* we want to select a boundary $\alpha$ that maximizes the information gain 

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/discretization-entropy.png


So for all possible values of $\alpha$
* we compute the information gain
* and select the best splitting
* the process can be repeated recursively


=== Example 1 ===
Can give the answer of &quot;how much unpredictable is your data?&quot;
* suppose that for the titanic dataset ([http://www.kaggle.com/c/titanic-gettingStarted/data]) we have 342 survived people out of 891
* $p(\text{Survive}) = \cfrac{342}{891}$
* \text{Entropy} = - \cfrac{342}{891} \log_2 \cfrac{342}{891}  - \cfrac{549}{891} \log_2 \cfrac{549}{891} \approx 0.96


This is important measure for splitting in [[Decision Tree (Data Mining)|Decision Trees]]
* select the attribute with the highest information gain 
* it will reduce the unpredictability the most


=== Example 2 ===
Suppose we have a data set of customers
* class $C_1$ - drinks milk and $C_2$ - doesn't drink
* what's the best boundary to split the age variable? 
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/discretization-entropy-ex.png


== Links ==
* http://en.wikipedia.org/wiki/Information_gain_in_decision_trees
* http://en.wikipedia.org/wiki/Mutual_information
* http://en.wikipedia.org/wiki/Information_entropy

== Sources ==
* [[Data Mining (UFRT)]]
* [[Introduction to Data Science (coursera)]]

[[Category:Machine Learning]]</text>
      <sha1>evp5cdac7ia9c3kkb4x2yqytaxost5n</sha1>
    </revision>
  </page>
  <page>
    <title>Experiments</title>
    <ns>0</ns>
    <id>452</id>
    <revision>
      <id>455</id>
      <timestamp>2014-05-12T10:10:37Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="58">#перенаправление [[Statistical Experiment]]</text>
      <sha1>hszpzki477aofy56gqw1gjv6tnmq2pi</sha1>
    </revision>
  </page>
  <page>
    <title>Local Pattern Discovery</title>
    <ns>0</ns>
    <id>453</id>
    <revision>
      <id>456</id>
      <timestamp>2014-06-07T09:59:06Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5686">== Local Patterns Discovery ==
=== Local Patterns ===
Suppose that we have the following table:

{| class=&quot;wikitable&quot;
! || Wings || Beak || Webfoot || Fly || Swim
|-
! Owl
| {{yes}} || {{yes}} || {{no}} || {{yes}} || {{no}}
|-
! Parrot
| {{yes}} || {{yes}} || {{no}} || {{yes}} || {{no}}
|-
! Flamingo
| {{yes}} || {{yes}} || {{yes}} || {{yes}} || {{yes}}
|-
! Penguin
| {{yes}} || {{yes}} || {{yes}} || {{no}} || {{yes}}
|}

What we can learn from this data?
* Global (mainstream) Patterns/Rules
** All birds have wings and beaks
** Almost all birds fly
* Local Patterns/Rules
** only 25% can swim and fly
** 100% of swimming birds are webfooted


Can reformulate these rules with probabilities
* $P(\text{swim} \land \text{fly}) = 0.25$: 25% of birds can swim and fly
* $P(\text{swim} \ | \ \text{webfoot}) = 1$: 100% of web-footed birds can swim
* $P(\text{webfoot} \ | \ \text{swim}) = 1$: 100% of swimming birds are web-footed ones



== Confidence and Support ==
=== Notation ===
* ''items'': set of distinct literals: $\{ a, b, c, ...\}$
* ''itemsets'': any combination of items $\{ a, f, ... \}$
* ''language'': all possible itemsets for the set of items
* ''dataset'': a multiset (i.e. a set that allows duplicates) of itemsets
* an itemset is ''frequent'' if it happens more than some certain threshold


Search space - [[Lattice]]
* all possible combinations of our items
* with arrows showing inclusions of one itemset into another
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/language-lattice.png


=== Support ===
Support of itemset $X$
* proportion of transactions in dataset $D$ that contain $X$
* $\text{supp}(X, D) = \cfrac{ \big| \{ T \in D \ | \ X \subseteq T \} \big| }{ | D | }$
* or simpler, $\text{supp}(X, D) = \cfrac{ \text{freq}(X, D) }{ | D | }$

Support of an association rule $X \to Y$ 
* $\text{supp}(X \to Y, D) = \text{supp}(X \cup Y, D)$


=== Confidence ===
Confidence of an association rule $X \to Y$ 
* $\text{conf}(X \to Y, D) = \cfrac{\text{supp}(X \to Y, D)}{\text{supp}(X, D)} = \cfrac{\text{supp}(X \cup Y, D)}{\text{supp}(X, D)}$


=== Example ===
Consider this 
* items: ${A, B, C, D, E, F}$
* $
\left[
\begin{matrix} 
{\color{red}{1}} &amp; {\color{red}{1}} &amp; {\color{red}{1}} &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\
{\color{red}{1}} &amp; {\color{red}{1}} &amp; {\color{red}{1}} &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 \\
\end{matrix} 
\right]$

* $\text{supp}(AC) = 3/4$ 
** in 3 cases out of 4 the statement is true
* $\text{supp}(AC \to B) = \text{supp}(ABC) = 2/4$ 
** this rule is true in 2 cases out of 4
* $\text{conf}(AC \to B) \cfrac{\text{supp}(ABC)}{\text{supp}(AC)} = \cfrac{2/4}{3/4} = \cfrac{2}{3}$
** intuition: $AC$ is true in 3 cases, and out of these 3, $ABC$ is true only in 2


=== Example 2 ===
${A, B, C, D, E, F}$
* $T_1 = \{A,B,D,E\}$
* $T_2 = \{A,B,C,D,F\}$
* $T_3 = \{B,D,F\}$
* $T_4 = \{C,E,F\}$

Find itemsets with support at least 50%
* $\text{supp}(X)$ - proportion of transactions that contain $X$
* here we want to find rules $X \to A$ with support 50% or more

Let's calculate it for a couple of rules
* $\text{conf}(B \to A, D) = \cfrac{2/4}{3/4} = \cfrac{2}{3}$
* $\text{conf}(D \to A, D) = \cfrac{2/4}{3/4} = \cfrac{2}{3}$
* $\text{conf}(BD \to A, D) = \cfrac{2/4}{3/4} = \cfrac{2}{3}$
* $B \to A$ and $D \to A$ are shorter - those rules are usually better


=== Measures of Interestingness ===
There could be other measures of ''interestingness'' of $X$ in $D_i \subset D$
* [[Lift (Data Mining)|Lift]]: $\text{lift}(X,D_i,D)=\cfrac{\text{supp}(X,D_i)}{\text{supp}(X,D)}$
* Growth rate: $\text{gr}(X,D_i,D)=\cfrac{\text{supp}(X,D_i)}{\text{supp}(X, D - D_i)}$
** how much more support $X$ has in $D_i$ than in $D - D_i$


== Problems ==
=== Frequent Patterns ===
[[Frequent Patterns Mining]]:
* finding patterns with probabilities that exceed a certain threshold
* Descriptive patterns: just combinations of items 

e.g.
* $\text{wings}$
* $\text{beak}$
* $\text{flying}$
* $\text{wings} \land \text{beak}$
* $\text{...}$
* $\text{wings} \land \text{beak} \land \text{fly}$

Or, formally
* find $\{ X \ : \ \text{supp}(X, D) \geqslant \text{min_supp} \}$


=== Association Rules ===
[[Association Rule Mining]]:
* Finding all the rules $X \to Y$ such that
* $P(X \land Y) \geqslant \text{min_supp}$ and 
* $P(Y \ | \ X) \geqslant \text{min_con}$
* these are ''predictive'' patterns

Or, formally
* find $\{ X \to Y \ : \ \text{supp}(X  \to Y, D) \geqslant \text{min_supp} \land \text{conf}(X \to Y, D) \geqslant \text{min_conf} \}$



== Other Patter Mining Tasks ==
With frequent patterns there are some problems:
* they are frequent, i.e happen a lot of the time
* bus we sometimes want to find some exceptional patterns that occur less rarely


So there are other mining tasks
* [[Constraint-Based Pattern Mining]]
** general case of [[Frequent Pattern Mining]]
* Exception mining
** finding rare features
* Contrast mining
** characterizing the difference between two classes
* Utility-pattern mining
** the frequency is not the only end-user interest
** (e.g., price of items in a supermarket)


=== Contrast Mining ===
Mining patterns that compares two or more datasets

Method 1
: (with [[Frequent Pattern Mining]])
* Mine all the non frequent patterns in class 1
* Mine all the frequent patterns in class 2
* Intersect results


Method 2 
: (without frequent pattern mining)
* Mine all the patterns with frequency in class 2 greater than that in class 1


== See Also ==
* [[Frequent Pattern Mining]]
* [[Apriori]]
* [[Eclat]]

== Sources ==
* [[Data Mining (UFRT)]]
* http://en.wikipedia.org/wiki/Association_rule_learning

[[Category:Data Mining]]
[[Category:Rule Mining]]</text>
      <sha1>i5h6sar0lx0o65ibnvraazwj6xz5y48</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Rule Mining</title>
    <ns>14</ns>
    <id>454</id>
    <revision>
      <id>457</id>
      <timestamp>2014-05-15T19:54:31Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24">[[Category:Data Mining]]</text>
      <sha1>mmzresy8g7cpr78mf5m4xjj3j1hl44p</sha1>
    </revision>
  </page>
  <page>
    <title>Lift (Data Mining)</title>
    <ns>0</ns>
    <id>455</id>
    <revision>
      <id>458</id>
      <timestamp>2014-05-16T14:56:10Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1228">== Lift ([[Data Mining]]) ==
Lift is an interestness measure used in [[Rule Mining]]
* for mining more relevant [[Association Rule Mining|association rules]]


Lift:
* for a rule $X \to Y$ with $\text{supp}(X) \ne 0$ and $\text{supp}(Y) \ne 0$
* $\text{lift}(X \to Y) = \cfrac{\text{supp}(X \to Y)}{\text{supp}(X) \cdot \text{supp}(Y)}$
* since $\text{conf}(X \to Y) = \cfrac{\text{supp}(X \to Y)}{\text{supp}(X)}$, can rewrite the formula as
* $\text{lift}(X \to Y) = \cfrac{\text{conf}(X \to Y)}{\text{supp}(Y)}$


=== Properties ===
* $\text{lift}(X \to Y) \ne 0$ 
* $\text{conf}(X \to Y) \in [0, 1]$, and $\text{supp}(Y) \in [0, 1]$
* so $\text{lift}(X \to Y) \in (0, +\infty)$


=== Example ===
Consider this dataset $D$:
* $T_1 = ABCD, T_2 = ADE, T_3 = BDE, T_4 = E$

Lift:
* $\text{lift}(A \to \varnothing) = 1 / 1 = 1$ (everything gives 0, so it's not interesting)
* $\text{lift}(A \to B) = 0.5 / 0.5 = 1$ ($A$ and $B$ are independent, so nothing interesting)
* $\text{lift}(A \to BC) = 0.5 / 0.24 = 2$
* so lift is 1 when two items are independent, and higher when there's some correlation between them


== Sources ==
* [[Data Mining (UFRT)]]
* http://en.wikipedia.org/wiki/Lift_(data_mining)

[[Category:Rule Mining]]</text>
      <sha1>ch9ogurn0wj3fihl6luoc770nci0tsg</sha1>
    </revision>
  </page>
  <page>
    <title>Frequent Patterns Mining</title>
    <ns>0</ns>
    <id>456</id>
    <revision>
      <id>459</id>
      <timestamp>2014-05-16T15:15:27Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4523">== Frequent [[Pattern Mining]] ==
This is a part of [[Local Pattern Discovery]]
* that deals with Descriptive Patterns 


=== Descriptive Patterns ===
Suppose that we have the following table:

{| class=&quot;wikitable&quot;
! || Wings || Beak || Webfoot || Fly || Swim
|-
! Owl
| {{yes}} || {{yes}} || {{no}} || {{yes}} || {{no}}
|-
! Parrot
| {{yes}} || {{yes}} || {{no}} || {{yes}} || {{no}}
|-
! Flamingo
| {{yes}} || {{yes}} || {{yes}} || {{yes}} || {{yes}}
|-
! Penguin
| {{yes}} || {{yes}} || {{yes}} || {{no}} || {{yes}}
|}

We can say that the following are descriptive patterns
* $\text{wings}$
* $\text{beak}$
* $\text{flying}$
* $\text{wings} \land \text{beak}$
* $\text{...}$
* $\text{wings} \land \text{beak} \land \text{fly}$


They involve no rules or inference
* so they are combination of items
* they just describe things that are true with some certain probability


== Frequent Patterns Mining ==
Goal
* finding descriptive patterns with probabilities that exceed a certain threshold

=== Notation ===
* ''items'': set of distinct literals: $\{ a, b, c, ...\}$
* ''itemsets'': any combination of items $\{ a, f, ... \}$
* ''language'': all possible itemsets for the set of items
* ''dataset'': a multiset (i.e. a set that allows duplicates) of itemsets
* an itemset is ''frequent'' if it happens more than some certain threshold


=== Naive Approach ===
* enumerate all possible itemsets
* for each possible itemset $X$ see how many occurrences there are in $D$
* i.e. calculate [[Local Pattern Discovery#Support|Support]] of $X$ in $F$
* if the # of occurrences is lower than some threshold, don't output it


Example
* items ${a,b,c,d,e,f}$
* 4 transactions $\big\{ \{a,b,c\}, \{a,c,d,e,f\}, \{a,b,c\}, \{d,e\} \big\}$

&lt;pre&gt;
I = 'abcdef'
T = ['abc', 'acdef', 'abc', 'de']
for X in powerset(I):
    cnt = sum([1 for i in T if set(X).issubset(set(i))])
    if (cnt != 0):
        print &quot;(%s, %d)&quot; % (''.join(X), cnt)
&lt;/pre&gt;


frequencies:

{| class=&quot;wikitable&quot;
! cnt || itemsets 
|- 
| 1 || $f,ad,ae,af,cd,ce,cf,df,ef,acd,ace,acf,ade,adf,aef,cde,cdf,cef,def,acde,acdf,acef,adef,cdef,acdef$
|- 
| 2 || $b,d,e,ab,bc,de,abc$
|- 
| 3 || $a,c,ac$
|- 
| 4 || $\{\}$
|}


Problems:
* search space: $2^{|D|}$ - very difficult
** e.g. only 6 items - 64 combinations
* but once we found the answer for the 1st problem, we can easily find the answer for the 2nd problem



=== Optimization: Downward Closure ===
* notice that the frequency decreases when going from up to down
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/lattice-frec-decrease.png
* intuition: frequency can never increase when we add a new item, it can only decrease 
* this is called a downward closure


Downward closure
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/downward-closure.png
* If an itemset is frequent, then all its subsets are frequent.
** $X \subseteq Y, \text{supp}(Y) = t \Rightarrow \text{supp}(X) \geqslant t$
** if $abc$ occurs 3 times, then $ab$ occurs at least 3 times, but maybe more
* If an itemset is not frequent, then all its supersets are not frequent
** $X \supseteq Y, \text{supp}(X) &lt; \text{min_t} \Rightarrow \text{supp}(Y) &lt; \text{min_t}$
** if $abc$ occurs less than 3 times, $abcd$ also occurs less than 3 times


=== Algorithms ===
There are two ways we can traverse this lattice:
* [[Breadth-First Search]] - [[Apriori]] algorithm
* [[Depth-First Search]] - [[Eclat]] algorithm


{| class=&quot;wikitable&quot;
! || [[Apriori]] || [[Eclat]]
|-
! $+$ 
| 
* &quot;Perfect&quot; pruning of infrequent candidate itemsets

| 
* [[Depth-First Search|DFS]] reduces memory requirements
* Usually (considerably) faster

|-
! $-$
|
* Can require a lot of memory (since all frequent item sets are represented)
* Support counting takes very long for large transactions
* so not always efficient in practice

|
* Storage of transaction lists

|}


== [[Association Rule Mining]] ==
After we found Frequent patterns it's easy to find association rules
* for each frequent pattern $X$ for each subset $Y \subset X$ 
* calculate support of $Y \to X - Y$
* if it's greater than some certain threshold, keep the rule



== References ==
* Frequent Pattern Mining. Lecture notes, Christian Borgelt. [http://www.borgelt.net/slides/fpm.pdf slides]
* Frequent Itemset Mining Implementations Repository http://fimi.ua.ac.be/

== See Also ==
* [[Local Pattern Discovery]]
* [[Association Rule Mining]]

== Sources ==
* [[Data Mining (UFRT)]]

[[Category:Rule Mining]]
[[Category:Python]]</text>
      <sha1>lw4ggqsdcmzhchsymnbw9s1ma6fk0e1</sha1>
    </revision>
  </page>
  <page>
    <title>Frequent Pattern Mining</title>
    <ns>0</ns>
    <id>457</id>
    <redirect title="Frequent Patterns Mining" />
    <revision>
      <id>460</id>
      <timestamp>2014-05-16T15:04:47Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="38">#REDIRECT [[Frequent Patterns Mining]]</text>
      <sha1>kri7il4i716ti8p8ykbrrkv8pmvhubo</sha1>
    </revision>
  </page>
  <page>
    <title>Apriori</title>
    <ns>0</ns>
    <id>458</id>
    <revision>
      <id>461</id>
      <timestamp>2014-05-16T15:05:02Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5196">== Apriori ==
This is an algorithm for [[Frequent Pattern Mining]] based on [[Breadth-First Search]] traversal of the itemset [[Lattice]]


=== Downward Closure ===
This method uses the property of this Lattice: 
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/downward-closure.png
* $X \subseteq Y, \text{supp}(Y) = t \Rightarrow \text{supp}(X) \geqslant t$
* $X \supseteq Y, \text{supp}(X) &lt; \text{min_t} \Rightarrow \text{supp}(Y) &lt; \text{min_t}$


=== Idea ===
* at a step $k$
* '''generate phase'''
** generate potentially frequent interesting itemsets of size $k$ based on the previous step
* '''test phase'''
** scan the generated itemsets
** eliminate non-frequent ones


=== Algorithm ===
Apriori(dataset $D$, frequency threshold $t$)
* $C_1 = \{ \text{all itemsets of len 1} \}$
* $i \leftarrow 1$
* while $C_i \not \equiv \varnothing$ 
** $F_i \leftarrow  \{ c \in C_i | \text{supp}(c, D) \geqslant t \} $
** $C_{i+1} \leftarrow  \{ \text{generate ($i+1$)-itemsets having $i+1$ frequent itemsets} \} $
** $i \leftarrow i+1$
* return $F_0 \ \cup \ ... \ \cup \ F_i$ 


=== Python ===
&lt;pre&gt;
def frequency(D, itemset):
    return sum([1 for T in D if itemset.issubset(T)])

def s(S, i): return frozenset(S | {i})

I = 'abcdef'
D = [set(x) for x in ['abc', 'acdef', 'abc', 'de']]

th = 2
frequent_items = []

C = [frozenset([i]) for i in I]

while C:
    F = [i for i in C if frequency(D, i) &gt;= th]
    C = {s(T, i)  for i in I   for T in F   if i not in T}
    frequent_items.extend(F)

res = [''.join(sorted(T)) for T in frequent_items]
&lt;/pre&gt;


=== Maximal Frequent Itemsets ===
There's no need to store all the frequent itemsets
* we can store only the maximal ones (ones that that have no superset)
* and generate the rest from them 


Consider the result obtained by the algorithm:
* $\{a, b, c, d, e, bc, ac, ab, de, abc\}$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/apriori-max-itemsets.png
* there are two maximal sets: \text{de} and \text{abc}
* so, if we generate all subsets of these two, we'll get all the frequent itemsets 

&lt;pre&gt;
&gt;&gt;&gt; powerset('de') | powerset('abc')
# sorted([''.join(i) for i in powerset('de') | powerset('abc')], 
#        key=lambda x: (len(x), x))
['', 'a', 'b', 'c', 'd', 'e', 'ab', 'ac', 'bc', 'de', 'abc']
&lt;/pre&gt;


== Examples ==
=== Example 1 ===
* items ${a,b,c,d,e,f}$
* threshold $t = 3$
* 4 transactions 
** $\{ abc, acdef, abc, de \}$
* notation: $\{ X \to \text{frequency}(X) \}$

step 0
* $C_1 \leftarrow \{a \to 3, b \to 2, c \to 3, d \to 2, e \to 2, f \to 1\}$

step 1
* $F_1 \leftarrow \{a \to 3, b \to 2, c \to 3, d \to 2, e \to 2\}$
* $C_2 \leftarrow \{ce \to 1, df \to 1, bf \to 0, af \to 1, ae \to 1, ad \to 1, bd \to 0, ef \to 1, be \to 0, bc \to 2, ac \to 3, cd \to 1, cf \to 1, ab \to 2, de \to 2\}$

step 2
* $F_2 \leftarrow \{bc \to 2, ac \to 3, ab \to 2, de \to 2\}$
* $C_3 \leftarrow \{abc \to 2, abe \to 0, ade \to 1, bde \to 0, bcd \to 0, bcf \to 0, bce \to 0, ace \to 1, acd \to 1, abd \to 0, def \to 1, cde \to 1, abf \to 0, acf \to 1\}$

step 3
* $F_3 \leftarrow \{abc \to 2\}$
* $C_4 \leftarrow \{abcd \to 0, abce \to 0, abcf \to 0\}$

step 4
* $F_4 \leftarrow \{\}$
* $C_5 \leftarrow \{\}$


final result:
* $\{a, b, c, d, e, bc, ac, ab, de, abc\}$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/apriori-ex-solution.png
* note that for $abc$ to be selected, all $ab$, $ac$, $bc$ have to be frequent itemsets


=== Example 2 ===
${A, B, C, D, E, F}$
* $T_1 = \{A,B,D,E\}$
* $T_2 = \{A,B,C,D,F\}$
* $T_3 = \{B,D,F\}$
* $T_4 = \{C,E,F\}$

Run:
* step 0
** $C: [(A, 2), (B, 3), (C, 2), (D, 3), (E, 2), (F, 3)]$
* step 1
** $F: [(A, 2), (B, 3), (C, 2), (D, 3), (E, 2), (F, 3)]$
** $C: [(CE, 1), (DF, 2), (BF, 2), (AF, 1), (AE, 1), (AD, 2), (BD, 3),$ 
*** $(BE, 1), (BC, 1), (AC, 1), (CD, 1), (EF, 1), (DE, 1), (AB, 2), (CF, 2)]$
step 2
** $F: [(DF, 2), (BF, 2), (AD, 2), (BD, 3), (AB, 2), (CF, 2)]$
** $C: [(ABC, 1), (ABE, 1), (CDF, 1), (ACF, 1), (BCF, 1), (BCD, 1),$ 
*** $(BDF, 2), (ADF, 1), (ACD, 1), (BEF, 0), (ABD, 2), (BDE, 1),$
*** $(CEF, 1), (DEF, 0), (ABF, 1), (ADE, 1)]$
* step 3
** $F: [(BDF, 2), (ABD, 2)]$
** $C: [(ABCD, 1), (BDEF, 0), (BCDF, 1), (ABDF, 1), (ABDE, 1)]$
* step 4
** $F: []$
* final result: $[A, B, C, D, E, F, DF, BF, AD, BD, AB, CF, BDF, ABD]$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/apriori-tut-ex.png


Note the step 2:
* we have $BD$ and $DF$. to take $BDF$ we also need to have $DF$. 
** do we have it? yes $\Rightarrow$ take it
* Even though we have $AB$ and $BF$, there's no $AF$
** so not taking $ABF$ 

Remark: 
* Maximal frequent itemsets are $E, CF, ABD$ and $BDF$. 
* $X$ is maximal $\iff$ there $\not \exists \ Y, Y \supset X : \text{freq}(Y) &gt; \text{freq}(X)$
* any frequent itemset is included in one of the maximal ones
* this is useful for checking if a pattern frequent or not:
** if it's not contained in any of the maximal frequent sets, it's not frequent



== See Also ==
* [[Local Pattern Discovery]]
* [[Frequent Pattern Mining]]
* [[Eclat]]

== Sources ==
* [[Data Mining (UFRT)]]

[[Category:Rule Mining]]
[[Category:Python]]</text>
      <sha1>k9bltxpx0x573jzilhunsify1bl6ky4</sha1>
    </revision>
  </page>
  <page>
    <title>Eclat</title>
    <ns>0</ns>
    <id>459</id>
    <revision>
      <id>462</id>
      <timestamp>2014-05-16T15:08:07Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4847">== Eclat ==
This is an algorithm for [[Frequent Pattern Mining]] based on [[Depth-First Search]] traversal of the itemset [[Lattice]]
* but it's rather a DFS traversal of the prefix tree than lattice
* and the [[Branch and Bound]] method is used for stopping


=== Downward Closure ===
This method uses the property of this Lattice: 
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/downward-closure.png
* $X \subseteq Y, \text{supp}(Y) = t \Rightarrow \text{supp}(X) \geqslant t$
* $X \supseteq Y, \text{supp}(X) &lt; \text{min_t} \Rightarrow \text{supp}(Y) &lt; \text{min_t}$



=== Idea ===
* TidList - list of transaction identifiers
* represent each item $i$ as a list of transaction where it participated (&quot;inverted list&quot;)
* and calculate support as the size of intersection of TidLists


Example
* items ${a,b,c,d,e,f}$
* 4 transactions: $T_1: abc, T_2: acdef, T_3: abc, T_4: de$
* $N = 4$, # of transactions

TidLists: 
* $\text{Tid}(a) = \{ T_1, T_2, T_3 \}$
* $\text{Tid}(b) = \{ T_1, T_3 \}$
* $\text{Tid}(c) = \{ T_1, T_2, T_3 \}$
* $\text{Tid}(d) = \{ T_2, T_4 \}$
* $\text{Tid}(e) = \{ T_2, T_4 \}$
* $\text{Tid}(f) = \{ T_2 \}$

Support:
* $\text{supp}(ab) = \cfrac{\big| \text{Tid}(a) \cap \text{Tid}(b) \big|}{N} = \cfrac{\big| \{T_1, T_2\} \big|}{N} = \cfrac{2}{4} = 0.5$



== Eclat Algorithm ==
=== Algorithm ===
Eclat(prefix $X$, items $I$)
* let $C$ be candidate itemsets and remove non-frequent items of $C$
* $C = \big\{ X \cup {i} \ | \ \forall i \in I \ : \ \text{freq}(X \cup {i}) \geqslant \text{min_th} \big\}$
* $F = \varnothing$
* $C_\text{it} \leftarrow C$
* for each frequent item $i$ added to $C$
** let $X_i = X \cap \{i\}$
** update $C_\text{it} = C_\text{it} - \{ i \}$
** $F \leftarrow F + X_i + \text{Eclat}(X_i, C_\text{it})$
* return $F$

&lt;pre&gt;
th = 2

def eclat(prefix, items, D):
    if not items: return
    candidates = [(prefix | {i}, frequency(D, prefix | {i}), i)
                  for i in items if i not in prefix]
    frequent = filter(lambda x: x[1] &gt;= th, candidates)

    for new_prefix, freq, i in frequent:
        frequent_items.append(new_prefix)
        items = items - {i}
        eclat(new_prefix, items, D)

eclat(set(), set(I), D)
&lt;/pre&gt;


=== Example ===
* items ${a,b,c,d,e,f}$
* threshold $t = 3$
* 4 transactions 
** $\{ abc, acdef, abc, de \}$
* notation: (item to add; prefix $\to$ frequency(prefix))


Let's run the algorithm on this input:
# eclat(prefix: $\{\}$, items: $acbedf$) (step 1)
#*  candidates $(a: a \to 3), (c: c \to 3), (b: b \to 2), (e: e \to 2), (d: d \to 2), (f: f \to 1)$
#*  frequent patterns $(a: a \to 3), (c: c \to 3), (b: b \to 2), (e: e \to 2), (d: d \to 2)$
#*  adding $a$ to $F$
# eclat(prefix: $a$, items: $cbedf$) (step 2)
#*  candidates $(c: ac \to 3), (b: ab \to 2), (e: ae \to 1), (d: ad \to 1), (f: af \to 1)$
#*  frequent patterns $(c: ac \to 3), (b: ab \to 2)$
#*  adding $ac$ to $F$
# eclat(prefix: $ac$, items: $bedf$) (step 3)
#*  candidates $(b: acb \to 2), (e: ace \to 1), (d: acd \to 1), (f: acf \to 1)$
#*  frequent patterns $(b: acb \to 2)$
#*  adding $acb$ to $F$
# eclat(prefix: $acb$, items: $edf$) (step 4)
#*  candidates $(e: acbe \to 0), (d: acbd \to 0), (f: acbf \to 0)$
#*  frequent patterns $\{\}$
#*  adding $ab$ to $F$
# eclat(prefix: $ab$, items: $edf$) (step 5)
#*  candidates $(e: abe \to 0), (d: abd \to 0), (f: abf \to 0)$
#*  frequent patterns $\{\}$
#*  adding $c$ to $F$
# eclat(prefix: $c$, items: $bedf$) (step 6)
#*  candidates $(b: cb \to 2), (e: ce \to 1), (d: cd \to 1), (f: cf \to 1)$
#*  frequent patterns $(b: cb \to 2)$
#*  adding $cb$ to $F$
# eclat(prefix: $cb$, items: $edf$) (step 7)
#*  candidates $(e: cbe \to 0), (d: cbd \to 0), (f: cbf \to 0)$
#*  frequent patterns $$
#*  adding $b$ to $F$
# eclat(prefix: $b$, items: $edf$) (step 8)
#*  candidates $(e: be \to 0), (d: bd \to 0), (f: bf \to 0)$
#*  frequent patterns $\{\}$
#*  adding $e$ to $F$
# eclat(prefix: $e$, items: $df$) (step 9)
#*  candidates $(d: ed \to 2), (f: ef \to 1)$
#*  frequent patterns $(d: ed \to 2)$
#*  adding $ed$ to $F$
# eclat(prefix: $ed$, items: $f$) (step 10)
#*  candidates $(f: edf \to 1)$
#*  frequent patterns $\{\}$
#*  adding $d$ to $F$
# eclat(prefix: $d$, items: $f$) (step 11)
#*  candidates $(f: df \to 1)$
#*  frequent patterns $\varnothing$

Result
: $[a, ac, acb, ab, c, cb, b, e, ed, d]$



=== Algorithm with TidList ===
To be able to calculate support quicker, 
* use TidList




== Links ==
=== Presentations ===
* http://www.analysis-of-patterns.net/files/bgoethals.pdf

=== Implementations ===
* http://www.borgelt.net/eclat.html
* http://adrem.ua.ac.be/sites/adrem.ua.ac.be/files/code/eclat.py


== See Also ==
* [[Local Pattern Discovery]]
* [[Frequent Pattern Mining]]
* [[Apriori]]

== Sources ==
* [[Data Mining (UFRT)]]

[[Category:Rule Mining]]
[[Category:Python]]</text>
      <sha1>g5q5ildd7ptd1vvksritgoti8ihizkk</sha1>
    </revision>
  </page>
  <page>
    <title>Rule Mining</title>
    <ns>0</ns>
    <id>460</id>
    <revision>
      <id>463</id>
      <timestamp>2014-05-16T15:21:11Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="404">{{stub}}

== Rule Mining ==
This is a specialization of [[Data Mining]] that deals with rules
* ''rules'' or ''patterns'' - correlation between features 

E.g. 
* like, lot $\Rightarrow$ positive
* not, like $\Rightarrow$ negative 



http://www.analysis-of-patterns.net/files/bgoethals.pdf


== Source ==
* [[Data Mining (UFRT)]]
* [[Web Intelligence and Big Data (coursera)]]


[[Category:Rule Mining]]</text>
      <sha1>57ejh4p7iwxfuknvnived6erb766of0</sha1>
    </revision>
  </page>
  <page>
    <title>Association Rule Mining</title>
    <ns>0</ns>
    <id>461</id>
    <revision>
      <id>464</id>
      <timestamp>2014-05-16T15:14:24Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3129">== Mining Association Rules ==
=== Association Rules ===
Association rule mining:
* Finding all the rules $X \to Y$ such that
* $P(X \land Y) \geqslant \text{min_supp}$ and 
* $P(Y | X) \geqslant \text{min_con}$
* these are ''predictive'' patterns

E.g.
* $\text{wings} \to \text{beak}$
* $\text{wings} \land \text{beak} \to \text{fly}$


Association rules
* $X \to Y$ is an ''association rule'' if
* $X$ and $Y$ are itemsets 
* $X \cap Y = \varnothing$
* $X$ is called the ''body''
* $Y$ is called the ''head'' (conclusion)


=== Motivation ===
Consider this example
* we data with customers and their purchases
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/as-rules-ex1.png


{| class=&quot;wikitable&quot;
!  || pasta || t.souse || red wine || seafood || white wine || salami
|-
! 1 
| {{yes}} || {{yes}} || {{yes}} ||  ||  ||  
|-
! 2 
| {{yes}} ||  || {{yes}} || {{yes}} || {{yes}} || {{yes}}
|-
! 3 
| {{yes}} || {{yes}} || {{yes}} || {{yes}} || {{yes}} || {{yes}} 
|-
! 4 
| {{yes}} || {{yes}} || {{yes}} || {{yes}} || {{yes}} || {{yes}} 
|-
! 5 
|  ||  ||  || {{yes}} || {{yes}} ||  
|}


Pattern 1: How to organize supermarket?
* we see that seafood and white wine usually go together, so put them together 
* these are associations that are not always observed in practice


Pattern 2: What to promote?
* we see a rule $\text{pasta} \land \text{souse} \to \text{red wine}$
* it doesn't always hold, but it's a typical pattern
* so promote red wine 


== Generation of Association Rules ==
* usually first you find [[Frequent Pattern Mining|Frequent Patterns]]
* then from them build association rules


=== Algorithm ===
Generate(frequent itemsets $F$, confidence threshold $\theta$)
* $R \leftarrow \varnothing$
* for each $X \in F$, for each $Y \subset X$
** if $\text{conf}(Y \subset X) = \cfrac{\text{supp}(X)}{\text{supp}(Y)} \geqslant \theta$
** then $R \leftarrow R \cup \{ Y \to X - Y \}$
* return $R$


=== Complexity ===
It computes association rules in polynomial time


== Examples ==
=== Example 1 ===
${A, B, C, D, E, F}$
* $T_1 = \{A,B,D,E\}$
* $T_2 = \{A,B,C,D,F\}$
* $T_3 = \{B,D,F\}$
* $T_4 = \{C,E,F\}$

Task:
* Find rules $X \to A$ ($A$ = Apple) with support threshold 50%
* Calculate the confidence of these rules
* Are there redundant rules?


Frequent items with support 50%:
* $[A, B, C, D, E, F, DF, BF, AD, BD, AB, CF, BDF, ABD]$ - calculated with [[Apriori]]
* ones that involve $A$: $[A, AD, AB, ABD]$
* so, rules are $\varnothing \to A, B \to A, D \to A, BD \to A$


Confidence:
* $\text{conf}(\varnothing \to A) = \cfrac{\text{supp}(\varnothing \to A)}{\text{supp}(\varnothing)} = \cfrac{2}{4}$
* $\text{conf}(B \to A) = \cfrac{\text{supp}(B \to A)}{\text{supp}(B)} = \cfrac{2}{3}$
* $\text{conf}(D \to A) = \cfrac{\text{supp}(D \to A)}{\text{supp}(D)} = \cfrac{2}{3}$
* $\text{conf}(BD \to A) =  \cfrac{\text{supp}(BD \to A)}{\text{supp}(BD)} = \cfrac{2}{3}$

Redundant rules
* the rule $BD \to A$ is redundant because we have $B \to A$ and $D \to A$


== See Also ==
* [[Local Pattern Discovery]]

== Sources ==
* [[Data Mining (UFRT)]]

[[Category:Rule Mining]]</text>
      <sha1>0v1n1gza7l79vf4yevn2c7epw8f8nb5</sha1>
    </revision>
  </page>
  <page>
    <title>Constraint-Based Pattern Mining</title>
    <ns>0</ns>
    <id>462</id>
    <revision>
      <id>465</id>
      <timestamp>2014-05-16T15:20:25Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4730">== Constraint-Based Pattern Mining ==
Goal: 
* to enumerate all patterns that satisfy some constraint $q$
* $q \equiv m(X, D) \geqslant \text{threshold}$
* so it's a general case of [[Frequent Pattern Mining]]
** where constraint is $\text{freq}(X, D) \geqslant \text{min_frec}$

=== Example ===
Example:
* suppose $q \equiv \sum_{x \in X} x.\text{price} \leqslant 8$
* prices: $(a \to 1, b \to 2, c \to 5, d \to 4, e \to 6, f \to 4)$
* the same idea as in [[Frequent Pattern Mining]]
* enumerate all subsets, check ones in which this constraint is satisfied
* solution:
** $(\{\} \to 0), (a \to 1), (b \to 2), (c \to 5), (d \to 4), (e \to 6),$ 
** $(f \to 4), (ab \to 3), (ac \to 6), (ad \to 5), (ae \to 7), (af \to 5),$
** $(bc \to 7), (bd \to 6), (be \to 8), (bf \to 6), (df \to 8), (abc \to 8),$
** $(abd \to 7), (abf \to 7)$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/lattice-price.png
* note that here when we add an item the price always increases!


== Properties ==
Properties of constraints in [[Lattice]]

=== Anti-Monotone ===
Anti-monotone constraint
* A constraint $q$ is ''anti-monotone'' iff 
** when an itemset $X$ satisfies $q$, then any $Y \subseteq X$ also satisfies $q$.
* $q(X) \Rightarrow \forall Y \subseteq X : q(Y)$


=== Monotone ===
Monotone constraint
* A constraint $q$ is ''monotone'' iff 
** when an itemset $X$ satisfies $q$, then any $Y \supseteq X$ also satisfies $q$.
* $q(X) \Rightarrow \forall Y \supseteq X : q(Y)$


=== Example ===
==== Example 1 ====
* Frequency is a anti-monotonic constraint:
** $\text{freq}(X) \geqslant \gamma \Rightarrow \forall Y \supseteq X: \text{freq}(Y) &gt; \gamma$
* sum of prices if a monotonic constraint:
** $\sum_{x \in X} x.\text{price} \leqslant \gamma \Rightarrow \forall Y \subseteq X: \sum_{y \in Y} y.\text{price} \leqslant \gamma$


==== Example 2 ====
* $T_1 = \{A,B,D,E\}, T_2 = \{A,B,C,D,F\}, T_3 = \{B,D,F\}, T_4 = \{C,E,F\}$
* $p(A) = 2, p(B) = 4, p(C) = 1, p(D) = 3, p(E) = 4, p(F) = 4$
* Consider this constraint: $\sum_{x \in X} p(x) \leqslant 6$ 
* Assume that $X$ is an itemset. When we add something to $X$, the sum only can grow
** so this constraint is monotonic:
** $\forall X \subseteq Y, \sum_{y \in Y} p(y) \leqslant 6 \Rightarrow \sum_{x \in X} p(X) \leqslant 6$
** and if we remove an item, we're sure that the price will decrease 

Since it's anti-monotone, can use Apriori to find all itemsets that satisfy it
* Level 1: $A, B, C, D, E, F$
* Level 2: $AB, AC, AD, AE, AF, BC, CD, CE, CF$
* Level 3: $ACD$


==== Summary ====
&lt;table class=&quot;wikitable&quot;&gt;
&lt;tr&gt;
	&lt;th&gt;Downward Closure&lt;/th&gt;&lt;th&gt;Upward Closure&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
	&lt;td&gt;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/downward-closure.png&lt;/td&gt;
	&lt;td&gt;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/upward-closure.png&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
	&lt;td&gt;
* $freq(X, D) \geqslant t$
* $\min(X.\text{val}) \geqslant t$
* $\max(X.\text{val}) \leqslant t$
* $\text{sum}(X.\text{val}) \leqslant t$
* $X \subseteq \{A, B, C\}$
	&lt;/td&gt;
	&lt;td&gt;
* $freq(X, D) \leqslant t$
* $\min(X.\text{val}) \leqslant t$
* $\max(X.\text{val}) \geqslant t$
* $\text{sum}(X.\text{val}) \geqslant t$
* $X \supseteq \{A, B, C\}$
	&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;


=== Convertible Constraints ===
Consider this dataset
* $T_1 = \{A,B,D,E\}, T_2 = \{A,B,C,D,F\}, T_3 = \{B,D,F\}, T_4 = \{C,E,F\}$
* $p(A) = 2, p(B) = 4, p(C) = 1, p(D) = 3, p(E) = 4, p(F) = 4$


And the following constraint
* $\text{avg}(X.\text{price}) \leqslant 3$
* it's not anti-monotonic: 
** $\text{avg}(B.\text{price}) = 4 \not \leqslant 3$, not satisfied
** $\text{avg}(AB.\text{price}) = 3 \leqslant 3$, satisfied
* it's not monotonic either:
** $\text{avg}(A.\text{price}) = 2$ and $\text{avg}(AB.\text{price}) = 3$


but we can convert it into anti-monotone by ordering items by price acs:
* $C &lt; A &lt; D &lt; B, E, F$
* now can traverse the search space in [[Breadth-First Search|BFS]]-way - with [[Eclat]]
** need to enumerate items in lexicographical ordering for that:
** $C, CA, CAD, ...$


Now we're sure that the average always increases 
* $\text{avg}(\varnothing) = 0, \text{avg}(C) = 1/1, \text{avg}(CA) = 4/2, \text{avg}(CAD) = 7/3, \text{avg}(CADF) = 11/4, \text{avg}(CADFE) = 16/5$




== Papers ==
* Heikki Mannila, Hannu Toivonen: Levelwise Search and Borders of Theories in Knowledge Discovery. Data Min. Knowl. Discov. 1(3): 241-258 (1997) (about anti-monotone constraints)
* Jian Pei, Jiawei Han: Can we push more constraints into frequent pattern mining? KDD 2000: 350-354 (about convertible constraints)

== See Also ==
* [[Local Pattern Discovery]]
* [[Frequent Pattern Mining]]

== Sources ==
* [[Data Mining (UFRT)]]

[[Category:Rule Mining]]</text>
      <sha1>n7v9i5xpxcmev1uwm0o8vjm18muwyey</sha1>
    </revision>
  </page>
  <page>
    <title>Pattern Mining</title>
    <ns>0</ns>
    <id>463</id>
    <revision>
      <id>466</id>
      <timestamp>2014-05-16T15:21:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="47">#перенаправление [[Rule Mining]]</text>
      <sha1>8oho1vrknj0e05viw4rr15pjej1i7yl</sha1>
    </revision>
  </page>
  <page>
    <title>Decision Tree (Data Mining)</title>
    <ns>0</ns>
    <id>464</id>
    <revision>
      <id>467</id>
      <timestamp>2014-05-27T10:19:23Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15558">== Decision Tree ==
This is a classification method used in [[Machine Learning]] and [[Data Mining]] that is based on [[Tree]]s
* not to confuse with Decision trees in [[Decision Analysis]]: [[Decision Tree (Decision Theory)]]


=== [[Rule-Based Classifier]]s ===
Suppose we have a set of rules
* if we group them by condition
* and then put redundant checks inside it
* we get a decision tree

Rules:
* IF pclass='1' AND sex='female' THEN survive=yes
* IF pclass='1' AND sex='male' AND age &lt; 5 THEN survive=yes
* IF pclass='2' AND sex='female' THEN survive=yes
* IF pclass='2' AND sex='male' THEN survive=no
* IF pclass='3' AND sex='male' THEN survive=no
* IF pclass='3' AND sex='female' AND age &lt; 4 THEN survive=yes
* IF pclass='3' AND sex='female' AND age &gt;= 4 THEN survive=no


If we put if conditions inside
* IF pclass='1' THEN
** IF sex='female' THEN survive=yes
** IF sex='male' AND age &lt; 5 THEN survive=yes
* IF pclass='2' 
** IF sex='female' THEN survive=yes
** IF sex='male' THEN survive=no
* IF pclass='3' 
** IF sex='male' THEN survive=no
** IF sex='female' 
*** IF age &lt; 4 THEN survive=yes
*** IF age &gt;= 4 THEN survive=no

We have a decision tree:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-ex-tit.png


=== Decision Trees ===
Consider this dataset 

{| class=&quot;wikitable&quot;
! Tid || Refund || Marital Status || Income || Cheat
|-
| 1 || Yes || Single || 125K || No
|-
| 2 || No || Married || 100K || No
|-
| 3 || No || Single || 70K || No
|-
| 4 || Yes || Married || 120K || No
|-
| 5 || No || Divorced || 95K || Yes
|-
| 6 || No || Married || 60K || No
|-
| 7 || Yes || Divorced || 220K || No
|-
| 8 || No || Single || 85K || Yes
|-
| 9 || No || Married || 75K || No
|-
| 10 || No || Single || 90K || Yes
|}

There could be several decision trees for this dataset:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-ex.png  https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-ex2.png


''Decision Tree'':
* leaves are labels with the predicted class
* internal nodes are labeled with attributes used to decide which path to take
* edges are labeled with values for this attributes or with boolean tests


Classification:
* suppose we take a previously unseen records (11, no, married, 112k, ?)
* we need to predict a class for this label 
* we put this instance on top of the tree and go the way to the leaf
* the leaf we end up is our class - cheat=no


=== Error Measures ===
A tree is ''perfect'' if it makes no errors on the training set
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-ex2.png
* this tree is perfect w.r.t. the training dataset
* learning error = 0%

Error measures:
* learning error: # of errors on the training dataset
* testing error: # of errors on the test set




== Learning Algorithms ==
There are several learning algorithms
* CART
* ID3, C4.5
* SLIQ, SPRINT, etc. 


=== Main Principles  ===
(ID3 algo) 

Given:
* training set $D$

The structure is recursive:
* let $D_t$ be a set of records that reach a node $t$
* at the beginning $t = \text{root}$ and $D_t \equiv D$
* if all $d \in D_t$ belong to the same class $y_t$
** then $t$ is labeled by $y_t$
* if $D_t \equiv \varnothing$
** then $t$ is labeled with the default class (e.g. the majority class)
* if $d \in D_t$ belong to different classes
** split $D_t$ into subsets $D_{t+1}$ and recursively apply the procedure to each



=== Splitting ===
* there is huge # of ways to split a set
* how to determine the best split?

Splitting:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-leaves.png
* multiway: good for nominal, most of the time select all of the attributes
* binary: good for numeric, but need to find where to split


Splitting numerical attributes
* goal: want to find subsets that are more &quot;pure&quot; than the original one
* &quot;pure&quot; = degree of homogeneity
* $\fbox{$C_1$: 5, $C_2$: 5}$ - homogeneous, high degree of impurity
* $\fbox{$C_1$: 9, $C_2$: 1}$ - non-homogeneous, low degree of impurity
* the lower the better
* use Information Gain for that


=== Stopping Conditions ===
Stop when
* all records in node $k$ belong to the same class
* the information gain is lower than some given threshold 


== [[Information Gain]] ==
Given a set $S$ with $K$ classes $C_1, ..., C_K$
* let $p_k = \cfrac{| C_k |}{| C |}$ - probability of record belonging to class $k$
* $I(S)$ - is a function of impurity that we want to minimize


=== Measures of Impurity ===
* Misclassification Error:
** $I(S) = 1 - \max_k p_k$
* Entropy and [[Information Gain]]
** $I(S) = - \sum_k p_k \cdot \log_2 p_k$
* Gini index:
** $I(S) = 1 - \sum_k p_k \cdot c_k$


https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-impurity.png


=== Information Gain ===
* how much information you get when partition the data? 
* def: $\Delta I = I(S) - p_L \cdot I(S_L) - p_R \cdot I(S_R)$
* $p_L = \cfrac{| S_L |}{| S |}, p_R = \cfrac{| S_R |}{| S |}$
* $I$ - a measure of impurity 


It's easy to generalize IG to Multi-way
* split $S$ to $K$ subsets $S_1, ..., S_K$
* $\Delta I = I(S) - \sum_k p_k \cdot I(S_k)$
* $\sum_k p_k \cdot I(S_k)$ is the [[Expected Value]] of Entropy in the partitioned dataset
** $E \big[ I \big( \{ S_1, ..., S_K \} \big) \big] = \sum_k p_k I(S_k) = - \sum_k p_k \log_2 p_k$
** with $p_k = \cfrac{| S_k |}{| S |}$
* but if we minimize this $\Delta I$, we end up with $K = N$
** i.e. we obtain as many subsets as there are records - and a set with just one element is 100% pure
* use Gain Ratio impurity
** $- \Delta I_K = \cfrac{\Delta I}{- \sum_k p_k \cdot \log_2 p_k}$


==== Example ====
Suppose we have a node with $S \equiv \fbox{$C_1$: 20, $C_2$: 30}$
* $S_L \equiv \fbox{$C_1$: 15, $C_2$: 5}$ and $S_L \equiv \fbox{$C_1$: 5, $C_2$: 25}$
* let $I$ be the Entropy function
* $I(S) = - \cfrac{20}{50} \log_2 \cfrac{20}{50} - \cfrac{30}{50} \log_2 \cfrac{30}{50} \approx 0.971$
* $I(S_L) = - \cfrac{15}{20} \log_2 \cfrac{15}{20} - \cfrac{5}{20} \log_2 \cfrac{5}{20} \approx 0.811$
* $I(S_R) = - \cfrac{5}{30} \log_2 \cfrac{5}{30} - \cfrac{5}{30} \log_2 \cfrac{5}{30} \approx 0.65$
* $\Delta I = I(S) - p_L \cdot I(S_L) - p_R \cdot I(S_R) = 0.971 - 0.4 \cdot 0.811 - 0.6 \cdot 0.65 = 0.26$


Another example with $S \equiv \fbox{$C_1$: 20, $C_2$: 30}$
* suppose that now we want to split to $S_L \equiv \fbox{$C_1$: 10, $C_2$: 15}$ and $S_L \equiv \fbox{$C_1$: 10, $C_2$: 15}$
* in this case it's clear that we don't have any IG
* so min value is 0, and there's no max boundary


=== Splitting Algorithm ===
for each attribute $A_i$ 
* find the best partitioning $P^*_{A_i} = \{S_1, ..., S_K\}$ of $S$
** $P^*_{A_i}$ maximizes the information gain
* among all $\{ P^*_{A_i} \}$ select the maximal one
* split by it


Best to split in halves: $K = 2$
* how to choose $\alpha$ that splits $S$ into $S_L$ and $S_R$?
* try several, pick up the best
* note that $\Delta I$ is not monotonic - have to try all of them



== [[Overfitting]] ==
Perfect decision trees perform 100% accurate on the training set
* but perform very poorly on a test set
* this is called [[Overfitting]]
* when performing [[Machine Learning Diagnosis]] we see that the more nodes a decision tree has, the poorer it performs
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/overfitting-learning-curves.png  



How to get the optimal complexity of a tree?
* Pre-pruning 
** Stop before a tree becomes perfect (fully-grown)
* Post-pruning 
** Grow a perfect tree
** Prune the nodes bottom-up


=== Pre-Pruning ===
It's about finding a good stopping criterion

Simple ones:
* when # of instances in a node goes below some threshold
* when the misclassification error is lower than some threshold $\beta$
** $1 - \max_k p_k &lt; \beta$
* when expanding current node doesn't give a significant information gain $\Delta I$
** $\Delta I &lt; \beta$


More complex:
* when class distribution of instances becomes independent from available features
** e.g. using [[Chi-square Test of Independence]]


=== Post-Pruning ===
[[Cost-Complexity Pruning]] 
* by Breiman, Olshen, Stone (1984) 


== Practical Issues ==
=== Decision Boundaries ===
the decision boundaries are rectilinear
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-boundary.png
* for some problems not always good
* use another models: [[Linear Regression]], [[Neural Networks]] etc



=== Handling Missing Values ===
Two options 
* discard all NAs
* modify the algorithm


==== Algorithm Modification ====
Modification:
* suppose that we have some splitting test criterion $T$ and dataset $S$
* information gain for splitting $S$ using $T$ is 
** $\Delta I (S, T) = I(S) - \sum_k \alpha_{T, k} \cdot I(S_k)$
* let $S_0 \subseteq S$ for which we can't evaluate $T$ (i.e. because needed values are missing)
* if $S_0 \not \equiv \varnothing$
** calculate the information gain as
** $\cfrac{|S - S_0|}{| S |} \Delta I (S - S_0, T)$
* suppose such $T$ is chosen, what to do with values from $S_0$?
** add them to all the subsets with weight proportional to the size of these subsets
** $w_k = \cfrac{| S |}{|S - S_0|}$
** and information gain is computed using sums of weights instead of counts 


==== Example ====
&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;
{| class=&quot;wikitable&quot;
! X || Y || Z || Class 
|-
| a || 70 || Yes || + 
|-
| a || 90 || Yes || - 
|-
| a || 85 || No || - 
|-
| a || 95 || No || - 
|-
| a || 70 || No || + 
|-
| ? || 90 || Yes || + 
|-
| b || 78 || No || + 
|-
| b || 65 || Yes || + 
|-
| b || 75 || No || + 
|-
| c || 80 || Yes || - 
|-
| c || 70 || Yes || - 
|-
| c || 80 || No || + 
|-
| c || 80 || No || + 
|-
| c || 96 || No || +
|}
&lt;/td&gt;

&lt;td&gt;

* There is one missing value for $X$:  $(?, 90, \text{Yes}, +)$
* let $I$ be the misclassification error
* $I(S - S_0) = 5/13$ (5 in &quot;-&quot;, 8 in &quot;+&quot;)
* $I(S - S_0 | X = a) = 2/5$
* $I(S - S_0 | X = b) = 0$
* $I(S - S_0 | X = c) = 2/5$
* calculate IG $\cfrac{|S - S_0|}{| S |} \Delta I (S - S_0, T)$
* $\Delta I = \cfrac{13}{14} \cdot (\cfrac{5}{13} - \cfrac{5}{13} \cdot \cfrac{2}{5} - \cfrac{3}{13} \cdot 0 - \cfrac{5}{13} \cdot \cfrac{2}{5}) = \cfrac{1}{14}$

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;


Distribute the values to subsets
* according to the value of $X$
* but the rows with missing values are put to all the subsets
** and the weight is proportional to the size of this subset prior to adding these rows

&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;
{| class=&quot;wikitable&quot;
|+ $X = a$
|-
| $Y$ || $Z$ || Class || $w$ 
|-
| 70 || Yes || + || 1 
|-
| 90 || Yes || - || 1 
|-
| 85 || No || - || 1 
|-
| 95 || No || - || 1 
|-
| 70 || No || + || 1 
|-
| '''90''' || '''Yes''' || '''+''' || '''5/13'''
|}
&lt;/td&gt;
&lt;td&gt;
{| class=&quot;wikitable&quot;
|+ $X = a$
|-
| $Y$ || $Z$ || Class || $w$ 
|-
| 78 || No || + || 1 
|-
| 65 || Yes || + || 1 
|-
| 75 || No || + || 1
|-
| '''90''' || '''Yes''' || '''+''' || '''3/13''' 
|}
&lt;/td&gt;
&lt;td&gt;
{| class=&quot;wikitable&quot;
|+ $X = a$
|-
| $Y$ || $Z$ || Class || $w$
|-
| 80 || Yes || - || 1 
|-
| 70 || Yes || - || 1 
|-
| 80 || No || + || 1 
|-
| 80 || No || + || 1 
|-
| 96 || No || + || 1 
|-
| '''90''' || '''Yes''' || '''+''' || '''5/13''' 
|}
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;


==== Classification with Modification ====
Classification:
* let $P(C | E,T)$ be the probability of classifying case $E$ to class $C$ using tree $T$
* define it recursively:
* if $t = \text{root}(T)$ is a leaf (i.e. it's a singleton tree)
** then P(C | E,T) is the relative frequency of training cases in class $C$ that reach $T$ 
* if $t = \text{root}(T)$ is not a leaf and $t$ is partitioned using attribute $X$
** if $E.X = x_k$
*** then $P(C | E,T) = P(C | E,T_k)$ where $T_k$ is a subtree of $T$ where $X = x_k$
** if $E.X$ is unknown,
*** then $P(C|E,T) = \sum_{k=1}^{K} \cfrac{|S_k|}{|S-S_0|} \cdot P(C | E,T)$ 
*** so we sum up probabilities of belonging to class $C$ from each child of $t$
* predict that a record belongs to class $C$ by selecting the highest probability $P(C|E,T)$


==== Example ====
https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-class-with-nas.png
* assume that $X$ is unknown - how to classify the case? 
* $P(+ |E,T) = \sum_{k=1}^{K} P(+ | E,T_k) = \cfrac{20}{50} \cdot \cfrac{15}{20} + \cfrac{30}{50} \cdot \cfrac{5}{30} = \cfrac{20}{50}$
* $P(- |E,T) = \sum_{k=1}^{K} P(- | E,T_k) = \cfrac{20}{50} \cdot \cfrac{5}{20} + \cfrac{30}{50} \cdot \cfrac{25}{30} = \cfrac{30}{50}$
* $P(- |E,T) &gt; P(+ |E,T) \Rightarrow$ predict &quot;$-$&quot;




== Decision Tree Learning Examples ==
=== Example 1 ===
Suppose we have the following data:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-ex1-0.png
* 2 classes: $\square$ (S) and $\bigcirc$ (C)
* there are 5S and 3C, total 8: 
** $I(S) = - \frac{3}{8} \log_2 \frac{3}{8} - \frac{5}{8} \log_2 \frac{5}{8}  = 0.954$
* there are 2 attributes: $X$ and $Y$ 
** and 2 ways to split each: $X &lt; 1.5, X &lt; 2.5, Y &lt; 1.5, Y &lt; 2.5$

{| class=&quot;wikitable&quot;
! || || $S_L$ || $I(S_L)$ || $S_R$ || $I(S_R)$ || $E[I(\{S_L, S_R\})]$ || $\Delta I$
|-
! $X &lt; 1.5$ 
| https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-ex0-1.png
| $2C$ || 0 || $3C, 3S$ || 1 || $\frac{2}{8} \cdot 0 + \frac{5}{8} \cdot 1 = 0.75$ || $0.954 - 0.75 = \fbox{0.204}$
|-
! $X &lt; 2.5$ 
| https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-ex0-2.png
| $3C, 2S$ || 0.971 || $2C, 1S$ || 0.918 || $\frac{5}{8} \cdot 0.971 + \frac{3}{8} \cdot 0.918 = 0.951$ || 0.003
|-
! $Y &lt; 1.5$ 
| https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-ex0-3.png
| $2C, 1S$ || 0.918 || $3C, 2S$ || 0.971 || 0.951 || 0.003
|-
! $Y &lt; 2.5$ 
| https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-ex0-4.png
| $2C$ || 1 || $3C, 3S$ || 0 || 0.75 || 0.204
|}


We decide to use $X &lt; 1.5$ to split the data
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-ex1-1.png
* left part is pure - no need to split it
* right part: $3C, 3S$, it's not pure: $I(S) = 1$


{| class=&quot;wikitable&quot;
! || $I(S_L)$ || $I(S_R)$ || $\Delta I$
|-
! $X &lt; 2.5$
| 0.918 || 0.918 || 0.082
|-
! $Y &lt; 1.5$
| 1 || 1 || 0
|-
! $Y &lt; 2.5$
| 0.811 || 0 || $\fbox{0.459}$
|}


* $Y &lt; 2.5$ - next best splitting criterion
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-ex1-2.png
* if we stop here, we obtain the following tree:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-ex1-res.png
* this tree is not a perfect tree - we can continue and at the end obtain a perfect one 



== Pros and Cons ==
=== Advantages ===
* fast 
* handles both symbolic and numerical attributes
* works well with redundant attributes
* invariant to any monotonic transformation of the dataset 
* robust to [[Outliers]]
** e.g. a tree with $\text{income}$ will behave the same way as a tree with $\sqrt{\text{income}}$
* easy to interpret and explain to non-specialists
* help to understand what are most important attributes

=== Disadvantages ===
* prone to overfitting, need pruning techniques
* even a small variation in data can lead to very different tree
* decision boundaries are rectilinear 


== Sources ==
* [[Data Mining (UFRT)]]
* [[Introduction to Data Science (coursera)]]

[[Category:Machine Learning]]
[[Category:Classifiers]]</text>
      <sha1>4kkdp0ifp5kl7xmjqmqxz4seua9wxkl</sha1>
    </revision>
  </page>
  <page>
    <title>Rule-Based Classifier</title>
    <ns>0</ns>
    <id>465</id>
    <revision>
      <id>468</id>
      <timestamp>2014-05-27T10:50:07Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6396">== Rule-Based Classifier ==
Rule-based classifiers
* use a set of IF-THEN rules for classification 
* if {condition} then {conclusion}
* if part - ''condition'' stated over the data
* then part - a class label, ''consequent''


== 1-Rule ==
=== Example ===
Suppose we have the following dataset 
{|class=&quot;wikitable&quot;
|+ Titanic dataset [http://www.kaggle.com/c/titanic-gettingStarted/data]
! pclass || sex || age || sibsp || parch || fare || embarked || survived
|-
| 3 || male || 22 || 1 || 0 || 7.25 || S || 0
|-
| 1 || female || 38 || 1 || 0 || 71.28 || C || 1
|-
| 3 || female || 26 || 0 || 0 || 7.93 || S || 1
|-
| 1 || female || 35 || 1 || 0 || 53.10 || S || 1
|-
| 3 || male || 35 || 0 || 0 || 8.05 || S || 0
|-
| 3 || male ||  || 0 || 0 || 8.46 || Q || 0
|-
| 1 || male || 54 || 0 || 0 || 51.86 || S || 0
|-
| 3 || male || 2 || 3 || 1 || 21.08 || S || 0
|-
| 3 || female || 27 || 0 || 2 || 11.13 || S || 1
|-
| 2 || female || 14 || 1 || 0 || 30.07 || C || 1
|-
| 3 || female || 4 || 1 || 1 || 16.70 || S || 1
|-
| 1 || female || 58 || 0 || 0 || 26.55 || S || 1
|}

If we visualize the data by sex
* color-coding survived with blue and not survived with red
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/ds/rules-tit-sex.png
* so we see that most women survived $\to$ can assume that all survived 
* e.g. have a rule $x.\text{women} \Rightarrow \text{survived}$


Rules 
* there could be many rules like this
* if most children under 4 survived, assume all children under 4 survived
* if most people with 1 sibling survived, assume all people with 1 sibling survided 
* calculate misclassification error (error rate) and take the best!


Some variables have more than 2 values
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/ds/rules-tit-plcass.png
* if pclass = 1 then survived=yes
* if pclass = 2 then survived=yes
* if pclass = 3 then survived=no


=== One Rule Algorithm ===
* for each attribute $A$ 
* for each value $V$ of $\text{dom}(A)$
* create a rule
** find the most frequent class $c$
** create a rule &quot;if $A = V$ then $c$
** calculate the error rate of this rule
* select attribute with best error rate for its rules


Can see 1-Rule as a one-level [[Decision Tree (Data Mining)]]
* one branch for each value
* each branch assigns most frequent class


== Several Conditions ==
We also can consider several attributes at the same time
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/ds/rules-tit-2cl.png
* IF pclass='1' AND sex='female' THEN survive=yes
* IF pclass='2' AND sex='female' THEN survive=yes
* IF pclass='2' AND sex='male' THEN survive=no
* IF pclass='3' AND sex='male' THEN survive=no
* ...


Can go further
* IF pclass='3' AND sex='female' AND age &lt; 4 THEN survive=yes
* IF pclass='3' AND sex='female' AND age &gt;= 4 THEN survive=no
* IF pclass='1' AND sex='male' AND age &lt; 5 THEN survive=yes


=== Getting Rules ===
Where to extract these rules from?
* from [[Decision Tree (Data Mining)|Decision Trees]]
** each path from top to the bottom is a rule, and the leaf is a class
* sequential covering - for learning rules directly (PRISM algorithm [http://www.cs.bc.edu/~alvarez/DataMining/Notes/covering.html])  
** repeatedly removes a portion of the dataset
** the portion - instances covered by the most promising rule at each stage


=== Sequential Covering Algorithm ===
'''PRISM'''(dataset $D$):
* $R$ - resulting rule dataset, $R \leftarrow \varnothing$
* for each class $C$ 
* while $D \not \equiv \varnothing$
** $r \leftarrow$ FindNextRule($C, D$)
** $R \leftarrow R \cup \{ r \}$
** remove from $D$ all instances correctly classified by $r$


Finding the next rule [http://www.evernote.com/shard/s344/sh/d82d9776-7319-4ce2-8cb3-f96c59dd70ba/86a3d6d63dc9ffef6e0420cd0944e845]
* FindNextRule($C, D$) subroutine
* uses [[Depth-First Search]] to construct the next rule for class $C$ 
* we know the consequent for this rule: it's $C$
* so we need to construct only ''antecedent'' (предыдущий член отношения)
** start with an empty antecedent,
** iteratively add most promising &quot;attribute=value&quot; constraints 
** use error rate to get the best one 
* continue DFS until the rule is specific enough to make no classification errors in the given dataset



'''FindNextRule'''(class $C$, dataset $D$):
* let $A$ be all attributes in $D$
* let $r$ be the initial rule $r: \varnothing \to C$
** not examining anything, just always returning $C$
* while $r$ incorrectly classifies some non-$C$ instances in $D$
** let $\text{ant}(r) \to C$ be the rule computed at the previous iteration
*** $\text{ant}(r)$ is the ''antecedent'' of $r$;
*** it means take the rule from the previous iteration of the rule creation loop 
*** (or an empty rule if this is the first iteration)
** for each pair $(a, v)$ s.t. $a \in A$ and $v \in \text{dom}(a)$
*** consider rule $\text{ant}(r) \land (a = v) \to C$
*** calculate the accuracy of this rule
** let $(a^*, v^*)$ be the pair with the best accuracy 
** so update $r$ by adding this condition:
*** let $r: \text{ant}(r) \land (a^* = v^*) \to C$
** remove attribute $a^*$ from $A$:
*** $A \leftarrow A - \{ a^* \}$
* return $r$


=== Example ===
A good example of PRISM can be found at [http://www.cs.bc.edu/~alvarez/DataMining/Notes/covering.html]


=== Strategies for Learning Rules ===
General-to-Specific
* start with an empty rule 
* add constraints to eliminate negative examples 
* stop when only positive examples are covered

Specific-to-General
* start with a rule that identifies a single random instance
* remove constraints to cover more positive examples
* stop when further generalization starts covering negatives



== Evaluation ==
Each rule can be evaluated using these measures
* coverage: # of data points that satisfy conditions
* accuracy = # of correct predictions / coverage


Other measures of &quot;promisingness&quot;
* [[Information Gain]]
* see page 38 at [http://www.slideshare.net/pierluca.lanzi/machine-learning-and-data-mining-12-classification-rules]


== Sources and Links ==
* [[Introduction to Data Science (coursera)]]
* http://www.slideshare.net/pierluca.lanzi/machine-learning-and-data-mining-12-classification-rules
* http://www.tutorialspoint.com/data_mining/dm_rbc.htm 
* http://www.cs.bc.edu/~alvarez/DataMining/Notes/covering.html


[[Category:Classifiers]]
[[Category:Machine Learning]]</text>
      <sha1>c8xd9hzfhg5qgaysoz5rwct4jfm13id</sha1>
    </revision>
  </page>
  <page>
    <title>Cost-Complexity Pruning</title>
    <ns>0</ns>
    <id>466</id>
    <revision>
      <id>469</id>
      <timestamp>2014-06-08T19:53:51Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5679">== Cost-Complexity Pruning ==
Post-pruning algorithm for [[Decision Tree (Data Mining)|Decision Trees]]
* by Breiman, Olshen, Stone (1984) 


=== Cost-Complexity Function ===
* need to optimize the cost-complexity function
* $R_\alpha (T) = R(T) + \alpha \cdot | f(T) |$ where
** $R(T)$ is the training/learning error
** $f(T)$ a function that returns the set of leaves of tree $T$
** $\alpha$ is a [[Regularization]] parameter
* $R(T) = \sum_{t \in f(T)} r(t) \cdot p(t) = \sum_{t \in f(T)} R(t)$
** $\sum_{t \in f(T)} R(t)$ - sum of misclassification errors at each leaf
** $r(t) = 1 - \max_k p(C_k - t)$  - ''misclassification rate''
** $p(t) = \cfrac{n(t)}{n}$ with $n(t)$ being the # of records in node $t$ and $n$ - total # of records


=== Pruning Subtrees ===
Subtrees:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-subtrees.png

Pruning a subtree $T_{t}$
* $R_\alpha(T - T_t) - R_\alpha(T)$ - variation of the cost-complexity function
** this is the cont-complexity when pruning subtree $T_t$
* $R_\alpha(T - T_t) - R_\alpha(T) = R(T - T_t) - R(T) + \alpha ( | f(T - T_t) | - |f(T)| ) = R(t) - R(T_t) + \alpha ( 1 - |f(T_t)| )$
* let $\alpha' = \cfrac{R(t) - R(T_t)}{|f(T_t)| - 1}$
* variation is 
** null if $\alpha = \alpha'$
** negative if $\alpha &lt; \alpha'$
** positive if $\alpha &gt; \alpha'$




=== Algorithm ===
Pruning Algorithm:
* Initialization:
** let $T^1$ be the tree obtained with $\alpha^1 = 0$
** by minimizing $R(T)$
* Step 1
** select node $t \in T^1 $ that minimizes 
*** $g_1(t) = \cfrac{R(t) - R(T^1_t)}{|f(T^1_t)| - 1}$
** let $t_1$ be this node
** let $\alpha^2 = g_1(t_1)$ and $T^2 = T^1 - T^1_{t_1}$
* step $i$
** select node $t \in T^i $ that minimizes 
*** $g_i(t) = \cfrac{R(t) - R(T^i_t)}{|f(T^i_t)| - 1}$
** let $t_i$ be this node
** let $\alpha^{i + 1} = g_i(t_i)$ and $T^{i+1} = T^i - T^i_{t_i}$


Output:
* a sequence of trees $T^1 \supseteq T^2 \supseteq \ ... \ \supseteq T^k \supseteq \ ... \ \supseteq \{ \text{root} \}$
* a sequence of parameters $\alpha^1 \leqslant \alpha^2 \leqslant \ ... \ \leqslant \alpha^k \leqslant \ ... $


=== Choosing $\alpha$ ===
The algorithm outputs $\alpha^1 \leqslant \alpha^2 \leqslant \ ... \ \leqslant \alpha^k \leqslant \ ... $
* need to choose some $\alpha \in [\alpha^k, \alpha^{k+1} )$
* let $\alpha \in [\alpha^k, \alpha^{k+1} )$

How to choose $\alpha$
* use [[Cross-Validation]]
* it's the parameter that minimizes the validation error
* thus helps avoid [[Overfitting]]


== Example ==
=== Example 1 ===
Suppose we have the following tree:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-pruning-ex1-1.png
* we want to prune it 
* we have 3 inner nodes where we can prune: $t_1 \equiv \text{root}, t_2, t_3$

Some formulas:
* $R(T_t)$ - training error of a subtree $T_t$ - a tree with root at node $t$
** $R(T_t) = \sum_{l \in f(T_t)} R(l)$ - sum of all training errors over all leaves
* $R_(t)$ - training error of node $t$
** $R_(t)  = r(t) \cdot p(t)$ 
** $r(t)$ - misclassification error at this none (without considering the leaves)
** $p(t)$ - proportion of data items reached $t$ (i.e. # of items reached $t$ divided by # of training items)
* $g(t) = \cfrac{R(t) - R(T_{T_t})}{| f(T_t) | - 1}$
** $| f(T_t) | - 1$ is the number of leaves to prune 


'''Iteration 1:'''
* let $\alpha^{(1)} = 0$
 
{| class=&quot;wikitable&quot;
! $t$ || $R_(t)$ || $R(T_t)$ || $g(t)$
|-
| $t_1$ || $\cfrac{8}{16} \cdot \cfrac{16}{16}$ || $T_{t_1}$ - the entire tree &lt;br/&gt; all leaves are pure &lt;br/&gt; $R(T_{t_1}) = 0$ || $\cfrac{8/16 - 0}{4 - 1} = \cfrac{1}{6}$ 
|-
| $t_2$ || $\cfrac{4}{12} \cdot \cfrac{12}{16} = \cfrac{4}{16}$ &lt;br/&gt; (there are 12 records, 4 $\blacksquare$ + 8 $\bigcirc$ ) || $R(T_{t_2}) = 0$ || $\cfrac{4/16 - 0}{3 - 1} = \cfrac{1}{8}$
|-
| $t_3$ || $\cfrac{2}{6} \cdot \cfrac{6}{16} = \cfrac{2}{16}$  || $R(T_{t_3}) = 0$ ||  $\cfrac{2/16 - 0}{3 - 1} = \cfrac{1}{8}$
|}

We want to find the minimal $g(t)$ 
* it's $g(t_2)$ and $g(t_3)$
* in case of a tie, we choose the one that prunes fewer nodes
* i.e. $g(t_3)$
* so prune at $t_3$
* let $\alpha^{(2)} = 1/8$ (the min $g(t)$)

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-pruning-ex1-2.png



'''Iteration 2:'''
* in the tree now we have only candidates: $t_1$ and $t_2$


{| class=&quot;wikitable&quot;
! $t$ || $R_(t)$ || $R(T_t)$ || $g(t)$
|-
| $t_1$ || $\cfrac{8}{16} \cdot \cfrac{16}{16}$ || $\cfrac{2}{16}$ || $\cfrac{8/16 - 2/16}{3 - 1} = \cfrac{6}{32}$
|-
| $t_2$ || $\cfrac{4}{12} \cdot \cfrac{12}{16}$ || $\cfrac{2}{16}$ || $\cfrac{4/16 - 2/16}{2 - 1} = \cfrac{1}{8}$
|}


Find minimal $g(t)$: 
* it's $g(t_2) = 1/8$
* let $\alpha^{(3)} = 1/8$
* prune at $t_2$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/decision-tree-pruning-ex1-3.png



'''Iteration 3:'''
* only one candidate for pruning: $t_1$
* $\alpha^{(4)} = g(t_1) = \cfrac{8/16 - 4/16}{2 - 1} = \cfrac{1}{4}$



'''Selecting the best''':
* we have these values: $\alpha^{(0)} = 0, \alpha^{(1)} = 1/8, \alpha^{(2)} = 1/8, \alpha^{(3)} = 1/4$
* by the theorem we want to find tree such $T$ that minimizes the cost-complexity function 
** if $0 \geqslant \alpha &lt; 1/8$, then $T_1$ is the best
** if $\alpha = 1/8$, then $T_2$ is the best
** if $1/8 &lt; \alpha &lt; 1/4$, then $T_3$ is the best
** if $1/8 &lt; \alpha &lt; 1/4$, then $T_3$ is the best
* to choose $\alpha$ use [[Cross-Validation]]



=== Example 2 ===
From IT4BI 2013 year exam:
* see [https://docs.google.com/document/d/1d0Mh6XBX9NVyDExkVRNFIbrGGIwDugNDnP75xuDX9Aw/pub here]


== Sources ==
* [[Data Mining (UFRT)]]

[[Category:Machine Learning]]</text>
      <sha1>khils8pjcbp0d6yic1bspjxfv8h6o93</sha1>
    </revision>
  </page>
  <page>
    <title>Error Metrics</title>
    <ns>0</ns>
    <id>467</id>
    <revision>
      <id>470</id>
      <timestamp>2014-05-27T16:14:33Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="68">#перенаправление [[Evaluation of Binary Classifiers]]</text>
      <sha1>68muyqmho9xsrzq1j3pjr85mflp4phx</sha1>
    </revision>
  </page>
  <page>
    <title>ROC Analysis</title>
    <ns>0</ns>
    <id>468</id>
    <revision>
      <id>471</id>
      <timestamp>2015-01-18T11:16:42Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15836">== ROC Analysis ==
ROC stands for '''R'''eceiver '''O'''perating '''C'''haracteristic (from Signal Detection Theory)
* initially - for distinguishing noise from not noise
* so it's a way of showing the performance of Binary Classifiers
** only two classes - noise vs not noise
* it's created by plotting the fraction of True Positives vs the fraction of False Positives
** True Positive Rate, $\text{tpr} = \cfrac{\text{TP}}{\text{TP} + \text{FN}}$   (sometimes called &quot;sensitivity&quot; or &quot;recall&quot;)
** False Positive Rate $\text{fpr} = \cfrac{\text{FP}}{\text{FP} + \text{TN}}$   (also Fall-Out)
** see [[Evaluation of Binary Classifiers]]


[[Evaluation of Binary Classifiers]]
* precision and recall are popular metrics to evaluate the quality of a classification system
* ROC Curves can be used to evaluate the tradeoff between true- and false-positive rates of classification algorithms


Properties:
* ROC Curves are insensitive to class distribution 
* If the proportion of positive to negative instances changes, the ROC Curve will not change


== ROC Space ==
When evaluating a binary classifier, we often use a [[Confusion Matrix]]
* however here we need only TPR and FPR
* $\text{tpr} = \cfrac{\text{TP}}{\text{TP} + \text{FN}}$
** Fraction of positive examples correctly classified 
* $\text{fpr} = \cfrac{\text{FP}}{\text{FP} + \text{TN}}$
** Fraction of negative examples incorrectly classified
* ROC space is 2DIM:
** $X: \text{fpr}, Y: \text{tpr}$

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/roc-space.png


=== ROC Space Baseline ===
Baseline
* for the baseline we put a random classifier that predicts 1 with some probability
* e.g. on the illustration we have 3 random classifiers:
* always predict 0 (0% change to predict 1)
* predict 1 in 80% cases
* always predict 1 (in 100% cases)


In practice, we can never obtain a classifier below this line 
* suppose we have a classifier $C_1$ below the line with $\text{fpr} = 80\%$, and $\text{tpr} = 30\%$
* can make it better than random by inverting its prediction:
* $C_2(x)$: if $C_1(x) = 1$, return 0; if $C_1(x) = 0$, return 1
* position on the ROC Space of $C_2$ is $(1 - \text{fpr}, 1 - \text{tpr}) = (20\%, 70\%)$
* roc-inv.png


=== Multi-Class Classifier ===
If you have a multi-class classifier, use [[One-vs-All Classification]]
* e.g. for 3 classes $C_1, C_2, C_3$ build 3 ROC spaces

{| class=&quot;wikitable&quot;
! ROC Space || 1 || 2 || 3
|-
! Positive 
| $C_1$  || $C_2$ || $C_3$ 
|-
! Negative 
| $C_2 \cup C_3$ || $C_1 \cup C_3$ || $C_1 \cup C_2$ 
|}


=== ROC Convex Hull ===
Suppose we have 5 classifiers $C_1, C_2, ..., C_5$
* we calculate $\text{fpr}$ and $\text{tpr}$ for each and plot them on one plot
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/roc-plot-classifiers.png


Then we can try to find classifiers that achieve the best $\text{fpr}$ and $\text{tpr}$
* by the [[Dominance]] principle, we have the following Pereto frontier
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/roc-convex-hull.png
* this is called the &quot;ROC Convex Hull&quot;
* classifiers below this Hull are always suboptimal 
* e.g. $C_3$ is always worse than anything else



=== ISO Accuracy Lines ===
There's a simple relationship between accuracy and $\text{fpr}$, $\text{tpr}$:
notation:
* $N$ the # of examples, 
* $\text{NEG}$ - # of negative examples, and $\text{POS}$ - # of positive examples
* $\text{neg}$ - fraction of negative examples, $\text{pos}$ - fraction of positive examples

$\text{acc} = \text{trp} \cdot \text{pos} + \text{neg} - \text{neg} \cdot \text{fpr}$
* $\text{acc} = \cfrac{\text{TP} + \text{TN}}{N} = \cfrac{\text{TP}}{N} + \cfrac{\text{TN}}{N} = \cfrac{\text{TP}}{\text{POS}} \cdot \cfrac{\text{POS}}{N} + \cfrac{\text{NEG} - \text{FP}}{N} = \cfrac{\text{TP}}{\text{POS}} \cdot \cfrac{\text{POS}}{N} + \cfrac{\text{NEG}}{N} - \cfrac{\text{FP}}{\text{NEG}} \cdot \cfrac{\text{NEG}}{N} = \text{trp} \cdot \text{pos} + \text{neg} - \text{neg} \cdot \text{fpr}$
* so can rewrite this and get 
** $\text{tpr} = \cfrac{\text{acc} - \text{neg}}{\text{pos}} + \cfrac{\text{neg}}{\text{pos}} \cdot \text{fpr}$
* it's a line: $y = ax + b$
** $y = \text{tpr}, x = \text{fpr}, a = \cfrac{\text{neg}}{\text{pos}}, x = \cfrac{\text{neg}}{\text{pos}}, b = \cfrac{\text{acc} - \text{neg}}{\text{pos}}$


Property
* the ratio $\text{neg} / \text{pos}$ is the slope $a$ of our line
** changing this ratio we can have many slopes
* and changing accuracy we can obtain many parallel lines with the same slope
* higher lines are better

to calculate the corresponding accuracy
* find the intersection point of the accuracy line (red)
* and the descending diagonal (blue)


{| class=&quot;wikitable&quot;
|+ Examples
! $\text{neg} / \text{pos}$ || Accuracy Lines 
|-
| $\text{neg} / \text{pos} = 1$ || https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/iso-lines-50.png
|-
| $\text{neg} / \text{pos} = 0.5$ || https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/iso-lines-25.png
|}


=== ISO Accuracy Lines vs Convex Hull ===
Recall this picture:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/roc-convex-hull.png
* this the convex hull of the ROC plot


Each line segment of the ROC Convex Hull is an ISO accuracy line
* for a particular class distribution (slope) and accuracy
** all classifiers on a line achieve the same accuracy for this distribution
* $\text{neg} / \text{pos} &gt; 1$
** distribution with more negative examples
** the slope is steep
** classifier on the left is better
* $\text{neg} / \text{pos} &lt; 1$
** distribution with more positive examples
** the slope is flatter
** classifier on the right is better


Each classifier on the convex hull is optimal 
* w.r.t. accuracy
* for a specific distribution


=== Selecting the Optimal Classifier ===
First, we need to know the ratio $\text{neg} / \text{pos}$
* given it, we can find the classifier that achieves the highest accuracy for this ratio
* fix the ratio, keep increasing accuracy until reach the end of the hull

{| class=&quot;wikitable&quot;
! Distribution || Best Classifier || Accuracy || ISO Accuracy Line
|-
| $\text{neg} / \text{pos} = 1/1$ || $C_2$ || $\approx$ 81% || https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/roc-convex-hull-best-acc-1.png
|-
| $\text{neg} / \text{pos} = 1/4$ || $C_4$ || $\approx$ 83% || https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/roc-convex-hull-best-acc-2.png
|-
| $\text{neg} / \text{pos} = 4/1$ || $C_4$ || $\approx$ 81% || https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/roc-convex-hull-best-acc-3.png
|}



== ROC Curves ==
=== Scoring Classifiers ===
A scoring classifier (or ranker) is an algorithm that 
* instead of one single label it outputs the scores for each class
* and you take the label with the highest score 
* e.g.: [[Naive Bayes Classifier]], [[Neural Networks]], etc


For binary classification  
* ranker $F$ outputs just a single number
* have to set some threshold $\theta$  to transform the raker into a classifier
** positive class if $F(X, +) &gt; \theta$ 
* e.g. like in [[Logistic Regression]]
* how to set a threshold? 
** use [[Cross-Validation]] for fining the best value for $\theta$
** or draw ROC Curves, producing a point in the ROC Space for each possible threshold


ROC Curve
* plot of $\text{fpr}$ vs $\text{tpr}$ for different thresholds of the same ranker
* a model with perfect discrimination passes through the upper left corner 
** ''perfect discrimination'' - with no overlap between the two classes
* so the closer the ROC curve to the upper corner, the better the accuracy


=== Naive Method ===
Algorithm
* given a ranker $F$ and a dataset $S$ with $N$ training examples 
* consider all possible thresholds ($N-1$ for $N$ examples)
* for each, 
** calculate $\text{fpr}$ and $\text{tpr}$
** and put in on the ROC space
* select the best, using the ROC Analysis
** knowing the ratio $\text{neg} / \text{pos}$


=== Practical Method ===
Algorithm
* rank test examples on decreasing score $F(x, +) $
* start in $(0, 0)$
* for each example $x$ (in the decreasing order)
** if $x$ is positive, move $1/\text{pos}$ up
** if $x$ is negative, move $1/\text{neg}$ right


=== Example 1 ===
Given
* 20 examples: https://www.dropbox.com/s/65rdiv42ixe2eac/roc-lift.xlsx
* $C$ - actual class of the training example
* $\text{pos} / \text{neg} = 1$, i.e. $1/\text{pos} = 1/\text{neg} = 0.1$ 

http://habrastorage.org/files/267/36b/ff1/26736bff158a4d82893ff85b2022cc5b.gif


Best threshold
* we know the slope of the accuracy line: it's 1
* the best classifier for this slope is the 6th one
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/roc-curve-ex1.png
* threshold value $\theta$
** so we take the score obtained on the 6th record 
** and use it as the threshold value $\theta$
** i.e. predict positive if $\theta \geqslant 0.54$
* if we check, we see that indeed we have accuracy = 0.7


=== Example 2 ===
Given
* 20 training examples, 12 negative and 8 positive 

&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;

{| class=&quot;wikitable&quot;
! # || Cls || Score  
|-
| 1 || N || 0.18
|-
| 2 || N || 0.24
|-
| 3 || N || 0.32
|-
| 4 || N || 0.33
|-
| 5 || N || 0.4
|-
| 6 || N || 0.53
|-
| 7 || N || 0.58
|-
| 8 || N || 0.59
|-
| 9 || N || 0.6
|-
| 10 || N || 0.7
|-
| 11 || N || 0.75
|-
| 12 || N || 0.85
|-
| 13 || P || 0.52
|-
| 14 || P || 0.72
|-
| 15 || P || 0.73
|-
| 16 || P || 0.79
|-
| 17 || P || 0.82
|-
| 18 || P || 0.88
|-
| 19 || P || 0.9
|-
| 20 || P || 0.92
|}
&lt;/td&gt;

&lt;td&gt; $\Rightarrow$ sort by score &lt;/td&gt;

&lt;td&gt;

{| class=&quot;wikitable&quot;
! # || Cls || Score  
|-
| 20 || P || 0.92
|-
| 19 || P || 0.9
|-
| 18 || P || 0.88
|-
| 12 || N || 0.85
|-
| 17 || P || 0.82
|-
| 16 || P || 0.79
|-
| 11 || N || 0.75
|-
| 15 || P || 0.73
|-
| 14 || P || 0.72
|-
| 10 || N || 0.7
|-
| 9 || N || 0.6
|-
| 8 || N || 0.59
|-
| 7 || N || 0.58
|-
| 6 || N || 0.53
|-
| 13 || P || 0.52
|-
| 5 || N || 0.4
|-
| 4 || N || 0.33
|-
| 3 || N || 0.32
|-
| 2 || N || 0.24
|-
| 1 || N || 0.18
|}
&lt;/td&gt;

&lt;td&gt;
Now draw the curves:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/roc-curve-ex2.png
* best accuracy achieved with example # 18
* so setting $\theta$ to 0.88
* obtained accuracy is $15/20$

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;



=== Other ROC Curve Examples ===
Taken from [http://www.cs.bris.ac.uk/~flach/ICML04tutorial/ROCtutorialPartI.pdf]

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/roc-curves.png



== AUC: Area Under ROC Curve ==
Area Under ROC Curve
* Measure for evaluating the performance of a classifier
* it's the area under the ROC Curve
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/roc-auc-ex1.png

total area is 100%
* so AUC = 1 is for a perfect classifier for which all positive come after all negatives
* AUC = 0.5 - randomly ordered 
* AUC = 0 - all negative come before all positive
* so AUC $\in [0, 1]$
* typically we don't have classifiers with AUC &lt; 0.5


=== Interpretation ===
Formally, the AUC of a classifier $C$ is
* probability that $C$ ranks a randomly drawn &quot;$+$&quot; example higher than a randomly drawn &quot;$-$&quot; example
* i.e. $\text{auc}(C) = P \big[ C(x^+) &gt; C(x^-) \big]$


Consider the ROC curve above (auc=0.68). 
* Let's make an experiment
* draw random positive and negative examples 
* then calculate the proportion of cases when positives have greater score than negatives
* at the end, we obtain 0.67926 - quite close to 0.68!


&lt;pre&gt;
cls = c('P', 'P', 'N', 'P', 'P', 'P', 'N', 'N', 'P', 'N', 'P',
        'N', 'P', 'N', 'N', 'N', 'P', 'N', 'P', 'N')
score = c(0.9, 0.8, 0.7, 0.6, 0.55, 0.51, 0.49, 0.43, 0.42, 0.39, 0.33, 
          0.31, 0.23, 0.22, 0.19, 0.15, 0.12, 0.11, 0.04, 0.01)

pos = score[cls == 'P']
neg = score[cls == 'N']

set.seed(14)
p = replicate(50000, sample(pos, size=1) &gt; sample(neg, size=1))
mean(p)
&lt;/pre&gt;

 


=== Examples ===
Examples:
* have a look at the examples in [[#Other ROC Curve Examples]]
* we see that the better classifier is, the bigger the area under its ROC curve
* and for the random one it's apparent that it's 0.5

== ROC Analysis in [[R]] ==
=== ROC Curves ===
In R there's a package called ROCR [http://cran.r-project.org/web/packages/ROCR/index.html] for drawing ROC Curves

&lt;pre&gt;
install.packages('ROCR')
require('ROCR')

cls = c('P', 'P', 'N', 'P', 'P', 'P', 'N', 'N', 'P', 'N', 'P', 
        'N', 'P', 'N', 'N', 'N', 'P', 'N', 'P', 'N')
score = c(0.9, 0.8, 0.7, 0.6, 0.55, 0.51, 0.49, 0.43, 
          0.42, 0.39, 0.33, 0.31, 0.23, 0.22, 0.19, 
          0.15, 0.12, 0.11, 0.04, 0.01)


pred = prediction(score, cls)
roc = performance(pred, &quot;tpr&quot;, &quot;fpr&quot;)

plot(roc, lwd=2, colorize=TRUE)
lines(x=c(0, 1), y=c(0, 1), col=&quot;black&quot;, lwd=1)
&lt;/pre&gt;


http://i.stack.imgur.com/Zw4Yw.png


=== AUC ===
With ROCR it's as well possible to calculate AUC:

&lt;pre&gt;
auc = performance(pred, &quot;auc&quot;)
auc = unlist(auc@y.values)
auc
&lt;/pre&gt;


=== Cutoff Plots ===
Also, can generate a plot of accuracy vs threshold - to select the best threshold.
Suppose we have the following ROC curve:

http://habrastorage.org/files/54b/611/188/54b611188a8b4b2a9ca1e41884f21a3f.png

For that we can plot accuracy vs cutoff plot:

http://habrastorage.org/files/b97/77c/d8e/b9777cd8e9334b9486f79c0dbfb7d00a.png

So the best cutoff is at around 0.5 for this graph


&lt;pre&gt;
path = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/wiki-r/roc/columns.txt'
cols = read.table(path, sep='\t', header=T, dec='.', as.is=T)

cols$score = as.numeric(cols$score)


library(ROCR)

pos = table(cols$class)['1']
neg.sample = sample(which(cols$class == 0), pos)

cols.sample = data.frame(score=c(cols$score[cols$class == 1], 
                                 cols$score[neg.sample]),
                         class=c(rep(1, pos), rep(0, pos)))

pred = prediction(cols.sample$score, cols.sample$class)
roc = performance(pred, &quot;tpr&quot;, &quot;fpr&quot;)

plot(roc, colorize=T, lwd=2)
lines(x=c(0, 1), y=c(0, 1), col=&quot;grey&quot;, lty=2)


auc = performance(pred, &quot;auc&quot;)
auc = unlist(auc@y.values)
auc

acc = performance(pred, &quot;acc&quot;)

ac.val = max(unlist(acc@y.values))
th = unlist(acc@x.values)[unlist(acc@y.values) == ac.val]

plot(acc)
abline(v=th, col='grey', lty=2)
&lt;/pre&gt;

== ROC in Java ==
=== AUC Calculation ===
(This code uses LambdaJ [https://code.google.com/p/lambdaj/]  for grouping and soring)

&lt;pre&gt;
private static final int NEGATIVE = 0;
private static final int POSITIVE = 1;

public static double auc(List&lt;TrainingInstance&gt; list) {
  List&lt;TrainingInstance&gt; data = sort(list, on(TrainingInstance.class).getPredictedScore(), DESCENDING);

  Group&lt;TrainingInstance&gt; group = group(data, by(on(TrainingInstance.class).getCls()));
  double tpr = 1.0 / group.find(POSITIVE).size();
  double fpr = 1.0 / group.find(NEGATIVE).size();

  double auc = 0.0;
  double height = 0.0;

  for (TrainingInstance ti : data) {
    if (ti.getCls() == POSITIVE) {
      height = height + tpr;
    } else {
      auc = auc + height * fpr;
    }
  }

  return auc;
}
&lt;/pre&gt;

== See Also ==
* [[Evaluation of Binary Classifiers]]
* [[Cumulative Gain Chart]]

== Links ==
* http://www.walkerbioscience.com/pdfs/ROC%20tutorial.pdf
* Flash applet to build ROC Curves - http://www.saedsayad.com/flash/RocGainKS.html
* http://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it
* http://stats.stackexchange.com/a/105577/49130 answer on CV about drawing ROC Curves

== Sources ==
* [[Data Mining (UFRT)]]
* http://www.cs.bris.ac.uk/~flach/ICML04tutorial/ROCtutorialPartI.pdf
* http://www.medcalc.org/manual/roc-curves.php

[[Category:Machine Learning]]
[[Category:Classifiers]]
[[Category:Model Performance Evaluation]]
[[Category:R]]</text>
      <sha1>sxldy0uk18ctblor3od9353h9bnjfej</sha1>
    </revision>
  </page>
  <page>
    <title>Cumulative Gain Chart</title>
    <ns>0</ns>
    <id>469</id>
    <revision>
      <id>472</id>
      <timestamp>2014-06-08T19:50:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7662">== Cumulative Gain Chart ==
Gain Charts are used for [[Evaluation of Binary Classifiers]]
* also it can be used for comparing two or more binary classifiers 
* the chart shows $\text{tpr}$ vs $\text{sup}$


=== Motivating Example ===
Suppose we have a direct marketing campaign
* population is very big 
* we want to select only a fraction of the population for marketing - those that are likely to respond
* we build a model that scores receivers - assigns probability that he will reply 
* want to evaluate the performance of this model


=== Cumulative Gain ===
Performance evaluation
* recall values that can be calculated for [[Evaluation of Binary Classifiers]] 
* accuracy - but it's not enough here
* $\text{tpr}$ - True Positive Rate or Sensitivity
** $\text{tpr} = \cfrac{\text{TP}}{\text{TP} + \text{FN}}$  
** fraction of examples correctly classified
* $\text{sup}$ - Support (Predictive Positive Rate)
** $\text{sup} = \cfrac{\text{TP} + \text{FP}}{N} = \cfrac{\text{predicted pos}}{\text{total}}$
** fraction of positively predicted examples

Suppose that we obtained the following data: 
* Cls = actual class
* score = predicted score


&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;
{| class=&quot;wikitable&quot;
! Cls || Score
|-
| N || 0.01
|-
| P || 0.51
|-
| N || 0.49
|-
| P || 0.55
|-
| P || 0.42
|-
| N || 0.7
|-
| P || 0.23
|-
| N || 0.39
|-
| P || 0.04
|-
| N || 0.19
|-
| P || 0.12
|-
| N || 0.15
|-
| N || 0.43
|-
| P || 0.33
|-
| N || 0.22
|-
| N || 0.11
|-
| N || 0.31
|-
| P || 0.8
|-
| P || 0.9
|-
| P || 0.6
|}
&lt;/td&gt;
&lt;td&gt; $\Rightarrow$ sort $\Rightarrow$ &lt;/td&gt;
&lt;td&gt;
{| class=&quot;wikitable&quot;
! # || Cls || Score
|-
| 1 || P || 0.9
|-
| 2 || P || 0.8
|-
| 3 || N || 0.7
|-
| 4 || P || 0.6
|-
| 5 || P || 0.55
|-
| 6 || P || 0.51
|-
| 7 || N || 0.49
|-
| 8 || N || 0.43
|-
| 9 || P || 0.42
|-
| 10 || N || 0.39
|-
| 11 || P || 0.33
|-
| 12 || N || 0.31
|-
| 13 || P || 0.23
|-
| 14 || N || 0.22
|-
| 15 || N || 0.19
|-
| 16 || N || 0.15
|-
| 17 || P || 0.12
|-
| 18 || N || 0.11
|-
| 19 || P || 0.04
|-
| 20 || N || 0.01
|}
&lt;/td&gt;
&lt;td&gt;
* sort the table by score desc
* max on top, min at bottom
* if model works well, expect
** responders at top
** non-responders at bottom
* the better the model 
** the clearer the separation 
** between positive and negative
&lt;/td&gt;
 &lt;/tr&gt;
&lt;/table&gt;


Intuition
* suppose now we select top 20% records
* we see that out of 4 examples 3 of them are positive 
* in total, there are 10 responders (positive classes)
* so with only 20% (4 records) we can target 3/10 = 30% responders
* we also can use a random model
** if you randomly sample 20% of records, you can expect to target only 20% your responders
** 20% of 10 = 2
* so we're doing better than random 
* can do it for all possible fractions of our data set and get this chart:


http://habrastorage.org/files/e79/67f/d02/e7967fd0250d439d86771ec15aa3dd28.gif


Best classifier 
* the optimal classifier will score positives and negatives s.t. there's a clear separation between them
* in such a case the gain chart will always go up until it reaches 1, and then go left
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/gain-chart-ex.png
* the closer our chart to the best one, the better our classifier is 


=== Gain Chart ===
So a gain chart shows
* Predicted Positive Rate (or support of the classifier)
* vs True Positive Rate (or sensitivity of the classifier)
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/gain-chart.png
* it says how much population we should sample to get the desired sensitivity of our classifier 
* i.e. if we want to direct 40% of potential repliers to our targeting campaign, we should select 20% 


[[Cross-Validation]]
* when we divide our data into two subsets, we can plot the charts for both
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/gain-chart-ex2.png
* we can easily see if a classifier overfits on the test set, but underperforms on the testing


=== Examples ===
Given
* 20 training examples, 12 negative and 8 positive 

&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;

{| class=&quot;wikitable&quot;
! # || Cls || Score  
|-
| 1 || N || 0.18
|-
| 2 || N || 0.24
|-
| 3 || N || 0.32
|-
| 4 || N || 0.33
|-
| 5 || N || 0.4
|-
| 6 || N || 0.53
|-
| 7 || N || 0.58
|-
| 8 || N || 0.59
|-
| 9 || N || 0.6
|-
| 10 || N || 0.7
|-
| 11 || N || 0.75
|-
| 12 || N || 0.85
|-
| 13 || P || 0.52
|-
| 14 || P || 0.72
|-
| 15 || P || 0.73
|-
| 16 || P || 0.79
|-
| 17 || P || 0.82
|-
| 18 || P || 0.88
|-
| 19 || P || 0.9
|-
| 20 || P || 0.92
|}
&lt;/td&gt;
&lt;td&gt; $\Rightarrow$ sort(score) &lt;/td&gt;
&lt;td&gt;

{| class=&quot;wikitable&quot;
! # || Cls || Score  
|-
| 20 || P || 0.92
|-
| 19 || P || 0.9
|-
| 18 || P || 0.88
|-
| 12 || N || 0.85
|-
| 17 || P || 0.82
|-
| 16 || P || 0.79
|-
| 11 || N || 0.75
|-
| 15 || P || 0.73
|-
| 14 || P || 0.72
|-
| 10 || N || 0.7
|-
| 9 || N || 0.6
|-
| 8 || N || 0.59
|-
| 7 || N || 0.58
|-
| 6 || N || 0.53
|-
| 13 || P || 0.52
|-
| 5 || N || 0.4
|-
| 4 || N || 0.33
|-
| 3 || N || 0.32
|-
| 2 || N || 0.24
|-
| 1 || N || 0.18
|}
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/gain-chart-ex5.png



=== Comparing Binary Classifiers ===
Can draw two or more gain charts over the same plot
* and thus be able to compare two or more classifiers 
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/gain-chart-ex3.png
* we see that one of the classifiers most likely overfits the training data
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/gain-chart-ex4.png
* but when we test, we see that it performs as good (bas) as other classfiers



=== Plotting Gain Chart in [[R]] ===
In R there's a package called ROCR [http://cran.r-project.org/web/packages/ROCR/index.html] (for drawing [[ROC Analysis|ROC Curves]])

&lt;pre&gt;
install.packages('ROCR')
require('ROCR')
&lt;/pre&gt;

It can be used for drawing gain charts as well:

&lt;pre&gt;
cls = c('P', 'P', 'N', 'P', 'P', 'P', 'N', 'N', 'P', 'N', 'P', 
        'N', 'P', 'N', 'N', 'N', 'P', 'N', 'P', 'N')
score = c(0.9, 0.8, 0.7, 0.6, 0.55, 0.51, 0.49, 0.43, 
          0.42, 0.39, 0.33, 0.31, 0.23, 0.22, 0.19, 
          0.15, 0.12, 0.11, 0.04, 0.01)

pred = prediction(score, cls)
gain = performance(pred, &quot;tpr&quot;, &quot;rpp&quot;)

plot(gain, col=&quot;orange&quot;, lwd=2)
&lt;/pre&gt;

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/gain-r1.png

But we also can add the baseline and the ideal line:

&lt;pre&gt;
plot(x=c(0, 1), y=c(0, 1), type=&quot;l&quot;, col=&quot;red&quot;, lwd=2,
     ylab=&quot;True Positive Rate&quot;, 
     xlab=&quot;Rate of Positive Predictions&quot;)
lines(x=c(0, 0.5, 1), y=c(0, 1, 1), col=&quot;darkgreen&quot;, lwd=2)

gain.x = unlist(slot(gain, 'x.values'))
gain.y = unlist(slot(gain, 'y.values'))

lines(x=gain.x, y=gain.y, col=&quot;orange&quot;, lwd=2)
&lt;/pre&gt;

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/gain-r2.png



== Cumulative Lift Chart ==
Lift charts show basically the same information as Gain charts
* $\text{ppr}$ Predicted Positive Rate (or support of the classifier)
* vs $\cfrac{\text{tpr}}{\text{ppr}}$ True Positive over Predicted Positive
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/lift-chart-ex.png


== See Also ==
* [[Evaluation of Binary Classifiers]]
* [[ROC Analysis]]

== Sources ==
* [[Data Mining (UFRT)]]
* [https://www.youtube.com/watch?v=IwCUZQllVVI Measuring Model Performance With Gains And Lift]
* [https://www.youtube.com/watch?v=aiC4AIf6ons 6k:175 Business Intelligence - Creating Lift and Cumulative Gains charts in Excel]


[[Category:Machine Learning]]
[[Category:Classifiers]]
[[Category:Model Performance Evaluation]]
[[Category:R]]</text>
      <sha1>qh57dwhyavac2gl2ljvaqsb58lm55hu</sha1>
    </revision>
  </page>
  <page>
    <title>Cost Matrix</title>
    <ns>0</ns>
    <id>470</id>
    <revision>
      <id>473</id>
      <timestamp>2014-06-08T19:52:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1721">== Cost Matrix ==
Used for comparing two different models
* A ''cost matrix'' is a matrix of the following form:

{| class=&quot;wikitable&quot;
! || $y = +$ || $y = -$
|-
! $h_\theta(x) = +$
| $C(+ | +)$ || $C(+ | -)$
|-
! $h_\theta(x) = -$
| $C(- | +)$ || $C(- | -)$
|}


In general case:
* $C(i | j)$ 
* a cost of classifying an example of class $j$ as class $i$
* this way we can express that some mispredictions are very costly


=== Example ===
{| class=&quot;wikitable&quot;
! || $y = +$ || $y = -$
|-
! $h_\theta(x) = +$
| $C(+ | +) = -1$ || $C(+ | -) = 1$
|-
! $h_\theta(x) = -$
| $C(- | +) = 100$ || $C(- | -) = 0$
|}

* we put $C(- | +) = 100$ because in this example false negatives are very costly

And assume we're comparing two classifiers $C_1$ and $C_2$
* below are their [[Contingency Table]]s

&lt;table class=&quot;wikitable&quot;&gt;
&lt;tr&gt;
&lt;td&gt;
{| class=&quot;wikitable&quot;
|+ stats of $C_1$
! || $y = +$ || $y = -$
|-
! $h_{C_1}(x) = +$
| 150 || 60
|-
! $h_{C_1}(x) = -$
| 40 || 250
|}

* $\text{acc}(C_1) = \cfrac{150+250}{150+40+60+250} = 80\%$
* $\text{cost}(C_1) = -1 \cdot 150 + 1 \cdot 60 + 100 \cdot 40 + 0 \cdot 250 = 3910$
&lt;/td&gt;
&lt;td&gt;
{| class=&quot;wikitable&quot;
|+ stats of $C_2$
! || $y = +$ || $y = -$
|-
! $h_{C_2}(x) = +$
| 250 || 5
|-
! $h_{C_2}(x) = -$
| 45 || 200
|}

* $\text{acc}(C_2) = \cfrac{250+200}{250+45+5+200} = 90\%$
* $\text{cost}(C_2) = -1 \cdot 250 + 1 \cdot 5 + 100 \cdot 45 + 0 \cdot 200 = 4255$
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

Selecting $C_1$
* because $C_1$ has lower cost: $\text{cost}(C_1) &lt; \text{cost}(C_2)$
* even though $C_2$ has better accuracy: $\text{acc}(C_2) &gt; \text{acc}(C_1)$ 


== Sources ==
* [[Data Mining (UFRT)]]

[[Category:Machine Learning]]
[[Category:Classifiers]]
[[Category:Model Performance Evaluation]]</text>
      <sha1>4y33tvmhzvpp00ebr08kpmielx0jgtc</sha1>
    </revision>
  </page>
  <page>
    <title>Rank Correlation</title>
    <ns>0</ns>
    <id>471</id>
    <revision>
      <id>474</id>
      <timestamp>2014-06-08T19:59:00Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4440">== Rank Correlation ==
a ''rank correlation'' is a measure of relationship 
* between different rankings of the same variable
* of between two rankings of different ordinal variables


=== Intuition ===
Two variables case:
* $X$ - basketball ranking of college teams
* $Y$ - football ranking of college teams
* is there a correlation between $X$ and $Y$? 
* e.g. do colleges with good football ranks tend to have good basketball ranks? 

One variable case:
* $X$ - football matches ranked by coaches 
* $Y$ - football matches ranked by sportswriters
* are these rankings similar?


== Correlation Coefficient ==
* A ''rank correlation coefficient'' shows the degree of similarity between two rankings
* so we want to calculate the distances between two rank vectors


== One Variable Case ==
=== Problem ===
let $X = \{A, B, C, D, E \}$ - be a set of 5 objects

want to compare 
* observed ranking $r(X): [E, B, A, C, D]$
* predicted ranking $r^*(X): [B, E, C, D, A]$
* need to be able to compute distance $d(r, r^*)$ between them


=== Running Example ===
{| class=&quot;wikitable&quot;
! || 1 || 2 || 3 || 4 || 5
|-
! $r$
| $B$ || $A$ || $C$ || $D$ || $E$
|-
| $r^*$
| $E$ || $C$ || $D$ || $A$ || $B$
|}


=== Spearman's Footrule ===
given $X = \{ x_1, ..., x_N \}$
* $d_{SF}(r, r^*) = \sum_{i=1}^{N} \big| r(x_i) - r^*(x_i) \big|$
* not normalized: $d_{SF}(r, r^*) \in [0, +\infty)$ 
* similar to the Manhattan distance


Example:
* $d_{SF}(r, r^*) = |1 - 2| + |2 - 1| + |3 - 5| + |4 - 3| + |5 - 4| = 1 + 1 + 2 + 1 + 1 = 6$


=== Spearman Distance ===
given $X = \{ x_1, ..., x_N \}$
* $d_{S}(r, r^*) = \sum_{i=1}^{N} \big( r(x_i) - r^*(x_i) \big)^2$
* also not normalized: $d_{SF}(r, r^*) \in [0, +\infty)$ 


Example:
* $d_{SF}(r, r^*) = |1 - 2|^2 + |2 - 1|^2 + |3 - 5|^2 + |4 - 3|^2 + |5 - 4|^2 = 1 + 1 + 4 + 1 + 1 = 8$


=== Spearman's $\rho$ (Rank Correlation Coefficient) ===
given $X = \{ x_1, ..., x_N \}$
* $\rho_S(r, r^*) = 1 - \cfrac{6 \cdot d_S(r, r^*)}{N \cdot (N^2 - 1)}$
* normalized: $\rho_S(r, r^*) \in [-1, 1]$
** $\rho_S(r, r^*) = 1$ - identical
** $\rho_S(r, r^*) = -1$ - inverse

Example:
* $\rho_S(r, r^*) = 1 - \cfrac{6 \cdot 5}{5 \cdot (5^2 - 1)} = 0.6$


=== Kendall's Distance ===
It counts the pair-wise disagreement between two ranking lists, i.e. [[Inversion Count]]
* $d_K(r, r^*) = \Big| \big\{ (x_i, x_j)  | r(x_i) &lt; r(x_j) \land r^*(x_i) &gt; r^*(x_j) \big\} \Big|$
* so it's the # of item pairs that are inverted in the $r$ compared to $r^*$, 
* also, the ranking can be partial
* and it's not normalized

Example:
* $d_K(r, r^*) = (1+0+0+0)+(0+0+0)+(1+1)+(0)=3$
 

=== Kendall's $\tau$ ===
It normalizes the Kendall's Distance
* $\tau_K(r, r^*) = 1 - \cfrac{4 \cdot d_k(r, r^*)}{N \cdot (N - 1)}$
* $\tau_K(r, r^*) \in [-1, 1]$


Example:
* $\tau_K(r, r^*) = 1 - \cfrac{4 \cdot 3}{5 \cdot (5 - 1)} = 0.4$


=== Gamma Coefficient ===
$\Gamma$ coefficient is based on the # of correct and incorrect rankings
* &quot;correct&quot;: 
** $d^+(r, r^*) = \big| \big\{ (x_i, x_j) \ | \ r(x_i) &lt; r(x_j) \land r^*(x_i) &lt; r^*(x_j)  \big\} \big|$
** the number of items at the same relative position in raking
* &quot;inverted&quot; (as in Kendall's $\tau$)
** $d^-(r, r^*) = \big| \big\{ (x_i, x_j) \ | \ r(x_i) &lt; r(x_j) \land r^*(x_i) &gt; r^*(x_j)  \big\} \big|$
** the number of inversions
* $\Gamma(r, r^*) = \cfrac{d^+(r, r^*) - d^-(r, r^*)}{d^+(r, r^*) + d^-(r, r^*)}$
* $\Gamma(r, r^*) \in [-1, 1]$
* it's equal to $\tau_K(r, r^*)$ if the rankings are total



=== Weighted Methods ===
The previous measures gave equal importance to all ranking positions
* i.e. differences in the first ranking positions have the same effect as for the last positions
* in many cases the closer position is to the beginning, the more important it is
* e.g. when we want to show only first 5 items, the rest after 5 are not important

Solution
* assign weight proportional to the importance
* if position is important, may assign weight s.t. they decrease with the ranking position
* $d_S(r, r^*) = \sum_{i = 1}^N w_i \cdot \big( r(x_i) - r^*(x_i) \big)^2$ with
** $w_i = \cfrac{1}{\log r(x_i) + 1}$


=== [[MCDA]] Methods ===
Can also use Multi-Criteria Decision Aid for that
* e.g. Concordance Index from [[ELECTRE]]


== Links ==
* http://theory.stanford.edu/~sergei/slides/www10-metrics.pdf

== Sources ==
* [[Data Mining (UFRT)]]
* http://en.wikipedia.org/wiki/Rank_correlation
* http://en.wikipedia.org/wiki/Kendall_tau_distance

[[Category:Statistics]]</text>
      <sha1>o16dskx2tqavdfltiknz04d76qepuox</sha1>
    </revision>
  </page>
  <page>
    <title>Inversion Count</title>
    <ns>0</ns>
    <id>472</id>
    <revision>
      <id>475</id>
      <timestamp>2014-06-08T20:00:17Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2118">== Inversion Count ==
Sequence inversion
* In a sequence $\pi = \langle a_0, ..., a_t \rangle$ or elements $A = \{ a_i \}$
* a pair $(a_i, a_j)$ is an ''inversion'' if $i &lt; j \land a_i &gt; a_j$
* the number of such inversions is the inversion number of sequence $\pi$
* this is a measure of &quot;sortedness&quot; of sequence $\pi$

Two ranked vectors
* An inversion in two rankings $r_1, r_2$ of the same variable $X$ is 
* a pair $(x_i, x_j) \ | \ r_1(x_i) &lt; r_1(x_j) \land r_2(x_i) &gt; r_2(x_j)$
* it's called a ''pair-wise disagreement'' between two ranking lists 


=== Graphical Counting ===
we can represent two rankings as a [[Bipartite Graph]] $G = \langle N, S, E \rangle$ 
* $N = r_1(X)$ and $E = r_2(X)$ being two disjoint set of nodes
* $X$ is some variable, and $r_1$ and $r_2$ are different rankings of this variable
* $E$ is set of edges $E = \Big\{ \big(r_1(x), r_2(x) \big) \Big\} $ i.e. corresponding elements of $X$ are connected in this graph

Counting:
* ''bilayer drawing'' of $G$ is when there are two parallel lines, edges of $N$ are drawn on one, and edges of $S$ are drawn on another
* ''bilayer cross count'' is a pairwise intersections edges of $N$ and $S$
* bilayer cross count corresponds to the number of inversions when $N$ and $S$ are ranking vectors


Example:
* $X = \{ A, B, C, D, E \}$
* two ranking $r_1 = \langle E, B, A, C, D \rangle$ and $r_2 = \langle B, E, C, D, A \rangle$
* draw this is a bipartite graph and count the number of intersections
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/inversion-count.png
* so there are 3 inversions in these two rankings 


=== Algorithms ===
A modification of [[Merge Sort]] can compute the # of inversions in $O(|N| \log |N|)$
* see [[Merge Sort#Counting Inversions]]


== See Also ==
* [[Kendal's Tau]]

== Sources ==
* Simple and efficient bilayer cross counting [http://www.emis.de/journals/JGAA/accepted/2004/BarthMutzelJuenger2004.8.2.pdf]
* http://en.wikipedia.org/wiki/Inversion_(discrete_mathematics)
* [[Algorithms Design and Analysis Part 1 (coursera)]]

[[Category:Combinatorics]]
[[Category:Graphs]]</text>
      <sha1>i3sxxz85l8rsh26uxuxqwh6135o82qx</sha1>
    </revision>
  </page>
  <page>
    <title>True Error of Model</title>
    <ns>0</ns>
    <id>473</id>
    <revision>
      <id>476</id>
      <timestamp>2014-06-08T20:01:00Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1889">== True Error of Model ==
What do we do when we want to know how accurately the model ''will'' perform in practice
* need to estimate its ''true error''


=== Estimating the Accuracy ===
Given: 
* classification model $C$ 
* dataset $S$ with $n$ examples drawn w.r.t. distribution $P$ 

Problem 
* estimate the accuracy of $C$ over future instances drawn with $P$ 
* this is called the ''true error''
* it's important to distinguish ''sample error'' and ''true error''


=== Sample Error ===
the ''sample error'' of $C$ calculated on sample $S$ is
* the proportion of examples in $S$ that $C$ misclassified
* $\text{error}(C, S) = \cfrac{1}{| S |} \sum_{(x,y) \in S} \delta (C(x) \ne y)$
* $\text{acc}(C, S)  = \cfrac{1}{| S |} \sum_{(x,y) \in S} \delta (C(x) = y)$


But usually we have training and testing sets (see [[Cross-Validation]])
* i.e. we have some data set $S$ (drawn from the population with distribution $P$) 
* learning set $R \subset S$,
* training set $T \subset S$,
* $R$ and $T$ are disjoint: $R \cap T = \varnothing$
* so the sample error is computed against $T$: $\text{error}(C, T)$


=== True Error ===
the ''true error'' of $C$ w.r.t distribution $S$ on the population $D$
* is the probability to misclassify an instance drawn from $D$ at random
* $\text{error}(C, D) = \sum_{(x,y) \in D} P(x, y) \cdot \delta(C(x) \ne y)$
** $P(x, y)$ is the probability to draw a pair $(x,y) \in D$


Estimate of $\text{error}(C, D)$
* Sample error $\text{error}(C, S)$ is just an estimate of $\text{error}(C, D)$
* since $S \subset D$, $S$ is always finite, while $D$ can be infinite 
* but this estimate is not always accurate! (need to have more accurate estimate)


More accurate estimates:
* [[K-Fold Cross-Validation]]
* average over $K$ testing errors to reduce variability 


[[Category:Machine Learning]]
[[Category:Statistics]]
[[Category:Model Performance Evaluation]]</text>
      <sha1>e3h5c27lamh3dtuw39siwx1kgp0sttx</sha1>
    </revision>
  </page>
  <page>
    <title>K-Fold Cross-Validation</title>
    <ns>0</ns>
    <id>474</id>
    <redirect title="Cross-Validation" />
    <revision>
      <id>477</id>
      <timestamp>2014-06-08T20:02:32Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="54">#REDIRECT [[Cross-Validation#K-Fold Cross-Validation]]</text>
      <sha1>2j9n089yob3amem1i2mytzexbagjkty</sha1>
    </revision>
  </page>
  <page>
    <title>Comparing Learning Algorithms</title>
    <ns>0</ns>
    <id>475</id>
    <revision>
      <id>478</id>
      <timestamp>2014-12-05T21:03:00Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4451">== Comparing Learning Algorithms ==
=== Comparing Classifiers ===
A lot of things
* [[Contingency Table]]s
* [[Cost Matrix]]
* best accuracy or $F_1$-score (see [[Evaluation of Binary Classifiers]]) 
* best [[True Error of Model]]
* best [[Cumulative Gain Chart]]
* other things


=== Comparing Algorithms ===
What if we want to compare 
* two learning algorithms $A_1$ and $A_2$
* not just two specific classifiers $C_1$ and $C_2$


We want to measure the expected error 
* for $R \subset D$ where $D$ is the population, we want to measure
* $E \Big[ \text{error} \big(A_1(R), D \big) - \text{error} \big(A_2(R), D \big) \Big]$
** with $\text{error} \big(A_1(R), D \big)$ being the [[True Error of Model|true error]]


How to estimate it?
* average result over many different training sets 
* ideally all of these sets must be independent from each other 
* but usually use [[K-Fold Cross-Validation]]


=== $K$-Fold Cross-Validation ===
Estimation:
* given a data set $S$
* for $k = 1..K$,
** let $T_k$ be the training set,
** and $R_k = S - T_k$
** train $C_1 = A_1(R_k)$ and $C_2 = A_2(R_k)$
** let $\delta_k = \text{error}(C_1, T_k) - \text{error}(C_2, T_k)$
* let $\delta^* = \cfrac{1}{K} \sum_{k = 1}^K \delta_k$
** this is the estimate of the expected error $E \Big[ \text{error} \big(A_1(R), D \big) - \text{error} \big(A_2(R), D \big) \Big]$


=== $K$-Fold CV Paired [[t-Test|$t$-Test]] ===
Let's conduct a [[Statistical Tests of Significance]]:
* assume (under the null hypothesis) that $A_1$ and $A_2$ have equal expected accuracy
* $t = \cfrac{\delta^*}{\sigma}$ follows the [[Student distribution]] with $K-1$ degrees of freedom
** $\delta^* = \cfrac{1}{K} \sum_{k = 1}^K \delta_k$ - the estimate of the expected error
** $\sigma = \sqrt{ \cfrac{1}{K \cdot (K - 1)} \sum_{k = 1}^K (\delta_k - \delta^*)^2 }$ 

Test:
* the hypothesis $H_A$: $A_1$ and $A_2$ have equal expected error rate
* $H_A$ is accepted with $N = (1 - \alpha)\%$ confidence 
* if $| t | &lt; t_{1 - \alpha / 2, K - 1}$
** $t_{1 - \alpha / 2, K - 1}$ is the $1 - \alpha / 2$ percentile of  the [[Student distribution]] with $K-1$ degrees of freedom


== Examples ==
=== Example 1 ===

{| class=&quot;wikitable&quot;
! $k$ || 1 || 2 || 3 || 4 || 5
|-
! $\text{error}(A_1, T_k)$ 
| 0.12 || 0.15 || 0.14 || 0.16 || 0.11
|-
! $\text{error}(A_2, T_k)$ 
| 0.13 || 0.16 || 0.13 || 0.14 || 0.17
|-
! $\delta_k$ 
| -0.01 || -0.01 || 0.01 || 0.02 || -0.06
|-
! $(\delta_k - \delta^*)^2$ with $\delta^* = -0.01$ 
| 0.0000 || 0.0000 || 0.0004 || 0.0009 || 0.0025
|-
! $\cfrac{\delta^*}{\sigma} $
|  -0.73 || || || ||  
|}

So,
* $\left| \cfrac{\delta^*}{\sigma} \right| = 0.73$ and $t_{97.5, 4} = 2.77$
* the hypothesis $H_A$ is accepted with 95% confidence	


=== Example 2 ===
* given two algorithms $A_1$ and $A_2$
* 10 rounds are performed

{| class=&quot;wikitable&quot;
|+ Obtained error rates
! $k$ || 1 || 2 || 3 || 4 || 5 || 6 || 7 || 8 || 9 || 10
|-
! $A_1$
| 0.305 || 0.322 || 0.207 || 0.206 || 0.31 || 0.41 || 0.277 || 0.26 || 0.215 || 0.26
|-
! $A_2$
| 0.224 || 0.145 || 0.224 || 0.196 || 0.207 || 0.204 || 0.221 || 0.194 || 0.162 || 0.35
|}

So we calculate and obtain the following table 

{| class=&quot;wikitable&quot;
! $k$ || $A_1$ || $A_2$ || $\delta_k$ || $(\delta_k - \delta^*)^2$
|-
| 1 || 0.305 || 0.224 || 0.081 || 0.00027225
|-
| 2 || 0.322 || 0.145 || 0.177 || 0.01265625
|-
| 3 || 0.207 || 0.224 || -0.017 || 0.00664225
|-
| 4 || 0.206 || 0.196 || 0.01 || 0.00297025
|-
| 5 || 0.31 || 0.207 || 0.103 || 0.00148225
|-
| 6 || 0.41 || 0.204 || 0.206 || 0.02002225
|-
| 7 || 0.277 || 0.221 || 0.056 || 0.00007225
|-
| 8 || 0.26 || 0.194 || 0.066 || 0.00000225
|-
| 9 || 0.215 || 0.162 || 0.053 || 0.00013225
|-
| 10 || 0.26 || 0.35 || -0.09 || 0.02387025
|-
! colspan=&quot;3&quot; | $\delta^* = \cfrac{1}{10} \sum \delta_k =$ 
| 0.0645 ||  
|-
! colspan=&quot;4&quot; | $\sigma^2 = \cfrac{1}{9 \cdot 10} \sum (\delta_k – \delta^*)^2 =$ 
| 0.0007569167
|}

$t = \cfrac{\delta^*}{\sigma^2} \approx 2.34$
* we have 9 degrees of freedom
* for confidence level $\alpha = 0.05$ $\Rightarrow$ need to look for $1 - \alpha/2 = 0.975/%$ percentile
* Calculate the $t$-value: $t_{9, 0.975} = 2.26$
* $t = 2.34 \geqslant 2.26 = t_{9, 0.975}$
* $\Rightarrow$ the hypothesis that $A_1$ and $A_2$ have the same error rate is rejected 




== See Also ==
* [[Cross-Validation]]

== Sources ==
* [[Data Mining (UFRT)]]

[[Category:Machine Learning]]
[[Category:Statistical Tests]]
[[Category:Model Performance Evaluation]]</text>
      <sha1>a11yk5nyzyjj1qhuxo2rnh8v6kfa37o</sha1>
    </revision>
  </page>
  <page>
    <title>Observation Studies</title>
    <ns>0</ns>
    <id>476</id>
    <revision>
      <id>479</id>
      <timestamp>2014-07-15T17:13:56Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2484">== Observation Studies ==
There are two types of [[Data Collection]]
* Observation Studies and [[Statistical Experiment]]s

In ''Observation Studies'' we observe existing characteristics of a subset of individuals in a population
* typically done via surveys, by following smb, etc
* this method doesn't directly interfere with how the data appear (in contrast to [[Statistical Experiment]]s)


the goal is to
* draw conclusions about the population or 
* find differences between 2 or more groups or
* find out about the relationships between variables


=== Types ===
* Prospective Study 
** collect the data as an event unfolds
* Retrospective Study
** use the data of some event that already took place 


== Finding Relationships ==
Types of variables: 
* outcome - the variables of our interest
* explanatory - the variables that are used to analyze and explain the outcome


=== Types of Relationships ===
The relationships between the explanatory variable and the outcome
* ''independent'': there is no association between the variables
* ''association'': the variables are dependent, but it's not clear what kind of relationship there is
** ''causes'': changes in the explanatory variables case the outcome to change 
** ''reverse causation'': changes in outcome cause the explanatory variable to change
** ''coincidence'': just pure chance
** ''common cause'': some other variable causes both the explanatory variables and the outcome to change (see also [[Confounding Variables]])


=== Correlation and Causation ===
* with this type of studies it is possible to find association relationship between the variables
* but it's not possible to show the causation here - need to run a controlled [[Statistical Experiment]] for that 
* beware of [[Confounding Variables]]


Example
* Suppose we run a sunscreen study and collected some data
* We saw that the more sunscreen is used, the more chances to have skin cancer 
* does sunscreen causes the cancer? 
* cannot say it here because the study is observational - we didn't run a controlled [[Statistical Experiment]] to make sure there are no other variables that might have caused it
* e.g. in this case  we don't see the exposure to sun - it's correlated with both sunscreen and cancer variables
** this is a [[Confounding Variables|Confounding Variable]] that is likely to have caused the effect



== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[OpenIntro Statistics (book)]]

[[Category:Statistics]]</text>
      <sha1>to9m3o0zofnl2r78jfxyf4a7ogw74yi</sha1>
    </revision>
  </page>
  <page>
    <title>R Visualization Snippets</title>
    <ns>0</ns>
    <id>477</id>
    <revision>
      <id>480</id>
      <timestamp>2015-04-19T10:23:19Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5676">== R Visualization Snippets ==


== [[Scatter Plot]]s ==
=== Labels and Grids ===
&lt;pre&gt;
x = c(2, 6, 7, 1, 8, 2, 5, 7)
y = c(3, 5, 1, 1, 1, 2, 3, 4)
l = c('A', 'B', 'C', 'D', 'B2', 'E', 'F', 'G')

plot(NULL, NULL, bty=&quot;n&quot;, 
     ylim=c(1-0.3, 5+0.3), 
     xlim=c(1-0.3, 8+0.3), xaxt=&quot;n&quot;,
     xlab=&quot;x&quot;, ylab=&quot;y&quot;)

# grids
abline(h=1:10, v=1:10, col=&quot;gray&quot;, lty=3)

axis(side=1, at=1:8) 
points(x, y, col=&quot;red&quot;, pch=19)
text(x + 0.3, y, labels=l, cex=0.7)
&lt;/pre&gt;

http://habrastorage.org/files/674/eca/b8c/674ecab8caee446b86526a6778e7e0b0.png

=== Circles Around Dots ===

Same code as for the previous example, with the following:

&lt;pre&gt;
pallete = rainbow(n, s=1, v=1, start=0, end=max(1, n-1)/8, alpha=0.5)
symbols(x, y, circles=rep(0.2, n), bg=pallete, add=T, inches = FALSE) 
&lt;/pre&gt;

http://habrastorage.org/files/9bf/52a/c7d/9bf52ac7d4d843f889ddfa61090e0b47.png

[https://www.evernote.com/shard/s344/nl/54547539/a5431ee0-bf98-46f7-97e5-2c8dd749cdca note]


=== Scatter Plot and [[Box Plot]]s ===
&lt;pre&gt;
oldpar = par(no.readonly = TRUE)
data(mtcars)
attach(mtcars)

# fig=c(x1, x2, y1, y2)
par(fig=c(0, 0.8, 0, 0.8))

# mar=c(bottom, left, top, right)
# default: c(5, 4, 4, 2) + 0.1.
par(mar=c(4, 4.1, 0, 0))
plot(mtcars$wt, mtcars$mpg, xlab=&quot;Miles Per Gallon&quot;,
     ylab=&quot;Car Weight&quot;, col=&quot;darkblue&quot;, pch=19)

par(fig=c(0, 0.8, 0.8, 1), new=TRUE)
par(mar=c(0, 4.1, 0, 0))
boxplot(mtcars$wt, horizontal=TRUE, axes=FALSE)


par(fig=c(0.8, 1, 0, 0.8), new=TRUE)

par(mar=c(4, 0, 0, 0))
boxplot(mtcars$mpg, horizontal=F, axes=FALSE)

par(oldpar)
&lt;/pre&gt;

http://habrastorage.org/files/ee0/b85/076/ee0b85076e6048e0abf716e00176eb9b.png


== [[Histogram]]s ==
=== Best Fit [[Normal Distribution|Normal Model]], Shaded ===
&lt;pre&gt;
load(url(&quot;http://www.openintro.org/stat/data/bdims.RData&quot;))

fdims = subset(bdims, bdims$sex == 0)

wgtm = mean(fdims$wgt)
wgts = sd(fdims$wgt)

xlim = c(min(fdims$wgt), max(fdims$wgt)) + c(-5, +5)
hist(fdims$wgt, probability=T, xlim=xlim)

x = seq(xlim[1], xlim[2], 0.5)
y = dnorm(x=x, mean=wgtm, sd=wgts)
lines(x=x, y=y, col=&quot;blue&quot;)

x1 = min(which(x &gt;= 57))
x2 = max(which(x &gt;= 57))

polygon(x=x[c(x1, x1:x2, x2)], y=c(0, y[x1:x2], 0), col=rgb(0,0.5,1,0.5))
&lt;/pre&gt;

http://habrastorage.org/files/0d4/0ae/1a8/0d40ae1a8e7d42d68d85116a972adc09.png

If we want to shade just a part, modify slightly:
&lt;pre&gt;
x1 = min(which(x &gt;= 57))
x2 = max(which(x &lt;= 70))

polygon(x=x[c(x1, x1:x2, x2)], y=c(0, y[x1:x2], 0), col=rgb(0,0.5,1,0.5))
&lt;/pre&gt;

http://habrastorage.org/files/48b/7e9/bb4/48b7e9bb47d14169bff445254792508f.png


[https://www.evernote.com/shard/s344/nl/54547539/31a15cdd-91a5-430d-84c7-8cf319e56fa6 note]


=== Two Histograms Overlaying ===
&lt;pre&gt;
load(url(&quot;http://www.openintro.org/stat/data/bdims.RData&quot;))

mdims = subset(bdims, bdims$sex == 1)
fdims = subset(bdims, bdims$sex == 0)

p1 = hist(mdims$hgt)
p2 = hist(fdims$hgt)

xlim = c(min(fdims$hgt), max(mdims$hgt)) + c(-5, 5)
plot( p1, col=rgb(0,0,1,1/4), xlim=xlim)
plot( p2, col=rgb(1,0,0,1/4), add=T)
&lt;/pre&gt;

http://habrastorage.org/files/eb5/0d2/b9c/eb50d2b9c0f44e5aba31cbd71879399e.png

[https://www.evernote.com/shard/s344/nl/54547539/f421ae65-cc95-4026-9114-803c1669209b note]


=== Histogram with Deviations Shown ===
http://habrastorage.org/files/24c/6a0/d64/24c6a0d641c345a39394f65c20db2542.png

&lt;pre&gt;
plot(x=NA, y=NA, ylim=c(0, 0.0057), xlim=c(1200, 1800),
     xlab='point estimates of mean', ylab='density',
     main='Sampling distribuion of mean', bty='n')
m = mean(sample_means50)
s = sd(sample_means50)

rect(xleft=m-3*s, xright=m+3*s, ybottom=-1, ytop=1,
     border=NA, col=adjustcolor('blue', 0.1))
rect(xleft=m-2*s, xright=m+2*s, ybottom=-1, ytop=1,
     border=NA, col=adjustcolor('blue', 0.1))
rect(xleft=m-s, xright=m+s, ybottom=-1, ytop=1,
     border=NA, col=adjustcolor('blue', 0.1))

hist(sample_means50, breaks=13, col='orange', probability=T, add=T)

fy = dnorm(x=1200:1800, mean=m, sd=s)
lines(x=1200:1800, y=fy)
&lt;/pre&gt;



== Barplot ==
=== Barplot DIY ===
&lt;pre&gt;
n = 10
p = 0.13
max.n = 30
x = seq(1, min(n, max.n))
fx = dbinom(x=x, size=n, prob=p) 
plot(x=NULL, y=NULL, xlim=c(0, max.n), ylim=c(0, 0.2),
     main=paste(&quot;binomomial distribution with n =&quot;, n),
     ylab=&quot;probability&quot;, xlab=&quot;outcome&quot;, axes=F)

axis(side=1); axis(side=2)

bar.width = 0.4
par(xpd=NA)
rect(xleft=x-bar.width, xright=x+bar.width,
     ybottom=0, ytop=fx, col='skyblue')
&lt;/pre&gt;

http://habrastorage.org/files/611/97f/732/61197f732d2a4cd6b1c65a2b2bc8ab8e.png

&lt;pre&gt;
fn = dnorm(x=c(-1, 0, 1, x), mean=n*p, sd=sqrt(n*p*(1-p)))
xspline(x=c(-1, 0, 1, x), y=fn, lwd=2, shape=1, border=&quot;blue&quot;)
&lt;/pre&gt;

http://habrastorage.org/files/a2a/95c/53f/a2a95c53f95640fc97f7869b5616a05c.png

== Animation ==

http://habrastorage.org/files/ad7/d13/3a5/ad7d133a5b254d62a83fe4c8f0d349d8.gif

&lt;pre&gt;
require(animation)

saveGIF({
  for (n in 2:130) {
    x = seq(1, min(n, max.n))
    fx = dbinom(x=x, size=n, prob=p)
    
    plot(x=NULL, y=NULL, xlim=c(0, max.n), ylim=c(0, 0.2),
         main=paste(&quot;binomomial distribution with n =&quot;, n),
         ylab=&quot;probability&quot;, xlab=&quot;outcome&quot;, axes=F)
    
    par(xpd=FALSE)
    abline(v=0:30, col='grey', lty=2)
    axis(side=1); axis(side=2)

    par(xpd=NA)
    bar.width = 0.4
    rect(xleft=x-bar.width, xright=x+bar.width,
         ybottom=0, ytop=fx, col='skyblue')
    
    fn = dnorm(x=c(-1, 0, 1, x), mean=n*p, sd=sqrt(n*p*(1-p)))
    xspline(x=c(-1, 0, 1, x), y=fn, lwd=2, shape=1, border=&quot;blue&quot;)
  }
}, interval=0.1)
&lt;/pre&gt;

Note:
* &lt;code&gt;par(xpd=NA)&lt;/code&gt; - to allow to draw outside of the main region
* &lt;code&gt;par(xpd=FALSE)&lt;/code&gt; - to disallow to draw outside of the main region


[[Category:R]]
[[Category:Snippets]]
[[Category:Visualization]]</text>
      <sha1>nmewfe6s14r270umyn89jocii186do9</sha1>
    </revision>
  </page>
  <page>
    <title>Plot</title>
    <ns>0</ns>
    <id>478</id>
    <redirect title="Plots" />
    <revision>
      <id>481</id>
      <timestamp>2014-07-18T04:58:13Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19">#REDIRECT [[Plots]]</text>
      <sha1>qepi2o0im7y25tx8lyh4cv1awauo6ov</sha1>
    </revision>
  </page>
  <page>
    <title>Dot Plot</title>
    <ns>0</ns>
    <id>479</id>
    <revision>
      <id>482</id>
      <timestamp>2014-07-18T05:02:21Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3370">== Dot Plots ==
This is a [[Plot]] that is used to show only one variable
* can say that this is one-dimensional [[Scatter Plot]]


=== Dot Plot ===
https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/b/openintrostat/dotplot-1.png

It also shows
* the [[Expected Value|mean]] of the distribution (as the &quot;balanced point&quot; of this distribution)


=== Stacked Dot Plot ===
https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/b/openintrostat/dotplot-2.png
* The same, but the dots are stacked on top of each other
* As the number of values grows, it becomes harder to read
* Note that this gives us the same information as [[Histogram]]s - but in there, the values are binned 



== [[R]] ==
In R, function &lt;code&gt;stripchart&lt;/code&gt; draws the dot plot

Example with &lt;code&gt;email50&lt;/code&gt; data from OpenIntro:
&lt;pre&gt;
library(openintro)
data(email50)
&lt;/pre&gt;


&lt;pre&gt;
stripchart(email50$num_char, pch=19, col=rgb(0, 0, 1, 0.3), 
           cex=1.5, axes=F, ylim=c(0.9, 1.5))
axis(side = 1)
m = mean(email50$num_char)
polygon(x=c(m-3, m, m+3), y=c(0.90, 0.95, 0.90), col=&quot;red&quot;)
&lt;/pre&gt;

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/b/openintrostat/dotplot-r1.png

Also we can add some jitter to have an idea of how many items we have in some area

&lt;pre&gt;
set.seed(10)
stripchart(email50$num_char, method=&quot;jitter&quot;, 
           pch=19, col=rgb(0, 0, 1, 0.3), cex=1.5, axes=F,
           ylim=c(0.75, 1.6))
axis(side = 1)
polygon(x=c(m-3, m, m+3), y=c(0.87, 0.95, 0.87) - 0.1, col=&quot;red&quot;)
&lt;/pre&gt;

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/b/openintrostat/dotplot-r2.png

Or can plot it vertically 
&lt;pre&gt;
stripchart(email50$num_char, method=&quot;jitter&quot;, 
           vertical=T, 
           pch=19, col=rgb(0, 0, 1, 0.3), cex=1.5)
&lt;/pre&gt;

To have a stacked plot, use &lt;code&gt;method=&quot;stack&quot;&lt;/code&gt;


&lt;pre&gt;
stripchart(round(email50$num_char), method=&quot;stack&quot;, 
           pch=19, col=rgb(0, 0, 1, 0.5), axes=F,
           ylim=c(0.8, 1.8))
axis(side = 1)
polygon(x=c(m-3, m, m+3), y=c(0.87, 0.95, 0.87), col=&quot;red&quot;)
&lt;/pre&gt;

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/b/openintrostat/dotplot-r3.png

Note that it given similar information to a [[Histogram]]
* but the latter is binned, and this is not (so it looks rather as a [[Bar Chart]])

&lt;pre&gt;
t = table(round(email50$num_char))
a = rep(NA, 65)
names(a) = 0:64

for (i in names(a)) {
  a[i] = t[i]
}

a[is.na(a)] = 0
barplot(a, ylim=c(-0.4, max(a)))
polygon(x=c(m-3, m, m+3), y=c(-0.4, -0.05, -0.4), col=&quot;red&quot;)
&lt;/pre&gt;
https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/b/openintrostat/dotplot-r3-as-hist-1.png


&lt;pre&gt;
hist(email50$num_char, breaks=30, col=&quot;red&quot;)
&lt;/pre&gt;

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/b/openintrostat/dotplot-r3-as-hist-2.png

And finally, an example from [http://stackoverflow.com/a/15245023/861423]

&lt;pre&gt;
set.seed(1)
A = sample(0:10, 100, replace=T)
stripchart(A, method=&quot;stack&quot;, offset=.5, at=.15, pch = 19,
           main = &quot;Dotplot of Random Values&quot;, xlab = &quot;Random Values&quot;)
&lt;/pre&gt;

http://i.stack.imgur.com/b14vG.png


== See Also ==
* [[R Visualization Snippets]]

== Links and Sources ==
* [[OpenIntro Statistics (book)]]
* http://www.cyclismo.org/tutorial/R/plotting.html
* http://stackoverflow.com/a/15245023/861423

[[Category:Plots]]
[[Category:R]]</text>
      <sha1>7ft3iwodjnxqfwipjtiiv8nc1hf50kw</sha1>
    </revision>
  </page>
  <page>
    <title>Q-Q Plot</title>
    <ns>0</ns>
    <id>480</id>
    <revision>
      <id>483</id>
      <timestamp>2014-07-22T19:17:50Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2976">== Q-Q Plot ==
=== Probability Plot ===
A Probability plot is a technique for comparing two data sets
* e.g. two empirical observations
* or empirical set vs theoretical set

Commonly used:
* P-P plot, &quot;Probability-Probability&quot; or &quot;Percent-Percent&quot; plot;
* Q-Q plot, &quot;Quantile-Quantile&quot; plot, which is more commonly used.


=== Normal Probability Plot ===
It's a special case of Q-Q plots:
* a Q-Q plot against the standard normal distribution;


The normal probability plot is formed by:
* Vertical axis: Ordered response values
* Horizontal axis: Normal order statistic medians or means (see rankit [https://en.wikipedia.org/wiki/Rankit])


Constructing 
# order the observations 
# determine the percentile for each
# identify the $z$-score for each percentile 
# create a [[Scatterplot]]
#* observation (vertical) vs
#* $z$-score (horizontal)


if the data is normally distributed, $z$-scores on the horizontal axis should approximately correspond to their percentiles


== [[R]] ==
=== Example 1 ===
Evaluating the [[Normal Distribution]] (see [http://rpubs.com/agrigorev/21480])

&lt;pre&gt;
load(url(&quot;http://www.openintro.org/stat/data/bdims.RData&quot;))
fdims = subset(bdims, bdims$sex == 0)

qqnorm(fdims$hgt, col=&quot;orange&quot;, pch=19)
qqline(fdims$hgt, lwd=2)
&lt;/pre&gt;

http://habrastorage.org/files/fb0/7c2/422/fb07c242281d4b25911459e38f3f1d58.png

Does it look similar to real [[Normal Distribution]]?
* it does
* let's simulate the normal distribution and compare 

&lt;pre&gt;
set.seed(123)
sim.norm = rnorm(n=length(fdims$hgt), mean=mean(fdims$hgt), sd=sd(fdims$hgt))
qqnorm(sim.norm, col=&quot;orange&quot;, pch=19, main=&quot;Normal Q-Q Plot of simulated data&quot;)
qqline(sim.norm, lwd=2)
&lt;/pre&gt;

http://habrastorage.org/files/471/d9f/11a/471d9f11a690436f96f56ad0c4c544c4.png


Can try to plot several simulations 

&lt;pre&gt;
qqnormsim = function(dat, dim=c(2,2)) {
  par(mfrow=dim)
  qqnorm(dat, main=&quot;Normal QQ Plot (Data)&quot;)
  qqline(dat)
  for (i in 1:(prod(dim) - 1)) {
    simnorm &lt;- rnorm(n=length(dat), mean=mean(dat), sd=sd(dat))
    qqnorm(simnorm, main = &quot;Normal QQ Plot (Sim)&quot;)
    qqline(simnorm)
  }
  par(mfrow=c(1, 1))
}
qqnormsim(fdims$hgt)
&lt;/pre&gt;

http://habrastorage.org/files/828/0c1/c21/8280c1c21ec94cd69916fc92d26dfe3b.png

Looks like it's indeed normal


=== Example 2 ===
(Same data set as in example 1)

Let's take a look at another dataset

&lt;pre&gt;
hist(fdims$wgt)
&lt;/pre&gt;

http://habrastorage.org/files/600/799/aa1/600799aa1fd24b03beed1d063fd7cb0f.png

Looks a bit skewed 

&lt;pre&gt;
qqnorm(fdims$wgt, col=&quot;orange&quot;, pch=19)
qqline(fdims$wgt, lwd=2)
&lt;/pre&gt;

http://habrastorage.org/files/fba/bb4/94c/fbabb494c4554aa8b9c88d58b0ae0213.png

&lt;pre&gt;
qqnormsim(fdims$wgt)
&lt;/pre&gt;

http://habrastorage.org/files/5ca/bf6/072/5cabf607296141b5b4297fe749f1bbd2.png

Most likely not normal 


== Sources ==
* [[OpenIntro Statistics (book)]]
* https://en.wikipedia.org/wiki/Q-Q_plot
* https://en.wikipedia.org/wiki/Normal_probability_plot

[[Category:Plots]]
[[Category:Data Analysis]]
[[Category:R]]</text>
      <sha1>ctn3t3qbc5safmupb5enchepgd2noc4</sha1>
    </revision>
  </page>
  <page>
    <title>Negative Binomial Distribution</title>
    <ns>0</ns>
    <id>481</id>
    <revision>
      <id>484</id>
      <timestamp>2014-07-22T19:21:33Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2278">== Negative Binomial Distribution ==
The negative binomial distribution is a Discrete [[Distribution]] of [[Random Variable]]s
* [[Geometric Distribution]]: probability of observing first success on $n$th trial 
* NBD: probability of observing $k$th success on $n$th trial 
* so NBD is a generic case of Geometric Distribution


A distribution is NBD if:
* trials are independent 
* each trial is a [[Bernoulli Trial]] - i.e. has only two outcomes - success and failure
* $p$ is the same for all the trials
* the last trial must be success 


NBD:
* $k$ - number of successes, $n$ - total number of trials
* $p$ - probability of success, $q = 1 - p$ - probability of failure
* [[Probability Mass Function|pmf]]: $Pr(X = x) = C^{k-1}_{n-1} q^{n-k} p^{k}$




== Example ==
=== Example 1 ===
A footballer can go home only after he scores 4th goal 
* $p$ - probability of success 

Suppose he made 6 attempts 
* what's the probability that he scored 4 goals, and &lt;u&gt;the last trial led to success&lt;/u&gt;?

Let's write down all possible sequences when the 4th kick is on the 6th attempt:

&lt;pre&gt;
from itertools import permutations
p = set([x for x in permutations('SSSSFF')])
[x for x in p if x[-1] == 'S']
&lt;/pre&gt;

{| class=&quot;wikitable&quot; 
! 1 
| F || S || S || F || S || S
|- 
! 2 
| S || S || F || S || F || S
|- 
! 3 
| S || F || F || S || S || S
|- 
! 4 
| F || F || S || S || S || S
|- 
! 5 
| F || S || F || S || S || S
|- 
! 6 
| S || F || S || S || F || S
|-
! 7 
| S || F || S || F || S || S
|- 
! 8 
| S || S || F || F || S || S
|- 
! 9 
| S || S || S || F || F || S
|- 
! 10 
| F || S || S || S || F || S
|}


There are 10 sequences that lead to this outcome 
* note that Success is always last!

Let's calculate the probability of going home after 6 kicks (having 6th kick successful)
* so $P(\text{go home}) = \sum_{i=1}^{10} P(\text{seq}_i)$
* each sequence has the same probability of occurring:
** $P(\text{seq}_i) = P(\text{seq}) = q^{n-k} p^{k}$
** this is the probability of observing $n-k$ failures and $k$ successes
* there are ${n - 1 \choose k - 1}$  ways to pick these elements ($C_{n - 1}^{k - 1}$)


== Sources ==
* [[OpenIntro Statistics (book)]]
* https://en.wikipedia.org/wiki/Negative_binomial_distribution


[[Category:Probability]]
[[Category:Distributions]]</text>
      <sha1>2i9urzcxgipehdclpspamjacfbxt417</sha1>
    </revision>
  </page>
  <page>
    <title>Standard Error</title>
    <ns>0</ns>
    <id>482</id>
    <revision>
      <id>485</id>
      <timestamp>2014-12-08T12:45:45Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3736">== Sampling Distribution ==
=== Parameter Estimation ===
Goal of [[Inferential Statistics]] - to make conclusion about the whole population based on a sample
* So we estimate the parameters based on sampled data 
** if the estimate is just one number, we call it a [[Point Estimate]]
* And with different samples (from the same population) we get different estimates of the same parameter - so we have ''variability'' (''sampling variability'') in estimates 
* The probability distribution of the parameter estimate is called ''Sampling Distribution'' 


=== Sampling Distribution ===
The sampling distribution represents the distribution of point estimates based on samples of fixed size from the same population
* we can think that a particular [[Point Estimate]] is drawn from the sampling distribution
* and [[Standard Error]] is the measure of variability (e.g. how uncertain we are about our estimate)


== Examples ==
=== Example 1 ===
* Suppose we flip a coin 10 times and count the number of heads
* Our parameter of interest is $p = p(\text{heads})$
* $\hat{p}$ - estimate of $p$
** $\hat{p} = \cfrac{\text{# of heads}}{\text{total # of flips}}$
** i.e. $\hat{p}$ is calculated from data

&lt;pre&gt;
set.seed(134)
rbinom(10, size=10, prob=0.5)
&lt;/pre&gt;

We get different results each time:

{| class='wikitable'
! Trial || 1 || 2 || 3 || 4 || 5 || 6 || 7 || 8 || 9 || 10
|-
! Outcome 
| 4 || 6 || 7 || 4 || 5 || 3 || 4 || 6 || 3 || 6
|}


Since we know that theoretically this [[Random Variable]] follows [[Binomial Distribution]], we can model the sampling distribution as

&lt;pre&gt;
d = dbinom(1:10, size=10, prob=0.5)
bp = barplot(d)
axis(side=1, at=bp[1:10], labels=1:10)
&lt;/pre&gt;

http://habrastorage.org/files/b39/001/83f/b3900183fe9f478fadf895deed1d0d56.png


This sampling distribution is used for [[Binomial Proportion Confidence Intervals]] and for [[Binomial Proportion Test]]
* note that as the sample size grows it becomes more reasonable to use the [[Binomial Distribution#Normal Approximation|Normal Approximation]] 



=== Example 2 ===
&lt;pre&gt;
load(url('http://s3.amazonaws.com/assets.datacamp.com/course/dasi/ames.RData'))
area = ames$Gr.Liv.Area
sample_means50 = rep(NA, 5000)
 
for (i in 1:5000) {
  samp = sample(area, 50)
  sample_means50[i] = mean(samp)
}

hist(sample_means50, breaks=13, probability=T, col='orange',
     xlab='point estimates of mean', main='Sampling distribuion of mean')
&lt;/pre&gt;

http://habrastorage.org/files/d9a/06a/02d/d9a06a02d0944fb495c81c29daa29047.png


=== Example: Running Mean ===
There's another example that shows that the more data we have, the more accurate our point estimates are
* A ''running mean'' (or '[[Moving Average]]') is a sequence of means, where each following mean uses one extra observation
* If we take the moving average from 1 data point and keep including next ones, it approaches the &quot;true mean&quot;

http://habrastorage.org/files/454/073/b0a/454073b0ac4149c789916b3dba2c61c6.png


{{ Hider |
   title=R code to produce the figure |
   content=
&lt;pre&gt;
library(openintro)
data(run10Samp)
time = run10Samp$time
avg = sapply(X=1:100, FUN=function(x) { mean(time[1:x]) })
plot(x=1:100, y=avg, type='l', col='blue',
     ylab='running mean', xlab='sample size', bty='n')
abline(h=mean(time), lty=2, col='grey')
&lt;/pre&gt;
}}


So it illustrates that the more sample size is, the better we can estimate the parameter



== Typical Sampling Distributions ==
* [[Normal Distribution]] for this
* [[t Distribution]] for that


== Sources ==
* [[OpenIntro Statistics (book)]]
* [[Statistics: Making Sense of Data (coursera)]]
* DataCamp, Lab 3A - Sampling distributions [http://rpubs.com/agrigorev/21595]
* https://en.wikipedia.org/wiki/Sampling_distribution

[[Category:Statistics]]</text>
      <sha1>24bv7x7wh3c3waeat1v8xdm2e3hkryl</sha1>
    </revision>
  </page>
  <page>
    <title>Biased Estimators</title>
    <ns>0</ns>
    <id>483</id>
    <revision>
      <id>486</id>
      <timestamp>2014-07-23T20:14:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3212">== Biased Estimators ==
A [[Point Estimate]] is [[Bias|''biased'']] if
* the [[Sampling Distribution]] of some parameter being estimated is not centered around the true parameter value
* otherwise a Point Estimate is ''unbiased''


[[Bias]] of an estimate is the expected difference between the estimated value and the true value


== Unbiased Estimation ==
A statistic used to estimate a parameter is ''unbiased'' if the expected value of its sampling distribution is equal to the value of the parameter being estimated


=== Proportion ===
In our coin flipping example
* a flip follows the [[Bernoulli Distribution]] with $p = 1/2$
** $X \sim \text{Bernoulli}(0.5)$
* and $E(X) = 0.5$


For the entire experiment:
* 10 coin flips = 10 Bernoulli experiments with outcomes $X_1, ..., X_{10}$
* so, $\hat{p} = \cfrac{X_1 + ... + X_{10}}{10} = \bar{X}$
* thus, $E(\hat{p}) = p$ since $E(X_i) = p$ and $E(\bar{X}) = \cfrac{10 p}{10}  = p$
* and $\hat{p}$ is called ''unbiased estimator''


== Biased Estimation ==


=== [[Standard Deviation]] ===
Standard Deviation is biased estimate of the true standard deviation of the proportion
* so we typically use the sample standard deviation, which is 
** $s = \cfrac{1}{n-1} \sum_{i=1}^n x_i $


Can simulate it to see that it's true
* suppose that we have the following population
** http://habrastorage.org/files/d6f/7d4/88b/d6f7d488b10e4e819d77def52d4bd26d.png
* we sample with sample size 25 many times (e.g. 5000) 
** each time calculate biased std as well as corrected std
* then plot the sampling distributions
** http://habrastorage.org/files/a33/440/4ea/a334404ea02a4ffd877dc57c7f0636b9.png
** we see that the corrected std is closer to the real population std
** note that the real population std should not be corrected!


{{ Hider |
   title=R simulation |
   content=
&lt;pre&gt;
sd.population = function(x) {
  n = length(x)
  m = mean(x)
  sqrt(sum((x - m) ^ 2) / n)
}

population = unlist(sapply(X=1:7, FUN=function(x) { rep(x, choose(8, x)) }))
pop = table(population)
b = barplot(pop)
text(x=b, y=pop-4, pop)

set.seed(1231)
sample.1 = rep(NA, 5000)
sample.2 = rep(NA, 5000)

size = 25

for (i in 1:5000) {
  s = sample(population, size)
  sample.1[i] = sd(s)
  sample.2[i] = sd.population(s)
}

true.pop = sd.population(population)
biased.center = mean(sample.2)
center = mean(sample.1)

c(true.pop, center, biased.center)
c(abs(true.pop - center), abs(true.pop - biased.center))

x = seq(0, 3, 0.1)

hist(sample.1, col=adjustcolor('blue', 1/4), breaks=35,
     probability=T, xlim=c(0.8, 1.9),
     main='Sampling Distributions of STD functions',
     xlab='Estimated Value')
abline(v=center, col='blue')
xspline(x=x, y=dnorm(x, mean=center, sd=sd(sample.1)), 
        lwd=1, shape=1, lty=2, border=&quot;blue&quot;)

hist(sample.2, col=adjustcolor('red', 1/4), probability=T,
     breaks=35, add=T)
abline(v=biased.center, col='red')
xspline(x=x, y=dnorm(x, mean=biased.center, sd=sd(sample.2)), 
        lwd=1, shape=1, lty=2, border=&quot;red&quot;)

abline(v=true.pop)
&lt;/pre&gt;
}}



== Sources ==
* [[OpenIntro Statistics (book)]]
* [[Statistics: Making Sense of Data (coursera)]]
* https://en.wikipedia.org/wiki/Bias_of_an_estimator

[[Category:Statistics]]
[[Category:R]]</text>
      <sha1>jatad5i41ro843mo8cvahqflw2fvwvn</sha1>
    </revision>
  </page>
  <page>
    <title>Mosaic Plot</title>
    <ns>0</ns>
    <id>484</id>
    <revision>
      <id>487</id>
      <timestamp>2014-07-23T20:21:36Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="823">== Mosaic Plot ==
This is a [[Plot]]
* it's a visualization of information from [[Contingency Table]]s
* it's similar to a [[Bar Chart]], but shows more information
* uses areas to represent this information


=== [[R]] ===
Add data

&lt;pre&gt;
library(openintro)
data(email)
&lt;/pre&gt;

One variable

&lt;pre&gt;
tab1 = table(email$number)
mosaicplot(tab1, col=c('yellow2', 'skyblue2', 'red'),
           main='Numbers in emails')
&lt;/pre&gt;

http://habrastorage.org/files/5d6/3a9/1dd/5d63a91dd2be45e499aeacedb579328e.png


&lt;pre&gt;
tab2 = table(email$number, email$spam)
mosaicplot(tab2, col=c('yellow2', 'skyblue2'),
           main='Numbers in emails vs spam/not spam')
&lt;/pre&gt;

http://habrastorage.org/files/afd/8ce/0b7/afd8ce0b7f3d4f71ad86a07b56d3a098.png


== Sources ==
* [[OpenIntro Statistics (book)]]

[[Category:Plots]]
[[Category:R]]</text>
      <sha1>pqvbyoysqamfytj7remfqiyormo3d1k</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Statistical Tests</title>
    <ns>14</ns>
    <id>485</id>
    <revision>
      <id>488</id>
      <timestamp>2014-07-26T09:07:30Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23">[[Category:Statistics]]</text>
      <sha1>topdxb3qmeiwmfbs592nr8eukj7029r</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Classifiers</title>
    <ns>14</ns>
    <id>486</id>
    <revision>
      <id>489</id>
      <timestamp>2014-07-26T09:13:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="29">[[Category:Machine Learning]]</text>
      <sha1>n8w88wwx02oq4b7xpy1nt4zqyteghjs</sha1>
    </revision>
  </page>
  <page>
    <title>Statistical Tests of Significance</title>
    <ns>0</ns>
    <id>487</id>
    <revision>
      <id>490</id>
      <timestamp>2014-07-27T10:12:32Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="54">#перенаправление [[Hypothesis Testing]]</text>
      <sha1>g1l0mwja7glyh07in8nnun5hbuzqvnf</sha1>
    </revision>
  </page>
  <page>
    <title>OpenIntro Statistics (book)</title>
    <ns>0</ns>
    <id>488</id>
    <revision>
      <id>491</id>
      <timestamp>2015-04-19T10:07:07Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2445">== OpenIntro Statistics ==
This is an introductory book to [[Statistics]]

Website: 
* http://www.openintro.org/stat/ 
* http://www.openintro.org/stat/textbook.php


=== [[Data Collection]] ===
* [[Sampling]]
* [[Observational Studies]]
* [[Statistical Experiment]]s


=== Descriptive Statistics ===

Examining Numerical Data
* [[Plots]]
** [[Scatter Plot]]s
** [[Box Plot]]s
** [[Bar Chart]]s
** [[Mosaic Plot]]s


* [[Contingency Tables]]
* [[Conditional Distribution]]
* [[Joint Distribution]]


=== Probability ===
[[Distributions]]
* [[Normal Distribution]]
* [[Binomial Distribution]]
* [[Geometric Distribution]]
* [[Negative Binomial Distribution]]



=== [[Inferential Statistics]] ===
[[Point Estimate]]s
* [[Sampling Distribution]] and [[Central Limit Theorem]]
* [[Standard Error]]
* [[Biased Estimators]]

[[Confidence Intervals]]
* [[Confidence Intervals for Means]]
* [[Binomial Proportion Confidence Intervals]]

[[Hypothesis Testing]]
* [[Confidence Intervals and Statistical Tests]]
* [[z-tests]] and [[t-tests]] for means (one-sample and two-sample)
* [[Binomial Proportion Tests]] for testing (one-sample and two-sample) for using Normal Approximation
** [[Exact Binomial Proportion Tests]] for using [[Binomial Distribution]]
* [[ANOVA]] and [[One-Way ANOVA F-Test]] for testing relationships between Numerical and Categorical variables
* [[Chi-Squared Tests]] for testing relationships between two Categorical variables


[[Statistical Simulation]]
* {{ TODO | Add later }}




== DataCamp Labs ==
The labs [https://www.datacamp.com/courses/data-analysis-and-statistical-inference_mine-cetinkaya-rundel-by-datacamp] are the interactive version of the exercises from the book


Labs:
* [http://rpubs.com/agrigorev/21475 Lab 1]: Introduction to Data
* [http://rpubs.com/agrigorev/21476 Lab 2]: Probability
* [http://rpubs.com/agrigorev/21595 Lab 3A]: [[Sampling Distribution]]s
* [http://rpubs.com/agrigorev/21596 Lab 3B]: [[Confidence Intervals]]
* [http://rpubs.com/agrigorev/23230 Lab 4]: Inference for numerical data
* [http://rpubs.com/agrigorev/23240 Lab 5]: Inference for categorical data
* [http://rpubs.com/agrigorev/23247 Lab 6]: Introduction to linear regression
* [http://rpubs.com/agrigorev/23249 Lab 7]: Multiple linear regression
* [http://rpubs.com/agrigorev/21480 Extra lab]: Distributions (lab 3 from [http://www.openintro.org/stat/labs.php])



[[Category:Statistics]]
[[Category:Books]]
[[Category:Notes]]</text>
      <sha1>5qcgq8zf1qzsgzgb5e3ytybjatmtd8j</sha1>
    </revision>
  </page>
  <page>
    <title>Z-tests</title>
    <ns>0</ns>
    <id>489</id>
    <revision>
      <id>492</id>
      <timestamp>2014-07-28T17:25:32Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4012">== $Z$ Tests ==
This is a family of [[Hypothesis Testing|statistical tests]] that use [[Normal Distribution|Normal Model]] to compute test statistics 
* most of the time $Z$ tests are restricted versions of [[t-tests|$t$-tests]], so it's more advisable to use $t$ tests, especially because for larger degrees of freedom [[t Distribution|$t$-distribution]] is very close to Normal


The following are $z$ tests
* one-sample $z$-test - for comparing the mean of a sample against some given mean
* paired $z$-test - for Matching Pairs setup
* two-sample $z$-test - for comparing the means of two samples



== Assumptions ==
* Observations are independent (if less than 10% of population is sampled, then we can make sure it's satisfied)
* Sample size is sufficiently large so [[Central Limit Theorem|C.L.T.]] holds
* Moderate skew, few outliers (not too extreme)

If these assumptions are hold, then we can use the $z$ statistics 
* if sample size is smaller, then it's better to use [[t-tests|$t$-tests]]
* if the distribution has skews and outliers, use simulations {{ TODO | add link !!!!!!!!}}
* but in any case the observations have to be independent


== One-Sample $z$ Test ==
=== Example 1: One-Sided ===
Assume we have the following
* http://habrastorage.org/files/9d6/bf3/a36/9d6bf3a3673e4ca9a37fe1e94a481b29.png
* source: [[OpenIntro Statistics (book)|OpenIntro]], figure 4.14

Sample: 110 students, conditions are met:
* less than 10% of all students are sampled,
* sufficiently large $\geqslant 30$
* only a couple of outliers, which is acceptable for sample size $n=110$


So we can apply the Normal Model and do the following test:
* $H_0: \mu = 7$ - students sleep only 7 hours on avg, $H_A: \mu &gt; 7$ students sleep more than 7 hours on avg


Calculate 
* the sample mean: $\bar{x} = 7.42$
* the [[Standard Error]]: $\text{SE}_{\bar{x}} = \cfrac{s_x}{\sqrt{n}} = \cfrac{1.75}{110} = 0.17$

$Z$ score:
* then compute the $Z$ score: $Z = \cfrac{x - \text{null value}}{\text{SE}_{\bar{x}}} = \cfrac{7.42 - 7}{0.17} = 2.47$
* then calculate the $p$-value for this test statistics 
** $p = 0.007$
** http://habrastorage.org/files/4c3/5c0/ae1/4c35c0ae1faf403cbb35255a3bd20544.png
** source: [[OpenIntro Statistics (book)|OpenIntro]], figure 4.15


so, under $H_0$ the probability of observing such $\bar{x}$ is just $p = 0.007$
* our level of significance is $\alpha 0.05$, we compare $\alpha$ and $p$: 
* $p =  0.007 &lt; 0.05 = \alpha$,
* $\Rightarrow$ we reject $H_0$ in favor of $H_A$: what we observe is so unusual under $H_0$ which casts a doubt on $H_0$ and provides strong evidence to $H_A$
* so we reject $H_0$ and conclude that on average students sleep more than 7 hours


== Other $z$-tests ==
=== Paired $z$-test ===
Analogously to Paired $t$-test, we can use $z$ statistics to analyze matched pairs data, provided that the sample size is sufficiently large 

Example:
* two samples: local bookshop and amazon 
* $\mu_\text{dif} = \mu_l - \mu_a$ - the mean of difference in the price
* $H_0: \mu_\text{dif} = 0$ - there's no difference in the price
* $H_A: \mu_\text{dif} \ne 0$ - there's some difference 
* $\bar{x}_\text{dif} = 12.76$
* Standard Error: $\text{se}_{\bar{x}_\text{dif}} = \cfrac{s_\text{dif}}{\sqrt{n_\text{dif}}} = 1.67$
* $Z = \cfrac{\bar{x}_\text{dif}}{\text{se}_{\bar{x}_\text{dif}}} = \cfrac{12.76}{1.67} = 7.59$
* this is too large $z$ score, but let's calculate the $p$-value
* $p = 0.00004$, less than $\alpha = 0.05$, so we reject $H_0$


&lt;pre&gt;
library(openintro)
data(textbooks)

hist(textbooks$diff, col='yellow')

n = length(textbooks$diff)
s = sd(textbooks$diff)
se = s / sqrt(n)

x.bar.nul = 0
x.bar.dif = mean(textbooks$diff)

z = (x.bar.dif - x.bar.nul) / se
z

p = pnorm(z, mean=x.bar.nul, sd=se, lower.tail=F) * 2
p
&lt;/pre&gt;




== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[OpenIntro Statistics (book)]]
* http://projectile.sv.cmu.edu/research/public/talks/t-test.htm

[[Category:Statistics]]
[[Category:Statistical Tests]]
[[Category:R]]</text>
      <sha1>oft4mx7zzjbgq9p3063pyffuzr00plk</sha1>
    </revision>
  </page>
  <page>
    <title>T Distribution</title>
    <ns>0</ns>
    <id>490</id>
    <revision>
      <id>493</id>
      <timestamp>2014-07-28T18:35:36Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1826">== $t$ Distribution ==
This is a family of Continuous [[Distribution]]s
* unimodal and bell-shaped, like [[Normal Distribution]]
* centered at 0
* has one parameter: degrees of freedom ($\text{df}$)


=== Origin ===
Origin (and usage):
* arises when estimating the mean of normally distributed population when 
* sample size is small and population standard deviation is unknown 



=== $t$-distribution vs [[Normal Distribution|Normal]] ===
* for large $\text{df}$ ($\geqslant 100$) $t$-dist closely follows $N(0,1)$
* but even for $\text{df} \geqslant 30$ it's already almost indistinguishable

http://habrastorage.org/files/2d3/6f1/963/2d36f1963cc54cd5be3534c691f68c1c.gif

* for $t$ tails are thicker 
** so observations are more likely to fall beyond 2$\sigma$ from the mean (than under $N(0,1)$)
* it's good for [[t-tests]]: 
** the thick tails are exactly the correction to deal with poorly estimated [[Standard Error]]


http://habrastorage.org/files/502/05d/b61/50205db619254cd9a7eded5d7579cabe.png
* here, $\text{df}$ is the lowest, and it approaches the normal curse as $\text{df}$ grows

{{ Hider |
   title=R code to produce the figure |
   content=
&lt;pre&gt;
default.par = par()

x = seq(-4,4,0.1)
n = dnorm(x)

library(animation)

saveGIF({
  par(mar=c(0,0,0,0))
  
  for (i in 1:100) {
    plot(x, n, type='l', lty=2, col='grey')
    t = dt(x, df=i)
    lines(x, t, col='blue')
    text(1.5, 0.37, paste('df =', i))
    text(1.66, 0.35, format(sum(abs(n - t)))) 
  }
}, interval=0.1)

par(mar=c(0,0,0,0))
plot(x, n, type='l', lty=2, col='grey')

for (i in 1:7) {
  t = dt(x, df=i)
  lines(x, t, col=i)
}

par(default.par)
&lt;/pre&gt;
}}



== Sources ==
* [[OpenIntro Statistics (book)]]
* http://projectile.sv.cmu.edu/research/public/talks/t-test.htm

[[Category:Probability]]
[[Category:Distributions]]
[[Category:R]]</text>
      <sha1>7mg68guevtx0b97w1bp9u02l07depu4</sha1>
    </revision>
  </page>
  <page>
    <title>Data Collection</title>
    <ns>0</ns>
    <id>491</id>
    <revision>
      <id>494</id>
      <timestamp>2014-07-28T18:37:37Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="722">== Data Collection ==
In [[Statistics]], there is 
* a research question about the target population
* and we need to answer it based on some data
* how to get the data?

=== [[Sampling]] ===
* Typically cannot get the data for the entire population
* Can take a fraction of this data - this is called [[Sampling]] 


=== Types ===
There are several types of data collection: 
* [[Observational Studies]] - monitor and record 
** sufficient to show association
** not sufficient to show causation
* [[Statistical Experiment]]s - conduct an experiment and collect the data 
** sufficient to show causation when the experiment is designed carefully 


== Sources ==
* [[OpenIntro Statistics (book)]]

[[Category:Statistics]]</text>
      <sha1>fnnfor2e9p48yw6wqa192ima9knedbk</sha1>
    </revision>
  </page>
  <page>
    <title>Hypothesis Testing Decision Errors</title>
    <ns>0</ns>
    <id>492</id>
    <revision>
      <id>495</id>
      <timestamp>2015-04-19T11:02:35Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2352">== Hypothesis Testing Decision Errors ==
[[Hypothesis Testing]] sometimes mistake - and we need to have tools quantify these mistakes 



== Type I and Type II Errors ==
{| class=&quot;wikitable&quot;
|+ Summary [http://en.wikipedia.org/wiki/Type_I_and_type_II_errors]
! || $H_0$ is true  || $H_0$ is false
|-
! Reject $H_0$
| align=&quot;center&quot;| Type&amp;nbsp;I error&lt;br /&gt;False positive
| align=&quot;center&quot;| Correct outcome&lt;br /&gt;True positive
|-
! Fail to reject $H_0$
| align=&quot;center&quot;| Correct outcome&lt;br /&gt;True negative
| align=&quot;center&quot;| Type&amp;nbsp;II error&lt;br /&gt;False negative
|}


* A decrease in one type of error leads to increase the probability of other 
* So we need to have more evidence 


== Type I Error ==
* Reject $H_0$ when it's true
* This happens with probability \alpha
* (An innocent is falsely convicted)


Significance Level $\alpha$ controls Type I errors 


=== Controlling Family-Wise Error Rate ===
* suppose we run [[Multiple Comparisons Tests]]
* e.g. want to compare pair-wise 10 samples
* thus we need to make about $\sum_{i=1}^{10} i = 45$ comparisons
* the chances hight that among the 45 tests a couple of them will incorrectly reject $H_0$ - i.e. they will make Type 1 Error 
* the solution is to modify the significance level, e.g. using the [[Bonferroni Correction]]
* see [[Family-Wise Error Rate]]



== Type II Error ==
* Fail to reject $H_0$ when $H_A$ is true 
* This happens with probability $\beta = 1 - \text{power}$
* We don't have enough power - probably the test size is too small
* (A criminal is freed)

The probability of making Type II Errors is called the ''Type II error rate''

=== Controlling Type II Errors ===
Type II Errors can be controlled by:
* the Sample Size 
* [[Statistical Power|Power of a Test]]


=== Sample Size ===
* we may find a specific sample size such that we have some certain margin of error 
* see [[Sample Size Estimation]]


=== [[Statistical Power|Power of a Test]] ===
Power of a test also allows to control the 
* suppose the power of a test is 0.979. what's the type II error rate?
* it's 1 - 0.979 = 0.021 - this is the probability of failing to reject $H_0$ when it's true



== Sources ==
* [[OpenIntro Statistics (book)]]
* [[Statistics: Making Sense of Data (coursera)]]
* http://en.wikipedia.org/wiki/Type_I_and_type_II_errors

[[Category:Statistics]]
[[Category:Statistical Tests]]</text>
      <sha1>9g0p4imb9acs1tl997dsap3371pic5i</sha1>
    </revision>
  </page>
  <page>
    <title>Sample Size Estimation</title>
    <ns>0</ns>
    <id>493</id>
    <revision>
      <id>496</id>
      <timestamp>2015-04-19T10:55:19Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3393">== Sample Size ==
When we need to estimate the size of a sample?
* For [[Confidence Intervals]] we want to know how much we need to sample to get some Margin of Error
* For [[Hypothesis Testing]] we want to control [[Type II Errors]]


== [[Confidence Intervals]] ==
=== [[Binomial Proportion Confidence Intervals]] ===
The best $n$?
* CI for $p$
** $\beta = z_{\alpha/2} \sqrt{p(1-p)/n}$, 
* we want margin error be $\beta = 0.03$
* for 95% CI $\alpha = 0.025$

We plug everything in and calculate
* $0.03 = 1.96 \sqrt{p(1-p)/n}$
* use $p = 0.5$ (it's the worst-case scenario)
* $n = \left(\cfrac{1.96 \cdot 0.5}{0.03}\right)^2 \approx 1067$

What if we want margin error 0.01? 
* $0.01 = 1.96 \sqrt{0.5 \cdot 0.5 / n}$ or
* $n \approx 9604 = 9 \cdot 1067$ !

To cut the margin error in half we need 4 times bigger sample size!
** So lovering the margin is expensive 


What if we want 99% CI instead of 95%? 
* $z_{\alpha/2} = z_{0.005} \approx 2.576$
* $0.03 = 2.576 \sqrt{0.5 \cdot 0.5 / n}$
* $n \approx 1843$

For 90% CI $n \approx 753$




=== [[R]] ===
Example 1
&lt;pre&gt;
p = 0.5
ME = 0.03
z = qnorm(0.025, mean=0, sd=1, lower.tail=F)
n = z^2 * p * (1 - p) / ME^2
&lt;/pre&gt;


Example 2:
* What sample size is needed to attain a margin error of 0.5% for 99% CI?
&lt;pre&gt;
p = 0.5 // worst-case estimate
ME = 0.005
cl = 0.99
al = (1 - cl) / 2

z = qnorm(al, mean=0, sd=1, lower.tail=F)
n = z^2 * p * (1 - p) / ME^2
&lt;/pre&gt;


== Controlling False Negatives ==
Sample Size controls [[Type II Errors]] - False Negatives
* What sample size is good for a certain margin of error?
* recall that a margin of error the &quot;radius&quot; of the [[Confidence Intervals|Confidence Interval]] - boundaries of the [[Point Estimate]]


=== [[z-tests|$Z$ Statistics]] for Means ===
Suppose we want to have a 95% confidence interval
* $Z = 1.96$
* $\text{ME}_{0.95} = Z \cdot \text{SE} = 1.96 \cfrac{\sigma}{\sqrt{n}}$
* we want $\text{ME} \leqslant 4$ 
* so $1.96 \cdot \cfrac{\sigma}{\sqrt{n}} \leqslant 4$, and we want to get $n$ from this inequality
** NOTE: need to know $\sigma$, otherwise we should use $T$ statistics instead of $Z$ and estimate $\sigma$ by $s$
* e.g. suppose that we know that the whole country $\sigma$ is 25, so it might be a good estimate for $\sigma$ within a company


We get:
* $1.96 \cdot \cfrac{\sigma}{\sqrt{n}} \approx 1.96 \cdot \cfrac{25}{\sqrt{n}}$
* $1.96 \cdot \cfrac{25}{4} \leqslant \sqrt{n}$
* $\left( 1.96 \cdot \cfrac{25}{4} \right)^2 \leqslant n$
* $150.06 \leqslant n$

$\Rightarrow$ we need $n \geqslant 151$ to have ME of 4


== Stuff ==
{{ TODO | Interesting Links}}
* http://www.mailund.dk/index.php/2009/07/05/false-positives-and-large-sample-sizes/


Caveat, with such a large sample size, one would expect even tiny differences in occurrence to produce &quot;strong&quot; significance levels. See Why does frequentist hypothesis testing become biased towards rejecting the null hypothesis with sufficiently large samples?

http://stats.stackexchange.com/questions/108911/why-does-frequentist-hypothesis-testing-become-biased-towards-rejecting-the-null/

I've seen this claim before in Karl Friston's 2012 paper in NeuroImage, where he calls it the fallacy of classical inference.



== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[OpenIntro Statistics (book)]]
* http://en.wikipedia.org/wiki/Sample_size

[[Category:Statistics]]
[[Category:Statistical Tests]]</text>
      <sha1>mvmyfyofbbyei2suvum9mnacizjtba7</sha1>
    </revision>
  </page>
  <page>
    <title>Binomial Proportion Confidence Intervals</title>
    <ns>0</ns>
    <id>494</id>
    <revision>
      <id>497</id>
      <timestamp>2014-08-02T20:35:08Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6132">== Binomial Proportion Confidence Intervals ==
These are [[Confidence Intervals]] for estimating a proportion in the population 
* When we sample, we calculate a [[Point Estimate]] of the proportion
* We know that due to variance in the [[Sampling Distribution]] each time we get different estimates
* How we can expand the point estimate so it's likely to include the true value? 


== Normal Approximation ==
This type of CI makes use of [[Central Limit Theorem]] and [[Binomial Distribution#Normal Approximation|Normal Approximation]] of [[Binomial Distribution]]

So, for any experiment, let 
* $p$ be the true probability 
* $n$ be the number of trials 

Then
* estimate $p$ as $\hat{p} = \cfrac{\text{success}}{n}$
* and the CI is $\left[\hat{p} - 1.96 \sqrt{p(1-p)/n};  \hat{p} + 1.96 \sqrt{p(1-p)/n}\right]$



=== Building a Confidence Interval ===
* We have a sample of $n$ observations: $X_1, ..., X_{n}$
* let $\hat{p} = $ fraction of successful $X_i$, i.e. $\hat{p} = \cfrac{\text{# of success}}{n}$
** so we calculate $\hat{p}$ based on the data in the sample
* if all observations are independent and probability of success $p$ is always the same, then [[Sampling Distribution]] is [[Binomial Distribution]] 
** i.e. each $X_i \sim \text{Bernoulli}(p)$, variance $\text{Var}[X_i] = p \cdot (1 - p) = pq$


Parameters of the [[Sampling Distribution]]
* $\hat{p}$ is an [[Biased Estimators|Unbiased Estimate]] of $p$: $E[\hat{p}] = p$ 
** $E[X_i] = p, \hat{p} = \cfrac{1}{n} \sum_{i=1}^n X_i$
** $E[\hat{p}] = E \left[ \cfrac{1}{n} \sum_{i=1}^n X_i \right] = \cfrac{1}{n} \sum_{i=1}^n E [ X_i ] = \cfrac{np}{n} = p$
* $\text{var}[\hat{p}] = \cfrac{p(1-p)}{n}$
** $\text{var}[\hat{p}] = \text{var} \left[ \cfrac{1}{n} \sum_{i=1}^n X_i \right] = \cfrac{1}{n^2} \sum_{i=1}^n \text{var}[X_i] = \cfrac{npq}{n^2} = \cfrac{pq}{n} = \cfrac{p(1-p)}{n}$
** $\text{sd}[ \hat{p} ] = \sqrt{ \cfrac{p \cdot (1 - p)}{n} }$
* Now we use the [[Binomial Distribution#Normal Approximation|Normal Approximation]] (i.e. apply the [[Central Limit Theorem|C.L.T.]] and calculate that the SD follows [[Normal Distribution]] $N \left( \mu=p, \sigma = \sqrt{ \cfrac{p(1-p)}{n} } \right)$)


We want to build CI at level of $\alpha$
* calculate the [[Z-score|$z$-score]] - $1 - 0.5 \cdot \alpha$ percentile of the Standard [[Normal Distribution]]


E.g. 95% CI
* $z = 1.96$ and we know that 95% of the values lie in $(-z, +z)$
* http://habrastorage.org/files/343/067/151/343067151a98437b821fae10709a8e52.png
* So only in 5 experiments out of 100 you end up outside of this interval


{{ Hider |
   title=R code to produce the figure |
   content=
&lt;pre&gt;
x = seq(-3, 3, 0.1)
y = dnorm(x)

plot(x, y, type='l', bty='n', main='95% CI on N(0,1)')

x1 = min(which(x &gt; -1.96)); x2 = max(which(x &lt; 1.96))
polygon(x[c(x1, x1:x2, x2)],
        c(0, y[x1:x2], 0), col=adjustcolor('blue', 0.4))

text(x=0, y=0.2, labels='0.95', cex=1.5)
text(x=c(-2.07, 2.07), y=0.025, labels='0.025', cex=0.6)
&lt;/pre&gt;
}}



This is called ''95% confidence interval'' for $p$:
* $\left[\hat{p} - 1.96 \sqrt{p(1-p)/n};  \hat{p} + 1.96 \sqrt{p(1-p)/n}\right]$
* left part - ''lower bound''
* right part - ''upper bound ''


We say that we're 95% confident that the true value of $p$ is somewhere in this interval.


=== Margin of Error ===
Problem: $p$ (to use under the square root) is unknown!

Solutions:
* use $\hat{p}$ instead of $p$ (we assume it should be close) or
* use $p = q = 0.5$: it maximizes our ''margin of error''
** &lt;img src=&quot;https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/margin-of-error.png&quot; /&gt;
** margin of error is $\beta = 1.96 \sqrt{p(1-p)/n}$



=== Critical Value ===
Why we chose 95% CI with $\alpha = 0.05$ and not another one?

We can compute any confidence interval using any $\alpha$
* Compute ''critical value'' $z_{\alpha/2}$ such that &quot;not interesting&quot; areas under the normal curve take $\alpha / 2$
** https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/ci-critical-value.png
* so the interval will be $\left[-z_{\alpha/2}; z_{\alpha/2}\right]$ and the &quot;interesting&quot; area under the bell curve is $1 - \alpha$

Margin of error is this case is 
* $\beta = z_{\alpha/2} \sqrt{p(1-p)/n}$ and, as we know, for $95\%$, $\alpha = 0.025$ and $z_{0.025} = 1.96$


As we see, the CI becomes wider as critical value grows 


=== Assumptions ===
Note that by using the [[Central Limit Theorem|C.L.T.]] we assume that:

he central limit theorem applies poorly to this distribution with a sample size less than 30 or where the proportion is close to 0 or 1. The normal approximation fails totally when the sample proportion is exactly zero or exactly one. A frequently cited rule of thumb is that the normal approximation is a reasonable one as long as np &gt; 5 and n(1 − p) &gt; 5; 



== Examples ==
=== Flipping a Beer Cap ===
Imagine an experiment where we flip a beer cap
* it follows the [[Binomial Distribution]], but we don't know the true parameter $p$
* say we flipped a beer cap 1000 times and got 576 reds: $\hat{p} = 0.576$
* what is its statistical model? What is $p$ in $\text{Binomial}(1000, p)$? 

Let's build a Confidence Interval for that
* so we estimate $\hat{p} = 0.576$ and $\text{Var}(\hat{p}) = \cfrac{p(1-p)}{n} = \cfrac{p(1-p)}{1000}$


Result:
* 95% CI is $[0.545, 0.607]$


In R:
&lt;pre&gt;
phat = 0.576
z = qnorm(0.025, mean=0, sd=1, lower.tail=F) // the right tail rather then left
ME = z * sqrt(phat * (1- phat) / 1000) // Margin of error: we replace p by phat
CI = phat + c(-ME, ME) // 0.545, 0.606
&lt;/pre&gt;


=== Example 2  ===
* Calculate the 90% CI for $p$
* With 60 successes out of 100 trials 

&lt;pre&gt;
phat = 0.6
cl = 0.9
al = (1 - cl) / 2
z = qnorm(al, mean=0, sd=1, lower.tail=F)
n = 100

ME = 2 * sqrt(0.5 * 0.5 / n)
ci = phat + c(-ME, ME)
// [0.52, 0.68]
&lt;/pre&gt;



== Sample Size ==
see [[Sample Size Estimation]]


== See Also ==
* [[Binomial Proportion Tests]]

== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[OpenIntro Statistics (book)]]
* https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval

[[Category:Statistics]]
[[Category:R]]</text>
      <sha1>lbmydm63qqfd0rt1l9hc5tsn0ijzvhs</sha1>
    </revision>
  </page>
  <page>
    <title>Point Estimate</title>
    <ns>0</ns>
    <id>495</id>
    <revision>
      <id>498</id>
      <timestamp>2014-07-28T19:05:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1116">=== Points Estimates ===
An estimate is a point estimate when we use only one certain value to describe what we think about the whole population [https://en.wikipedia.org/wiki/Point_estimation]


=== Examples ===
* $\bar{x}$ - sample mean, $\mu$ - population mean, $\bar{x}$ estimates $\mu$
* $\hat{p}$ - estimate of proportion, $p$ - true proportion
* $s$ - sample [[Standard Deviation]], $\sigma$ - std of population
* etc

Point estimates are not necessarily good, but they tend to become better as we collect more data


=== Standard Error ===
[[Standard Error]] - a measure of uncertainty associated with this point estimate


=== Confidence Intervals ===
A point estimate - is a single plausible value for a parameter 
* but one point is rarely enough - we'd like to have a range of plausible values 
* so we typically use [[Confidence Intervals]]


== See Also ==
* [[Confidence Intervals]]
* [[Sampling Distribution]]

== Sources ==
* [[OpenIntro Statistics (book)]]
* http://onlinestatbook.com/2/glossary/point_estimate.html
* http://en.wikibooks.org/wiki/Statistics/Point_Estimates

[[Category:Statistics]]</text>
      <sha1>t5qv6776sp8vn72rttngv7is7ncrnzh</sha1>
    </revision>
  </page>
  <page>
    <title>Confidence Intervals for Means</title>
    <ns>0</ns>
    <id>496</id>
    <revision>
      <id>499</id>
      <timestamp>2014-08-06T20:04:08Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7003">== Confidence Intervals for Means ==
We want to build a [[Confidence Intervals|Confidence Interval]] for a [[Point Estimate]] of the population mean


=== Problem ===
* let $\mu$ be the true mean parameter 
* $X_1, ..., X_n$ our sample of size $n$
* $\bar{X}$ - the average value for the sample $\bar{X} = \cfrac{1}{n} \sum_{i=1}^n X_i$
* we want to estimate $\mu$ using $\bar{X}$ and a Confidence Interval around it


== [[Normal Distribution|Normal Model]] ==
With sufficiently large sample and no violations of the assumptions, we can use [[Normal Distribution]] to model the [[Sampling Distribution]] of mean
* note that it's better to use the $t$ statistics described below


=== Normal Approximation ===
Normal approximation is crucial for this - because we use [[Normal Distribution]] to find percentiles 

=== Assumptions ===
* sample observations are independent
* the distribution is not strongly skewed and there are few outliers 
* sample size is sufficiently large (e.g. $\geqslant 30$)
** the larger the sample, the more tolerant we can be to the skews (thanks to the [[Central Limit Theorem|C.L.T]])
* sampling distribution is symmetric, unimodal, no outliers - approximately normal


If these conditions are met, can use Normal Model to find the confidence intervals 


==== Example ====
We have this data set that contains data about the whole population
* http://habrastorage.org/files/046/7ff/4d0/0467ff4d079546afb8acf7e0b669cbd0.png


Suppose we take 10k samples 
* and for each sample we calculate the mean
* and then draw the histogram of this data - thus we'll get the sampling distribution
* http://habrastorage.org/files/8fd/562/12b/8fd56212b94641918e49649673a26113.png
* we see that it's normal, but can also try to draw the [[Normal Probability Plot]] to see that it's indeed the case
* http://habrastorage.org/files/8a1/8f9/d42/8a18f9d42fb74957acb26f859b51c289.png


{{ Hider |
   title=R code to reproduce the experiment |
   content=
&lt;pre&gt;
load(url('http://s3.amazonaws.com/assets.datacamp.com/course/dasi/ames.RData'))
population = ames$Gr.Liv.Area

oldpar = par(no.readonly=TRUE)

# fig=c(x1, x2, y1, y2)
par(fig=c(0, 1, 0, 1))
par(mar=c(6, 2, 2, 1))
h = hist(population, col='grey', probability=T, axes=F, xlab='', main='Histogram')
dens = density(population, adjust=2)
lines(dens, col=&quot;black&quot;, lwd=2)

axis(side=1, pos=c(-max(h$density)/4,0))
axis(side=2)

par(fig=c(0, 1, 0.16, 0.41), new=TRUE)
par(mar=c(0, 2, 0, 1))
boxplot(population, horizontal=TRUE, axes=F, col='grey')

par(oldpar)

set.seed(1237)
n = 50
samp.mean = replicate(10000, mean(sample(population, n)))

plot(x=NA, y=NA, xlim=c(1250, 1750), ylim=c(0, 0.006), axes=F,
     xlab='Estimate of mean', ylab='Frequency',
     main='Sampling Distribution of mean')

m = mean(samp.mean)
s = sd(samp.mean)

par(xpd=FALSE)

rect(xleft=m-3*s, xright=m+3*s, ybottom=-1, ytop=1,
     border=NA, col=adjustcolor('blue', 0.1))
rect(xleft=m-2*s, xright=m+2*s, ybottom=-1, ytop=1,
     border=NA, col=adjustcolor('blue', 0.1))
rect(xleft=m-s, xright=m+s, ybottom=-1, ytop=1,
     border=NA, col=adjustcolor('blue', 0.1))

hist(samp.mean, probability=T, add=T, breaks=50, col='white')
axis(side = 1)

dens = dnorm(1200:1800, mean=m, sd=s)
lines(1200:1800, dens, col=&quot;blue&quot;, lwd=2)


qqnorm(samp.mean, col=adjustcolor('orange', 0.1))
qqline(samp.mean)
&lt;/pre&gt;
}}

In this case all the assumptions hold - can use the Normal Approximation to calculate the confidence intervals


=== Model ===
* $E[\bar{X}] = \mu$, it's an unbiased estimate of mean
* [[Standard Error]]: $\text{var}(\bar{X}) = \cfrac{\sigma^2}{n}$
* by [[Central Limit Theorem|C.L.T.]] have $\bar{X} \approx N\left(\mu, \cfrac{\sigma^2}{n}\right)$
* therefore
** $\cfrac{\bar{X} - \mu}{\sqrt{\sigma^2 / n}} \approx N(0, 1)$


So the 95% CI with $z$-score is:
* $\left[ \bar{X} - 1.96 \sqrt{\sigma^2 / n}; \bar{X} + 1.96 \sqrt{\sigma^2 / n} \right]$



=== Estimating $\sigma$ ===
To compute a CI we need to know $\sigma^2$, but it's a parameter - we need to estimate it
* We know that
** $\text{Var}(X) = \cfrac{1}{n - 1} \sum (x_i - \bar{X})^2 $
** $s = \text{sd}(X) = \sqrt{\text{Var}(X)}$
* $\sigma^2$ is unknown. Can we substitute it by $s^2$? 
** $s^2$ is [[Biased Estimators|unbiased estimate]] of $\sigma^2$
** $E[s^2] = \sigma^2$ (this is the reason for $n - 1$ instead of $n$)
** so yes, we can, but it's better to use the $t$-distribution (described below) instead and use $s^2$ 





== Using $t$ Statistic ==
To use normal approximation we need a sufficiently large sample
* what if we don't have it? 
* use $t$-statistics that follows [[t Distribution|$t$-distribution]]
** note that with high degrees of freedom $t$-distribution very closely resembles $N(0,1)$


=== [[t Distribution|$t$-distribution]] ===
$t$-distribution
* We say that value follows [[t-distribution|$t$-distribution]] with $n - 1$ degrees of freedom
* This distribution is similar to normal, but not quite: it's little wider and allows for more uncertainty 


Use the $t$- distribution rather than the normal distribution when 
* the variance is not known and 
* has to be estimated from sample data. 


Shape of $t$ vs Normal:
* When the sample size is large, e.g. $\geqslant$ 100, the $t$ is very similar to $N(0,1)$
* on smaller sizes, $t$ is ''leptokurtic'' - it has relatively more scores in its tails than the normal distribution
** $\Rightarrow$ you have to extend farther from the mean to span a given proportion of the area. 
* for $N(0,1)$ 95% of data is within 1.96 $\sigma$ from the mean
* for $t$, if you a sample size is only 5, 95% of the area is within 2.78 std from the mean
* $\Rightarrow$ the SE of the mean would be multiplied by 2.78 rather than 1.96.


=== $t$-Statistic Confidence Intervals ===
Thus
* we replace $\sigma^2 = s^2$ and 
* use the $t$-distribution with $n-1$ degrees of freedom
** i.e. replace $z$-score with $z = t_{n - 1}$


95% CI becomes 
* $\left[\bar{X} - t \cdot \sqrt{s^2 / 2}; \bar{X} + t \cdot \sqrt{s^2 / 2}\right]$
* we we have $n = 400$ (therefore $df=399$), $t \approx 1.969$


=== R-code ===
In R:
&lt;pre&gt;
n = 60
xbar = mean(d)
v = var(d)
t = qt(0.025, df=n-1, lower.tail=F)
ME = t * sqrt(v / n)
xbar + c(-ME, ME)
&lt;/pre&gt;

or:
&lt;pre&gt;
t.test(d, conf.int=0.95)$confint
&lt;/pre&gt;

The last chuck actually uses [[t-test|$t$-test]] and returns its confidence interval


=== Examples ===
Example1: 
* The mean for 51 observations was 20
* The sample variance was 5
* Calculate the 99% CI for the mean

&lt;pre&gt;
xbar = 20
v = 5
t = qt(0.005, df=50, lower.tail=F)
ME = t * sqrt(v / 50)
xbar + c(-ME, ME)
// [19.16, 20.84]
&lt;/pre&gt;




== Links ==
Normal-distr based 
* http://www.stat.wmich.edu/s160/book/node46.html
* http://onlinestatbook.com/2/estimation/mean.html
* http://stattrek.com/estimation/confidence-interval-mean.aspx

t-based CI for mean 
* http://www.stat.wmich.edu/s216/book/node79.html

== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[OpenIntro Statistics (book)]]

[[Category:Statistics]]
[[Category:R]]</text>
      <sha1>6betsww7kvu79gvgr55i24nw7ma7k2t</sha1>
    </revision>
  </page>
  <page>
    <title>Normal Distribution</title>
    <ns>0</ns>
    <id>497</id>
    <revision>
      <id>500</id>
      <timestamp>2015-04-19T09:28:50Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3786">== Normal Distribution ==
This is a continuous Symmetric, unimodal bell-shaped [[Distribution]] 
* it has two parameters: mean $\mu$ and std $\sigma$, denoted as $N(\mu, \sigma)$
* Standard Normal Distribution is $N(\mu = 0, \sigma = 1)$



=== [[Probability Density Function]] ===
&lt;pre&gt;
x = seq(from=-3, to=3, length=15)
normalDensity = dnorm(x, mean=0, sd=1)
r = round(normalDensity, 2)
bp = barplot(r)
xspline(x=bp, y=r, lwd=2, shape=1, border=&quot;blue&quot;)
text(x=bp, y=r+0.03, labels=as.character(r), xpd=TRUE, cex=0.7)
&lt;/pre&gt;
Code [http://stackoverflow.com/a/14264451/861423] [https://stat.ethz.ch/pipermail/r-help/2003-November/041967.html]

http://habrastorage.org/files/226/4f4/847/2264f48471de4f249b0db00035fd3261.png




== Z-score ==
=== 68-95-99.7 rule ===
Also referred as the &quot;rule of 3 sigmas&quot; 
* most of the data lay within 3 $\sigma$s from $\mu$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/b/openintrostat/normal-3-sigmas.png


=== $Z$-score ===
$Z$-score of an observation is the number of standard deviations for the mean
* 1 sdt above - $z = +1$
* 1.5 std below - $z = -1.5$
* $z = \cfrac{x - \mu}{\sigma}$


we can use $z$-scores to identify unusual observations 
* $x_1$ is more unusual than $x_2$ if $| z_1 | &gt; | z_2 |$


=== $Z$-standardization ===
* so $Z$-scores are used to standardize the observations 
* in effect, it normalizes any normal distribution $N(\mu, \sigma$) to $N(0, 1)$
* see [[Normalization]]


=== Percentile === 
Example:
* Scores of SAT takers are distributed normally
* parameters: $\mu = 1500, \sigma = 300$
* Ann earned 1800 on SAT,
* so Ann's $z = 1$


Ann's ''percentile'' - percent of people who earned lower SAT score 
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/b/openintrostat/normal-ex-percentile.png
* shaded - individuals who scored below Ann
* so knowing the $z$-score we can calculate the percentile 
** Ann is the 84th percentile of SAT takers 
* and vise-versa: we can also find $z$-score for given percentile 


Example 2
* Shannon is a randomly selected SAT-taker.
* What's the probability that she'll score 1630 or more? 
* Can find the $z$-score for that - it's $z = \cfrac{x - \mu}{\sigma} = 0.43$
* so we calculate the percentiles
** probability of getting below $z=0.43$ is 2/3
** so probability of getting above $z=0.43$ is 1 - 2/3 = 1/3


Always draw the bell shape first and then shade the area of interest 


=== $Z$-scores for [[Inferential Statistics]] ===
it may be useful for
* calculating [[Confidence Intervals]], e.g. [[Confidence Intervals for Means]] or [[Binomial Proportion Confidence Intervals]]
* doing [[Hypothesis Testing]], e.g. 


== Normal Approximation ==
Many processes can be approximated well by normal distribution 
* e.g. SAT, height of USA males, etc

But need to check if it's reasonable to use the normal approximation 

2 visual methods for checking the assumption of normality 
# simple histogram + best fit of normal shape
#* http://habrastorage.org/files/dd4/cda/bcd/dd4cdabcdf864de594a2d46d760ee067.png
# [[Q-Q Plot]] (or Normal Probability Plot)
#* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/b/openintrostat/normal-prob-plot-ex.png


Code to produce the first figure:

&lt;pre&gt;
load(url(&quot;http://www.openintro.org/stat/data/bdims.RData&quot;))
fdims = subset(bdims, bdims$sex == 0)
hist(fdims$hgt, probability=TRUE, ylim=c(0, 0.07))
x = 140:190
y = dnorm(x=x, mean=mean(fdims$hgt), sd=sd(fdims$hgt))
lines(x=x, y=y, col=&quot;blue&quot;)
&lt;/pre&gt;


Code to produce  [[Q-Q Plot]]s

&lt;pre&gt;
qqnorm(fdims$hgt, col=&quot;orange&quot;, pch=19)
qqline(fdims$hgt, lwd=2)
&lt;/pre&gt;


== Sources ==
* [[OpenIntro Statistics (book)]]
* [[Statistics: Making Sense of Data (coursera)]]

[[Category:Probability]]
[[Category:Distributions]]
[[Category:R]]</text>
      <sha1>ncffr7yq9h78b1yd4we47z6agrjcksg</sha1>
    </revision>
  </page>
  <page>
    <title>Binomial Proportion Tests</title>
    <ns>0</ns>
    <id>498</id>
    <revision>
      <id>501</id>
      <timestamp>2015-04-19T08:38:27Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10413">== Binomial Proportion Tests ==
This is a family of [[Hypothesis Testing|statistical tests]]  
* they are typically used for assessing the true proportions of the populations
* the [[Sampling Distribution]] underneath is [[Binomial Distribution]], but the tests  use $Z$-statistics and rely on [[Normal Distribution]] and [[Binomial Distribution#Normal Approximation|Normal Approximation]]


=== Exact Binomial Model ===
Not always we need to use the Normal Approximation
* sometimes we can model the null distribution directly with Binomial Model
* see [[Exact Binomial Proportion Tests]]


=== Types Of Tests ===
* One-Sample Binomial Test - for testing if the proportion is equal to something
* Two-Sample Binomial Test - for testing the differences in proportions


== One-Sample Binomial Test ==
Suppose that we have a sample where outcomes are binary - e.g. only &quot;success&quot; and &quot;failure&quot;
* given the sample, we want to estimate what's the true proportion - and use [[Binomial Proportion Confidence Intervals]] for that
* but we can also set up a statistical test to check if the proportion is equal to some value 


So, given
* $n$ - sample size, $n_1$ - proportion of successful observations, 
* [[Point Estimate]] $\hat{p} = \cfrac{n_1}{n}$
* [[Standard Error]] $\text{SE}_{\hat{p}} = \sqrt{ \cfrac{p \cdot (1 - p)}{n} } $
** can use $p = \hat{p}$ instead of $p$ or $p = 0.5$ (it maximizes the margin of error)


Perform the test:
* $H_0: p = p_0$
* $H_A: p \ne p_0$ or $H_A: p &lt; p_0$ or $H_A: p &gt; p_0$
* calculate the $Z$ statistics and the $p$ value



=== Conditions ===
* observations are independent
** can satisfy when random-sample less than 10% of the population
* [[Sampling Distribution]] of $\hat{p}$ should be nearly Normal
* we should see at least 10 success and 10 failures in our samples (&quot;success-failure condition&quot;)
** enough to check that $n \cdot p_0 \geqslant 10$ and $n \cdot (1 - p_0) \geqslant 10$



=== Confidence Intervals vs Proportion Tests ===
There's a clear parallel with [[Binomial Proportion Confidence Intervals]]
* if a CI includes the null value, then we fail to reject $H_0$
* otherwise we reject $H_0$ in favor of $H_A$ 



=== Example 1 ===
Newspaper collects data about support of some politician 
* there are $n = 500$ responses in the sample
* the support is estimates as $\hat{p} = 0.52$
* want to check if the true proportion is $p_0 = 0.5$ 


Verify the conditions:
* sample is random with less than 10% of the population
* $n \cdot p_0 = n \cdot (1 - p_0) = 500 \cdot 0.5 = 250 \geqslant 10$ 
* can apply the normal approximation

Test:
* $H_0: p_0 = 0.5, H_A: p_0 &gt; 0.5$ - one-sided test
* $\text{SE}_{\hat{p}} = \sqrt{ \cfrac{0.5 \cdot (1 - 0.5)}{500} } \approx 0.022$
* $Z = \cfrac{\hat{p} - p_0}{ \text{SE}_{\hat{p}} }  = \cfrac{0.52 - 0.5}{0.022} \approx 0.89$
* http://habrastorage.org/files/56e/b12/500/56eb125008354212b8ffdfcf4e84e815.png
* the $p$ value is $p = 0.1867$
* so can't reject $H_0$



=== Example 2 ===
* $n = 1046$
* 42% support the mayor 
* $p = \text{true support}$ (unknown)
* $\hat{p} = 0.42$ (estimated)

Question we want to answer:
* Is the true support less than 50% of the population? 


Our test
* $H_0: p = 0.5, H_A: p &lt; 0.5$
* Can we reject $H_0$? 

Under $H_0$, $p = 0.5$, so
* We know that $\cfrac{\hat{p} - p}{\sqrt{p (1- p) / n }} \approx N(0, 1)$
* and it should be  $\cfrac{\hat{p} - p}{\sqrt{0.5 \cdot 0.5 / 1046}} \approx N(0, 1)$


Observed (assuming $H_0$)
* $\hat{p} - p = 0.42 - 0.5 = -0.08$


Now we calculate the $p$-value:
* $P\left(\hat{p} - p \leqslant -0.08\right)$ = 
* $P\left(\cfrac{\hat{p} - p}{\sqrt{0.5 \cdot 0.5 / 1046}} \leqslant \cfrac{- 0.08}{\sqrt{0.5 \cdot 0.5 / 1046}}\right) \approx $
* $P(N(0, 1) \leqslant -5.17) \approx 1 / 9000000$


Small!
* The probability that (by chance we may get the sample with 0.42 support when the true level of support is 0.5) is 1 / 9000000
* So we reject the $H_0$


=== Example 3: Flipping a Beer Cap ===
* Suppose we flip a cap 1000 times, and the obtained proportion is $\hat{p} = 0.576$
* want to find out the real proportion. Is it $p = P(\text{Red}) = 0.5$?

The test:
* $H_0: p = 0.5, H_A: p \neq 0.5$ (2-sided)

Assuming $H_0$, the observed statistic is 
* $Z = \hat{p} - p = 0.567 - 0.5 = 0.076$


$p$-value:
* $P(|\hat{p} - p| \geqslant 0.076) =$
* $P\left(\left| \cfrac{\hat{p} - p}{\sqrt{0.5 \cdot 0.5 / 1000}} \right| \geqslant \left| \cfrac{0.076}{\sqrt{0.5 \cdot 0.5 /  1000}} \right|\right) \approx$
* $P\left(|N(0, 1)| \geqslant 4.81\right) = $
* $2 \cdot P(N(0, 1) \leqslant -4.81) \approx 1 / 661000$


Too small - so we reject the $H_0$.


=== R-code (proportions) ===
Our test statistics is $z = \cfrac{\hat{p} - p}{\sqrt{p (1 - p) / n}}$
&lt;pre&gt;
test.stat = (0.42 - 0.5) / sqrt(0.5 * 0.5 / 1046) // -5.17
pnorm(test.stat, mean=0, sd=1, lower.tail=T) // 1.17 * 10E-7
&lt;/pre&gt;


or, using '''binom.test''' 
&lt;pre&gt;
x = round(0.42 * 1046, 0) // 439 successes
binom.test(x, 1046, p=0.5 // our H_0
           alternative=&quot;less&quot;)
// or alternative=&quot;two.sided&quot;
&lt;/pre&gt;



== Two-Sample Binomial Proportion Test ==
Suppose we have two samples $a$ and $b$ 
* sample size: $n_a$ and $n_b$
* we calculate proportions from these samples $\hat{p}_a$ and $\hat{p}_a$
* want to see if the two samples have the same proportions or not

Test:
* $H_0: p_a = p_b$ or $H_0: p_a - p_a = 0$ - two samples have the same proportions
* $H_A: p_a \ne p_b$ or $H_A: p_b - p_b \ne 0$ - two samples have different proportions
** could also be $H_A: p_b - p_b &gt; 0$ or $H_A: p_b - p_b &lt; 0$


Typical example
* calculate support of some politician in one year and later in another
* has the support grown over time? 
* has the support decreased? 
* has the support changed?


$\hat{p}_a - \hat{p}_b$ is a [[Point Estimate]] of $p_a - p_b$
* it's an unbiased estimate 
* if [[Sampling Distribution]]s for both $\hat{p}_a$ and $\hat{p}_b$ are nearly normal, then the difference also must be nearly normal 
* $\text{Var}(\hat{p}_a - \hat{p}_a) = \text{Var}(\hat{p}_a) + (-1)^2 \cdot \text{Var}(\hat{p}_a) = \cfrac{p_a (1 - p_a)}{n_a} + \cfrac{p_a (1 - p_a)}{n_a}$



Test statistics calculation:
* null value is typically 0 (this is the value of $p_a - p_b$ under $H_0$)
* $Z$-score: $Z = \cfrac{\text{p.e.} - \text{null value}}{\text{SE}_\text{p.e.}} = \cfrac{ \hat{p}_a - \hat{p}_b }{ \text{SE}_{\hat{p}_a - \hat{p}_b} } $ 
** $\text{p.e.}$ is our point estimate and $\text{SE}_{\hat{p}_a - \hat{p}_b}$ is the [[Standard Error]]


=== Pooled Proportion Estimate ===
Under $H_0$ we assume that $p_a = p_b$ so we approximate '''both''' $p_a$ and $p_b$ by 
* $\hat{p} = \cfrac{n_a \hat{p}_a + n_b \hat{p}_b}{n_a + n_b}$
* This is called ''pooled estimate''
* $\text{SE} = \sqrt{\hat{p} (1 - \hat{p})(1/n_a + 1/n_b)}$
* Then $\cfrac{(\hat{p}_a - \hat{p}_b) - (p_a - p_b)}{\text{SE}} = \cfrac{\hat{p}_a - \hat{p}_b}{\text{SE}} \approx N(0, 1)$

And now we can compute $p$-values



=== Example 1 ===
Want to test if the drug reduces the death rate in heart attack patients 
* we set up a [[Statistical Experiment]]
* there are 1475 patients, whom we divided into two groups:
** treatment group who receive the drug
** control group who receive placebo

We record the following:
* $\hat{p}_c = 60/742$ - proportion of patients who died in the control group
* $\hat{p}_t = 41/733$ - proportion of patients who died in the treatment group

Test:
* $H_0: p_c = p_t$ or $H_0: p_c - p_t = 0$ - i.e. the drug doesn't work
* $H_A: p_c &gt; p_t$ or $H_A: p_c - p_t &gt; 0$ - i.e. the drug works



Perform the test:
* $\hat{p}_c - \hat{p}_t = 60/742 - 41/733 = 0.025$
* $\text{SE} = 0.013$
* $Z$-score: $Z = \cfrac{0.025}{0.013} = 1.92$
* for this $Z$ score we have $p = 0.027$ 
** http://habrastorage.org/files/0cb/b90/bc0/0cbb90bc05dc43b68ca0ad0a2c7c9ea7.png
** (figure source: [[OpenIntro Statistics (book)|OpenIntro]], figure 4.22)
* with $\alpha = 0.05$, $p &lt; \alpha$, so 
** we reject $H_0$ in favor of $H_A$ and
** conclude that the drug is effective


=== Example 2 ===
* poll #1: $n_1 = 1050$, $\hat{p}_1 = 0.57$
* poll #2: $n_2 = 1046$, $\hat{p}_2 = 0.42$


Was there a drop in the support? 
* Test: $H_0: p_1 = p_2, H_A: p_1 \neq p_2 $

* $\hat{p}_1 - \hat{p}_2 = 0.57 - 0.42 = 0.15$
* $\hat{p} = \cfrac{n_1 \hat{p}_1 + n_2 \hat{p}_2}{n_1 + n_2} \approx 0.495$


then $p$-value under $H_0$ is 
* $P( | \hat{p}_1 - \hat{p}_2 | \geqslant 0.15 ) = $
* $P( | \cfrac{  (\hat{p}_1 - \hat{p}_2) - (p_1 - p_2)  }{\sqrt{\hat{p} (1 - \hat{p})(1/n_1 + 1/n_2)}} | \geqslant \cfrac{ 0.15 }{\sqrt{\hat{p} (1 - \hat{p})(1/n_1 + 1/n_2)}} ) \approx $
* $P( | N(0, 1) | \geqslant \cfrac{ 0.15 }{\sqrt{0.495 (1 - 0.495)(1/1050 + 1/1046)}} ) \approx $
* $P( | N(0, 1) | \geqslant 6.87 ) \approx 6 \cdot 10^{-12} $

Very low! So we reject the $H_0$ and conclude that the support dropped (i.e. $p_1 \neq p_2$).


=== Example 3 ===
Obama support poll:
* $n_1 = 1010, \hat{p}_1 = 0.52$ (taken 12.08)
* $n_2 = 563, \hat{p}_2 = 0.48$ (taken 12.10)
* Seems that Obama's support declined over 2 years


Is that true?

We want to test if the support dropped: 
* $H_0: p_1 = p_2, H_A: p_1 \neq p_2 $
* $\hat{p}_1 - \hat{p}_2 = 0.52 - 0.48 = 0.04$

Pooled estimate:
* $\hat{p} = \cfrac{n_1 \hat{p}_1 + n_2 \hat{p}_2}{n_1 + n_2} \approx 0.506$

$p$-value (under $H_0$):
* $P(| \hat{p}_1 - \hat{p}_2 | \geqslant 0.04 ) = $
* $P \left( \left| \cfrac{  (\hat{p}_1 - \hat{p}_2) - (p_1 - p_2)  }{\sqrt{\hat{p} (1 - \hat{p})(1/n_1 + 1/n_2)}} \right| \geqslant \cfrac{ 0.04 }{\sqrt{\hat{p} (1 - \hat{p})(1/n_1 + 1/n_2)}} \right) \approx $
* $P \left( | N(0, 1) | \geqslant \cfrac{ 0.04 }{\sqrt{0.506 (1 - 0.506)(1/1010 + 1/563)}} \right) \approx $
* $P( | N(0, 1) | \geqslant 1.52 ) \approx 0.129 $

Not so unlikely, so we cannot reject $H_0$. Perhaps no drop.


=== R ===
&lt;pre&gt;
n1 = 1050
n2 = 1046

phat1 = 0.57
phat2 = 0.42 

# number of successes
x1 = round(n1 * phat1, 0)
x1 = round(n2 * phat2, 0)

prop.test(c(x1, x2), c(n1, n2), alternative=&quot;two.sided&quot;, correct=F)
&lt;/pre&gt;



== Links ==
* http://ocw.jhsph.edu/courses/methodsinbiostatisticsii/PDFs/lecture18.pdf
* http://www.itl.nist.gov/div898/software/dataplot/refman1/auxillar/binotest.htm

== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[OpenIntro Statistics (book)]]
* http://www.cliffsnotes.com/math/statistics/univariate-inferential-tests/test-for-comparing-two-proportions


[[Category:Statistics]]
[[Category:Statistical Tests]]
[[Category:R]]</text>
      <sha1>hjo6zxbmwssuf45yjf9256xvhv4qxtt</sha1>
    </revision>
  </page>
  <page>
    <title>Chi-square Test of Independence</title>
    <ns>0</ns>
    <id>499</id>
    <redirect title="Chi-Squared Test of Independence" />
    <revision>
      <id>502</id>
      <timestamp>2014-08-09T19:37:14Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="68">#перенаправление [[Chi-Squared Test of Independence]]</text>
      <sha1>4ftcujmlc2ozfi0np74bfwj5t50k4lg</sha1>
    </revision>
    <revision>
      <id>753</id>
      <parentid>502</parentid>
      <timestamp>2016-11-03T16:56:02Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Redirected page to [[Chi-Squared Test of Independence]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="46">#REDIRECT [[Chi-Squared Test of Independence]]</text>
      <sha1>bgzdn8615kfjh3m70c54irbw5kklz06</sha1>
    </revision>
  </page>
  <page>
    <title>Chi-Squared Tests</title>
    <ns>0</ns>
    <id>500</id>
    <revision>
      <id>503</id>
      <timestamp>2014-08-09T19:38:19Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="759">== Chi-Squared Tests ==
This is a family of [[Hypothesis Testing|Statistical Tests]] that use [[Chi-Squared Distribution]] to calculate values of the statistics 


=== One-Way and Two-Way Tables ===
There are two type of tests 


One-Way Table Tests 
* counts for each outcome in a single variable, it's a [[Frequency Table]]
* it's for checking if the observed data comes from some distribution
* test: [[Chi-Squared Goodness of Fit Test]]


Two-Way Table Tests
* counts for combination of outcomes from two variables, it's a [[Contingency Table]]
* for checking if two categorical variables are independent
* test: [[Chi-Squared Test of Independence]]


== Sources ==
* [[OpenIntro Statistics (book)]]

[[Category:Statistics]]
[[Category:Statistical Tests]]</text>
      <sha1>c1h2epwto83js8gura2e6o43p84u3xv</sha1>
    </revision>
  </page>
  <page>
    <title>Chi-Squared Goodness of Fit Test</title>
    <ns>0</ns>
    <id>501</id>
    <revision>
      <id>504</id>
      <timestamp>2014-08-09T19:57:39Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7515">== Chi-Squared Goodness of Fit Test ==
This is one of [[Chi-Squared Tests|$\chi^2$ tests]]
* one-way table tests - for testing [[Frequency Tables]], this one
* two-way table tests - for testing [[Contingency Tables]], [[Chi-Squared Test of Independence]]


=== $\chi^2$ One-Way Table Test ===
This is a method for assessing a null model when the data is binned 

Used when:
* given a sample of cases that can be classified into several groups, determine if the sample is representative of the general population 
* evaluate is the data resemble some distribution, e.g. normal or geometric (&quot;Goodness Of Fit&quot;)


=== Idea ===
Goodness of Fit test:
* suppose we have a variable with $n$ modalities 
** it can be a categorical variable with $n$ groups
** or numerical data binned into $n$ bins
** or even discrete numerical data with not many distinct values
* suppose that we have some observed values $O_i$, for each bin $i$ 
* also for each bin $i$, values $E_i$ represent values expected under $H_0$
* are the observed values statistically different from expected? 


=== Test ===
* $H_0$: the observed values do not differ from given distribution
* $H_A$: the observed values are statistically different from expected


=== Test Statistics $X^2$ ===
* for each group $i$ we calculate the squared difference between observed and expected
* this difference is normalized with standard error for each group

Values:
* $O_i$ - observed count 
* $E_i$ - count expected under $H_0$


Test statistics
* we can think of it as calculating $n$ $Z$ statistics (standardized differences) and sum them up:
* $Z_i = \cfrac{O_i - E_i}{\text{SE}_i}$, each $Z_i$ follows the [[Normal Distribution|Normal Model]]
** note that $\text{SE}_i$ is a sampling distribution under $H_0$, i.e. 
** $\text{SE}_i = \sqrt{ E_i }$
* Since we want to minimize the squared error, we calculate 
** $X^2 = \sum_{i=1}^{k} Z^2_i = \sum_{i=1}^{k} \cfrac{(O_i - E_i)^2}{ E_i }$
* it's called Pearson's cumulative test stat
* it follows $\chi^2$ distribution with $k - 1$ degrees of freedom, where $k$ is the number of categories 


=== $p$-values ===
* typically need only upper-tail values 
* because the larger values correspond to stronger evidence against $H_0$

http://habrastorage.org/files/3d7/3c4/567/3d73c4567229481585119a0829fd4165.png


=== Conditions ===
* The observations must be independent 
* Sample size should be big enough, so we should have at least 5 at each cell of the expected count table
* $\text{df} \geqslant 2$



== Examples ==
=== Example: County Jurors ===
* suppose we have a set of 275 jurors from a small county
* they are categorized with their racial group 
* are they representing the population of eligible jurors or there's some racial bias?
* (source: [[OpenIntro Statistics (book)|OpenIntro]], table 6.5)


{| class=&quot;wikitable&quot;
! Race || White || Black || Hispanic || Other || Total
|-
! County 
| 205 || 26 || 25 || 19 
! 275
|-
! Ratio 
| 0.75 || 0.09 || 0.09 || 0.07
! 1.00
|-
! Population Ratio 
| 0.72 || 0.07 || 0.12 || 0.09 |
! 1.00  
|}


* It doesn't look like it's precisely representative 
* might it be solely due to chance or there's some bias? 


Expected values
* What we do is to create another table, where we add expected 
* Expected numbers represent the values we expect to see if the sample set was entirely representative


{| class=&quot;wikitable&quot;
! Race || White || Black || Hispanic || Other || Total
|-
! Observed 
| 205 || 26 || 25 || 19 
! 275
|-
! Expected
| 198 || 19.25 || 33 || 24.75
! 275
|}


And now we calculate the squared difference between observed and expected values for each category:


Test:
* $H_0$: the jurors are random sample, there is no racial bias and the observed counts reflect natural sampling variability
* $H_A$: there's racial bias in the selection 


Calculation:
* $X^2 = \cfrac{(205 - 198)^2}{198} +  \cfrac{(26 - 19.25)^2}{19.25} +  \cfrac{(25 - 33)^2}{33} +  \cfrac{(19 - 24.75)^2}{24.75} \approx 5.8$ 
* http://habrastorage.org/files/be8/8a1/b89/be88a1b895de4380963547530e9c6899.png
* $p$-values is quite big: 0.11 - so we can't reject $H_0$


R code 
Manual:
&lt;pre&gt;
obs = c(205, 26, 25, 19)
exp = c(198, 19.25, 33, 24.75)

x2 = sum( (obs-exp)^2 / exp )

x = seq(0, 10, 0.01)
y = dchisq(x, df=length(obs) - 1)
plot(x, y, type='l', bty='n', ylab='probability', xlab='x value')

x.min = min(which(x &gt;= x2))
x.max = length(x)
polygon(x=x[c(x.min, x.min:x.max, x.max)],
        y=c(0, y[x.min:x.max], 0), 
        col='orange')

pchisq(x2, df=length(obs) - 1, lower.tail=F)
&lt;/pre&gt;



=== Example: Trading === 
* Suppose that we have some data from some stock exchange 
* we want to test if stock activity on one day is independent from previous day
* the data is taken [http://research.stlouisfed.org/fred2/series/SP500/downloaddata] for 2004-08-04	 to 2014-07-01
* example motivated by an example from [[OpenIntro Statistics (book)|OpenIntro]] 


Idea
* If the change in the price was positive, we say that that stock was up ($U$), otherwise we say it was down $D$)
* if the days are really independent, then the number of days before seeing $U$ should follow [[Geometric Distribution]]. 
* How many days should we wait until seeing $U$?


{| class=&quot;wikitable&quot;
! Days || 0 || 1 || 2 || 3 || 4 || 5 || 6 || 7+
|-
! Expected 
| 540.5 || 270.25 || 135.13 || 67.56 || 33.78 || 16.89 || 8.45 || 7.39
|-
! Actual |
| 450.0 || 298.00 || 150.00 || 85.00 || 53.00 || 22.00 || 13.00 || 10.00
|}


http://habrastorage.org/files/6a9/7b6/ace/6a97b6acefca4480a96660a7dd0ac6f4.png


Test:
* $H_0$: stock marked days are independent from each other
** i.e. we assume that the number of days before seeing $U$ follows geometric distribution
* $H_A$: not independent 


Calculations:
* calculate $X^2 = \sum_{i=0}^{7} \cfrac{(O_i - E_i)^2}{E_i} \approx 43.04$
* $k = 8$, $\text{df} = 8 - 1 = 7$,
* calculate the $p$ value: $p \approx 10^{-6}$
* so we reject $H_0$ and conclude that the market days are not independent from each other


http://habrastorage.org/files/bb9/c3c/ba9/bb9c3cba91844b3facdf9e0d37e35bc2.png


{{ Hider |
   title=R code |
   content=
&lt;pre&gt;
sp500 = read.csv('http://goo.gl/lv268V')
values = as.numeric( as.character(sp500$VALUE) )
change = as.factor(values &gt; 0)
levels(change) = c('D', 'U')

change = change[complete.cases(change)]

y = rep(0, length(change))
y[change == 'U'] = 1
y = c(0, y, 0)
wz = which(y == 0)
streak = diff(wz) - 1

# chi^2 test
act = table(streak)

n = length(streak)
k = length(act)
exp = n / (2 ^ (1:k))

barplot(rbind(exp, act), beside=T, col=c('skyblue', 'orange'))
legend('topright', c('expected', 'actual'), bty='n', pch=15, 
       col=c('skyblue', 'orange'))

x2 = sum( (act - exp)^2 / exp )

pchisq(x2, df=k - 1, lower.tail=F)
c(x2=x2, theoretic=qchisq(0.95, df=k - 1))

# let's merge the data for 7,8 and 9 days 
streak[streak &gt;= 7] = 7
streaks = as.factor(streak)
levels(streaks)[8] = '7+'

act = table(streaks)
exp.n = c(exp[1:7], sum(exp[8:10]))
barplot(rbind(exp.n, act), beside=T, col=c('skyblue', 'orange'))
legend('topright', c('expected', 'actual'), bty='n', pch=15, 
       col=c('skyblue', 'orange'))

k = length(act)
x2 = sum( (act - exp.n)^2 / exp.n )

pchisq(x2, df=k - 1, lower.tail=F)
c(x2=x2, theoretic=qchisq(0.95, df=k - 1))
&lt;/pre&gt;
}}



== Links ==
* http://en.wikipedia.org/wiki/Goodness_of_fit#Pearson.27s_chi-squared_test

== Sources ==
* [[OpenIntro Statistics (book)]]
* https://onlinecourses.science.psu.edu/stat504/node/61


[[Category:Statistics]]
[[Category:Statistical Tests]]
[[Category:R]]</text>
      <sha1>5benbvzs9poxtvw5zrxwiru0ntcl4zd</sha1>
    </revision>
  </page>
  <page>
    <title>Statistics</title>
    <ns>0</ns>
    <id>502</id>
    <revision>
      <id>505</id>
      <timestamp>2014-08-09T20:31:54Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1142">== Statistics ==
''Statistics'' - the science of 
* collecting, organizing, summarizing, analyzing data
* drawing conclusions from it


Goal: use imperfect information to infer facts, make predictions, and make decisions.

''A statistic'' a number or value measured in context


=== Statistical Investigation ===
[[Data Analysis]]: Process of statistical investigation: 
# pose a question
# [[Data Collection|collect relevant data]]
# [[Descriptive Statistics|analyze]]
# [[Inferential Statistics|form a conclusion]] (how?) 

Questions 2-4 - answered by Statistics 


=== Types ===
There are two types of statistics:
* [[Descriptive Statistics]] - summarizing data with numbers or plots 
* [[Inferential Statistics]] - making conclusions or decisions based on data 



== Good Online Resources ==
Free online books and online resources on statistics
* [[OpenIntro Statistics (book)]]
* http://en.wikibooks.org/wiki/Statistics
* http://onlinestatbook.com/2/index.html
* http://en.wikiversity.org/wiki/Topic:Statistics



== Sources ==
* [[OpenIntro Statistics (book)]]
* [[Statistics: Making Sense of Data (coursera)]]

[[Category:Statistics]]</text>
      <sha1>0fh1fegbcbmzs75bvetkvmewouvf0di</sha1>
    </revision>
  </page>
  <page>
    <title>Pairwise t-test</title>
    <ns>0</ns>
    <id>503</id>
    <revision>
      <id>506</id>
      <timestamp>2014-08-09T20:33:41Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="37">#REDIRECT [[t-tests#Pairwise t-test]]</text>
      <sha1>bc7y69cntga9j7vxqw9pr0yua48ltr6</sha1>
    </revision>
    <revision>
      <id>716</id>
      <parentid>506</parentid>
      <timestamp>2015-11-23T15:58:34Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="786">{{stub}}

== Pairwise t-test ==
* we have $n$ groups, $n &gt; 2$
* we conduct a series of [[Two-Sample t-test]]s to find out which groups are different 
* e.g. in post-[[ANOVA]] analysis


=== Controlling [[Family-Wise Error Rate]] ===
It's important to modify $\alpha$ to avoid [[Type I Errors]]
* when we run many tests, it's inevitable that we make them just by chance

E.g. use [[Bonferroni Correction]]
* use modified confidence level $\alpha^* = \alpha \cdot \cfrac{1}{K}$
* where for $k$ groups $K= \cfrac{k \cdot (k - 1)}{2}$ 


== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[OpenIntro Statistics (book)]]
* http://projectile.sv.cmu.edu/research/public/talks/t-test.htm

[[Category:T-Test]]
[[Category:Statistics]]
[[Category:Statistical Tests]]
[[Category:R]]</text>
      <sha1>hucdu2k5yf70rhu3heyr2wq1sc8dkvh</sha1>
    </revision>
  </page>
  <page>
    <title>T-tests</title>
    <ns>0</ns>
    <id>504</id>
    <revision>
      <id>507</id>
      <timestamp>2014-08-09T20:41:11Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9406">== $t$ Tests ==
$t$-tests is a family of [[Hypothesis Testing|Statistical tests]] that use $t$-statistics (those values come from the [[t Distribution|$t$-distribution]]) to calculate $p$-values


The following tests are $t$-tests:
* one-sample $t$-test - for comparing the mean of a sample against some given mean
* two-sample $t$-test - for comparing the means of two samples
* paired $t$-test - for Matching Pairs setup
* pairwise $t$-test - for comparing the means of more than two samples


== When To Use ==
=== Assumptions ===
Assumptions for $t$ tests are similar to the assumptions of the [[z-tests|$z$-tests]]
* Observations are independent (if less than 10% of population is sampled, then we can make sure it's satisfied)
* Sample size is sufficiently large so [[Central Limit Theorem|C.L.T.]] holds
* Moderate skew, few outliers (not too extreme)


=== vs [[z-tests|$z$-tests]] ===
Sample Size
* the sample size can be smaller than for $z$-tests 
* so it can be smaller than 30 - after 30 we can safely use $z$-tests with almost the same outcomes 

$t$-distribution:
* the tails are thicker than for $N(0,1)$ and observations are more likely to fall within 2$\sigma$ from the mean
* this is exactly the correction we need to account for poorly estimated [[Standard Error]] when the sample size is not big



== One-Sample t-test ==
This is a test for one variable
* it's used mainly to calculate a [[Confidence Intervals|Confidence Interval]] for the true mean $\mu$ 
* the null value for $H_0$ might come from other research or from your knowledge 

Parameters:
* $\text{df} = n - 1$ with $n$ being the sample size 


=== Example 1 ===
* Sample: $n = 60, \bar{X} = 7.177, s = 2.948$
* True mean $\mu$ is unknown 

Let's run a test:
* $H_0: \mu = 0, H_A: \mu &gt; 0$ (this is one-sided test)
* Under $H_0$, we know that $\cfrac{\bar{X} - \mu}{\sqrt{s^2 / n}} \approx t_{n - 1}$
* Observed: $\bar{X} - \mu = 7.177 - 0 = 7.177$
* How plausible is the observed value under $H_0$? 


The probability of observing this value is 
* $P(\bar{X} - \mu \geqslant 7.177) = $
** $P\left(\cfrac{\bar{X} - \mu}{\sqrt{s^2 / n}} \geqslant \cfrac{7.177}{\sqrt{s^2 / n}}\right) \approx$
** $P\left(t_{59} \geqslant \cfrac{7.177}{\sqrt{2.948^2 / 60}}\right) \approx$
** $P(t_{59} \geqslant 18.86) \approx 1 / 10^{26}$

Extremely small! So we reject $H_0$ and conclude that $\mu &gt; 0$



=== Example 2 ===
* Sample $n = 400, \bar{X} = -14.15, s = 14.13$
* Test: $H_0: \mu = 0$  vs $H_A: \mu \neq 0$ (this is a 2-sided)

We know that
* $\cfrac{\bar{X} - \mu}{\sqrt{s^2 / n}} \approx t_{n - 1} = t_{399}$


$p$-value:
* $P( | \bar{X} - \mu | \geqslant | -14.15 - 0 |) = $
** $P\left( \left| \cfrac{\bar{X} - \mu}{\sqrt{s^2 / n}} \right| \geqslant \cfrac{14.15}{\sqrt{14.13^2 / 400}}\right) \approx $
** $P( | t_{399} | \geqslant 20.03 ) =$
** $2 \cdot P( t_{399} \leqslant -20.03) \approx$
** $1 / 3.5 \cdot 10^{64}$


Extremely small! Reject the $H_0$ and conclude that $\mu \neq 0$


=== R code ===
Our test statistic is $T = \cfrac{\bar{X} - \mu}{\sqrt{s^2 / n}}$.

&lt;pre&gt;
xbar = mean(ch)
s2 = var(ch)
n = length(ch)
mu = 0

t = (xbar - mu) / sqrt(s2 / n) // 18.856
pt(t, df=n-1, lower.tail=F) // 5.84E-24
// so we reject
&lt;/pre&gt;




== Paired t-test ==
=== Paired Data ===
Two set of observations are ''paired'' if each observation in one set has exactly one corresponding observation is another set. 


Examples:
* pre- and post-test scores on the same person
* measures in pairs at the same time or place 
* outcome with or without a treatment - on same subject (cross-over study)


=== [[R]] Function ===
&lt;pre&gt;
library(openintro)
data(textbooks)
t.test(textbooks$diff, mu=x.bar.nul, alternative='two.sided')
&lt;/pre&gt;

or 

&lt;pre&gt;
t.test(textbooks$uclaNew, textbooks$amazNew, paired=T, 
       alternative='two.sided')
&lt;/pre&gt;



=== Example: Bookstore vs Amazon ===
* two samples: local bookshop and amazon 
* $\mu_\text{dif} = \mu_l - \mu_a$ - the mean of difference in the price

Test
* $H_0: \mu_\text{dif} = 0$ - there's no difference in the price
* $H_A: \mu_\text{dif} \ne 0$ - there's some difference 

Calculations
* $\bar{x}_\text{dif} = 12.76$
* Standard Error: $\text{se}_{\bar{x}_\text{dif}} = \cfrac{s_\text{dif}}{\sqrt{n_\text{dif}}} = 1.67$
* $T = \cfrac{\bar{x}_\text{dif}}{\text{se}_{\bar{x}_\text{dif}}} = \cfrac{12.76}{1.67} = 7.59$
* $p = 6 \cdot 10^{-11}$, less than $\alpha = 0.05$, so we reject $H_0$


&lt;pre&gt;
library(openintro)
data(textbooks)

hist(textbooks$diff, col='yellow')

n = length(textbooks$diff)
s = sd(textbooks$diff)
se = s / sqrt(n)

x.bar.nul = 0
x.bar.dif = mean(textbooks$diff)

t = (x.bar.dif - x.bar.nul) / se
t
p = pt(t, df=n-1, lower.tail=F) * 2
p
&lt;/pre&gt;

or 

&lt;pre&gt;
t.test(textbooks$diff, mu=x.bar.nul, alternative='two.sided')
&lt;/pre&gt;


=== Example 2 ===
Let $\mu_d = \mu_0 - \mu_1$ be the difference between two methods

Our test:
* $H_0: \mu_d = 0, H_A: \mu_d \neq 0$

Say, we have:
* $\bar{X}_d = 6.854$
* $s_d = 11.056$
* $n = 398$

Test statistics:
* $\cfrac{\bar{X}_d - 0}{s_d / \sqrt{n}} = \cfrac{6.854}{11.056 / \sqrt{398}} \approx 12.37$

Then we compare it with $t_{397}$
* $p$-value is $2.9 \cdot 10^{29}$

And we conclude that the difference between the two methods is not 0



== Two-Sample t-test ==
This variation of $t$-test is used when we want to compare the means of two different samples
* suppose that we have two samples $a$ and $b$ of sizes $n_a$ and $n_b$ resp.
* we're interested in inferring something about $\mu_a - \mu_b$ 
* [[Point Estimate]] in this case is $\bar{x}_a - \bar{x}_b$
* [[Standard Error]] is $\text{SE}_{\bar{x}_a - \bar{x}_b} = \sqrt{\text{SE}_a + \text{SE}_b } = \sqrt{ s^2_a / n_a + s^2_b / n_b}$
** because $\text{SE}^2_{\bar{x}_a - \bar{x}_b} = \text{var}[\bar{x}_a - \bar{x}_b] = \text{var}[x_a] + \text{var}[x_b] = \text{SE}^2_a + \text{SE}^2_b$


The test is of the following form
* $H_0: \mu_a = \mu_b$, or $H_0: \mu_a - \mu_b = 0$
* $H_A: \mu_a \neq \mu_b$ or $H_A: \mu_a - \mu_b \neq 0$ (two-sided, can also be $&lt;$ or $&gt;$)


So, test statistics:
* $T = \cfrac{(\bar{X}_1 - \bar{X}_2) - (\mu_1 - \mu_2)}{\sqrt{s_1^2 / n_1 + s_2^2 / n_2}}$
* $T \approx t_{\text{df}}$
* $\text{df}$ depends on a few things, discussed below


=== Welch-Satterthwaite Approximation ===
What is $\text{df}$ there?
* Welch-Satterthwaite Approximation for df is
* $\text{df} = \cfrac{( s_1^2 / n_1 + s_2^2 / n_2 )^2 }{ \frac{(s_1^2 / n_1)^2 }{n_1 - 1} + \frac{(s_2^2 / n_2)^2 }{n_2 - 1} }$

This can be a non-integer value, but that's fine


=== Pooled Variance Estimation ===
* Can we &quot;pool&quot; the samples?
* Yes, but only under assumption that $\sigma_1^2 = \sigma_2^2$ (in other words, we assume that the variances are equal)

We can replace $s_1^2$ and $s_2^2$ by the ''pooled variance'':
* $s^2 = \cfrac{(n_1 - 1) s_1^2 + (n_2 - 1) s_2^2 }{ (n_1 - 1) + (n_2 - 1)}$
* and $\text{df} = (n_1 - 1) + (n_2 - 1) = n_1 + n_2 - 2$



=== Example 1 ===
* males: $n_1 = 281 $
* females: $n_2 = 199$
* $\bar{X}_1 = -12.9, s_1^2 = 181.5$
* $\bar{X}_2 = -17.1, s_2^2 = 231.5$
* $\bar{X}_1 - \bar{X}_2 = -12.9 + 17.1 = 4.2$

We then calculate
* $\text{df} = 200.09$
* so $T_{0.025, 200.09} = 1.97$


We have the following test
* $H_0: \mu_1 = \mu_2, H_A: \mu_1 \neq \mu_2$
* and $\bar{X}_1 - \bar{X}_2 = 4.2$


$p$-value:
* $P(| \bar{X}_1 - \bar{X}_2 |  \geqslant  4.2 ) = $
* $P \left( \left| \cfrac{(\bar{X}_1 - \bar{X}_2) - (\mu_1 - \mu_2)}{\sqrt{s_1^2 / n_1 + s_2^2 / n_2}} \right|  \geqslant  \cfrac{4.2}{\sqrt{s_1^2 / n_1 + s_2^2 / n_2}} \right) \approx $
* $P\left( |t_\text{df} |  \geqslant \cfrac{4.2}{\sqrt{181.5 / 281 + 231 / 119}} \right) = 0.0097$

pretty small, so we reject the $H_0$.


=== Example 2 ===
Life expectancy in E.Asia and Pacific vs S.Asia
* EA&amp;P: $n_1: 30, \bar{X}_1 = 73.1, s_1^2 = 38.7$
* SA: $n_2: 8, \bar{X} = 67.0, s_2^2 = 72.5$
* $\bar{X}_1 - \bar{X}_2 = 73.1 - 67.0 = 6.1$


We then calculate
* $\text{df} = 9.09$ by Welch-Satterthwaite Approximation
* $T_{0.025, 0.09} = 2.26$


Our test:
* $H_0: \mu_0 = \mu_1, H_A: \mu_0 \neq \mu_1$

$p$-value:
* $P(| \bar{X}_1 - \bar{X}_2 |  \geqslant  6.1 ) = $
* $P \left( \left| \cfrac{(\bar{X}_1 - \bar{X}_2) - (\mu_1 - \mu_2)}{\sqrt{s_1^2 / n_1 + s_2^2 / n_2}} \right|  \geqslant  \cfrac{6.1}{\sqrt{s_1^2 / n_1 + s_2^2 / n_2}} \right) \approx $
* $P ( |t_\text{df} |  \geqslant 1.90 ) \approx 0.09$

Not so small - we can't reject the $H_0$, it might be true that $\mu_0 = \mu_1$


=== R (Means) ===
&lt;pre&gt;
male = skeletons[sex == '1', 6]
female = skeletons[sex == '2', 6]

# critical value
qt(0.025, df=200.9, lower.tail=F)
&lt;/pre&gt;

or 

&lt;pre&gt;
t.test(male, female, mu=0, conf.level=0.95, alternative='two.sided')
&lt;/pre&gt;



== Pairwise t-test ==
* we have $n$ groups, $n &gt; 2$
* we conduct a series of Two-Sample t-tests to find out which groups are different 
* e.g. in post-[[ANOVA]] analysis


=== Controlling [[Family-Wise Error Rate]] ===
It's important to modify $\alpha$ to avoid [[Type I Errors]]
* when we run many tests, it's inevitable that we make them just by chance

E.g. use [[Bonferroni Correction]]
* use modified confidence level $\alpha^* = \alpha \cdot \cfrac{1}{K}$
* where for $k$ groups $K= \cfrac{k \cdot (k - 1)}{2}$ 


== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[OpenIntro Statistics (book)]]
* http://projectile.sv.cmu.edu/research/public/talks/t-test.htm

[[Category:Statistics]]
[[Category:Statistical Tests]]
[[Category:R]]</text>
      <sha1>eyxgv8594h9leto1wk3e92age29ke84</sha1>
    </revision>
    <revision>
      <id>710</id>
      <parentid>507</parentid>
      <timestamp>2015-11-23T15:32:49Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1685">== Family of $t$ Tests ==
$t$-tests is a family of [[Hypothesis Testing|Statistical tests]] that use $t$-statistics 
* critical values come from the [[t Distribution|$t$-distribution]] - used for calculating $p$-values


== $t$ Tests ==
The following tests are $t$-tests:
* [[One-Sample t-test|One-Sample $t$-test]] - for comparing the mean of a sample against some given mean
* [[Two-Sample t-test|Two-Sample $t$-test]] - for comparing the means of two samples
* [[Paired t-test|Paired $t$-test]] - for Matching Pairs setup
* [[Pairwise t-test|Pairwise $t$-test]] - for comparing the means of more than two samples


=== Assumptions ===
Assumptions for $t$ tests are similar to the assumptions of the [[z-tests|$z$-tests]]
* Observations are independent (if less than 10% of population is sampled, then we can make sure it's satisfied)
* Sample size is sufficiently large so [[Central Limit Theorem|C.L.T.]] holds
* Moderate skew, few outliers (not too extreme)


=== $t$-tests vs [[z-tests|$z$-tests]] ===
Sample Size
* the sample size can be smaller than for $z$-tests 
* so it can be smaller than 30 - after 30 we can safely use $z$-tests with almost the same outcomes 

$t$-distribution:
* the tails are thicker than for $N(0,1)$ and observations are more likely to fall within 2$\sigma$ from the mean
* this is exactly the correction we need to account for poorly estimated [[Standard Error]] when the sample size is not big


== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[OpenIntro Statistics (book)]]
* http://projectile.sv.cmu.edu/research/public/talks/t-test.htm

[[Category:T-Test]]
[[Category:Statistics]]
[[Category:Statistical Tests]]
[[Category:R]]</text>
      <sha1>4srhmunteva32gpp1ln7ifwo0b6bzew</sha1>
    </revision>
    <revision>
      <id>757</id>
      <parentid>710</parentid>
      <timestamp>2017-04-25T20:49:48Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1837">== Family of $t$ Tests ==
$t$-tests is a family of [[Hypothesis Testing|Statistical tests]] that use $t$-statistics 
* critical values come from the [[t Distribution|$t$-distribution]] - used for calculating $p$-values


== $t$ Tests ==
The following tests are $t$-tests:
* [[One-Sample t-test|One-Sample $t$-test]] - for comparing the mean of a sample against some given mean
* [[Two-Sample t-test|Two-Sample $t$-test]] - for comparing the means of two samples
* [[Paired t-test|Paired $t$-test]] - for Matching Pairs setup
* [[Pairwise t-test|Pairwise $t$-test]] - for comparing the means of more than two samples


=== Assumptions ===
Assumptions for $t$ tests are similar to the assumptions of the [[z-tests|$z$-tests]]
* Observations are independent (if less than 10% of population is sampled, then we can make sure it's satisfied)
* Sample size is sufficiently large so [[Central Limit Theorem|C.L.T.]] holds
* Moderate skew, few outliers (not too extreme)


=== $t$-tests vs [[z-tests|$z$-tests]] ===
Sample Size
* the sample size can be smaller than for $z$-tests 
* so it can be smaller than 30 - after 30 we can safely use $z$-tests with almost the same outcomes 

$t$-distribution:
* the tails are thicker than for $N(0,1)$ and observations are more likely to fall within 2$\sigma$ from the mean
* this is exactly the correction we need to account for poorly estimated [[Standard Error]] when the sample size is not big

== Alternatives to $t$-Tests ==
* http://stats.stackexchange.com/questions/183456/have-the-reports-of-the-death-of-the-t-test-been-greatly-exaggerated


== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[OpenIntro Statistics (book)]]
* http://projectile.sv.cmu.edu/research/public/talks/t-test.htm

[[Category:T-Test]]
[[Category:Statistics]]
[[Category:Statistical Tests]]
[[Category:R]]</text>
      <sha1>ti5rnlka8stumz154fh8l7ue1tj20q1</sha1>
    </revision>
  </page>
  <page>
    <title>Sequential Pattern Mining</title>
    <ns>0</ns>
    <id>505</id>
    <revision>
      <id>508</id>
      <timestamp>2014-11-25T20:47:02Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9709">$\require{color}$

== Sequence Mining ==
Data Model 
* similar to [[Local Pattern Discovery]]
* item - binary-valued attribute (either present - 1, or not present - 0)
* itemset - &lt;u&gt;lexicographically&lt;/u&gt; sorted subset of all items 
* sequence - an ordered list of itemsets (i.e. transactions)
** they may be ordered by date/time, location, price, etc


=== Sequence Data ===
Examples

Supermarket
* a supermarket: each product is an item 
* A receipt - an itemset (don't consider the quantity) 
* for a certain customer, all his receipt ordered by date form a sequence of transactions

Web:
* each user session is a sequence
* each click is an itemset
* items: remote hosts, user names, date, URLs, etc

[[NLP]]:
* text - sequence with [[Part of Speech Tagging]]
* sentence - itemset
* words with POS-tags - items


=== Notation ===
* items: lowercase letters $a,b,c,...$
* itemsets: uppercase letters $I=(abc), I'=(abc), I_1=(abc)$
* sequence: 
** $s = \langle I_1 \ I_2 \ ... \ I_k \rangle$ or
** $s = \langle (ab)(c)(bdc) \rangle \equiv \langle (ab)c(bdc) \rangle$
** note that $\langle abc \rangle \equiv \langle (a)(b)(c) \rangle \not \equiv \langle (abc) \rangle$


=== Subsequences ===
Sequence containment:
* $s$ is contained in $s'$ ($s \sqsubseteq s'$) $\iff$
** $\forall I \in s$ (in order) $\exists I' \in s'$ (in order) s.t. $I \subseteq I'$
** order is important! 
* $s'$ is a super sequence for $s$, or $s'$ &quot;supports&quot; $s$


Example:
* $\langle (a)(bc)(d)(c) \rangle \sqsubseteq \langle (a)(abc)(ac)(d)(cf) \rangle$
* $\langle (a)(b)(cd)(c) \rangle \not \sqsubseteq \langle (a)(abc)(ac)(d)(cf) \rangle$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/seq-containment.png


== Sequential Pattern Mining ==
Like in [[Local Pattern Discovery]], we have the notion of Support
* the support of sequence $s$ w.r.t to dataset $D$ is the # of sequenced in $D$ that support $s$ 
* $\text{supp}(s, D) = \big| \{ s' \in D \ : \ s \sqsubseteq s' \} \big|$

Frequent patterns:
* a sequence $s$ is frequent if $\text{supp}(s, D) \geqslant \theta$
* where $\theta$ is the desired minimal support (parameter)
* A frequent (sub)sequence is called a ''sequential pattern''


Sequential Pattern Mining
* given a sequence database $D$, find the complete set of all frequent subsequences 


=== Example ===
Given:
* Support threshold $\theta = 3$
* Database $D$

{| class=&quot;wikitable&quot;
! SID || Sequence 
|-
| 10 || $\langle (a)(abc)(ac)(d)(af) \rangle$
|-
| 20 || $\langle (ad)(c)(bc)(ae) \rangle$
|-
| 30 || $\langle (ef)(ab)(df)(c)(b) \rangle$
|-
| 40 || $\langle (ae)(af)(c)(b)(cf) \rangle$
|-
| 50 || $\langle (abd)(af)(c)(b)(ad) \rangle$
|}


Which of the following patterns are frequent?
* $\langle (a) \rangle$
* $\langle (a)(bc) \rangle$
* $\langle (a)(b)(c) \rangle$
* $\langle (a)(b)(c)(d) \rangle$


{| class=&quot;wikitable&quot;
! Pattern || Frequency || Table
|- 
| $\langle (a) \rangle$ || 5 || $\langle (\colorbox{red}{a})(abc)(ac)(d)(af) \rangle$ &lt;br/&gt; $\langle (\colorbox{red}{a}d)(c)(bc)(ae) \rangle$ &lt;br/&gt; $\langle (ef)(\colorbox{red}{a}b)(df)(c)(b) \rangle$ &lt;br/&gt; $\langle (\colorbox{red}{a}e)(af)(c)(b)(cf) \rangle$ &lt;br/&gt; $\langle (\colorbox{red}{a}bd)(af)(c)(b)(ad) \rangle$
|-
| $\langle (a)(bc) \rangle$ || 2 || $\langle (\colorbox{red}{a})(\colorbox{red}{ab}c)(ac)(d)(af) \rangle$ &lt;br/&gt; $\langle (\colorbox{red}{a}d)(c)(\colorbox{red}{bc})(ae) \rangle$ &lt;br/&gt; $\langle (ef)(ab)(df)(c)(b) \rangle$ &lt;br/&gt; $\langle (ae)(af)(c)(b)(cf) \rangle$ &lt;br/&gt; $\langle (abd)(af)(c)(b)(ad) \rangle$
|- 
| $\langle (a)(b)(c) \rangle$ || 2 || $\langle (\colorbox{red}{a})(a\colorbox{red}{b}c)(a\colorbox{red}{c})(d)(af) \rangle$ &lt;br/&gt; $\langle (ad)(c)(bc)(ae) \rangle$ &lt;br/&gt; $\langle (ef)(ab)(df)(c)(b) \rangle$ &lt;br/&gt; $\langle (\colorbox{red}{a}e)(af)(c)(\colorbox{red}{b})(\colorbox{red}{c}f) \rangle$ &lt;br/&gt; $\langle (abd)(af)(c)(b)(ad) \rangle$
|-
| $\langle (a)(b)(c)(d) \rangle$ || 1 || $\langle (\colorbox{red}{a})(a\colorbox{red}{b}c)(a\colorbox{red}{c})(\colorbox{red}{d})(af) \rangle$ &lt;br/&gt; $\langle (ad)(c)(bc)(ae) \rangle$ &lt;br/&gt; $\langle (ef)(ab)(df)(c)(b) \rangle$ &lt;br/&gt; $\langle (ae)(af)(c)(b)(cf) \rangle$ &lt;br/&gt; $\langle (abd)(af)(c)(b)(ad) \rangle$
|}


=== Downwards Closure ===
Frequency is an anti-monotonic property of a [[Lattice]]
* it's sometimes called &quot;[[Apriori]] Property&quot;
* it forms the down-wards closure
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/downward-closure.png


Downwards Closure property
* if a sequence is frequent, then all its subsequences are frequent

E.g.
* if $\langle (a)(bc) \rangle$ is frequent, then 
* $\langle (a) \rangle$, $\langle (b) \rangle$, $\langle (c) \rangle$, $\langle (bc) \rangle$, $\langle (a)(b) \rangle$, and $\langle (a)(c) \rangle$ are also frequent



== Sequential [[Apriori]] Approach ==
Can adapt Apriori to mining sequential patterns:
* R. Agrawal and R. Srikant. Mining sequential patterns. 1995.


=== Algorithm ===
Sequential Apriori
* at level 1
** generate length-1 sequences: ones that contain only 1 itemset of 1 item
** prune non-frequent
* at level $i$
** generate length-$i$ candidate sequences from frequent length-$(i-1)$ sequences
** prune non-frequent


=== Example ===
Given 
* items $a, b, c, d, e, f, g, h$
* the following database $D$

\langle (a) \rangle, \langle (b) \rangle, \langle (c) \rangle, \langle (d) \rangle, \langle (e) \rangle, \langle (f) \rangle, \langle (g) \rangle, \langle (h) \rangle

{| class=&quot;wikitable&quot;
! SID || Sequence
|-
| 10 || $\langle (bd)(c)(b)(ac) \rangle$
|-
| 20 || $\langle (bf)(ce)(b)(fg) \rangle$
|-
| 30 || $\langle (ah)(bf)(a)(b)(f) \rangle$
|-
| 40 || $\langle (be)(ce)(d) \rangle$
|-
| 50 || $\langle (a)(bd)(b)(c)(b)(ade) \rangle$
|}


'''Step 1:'''
* generate length-1 candidates 
* $\langle (a) \rangle, \langle (b) \rangle, \langle (c) \rangle, \langle (d) \rangle, \langle (e) \rangle, \langle (f) \rangle, \langle (g) \rangle, \langle (h) \rangle$
* calculate frequency
** $\text{freq}\big(\langle (a) \rangle \big) = 3$
** $\text{freq}\big(\langle (b) \rangle \big) = 5$
** $\text{freq}\big(\langle (c) \rangle \big) = 4$
** $\text{freq}\big(\langle (d) \rangle \big) = 3$
** $\text{freq}\big(\langle (e) \rangle \big) = 3$
** $\text{freq}\big(\langle (f) \rangle \big) = 2$
** $\text{freq}\big(\langle (g) \rangle \big) = {\color{red}{1}}$
** $\text{freq}\big(\langle (h) \rangle \big) = {\color{red}{1}}$
* prune non-frequent: $\langle (g) \rangle$ and $\langle (h) \rangle$



'''Step 2'''
Now need to generate length-2 candidates
* two ways
** adding an item to a new itemset, i.e. $\langle (a) \rangle$ becomes $\langle (a)(b) \rangle$ when we add $b$
** adding to last itemset: $\langle (a) \rangle$ becomes $\langle (ab) \rangle$

So we have the following candidates:

&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;
{| class=&quot;wikitable&quot;
|+ Way 1
! || $\langle (a) \rangle$ || $\langle (b) \rangle$ || $\langle (c) \rangle$ || $\langle (d) \rangle$ || $\langle (e) \rangle$ || $\langle (f) \rangle$
|- 
! $\langle (a) \rangle$ 
| $\langle (a)(a) \rangle$ || $\langle (a)(b) \rangle$ || $\langle (a)(c) \rangle$ || $\langle (a)(d) \rangle$ || $\langle (a)(e) \rangle$ || $\langle (a)(f) \rangle$
|- 
! $\langle (b) \rangle$ 
| $\langle (b)(a) \rangle$ || $\langle (b)(b) \rangle$ || $\langle (b)(c) \rangle$ || $\langle (b)(d) \rangle$ || $\langle (b)(e) \rangle$ || $\langle (b)(f) \rangle$
|- 
! $\langle (c) \rangle$ 
| $\langle (c)(a) \rangle$ || $\langle (c)(b) \rangle$ || $\langle (c)(c) \rangle$ || $\langle (c)(d) \rangle$ || $\langle (c)(e) \rangle$ || $\langle (c)(f) \rangle$
|- 
! $\langle (d) \rangle$ 
| $\langle (d)(a) \rangle$ || $\langle (d)(b) \rangle$ || $\langle (d)(c) \rangle$ || $\langle (d)(d) \rangle$ || $\langle (d)(e) \rangle$ || $\langle (d)(f) \rangle$
|- 
! $\langle (e) \rangle$ 
| $\langle (e)(a) \rangle$ || $\langle (e)(b) \rangle$ || $\langle (e)(c) \rangle$ || $\langle (e)(d) \rangle$ || $\langle (e)(e) \rangle$ || $\langle (e)(f) \rangle$
|- 
! $\langle (f) \rangle$ 
|  $\langle (f)(a) \rangle$ || $\langle (f)(b) \rangle$ || $\langle (f)(c) \rangle$ || $\langle (f)(d) \rangle$ || $\langle (f)(e) \rangle$ || $\langle (f)(f) \rangle$
|}
&lt;/td&gt;
&lt;td&gt;
{| class=&quot;wikitable&quot;
|+ Way 2 
! || $\langle (a) \rangle$ || $\langle (b) \rangle$ || $\langle (c) \rangle$ || $\langle (d) \rangle$ || $\langle (e) \rangle$ || $\langle (f) \rangle$
|-
! $\langle (a) \rangle$
| || $\langle (ab) \rangle$ || $\langle (ac) \rangle$ || $\langle (ad) \rangle$ || $\langle (ae) \rangle$ || $\langle (af) \rangle$ 
|-
! $\langle (b) \rangle$
| || || $\langle (bc) \rangle$ || $\langle (bd) \rangle$ || $\langle (be) \rangle$ || $\langle (bf) \rangle$ 
|-
! $\langle (c) \rangle$
| || || || $\langle (cd) \rangle$ || $\langle (ce) \rangle$ || $\langle (cf) \rangle$ 
|-
! $\langle (d) \rangle$
| || || || || $\langle (de) \rangle$ || $\langle (df) \rangle$ 
|-
! $\langle (e) \rangle$
| || || || || || $\langle (ef) \rangle$  
|-
! $\langle (f) \rangle$
| || || || || || 
|}
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;


Now we prune infrequent 

And so on...


=== Drawbacks ===
* Exponential growth in # of combinations
* Computationally expensive 



== PrefixSpan ==
PrefixSpan: A prefix-projected pattern growth method 
* Pei et al. PrefixSpan: Mining sequential patterns efficiently by prefix-projected pattern growth, 2001.
* doesn't generate non-existing patterns (like Apriori)

Idea:
* use database $D$ prefix-projected on some sequence $s$ (it's called prefix-projected database)
* grow frequent subsequences from them - without generating candidates
* examine only prefix subsequences 

{{ TODO | Add description}}


== See Also ==
* [[Local Pattern Discovery]]

== Sources ==
* [[Data Mining (UFRT)]]

[[Category:Rule Mining]]</text>
      <sha1>szlumy6nf7frwfijtavq0wumdbn172o</sha1>
    </revision>
  </page>
  <page>
    <title>Linear Algebra MIT 18.06 (OCW)</title>
    <ns>0</ns>
    <id>506</id>
    <revision>
      <id>509</id>
      <timestamp>2015-04-26T17:17:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4347">== Linear Algebra MIT 18.06 (OCW) ==
Lectures by G. Strang, 2005

http://habrastorage.org/files/f79/611/ba1/f79611ba168d48008d8b3837bc157054.jpg


=== List of Topics ===
# The Geometry of [[System of Linear Equations|Linear Equations]] [http://www.youtube.com/watch?v=ZK3O402wf1c]
# [[Gaussian Elimination|Elimination with Matrices]] [http://www.youtube.com/watch?v=QVKj3LADCnA]
# [[Matrix Multiplication|Multiplication]] and [[Inverse Matrices]] [http://www.youtube.com/watch?v=FX4C-JpTFgY]
# [[LU Factorization|Factorization into $A = LU$]] [http://www.youtube.com/watch?v=5hO3MrzPa0A]
# [[Matrix Transposition|Transposes]], [[Permutation Matrices|Permutations]], [[Vector Spaces|Spaces $\mathbb R^n$]] [http://www.youtube.com/watch?v=JibVXBElKL0]
# [[Vector Subspaces]]: [[Column Space]] and [[Nullspace]] [http://www.youtube.com/watch?v=8o5Cmfpeo6g]
# [[Homogeneous Systems of Linear Equations|Solving $A \mathbf x = \mathbf 0$]]: Pivot Variables, Special Solutions [http://www.youtube.com/watch?v=VqP2tREMvt0]
# [[System of Linear Equations|Solving $A \mathbf x = \mathbf b$]]: [[Row Reduced Echelon Form|Row Reduced Form $R$]] [http://www.youtube.com/watch?v=9Q1q7s1jTzU]
# [[Linear Independence|Independence]], [[Basis (Linear Algebra)|Basis]], and Dimension [http://www.youtube.com/watch?v=yjBerM5jWsc]
# The [[Four Fundamental Subspaces]] [http://www.youtube.com/watch?v=nHlE7EgJFds]
# [[Matrix Vector Spaces|Matrix Spaces]]; [[Outer Product|Rank 1 Matrices]]; Small World Graphs [http://www.youtube.com/watch?v=2IdtqGM6KWU]
# Graphs, Networks, Incidence Matrices [http://www.youtube.com/watch?v=6-wh6yvk6uc]
# Quiz 1 Review [http://www.youtube.com/watch?v=l88D4r74gtM]
# [[Orthogonality]]: [[Vector Orthogonality|Orthogonal Vectors]] and [[Space Orthogonality|Orthogonal Subspaces]] [http://www.youtube.com/watch?v=YzZUIYRCE38]
# [[Projection onto Subspaces]] [http://www.youtube.com/watch?v=Y_Ac6KiQ1t0]
# [[Projection onto Subspaces#Projection Matrix|Projection Matrices]] and [[OLS Regression|Least Squares]] [http://www.youtube.com/watch?v=osh80YCg_GM]
# [[Orthogonal Matrices]] and [[Gram-Schmidt Process|Gram-Schmidt]] [http://www.youtube.com/watch?v=uNsCkP9mgRk]
# Properties of [[Determinants]] [http://www.youtube.com/watch?v=srxexLishgY]
# Determinant Formulas and [[Cofactors]] [http://www.youtube.com/watch?v=23LLB9mNJvc]
# [[Cramer's Rule]], [[Inverse Matrices|Inverse Matrix]], and Volume [http://www.youtube.com/watch?v=QNpj-gOXW9M]
# [[Eigenvalues and Eigenvectors]] [http://www.youtube.com/watch?v=lXNXrLcoerU]
# [[Eigendecomposition|Matrix Diagonalization]] and Powers of $A$ [http://www.youtube.com/watch?v=13r9QY6cmjc]
# Differential Equations and $\exp(At)$ [http://www.youtube.com/watch?v=IZqwi0wJovM]
# [[Stochastic Matrices|Markov Matrices]]; [[Fourier Transformation|Fourier Series]] [http://www.youtube.com/watch?v=8MF3pz-oYHo]
# Quiz 2 Review [http://www.youtube.com/watch?v=sFxA8eIS6tA]
# [[Symmetric Matrices]] and [[Positive-Definite Matrices|Positive Definiteness]] [http://www.youtube.com/watch?v=umt6BB1nJ4w]
# [[Complex Vector Space|Complex Matrices]]; [[Fourier Transformation#Fast Fourier Transform|Fast Fourier Transform]] [http://www.youtube.com/watch?v=M0Sa8fLOajA]
# [[Positive-Definite Matrices]] and Minima [http://www.youtube.com/watch?v=vF7eyJ2g3kU]
# [[Similar Matrices]] and Jordan Form [http://www.youtube.com/watch?v=z_zYQHmrh08]
# [[Singular Value Decomposition]] [http://www.youtube.com/watch?v=Nx0lRBaXoz4]
# [[Linear Transformations]] and Their Matrices [http://www.youtube.com/watch?v=Ts3o2I8_Mxc]
# [[Change of Basis]]; Image Compression [http://www.youtube.com/watch?v=vGkn-3NFGck]
# Quiz 3 Review [http://www.youtube.com/watch?v=HgC1l_6ySkc]
# [[General Inverses]]: Left and Right Inverses; Pseudoinverse [http://www.youtube.com/watch?v=Go2aLo7ZOlU]
# Final Course Review [http://www.youtube.com/watch?v=RWvi4Vx4CDc]


=== Links ===
* Youtube list: [https://www.youtube.com/watch?v=ZK3O402wf1c&amp;list=PL49CF3715CB9EF31D]
* My note with progress: [https://www.evernote.com/shard/s344/nl/54547539/8b259a87-306c-483e-9029-b4ae466adee3]
* 18.06 MIT Page: http://web.mit.edu/18.06/www/videos.shtml
* OCW page: http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/index.htm


[[Category:Notes]]
[[Category:Mathematics‏‎]]
[[Category:Linear Algebra]]
[[Category:OCW]]</text>
      <sha1>61q8sfknlyeuei7qbf4ftguaal8jykq</sha1>
    </revision>
  </page>
  <page>
    <title>Binomial Proportion Test</title>
    <ns>0</ns>
    <id>507</id>
    <redirect title="Binomial Proportion Tests" />
    <revision>
      <id>510</id>
      <timestamp>2014-12-06T10:17:25Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="39">#REDIRECT [[Binomial Proportion Tests]]</text>
      <sha1>dc6dc805qtjgyhg71yuplxuv9d67gtu</sha1>
    </revision>
  </page>
  <page>
    <title>Statistical Test</title>
    <ns>0</ns>
    <id>508</id>
    <redirect title="Hypothesis Testing" />
    <revision>
      <id>511</id>
      <timestamp>2014-12-08T12:49:02Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="32">#REDIRECT [[Hypothesis Testing]]</text>
      <sha1>2088mzrqs93kb38x3bz8pficlo9btih</sha1>
    </revision>
  </page>
  <page>
    <title>Inverse Matrices</title>
    <ns>0</ns>
    <id>509</id>
    <revision>
      <id>512</id>
      <timestamp>2014-12-30T21:28:49Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3499">== Inverse Matrices ==
A square $n \times n$ matrix $A$ has inverse (or $A$ is ''invertible'') if there exists $B$ s.t. $A \times B = B \times A = I_n$ 
* If $B$ exists, then it's denoted $A^{-1}$  
* $A$ in such case is called ''non-singular''
* otherwise (no $A^{-1}$ exists) $A$ is called ''singular''



There are two types of inverses:
* left and right
* $\underbrace{A \times A^{-1}}_\text{left} = I_n = \underbrace{A^{-1} \times A}_\text{right}$ 
* for square matrices left and right inverses are equal


== Finding the Inverse ==
=== Gauss-Jordan Elimination ===
Suppose we have an equation $A \times A^{-1} = I$
* how can we solve it to find $A^{-1}$? Let's replace $A^{-1}$ by $X$ and solve $A \times X = I$
* $A \times X = \begin{bmatrix}
a_{11} &amp; a_{12} \\ 
a_{21} &amp; a_{22} \\
\end{bmatrix} \times \begin{bmatrix}
x_{11} &amp; x_{12} \\ 
x_{21} &amp; x_{22} \\
\end{bmatrix} = \begin{bmatrix}
1 &amp; 0 \\ 
0 &amp; 1
\end{bmatrix} = I$
* one idea: Solve $n$ different [[System of Linear Equations|systems of linear equations]]
** $\begin{bmatrix}
a_{11} &amp; a_{12} \\ 
a_{21} &amp; a_{22} \\
\end{bmatrix} \times \begin{bmatrix}
x_{11} \\ 
x_{21} \\
\end{bmatrix} = \begin{bmatrix}
1 \\ 
0
\end{bmatrix}$ and 
** $\begin{bmatrix}
a_{11} &amp; a_{12} \\ 
a_{21} &amp; a_{22} \\
\end{bmatrix} \times \begin{bmatrix}
x_{12} \\ 
x_{22} \\
\end{bmatrix} = \begin{bmatrix}
0 \\ 
1
\end{bmatrix}$ 
** i.e. for $i$th system, take $i$th column of $X$ ($\mathbf x_i$) and $i$th row of $I$ ($\mathbf  e_i$)
* we have a bunch of systems like $A \mathbf x_i = \mathbf e_i$ that we know how to solve
** so we can use [[Gaussian Elimination]] for that 
** we'll have several augmented matrices like $\left[ \begin{array}{cc|c}
a_{11} &amp; a_{12} &amp; 1 \\ 
a_{21} &amp; a_{22} &amp; 0 \\
\end{array} \right]$ and $\left[ \begin{array}{cc|c}
a_{11} &amp; a_{12} &amp; 0 \\ 
a_{21} &amp; a_{22} &amp; 1 \\
\end{array} \right]$ that we can solve to get $\begin{bmatrix}
x_{11} \\ 
x_{21} \\
\end{bmatrix}$ and $\begin{bmatrix}
x_{12} \\ 
x_{22} \\
\end{bmatrix}$
* but we can also put all such vectors $\mathbf x_i$ and $\mathbf e_i$ at the same time!
**  $\left[ \begin{array}{cc|cc}
a_{11} &amp; a_{12} &amp; 1 &amp; 0 \\ 
a_{21} &amp; a_{22} &amp; 0 &amp; 1 \\
\end{array} \right]$


Gaussian Elimination:
* so once we have an augmented matrix $\Big[ \ A \; \Big| \; I \ \Big] = \left[ \begin{array}{cc|cc}
a_{11} &amp; a_{12} &amp; 1 &amp; 0 \\ 
a_{21} &amp; a_{22} &amp; 0 &amp; 1 \\
\end{array} \right]$
* we come from $A$ to $I$  while applying the same actions to the augmented part $I$.
* at the end we should get $\Big[ \ A \; \Big| \; I \ \Big] \to \Big[ \ I \; \Big| \; A^{-1} \ \Big]$


Why does it work? 
* suppose you did your elimination on $A$ alone, so you obtained $EA = I$ (assume no row exchanges)
* let's apply $E$ to augmented $\Big[ \ A \; \Big| \; I \ \Big]$. 
* $E \times \Big[ \ A \; \Big| \; I \ \Big] = \Big[ \ EA \; \Big| \; EI \ \Big] = \Big[ \ I \; \Big| \; E \ \Big]$
* what is $E$? Since $EA = I$ we know that it can be only when $E = A^{-1}$
* so we finally have $\Big[ \ I \; \Big| \; A^{-1} \ \Big]$


=== [[Cramer's Rule]] ===
* We can compute the inverse of $A$ using the following formula:
* $A^{-1} = \cfrac{1}{| A |} C^T$ 
* where $|A|$ is the [[Determinant]] of $A$ and $C^T$ is the [[Cofactors]] matrix



== Properties ==
* $(AB)^{-1} = B^{-1} A^{-1}$ 
* $(A^{-1})^T = (A^T)^{-1}$


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* http://en.wikipedia.org/wiki/Invertible_matrix
* Курош А.Г. Курс Высшей Алгебры

[[Category:Linear Algebra]]</text>
      <sha1>gzwzgbxjylq2diiantkpf80tsyx26z6</sha1>
    </revision>
    <revision>
      <id>754</id>
      <parentid>512</parentid>
      <timestamp>2017-01-27T15:46:22Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3608">== Inverse Matrices ==
A square $n \times n$ matrix $A$ has inverse (or $A$ is ''invertible'') if there exists $B$ s.t. $A \times B = B \times A = I_n$ 
* If $B$ exists, then it's denoted $A^{-1}$  
* $A$ in such case is called ''non-singular''
* otherwise (no $A^{-1}$ exists) $A$ is called ''singular''



There are two types of inverses:
* left and right
* $\underbrace{A \times A^{-1}}_\text{left} = I_n = \underbrace{A^{-1} \times A}_\text{right}$ 
* for square matrices left and right inverses are equal


== Finding the Inverse ==
=== Gauss-Jordan Elimination ===
Suppose we have an equation $A \times A^{-1} = I$
* how can we solve it to find $A^{-1}$? Let's replace $A^{-1}$ by $X$ and solve $A \times X = I$
* &lt;math&gt;A \times X = \begin{bmatrix}
a_{11} &amp; a_{12} \\ 
a_{21} &amp; a_{22} \\
\end{bmatrix} \times \begin{bmatrix}
x_{11} &amp; x_{12} \\ 
x_{21} &amp; x_{22} \\
\end{bmatrix} = \begin{bmatrix}
1 &amp; 0 \\ 
0 &amp; 1
\end{bmatrix} = I&lt;/math&gt;
* one idea: Solve $n$ different [[System of Linear Equations|systems of linear equations]]
** &lt;math&gt;\begin{bmatrix}
a_{11} &amp; a_{12} \\ 
a_{21} &amp; a_{22} \\
\end{bmatrix} \times \begin{bmatrix}
x_{11} \\ 
x_{21} \\
\end{bmatrix} = \begin{bmatrix}
1 \\ 
0
\end{bmatrix}&lt;/math&gt; and 
** &lt;math&gt;\begin{bmatrix}
a_{11} &amp; a_{12} \\ 
a_{21} &amp; a_{22} \\
\end{bmatrix} \times \begin{bmatrix}
x_{12} \\ 
x_{22} \\
\end{bmatrix} = \begin{bmatrix}
0 \\ 
1
\end{bmatrix}&lt;/math&gt;
** i.e. for $i$th system, take $i$th column of $X$ ($\mathbf x_i$) and $i$th row of $I$ ($\mathbf  e_i$)
* we have a bunch of systems like $A \mathbf x_i = \mathbf e_i$ that we know how to solve
** so we can use [[Gaussian Elimination]] for that 
** we'll have several augmented matrices like &lt;math&gt;\left[ \begin{array}{cc|c}
a_{11} &amp; a_{12} &amp; 1 \\ 
a_{21} &amp; a_{22} &amp; 0 \\
\end{array} \right]&lt;/math&gt; and &lt;math&gt;\left[ \begin{array}{cc|c}
a_{11} &amp; a_{12} &amp; 0 \\ 
a_{21} &amp; a_{22} &amp; 1 \\
\end{array} \right]&lt;/math&gt; that we can solve to get &lt;math&gt;\begin{bmatrix}
x_{11} \\ 
x_{21} \\
\end{bmatrix}&lt;/math&gt; and &lt;math&gt;\begin{bmatrix}
x_{12} \\ 
x_{22} \\
\end{bmatrix}&lt;/math&gt;
* but we can also put all such vectors $\mathbf x_i$ and $\mathbf e_i$ at the same time!
**  &lt;math&gt;\left[ \begin{array}{cc|cc}
a_{11} &amp; a_{12} &amp; 1 &amp; 0 \\ 
a_{21} &amp; a_{22} &amp; 0 &amp; 1 \\
\end{array} \right]&lt;/math&gt;


Gaussian Elimination:
* so once we have an augmented matrix &lt;math&gt;\Big[ \ A \; \Big| \; I \ \Big] = \left[ \begin{array}{cc|cc}
a_{11} &amp; a_{12} &amp; 1 &amp; 0 \\ 
a_{21} &amp; a_{22} &amp; 0 &amp; 1 \\
\end{array} \right]&lt;/math&gt;
* we come from $A$ to $I$  while applying the same actions to the augmented part $I$.
* at the end we should get &lt;math&gt;\Big[ \ A \; \Big| \; I \ \Big] \to \Big[ \ I \; \Big| \; A^{-1} \ \Big]&lt;/math&gt;


Why does it work? 
* suppose you did your elimination on $A$ alone, so you obtained $EA = I$ (assume no row exchanges)
* let's apply $E$ to augmented $\Big[ \ A \; \Big| \; I \ \Big]$. 
* $E \times \Big[ \ A \; \Big| \; I \ \Big] = \Big[ \ EA \; \Big| \; EI \ \Big] = \Big[ \ I \; \Big| \; E \ \Big]$
* what is $E$? Since $EA = I$ we know that it can be only when $E = A^{-1}$
* so we finally have $\Big[ \ I \; \Big| \; A^{-1} \ \Big]$


=== [[Cramer's Rule]] ===
* We can compute the inverse of $A$ using the following formula:
* $A^{-1} = \cfrac{1}{| A |} C^T$ 
* where $|A|$ is the [[Determinant]] of $A$ and $C^T$ is the [[Cofactors]] matrix



== Properties ==
* $(AB)^{-1} = B^{-1} A^{-1}$ 
* $(A^{-1})^T = (A^T)^{-1}$


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* http://en.wikipedia.org/wiki/Invertible_matrix
* Курош А.Г. Курс Высшей Алгебры

[[Category:Linear Algebra]]</text>
      <sha1>tidk6kc1oba5ipx0y53aabjrwv3m21d</sha1>
    </revision>
  </page>
  <page>
    <title>Gaussian Elimination</title>
    <ns>0</ns>
    <id>510</id>
    <revision>
      <id>513</id>
      <timestamp>2014-12-12T14:07:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6155">== Gaussian Elimination ==
Gaussian Elimination or Row Reduction is a method for solving a [[System of Linear Equations]]
* it corresponds to elimination of variables in the system 
* if a matrix $A$ that we reduce is non-singular and invertible, then we always have a solution
* a by-product of Gaussian Elimination is [[LU Factorization]]


=== Row Elimination ===
* First, do the forward elimination to reduce the matrix to triangular 
* Then we do the back-substitution to find the solution
* When we multiply a row on some constant $c$ and subtract from any other row, we get an equivalent system


== Elimination by Example ==
We have the following system with 3 equations and 3 unknowns:

$\left\{\begin{array}{l}
x + 2y + z = 2\\ 
3x + 8y + z = 12 \\ 
4y + z = 2
\end{array}\right.$

Matrix form:
* $\underbrace{\begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}}_{A} \cdot \underbrace{\begin{bmatrix}
x \\ y \\ z
\end{bmatrix}}_{\mathbf x} = 
\underbrace{\begin{bmatrix}
2 \\ 12 \\ 2
\end{bmatrix}}_{\mathbf b}$



=== Forward elimination ===
So, first let's see how elimination works 
* i.e. concentrate only on the matrix $A$
* $A = \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}$


Let's proceed
* at each step
** multiply the $i$th equation by the right number and subtract it from the equations below
** s.t. there's 0 for the first column in all other rows
** so we want to knock out the $x_i$ part of the equation, or &quot;eliminate&quot; $x_i$
* $\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}$. $\boxed 1$ is the 1st pivot 
* step 2.1: clean cell $a_{21}$:
** $\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix} \sim \begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}$ 
* multiplying row 1 by 3 will knock out $x$ from the 2nd equation
* step 3.1: clean cell $a_{21}$
** already 0, continuing
* $\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; \boxed 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}$, $\boxed 2$ is the 2nd pivot
* step 3.2
** $\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; \boxed 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix} \sim \begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; \boxed 2 &amp; -2\\ 
0 &amp; 0 &amp; \boxed 5
\end{bmatrix}$
* $\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; \boxed 2 &amp; -2\\ 
0 &amp; 0 &amp; \boxed 5
\end{bmatrix}$, $\boxed 5$ - it's 3rd pivot


The matrix is now in the upper-triangular form $U$


=== When Does if Fails? ===
Not always we are able to do the forward elimination

0 at a Pivot position:
* suppose the first pivot is 0:
* $\begin{bmatrix}
\boxed 0 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}$
* But here it doesn't mean that we can't solve the system: we can switch the rows and continue:
* $\begin{bmatrix}
\boxed 3 &amp; 8 &amp; 1\\ 
0 &amp; 2 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}$
* so, if there's a 0 at the pivot position, try to exchange rows
* if there's no rows with non-zero values at the pivot position - the elimination fails
** there's no solution to the system


=== Augmented Matrix === 
But we shouldn't forget about $\mathbf b$!
* $A$ augmented is $\begin{bmatrix}
\mathop{a_1}\limits_|^| \mathop{a_2}\limits_|^|  ...  \mathop{a_n}\limits_|^| \ \Bigg| \ \mathop{\mathbf b}\limits_|^| 
\end{bmatrix}$: matrix $A$ with column $\mathbf b$ stacked to the right
* $A$ augmented: $\left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
3 &amp; 8 &amp; 1 &amp; 12\\ 
0 &amp; 4 &amp; 1 &amp; 2
\end{array}\right]$
* the right part $\mathbf b$ also changes as we go through elimination
* $\left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
3 &amp; 8 &amp; 1 &amp; 12\\ 
0 &amp; 4 &amp; 1 &amp; 2
\end{array}\right] \to \left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
0 &amp; 2 &amp; -6 &amp; 6\\ 
0 &amp; 4 &amp; 1 &amp; 2
\end{array}\right] \to \left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
0 &amp; 2 &amp; -6 &amp; 6\\ 
0 &amp; 0 &amp; 5 &amp; -10
\end{array}\right]$
* let $\mathbf c$ be the result of applying elimination to $\mathbf b$


=== Back Substitution ===
After we forward-eliminated variables of augmented $A$, we can do back substitution:
* Our matrix is 
$\left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
0 &amp; 2 &amp; -6 &amp; 6\\ 
0 &amp; 0 &amp; 5 &amp; -10
\end{array}\right]$
* It means that our system is 


$\left\{\begin{array}{rl}
x + 2y + z &amp; = 2\\ 
2y - 2z &amp; = 6 \\ 
5z &amp; = -10
\end{array}\right.$

Now we just go backwards and solve: first for $z$, then for $y$, and finally for $x$
* we get $z = -2, y = -1, x =2$
* it's easy to solve because the matrix is triangular


=== Elimination: Matrix Form ===
We can write these elimination steps in matrix form
* $\begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}$
* the first step of the elimination was to take first and last rows unchanged, and subtract 3 times 1st row from the second. 
* Can we write it with [[Matrix Multiplication]]?
** $\begin{bmatrix}
1 &amp; 0 &amp; 0\\ 
? &amp; ? &amp; ?\\ 
0 &amp; 0 &amp; 1
\end{bmatrix} \times \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}$
** The first and last rows remain unchanged - hence we have $\begin{bmatrix}
1\\ 
?\\ 
0
\end{bmatrix}$ and $\begin{bmatrix}
0\\ 
?\\ 
1
\end{bmatrix}$
** what should we put instead of $[? \ ? \ ?]$ so multiplication takes us from one matrix to another?
** $\begin{bmatrix}
1 &amp; 0 &amp; 0\\ 
\boxed{-3} &amp; 1 &amp; 0\\ 
0 &amp; 0 &amp; 1
\end{bmatrix}$
** we want to subtract 3 times row 1 from row 2:
** $\begin{bmatrix}
1 &amp; 0 &amp; 0\\ 
\boxed{-3} &amp; 1 &amp; 0\\ 
0 &amp; 0 &amp; 1
\end{bmatrix} \times \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix} = \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
0 &amp; 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}$
* let $E_{21}$ be the matrix that's used for step 2,1 of the elimination
** $E_{21} A = \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
0 &amp; 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}$
* we continue this way until we transform $A$ to $U$
** so we have $E_{21} (E_{21} A) = U$ 
** or $\underbrace{(E_{21} E_{21})}_E A = EA = U $ 
** This a part of [[LU Factorization|$LU$ Factorization]]


What if we need to exchange rows? 
* use a [[Permutation Matrices|Permutation Matrix]]!
* in this case the correct solution is $E (PA) = U$



== See Also ==
* [[Inverse Matrices#Gauss-Jordan Elimination]]
* [[LU Factorization]]

== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Курош А.Г. Курс Высшей Алгебры

[[Category:Linear Algebra]]</text>
      <sha1>btzb023qe3qlq02qixx3qq9bkkd7ej2</sha1>
    </revision>
    <revision>
      <id>755</id>
      <parentid>513</parentid>
      <timestamp>2017-01-27T15:52:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6384">== Gaussian Elimination ==
Gaussian Elimination or Row Reduction is a method for solving a [[System of Linear Equations]]
* it corresponds to elimination of variables in the system 
* if a matrix $A$ that we reduce is non-singular and invertible, then we always have a solution
* a by-product of Gaussian Elimination is [[LU Factorization]]


=== Row Elimination ===
* First, do the forward elimination to reduce the matrix to triangular 
* Then we do the back-substitution to find the solution
* When we multiply a row on some constant $c$ and subtract from any other row, we get an equivalent system


== Elimination by Example ==
We have the following system with 3 equations and 3 unknowns:

$\left\{\begin{array}{l}
x + 2y + z = 2\\ 
3x + 8y + z = 12 \\ 
4y + z = 2
\end{array}\right.$

Matrix form:
* &lt;math&gt;\underbrace{\begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}}_{A} \cdot \underbrace{\begin{bmatrix}
x \\ y \\ z
\end{bmatrix}}_{\mathbf x} = 
\underbrace{\begin{bmatrix}
2 \\ 12 \\ 2
\end{bmatrix}}_{\mathbf b}&lt;/math&gt;



=== Forward elimination ===
So, first let's see how elimination works 
* i.e. concentrate only on the matrix $A$
* &lt;math&gt;A = \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;


Let's proceed
* at each step
** multiply the $i$th equation by the right number and subtract it from the equations below
** s.t. there's 0 for the first column in all other rows
** so we want to knock out the $x_i$ part of the equation, or &quot;eliminate&quot; $x_i$
* &lt;math&gt;\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;. $\boxed 1$ is the 1st pivot 
* step 2.1: clean cell $a_{21}$:
** &lt;math&gt;\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix} \sim \begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* multiplying row 1 by 3 will knock out $x$ from the 2nd equation
* step 3.1: clean cell $a_{21}$
** already 0, continuing
* &lt;math&gt;\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; \boxed 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;, $\boxed 2$ is the 2nd pivot
* step 3.2
** &lt;math&gt;\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; \boxed 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix} \sim \begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; \boxed 2 &amp; -2\\ 
0 &amp; 0 &amp; \boxed 5
\end{bmatrix}&lt;/math&gt;
* &lt;math&gt;\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; \boxed 2 &amp; -2\\ 
0 &amp; 0 &amp; \boxed 5
\end{bmatrix}&lt;/math&gt;, $\boxed 5$ - it's 3rd pivot


The matrix is now in the upper-triangular form $U$


=== When does it fail? ===
Not always we are able to do the forward elimination

0 at a Pivot position:
* suppose the first pivot is 0:
* &lt;math&gt;\begin{bmatrix}
\boxed 0 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* But here it doesn't mean that we can't solve the system: we can switch the rows and continue:
* &lt;math&gt;\begin{bmatrix}
\boxed 3 &amp; 8 &amp; 1\\ 
0 &amp; 2 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* so, if there's a 0 at the pivot position, try to exchange rows
* if there's no rows with non-zero values at the pivot position - the elimination fails
** there's no solution to the system


=== Augmented Matrix === 
But we shouldn't forget about $\mathbf b$!
* $A$ augmented is &lt;math&gt;\begin{bmatrix}
\mathop{a_1}\limits_|^| \mathop{a_2}\limits_|^|  ...  \mathop{a_n}\limits_|^| \ \Bigg| \ \mathop{\mathbf b}\limits_|^| 
\end{bmatrix}&lt;/math&gt;: matrix $A$ with column $\mathbf b$ stacked to the right
* $A$ augmented: &lt;math&gt;\left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
3 &amp; 8 &amp; 1 &amp; 12\\ 
0 &amp; 4 &amp; 1 &amp; 2
\end{array}\right]&lt;/math&gt;
* the right part $\mathbf b$ also changes as we go through elimination
* &lt;math&gt;\left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
3 &amp; 8 &amp; 1 &amp; 12\\ 
0 &amp; 4 &amp; 1 &amp; 2
\end{array}\right] \to \left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
0 &amp; 2 &amp; -6 &amp; 6\\ 
0 &amp; 4 &amp; 1 &amp; 2
\end{array}\right] \to \left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
0 &amp; 2 &amp; -6 &amp; 6\\ 
0 &amp; 0 &amp; 5 &amp; -10
\end{array}\right]&lt;/math&gt;
* let $\mathbf c$ be the result of applying elimination to $\mathbf b$


=== Back Substitution ===
After we forward-eliminated variables of augmented $A$, we can do back substitution:
* Our matrix is 
&lt;math&gt;\left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
0 &amp; 2 &amp; -6 &amp; 6\\ 
0 &amp; 0 &amp; 5 &amp; -10
\end{array}\right]&lt;/math&gt;
* It means that our system is 


&lt;math&gt;\left\{\begin{array}{rl}
x + 2y + z &amp; = 2\\ 
2y - 2z &amp; = 6 \\ 
5z &amp; = -10
\end{array}\right.&lt;/math&gt;

Now we just go backwards and solve: first for $z$, then for $y$, and finally for $x$
* we get $z = -2, y = -1, x =2$
* it's easy to solve because the matrix is triangular


=== Elimination: Matrix Form ===
We can write these elimination steps in matrix form
* &lt;math&gt;\begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* the first step of the elimination was to take first and last rows unchanged, and subtract 3 times 1st row from the second. 
* Can we write it with [[Matrix Multiplication]]?
** &lt;math&gt;\begin{bmatrix}
1 &amp; 0 &amp; 0\\ 
? &amp; ? &amp; ?\\ 
0 &amp; 0 &amp; 1
\end{bmatrix} \times \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
** The first and last rows remain unchanged - hence we have &lt;math&gt;\begin{bmatrix}
1\\ 
?\\ 
0
\end{bmatrix}&lt;/math&gt; and &lt;math&gt;\begin{bmatrix}
0\\ 
?\\ 
1
\end{bmatrix}&lt;/math&gt;
** what should we put instead of $[? \ ? \ ?]$ so multiplication takes us from one matrix to another?
** &lt;math&gt;\begin{bmatrix}
1 &amp; 0 &amp; 0\\ 
\boxed{-3} &amp; 1 &amp; 0\\ 
0 &amp; 0 &amp; 1
\end{bmatrix}&lt;/math&gt;
** we want to subtract 3 times row 1 from row 2:
** &lt;math&gt;\begin{bmatrix}
1 &amp; 0 &amp; 0\\ 
\boxed{-3} &amp; 1 &amp; 0\\ 
0 &amp; 0 &amp; 1
\end{bmatrix} \times \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix} = \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
0 &amp; 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* let $E_{21}$ be the matrix that's used for step 2,1 of the elimination
** &lt;math&gt;E_{21} A = \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
0 &amp; 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* we continue this way until we transform $A$ to $U$
** so we have $E_{21} (E_{21} A) = U$ 
** or $\underbrace{(E_{21} E_{21})}_E A = EA = U $ 
** This a part of [[LU Factorization|$LU$ Factorization]]


What if we need to exchange rows? 
* use a [[Permutation Matrices|Permutation Matrix]]!
* in this case the correct solution is $E (PA) = U$



== See Also ==
* [[Inverse Matrices#Gauss-Jordan Elimination]]
* [[LU Factorization]]

== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Курош А.Г. Курс Высшей Алгебры

[[Category:Linear Algebra]]</text>
      <sha1>c2twrx0cw2fcy2ygucju964nh5w2zam</sha1>
    </revision>
    <revision>
      <id>775</id>
      <parentid>755</parentid>
      <timestamp>2017-06-14T20:49:28Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6961">== Gaussian Elimination ==
Gaussian Elimination or Row Reduction is a method for solving a [[System of Linear Equations]]
* it corresponds to elimination of variables in the system 
* if a matrix $A$ that we reduce is non-singular and invertible, then we always have a solution
* a by-product of Gaussian Elimination is [[LU Factorization]]


=== Row Elimination ===
* First, do the forward elimination to reduce the matrix to triangular 
* Then we do the back-substitution to find the solution
* When we multiply a row on some constant $c$ and subtract from any other row, we get an equivalent system


== Elimination by Example ==
We have the following system with 3 equations and 3 unknowns:

$\left\{\begin{array}{l}
x + 2y + z = 2\\ 
3x + 8y + z = 12 \\ 
4y + z = 2
\end{array}\right.$

Matrix form:
* &lt;math&gt;\underbrace{\begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}}_{A} \cdot \underbrace{\begin{bmatrix}
x \\ y \\ z
\end{bmatrix}}_{\mathbf x} = 
\underbrace{\begin{bmatrix}
2 \\ 12 \\ 2
\end{bmatrix}}_{\mathbf b}&lt;/math&gt;



=== Forward elimination ===
So, first let's see how elimination works 
* i.e. concentrate only on the matrix $A$
* &lt;math&gt;A = \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;


Let's proceed
* at each step
** multiply the $i$th equation by the right number and subtract it from the equations below
** s.t. there's 0 for the first column in all other rows
** so we want to knock out the $x_i$ part of the equation, or &quot;eliminate&quot; $x_i$
* &lt;math&gt;\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;. $\boxed 1$ is the 1st pivot 
* step 2.1: clean cell $a_{21}$:
** &lt;math&gt;\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix} \sim \begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* multiplying row 1 by 3 will knock out $x$ from the 2nd equation
* step 3.1: clean cell $a_{21}$
** already 0, continuing
* &lt;math&gt;\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; \boxed 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;, $\boxed 2$ is the 2nd pivot
* step 3.2
** &lt;math&gt;\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; \boxed 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix} \sim \begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; \boxed 2 &amp; -2\\ 
0 &amp; 0 &amp; \boxed 5
\end{bmatrix}&lt;/math&gt;
* &lt;math&gt;\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; \boxed 2 &amp; -2\\ 
0 &amp; 0 &amp; \boxed 5
\end{bmatrix}&lt;/math&gt;, $\boxed 5$ - it's 3rd pivot


The matrix is now in the upper-triangular form $U$


=== When does it fail? ===
Not always we are able to do the forward elimination

0 at a Pivot position:
* suppose the first pivot is 0:
* &lt;math&gt;\begin{bmatrix}
\boxed 0 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* But here it doesn't mean that we can't solve the system: we can switch the rows and continue:
* &lt;math&gt;\begin{bmatrix}
\boxed 3 &amp; 8 &amp; 1\\ 
0 &amp; 2 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* so, if there's a 0 at the pivot position, try to exchange rows
* if there's no rows with non-zero values at the pivot position - the elimination fails
** there's no solution to the system


=== Augmented Matrix === 
But we shouldn't forget about $\mathbf b$!
* $A$ augmented is &lt;math&gt;\begin{bmatrix}
\mathop{a_1}\limits_|^| \mathop{a_2}\limits_|^|  ...  \mathop{a_n}\limits_|^| \ \Bigg| \ \mathop{\mathbf b}\limits_|^| 
\end{bmatrix}&lt;/math&gt;: matrix $A$ with column $\mathbf b$ stacked to the right
* $A$ augmented: &lt;math&gt;\left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
3 &amp; 8 &amp; 1 &amp; 12\\ 
0 &amp; 4 &amp; 1 &amp; 2
\end{array}\right]&lt;/math&gt;
* the right part $\mathbf b$ also changes as we go through elimination
* &lt;math&gt;\left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
3 &amp; 8 &amp; 1 &amp; 12\\ 
0 &amp; 4 &amp; 1 &amp; 2
\end{array}\right] \to \left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
0 &amp; 2 &amp; -6 &amp; 6\\ 
0 &amp; 4 &amp; 1 &amp; 2
\end{array}\right] \to \left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
0 &amp; 2 &amp; -6 &amp; 6\\ 
0 &amp; 0 &amp; 5 &amp; -10
\end{array}\right]&lt;/math&gt;
* let $\mathbf c$ be the result of applying elimination to $\mathbf b$


=== Back Substitution ===
After we forward-eliminated variables of augmented $A$, we can do back substitution:
* Our matrix is 
&lt;math&gt;\left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
0 &amp; 2 &amp; -6 &amp; 6\\ 
0 &amp; 0 &amp; 5 &amp; -10
\end{array}\right]&lt;/math&gt;
* It means that our system is 


&lt;math&gt;\left\{\begin{array}{rl}
x + 2y + z &amp; = 2\\ 
2y - 2z &amp; = 6 \\ 
5z &amp; = -10
\end{array}\right.&lt;/math&gt;

Now we just go backwards and solve: first for $z$, then for $y$, and finally for $x$
* we get $z = -2, y = -1, x =2$
* it's easy to solve because the matrix is triangular


=== Elimination: Matrix Form ===
We can write these elimination steps in matrix form
* &lt;math&gt;\begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* the first step of the elimination was to take first and last rows unchanged, and subtract 3 times 1st row from the second. 
* Can we write it with [[Matrix Multiplication]]?
** &lt;math&gt;\begin{bmatrix}
1 &amp; 0 &amp; 0\\ 
? &amp; ? &amp; ?\\ 
0 &amp; 0 &amp; 1
\end{bmatrix} \times \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
** The first and last rows remain unchanged - hence we have &lt;math&gt;\begin{bmatrix}
1\\ 
?\\ 
0
\end{bmatrix}&lt;/math&gt; and &lt;math&gt;\begin{bmatrix}
0\\ 
?\\ 
1
\end{bmatrix}&lt;/math&gt;
** what should we put instead of $[? \ ? \ ?]$ so multiplication takes us from one matrix to another?
** &lt;math&gt;\begin{bmatrix}
1 &amp; 0 &amp; 0\\ 
\boxed{-3} &amp; 1 &amp; 0\\ 
0 &amp; 0 &amp; 1
\end{bmatrix}&lt;/math&gt;
** we want to subtract 3 times row 1 from row 2:
** &lt;math&gt;\begin{bmatrix}
1 &amp; 0 &amp; 0\\ 
\boxed{-3} &amp; 1 &amp; 0\\ 
0 &amp; 0 &amp; 1
\end{bmatrix} \times \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix} = \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
0 &amp; 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* let $E_{21}$ be the matrix that's used for step 2,1 of the elimination
** &lt;math&gt;E_{21} A = \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
0 &amp; 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* we continue this way until we transform $A$ to $U$
** so we have $E_{21} (E_{21} A) = U$ 
** or $\underbrace{(E_{21} E_{21})}_E A = EA = U $ 
** This a part of [[LU Factorization|$LU$ Factorization]]


What if we need to exchange rows? 
* use a [[Permutation Matrices|Permutation Matrix]]!
* in this case the correct solution is $E (PA) = U$

== Implementations ==
=== Python ===
Simple elimination with no permutation:

 
 A = np.array([[60, 91, 26], [60, 3, 75], [45, 90, 31]], dtype='float')
 b = np.array([1, 0, 0])
 
 Ab = np.hstack([A, b.reshape(-1, 1)])
 
 n = len(b)
 
 for i in range(n):
     a = Ab[i]
 
     for j in range(i + 1, n):
         b = Ab[j]
         m = a[i] / b[i]
         Ab[j] = a - m * b
 
 for i in range(n - 1, -1, -1):
     Ab[i] = Ab[i] / Ab[i, i]
     a = Ab[i]
 
     for j in range(i - 1, -1, -1):
         b = Ab[j]
         m = a[i] / b[i]
         Ab[j] = a - m * b
 
 x = Ab[:, 3]


== See Also ==
* [[Inverse Matrices#Gauss-Jordan Elimination]]
* [[LU Factorization]]

== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Курош А.Г. Курс Высшей Алгебры

[[Category:Linear Algebra]]</text>
      <sha1>t2a91lfobehpm1v9ydf8buxpachrsym</sha1>
    </revision>
    <revision>
      <id>817</id>
      <parentid>775</parentid>
      <timestamp>2018-04-21T10:51:40Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6961">== Gaussian Elimination ==
Gaussian Elimination or Row Reduction is a method for solving a [[System of Linear Equations]]
* it corresponds to elimination of variables in the system 
* if a matrix $A$ that we reduce is non-singular and invertible, then we always have a solution
* a by-product of Gaussian Elimination is [[LU Factorization]]


=== Row Elimination ===
* First, do the forward elimination to reduce the matrix to triangular 
* Then we do the back-substitution to find the solution
* When we multiply a row on some constant $c$ and subtract from any other row, we get an equivalent system


== Elimination by Example ==
We have the following system with 3 equations and 3 unknowns:

$\left\{\begin{array}{l}
x + 2y + z = 2\\ 
3x + 8y + z = 12 \\ 
4y + z = 2
\end{array}\right.$

Matrix form:
* &lt;math&gt;\underbrace{\begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}}_{A} \cdot \underbrace{\begin{bmatrix}
x \\ y \\ z
\end{bmatrix}}_{\mathbf x} = 
\underbrace{\begin{bmatrix}
2 \\ 12 \\ 2
\end{bmatrix}}_{\mathbf b}&lt;/math&gt;



=== Forward elimination ===
So, first let's see how elimination works 
* i.e. concentrate only on the matrix $A$
* &lt;math&gt;A = \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;


Let's proceed
* at each step
** multiply the $i$th equation by the right number and subtract it from the equations below
** s.t. there's 0 for the first column in all other rows
** so we want to knock out the $x_i$ part of the equation, or &quot;eliminate&quot; $x_i$
* &lt;math&gt;\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;. $\boxed 1$ is the 1st pivot 
* step 2.1: clean cell $a_{21}$:
** &lt;math&gt;\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix} \sim \begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* multiplying row 1 by 3 will knock out $x$ from the 2nd equation
* step 3.1: clean cell $a_{21}$
** already 0, continuing
* &lt;math&gt;\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; \boxed 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;, $\boxed 2$ is the 2nd pivot
* step 3.2
** &lt;math&gt;\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; \boxed 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix} \sim \begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; \boxed 2 &amp; -2\\ 
0 &amp; 0 &amp; \boxed 5
\end{bmatrix}&lt;/math&gt;
* &lt;math&gt;\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 1\\ 
0 &amp; \boxed 2 &amp; -2\\ 
0 &amp; 0 &amp; \boxed 5
\end{bmatrix}&lt;/math&gt;, $\boxed 5$ - it's 3rd pivot


The matrix is now in the upper-triangular form $U$


=== When does it fail? ===
Not always we are able to do the forward elimination

0 at a Pivot position:
* suppose the first pivot is 0:
* &lt;math&gt;\begin{bmatrix}
\boxed 0 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* But here it doesn't mean that we can't solve the system: we can switch the rows and continue:
* &lt;math&gt;\begin{bmatrix}
\boxed 3 &amp; 8 &amp; 1\\ 
0 &amp; 2 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* so, if there's a 0 at the pivot position, try to exchange rows
* if there's no rows with non-zero values at the pivot position - the elimination fails
** there's no solution to the system


=== Augmented Matrix === 
But we shouldn't forget about $\mathbf b$!
* $A$ augmented is &lt;math&gt;\begin{bmatrix}
\mathop{a_1}\limits_|^| \mathop{a_2}\limits_|^|  ...  \mathop{a_n}\limits_|^| \ \Bigg| \ \mathop{\mathbf b}\limits_|^| 
\end{bmatrix}&lt;/math&gt;: matrix $A$ with column $\mathbf b$ stacked to the right
* $A$ augmented: &lt;math&gt;\left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
3 &amp; 8 &amp; 1 &amp; 12\\ 
0 &amp; 4 &amp; 1 &amp; 2
\end{array}\right]&lt;/math&gt;
* the right part $\mathbf b$ also changes as we go through elimination
* &lt;math&gt;\left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
3 &amp; 8 &amp; 1 &amp; 12\\ 
0 &amp; 4 &amp; 1 &amp; 2
\end{array}\right] \to \left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
0 &amp; 2 &amp; -2 &amp; 6\\ 
0 &amp; 4 &amp; 1 &amp; 2
\end{array}\right] \to \left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
0 &amp; 2 &amp; -2 &amp; 6\\ 
0 &amp; 0 &amp; 5 &amp; -10
\end{array}\right]&lt;/math&gt;
* let $\mathbf c$ be the result of applying elimination to $\mathbf b$


=== Back Substitution ===
After we forward-eliminated variables of augmented $A$, we can do back substitution:
* Our matrix is 
&lt;math&gt;\left[\begin{array}{ccc|c}
1 &amp; 2 &amp; 1 &amp; 2\\ 
0 &amp; 2 &amp; -6 &amp; 6\\ 
0 &amp; 0 &amp; 5 &amp; -10
\end{array}\right]&lt;/math&gt;
* It means that our system is 


&lt;math&gt;\left\{\begin{array}{rl}
x + 2y + z &amp; = 2\\ 
2y - 2z &amp; = 6 \\ 
5z &amp; = -10
\end{array}\right.&lt;/math&gt;

Now we just go backwards and solve: first for $z$, then for $y$, and finally for $x$
* we get $z = -2, y = -1, x =2$
* it's easy to solve because the matrix is triangular


=== Elimination: Matrix Form ===
We can write these elimination steps in matrix form
* &lt;math&gt;\begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* the first step of the elimination was to take first and last rows unchanged, and subtract 3 times 1st row from the second. 
* Can we write it with [[Matrix Multiplication]]?
** &lt;math&gt;\begin{bmatrix}
1 &amp; 0 &amp; 0\\ 
? &amp; ? &amp; ?\\ 
0 &amp; 0 &amp; 1
\end{bmatrix} \times \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
** The first and last rows remain unchanged - hence we have &lt;math&gt;\begin{bmatrix}
1\\ 
?\\ 
0
\end{bmatrix}&lt;/math&gt; and &lt;math&gt;\begin{bmatrix}
0\\ 
?\\ 
1
\end{bmatrix}&lt;/math&gt;
** what should we put instead of $[? \ ? \ ?]$ so multiplication takes us from one matrix to another?
** &lt;math&gt;\begin{bmatrix}
1 &amp; 0 &amp; 0\\ 
\boxed{-3} &amp; 1 &amp; 0\\ 
0 &amp; 0 &amp; 1
\end{bmatrix}&lt;/math&gt;
** we want to subtract 3 times row 1 from row 2:
** &lt;math&gt;\begin{bmatrix}
1 &amp; 0 &amp; 0\\ 
\boxed{-3} &amp; 1 &amp; 0\\ 
0 &amp; 0 &amp; 1
\end{bmatrix} \times \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
3 &amp; 8 &amp; 1\\ 
0 &amp; 4 &amp; 1
\end{bmatrix} = \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
0 &amp; 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* let $E_{21}$ be the matrix that's used for step 2,1 of the elimination
** &lt;math&gt;E_{21} A = \begin{bmatrix}
1 &amp; 2 &amp; 1\\ 
0 &amp; 2 &amp; -2\\ 
0 &amp; 4 &amp; 1
\end{bmatrix}&lt;/math&gt;
* we continue this way until we transform $A$ to $U$
** so we have $E_{21} (E_{21} A) = U$ 
** or $\underbrace{(E_{21} E_{21})}_E A = EA = U $ 
** This a part of [[LU Factorization|$LU$ Factorization]]


What if we need to exchange rows? 
* use a [[Permutation Matrices|Permutation Matrix]]!
* in this case the correct solution is $E (PA) = U$

== Implementations ==
=== Python ===
Simple elimination with no permutation:

 
 A = np.array([[60, 91, 26], [60, 3, 75], [45, 90, 31]], dtype='float')
 b = np.array([1, 0, 0])
 
 Ab = np.hstack([A, b.reshape(-1, 1)])
 
 n = len(b)
 
 for i in range(n):
     a = Ab[i]
 
     for j in range(i + 1, n):
         b = Ab[j]
         m = a[i] / b[i]
         Ab[j] = a - m * b
 
 for i in range(n - 1, -1, -1):
     Ab[i] = Ab[i] / Ab[i, i]
     a = Ab[i]
 
     for j in range(i - 1, -1, -1):
         b = Ab[j]
         m = a[i] / b[i]
         Ab[j] = a - m * b
 
 x = Ab[:, 3]


== See Also ==
* [[Inverse Matrices#Gauss-Jordan Elimination]]
* [[LU Factorization]]

== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Курош А.Г. Курс Высшей Алгебры

[[Category:Linear Algebra]]</text>
      <sha1>lqxueyt3yxp01c0w4bvbrueff460mq7</sha1>
    </revision>
  </page>
  <page>
    <title>Permutation Matrices</title>
    <ns>0</ns>
    <id>511</id>
    <revision>
      <id>514</id>
      <timestamp>2014-12-12T14:12:00Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2146">== Permutation Matrix ==
A [[Matrix]] that exchanges 2 or more rows is called a ''permutation matrix'' 
* a permutation matrix $P$ is a matrix that is obtained by permuting rows/columns of identity matrix $I$
* this is an important type of matrices - it's used for solving [[System of Linear Equations]] and for [[LU Factorization]]
* e.g. for [[Gaussian Elimination]] when we have a zero in the pivot position, we would like to exchange this to get non-zero pivot - this is done with a Permutation Matrix


=== $P$ for Square Matrices ===
Suppose we have a $3 \times 3$ matrix $A$ and we want to permute it's rows

Let's list all possible permutation matrices for $3 \times 3$
* $\begin{bmatrix}
1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 1\\
\end{bmatrix}$ - permutes nothing
* $\begin{bmatrix}
0 &amp; 1 &amp; 0\\
1 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 1
\end{bmatrix}$ - permutes 1st and 2nd rows
* $\begin{bmatrix}
0 &amp; 0 &amp; 1\\
0 &amp; 1 &amp; 0\\
1 &amp; 0 &amp; 0\\
\end{bmatrix}$ - 1st and 3rd
* $\begin{bmatrix}
1 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 1\\
0 &amp; 1 &amp; 0\\
\end{bmatrix}$ - 2nd and 3rd
* $\begin{bmatrix}
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 1\\
1 &amp; 0 &amp; 0\\
\end{bmatrix}$ - 2nd, 3rd and 1st
* $\begin{bmatrix}
0 &amp; 0 &amp; 1\\
1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
\end{bmatrix}$ - 3, 1, 2


=== [[Permutations]] ===
In how many ways we can permute rows of $I_n$?
* it's the number of permutations of $n$: $n!$


== Types ==
=== Row Exchange ===
$\begin{bmatrix}
0 &amp; 1\\
1 &amp; 0
\end{bmatrix} \times \begin{bmatrix}
a &amp; b\\
c &amp; d
\end{bmatrix} = \begin{bmatrix}
c &amp; d\\
a &amp; b
\end{bmatrix}$


=== Column Exchange ===
What if we want to exchange columns? 

$\left[ \; \; \LARGE ? \; \; \;  \right] \times 
\begin{bmatrix}
a &amp; b\\
c &amp; d
\end{bmatrix} = \begin{bmatrix}
b &amp; a\\
d &amp; c
\end{bmatrix}$


Can't put such a matrix on the left! Put in on the right instead

$\begin{bmatrix}
a &amp; b\\
c &amp; d
\end{bmatrix} \times 
\begin{bmatrix}
0 &amp; 1\\
1 &amp; 0
\end{bmatrix}
= \begin{bmatrix}
b &amp; a\\
d &amp; c
\end{bmatrix}$


== Properties ==
* When we transpose $P$ or inverse, the obtained matrix is also a permutation matrix 
* $P^{-1} = P^T$
* thus $P^T P = P P^T = I$


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>hatzflnpmugg1lkpyh8wy7eddhml36n</sha1>
    </revision>
  </page>
  <page>
    <title>LU Factorization</title>
    <ns>0</ns>
    <id>512</id>
    <redirect title="LU Decomposition" />
    <revision>
      <id>515</id>
      <timestamp>2015-04-23T16:31:08Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="30">#REDIRECT [[LU Decomposition]]</text>
      <sha1>gbwf6g2lm95zeekofrembq1afpgea7o</sha1>
    </revision>
  </page>
  <page>
    <title>System of Linear Equations</title>
    <ns>0</ns>
    <id>513</id>
    <revision>
      <id>516</id>
      <timestamp>2014-12-18T21:21:23Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7762">== System of Linear Equations ==
The fundamental problem of [[Linear Algebra]] is solving a system of Linear Equations.
* A system of linear equations is a system of first order equations with multiple unknowns. 


== $A \mathbf x = \mathbf b$ ==
=== Matrix View ===
Suppose we have a system with $m$ equations and $n$ unknowns:

$\left\{\begin{matrix}
a_{11} x_1 + a_{12} x_2 + \ ... \ + a_{1n} x_n = b_1\\ 
a_{21} x_1 + a_{22} x_2 + \ ... \ + a_{2n} x_n = b_2\\ 
\vdots \\
a_{m1} x_1 + a_{22} x_2 + \ ... \ + a_{mn} x_n = b_m\\ 
\end{matrix}\right.$


The coefficients of the unknowns form a [[Matrix]] - a rectangular array of numbers:
* $A = \begin{bmatrix}
a_{11} &amp; a_{12} &amp; ... &amp; a_{1n}\\ 
a_{21} &amp; a_{22} &amp; ... &amp; a_{2n}\\ 
\vdots &amp; \vdots &amp;  \vdots &amp; \vdots \\ 
a_{m1} &amp; a_{m2} &amp; ... &amp; a_{mn}
\end{bmatrix}$
* We call this matrix $A$, it's $m \times n$ matrix: with $m$ rows and $n$ columns


The unknowns themselves form a column vector $\mathbf{x}$, and the ... form a column vector $b$
* $\mathbf{x} = \begin{bmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n \\
\end{bmatrix}$, $\mathbf{b} = \begin{bmatrix}
b_1 \\
b_2 \\
\vdots \\
b_m \\
\end{bmatrix}$, 
* they're both column vectors, $\mathbf{x}$ has size $n$, and $\mathbf{b}$ has size $m$ 
* can write them as rows using the transposition notation: $\mathbf{x} = [x_1, x_2, ..., x_n]^T$ (but they still remain column vectors)


So the system of linear equations can be expressed in a matrix form as $A\mathbf{x} = \mathbf{b}$



== Geometry of Linear Equations ==
Suppose we have the following system of linear equations:

$\left\{\begin{matrix}
2x - y = 0\\ 
-x + 2y = 3
\end{matrix}\right.$

Matrix form:
* $\begin{bmatrix}
2 &amp; -1 \\ 
-1 &amp; 2 
\end{bmatrix} \begin{bmatrix}
x \\ y  
\end{bmatrix} = \begin{bmatrix}
0 \\ 
3  
\end{bmatrix}$

We can see this in two possible ways: 
* as a crossing of lines (hyperplanes) - the row picture
* as vectors - the column picture


=== Row Picture ===
We have two lines: 
* $2x - y = 0$, $-x + 2y = 3$
* plot them, and the point where they cross is the solution $\mathbf{x}$ 

http://habrastorage.org/files/124/fc0/33a/124fc033acc3431f92e7749f19484e6e.png

The solution is $[x, y]^T = [1, 2]^T$

For 3 and more dimensions, we have (hyper)planes instead of lines. 
* But it's the same: we want to find a point where they cross
* [[File:Secretsharing_3-point.svg]]


=== Column Picture ===
We have two vectors: 
* $x \begin{bmatrix}
2 \\ 
-1  
\end{bmatrix} + y \begin{bmatrix}
-1 \\ 
2 
\end{bmatrix} = \begin{bmatrix}
0 \\ 
3 
\end{bmatrix}$

We need to combine first two vectors $v = \begin{bmatrix}
2 \\ 
-1 
\end{bmatrix}$ and $u = \begin{bmatrix}
-1 \\ 
2 
\end{bmatrix}$ so they form $\begin{bmatrix}
0 \\ 
3 
\end{bmatrix}$ 


I.e. we want to find a [[Linear Combination]] of these columns.
* From the vector picture we know that the solution is $[1, 2]^T$, so let's take 
* http://habrastorage.org/files/b17/368/e5e/b17368e5e7774f8ca58e054c7b98183e.png
* so we take 1 of vector $\mathbf u$ and 2 of vector $\mathbf v$ and end up at exactly $\mathbf b$!



=== Python Code ===
{{ Hider | 
   title=Python code to reproduce the figures |
   content=
&lt;pre&gt;
import matplotlib.pylab as plt
import numpy as np

class Line:
    def __init__(self, slope, intercept):
        self.slope = slope
        self.intercept = intercept

    def calculate(self, x1):
        x2 = x1 * self.slope + self.intercept
        return x2

line1 = Line(2, 0)
line2 = Line(0.5, 1.5)

a = np.array([-6, 6])
plt.plot(a, line1.calculate(a), color='red', marker='')
plt.plot(a, line2.calculate(a), color='blue', marker='')
plt.scatter([1], [2])
plt.grid()
plt.axis('equal')
plt.ylim([-1, 3])
plt.xlim([-1, 3])
&lt;/pre&gt;


&lt;pre&gt;
import matplotlib.pylab as plt

plt.axis('equal')
plt.quiver([0, 0, 0], [0, 0, 0], 
           [-1, 2, 0], [2, -1, 3], color=['red', 'blue', 'black'], 
           angles='xy', 
           scale_units='xy', scale=1)
plt.quiver([2], [-1], 
           [-2], [4], color='red', width=0.005, scale=1,
           angles='xy', scale_units='xy')
plt.grid()
plt.ylim([-2, 5])
plt.xlim([-4, 4])
plt.show()
&lt;/pre&gt;
}}


== Solving the System ==
How we can solve the system $A \mathbf x = \mathbf b$?
* The easiest way: [[Gaussian Elimination]] - elimination of variables
* this is the row picture 

Vector Solution: the solution found with the column picture 


Matrix Solution
* if $A$ is non-singular and invertible, then to find $\mathbf x$ multiply $\mathbf b$ by the [[Inverse Matrices|inverse]] of $A$: $\mathbf x = A^{-1} \mathbf b$
* if $\mathbf b \in C(A)$ - [[Column Space]] of $A$ 
** this is especially important when the number of columns $n$ is less than the number of rows $m$


=== Solving $A \mathbf x = \mathbf 0$ ===
Such systems are called ''homogeneous'' - see [[Homogeneous Systems of Linear Equations]]


=== Complete Solution to $A \mathbf x = \mathbf b$ ===
Let $A$ be $n \times m$ matrix of rank $r$
* we know that the system has a solution if $\mathbf b \in C(A)$


Steps:
* reduce $A$ to [[Row Reduced Echelon Form]]
* set all free variables to 0 and solve - get $\textbf x_p = \textbf x_\text{particular}$ 
* then solve $A \mathbf x_n = \mathbf 0$ - get all $\mathbf x_n$ - all $\mathbf x$ that solve the homogeneous system
* Then find all other solutions: they are $\mathbf x = \textbf x_p + \mathbf x_n$
* this solution is called ''the complete solution''
* why? $A \mathbf x_p = \mathbf b$ and $A \mathbf x_n = \mathbf 0$. Add them and get $A \cdot (\mathbf x_p + \mathbf x_n) = \mathbf b + \mathbf 0 = \mathbf b$
* so we can the solution as the Nullspace $C(A)$ but shifted away from the origin by $x_p$ 
* note that this solution doesn't form a subspace


== General Case, $A \mathbf x = \mathbf b$ ==
Let $A$ be $m \times n$ matrix of rank $r$
* $m$ - rows, $n$ - cols
* $r \leqslant m$, $r \leqslant n$


=== Full Column Rank ===
Full rank = $r$ is as big as it can be
* suppose that $n \leqslant m$, i.e. the number of columns is smaller than the number of rows
* so full column rank matrix = $r = n$
* there's a pivot in every column, $n$ pivots $\Rightarrow$ no free variables

http://habrastorage.org/files/765/fc6/d10/765fc6d1001040cd977ae72c239a1430.png


Nullspace $N(A)$?
* there are no free variables to consider 
* so $N(A) = \{ \ \mathbf 0 \ \}$

Solution to $A \mathbf x = \mathbf b$:
* if the solution exists (i.e. $\mathbf b \in C(A)$) then this solution is unique
* so we have either 0 solutions or 1 
* No solution? Can approximate it with [[Normal Equation]] (That would be the Least Squares solution)


=== Full Row Rank ===
* Now suppose that $m \leqslant n$ and $r = m$ 
* so every row has a pivot, but only $r$ columns have pivots, the remaining $n - r$ don't
* so there are $r$ pivot columns, and $n - r$ free columns

http://habrastorage.org/files/67d/5e5/d6f/67d5e5d6f8424d0ebd2ec310c4ed8ef4.png


for which $\mathbf b$ we can solve $A \mathbf x = \mathbf b$?
* there are no zero rows, so can solve the system for any $\mathbf b$ 


=== Full Rank ===
* If our $A$ is square, $m = n = r$
* then there's always a solution, and $A$ is called ''invertible''
* $N(A) = \{ \ \mathbf 0 \ \}$ - there's only one unique solution


=== $r &lt; m$ and $r &lt; n$ === 
http://habrastorage.org/files/d2a/f16/064/d2af160643b24017846c05381c600fe6.png

* $A \mathbf x = \mathbf 0$ always have a solution - there's always something in the [[Nullspace]] $N(A)$ of $A$ apart from the zero-vector
* reason: there are always free variables and we can assign any non-zero values to them and solve the homogeneous system


Zero or $\infty$ solutions



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Курош А.Г. Курс Высшей Алгебры
* http://en.wikipedia.org/wiki/System_of_linear_equations

[[Category:Linear Algebra]]</text>
      <sha1>smf7i6dpszc40qpacw0rg702twxpqgq</sha1>
    </revision>
    <revision>
      <id>795</id>
      <parentid>516</parentid>
      <timestamp>2017-06-27T12:06:37Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8388">== System of Linear Equations ==
The fundamental problem of [[Linear Algebra]] is solving a system of Linear Equations.
* A system of linear equations is a system of first order equations with multiple unknowns. 


== $A \mathbf x = \mathbf b$ ==
=== Matrix View ===
Suppose we have a system with $m$ equations and $n$ unknowns:

$\left\{\begin{matrix}
a_{11} x_1 + a_{12} x_2 + \ ... \ + a_{1n} x_n = b_1\\ 
a_{21} x_1 + a_{22} x_2 + \ ... \ + a_{2n} x_n = b_2\\ 
\vdots \\
a_{m1} x_1 + a_{22} x_2 + \ ... \ + a_{mn} x_n = b_m\\ 
\end{matrix}\right.$


The coefficients of the unknowns form a [[Matrix]] - a rectangular array of numbers:
* &lt;math&gt;A = \begin{bmatrix}
a_{11} &amp; a_{12} &amp; ... &amp; a_{1n}\\ 
a_{21} &amp; a_{22} &amp; ... &amp; a_{2n}\\ 
\vdots &amp; \vdots &amp;  \vdots &amp; \vdots \\ 
a_{m1} &amp; a_{m2} &amp; ... &amp; a_{mn}
\end{bmatrix}&lt;/math&gt;
* We call this matrix $A$, it's $m \times n$ matrix: with $m$ rows and $n$ columns


The unknowns themselves form a column vector $\mathbf{x}$, and the ... form a column vector $b$
* &lt;math&gt;\mathbf{x} = \begin{bmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n \\
\end{bmatrix}&lt;/math&gt;, &lt;math&gt;\mathbf{b} = \begin{bmatrix}
b_1 \\
b_2 \\
\vdots \\
b_m \\
\end{bmatrix}&lt;/math&gt;, 
* they're both column vectors, $\mathbf{x}$ has size $n$, and $\mathbf{b}$ has size $m$ 
* can write them as rows using the transposition notation: $\mathbf{x} = [x_1, x_2, ..., x_n]^T$ (but they still remain column vectors)


So the system of linear equations can be expressed in a matrix form as $A\mathbf{x} = \mathbf{b}$



== Geometry of Linear Equations ==
Suppose we have the following system of linear equations:

$\left\{\begin{matrix}
2x - y = 0\\ 
-x + 2y = 3
\end{matrix}\right.$

Matrix form:
* &lt;math&gt;\begin{bmatrix}
2 &amp; -1 \\ 
-1 &amp; 2 
\end{bmatrix} \begin{bmatrix}
x \\ y  
\end{bmatrix} = \begin{bmatrix}
0 \\ 
3  
\end{bmatrix}&lt;/math&gt;

We can see this in two possible ways: 
* as a crossing of lines (hyperplanes) - the row picture
* as vectors - the column picture


=== Row Picture ===
We have two lines: 
* $2x - y = 0$, $-x + 2y = 3$
* plot them, and the point where they cross is the solution $\mathbf{x}$ 

http://habrastorage.org/files/124/fc0/33a/124fc033acc3431f92e7749f19484e6e.png

The solution is $[x, y]^T = [1, 2]^T$

For 3 and more dimensions, we have (hyper)planes instead of lines. 
* But it's the same: we want to find a point where they cross
* [[File:Secretsharing_3-point.svg]]


=== Column Picture ===
We have two vectors: 
* &lt;math&gt;x \begin{bmatrix}
2 \\ 
-1  
\end{bmatrix} + y \begin{bmatrix}
-1 \\ 
2 
\end{bmatrix} = \begin{bmatrix}
0 \\ 
3 
\end{bmatrix}&lt;/math&gt;

We need to combine first two vectors &lt;math&gt;v = \begin{bmatrix}
2 \\ 
-1 
\end{bmatrix}&lt;/math&gt; and &lt;math&gt;u = \begin{bmatrix}
-1 \\ 
2 
\end{bmatrix}&lt;/math&gt; so they form &lt;math&gt;\begin{bmatrix}
0 \\ 
3 
\end{bmatrix}&lt;/math&gt;


I.e. we want to find a [[Linear Combination]] of these columns.
* From the vector picture we know that the solution is $[1, 2]^T$, so let's take 
* http://habrastorage.org/files/b17/368/e5e/b17368e5e7774f8ca58e054c7b98183e.png
* so we take 1 of vector $\mathbf u$ and 2 of vector $\mathbf v$ and end up at exactly $\mathbf b$!



=== Python Code ===
{{ Hider | 
   title=Python code to reproduce the figures |
   content=
&lt;pre&gt;
import matplotlib.pylab as plt
import numpy as np

class Line:
    def __init__(self, slope, intercept):
        self.slope = slope
        self.intercept = intercept

    def calculate(self, x1):
        x2 = x1 * self.slope + self.intercept
        return x2

line1 = Line(2, 0)
line2 = Line(0.5, 1.5)

a = np.array([-6, 6])
plt.plot(a, line1.calculate(a), color='red', marker='')
plt.plot(a, line2.calculate(a), color='blue', marker='')
plt.scatter([1], [2])
plt.grid()
plt.axis('equal')
plt.ylim([-1, 3])
plt.xlim([-1, 3])
&lt;/pre&gt;


&lt;pre&gt;
import matplotlib.pylab as plt

plt.axis('equal')
plt.quiver([0, 0, 0], [0, 0, 0], 
           [-1, 2, 0], [2, -1, 3], color=['red', 'blue', 'black'], 
           angles='xy', 
           scale_units='xy', scale=1)
plt.quiver([2], [-1], 
           [-2], [4], color='red', width=0.005, scale=1,
           angles='xy', scale_units='xy')
plt.grid()
plt.ylim([-2, 5])
plt.xlim([-4, 4])
plt.show()
&lt;/pre&gt;
}}


== Solving the System ==
How we can solve the system $A \mathbf x = \mathbf b$?
* The easiest way: [[Gaussian Elimination]] - elimination of variables
* this is the row picture 

Vector Solution: the solution found with the column picture 


Matrix Solution
* if $A$ is non-singular and invertible, then to find $\mathbf x$ multiply $\mathbf b$ by the [[Inverse Matrices|inverse]] of $A$: $\mathbf x = A^{-1} \mathbf b$
* if $\mathbf b \in C(A)$ - [[Column Space]] of $A$ 
** this is especially important when the number of columns $n$ is less than the number of rows $m$


=== Solving $A \mathbf x = \mathbf 0$ ===
Such systems are called ''homogeneous'' - see [[Homogeneous Systems of Linear Equations]]


=== Complete Solution to $A \mathbf x = \mathbf b$ ===
Let $A$ be $n \times m$ matrix of rank $r$
* we know that the system has a solution if $\mathbf b \in C(A)$


Steps:
* reduce $A$ to [[Row Reduced Echelon Form]]
* set all free variables to 0 and solve - get $\textbf x_p = \textbf x_\text{particular}$ 
* then solve $A \mathbf x_n = \mathbf 0$ - get all $\mathbf x_n$ - all $\mathbf x$ that solve the homogeneous system
* Then find all other solutions: they are $\mathbf x = \textbf x_p + \mathbf x_n$
* this solution is called ''the complete solution''
* why? $A \mathbf x_p = \mathbf b$ and $A \mathbf x_n = \mathbf 0$. Add them and get $A \cdot (\mathbf x_p + \mathbf x_n) = \mathbf b + \mathbf 0 = \mathbf b$
* so we can the solution as the Nullspace $C(A)$ but shifted away from the origin by $x_p$ 
* note that this solution doesn't form a subspace



== General Case, $A \mathbf x = \mathbf b$ ==
Let $A$ be $m \times n$ matrix of rank $r$
* $m$ - rows, $n$ - cols
* $r \leqslant m$, $r \leqslant n$


=== Full Column Rank ===
Full rank = $r$ is as big as it can be
* suppose that $n \leqslant m$, i.e. the number of columns is smaller than the number of rows
* so full column rank matrix = $r = n$
* there's a pivot in every column, $n$ pivots $\Rightarrow$ no free variables

http://habrastorage.org/files/765/fc6/d10/765fc6d1001040cd977ae72c239a1430.png


Nullspace $N(A)$?
* there are no free variables to consider 
* so $N(A) = \{ \ \mathbf 0 \ \}$

Solution to $A \mathbf x = \mathbf b$:
* if the solution exists (i.e. $\mathbf b \in C(A)$) then this solution is unique
* so we have either 0 solutions or 1


=== [[Gauss Elimination]] and [[LU Decomposition]] ===
Solving $A\mathbf x = \mathbf b$
* As metioned earlier - need to reduce it to RREF
* Can do that with Gaussian Elimination via LU Decomposition
* Let $LU = A$
* then $A \mathbf x = \mathbf b$ becomes $LU \mathbf x = \mathbf b$
* Now let $U \mathbf x = \mathbf y$ and $L \mathbf y = \mathbf x$
* With this substitution we need to solve two equations now, but they are simple because $L$ is lower-diagonal and $U$ is upper-diagonal 



=== No Solution ===
No solution?
* Can approximate it with [[Normal Equation]] 
* That would be the [[Ordinary Least Squares|Least Squares]] solution


=== Full Row Rank ===
* Now suppose that $m \leqslant n$ and $r = m$ 
* so every row has a pivot, but only $r$ columns have pivots, the remaining $n - r$ don't
* so there are $r$ pivot columns, and $n - r$ free columns

http://habrastorage.org/files/67d/5e5/d6f/67d5e5d6f8424d0ebd2ec310c4ed8ef4.png


for which $\mathbf b$ we can solve $A \mathbf x = \mathbf b$?
* there are no zero rows, so can solve the system for any $\mathbf b$ 


=== Full Rank ===
* If our $A$ is square, $m = n = r$
* then there's always a solution, and $A$ is called ''invertible''
* $N(A) = \{ \ \mathbf 0 \ \}$ - there's only one unique solution


=== $r &lt; m$ and $r &lt; n$ === 
http://habrastorage.org/files/d2a/f16/064/d2af160643b24017846c05381c600fe6.png

* $A \mathbf x = \mathbf 0$ always have a solution - there's always something in the [[Nullspace]] $N(A)$ of $A$ apart from the zero-vector
* reason: there are always free variables and we can assign any non-zero values to them and solve the homogeneous system


Zero or $\infty$ solutions



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Курош А.Г. Курс Высшей Алгебры
* http://en.wikipedia.org/wiki/System_of_linear_equations

[[Category:Linear Algebra]]</text>
      <sha1>narii9ns89s3zrqdxxqfhfcxq0o2mm0</sha1>
    </revision>
    <revision>
      <id>799</id>
      <parentid>795</parentid>
      <timestamp>2017-06-27T12:20:33Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8391">== System of Linear Equations ==
The fundamental problem of [[Linear Algebra]] is solving a system of Linear Equations.
* A system of linear equations is a system of first order equations with multiple unknowns. 


== $A \mathbf x = \mathbf b$ ==
=== Matrix View ===
Suppose we have a system with $m$ equations and $n$ unknowns:

$\left\{\begin{matrix}
a_{11} x_1 + a_{12} x_2 + \ ... \ + a_{1n} x_n = b_1\\ 
a_{21} x_1 + a_{22} x_2 + \ ... \ + a_{2n} x_n = b_2\\ 
\vdots \\
a_{m1} x_1 + a_{22} x_2 + \ ... \ + a_{mn} x_n = b_m\\ 
\end{matrix}\right.$


The coefficients of the unknowns form a [[Matrix]] - a rectangular array of numbers:
* &lt;math&gt;A = \begin{bmatrix}
a_{11} &amp; a_{12} &amp; ... &amp; a_{1n}\\ 
a_{21} &amp; a_{22} &amp; ... &amp; a_{2n}\\ 
\vdots &amp; \vdots &amp;  \vdots &amp; \vdots \\ 
a_{m1} &amp; a_{m2} &amp; ... &amp; a_{mn}
\end{bmatrix}&lt;/math&gt;
* We call this matrix $A$, it's $m \times n$ matrix: with $m$ rows and $n$ columns


The unknowns themselves form a column vector $\mathbf{x}$, and the ... form a column vector $b$
* &lt;math&gt;\mathbf{x} = \begin{bmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n \\
\end{bmatrix}&lt;/math&gt;, &lt;math&gt;\mathbf{b} = \begin{bmatrix}
b_1 \\
b_2 \\
\vdots \\
b_m \\
\end{bmatrix}&lt;/math&gt;, 
* they're both column vectors, $\mathbf{x}$ has size $n$, and $\mathbf{b}$ has size $m$ 
* can write them as rows using the transposition notation: $\mathbf{x} = [x_1, x_2, ..., x_n]^T$ (but they still remain column vectors)


So the system of linear equations can be expressed in a matrix form as $A\mathbf{x} = \mathbf{b}$



== Geometry of Linear Equations ==
Suppose we have the following system of linear equations:

$\left\{\begin{matrix}
2x - y = 0\\ 
-x + 2y = 3
\end{matrix}\right.$

Matrix form:
* &lt;math&gt;\begin{bmatrix}
2 &amp; -1 \\ 
-1 &amp; 2 
\end{bmatrix} \begin{bmatrix}
x \\ y  
\end{bmatrix} = \begin{bmatrix}
0 \\ 
3  
\end{bmatrix}&lt;/math&gt;

We can see this in two possible ways: 
* as a crossing of lines (hyperplanes) - the row picture
* as vectors - the column picture


=== Row Picture ===
We have two lines: 
* $2x - y = 0$, $-x + 2y = 3$
* plot them, and the point where they cross is the solution $\mathbf{x}$ 

http://habrastorage.org/files/124/fc0/33a/124fc033acc3431f92e7749f19484e6e.png

The solution is $[x, y]^T = [1, 2]^T$

For 3 and more dimensions, we have (hyper)planes instead of lines. 
* But it's the same: we want to find a point where they cross
* [[File:Secretsharing_3-point.svg]]


=== Column Picture ===
We have two vectors: 
* &lt;math&gt;x \begin{bmatrix}
2 \\ 
-1  
\end{bmatrix} + y \begin{bmatrix}
-1 \\ 
2 
\end{bmatrix} = \begin{bmatrix}
0 \\ 
3 
\end{bmatrix}&lt;/math&gt;

We need to combine first two vectors &lt;math&gt;v = \begin{bmatrix}
2 \\ 
-1 
\end{bmatrix}&lt;/math&gt; and &lt;math&gt;u = \begin{bmatrix}
-1 \\ 
2 
\end{bmatrix}&lt;/math&gt; so they form &lt;math&gt;\begin{bmatrix}
0 \\ 
3 
\end{bmatrix}&lt;/math&gt;


I.e. we want to find a [[Linear Combination]] of these columns.
* From the vector picture we know that the solution is $[1, 2]^T$, so let's take 
* http://habrastorage.org/files/b17/368/e5e/b17368e5e7774f8ca58e054c7b98183e.png
* so we take 1 of vector $\mathbf u$ and 2 of vector $\mathbf v$ and end up at exactly $\mathbf b$!



=== Python Code ===
{{ Hider | 
   title=Python code to reproduce the figures |
   content=
&lt;pre&gt;
import matplotlib.pylab as plt
import numpy as np

class Line:
    def __init__(self, slope, intercept):
        self.slope = slope
        self.intercept = intercept

    def calculate(self, x1):
        x2 = x1 * self.slope + self.intercept
        return x2

line1 = Line(2, 0)
line2 = Line(0.5, 1.5)

a = np.array([-6, 6])
plt.plot(a, line1.calculate(a), color='red', marker='')
plt.plot(a, line2.calculate(a), color='blue', marker='')
plt.scatter([1], [2])
plt.grid()
plt.axis('equal')
plt.ylim([-1, 3])
plt.xlim([-1, 3])
&lt;/pre&gt;


&lt;pre&gt;
import matplotlib.pylab as plt

plt.axis('equal')
plt.quiver([0, 0, 0], [0, 0, 0], 
           [-1, 2, 0], [2, -1, 3], color=['red', 'blue', 'black'], 
           angles='xy', 
           scale_units='xy', scale=1)
plt.quiver([2], [-1], 
           [-2], [4], color='red', width=0.005, scale=1,
           angles='xy', scale_units='xy')
plt.grid()
plt.ylim([-2, 5])
plt.xlim([-4, 4])
plt.show()
&lt;/pre&gt;
}}


== Solving the System ==
How we can solve the system $A \mathbf x = \mathbf b$?
* The easiest way: [[Gaussian Elimination]] - elimination of variables
* this is the row picture 

Vector Solution: the solution found with the column picture 


Matrix Solution
* if $A$ is non-singular and invertible, then to find $\mathbf x$ multiply $\mathbf b$ by the [[Inverse Matrices|inverse]] of $A$: $\mathbf x = A^{-1} \mathbf b$
* if $\mathbf b \in C(A)$ - [[Column Space]] of $A$ 
** this is especially important when the number of columns $n$ is less than the number of rows $m$


=== Solving $A \mathbf x = \mathbf 0$ ===
Such systems are called ''homogeneous'' - see [[Homogeneous Systems of Linear Equations]]


=== Complete Solution to $A \mathbf x = \mathbf b$ ===
Let $A$ be $n \times m$ matrix of rank $r$
* we know that the system has a solution if $\mathbf b \in C(A)$


Steps:
* reduce $A$ to [[Row Reduced Echelon Form]]
* set all free variables to 0 and solve - get $\textbf x_p = \textbf x_\text{particular}$ 
* then solve $A \mathbf x_n = \mathbf 0$ - get all $\mathbf x_n$ - all $\mathbf x$ that solve the homogeneous system
* Then find all other solutions: they are $\mathbf x = \textbf x_p + \mathbf x_n$
* this solution is called ''the complete solution''
* why? $A \mathbf x_p = \mathbf b$ and $A \mathbf x_n = \mathbf 0$. Add them and get $A \cdot (\mathbf x_p + \mathbf x_n) = \mathbf b + \mathbf 0 = \mathbf b$
* so we can the solution as the Nullspace $C(A)$ but shifted away from the origin by $x_p$ 
* note that this solution doesn't form a subspace



== General Case, $A \mathbf x = \mathbf b$ ==
Let $A$ be $m \times n$ matrix of rank $r$
* $m$ - rows, $n$ - cols
* $r \leqslant m$, $r \leqslant n$


=== Full Column Rank ===
Full rank = $r$ is as big as it can be
* suppose that $n \leqslant m$, i.e. the number of columns is smaller than the number of rows
* so full column rank matrix = $r = n$
* there's a pivot in every column, $n$ pivots $\Rightarrow$ no free variables

http://habrastorage.org/files/765/fc6/d10/765fc6d1001040cd977ae72c239a1430.png


Nullspace $N(A)$?
* there are no free variables to consider 
* so $N(A) = \{ \ \mathbf 0 \ \}$

Solution to $A \mathbf x = \mathbf b$:
* if the solution exists (i.e. $\mathbf b \in C(A)$) then this solution is unique
* so we have either 0 solutions or 1


=== [[Gaussian Elimination]] and [[LU Decomposition]] ===
Solving $A\mathbf x = \mathbf b$
* As metioned earlier - need to reduce it to RREF
* Can do that with Gaussian Elimination via LU Decomposition
* Let $LU = A$
* then $A \mathbf x = \mathbf b$ becomes $LU \mathbf x = \mathbf b$
* Now let $U \mathbf x = \mathbf y$ and $L \mathbf y = \mathbf x$
* With this substitution we need to solve two equations now, but they are simple because $L$ is lower-diagonal and $U$ is upper-diagonal 



=== No Solution ===
No solution?
* Can approximate it with [[Normal Equation]] 
* That would be the [[Ordinary Least Squares|Least Squares]] solution


=== Full Row Rank ===
* Now suppose that $m \leqslant n$ and $r = m$ 
* so every row has a pivot, but only $r$ columns have pivots, the remaining $n - r$ don't
* so there are $r$ pivot columns, and $n - r$ free columns

http://habrastorage.org/files/67d/5e5/d6f/67d5e5d6f8424d0ebd2ec310c4ed8ef4.png


for which $\mathbf b$ we can solve $A \mathbf x = \mathbf b$?
* there are no zero rows, so can solve the system for any $\mathbf b$ 


=== Full Rank ===
* If our $A$ is square, $m = n = r$
* then there's always a solution, and $A$ is called ''invertible''
* $N(A) = \{ \ \mathbf 0 \ \}$ - there's only one unique solution


=== $r &lt; m$ and $r &lt; n$ === 
http://habrastorage.org/files/d2a/f16/064/d2af160643b24017846c05381c600fe6.png

* $A \mathbf x = \mathbf 0$ always have a solution - there's always something in the [[Nullspace]] $N(A)$ of $A$ apart from the zero-vector
* reason: there are always free variables and we can assign any non-zero values to them and solve the homogeneous system


Zero or $\infty$ solutions



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Курош А.Г. Курс Высшей Алгебры
* http://en.wikipedia.org/wiki/System_of_linear_equations

[[Category:Linear Algebra]]</text>
      <sha1>dn6urjk2rv167js99xzhql97xy1cerc</sha1>
    </revision>
  </page>
  <page>
    <title>Column Space</title>
    <ns>0</ns>
    <id>514</id>
    <revision>
      <id>517</id>
      <timestamp>2014-12-18T21:23:04Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3140">== Column Space ==
A column space $C(A)$ of a matrix $A$ is a subspace formed by columns of $A$
* it's one of is one of the [[Four Fundamental Subspaces]] of $A$


=== $C(A)$ ===
Let $A$ be $m \times n$ matrix:
* $A = \left[ \mathop{a_1}\limits_|^| \, \mathop{a_2}\limits_|^| \ \cdots \  \mathop{a_n}\limits_|^| \right]$
* the columns of $A$ form a subspace - a hyperplane through the origin 
* http://habrastorage.org/files/577/050/70e/57705070eeef45ee91d525a65ba2ea75.png
* $C(A)$ is in $\mathbb R^r$ space where $r \leqslant n$ is the $A$'s [[Rank (Matrix)|Rank]] 
* so the dimensionality is at most the number of columns, and at least the rank of the matrix 


It's a subspace:
* if we take any vectors from $C(A)$, the linear combination will still be $C(A)$ (by definition)
* http://habrastorage.org/files/f51/d03/568/f51d03568a64453d91ca9e198318de93.png


=== Example ===
Suppose we have a matrix $A \in \mathbb R^{3 \times 2}$

$A = \begin{bmatrix}
1 &amp; 3 \\
2 &amp; 3 \\
4 &amp; 1 \\
\end{bmatrix}$

Subspace from columns - $C(A)$ - the [[Column Space]] of $A$:
* we cannot just take the two columns and call it a subspace: 
* it also must include all linear combinations of these columns
* these linear combinations of two vectors form a plane - a subspace $\mathbb R^2$ in the space $\mathbb R^3$
* since we include all possible combinations, we're guaranteed to have a subspace 
* http://habrastorage.org/files/cf5/432/f56/cf5432f561ec4f14888e8b376c5f438b.png
* $v_1$ and $v_2$ are 1st and 2nd columns of $A$ - they form a plane through the origin


=== [[System of Linear Equations|System]] $A \mathbf x = \mathbf b$ ===
Column Space $C(A)$ of $A$ is important: the system $A \mathbf x = \mathbf b$ has the solution only when $\mathbf b \in C(A)$

For example: 

$A = \begin{bmatrix}
1 &amp; 1 &amp; 2 \\
2 &amp; 1 &amp; 3 \\
3 &amp; 1 &amp; 4 \\
4 &amp; 1 &amp; 5 \\
\end{bmatrix}$. 
* There are 3 columns and they are 4-dim vectors 
* so $C(A)$ is a subspace $\mathbb R^4$
* but how big it is? is it the entire $\mathbb R^4$? No - we have only 3 vectors, so it's at most $\mathbb R^3$


Since there are only 3 columns, in $A \mathbf x = \mathbf b$
* $\mathbf x \in \mathbb R^3$ and $\mathbf b \in \mathbb R^4$
* does it always have a solution? no: we have 4 equations and 3 unknowns
* there are many $\mathbf b$'s that can't solve the system
* but there are some that can: they are linear combinations of the columns - so those $\mathbf b$ that are from $C(A)$


For example, the following can solve it:
* $\mathbf 0_4$, because $\mathbf x = \mathbf 0_3$ will solve it
* $\begin{bmatrix}
1 \\
2 \\
3 \\
4 \\
\end{bmatrix}$ - one of the columns, so $\mathbf x = \begin{bmatrix}
1 \\
0 \\
0 \\
\end{bmatrix}$


if $\mathbf b \not \in C(A)$ there's no way to solve the system 


What's the dimension of $C(A)$? 
* $\text{dim } C(A) = r$ where $r$ -rank of $A$
* the easiest way to determine it - is calculate the number of pivot columns during [[Gaussian Elimination]]
* in this case, $\text{dim } C(A) = 2$ because the rank is 2 (the 3rd column is a linear combination of 1st and 2nd)




== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>mkvv3c0ocs9jogqftyiphfp8y31170p</sha1>
    </revision>
    <revision>
      <id>787</id>
      <parentid>517</parentid>
      <timestamp>2017-06-27T10:48:28Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3719">== Column Space ==
A column space $C(A)$ of a matrix $A$ is a subspace formed by columns of $A$
* it's one of is one of the [[Four Fundamental Subspaces]] of $A$


=== The Column Space $C(A)$ ===
Let $A$ be $m \times n$ matrix:
* $A = \left[ \mathop{a_1}\limits_|^| \, \mathop{a_2}\limits_|^| \ \cdots \  \mathop{a_n}\limits_|^| \right]$
* the columns of $A$ form a subspace - a hyperplane through the origin 
* http://habrastorage.org/files/577/050/70e/57705070eeef45ee91d525a65ba2ea75.png
* $C(A)$ is in $\mathbb R^r$ space where $r \leqslant n$ is the $A$'s [[Rank (Matrix)|Rank]] 
* so the dimensionality is at most the number of columns, and at least the rank of the matrix 


&lt;img width=&quot;50%&quot; src=&quot;http://alexeygrigorev.com/projects/imsem-ws14-lina/img-svg/diagram1.svg&quot; /&gt;


It's also called the ''range'' of $A$:
* $\text{ran}(A) = \{ \mathbf y \in \mathbb R^m \ : \ \mathbf y = A \mathbf x \ \forall \mathbf x \in \mathbb R^n   \}$
* if we think about [[Linear Transformation]] $T_{A}$ formed by $A$, this is what it does to an $n$-dimensional vector $\mathbf x$: it brings it to an $m$-dinesional vector $\mathbf y$
* all such vectors $\mathbf y$ form the column space of $A$



It's a subspace:
* if we take any vectors from $C(A)$, the linear combination will still be $C(A)$ (by definition)
* http://habrastorage.org/files/f51/d03/568/f51d03568a64453d91ca9e198318de93.png


=== Example ===
Suppose we have a matrix $A \in \mathbb R^{3 \times 2}$

$A = \begin{bmatrix}
1 &amp; 3 \\
2 &amp; 3 \\
4 &amp; 1 \\
\end{bmatrix}$

Subspace from columns - $C(A)$ - the [[Column Space]] of $A$:
* we cannot just take the two columns and call it a subspace: 
* it also must include all linear combinations of these columns
* these linear combinations of two vectors form a plane - a subspace $\mathbb R^2$ in the space $\mathbb R^3$
* since we include all possible combinations, we're guaranteed to have a subspace 
* http://habrastorage.org/files/cf5/432/f56/cf5432f561ec4f14888e8b376c5f438b.png
* $v_1$ and $v_2$ are 1st and 2nd columns of $A$ - they form a plane through the origin


=== [[System of Linear Equations|System]] $A \mathbf x = \mathbf b$ ===
Column Space $C(A)$ of $A$ is important: the system $A \mathbf x = \mathbf b$ has the solution only when $\mathbf b \in C(A)$

For example: 

$A = \begin{bmatrix}
1 &amp; 1 &amp; 2 \\
2 &amp; 1 &amp; 3 \\
3 &amp; 1 &amp; 4 \\
4 &amp; 1 &amp; 5 \\
\end{bmatrix}$. 
* There are 3 columns and they are 4-dim vectors 
* so $C(A)$ is a subspace $\mathbb R^4$
* but how big it is? is it the entire $\mathbb R^4$? No - we have only 3 vectors, so it's at most $\mathbb R^3$


Since there are only 3 columns, in $A \mathbf x = \mathbf b$
* $\mathbf x \in \mathbb R^3$ and $\mathbf b \in \mathbb R^4$
* does it always have a solution? no: we have 4 equations and 3 unknowns
* there are many $\mathbf b$'s that can't solve the system
* but there are some that can: they are linear combinations of the columns - so those $\mathbf b$ that are from $C(A)$


For example, the following can solve it:
* $\mathbf 0_4$, because $\mathbf x = \mathbf 0_3$ will solve it
* &lt;math&gt;\begin{bmatrix}
1 \\
2 \\
3 \\
4 \\
\end{bmatrix}&lt;/math&gt; - one of the columns, so &lt;math&gt;\mathbf x = \begin{bmatrix}
1 \\
0 \\
0 \\
\end{bmatrix}&lt;/math&gt;


if $\mathbf b \not \in C(A)$ there's no way to solve the system 


What's the dimension of $C(A)$? 
* $\text{dim } C(A) = r$ where $r$ -rank of $A$
* the easiest way to determine it - is calculate the number of pivot columns during [[Gaussian Elimination]]
* in this case, $\text{dim } C(A) = 2$ because the rank is 2 (the 3rd column is a linear combination of 1st and 2nd)




== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* [[Matrix Computations (book)]]

[[Category:Linear Algebra]]</text>
      <sha1>h75qx2sph1jlxb16dajhv2fcr5fjy59</sha1>
    </revision>
  </page>
  <page>
    <title>Homogeneous Systems of Linear Equations</title>
    <ns>0</ns>
    <id>515</id>
    <revision>
      <id>518</id>
      <timestamp>2014-12-18T21:24:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6184">== Homogeneous Linear Systems $A\mathbf x = \mathbf 0$ ==
Suppose we have a [[System of Linear Equations|system]] $A\mathbf x = \mathbf 0$. Such a system is called ''homogeneous'' - because we have $\mathbf 0$ on the right side of the system. 


== Solving $A\mathbf x = \mathbf 0$ ==
How to solve such a system? 
* The solutions to this system form [[Nullspace]] $N(A)$
* we can solve it with [[Gaussian Elimination]]. The elimination doesn't change $N(A)$ - the solutions remain the same if we linearly combine the rows
* but note that the elimination changes the [[Column Space]] $C(A)$ of $A$ 


=== Elimination and Echelon Form ===
Suppose we have a matrix $A = 
\begin{bmatrix}
1 &amp; 2 &amp; 2 &amp; 2 \\ 
2 &amp; 4 &amp; 6 &amp; 8 \\
3 &amp; 6 &amp; 8 &amp; 10 \\
\end{bmatrix}$
* note that row 3 is a linear combination of row 1 and row 2 (the system is not [[Linear Independence|linearly independent]])
* while doing the elimination we'll notice it 

Let's do it:
* $\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 2 &amp; 2 \\ 
2 &amp; 4 &amp; 6 &amp; 8 \\
3 &amp; 6 &amp; 8 &amp; 10 \\
\end{bmatrix} \to 
\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 2 &amp; 2 \\ 
0 &amp; 0 &amp; 2 &amp; 4 \\
0 &amp; 0 &amp; 2 &amp; 4 \\
\end{bmatrix}$
* we have 0's in the second column, but in the next column there's a non-zero value - can take it as a pivot!
* $\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 2 &amp; 2 \\ 
0 &amp; 0 &amp; \boxed 2 &amp; 4 \\
0 &amp; 0 &amp; 2 &amp; 4 \\
\end{bmatrix} \to
\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 2 &amp; 2 \\ 
0 &amp; 0 &amp; \boxed 2 &amp; 4 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
\end{bmatrix} = U$
* it's not really an upper-triangular matrix, but we still can call it $U$
* this $U$ is in the ''echelon form'' (or &quot;staircase&quot; form)
* http://habrastorage.org/files/fff/873/751/fff8737512334debaf8ae3f1878cd8b3.png


[[Rank|''rank'']] $r$ of a matrix is the number of Pivot variables in the echelon form


During the elimination the nullspace $N(A)$ of $A$ doesn't change
* so systems $A\mathbf x = \mathbf 0$ and $U \mathbf x = \mathbf 0$ have the same solutions $\mathbf x$
* the column with pivot variables are called ''pivot columns'', there are $r$ of them 
* the rest of the columns are called ''free columns'', there are $n - r$ of them 
* http://habrastorage.org/files/fcb/1dc/c9e/fcb1dcc9e07345df9fd4c6624d8038a7.png


Now let's try to solve this system 
$\left\{\begin{array}{rl}
x_1 + 2 x_2 + 2 x_3 + 2 x_4 &amp; = 0 \\
2 x_3 + 4 x_4 &amp; = 0 \\
\end{array}\right.$

We can find some solutions for pivot variables, but what to do with the free ones? 
* They can have any value
* So we may assign something to them and then solve the system with backsubstitution for the pivot variables

* E.g. let's assign 1 and 0 to $x_2$ and $x_4$
** we have $\mathbb x = \begin{bmatrix}
x_1 \\ 1 \\ x_3 \\ 0
\end{bmatrix}$, then we solve the system and get $\mathbb x = \begin{bmatrix}
-2 \\ 1 \\ 0 \\ 0
\end{bmatrix}$
** we can also take any linear combination of this solution, so we should write $\mathbb x = c_1 \cdot \begin{bmatrix}
-2 \\ 1 \\ 0 \\ 0 
\end{bmatrix}$
* what if we assign different values to $x_2$ and $x_4$?
** Can assign this way: $\mathbb x = \begin{bmatrix}
x_1 \\ 0 \\ x_3 \\ 1
\end{bmatrix}$, then we solve and get $\mathbb x = \begin{bmatrix}
2 \\ 0 \\ -2 \\ 1
\end{bmatrix}$
** so we have another &quot;special&quot; solution $\mathbb x = c_2 \cdot \begin{bmatrix}
2 \\ 0 \\ -2 \\ 1
\end{bmatrix}$
* so the final solution to this system will be 
** $\mathbf x = c_1 \cdot \begin{bmatrix}
-2 \\ 1 \\ 0 \\ 0 
\end{bmatrix} + c_2 \cdot \begin{bmatrix}
2 \\ 0 \\ -2 \\ 1
\end{bmatrix}$
** this is the Nullspace $N(A)$ of the matrix $A$


=== Row Reduced Echelon Form ===
Can we do simpler? 

Suppose we have matrix $A$ that we reduced to $U = \begin{bmatrix}
\boxed 1 &amp; 2 &amp; 2 &amp; 2 \\ 
0 &amp; 0 &amp; \boxed 2 &amp; 4 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
\end{bmatrix}$ 
* can we clean it further? Can try to clean the pivot columns upwards - so there's only one 1 and the rest are 0's 
* $U = \begin{bmatrix}
\boxed 1 &amp; 2 &amp; 2 &amp; 2 \\ 
0 &amp; 0 &amp; \boxed 2 &amp; 4 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
\end{bmatrix} \to 
\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 0 &amp; -2 \\ 
0 &amp; 0 &amp; \boxed 1 &amp; 4 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
\end{bmatrix} = R$
* $R$ is a ''Row Reduced Echelon Form'' (RRFR) of $A$ 
* http://habrastorage.org/files/d02/b71/666/d02b7166629a482fa5e29591cf5d6baf.png
* note that if we consider only the pivot rows and columns, we see that we have the identity matrix $\begin{bmatrix}
1 &amp; 0 \\
0 &amp; 1 \\
\end{bmatrix}$



So now if we take a look at our new system, we have
* $\left\{\begin{array}{rl}
x_1 + 2 x_2 - 2 x_4 &amp; = 0 \\
x_3 + 2 x_4 &amp; = 0 \\
\end{array}\right.$
* $A \mathbf x = \mathbf 0$, $U \mathbf x = \mathbf 0$ and $R \mathbf x = \mathbf 0$ - all have the same solutions $\mathbf x$!


Let's rearrange columns in $R$ so first we have the pivot columns, and then the free columns
* $\begin{bmatrix}
1 &amp; 0 &amp; 2 &amp; -2 \\ 
0 &amp; 1 &amp; 0 &amp; 2 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
\end{bmatrix}$
* now can distinguish the $I$ part (identity) and the $F$ part (free)
* http://habrastorage.org/files/13b/2e5/439/13b2e543918546ee99bb2ee4de2b5c9a.png
* these $I$ and $F$ appear in the &quot;special&quot; solutions of the $U \mathbf x = \mathbf 0$! 
* only $F$ comes with the minus sign:
* http://habrastorage.org/files/e62/6bf/0a7/e626bf0a7f1946e2a60df299631aee40.png


Why does it happen?
* assume we have a RREF $R = \begin{bmatrix}
I &amp; F \\
0 &amp; 0 \\
\end{bmatrix}$
* we have $r$ pivot columns, $n-r$ free columns and $r$ pivot rows
* we want to solve $R\mathbf x = \mathbf 0$. What are the &quot;special&quot; solutions?
* let's create a ''Nullspace matrix'' $N$, $N = \begin{bmatrix}
-F \\ I
\end{bmatrix}$
* Columns of $N$ are our special solutions
* let's take a closer look at one of these columns $\begin{bmatrix}
\mathop{\mathbf x_\text{pivot}}\limits_{|}^{|} \\
\mathop{\mathbf x_\text{free}}\limits_{|}^{|} \\
\end{bmatrix}$. The system is $\begin{bmatrix}
I &amp; F \\
0 &amp; 0 \\
\end{bmatrix} \cdot \begin{bmatrix}
\mathop{\mathbf x_\text{pivot}}\limits_{|}^{|} \\
\mathop{\mathbf x_\text{free}}\limits_{|}^{|} \\
\end{bmatrix} = \mathbf 0$ 
* $\Rightarrow$ $I  x_\text{pivot} + F x_\text{free} = \mathbf 0$ or $x_\text{pivot} = - F x_\text{free}$
* where for $x_\text{free}$ we use &quot;special&quot; choices $\mathbf e_1, \mathbf e_2, ...$ (columns of $I$)




== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>hgwalir8nloqbgakiui0x5hdzyagabg</sha1>
    </revision>
    <revision>
      <id>790</id>
      <parentid>518</parentid>
      <timestamp>2017-06-27T11:48:30Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6396">== Homogeneous Linear Systems $A\mathbf x = \mathbf 0$ ==
Suppose we have a [[System of Linear Equations|system]] $A\mathbf x = \mathbf 0$. Such a system is called ''homogeneous'' - because we have $\mathbf 0$ on the right side of the system. 


== Solving $A\mathbf x = \mathbf 0$ ==
How to solve such a system? 
* The solutions to this system form [[Nullspace]] $N(A)$
* we can solve it with [[Gaussian Elimination]]. The elimination doesn't change $N(A)$ - the solutions remain the same if we linearly combine the rows
* but note that the elimination changes the [[Column Space]] $C(A)$ of $A$ 


=== Elimination and Echelon Form ===
Suppose we have a matrix $A = 
\begin{bmatrix}
1 &amp; 2 &amp; 2 &amp; 2 \\ 
2 &amp; 4 &amp; 6 &amp; 8 \\
3 &amp; 6 &amp; 8 &amp; 10 \\
\end{bmatrix}$
* note that row 3 is a linear combination of row 1 and row 2 (the system is not [[Linear Independence|linearly independent]])
* while doing the elimination we'll notice it 

Let's do it:
* &lt;math&gt;\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 2 &amp; 2 \\ 
2 &amp; 4 &amp; 6 &amp; 8 \\
3 &amp; 6 &amp; 8 &amp; 10 \\
\end{bmatrix} \to 
\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 2 &amp; 2 \\ 
0 &amp; 0 &amp; 2 &amp; 4 \\
0 &amp; 0 &amp; 2 &amp; 4 \\
\end{bmatrix}&lt;/math&gt;
* we have 0's in the second column, but in the next column there's a non-zero value - can take it as a pivot!
* &lt;math&gt;\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 2 &amp; 2 \\ 
0 &amp; 0 &amp; \boxed 2 &amp; 4 \\
0 &amp; 0 &amp; 2 &amp; 4 \\
\end{bmatrix} \to
\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 2 &amp; 2 \\ 
0 &amp; 0 &amp; \boxed 2 &amp; 4 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
\end{bmatrix} = U&lt;/math&gt;
* it's not really an upper-triangular matrix, but we still can call it $U$
* this $U$ is in the ''echelon form'' (or &quot;staircase&quot; form)
* http://habrastorage.org/files/fff/873/751/fff8737512334debaf8ae3f1878cd8b3.png


[[Rank|''rank'']] $r$ of a matrix is the number of Pivot variables in the echelon form


During the elimination the nullspace $N(A)$ of $A$ doesn't change
* so systems $A\mathbf x = \mathbf 0$ and $U \mathbf x = \mathbf 0$ have the same solutions $\mathbf x$
* the column with pivot variables are called ''pivot columns'', there are $r$ of them
* the rest of the columns are called ''free columns'', there are $n - r$ of them
* http://habrastorage.org/files/fcb/1dc/c9e/fcb1dcc9e07345df9fd4c6624d8038a7.png


Now let's try to solve this system 
$\left\{\begin{array}{rl}
x_1 + 2 x_2 + 2 x_3 + 2 x_4 &amp; = 0 \\
2 x_3 + 4 x_4 &amp; = 0 \\
\end{array}\right.$

We can find some solutions for pivot variables, but what to do with the free ones? 
* They can have any value
* So we may assign something to them and then solve the system with backsubstitution for the pivot variables

* E.g. let's assign 1 and 0 to $x_2$ and $x_4$
** we have &lt;math&gt;\mathbb x = \begin{bmatrix}
x_1 \\ 1 \\ x_3 \\ 0
\end{bmatrix}&lt;/math&gt;, then we solve the system and get &lt;math&gt;\mathbb x = \begin{bmatrix}
-2 \\ 1 \\ 0 \\ 0
\end{bmatrix}&lt;/math&gt;
** we can also take any linear combination of this solution, so we should write &lt;math&gt;\mathbb x = c_1 \cdot \begin{bmatrix}
-2 \\ 1 \\ 0 \\ 0 
\end{bmatrix}&lt;/math&gt;
* what if we assign different values to $x_2$ and $x_4$?
** Can assign this way: &lt;math&gt;\mathbb x = \begin{bmatrix}
x_1 \\ 0 \\ x_3 \\ 1
\end{bmatrix}&lt;/math&gt;, then we solve and get &lt;math&gt;\mathbb x = \begin{bmatrix}
2 \\ 0 \\ -2 \\ 1
\end{bmatrix}&lt;/math&gt;
** so we have another &quot;special&quot; solution &lt;math&gt;\mathbb x = c_2 \cdot \begin{bmatrix}
2 \\ 0 \\ -2 \\ 1
\end{bmatrix}&lt;/math&gt;
* so the final solution to this system will be 
** &lt;math&gt;\mathbf x = c_1 \cdot \begin{bmatrix}
-2 \\ 1 \\ 0 \\ 0 
\end{bmatrix} + c_2 \cdot \begin{bmatrix}
2 \\ 0 \\ -2 \\ 1
\end{bmatrix}&lt;/math&gt;
** this is the Nullspace $N(A)$ of the matrix $A$


=== Row Reduced Echelon Form ===
Can we do simpler? 

Suppose we have matrix $A$ that we reduced to &lt;math&gt;U = \begin{bmatrix}
\boxed 1 &amp; 2 &amp; 2 &amp; 2 \\ 
0 &amp; 0 &amp; \boxed 2 &amp; 4 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
\end{bmatrix}&lt;/math&gt;
* can we clean it further? Can try to clean the pivot columns upwards - so there's only one 1 and the rest are 0's 
* &lt;math&gt;U = \begin{bmatrix}
\boxed 1 &amp; 2 &amp; 2 &amp; 2 \\ 
0 &amp; 0 &amp; \boxed 2 &amp; 4 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
\end{bmatrix} \to 
\begin{bmatrix}
\boxed 1 &amp; 2 &amp; 0 &amp; -2 \\ 
0 &amp; 0 &amp; \boxed 1 &amp; 4 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
\end{bmatrix} = R&lt;/math&gt;
* $R$ is a ''Row Reduced Echelon Form'' (RRFR) of $A$ 
* http://habrastorage.org/files/d02/b71/666/d02b7166629a482fa5e29591cf5d6baf.png
* note that if we consider only the pivot rows and columns, we see that we have the identity matrix &lt;math&gt;\begin{bmatrix}
1 &amp; 0 \\
0 &amp; 1 \\
\end{bmatrix}&lt;/math&gt;



So now if we take a look at our new system, we have
* &lt;math&gt;\left\{\begin{array}{rl}
x_1 + 2 x_2 - 2 x_4 &amp; = 0 \\
x_3 + 2 x_4 &amp; = 0 \\
\end{array}\right.&lt;/math&gt;
* $A \mathbf x = \mathbf 0$, $U \mathbf x = \mathbf 0$ and $R \mathbf x = \mathbf 0$ - all have the same solutions $\mathbf x$!


Let's rearrange columns in $R$ so first we have the pivot columns, and then the free columns
* &lt;math&gt;\begin{bmatrix}
1 &amp; 0 &amp; 2 &amp; -2 \\ 
0 &amp; 1 &amp; 0 &amp; 2 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
\end{bmatrix}&lt;/math&gt;
* now can distinguish the $I$ part (identity) and the $F$ part (free)
* http://habrastorage.org/files/13b/2e5/439/13b2e543918546ee99bb2ee4de2b5c9a.png
* these $I$ and $F$ appear in the &quot;special&quot; solutions of the $U \mathbf x = \mathbf 0$! 
* only $F$ comes with the minus sign:
* http://habrastorage.org/files/e62/6bf/0a7/e626bf0a7f1946e2a60df299631aee40.png


Why does it happen?
* assume we have a RREF &lt;math&gt;R = \begin{bmatrix}
I &amp; F \\
0 &amp; 0 \\
\end{bmatrix}&lt;/math&gt;
* we have $r$ pivot columns, $n-r$ free columns and $r$ pivot rows
* we want to solve $R\mathbf x = \mathbf 0$. What are the &quot;special&quot; solutions?
* let's create a ''Nullspace matrix'' $N$, &lt;math&gt;N = \begin{bmatrix}
-F \\ I
\end{bmatrix}&lt;/math&gt;
* Columns of $N$ are our special solutions
* let's take a closer look at one of these columns &lt;math&gt;\begin{bmatrix}
\mathop{\mathbf x_\text{pivot}}\limits_{|}^{|} \\
\mathop{\mathbf x_\text{free}}\limits_{|}^{|} \\
\end{bmatrix}&lt;/math&gt;. The system is &lt;math&gt;\begin{bmatrix}
I &amp; F \\
0 &amp; 0 \\
\end{bmatrix} \cdot \begin{bmatrix}
\mathop{\mathbf x_\text{pivot}}\limits_{|}^{|} \\
\mathop{\mathbf x_\text{free}}\limits_{|}^{|} \\
\end{bmatrix} = \mathbf 0&lt;/math&gt;
* &lt;math&gt;\Rightarrow I x_\text{pivot} + F x_\text{free} = \mathbf 0&lt;/math&gt; or &lt;math&gt;x_\text{pivot} = - F x_\text{free}&lt;/math&gt;
* where for $x_\text{free}$ we use &quot;special&quot; choices $\mathbf e_1, \mathbf e_2, ...$ (columns of $I$)



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>6f2xe3ynym22urq3t2quf38xue302vp</sha1>
    </revision>
  </page>
  <page>
    <title>Nullspace</title>
    <ns>0</ns>
    <id>516</id>
    <revision>
      <id>519</id>
      <timestamp>2015-04-26T17:10:51Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4840">== Nullspace ==
Nullspace $N(A)$ of a matrix $A$ is one of the [[Four Fundamental Subspaces]] of the matrix $A$

The nullspace of $A$ contains all $\mathbf x$ that solve the [[System of Linear Equations|system]] $A \mathbf x = \mathbf 0$ (this system is called [[Homogeneous Systems of Linear Equations|''homogeneous'']])


=== Example ===
$A = \begin{bmatrix}
1 &amp; 1 &amp; 2 \\
2 &amp; 1 &amp; 3 \\
3 &amp; 1 &amp; 4 \\
4 &amp; 1 &amp; 5 \\
\end{bmatrix}$, $\mathbf x = \begin{bmatrix}
x_1 \\ x_2 \\ x_3
\end{bmatrix}$, $\mathbf b = \mathbf 0_4 = \begin{bmatrix}
0 \\ 0 \\ 0 \\ 0
\end{bmatrix}$
* There are 3 columns and they are 4-dim vectors 
* the [[Column Space]] $C(A)$ is a subspace of $\mathbb R^4$, but $\text{dim } C(A) = 2$ (because the [[Rank (Matrix)|rank]] of this matrix is 2)
* since there are only 3 columns, the number of unknowns is 3 - so $N(A)$ is a subspace of $\mathbb R^3$


Let's find what's inside $N(A)$
* i.e. all such $\mathbf x$ that solve $A \mathbf x = \mathbf 0$ 
* $\mathbf 0 \in N(A)$ always
* $\begin{bmatrix}
1 \\ 1 \\ -1
\end{bmatrix}$ or any multiple of this vector $c \cdot \begin{bmatrix}
1 \\ 1 \\ -1
\end{bmatrix}$
* so it's a subspace - a line in $\mathbb R^3$ through the origin


=== Is $N(A)$ a Subspace? ===
Does it form a [[Vector Space]] on its own?
* so we need to check that all possible $\mathbf x$ for that solve $A \mathbf x = \mathbf 0$  form a subspace
* let $\mathbf v$ and $\mathbf w$  be two solutions
** $A \cdot (\mathbf v + \mathbf w) = A \mathbf v + A \mathbf w = \mathbf 0 + \mathbf 0 = \mathbf 0$. so $\mathbf v + \mathbf w$ is also a solution
* if $A \mathbf v = 0$, then $A \cdot (c \cdot \mathbf v) = (c \cdot A) \cdot  \mathbf v = 0$
** this would just multiply all columns of $A$ on the same number 
* so yes, it is a subspace


=== [[Basis (Linear Algebra)|Basis]] of $N(A)$ ===
Basis for $N(A)$ is formed by the &quot;special&quot; solutions



== Left Nullspace ==
We can also consider another nullspace of $A$ - the nullspace of $A^T$ (this is the 4th [[Four Fundamental Subspaces|fundamental subspace]] of a matrix)

Let's have a look at a system $A^T \mathbf y = \mathbf 0$
* $A$ is an $n \times m$ matrix, so $A^T$ is $m \times n$
* $y$ is $n$-len column vector

Let's take the transpose of $A^T \mathbf y = \mathbf 0$:
* $(A^T \mathbf y)^T = \mathbf 0^T$
* $\mathbf y^T A  = \mathbf 0^T$
* so now we have a row vector $\mathbf y^T$ that is on the left side of $A$ 

$\big[ - \, \mathbf y^T - \big] \Bigg[ ~ ~ ~ ~ ~ {A} ~ ~ ~ ~ ~ \Bigg] = \big[ - \, \mathbf 0^T - \big]$


=== [[Basis (Linear Algebra)|Basis]] of $N(A^T)$ ===
Let's consider this example 

Let $A$ be some rectangular matrix and we find it's rref $R$
* $A = \begin{bmatrix}
1 &amp; 2 &amp; 3 &amp; 1 \\
1 &amp; 1 &amp; 2 &amp; 1 \\
2 &amp; 3 &amp; 5 &amp; 2 \\
\end{bmatrix} \leadsto 
\begin{bmatrix}
1 &amp; 0 &amp; 1 &amp; 1 \\
0 &amp; 1 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
\end{bmatrix} = R$
* we see that one of the rows are $\mathbf 0$ - so the nullspace of $A^T$ should have something apart from $\mathbf 0$


How to best find this left nullspace?
* Let's do Gauss-Jordan Elimination: create the augmented matrix by appending $I$ and reduce it to the echelon form:
* $\big[  A_{m \times n} \ I_{n \times n} \big] \to \big[  R_{m \times n} \ E_{n \times n} \big]$
* So $E$ is the elimination matrix - the matrix that brings $A$ to rref $R$
* $E A = R$
** If $A$ is square and invertible, then $E \equiv A^{-1}$
** but since $A$ is rectangular, it has no inverse 

Example cont'd 
* $\left[ \begin{array}{cccc|ccc}
1 &amp; 2 &amp; 3 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 0 \\
2 &amp; 3 &amp; 5 &amp; 2 &amp; 0 &amp; 0 &amp; 1 \\
\end{array}\right] \leadsto 
\left[ \begin{array}{cccc|ccc}
1 &amp; 0 &amp; 1 &amp; 1 &amp; -1 &amp; 2 &amp; 0 \\
0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; -1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; -1 &amp; 0 &amp; 1 \\
\end{array}\right]$
* now if we take $E = \begin{bmatrix}
-1 &amp; 2 &amp; 0 \\
1 &amp; -1 &amp; 0 \\
-1 &amp; 0 &amp; 1 \\
\end{bmatrix}$ and multiply it by $A$, we get 
** $\begin{bmatrix}
-1 &amp; 2 &amp; 0 \\
1 &amp; -1 &amp; 0 \\
-1 &amp; 0 &amp; 1 \\
\end{bmatrix} \cdot 
\begin{bmatrix}
1 &amp; 2 &amp; 3 &amp; 1 \\
1 &amp; 1 &amp; 2 &amp; 1 \\
2 &amp; 3 &amp; 5 &amp; 2 \\
\end{bmatrix} = 
\begin{bmatrix}
- &amp; - &amp; - &amp; - \\
- &amp; - &amp; - &amp; - \\
0 &amp; 0 &amp; 0 &amp; 0 \\
\end{bmatrix}$
** so indeed we manage to get the last row with zeros 
* so we need the last row of $E$ to get $\mathbf 0^T$
** recall the row picture from [[Matrix Multiplication]]


== Numerical Computation ==
Use [[SVD]] to compute the nullspace
* $A = U \Sigma V^T$ 
* vectors of $V$ that correspond to $\sigma_i = 0$ are from the nullspace 


&lt;pre&gt;
def null(A, eps=1e-15):
    u, s, vh = np.linalg.svd(A)
    null_space = np.compress(s &lt;= eps, vh, axis=0)
    return null_space.T
&lt;/pre&gt;

From [http://stackoverflow.com/questions/1835246/how-to-solve-homogeneous-linear-equations-with-numpy]



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* http://en.wikipedia.org/wiki/Kernel_%28linear_algebra%29#Numerical_computation

[[Category:Linear Algebra]]</text>
      <sha1>85a6j2jvaqwuo7w4q3ni3jnj8psfer3</sha1>
    </revision>
    <revision>
      <id>782</id>
      <parentid>519</parentid>
      <timestamp>2017-06-25T09:51:36Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4896">== Nullspace ==
Nullspace $N(A)$ of a matrix $A$ is one of the [[Four Fundamental Subspaces]] of the matrix $A$

The nullspace of $A$ contains all $\mathbf x$ that solve the [[System of Linear Equations|system]] $A \mathbf x = \mathbf 0$ (this system is called [[Homogeneous Systems of Linear Equations|''homogeneous'']])


=== Example ===
$A = \begin{bmatrix}
1 &amp; 1 &amp; 2 \\
2 &amp; 1 &amp; 3 \\
3 &amp; 1 &amp; 4 \\
4 &amp; 1 &amp; 5 \\
\end{bmatrix}$, $\mathbf x = \begin{bmatrix}
x_1 \\ x_2 \\ x_3
\end{bmatrix}$, $\mathbf b = \mathbf 0_4 = \begin{bmatrix}
0 \\ 0 \\ 0 \\ 0
\end{bmatrix}$
* There are 3 columns and they are 4-dim vectors 
* the [[Column Space]] $C(A)$ is a subspace of $\mathbb R^4$, but $\text{dim } C(A) = 2$ (because the [[Rank (Matrix)|rank]] of this matrix is 2)
* since there are only 3 columns, the number of unknowns is 3 - so $N(A)$ is a subspace of $\mathbb R^3$


Let's find what's inside $N(A)$
* i.e. all such $\mathbf x$ that solve $A \mathbf x = \mathbf 0$ 
* $\mathbf 0 \in N(A)$ always
* &lt;math&gt;\begin{bmatrix}
1 \\ 1 \\ -1
\end{bmatrix}&lt;/math&gt; or any multiple of this vector &lt;math&gt;c \cdot \begin{bmatrix}
1 \\ 1 \\ -1
\end{bmatrix}&lt;/math&gt;
* so it's a subspace - a line in $\mathbb R^3$ through the origin


=== Is $N(A)$ a Subspace? ===
Does it form a [[Vector Space]] on its own?
* so we need to check that all possible $\mathbf x$ for that solve $A \mathbf x = \mathbf 0$  form a subspace
* let $\mathbf v$ and $\mathbf w$  be two solutions
** $A \cdot (\mathbf v + \mathbf w) = A \mathbf v + A \mathbf w = \mathbf 0 + \mathbf 0 = \mathbf 0$. so $\mathbf v + \mathbf w$ is also a solution
* if $A \mathbf v = 0$, then $A \cdot (c \cdot \mathbf v) = (c \cdot A) \cdot  \mathbf v = 0$
** this would just multiply all columns of $A$ on the same number 
* so yes, it is a subspace


=== [[Basis (Linear Algebra)|Basis]] of $N(A)$ ===
Basis for $N(A)$ is formed by the &quot;special&quot; solutions



== Left Nullspace ==
We can also consider another nullspace of $A$ - the nullspace of $A^T$ (this is the 4th [[Four Fundamental Subspaces|fundamental subspace]] of a matrix)

Let's have a look at a system $A^T \mathbf y = \mathbf 0$
* $A$ is an $n \times m$ matrix, so $A^T$ is $m \times n$
* $y$ is $n$-len column vector

Let's take the transpose of $A^T \mathbf y = \mathbf 0$:
* $(A^T \mathbf y)^T = \mathbf 0^T$
* $\mathbf y^T A  = \mathbf 0^T$
* so now we have a row vector $\mathbf y^T$ that is on the left side of $A$ 

$\big[ - \, \mathbf y^T - \big] \Bigg[ ~ ~ ~ ~ ~ {A} ~ ~ ~ ~ ~ \Bigg] = \big[ - \, \mathbf 0^T - \big]$


=== [[Basis (Linear Algebra)|Basis]] of $N(A^T)$ ===
Let's consider this example 

Let $A$ be some rectangular matrix and we find it's rref $R$
* &lt;math&gt;A = \begin{bmatrix}
1 &amp; 2 &amp; 3 &amp; 1 \\
1 &amp; 1 &amp; 2 &amp; 1 \\
2 &amp; 3 &amp; 5 &amp; 2 \\
\end{bmatrix} \leadsto 
\begin{bmatrix}
1 &amp; 0 &amp; 1 &amp; 1 \\
0 &amp; 1 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
\end{bmatrix} = R&lt;/math&gt;
* we see that one of the rows are $\mathbf 0$ - so the nullspace of $A^T$ should have something apart from $\mathbf 0$


How to best find this left nullspace?
* Let's do Gauss-Jordan Elimination: create the augmented matrix by appending $I$ and reduce it to the echelon form:
* $\big[  A_{m \times n} \ I_{n \times n} \big] \to \big[  R_{m \times n} \ E_{n \times n} \big]$
* So $E$ is the elimination matrix - the matrix that brings $A$ to rref $R$
* $E A = R$
** If $A$ is square and invertible, then $E \equiv A^{-1}$
** but since $A$ is rectangular, it has no inverse 

Example cont'd 
* &lt;math&gt;\left[ \begin{array}{cccc|ccc}
1 &amp; 2 &amp; 3 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 0 \\
2 &amp; 3 &amp; 5 &amp; 2 &amp; 0 &amp; 0 &amp; 1 \\
\end{array}\right] \leadsto 
\left[ \begin{array}{cccc|ccc}
1 &amp; 0 &amp; 1 &amp; 1 &amp; -1 &amp; 2 &amp; 0 \\
0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; -1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; -1 &amp; 0 &amp; 1 \\
\end{array}\right]&lt;/math&gt;
* now if we take &lt;math&gt;E = \begin{bmatrix}
-1 &amp; 2 &amp; 0 \\
1 &amp; -1 &amp; 0 \\
-1 &amp; 0 &amp; 1 \\
\end{bmatrix}&lt;/math&gt; and multiply it by $A$, we get 
** &lt;math&gt;\begin{bmatrix}
-1 &amp; 2 &amp; 0 \\
1 &amp; -1 &amp; 0 \\
-1 &amp; 0 &amp; 1 \\
\end{bmatrix} \cdot 
\begin{bmatrix}
1 &amp; 2 &amp; 3 &amp; 1 \\
1 &amp; 1 &amp; 2 &amp; 1 \\
2 &amp; 3 &amp; 5 &amp; 2 \\
\end{bmatrix} = 
\begin{bmatrix}
- &amp; - &amp; - &amp; - \\
- &amp; - &amp; - &amp; - \\
0 &amp; 0 &amp; 0 &amp; 0 \\
\end{bmatrix}&lt;/math&gt;
** so indeed we manage to get the last row with zeros 
* so we need the last row of $E$ to get $\mathbf 0^T$
** recall the row picture from [[Matrix Multiplication]]


== Numerical Computation ==
Use [[SVD]] to compute the nullspace
* $A = U \Sigma V^T$ 
* vectors of $V$ that correspond to $\sigma_i = 0$ are from the nullspace 

 def null(A, eps=1e-15):
     u, s, vh = np.linalg.svd(A)
     null_space = np.compress(s &lt;= eps, vh, axis=0)
     return null_space.T

From [http://stackoverflow.com/questions/1835246/how-to-solve-homogeneous-linear-equations-with-numpy]



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* http://en.wikipedia.org/wiki/Kernel_%28linear_algebra%29#Numerical_computation

[[Category:Linear Algebra]]</text>
      <sha1>5og2v20rres9h9nzrtb2lwkisfz8ezu</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Linear Algebra</title>
    <ns>14</ns>
    <id>517</id>
    <revision>
      <id>520</id>
      <timestamp>2014-12-18T21:29:02Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24">[[Category:Mathematics]]</text>
      <sha1>b9vk507szcbw6tn1xarrdf31jl1qtsn</sha1>
    </revision>
  </page>
  <page>
    <title>Matrix Multiplication</title>
    <ns>0</ns>
    <id>518</id>
    <revision>
      <id>521</id>
      <timestamp>2015-05-08T19:57:26Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="836">== Matrix Multiplication ==
A [[Matrix]] can be multiplied
* by a scalar
* by a vector: [[Matrix-Vector Multiplication]]
* by another matrix [[Matrix-Matrix Multiplication]]



== Scalar Multiplication ==
To multiply a matrix on scalar, multiply each element $a_{ij}$ of the matrix on this scalar:

$A = \begin{bmatrix}
a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n}\\ 
a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n}\\ 
\vdots &amp; \vdots &amp;  \ddots &amp; \vdots \\ 
a_{m1} &amp; a_{m2} &amp; \cdots &amp; a_{mn}
\end{bmatrix}$, then
$c \cdot A \begin{bmatrix}
c \cdot a_{11} &amp; c \cdot a_{12} &amp; \cdots &amp; c \cdot  a_{1n}\\ 
c \cdot a_{21} &amp; c \cdot a_{22} &amp; \cdots &amp; c \cdot  a_{2n}\\ 
 \vdots &amp; \vdots &amp;  \ddots &amp; \vdots  \\ 
c \cdot a_{m1} &amp; c \cdot a_{m2} &amp; \cdots &amp; c \cdot  a_{mn}
\end{bmatrix}$



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>ehimh8hwgzwewzl1g2nwpymx5u64zf9</sha1>
    </revision>
    <revision>
      <id>781</id>
      <parentid>521</parentid>
      <timestamp>2017-06-22T20:27:57Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="859">== Matrix Multiplication ==
A [[Matrix]] can be multiplied
* by a scalar
* by a vector: [[Matrix-Vector Multiplication]]
* by another matrix [[Matrix-Matrix Multiplication]]



== Scalar Multiplication ==
To multiply a matrix on scalar, multiply each element $a_{ij}$ of the matrix on this scalar:

&lt;math&gt;A = \begin{bmatrix}
a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n}\\ 
a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n}\\ 
\vdots &amp; \vdots &amp;  \ddots &amp; \vdots \\ 
a_{m1} &amp; a_{m2} &amp; \cdots &amp; a_{mn}
\end{bmatrix}
&lt;/math&gt;, then
&lt;math&gt;c \cdot A \begin{bmatrix}
c \cdot a_{11} &amp; c \cdot a_{12} &amp; \cdots &amp; c \cdot  a_{1n}\\ 
c \cdot a_{21} &amp; c \cdot a_{22} &amp; \cdots &amp; c \cdot  a_{2n}\\ 
 \vdots &amp; \vdots &amp;  \ddots &amp; \vdots  \\ 
c \cdot a_{m1} &amp; c \cdot a_{m2} &amp; \cdots &amp; c \cdot  a_{mn}
\end{bmatrix}&lt;/math&gt;



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>m2iwt3wjqo8ixn9tlmx7ijw67hr5lfd</sha1>
    </revision>
  </page>
  <page>
    <title>Vector Spaces</title>
    <ns>0</ns>
    <id>519</id>
    <revision>
      <id>522</id>
      <timestamp>2015-04-26T09:09:45Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3684">== Vector Spaces ==
Suppose we have a set $V$ and elements $\mathbf v_1, ..., \mathbf v_i ... \in V$
* we define ''addition'' on $V$ where we map any pair $\mathbf v_i, \mathbf v_j \in V$ to a value $\mathbf v_i + \mathbf v_j$
* and we define the operation ''scalar multiplication'' where for any scalar number $c$ and a vector $\mathbf v \in V$ we have a value $c \cdot \mathbf v$


So, what can we do with elements in a vector space? 
* add two elements 
* multiply them by a scalar 
* it means we should be able to take linear combinations of elements in the space


== Axioms ==
The elements of $V$ are ''vectors'' and $V$ is a space if the axioms hold
* commutativity: $\mathbf v_i + \mathbf v_j = \mathbf v_j + \mathbf v_i$
* associativity: $(\mathbf v_i + \mathbf v_j) + \mathbf v_k = \mathbf v_j + (\mathbf v_i + \mathbf v_k)$
* there exists an element $\mathbf 0 \in V$ s.t. $\mathbf 0 + \mathbf v = \mathbf v$
* for any element $\mathbf v$ there exists the ''opposite'' $-\mathbf v$ s.t. $\mathbf v + (-\mathbf v) = \mathbf 0$
** therefore can define ''difference'' as $\mathbf v_1 - \mathbf v_2 = \mathbf v_1 + (-\mathbf v_2)$

multiplication on scalars ($c$'s are scalars): 
* $c (\mathbf v_1 + \mathbf v_2) = c \mathbf v_1 + c \mathbf v_2$
* $(c_1 + c_2) \mathbf v = c_1 \mathbf v + c_2 \mathbf v$
* $(c_1 \cdot c_2) \cdot \mathbf v =  c_1 \cdot (c_2 \cdot \mathbf v)$
* $1 \cdot \mathbf v = \mathbf v$


=== Implications: ===
* $c \cdot \mathbf 0 = \mathbf 0$
* $0 \cdot \mathbf v = \mathbf 0$
* if $c \cdot \mathbf v = \mathbf 0$ then either $c = 0$ or $\mathbf v = \mathbf 0$
* $c \cdot (- \mathbf v) = - c \cdot \mathbf v$
* $(- c) \cdot \mathbf v = - c \cdot \mathbf v$
* $c (\mathbf v_1 - \mathbf v_2) = c \mathbf v_1 - c \mathbf v_2$
* $(c_1 - c_2) \mathbf v = c_1 \mathbf v - c_2 \mathbf v$




== Example: Coordinate Spaces ==
* $\mathbb R^2$ - real numbers (&quot;$x/y$ plane&quot;)
* e.g. $\begin{bmatrix}
3 \\
2
\end{bmatrix}$, 
$\begin{bmatrix}
0 \\
0
\end{bmatrix}$, 
$\begin{bmatrix}
\pi \\
e
\end{bmatrix}$, ...
* there's a picture that goes with $\mathbb R^2$
* http://habrastorage.org/files/774/a1e/4ef/774a1e4efbfb4ee9996aa4a14d184659.png
* so, we can picture every vector in the space 
* (same for $\mathbb R^3$)


== [[Vector Subspaces]] ==
A subspace of a vector space should form a space on it's own. 


Any line through the origin:
* http://habrastorage.org/files/366/809/70e/36680970ea4e49dd8690c9ae3b9f8e84.png
* is it a vector space? 
* yes. We can take any scalar, and the result will still be on the line 
* if the line is not through the origin, then multiplying by 0 will bring us out of the space - so the origin must be included 


For a [[Matrix]] there are [[Four Fundamental Subspaces]]:
* [[Column Space]]
* [[Row Space]] 
* [[Nullspace]]
* [[Nullspace#Left Nullspace|Left Nullspace]]



== Vector Spaces ==
=== [[Matrix Vector Spaces]] ===
A matrix space is also a vector space, where elements are matrices of the same dimensionality: we can multiply matrices by a scalar and can add two matrices of the same dimension.
* [[Inner Product]]: e.g. $\langle A, B \rangle = \sum_{ij} a_{ij} b_{ij}$
* norm: e.g. [[Frobenius Norm]]: $\| A \|_F = \langle A, A \rangle$



=== [[Function Spaces]] ===
In a function space, the &quot;vectors&quot; are functions:
* we can define an [[Inner Product]] as $\langle f, g \rangle = \int\limits_{-\infty}^{\infty} f(x) \, g(x) \, dx$ with [[Integral]] instead of sum
* and we define [[Orthogonal Functions|orthogonality]] as $\langle f, g \rangle = 0$ 


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Курош А.Г. Курс Высшей Алгебры

[[Category:Linear Algebra]]
[[Category:Vector Spaces]]</text>
      <sha1>l9zifs8ofkze9b8bxu35ztnfis9z84c</sha1>
    </revision>
    <revision>
      <id>722</id>
      <parentid>522</parentid>
      <timestamp>2015-12-06T19:57:28Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3730">== Vector Spaces ==
Suppose we have a set $V$ and elements $\mathbf v_1, ..., \mathbf v_i ... \in V$
* we define ''addition'' on $V$ where we map any pair $\mathbf v_i, \mathbf v_j \in V$ to a value $\mathbf v_i + \mathbf v_j$
* and we define the operation ''scalar multiplication'' where for any scalar number $c$ and a vector $\mathbf v \in V$ we have a value $c \cdot \mathbf v$


So, what can we do with elements in a vector space? 
* add two elements 
* multiply them by a scalar 
* it means we should be able to take linear combinations of elements in the space


== Axioms ==
The elements of $V$ are ''vectors'' and $V$ is a space if the axioms hold
* commutativity: $\mathbf v_i + \mathbf v_j = \mathbf v_j + \mathbf v_i$
* associativity: $(\mathbf v_i + \mathbf v_j) + \mathbf v_k = \mathbf v_j + (\mathbf v_i + \mathbf v_k)$
* there exists an element $\mathbf 0 \in V$ s.t. $\mathbf 0 + \mathbf v = \mathbf v$
* for any element $\mathbf v$ there exists the ''opposite'' $-\mathbf v$ s.t. $\mathbf v + (-\mathbf v) = \mathbf 0$
** therefore can define ''difference'' as $\mathbf v_1 - \mathbf v_2 = \mathbf v_1 + (-\mathbf v_2)$

multiplication on scalars ($c$'s are scalars): 
* $c\, (\mathbf v_1 + \mathbf v_2) = c\, \mathbf v_1 + c\, \mathbf v_2$
* $(c_1 + c_2)\, \mathbf v = c_1 \mathbf v + c_2 \mathbf v$
* $(c_1 \cdot c_2) \cdot \mathbf v =  c_1 \cdot (c_2 \cdot \mathbf v)$
* $1 \cdot \mathbf v = \mathbf v$


=== Implications: ===
* $c \cdot \mathbf 0 = \mathbf 0$
* $0 \cdot \mathbf v = \mathbf 0$
* if $c \cdot \mathbf v = \mathbf 0$ then either $c = 0$ or $\mathbf v = \mathbf 0$
* $c \cdot (- \mathbf v) = - c \cdot \mathbf v$
* $(- c) \cdot \mathbf v = - c \cdot \mathbf v$
* $c\, (\mathbf v_1 - \mathbf v_2) = c\, \mathbf v_1 - c\, \mathbf v_2$
* $(c_1 - c_2)\, \mathbf v = c_1 \mathbf v - c_2 \mathbf v$



== Example: Coordinate Spaces ==
* $\mathbb R^2$ - real numbers (&quot;$x/y$ plane&quot;)
* e.g. &lt;math&gt;\begin{bmatrix}
3 \\
2
\end{bmatrix}&lt;/math&gt;, &lt;math&gt;\begin{bmatrix}
0 \\
0
\end{bmatrix}&lt;/math&gt;, &lt;math&gt;\begin{bmatrix}
\pi \\
e
\end{bmatrix}&lt;/math&gt;, ...
* there's a picture that goes with $\mathbb R^2$
* http://habrastorage.org/files/774/a1e/4ef/774a1e4efbfb4ee9996aa4a14d184659.png
* so, we can picture every vector in the space 
* (same for $\mathbb R^3$)


== [[Vector Subspaces]] ==
A subspace of a vector space should form a space on it's own. 


Any line through the origin:
* http://habrastorage.org/files/366/809/70e/36680970ea4e49dd8690c9ae3b9f8e84.png
* is it a vector space? 
* yes. We can take any scalar, and the result will still be on the line 
* if the line is not through the origin, then multiplying by 0 will bring us out of the space - so the origin must be included 


For a [[Matrix]] there are [[Four Fundamental Subspaces]]:
* [[Column Space]]
* [[Row Space]] 
* [[Nullspace]]
* [[Nullspace#Left Nullspace|Left Nullspace]]



== Vector Spaces ==
=== [[Matrix Vector Spaces]] ===
A matrix space is also a vector space, where elements are matrices of the same dimensionality: we can multiply matrices by a scalar and can add two matrices of the same dimension.
* [[Inner Product]]: e.g. $\langle A, B \rangle = \sum_{ij} a_{ij} b_{ij}$
* norm: e.g. [[Frobenius Norm]]: $\| A \|_F = \langle A, A \rangle$



=== [[Function Spaces]] ===
In a function space, the &quot;vectors&quot; are functions:
* we can define an [[Inner Product]] as $\langle f, g \rangle = \int\limits_{-\infty}^{\infty} f(x) \, g(x) \, dx$ with [[Integral]] instead of sum
* and we define [[Orthogonal Functions|orthogonality]] as $\langle f, g \rangle = 0$ 


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Курош А.Г. Курс Высшей Алгебры

[[Category:Linear Algebra]]
[[Category:Vector Spaces]]</text>
      <sha1>6scxzg5ndmwp8ig1qbog7gaj48ogspo</sha1>
    </revision>
    <revision>
      <id>789</id>
      <parentid>722</parentid>
      <timestamp>2017-06-27T10:52:11Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4632">== Vector Spaces ==
Suppose we have a set of vectors $V$ and elements $\mathbf v_1, ..., \mathbf v_i ... \in V$
* we define ''addition'' on $V$ where we map any pair $\mathbf v_i, \mathbf v_j \in V$ to a value $\mathbf v_i + \mathbf v_j$
* and we define the operation ''scalar multiplication'' where for any scalar number $c$ and a vector $\mathbf v \in V$ we have a value $c \cdot \mathbf v$


So, what can we do with elements in a vector space? 
* add two elements 
* multiply them by a scalar 
* it means we should be able to take linear combinations of elements in the space


== Axioms ==
The elements of $V$ are ''vectors'' and $V$ is a space if the axioms hold
* commutativity: $\mathbf v_i + \mathbf v_j = \mathbf v_j + \mathbf v_i$
* associativity: $(\mathbf v_i + \mathbf v_j) + \mathbf v_k = \mathbf v_j + (\mathbf v_i + \mathbf v_k)$
* there exists an element $\mathbf 0 \in V$ s.t. $\mathbf 0 + \mathbf v = \mathbf v$
* for any element $\mathbf v$ there exists the ''opposite'' $-\mathbf v$ s.t. $\mathbf v + (-\mathbf v) = \mathbf 0$
** therefore can define ''difference'' as $\mathbf v_1 - \mathbf v_2 = \mathbf v_1 + (-\mathbf v_2)$

multiplication on scalars ($c$'s are scalars): 
* $c\, (\mathbf v_1 + \mathbf v_2) = c\, \mathbf v_1 + c\, \mathbf v_2$
* $(c_1 + c_2)\, \mathbf v = c_1 \mathbf v + c_2 \mathbf v$
* $(c_1 \cdot c_2) \cdot \mathbf v =  c_1 \cdot (c_2 \cdot \mathbf v)$
* $1 \cdot \mathbf v = \mathbf v$


=== Implications: ===
* $c \cdot \mathbf 0 = \mathbf 0$
* $0 \cdot \mathbf v = \mathbf 0$
* if $c \cdot \mathbf v = \mathbf 0$ then either $c = 0$ or $\mathbf v = \mathbf 0$
* $c \cdot (- \mathbf v) = - c \cdot \mathbf v$
* $(- c) \cdot \mathbf v = - c \cdot \mathbf v$
* $c\, (\mathbf v_1 - \mathbf v_2) = c\, \mathbf v_1 - c\, \mathbf v_2$
* $(c_1 - c_2)\, \mathbf v = c_1 \mathbf v - c_2 \mathbf v$



== Example: Coordinate Spaces ==
* $\mathbb R^2$ - real numbers (&quot;$x/y$ plane&quot;)
* e.g. &lt;math&gt;\begin{bmatrix}
3 \\
2
\end{bmatrix}&lt;/math&gt;, &lt;math&gt;\begin{bmatrix}
0 \\
0
\end{bmatrix}&lt;/math&gt;, &lt;math&gt;\begin{bmatrix}
\pi \\
e
\end{bmatrix}&lt;/math&gt;, ...
* there's a picture that goes with $\mathbb R^2$
* http://habrastorage.org/files/774/a1e/4ef/774a1e4efbfb4ee9996aa4a14d184659.png
* so, we can picture every vector in the space 
* (same for $\mathbb R^3$)


== Linear Span ==
A ''linear span'' (or just ''span'') of a set of vectors $V = \{ \mathbf v_1, ..., \mathbf v_n  \}$ 
* is a set of all linear combinations of these vectors:
* $\text{span}(V) = \{ \sum \beta_j \mathbf v_i \ \forall \beta_j \in \mathbb R \}$
* Linear span of $V$ is a Vector Space

Unique representation
* if vectors of $V$ are linearly independent and $\mathbf b \in V$ 
* then $\mathbf b$ is a unique linear combinations of vectors from $V$
* i.e. $\mathbf b = \sum \beta_j \mathbf v_i$ and all $\beta_j$ are unique


== Basis ==
Maximal Independent Subset
* if $V^*$ is maximal independent subset of $V$ (all vectors in $V$ are linearly independent and $V^*$ is not contained in any other subset of linearly independent vectors)
* then $\text{span}(V) = \text{span}(V^*)$
* and $V^*$ is the ''basis'' for $\text{span}(V)$



== [[Vector Subspaces]] ==
A subspace of a vector space should form a space on it's own. 


Any line through the origin:
* http://habrastorage.org/files/366/809/70e/36680970ea4e49dd8690c9ae3b9f8e84.png
* is it a vector space? 
* yes. We can take any scalar, and the result will still be on the line 
* if the line is not through the origin, then multiplying by 0 will bring us out of the space - so the origin must be included 


For a [[Matrix]] there are [[Four Fundamental Subspaces]]:
* [[Column Space]] (or &quot;range&quot;)
* [[Row Space]] 
* [[Nullspace]]
* [[Nullspace#Left Nullspace|Left Nullspace]]



== Vector Spaces ==
=== [[Matrix Vector Spaces]] ===
A matrix space is also a vector space, where elements are matrices of the same dimensionality: we can multiply matrices by a scalar and can add two matrices of the same dimension.
* [[Inner Product]]: e.g. $\langle A, B \rangle = \sum_{ij} a_{ij} b_{ij}$
* norm: e.g. [[Frobenius Norm]]: $\| A \|_F = \langle A, A \rangle$



=== [[Function Spaces]] ===
In a function space, the &quot;vectors&quot; are functions:
* we can define an [[Inner Product]] as $\langle f, g \rangle = \int\limits_{-\infty}^{\infty} f(x) \, g(x) \, dx$ with [[Integral]] instead of sum
* and we define [[Orthogonal Functions|orthogonality]] as $\langle f, g \rangle = 0$ 


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Курош А.Г. Курс Высшей Алгебры
* [[Matrix Computations (book)]]

[[Category:Linear Algebra]]
[[Category:Vector Spaces]]</text>
      <sha1>dgsotqi6vvewh32b7iisiapy4e2a6mm</sha1>
    </revision>
  </page>
  <page>
    <title>Vector Subspaces</title>
    <ns>0</ns>
    <id>520</id>
    <revision>
      <id>523</id>
      <timestamp>2014-12-18T21:55:24Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3188">== Subspaces ==
A subspace of a [[Vector Space]] is a vector space on its own 


== Illustration by example ==
Suppose we have a space $\mathbb R^n$ (e.g. $\mathbb R^2$)

What if we removed one vector? Say, we remove $\bf 0$?
* The space becomes no longer closed under multiplication by scalar. $\forall \mathbf x: \mathbf 0 \cdot \mathbf x = 0$ which we removed. 
* this is not a vector space - it must be closed under all operations 


Another candidate:
* let's consider the positive quarter of the $x/y$ plane (where $x_1, x_2 &gt; 0$):
* http://habrastorage.org/files/76e/e20/e60/76ee20e60bb14133a54723133551d98a.png
* let's take a vector $\vec x$ from there and multiply it by -1. We no longer stay in this quarter.
* So this is not a vector space 


Any line through the origin:
* http://habrastorage.org/files/366/809/70e/36680970ea4e49dd8690c9ae3b9f8e84.png
* is it a vector space? 
* yes. We can take any scalar, and the result will still be on the line 
* if the line is not through the origin, then multiplying by 0 will bring us out of the space - so the origin must be included 


So, a ''subspace'' of a space should form a space on its own: it should be closed under all possible operations on elements in the subspace


=== Subspaces of $\mathbb R^2$ ===
* whole $\mathbb R^2$ 
* any line through the origin $\mathbf 0_2$
* only vector $\mathbf 0_2$


=== Subspaces of $\mathbb R^3$ ===
* whole $\mathbb R^3$ 
* only vector $\mathbf 0_3$
* any line through the origin $\mathbf 0_3$
* any plane through the origin $\mathbf 0_3$


=== Subspaces from Matrices ===
For a [[Matrix]] there are [[Four Fundamental Subspaces]]:
* [[Column Space]]
* [[Row Space]] 
* [[Nullspace]]
* [[Nullspace#Left Nullspace|Left Nullspace]]


==== Column Space ====
Suppose we have a matrix $A \in \mathbb R^{3 \times 2}$

$A = \begin{bmatrix}
1 &amp; 3 \\
2 &amp; 3 \\
4 &amp; 1 \\
\end{bmatrix}$

Subspace from columns - $C(A)$ - the [[Column Space]] of $A$:
* we cannot just take the two columns and call it a subspace: 
* it also must include all linear combinations of these columns
* these linear combinations of two vectors form a plane - a subspace $\mathbb R^2$ in the space $\mathbb R^3$
* since we include all possible combinations, we're guaranteed to have a subspace 
* http://habrastorage.org/files/cf5/432/f56/cf5432f561ec4f14888e8b376c5f438b.png
* $v_1$ and $v_2$ are 1st and 2nd columns of $A$ - they form a plane through the origin




=== Subspace Properties ===
Take $\mathbb R^3$ and 2 subspaces: $P$ (plane) and $L$ (line)
* is $P \cup L$ a subspace? 
** $P \cup L$ $\equiv$ all vectors in $P$ or $L$ or both
** not a subspace: take $v_1 \in P$ and $v_2 \in L$. $v_1 + v_2$ maybe somewhere else - go outside of the union
* is $P \cap L$ a subspace? 
** $P \cap L \equiv$ vectors in both $P$ and $L$
** yes (see reasoning below)


$S \cap T$ is a subspace: 
* if $v, w \in S$ then $v + w \in S$ (and all linear combinations)
* if $v, w \in T$ then $v + w \in T$ (and all linear combinations)
* then if $v, w \in S \cap T$ then  $v + w \in S \cap T$



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Курош А.Г. Курс Высшей Алгебры

[[Category:Linear Algebra]]</text>
      <sha1>7hae8hbk7sclivw773r37cck59kelel</sha1>
    </revision>
  </page>
  <page>
    <title>Vector Space</title>
    <ns>0</ns>
    <id>521</id>
    <redirect title="Vector Spaces" />
    <revision>
      <id>524</id>
      <timestamp>2014-12-18T21:55:51Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27">#REDIRECT [[Vector Spaces]]</text>
      <sha1>salixfxoh40xr2xu7oeeb48qj8v1cgn</sha1>
    </revision>
  </page>
  <page>
    <title>Orthogonality</title>
    <ns>0</ns>
    <id>522</id>
    <revision>
      <id>525</id>
      <timestamp>2015-04-24T08:31:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="744">== Orthogonality ==

There are several definitions of ''orthogonality'':
* Two Euclidean vectors are ''orthogonal'' if they are perpendicular, i.e., they form a right angle.
* Two vectors, $\mathbf x$ and $\mathbf y$ are ''orthogonal'' if their [[Inner Product]] $\mathbf x^T \mathbf y = 0$ This relationship is denoted $\mathbf x \, \bot \, \mathbf y$: [[Vector Orthogonality]]
* Two [[Vector Subspaces]] are ''orthogonal'' if each vector from one subspace is orthogonal to each vector of another subspace: [[Space Orthogonality]]
* Two [[Functions]] are orthogonal if their inner product is 0: [[Orthogonal Functions]]


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* http://en.wikipedia.org/wiki/Orthogonality

[[Category:Mathematics]]</text>
      <sha1>guu6m8ktnkyepynm51cinh959e1izjm</sha1>
    </revision>
  </page>
  <page>
    <title>Vector Orthogonality</title>
    <ns>0</ns>
    <id>523</id>
    <revision>
      <id>526</id>
      <timestamp>2014-12-18T21:57:36Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1562">== Vector [[Orthogonality]] ==
In geometry, we call two vectors $\mathbf x$ and $\mathbf y$ ''orthogonal'' of the angle between then is 90 - i.e. they are perpendicular. 


http://habrastorage.org/files/88f/e6b/149/88fe6b149c7148d9b93fa4a1fb203206.png


=== Inner Product Test ===
* If $\mathbf x$ and $\mathbf y$ are perpendicular, then we can use the Pythagoras theorem
* $\| \mathbf x \|^2 + \| \mathbf y \|^2 = \| \mathbf x + \mathbf y* \|^2$ 
* is there an easier way to tell if 2 vectors are orthogonal?
* yes! if their [[Inner Product]] is zero, then they are: $\mathbf x^T \mathbf y = \sum x_i y_i = 0 \Rightarrow \mathbf x \, \bot \, \mathbf y$


Why?
* $\| \mathbf x \|^2 = \left(\sqrt{\sum x_i^2 } \right)^2 = \mathbf x^T \mathbf x$
* let's expand the Pythagoras theorem: 
* $\| \mathbf x \|^2 + \| \mathbf y \|^2 = \| \mathbf x + \mathbf y* \|^2$
* $\mathbf x^T \mathbf x + \mathbf y^T \mathbf y = (\mathbf x + \mathbf y)^T (\mathbf x + \mathbf y) = \mathbf x^T \mathbf x + \mathbf x^T \mathbf y + \mathbf y^T \mathbf x + \mathbf y^T \mathbf y$
* or $\mathbf x^T \mathbf y + \mathbf y^T \mathbf x = 0$
* note that $\mathbf x^T \mathbf y = \mathbf y^T \mathbf x$, so we have 
* $2 \mathbf x^T \mathbf y = 0$ or $\mathbf x^T \mathbf y = 0$


=== Zero Vectors ===
Zero vectors $\mathbf 0$ are orthogonal to any vector in its space
* $\mathbf 0 \; \bot \; \mathbf x$ $\forall \mathbf x$ 
* because $\mathbf 0^T \mathbf x = 0$




== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* http://en.wikipedia.org/wiki/Orthogonality

[[Category:Linear Algebra]]</text>
      <sha1>esk8xgppgms2lsup97d1rzdu3uxb491</sha1>
    </revision>
  </page>
  <page>
    <title>Space Orthogonality</title>
    <ns>0</ns>
    <id>524</id>
    <revision>
      <id>527</id>
      <timestamp>2014-12-18T22:01:35Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2800">== Space Orthogonality ==
Two vectors [[Vector Spaces|(sub)spaces]] can also be [[Orthogonality|orthogonal]] 


Consider two subspaces $S$ and $T$
* $S \; \bot \; T$ means that $\forall \mathbf s \in S, \forall \mathbf t \in T: \mathbf s \; \bot \; \mathbf t$
* i.e. if every vector in $T$ is [[Vector Orthogonality|orthogonal]] to every vector in $S$, then $S$ and $T$ are ''orthogonal''


== Examples ==
=== Example 1 ===
Suppose you have two spaces: a wall and a floor. Are they orthogonal? 
* http://habrastorage.org/files/40a/44a/1b5/40a44a1b5a02484cbab4cbff0176e6f2.png
* take one vector from the wall that is 45° to one of the axis. It's not orthogonal to the floor! it's 45°
* also, there are vectors that belong to both subspaces (and not just the origin!) - these vectors are not orthogonal 

So, if two spaces intersect in more than just the zero-vector, then they cannot be orthogonal 


=== Example 2 ===
Two subspaces that meet in $\mathbf 0$ can be orthogonal

http://habrastorage.org/files/a8f/5a6/c88/a8f5a6c88d5641afb9845c57911c0b15.png


=== [[Row space]] and [[Nullspace]] ===
Row space $C(A^T)$ and nullspace $N(A)$ are orthogonal.
* http://habrastorage.org/files/c67/a41/cc5/c67a41cc5bfb4bcaa634b1135f5d97ad.png

why?

Let's consider only rows from $A$
* $\mathbf x \in N(A) \Rightarrow A \mathbf x = \mathbf 0$
* $\begin{bmatrix}
— (\text{row 1}) \,— \\ 
— (\text{row 2}) \,— \\ 
 \vdots   \\ 
— (\text{row $n$}) \,— 
\end{bmatrix} \cdot \mathbf x = \begin{bmatrix}
0 \\ 0 \\ \vdots \\ 0
\end{bmatrix}$
* or $\begin{bmatrix}
(\text{row 1})^T \mathbf x = 0 \\ 
(\text{row 2})^T \mathbf x = 0 \\ 
 \vdots   \\ 
(\text{row $n$})^T \mathbf x = 0 \\ 
\end{bmatrix}$
* so $\mathbf x$ is orthogonal to all rows in $A$ 

what else is in the row space? linear combinations of rows of $A$ 
* $c_1 \cdot \text{row 1} + \ ... \ + c_n \cdot \text{row $n$}$ what if we multiply it by $\mathbf x$?
* $(c_1 \cdot \text{row 1} + \ ... \ + c_n \cdot \text{row $n$})^T \mathbf x = (c_1 \cdot \text{row 1})^T \mathbf x + \ ... \ + (c_n \cdot  \text{row $n$})^T \mathbf x = c_1 \cdot  \underbrace{(\text{row 1})^T \mathbf x}_{0} + \ ... \ + c_n \cdot  \underbrace{(\text{row $n$})^T \mathbf x}_{0} = 0$


=== [[Column Space]] and Left Nullspace ===

http://habrastorage.org/files/11e/4ad/d32/11e4add32dbe4ba0a4aa6ba8adb9b456.png

They are orthogonal for exactly the same reason 
* just transpose $A$ and go through the same argument as for row space and nullspace


== Orthogonal Compliments ==
$N(A) \; \bot \; C(A^T)$ and $\text{dim} N(A) + \text{dim} C(A^T) = n$
* they add up to the whole space 
* so they are ''orthogonal compliments'' in $\mathbb R^n$


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* http://en.wikipedia.org/wiki/Orthogonality

[[Category:Linear Algebra]]</text>
      <sha1>c93hqwxxjflxqabueyd27wh8xrfocpp</sha1>
    </revision>
  </page>
  <page>
    <title>Projection onto Subspaces</title>
    <ns>0</ns>
    <id>525</id>
    <revision>
      <id>528</id>
      <timestamp>2015-05-08T16:16:21Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12300">$\require{cancel}$

== Projections ==
Suppose we have an $n$-dimensional subspace that we want to project on 
* what do we do? 


== Two-Dimensional Case: Motivation and Intuition ==
Suppose we have two vectors $\mathbf a$ and $\mathbf b$
* we want to ''project'' $\mathbf b$ to $\mathbf a$: find a point on $\mathbf a$ that is closest to $\mathbf b$ 

http://habrastorage.org/files/2fa/2d0/3be/2fa2d03be62e43f3a14f0e4c7bb1398c.png


* let $\mathbf e$ be the vector from $\mathbf b$ to $\mathbf  a$ - it's our ''projection error'' - how much we're wrong about it
* let $\mathbf p$ be the projection of $\mathbf  b$ to $\mathbf  a$ 
* $\mathbf e = \mathbf b - \mathbf p$ 


=== Trigonometry ===
http://habrastorage.org/files/a46/b84/d2b/a46b84d2b26c4f678d84ec343ce4d0a8.png
* (Triangle method of subtraction)

Can use trigonometry to do it
* magnitude is $\| \mathbf e \| = \sqrt{ \| \mathbf p \| ^2 - \| \mathbf b \|^2 - 2 \cdot \| \mathbf p \| \cdot \| \mathbf b \| }$
* so we want to find such $\mathbf p$ that minimizes the magnitude of $\mathbf e$
* it's nasty, we don't want to deal with it
* alternatively can use Linear Algebra for that 


=== Linear Algebra ===
The ''closest'' - means that $\mathbf e$ must be as small as possible
* it's possible when $\mathbf e \; \bot \; \mathbf a$
* we don't know $\mathbf p$, but can express it in terms of $\mathbf a$: 
** we know that $\mathbf p$ lies on the line that's formed by $\mathbf a$,
** thus $\mathbf p$ is some multiple of $\mathbf a$, or $\mathbf p = x \cdot \mathbf a$
* so $\mathbf e = \mathbf b - \mathbf p = \mathbf b - x \cdot \mathbf a$


We want to find this $x$ 
* $\mathbf a \; \bot \; \mathbf e$ $\Rightarrow$ $\mathbf a \; \bot \; (\mathbf b - x \cdot  \mathbf a)$ 
* or $\mathbf a^T (\mathbf b - x \cdot \mathbf a) = 0$ (by [[Vector Orthogonality]])
* let's find $x$
* $\mathbf a^T (\mathbf b - x \cdot \mathbf a) = 0$, $\mathbf a^T \mathbf b - x \cdot \mathbf a^T \mathbf a = 0$, $x \cdot \mathbf a^T \mathbf a = \mathbf a^T \mathbf b$
* $x = \cfrac{\mathbf a^T \mathbf b}{\mathbf a^T \mathbf a}$ (the $\cos \theta$ is built in, so we don't need to deal with angles)

Projection $\mathbf p$
* $x = \| \mathbf p\|$,  $x$ is the distance (magnitude of $\mathbf p$), what's about the vector $\mathbf p$ itself? 
* just multiply $x$ by $\mathbf a$:
* $\mathbf p = x \cdot \mathbf a = \mathbf a \cdot \cfrac{\mathbf a^T \mathbf b}{\mathbf a^T \mathbf a}$


=== Properties ===
What if we double $\mathbf b$? 
* so let $\mathbf b' = 2 \mathbf b$ 
* $\mathbf p' = \mathbf a \cdot \cfrac{\mathbf a^T \mathbf b'}{\mathbf a^T \mathbf a} = 2 \mathbf a \cdot \cfrac{\mathbf a^T \mathbf b}{\mathbf a^T \mathbf a} = 2 \mathbf p$
* the projection goes 2 times further 

What if we double $\mathbf a$
* it shouldn't change anything - $\mathbf a' = 2 \cdot \mathbf a$ still defines the same subspace (the same line)


What if $\mathbf b$ is on the line
* i.e. $\mathbf b$ is a multiple of $\mathbf a$
* $\mathbf b = c \cdot \mathbf a$
* then the projection $\mathbf p$ of $\mathbf b$ onto $\mathbf a$ is $\mathbf p = \mathbf b$



== Projection onto Subspaces ==
=== Motivation ===
Suppose we cannot solve $A \mathbf x = \mathbf b$
* i.e. $\mathbf b$ is not in $C(A)$
* but we can try to get as close as possible to $C(A)$ by projecting onto it!
* how do we do it? $C(A)$ is all the combinations of columns in $A$, so they form a hyperplane
* $\mathbf b$ is not on this hyperplane - otherwise we would not need to project on it
* this is what we do for [[Linear Least Squares]] via [[Normal Equation]]


=== Projection onto Plane ===
Example $\mathbb R^3 \to \mathbb R^2$
* suppose that $\text{dim } C(A) = 2$, i.e. the basis made of columns of $A$: $\mathbf a_1$ and $\mathbf a_2$, $A = \Bigg[ \ \mathop{\mathbf a_1}\limits_|^| \ \mathop{\mathbf a_1}\limits_|^| \ \Bigg]$
** $\mathbf a_1$ and $\mathbf a_2$ are [[Linear Independence|linearly independent]]
* http://habrastorage.org/files/245/834/296/245834296b494b6a8f42522ff1feb119.png
* $\mathbf b$ is not on the plane $C(A)$, but we project on it to get $\mathbf p$ 
* $\mathbf e = \mathbf b - \mathbf p$ is our projection error


$\mathbf e$ - want to make it as small as possible, 
* so $\mathbf e \; \bot \; \text{plane}$ or $\mathbf b - \mathbf p \; \bot \; \text{plane}$ 
* we want to find what combinations of the basis vectors $\mathbf a_1$ and $\mathbf a_2$ will make $\mathbf p$
* thus we express $\mathbf p$ as $\mathbf p = \hat x_1 \mathbf a_1 + \hat x_2 \mathbf a_2$
* since these $\mathbf a_1$ and $\mathbf a_2$ are from the matrix $A$, we can write $\mathbf p = A \mathbf{\hat x}$ 
* so the goal is to find the right combinations of $\mathbf a_1$ and $\mathbf a_2$ s.t. $\mathbf e \; \bot \; \text{plane}$


Now we're solving $\mathbf p = A \mathbf{\hat x}$ 
* how to find $\mathbf{\hat x}$? 
* $\mathbf e = \mathbf b - \mathbf p = \mathbf b - A \mathbf{\hat x}$, 
* $\mathbf e \; \bot \; \text{plane}$, or $\mathbf e \; \bot \; \mathbf a_1$ and $\mathbf e \; \bot \; \mathbf a_2$ - $\mathbf e$ is [[Vector Orthogonality|orthogonal]] to every vector in $C(A)$
* if vectors are orthogonal, their [[Dot Product]] is zero. So now we have two equations:
** $\mathbf a_1^T (\mathbf b - A \mathbf{\hat x}) = 0$
** $\mathbf a_2^T (\mathbf b - A \mathbf{\hat x}) = 0$
* let's write it in the matrix form:
** $A^T = \begin{bmatrix}
- \ \mathbf a_1^T - \\
- \ \mathbf a_2^T - \\
\end{bmatrix}$
** $\begin{bmatrix}
- \ \mathbf a_1^T - \\
- \ \mathbf a_2^T - \\
\end{bmatrix} \cdot (\mathbf b - A \mathbf{\hat x}) = \begin{bmatrix}
0 \\
0 \\
\end{bmatrix}$ 
** or $A^T \mathbf e = \mathbf 0$


* thus $\mathbf e \in N(A^T)$ - the projection error belongs to the [[Nullspace#Left Nullspace|left nullspace]]!
* and we know that $C(A) \; \bot \; N(A^T)$ (see [[Space Orthogonality]])
* http://habrastorage.org/files/f3a/ab5/ebc/f3aab5ebc51540579f18f34bff5d4476.png

Let's solve it
* $A^T \mathbf e = \mathbf 0$, $\mathbf e = \mathbf b - \mathbf p = \mathbf b - A \mathbf{ \hat x}$
* so $A^T (\mathbf b - A \mathbf{\hat x}) = 0$
* $A^T \mathbf b - A^T A \mathbf{\hat x} = 0$
* $A^T A \mathbf{\hat x} = A^T \mathbf b$
* or $\mathbf{\hat x} = (A^T A)^{-1} A^T \mathbf b$ 
* $A^T A$ is invertible when $A$ has independent columns (see the theorem below)


The projection $\mathbf p$
* this way we found the coefficients $\mathbf{\hat x}$, but not the projection $\mathbf p$
* we need to take all vectors of $C(A)$ (columns of $A$) and scale by $\mathbf{\hat x}$
* thus we have $\mathbf p = A \mathbf{\hat x} = A (A^T A)^{-1} A^T \mathbf b$
** recall the 1-dim case: $\mathbf p = x \cdot \mathbf a = \mathbf a \cdot \cfrac{\mathbf a^T \mathbf b}{\mathbf a^T \mathbf a}$ - it's very similar!



== Projection Matrix ==
How do we use a nice matrix representation for projecting onto subspaces?
* we introduce a ''Projection'' matrix $P$ that projects from one subspace to another


=== Projecting on a Line ===
It's $\mathbb R^n \to \mathbb R^1$ case

Let $P$ be the projection matrix, i.e. 
* $P$ s.t. $\mathbf p = P \mathbf b$ - a matrix $P$ with which we can express the [[Linear Transformation]] that brings $\mathbf b$ to $\mathbf p$
* we know that $\mathbf p = \mathbf a \cdot \cfrac{\mathbf a^T \mathbf b}{\mathbf a^T \mathbf a}$
* so $\mathbf p = P \mathbf b$ or $P = \cfrac{\mathbf a \mathbf a^T}{\mathbf a^T \mathbf a}$
* in the numerator we have an [[Outer Product]], and we have an [[Inner Product]] in the denominator - it's $\| \mathbf a \|^2$


==== Properties ====
* it's normalized rank-1 matrix
* $\text{dim } C(P) = 1$, it consists of a line through $\mathbf a$, and $\mathbf a$ is the basis for $C(P)$
* $P$ is symmetric: 
** $P^T = \left( \cfrac{\mathbf a \mathbf a^T}{\mathbf a^T \mathbf a} \right)^T = \cfrac{1}{\mathbf a^T \mathbf a} (\mathbf a \mathbf a^T)^T = \cfrac{1}{\mathbf a^T \mathbf a} \mathbf a^T (\mathbf a^T)^T = \cfrac{\mathbf a \mathbf a^T}{\mathbf a^T \mathbf a} = P$
* what happens if we project something twice?
** it shouldn't do anything the 2nd time 
** so $\mathbf p = P \cdot \mathbf b = P \cdot P \cdot \mathbf b$
** or $P^2 = P$


=== General Case ===
It's $\mathbb R^n \to \mathbb R^k$ case
* from the previous example we learned that $\mathbf p = A \mathbf{\hat x} = A (A^T A)^{-1} A^T \mathbf b$
* so it means that $P = A (A^T A)^{-1} A^T$ 

Note: 
* we cannot expand $(A^T A)^{-1}$ as $A^{-1} (A^T)^{-1}$ because we assume that $A$ is not invertible
* if $A$ is invertible, then it would span the entire space and $P = I$


==== Properties ====
$P$ from $n$-dim has the same properties as $P$ for 1-dim
* $P^T = P$
* $P^2 = P$
** $P^2 = \Big(A (A^T A)^{-1} A^T \Big) \cdot \Big(A (A^T A)^{-1} A^T \Big) = A (A^T A)^{-1} \cancel{A^T A (A^T A)^{-1}} A^T = A (A^T A)^{-1} A^T = P$


We want to project $\mathbf b$. 
* if $\mathbf b \in C(A)$ then $P \mathbf b = \mathbf b$
** $\mathbf b \in C(A)$ $\Rightarrow$ $\mathbf b$ is a combination of columns of $A$ 
** so $\mathbf b = A \mathbf x$, thus $p = P \mathbf b = A (A^T A)^{-1} A^T \mathbf p = A \cancel{(A^T A)^{-1} A^T A} \mathbf x = A \mathbf x = \mathbf b$
* if $\mathbf b \; \bot \; C(A)$ then $P \mathbf b = \mathbf 0$ 
** $\mathbf b \; \bot \; C(A) \Rightarrow A^T \mathbf b = \mathbf 0$ or $\mathbf b \in N(A^T)$
** $P \mathbf b = A (A^T A)^{-1} \underbrace{A^T \mathbf b}_{\mathbf 0} = \mathbf 0$



=== $P$ as an action of $A$ ===
We can show the projection matrix $P$ as an action performed on $A$ 
* in terms of pictures, here's what $P$ does:

http://habrastorage.org/files/3fd/d21/ded/3fdd21ded0584e229a06f03ca6c0689c.png



Picture 
* $\mathbf b \not \in C(A)$ so cannot solve $A \mathbf x = \mathbf b$. 
* project on $C(A)$: solve $A^T A \mathbf{\hat x} = A^T \mathbf b$ instead
* at the same time, there's another part of $\mathbf b$ - it's $\mathbf e \in N(A^T)$, $\mathbf b = \mathbf p + \mathbf e$
* $\mathbf b = P \mathbf b + \mathbf e$
* $\mathbf e$ is also a projection of $\mathbf b$, but on $N(A^T)$
* the projection matrix is $(I - P) \mathbf b$ - this is the projection onto space orthogonal to $A$
* check: $\mathbf p + \mathbf e = P \mathbf b + (I - P) \mathbf b = \mathbf b$
* $(I - P)$ is a projection matrix, so it obeys all the rules and properties of projection matrices


When $P$ projects on some subspace, $I - P$ projects onto the perpendicular subspace


== Theorem: $A^T A$ is Invertible ==
See this theorem in [[Gram Matrices]]


== Projection onto Orthogonal Basis ==
Let $\mathbf q_1, \ ... \ , \mathbf q_n \in \mathbb R^m$ be a set of orthonormal vectors 
* $Q = \Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^| \ \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg]$. It's an [[Orthogonal Matrix]]
* suppose we want to project on the subspace $C(Q)$
* Projection matrix $P$, usual case: $P = A (A^T A)^{-1} A^T$
* For orthogonal matrices $Q^T Q = I$, so $P = Q (Q^T Q)^{-1} Q^T = Q Q^T$


Thus, to project $\mathbf b$ onto $C(Q)$ we do this: $\mathbf p = P \mathbf b$
* $\mathbf p = P \mathbf b = Q (Q^T \mathbf b) = \Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^|  \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg] \begin{bmatrix}
\mathbf q_1^T \mathbf b \\
\vdots \\
\mathbf q_n^T \mathbf b \\
\end{bmatrix} = \mathbf q_1 (\mathbf q_1^T \mathbf b) + \ ... \ + \mathbf q_n (\mathbf q_n^T \mathbf b)$


What if $m = n$? 
* $Q$ is square and then $Q Q^T = I$ as well
* That means that $P = I$, i.e. the basis spans the entire space
* but still, $\mathbf b = \mathbf q_1 (\mathbf q_1^T \mathbf b) + \ ... \ + \mathbf q_n (\mathbf q_n^T \mathbf b)$
* why is it useful? because it enables us to decompose a vectors into perpendicular pieces 
* this is the foundation of the [[Fourier Transformation]]!


== Applications ==
* [[Normal Equation]] in [[Linear Least Squares]]
* [[Fourier Transformation]]


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* The Four Fundamental Subspaces: 4 Lines, G. Strang, [http://web.mit.edu/18.06/www/Essays/newpaper_ver3.pdf] 
* The fundamental theorem of linear algebra, G. Strang [http://www.engineering.iastate.edu/~julied/classes/CE570/Notes/strangpaper.pdf]
* Strang, G. Introduction to linear algebra.
* http://physics-help.info/physicsguide/appendices/vectors.shtml
* http://en.wikipedia.org/wiki/Linear_least_squares_%28mathematics%29


[[Category:Linear Algebra]]</text>
      <sha1>lz1z7ka9bj0lfxipjmmfidq3jdtz5ki</sha1>
    </revision>
  </page>
  <page>
    <title>QR Decomposition</title>
    <ns>0</ns>
    <id>526</id>
    <redirect title="Gram-Schmidt Process" />
    <revision>
      <id>529</id>
      <timestamp>2015-04-26T15:14:17Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="51">#REDIRECT [[Gram-Schmidt Process#QR Factorization]]</text>
      <sha1>31k7xovm3za22avd7vhk42hrmh49wqm</sha1>
    </revision>
  </page>
  <page>
    <title>Inner Product</title>
    <ns>0</ns>
    <id>527</id>
    <revision>
      <id>530</id>
      <timestamp>2014-12-27T10:05:14Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="47">#перенаправление [[Dot Product]]</text>
      <sha1>lne8gblsaxh1mxt29bt900whrw3xxve</sha1>
    </revision>
  </page>
  <page>
    <title>Gram-Schmidt Process</title>
    <ns>0</ns>
    <id>528</id>
    <revision>
      <id>531</id>
      <timestamp>2014-12-27T11:14:11Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7968">$\require{cancel}$

== Gram-Schmidt Process ==
In Linear Algebra, Gram-Schmidt process is a method for orthogonalization: 
* given a matrix $A$ it produces an [[Orthogonal Matrix]] $Q$ from it
* $A$ must have [[Linear Independence|linearly independent]] columns



=== 2D Case ===
Suppose we have two linearly independent vectors $\mathbf a$ and $\mathbf b$
* we want to make them orthogonal $\mathbf a \Rightarrow \mathbf v_1$, $\mathbf b \Rightarrow \mathbf v_2$
* and then we normalize them: $\mathbf v_1 \Rightarrow \mathbf q_1$ and $\mathbf v_2 \Rightarrow \mathbf q_2$
* http://habrastorage.org/files/dc7/5bd/285/dc75bd285d314c4a8da6b7c6d1267716.png
* $\mathbf a$ is already fine, let's keep its direction for $\mathbf q_1$ as well
* $\mathbf b$ is not fine: we want it to be orthogonal to $\mathbf q_1$


How do we produce a vector $\mathbf v_2$ from $\mathbf b$ such that $\mathbf v_2 \; \bot \; \mathbf v_1 = \mathbf a$ 
* http://habrastorage.org/files/dcc/304/33e/dcc30433e98143b2b236fa419bc06d4d.png
* let's [[Projection onto Subspaces|project]] $\mathbf b$ on $\mathbf v_1$, and we get $P \cdot \mathbf v_1 = \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1$
* $\mathbf e$ is our projection error, so $\mathbf e = \mathbf b - P \mathbf v_1 = \mathbf b - P \mathbf v_1 = \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1$
* note that $\mathbf v_2 = \mathbf e$! it has the same length and the same direction 
* so $\mathbf v_2 = \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1$ 
* interpretation: we take the original vector $\mathbf b$ and remove the projection of this vector onto $\mathbf v_1$, and it leaves only the orthogonal part
* now $\mathbf v_1 \; \bot \mathbf v_2$
* let's check: $\mathbf v_1^T \mathbf v_2 = \mathbf v_1^T \left( \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1 \right) = \mathbf v_1^T \mathbf b - \mathbf v_1^T \cdot \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1 = \mathbf v_1^T \mathbf b - \mathbf v_1^T \mathbf b = 0$


To find the final solution, we just normalize $\mathbf v_1$ and $\mathbf v_2$:
* $\mathbf q_1 = \mathbf v_1 / \| \mathbf v_1 \|$ 
* $\mathbf q_2 = \mathbf v_2 / \| \mathbf v_2 \|$



=== 3D Case ===
What if we have 3 vectors $\mathbf a, \mathbf b, \mathbf c$?
* need to find (pair-wise) orthogonal vectors $\mathbf v_1, \mathbf v_2, \mathbf v_3$ and then normalize them
* have $\mathbf v_1 = a$, $\mathbf v_2 = \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \mathbf v_1$
* what about $\mathbf v_3$? Know that we want to have $\mathbf v_3 \; \bot \; \mathbf v_1$ and $\mathbf v_3 \; \bot \; \mathbf v_2$
* for $\mathbf v_3$, we want to subtract its components in direction $\mathbf v_1$ as well as in direction $\mathbf v_2$ 
* so $\mathbf v_3 = \mathbf c - \cfrac{\mathbf v_1^T \mathbf c}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1 - \cfrac{\mathbf v_2^T \mathbf c}{\mathbf v_2^T \mathbf v_2} \cdot \mathbf v_2$


To get $\mathbf q_1, \mathbf q_2, \mathbf q_3$, we just normalize:
* $\mathbf q_1 = \mathbf v_1 / \| \mathbf v_1 \|$ 
* $\mathbf q_2 = \mathbf v_2 / \| \mathbf v_2 \|$
* $\mathbf q_3 = \mathbf v_3 / \| \mathbf v_3 \|$



=== 3D Case Animation ===
[[File:Gram-Schmidt_orthonormalization_process.gif]]

Source: http://en.wikipedia.org/wiki/File:Gram-Schmidt_orthonormalization_process.gif



== [[Column Space]]s ==
Claim: The column space of $A$ does not change when we orthogonalize it


Suppose that we take a matrix $A = \Bigg[ \mathop{\mathbf a_1}\limits_|^| \ \mathop{\mathbf a_2}\limits_|^| \ \cdots \  \mathop{\mathbf a_n}\limits_|^| \Bigg]$ and orthogonalize its columns  into $Q = \Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^| \ \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg]$ 
* Why $C(A) = C(Q)$?
* at each step of the Gram-Schmidt process we take linear combinations from $C(A)$!
* e.g. $\mathbf v_3 = \mathbf c - \alpha_1  \mathbf v_1 - \alpha_2  \mathbf v_2 = \mathbf c - \alpha_1\mathbf a - \alpha_2 \cdot \left(\mathbf b - \alpha_3 \mathbf a \right) = \mathbf c - \alpha_1 \mathbf a - \alpha_2 \mathbf b - \alpha_2 \alpha_3 \mathbf a$
* $\alpha_1 = \cfrac{\mathbf v_1^T \mathbf c}{\mathbf v_1^T \mathbf v_1}, \alpha_2 = \cfrac{\mathbf v_2^T \mathbf c}{\mathbf v_2^T \mathbf v_2}, \alpha_3 = \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1}$ are just scalars 


== QR Factorization ==
We can think of the [[Gram-Schmidt Process]] in the matrix language (like for [[Gaussian Elimination]] that brings us to [[LU Factorization]])
* recall that $C(Q) = C(A)$ 
* because of this, there exists a third matrix $R$ that brings $A$ to $Q$ 
* or, $A = Q R$
* (so we want Gram-Schmidt applied to the columns of $A$)


How to find this $R$?
* $A = QR$, let's multiply both sides by $Q^T$:
* $Q^T A = Q^T Q R$
* since $Q^T Q = I$, we have $R = Q^T A$
* let $A = \Bigg[ \mathop{\mathbf a_1}\limits_|^| \ \mathop{\mathbf a_2}\limits_|^| \ \cdots \  \mathop{\mathbf a_n}\limits_|^| \Bigg]$ and $Q = \Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^| \ \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg]$
* thus we have $R = Q^T A = \begin{bmatrix} 
\mathbf q_1^T \mathbf a_1 &amp; \mathbf q_1^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_1^T \mathbf a_n \\
\mathbf q_2^T \mathbf a_1 &amp; \mathbf q_2^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_2^T \mathbf a_n \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\mathbf q_n^T \mathbf a_1 &amp; \mathbf q_n^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_n^T \mathbf a_n \\
\end{bmatrix}$


Now recall the way we constructed $Q$
* we took $\mathbf q_1 = \mathbf a_1 / \| \mathbf a_1 \|$ and make all other $\mathbf a_i$ orthogonal to it, so $\mathbf q_2^T \mathbf a_1 = \ ... \ = \mathbf q_n^T \mathbf a_1 = 0$
* then we took $\mathbf q_1$ and $\mathbf q_2$ and made all $\mathbf a_3, ..., \mathbf a_n$ orthogonal to them, so $\mathbf q_3^T \mathbf a_2 = \ ... \ = \mathbf q_n^T \mathbf a_2 = 0$
* proceeding this way till the end we see that $R$ is upper-diagonal:
* thus we have $R = Q^T A = \begin{bmatrix} 
\mathbf q_1^T \mathbf a_1 &amp; \mathbf q_1^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_1^T \mathbf a_n \\
0 &amp; \mathbf q_2^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_2^T \mathbf a_n \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \mathbf q_n^T \mathbf a_n \\
\end{bmatrix}$


Note that for the diagonal elements of $R$, $\mathbf q_i^T \mathbf a_i = \| \mathbf v_i \|$
* why? 
* http://habrastorage.org/files/4d5/edf/1db/4d5edf1db6d04f2a9b1310228db15afa.png
* $\mathbf q_i^T \mathbf a_i = \| \mathbf q_i \| \| \mathbf a_i \| \cos \theta$ by the [[Dot Product]] definition
* $\| \mathbf q_i \| = 1$ and $\cos \theta = \cfrac{\| \mathbf v_i \|}{\| \mathbf a_i \|}$, so
* $\mathbf q_i^T \mathbf a_i = \| \mathbf q_i \| \| \mathbf a_i \| \cos \theta = 1 \cdot \cancel{\| \mathbf a_i \|} \cfrac{\| \mathbf v_i \|}{ \cancel{\| \mathbf a_i \|} } = \| \mathbf v_i \|$
* this can be uses to speed up the computation a bit


== Usage ==
This is often used for [[Linear Least Squares]] - to make the [[Normal Equation]] faster


== Implementation code ==
=== Python ===
Implementation of the pseudo-code from the Strang's book:

&lt;pre&gt;
import numpy as np

def qr_factorization(A):
  m, n = A.shape
  Q = np.zeros((m, n))
  R = np.zeros((n, n))

  for j in range(n):
    v = A[:, j]
        
    for i in range(j - 1):
      q = Q[:, i]
      R[i, j] = q.dot(v)
      v = v - R[i, j] * q

    norm = np.linalg.norm(v)
    Q[:, j] = v / norm
    R[j, j] = norm
  return Q, R

A = np.random.rand(13, 10) * 1000
Q, R = qr_factorization(A)

Q.shape, R.shape
np.abs((A - Q.dot(R)).sum()) &lt; 1e-6
&lt;/pre&gt;


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Strang, G. Introduction to linear algebra.
* http://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process
* http://inst.eecs.berkeley.edu/~ee127a/book/login/l_mats_qr.html


[[Category:Linear Algebra]]</text>
      <sha1>sc0tf5cmi262mipri2e7hc6mqkjh7lz</sha1>
    </revision>
    <revision>
      <id>751</id>
      <parentid>531</parentid>
      <timestamp>2016-10-02T20:01:25Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8599">$\require{cancel}$

== Gram-Schmidt Process ==
In Linear Algebra, Gram-Schmidt process is a method for orthogonalization: 
* given a matrix $A$ it produces an [[Orthogonal Matrix]] $Q$ from it
* $A$ must have [[Linear Independence|linearly independent]] columns



=== 2D Case ===
Suppose we have two linearly independent vectors $\mathbf a$ and $\mathbf b$
* we want to make them orthogonal $\mathbf a \Rightarrow \mathbf v_1$, $\mathbf b \Rightarrow \mathbf v_2$
* and then we normalize them: $\mathbf v_1 \Rightarrow \mathbf q_1$ and $\mathbf v_2 \Rightarrow \mathbf q_2$
* http://habrastorage.org/files/dc7/5bd/285/dc75bd285d314c4a8da6b7c6d1267716.png
* $\mathbf a$ is already fine, let's keep its direction for $\mathbf q_1$ as well
* $\mathbf b$ is not fine: we want it to be orthogonal to $\mathbf q_1$


How do we produce a vector $\mathbf v_2$ from $\mathbf b$ such that $\mathbf v_2 \; \bot \; \mathbf v_1 = \mathbf a$ 
* http://habrastorage.org/files/dcc/304/33e/dcc30433e98143b2b236fa419bc06d4d.png
* let's [[Projection onto Subspaces|project]] $\mathbf b$ on $\mathbf v_1$, and we get $P \cdot \mathbf v_1 = \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1$
* $\mathbf e$ is our projection error, so $\mathbf e = \mathbf b - P \mathbf v_1 = \mathbf b - P \mathbf v_1 = \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1$
* note that $\mathbf v_2 = \mathbf e$! it has the same length and the same direction 
* so $\mathbf v_2 = \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1$ 
* interpretation: we take the original vector $\mathbf b$ and remove the projection of this vector onto $\mathbf v_1$, and it leaves only the orthogonal part
* now $\mathbf v_1 \; \bot \mathbf v_2$
* let's check: $\mathbf v_1^T \mathbf v_2 = \mathbf v_1^T \left( \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1 \right) = \mathbf v_1^T \mathbf b - \mathbf v_1^T \cdot \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1 = \mathbf v_1^T \mathbf b - \mathbf v_1^T \mathbf b = 0$


To find the final solution, we just normalize $\mathbf v_1$ and $\mathbf v_2$:
* $\mathbf q_1 = \mathbf v_1 / \| \mathbf v_1 \|$ 
* $\mathbf q_2 = \mathbf v_2 / \| \mathbf v_2 \|$



=== 3D Case ===
What if we have 3 vectors $\mathbf a, \mathbf b, \mathbf c$?
* need to find (pair-wise) orthogonal vectors $\mathbf v_1, \mathbf v_2, \mathbf v_3$ and then normalize them
* have $\mathbf v_1 = a$, $\mathbf v_2 = \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \mathbf v_1$
* what about $\mathbf v_3$? Know that we want to have $\mathbf v_3 \; \bot \; \mathbf v_1$ and $\mathbf v_3 \; \bot \; \mathbf v_2$
* for $\mathbf v_3$, we want to subtract its components in direction $\mathbf v_1$ as well as in direction $\mathbf v_2$ 
* so $\mathbf v_3 = \mathbf c - \cfrac{\mathbf v_1^T \mathbf c}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1 - \cfrac{\mathbf v_2^T \mathbf c}{\mathbf v_2^T \mathbf v_2} \cdot \mathbf v_2$


To get $\mathbf q_1, \mathbf q_2, \mathbf q_3$, we just normalize:
* $\mathbf q_1 = \mathbf v_1 / \| \mathbf v_1 \|$ 
* $\mathbf q_2 = \mathbf v_2 / \| \mathbf v_2 \|$
* $\mathbf q_3 = \mathbf v_3 / \| \mathbf v_3 \|$



=== 3D Case Animation ===
[[File:Gram-Schmidt_orthonormalization_process.gif]]

Source: http://en.wikipedia.org/wiki/File:Gram-Schmidt_orthonormalization_process.gif



=== [[Column Space]]s ===
Claim: The column space of $A$ does not change when we orthogonalize it


Suppose that we take a matrix $A = \Bigg[ \mathop{\mathbf a_1}\limits_|^| \ \mathop{\mathbf a_2}\limits_|^| \ \cdots \  \mathop{\mathbf a_n}\limits_|^| \Bigg]$ and orthogonalize its columns  into $Q = \Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^| \ \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg]$ 
* Why $C(A) = C(Q)$?
* at each step of the Gram-Schmidt process we take linear combinations from $C(A)$!
* e.g. $\mathbf v_3 = \mathbf c - \alpha_1  \mathbf v_1 - \alpha_2  \mathbf v_2 = \mathbf c - \alpha_1\mathbf a - \alpha_2 \cdot \left(\mathbf b - \alpha_3 \mathbf a \right) = \mathbf c - \alpha_1 \mathbf a - \alpha_2 \mathbf b - \alpha_2 \alpha_3 \mathbf a$
* $\alpha_1 = \cfrac{\mathbf v_1^T \mathbf c}{\mathbf v_1^T \mathbf v_1}, \alpha_2 = \cfrac{\mathbf v_2^T \mathbf c}{\mathbf v_2^T \mathbf v_2}, \alpha_3 = \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1}$ are just scalars 


=== Implementation ===
==== Java ====
The implementation is taken from Smile: https://github.com/haifengl/smile/blob/master/core/src/main/java/smile/projection/RandomProjection.java

 double[][] X;
 Math.unitize(X[0]);
 for (int i = 1; i &lt; p; i++) {
     for (int j = 0; j &lt; i; j++) {
         double t = -Math.dot(X[i], X[j]);
         Math.axpy(t, X[j], X[i]);
     }
     Math.unitize(X[i]);
 }

where
* &lt;code&gt;Math.unitize&lt;/code&gt; unit-normalizes the vector
* &lt;code&gt;Math.axpy&lt;/code&gt; updates an array by adding a multiple of another array y = a * x + y.


== QR Factorization ==
We can think of the [[Gram-Schmidt Process]] in the matrix language (like for [[Gaussian Elimination]] that brings us to [[LU Factorization]])
* recall that $C(Q) = C(A)$ 
* because of this, there exists a third matrix $R$ that brings $A$ to $Q$ 
* or, $A = Q R$
* (so we want Gram-Schmidt applied to the columns of $A$)


How to find this $R$?
* $A = QR$, let's multiply both sides by $Q^T$:
* $Q^T A = Q^T Q R$
* since $Q^T Q = I$, we have $R = Q^T A$
* let $A = \Bigg[ \mathop{\mathbf a_1}\limits_|^| \ \mathop{\mathbf a_2}\limits_|^| \ \cdots \  \mathop{\mathbf a_n}\limits_|^| \Bigg]$ and $Q = \Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^| \ \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg]$
* thus we have &lt;math&gt;
R = Q^T A = \begin{bmatrix} 
\mathbf q_1^T \mathbf a_1 &amp; \mathbf q_1^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_1^T \mathbf a_n \\
\mathbf q_2^T \mathbf a_1 &amp; \mathbf q_2^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_2^T \mathbf a_n \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\mathbf q_n^T \mathbf a_1 &amp; \mathbf q_n^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_n^T \mathbf a_n \\
\end{bmatrix}
&lt;/math&gt;


Now recall the way we constructed $Q$
* we took $\mathbf q_1 = \mathbf a_1 / \| \mathbf a_1 \|$ and make all other $\mathbf a_i$ orthogonal to it, so $\mathbf q_2^T \mathbf a_1 = \ ... \ = \mathbf q_n^T \mathbf a_1 = 0$
* then we took $\mathbf q_1$ and $\mathbf q_2$ and made all $\mathbf a_3, ..., \mathbf a_n$ orthogonal to them, so $\mathbf q_3^T \mathbf a_2 = \ ... \ = \mathbf q_n^T \mathbf a_2 = 0$
* proceeding this way till the end we see that $R$ is upper-diagonal:
* thus we have &lt;math&gt;
R = Q^T A = \begin{bmatrix} 
\mathbf q_1^T \mathbf a_1 &amp; \mathbf q_1^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_1^T \mathbf a_n \\
0 &amp; \mathbf q_2^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_2^T \mathbf a_n \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \mathbf q_n^T \mathbf a_n \\
\end{bmatrix}
&lt;/math&gt;


Note that for the diagonal elements of $R$, $\mathbf q_i^T \mathbf a_i = \| \mathbf v_i \|$
* why? 
* http://habrastorage.org/files/4d5/edf/1db/4d5edf1db6d04f2a9b1310228db15afa.png
* $\mathbf q_i^T \mathbf a_i = \| \mathbf q_i \| \| \mathbf a_i \| \cos \theta$ by the [[Dot Product]] definition
* $\| \mathbf q_i \| = 1$ and $\cos \theta = \cfrac{\| \mathbf v_i \|}{\| \mathbf a_i \|}$, so
* $\mathbf q_i^T \mathbf a_i = \| \mathbf q_i \| \| \mathbf a_i \| \cos \theta = 1 \cdot \cancel{\| \mathbf a_i \|} \cfrac{\| \mathbf v_i \|}{ \cancel{\| \mathbf a_i \|} } = \| \mathbf v_i \|$
* this can be uses to speed up the computation a bit


=== Usage ===
This is often used for [[Linear Least Squares]] - to make the [[Normal Equation]] faster


=== Implementation code ===
==== Python ====
Implementation of the pseudo-code from the Strang's book:

&lt;pre&gt;
import numpy as np

def qr_factorization(A):
    m, n = A.shape
    Q = np.zeros((m, n))
    R = np.zeros((n, n))

    for j in range(n):
        v = A[:, j]

        for i in range(j - 1):
            q = Q[:, i]
            R[i, j] = q.dot(v)
            v = v - R[i, j] * q

        norm = np.linalg.norm(v)
        Q[:, j] = v / norm
        R[j, j] = norm
    return Q, R

A = np.random.rand(13, 10) * 1000
Q, R = qr_factorization(A)

Q.shape, R.shape
np.abs((A - Q.dot(R)).sum()) &lt; 1e-6
&lt;/pre&gt;


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Strang, G. Introduction to linear algebra.
* http://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process
* http://inst.eecs.berkeley.edu/~ee127a/book/login/l_mats_qr.html


[[Category:Linear Algebra]]</text>
      <sha1>0unf57xv25ps0qoef8rhq8oskktgctd</sha1>
    </revision>
    <revision>
      <id>752</id>
      <parentid>751</parentid>
      <timestamp>2016-10-02T20:13:31Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>/* Java */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8656">$\require{cancel}$

== Gram-Schmidt Process ==
In Linear Algebra, Gram-Schmidt process is a method for orthogonalization: 
* given a matrix $A$ it produces an [[Orthogonal Matrix]] $Q$ from it
* $A$ must have [[Linear Independence|linearly independent]] columns



=== 2D Case ===
Suppose we have two linearly independent vectors $\mathbf a$ and $\mathbf b$
* we want to make them orthogonal $\mathbf a \Rightarrow \mathbf v_1$, $\mathbf b \Rightarrow \mathbf v_2$
* and then we normalize them: $\mathbf v_1 \Rightarrow \mathbf q_1$ and $\mathbf v_2 \Rightarrow \mathbf q_2$
* http://habrastorage.org/files/dc7/5bd/285/dc75bd285d314c4a8da6b7c6d1267716.png
* $\mathbf a$ is already fine, let's keep its direction for $\mathbf q_1$ as well
* $\mathbf b$ is not fine: we want it to be orthogonal to $\mathbf q_1$


How do we produce a vector $\mathbf v_2$ from $\mathbf b$ such that $\mathbf v_2 \; \bot \; \mathbf v_1 = \mathbf a$ 
* http://habrastorage.org/files/dcc/304/33e/dcc30433e98143b2b236fa419bc06d4d.png
* let's [[Projection onto Subspaces|project]] $\mathbf b$ on $\mathbf v_1$, and we get $P \cdot \mathbf v_1 = \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1$
* $\mathbf e$ is our projection error, so $\mathbf e = \mathbf b - P \mathbf v_1 = \mathbf b - P \mathbf v_1 = \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1$
* note that $\mathbf v_2 = \mathbf e$! it has the same length and the same direction 
* so $\mathbf v_2 = \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1$ 
* interpretation: we take the original vector $\mathbf b$ and remove the projection of this vector onto $\mathbf v_1$, and it leaves only the orthogonal part
* now $\mathbf v_1 \; \bot \mathbf v_2$
* let's check: $\mathbf v_1^T \mathbf v_2 = \mathbf v_1^T \left( \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1 \right) = \mathbf v_1^T \mathbf b - \mathbf v_1^T \cdot \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1 = \mathbf v_1^T \mathbf b - \mathbf v_1^T \mathbf b = 0$


To find the final solution, we just normalize $\mathbf v_1$ and $\mathbf v_2$:
* $\mathbf q_1 = \mathbf v_1 / \| \mathbf v_1 \|$ 
* $\mathbf q_2 = \mathbf v_2 / \| \mathbf v_2 \|$



=== 3D Case ===
What if we have 3 vectors $\mathbf a, \mathbf b, \mathbf c$?
* need to find (pair-wise) orthogonal vectors $\mathbf v_1, \mathbf v_2, \mathbf v_3$ and then normalize them
* have $\mathbf v_1 = a$, $\mathbf v_2 = \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \mathbf v_1$
* what about $\mathbf v_3$? Know that we want to have $\mathbf v_3 \; \bot \; \mathbf v_1$ and $\mathbf v_3 \; \bot \; \mathbf v_2$
* for $\mathbf v_3$, we want to subtract its components in direction $\mathbf v_1$ as well as in direction $\mathbf v_2$ 
* so $\mathbf v_3 = \mathbf c - \cfrac{\mathbf v_1^T \mathbf c}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1 - \cfrac{\mathbf v_2^T \mathbf c}{\mathbf v_2^T \mathbf v_2} \cdot \mathbf v_2$


To get $\mathbf q_1, \mathbf q_2, \mathbf q_3$, we just normalize:
* $\mathbf q_1 = \mathbf v_1 / \| \mathbf v_1 \|$ 
* $\mathbf q_2 = \mathbf v_2 / \| \mathbf v_2 \|$
* $\mathbf q_3 = \mathbf v_3 / \| \mathbf v_3 \|$



=== 3D Case Animation ===
[[File:Gram-Schmidt_orthonormalization_process.gif]]

Source: http://en.wikipedia.org/wiki/File:Gram-Schmidt_orthonormalization_process.gif



=== [[Column Space]]s ===
Claim: The column space of $A$ does not change when we orthogonalize it


Suppose that we take a matrix $A = \Bigg[ \mathop{\mathbf a_1}\limits_|^| \ \mathop{\mathbf a_2}\limits_|^| \ \cdots \  \mathop{\mathbf a_n}\limits_|^| \Bigg]$ and orthogonalize its columns  into $Q = \Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^| \ \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg]$ 
* Why $C(A) = C(Q)$?
* at each step of the Gram-Schmidt process we take linear combinations from $C(A)$!
* e.g. $\mathbf v_3 = \mathbf c - \alpha_1  \mathbf v_1 - \alpha_2  \mathbf v_2 = \mathbf c - \alpha_1\mathbf a - \alpha_2 \cdot \left(\mathbf b - \alpha_3 \mathbf a \right) = \mathbf c - \alpha_1 \mathbf a - \alpha_2 \mathbf b - \alpha_2 \alpha_3 \mathbf a$
* $\alpha_1 = \cfrac{\mathbf v_1^T \mathbf c}{\mathbf v_1^T \mathbf v_1}, \alpha_2 = \cfrac{\mathbf v_2^T \mathbf c}{\mathbf v_2^T \mathbf v_2}, \alpha_3 = \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1}$ are just scalars 


=== Implementation ===
==== Java ====
The implementation is taken from Smile: https://github.com/haifengl/smile/blob/master/core/src/main/java/smile/projection/RandomProjection.java

 double[][] X;
 Math.unitize(X[0]);
 for (int i = 1; i &lt; p; i++) {
     for (int j = 0; j &lt; i; j++) {
         double t = -Math.dot(X[i], X[j]);
         Math.axpy(t, X[j], X[i]);
     }
     Math.unitize(X[i]);
 }

where
* &lt;code&gt;Math.unitize&lt;/code&gt; unit-normalizes the vector
* &lt;code&gt;Math.axpy&lt;/code&gt; updates an array by adding a multiple of another array y = a * x + y.
* here &lt;code&gt;X[i]&lt;/code&gt; is $i$th '''''column''''' of $X$

== QR Factorization ==
We can think of the [[Gram-Schmidt Process]] in the matrix language (like for [[Gaussian Elimination]] that brings us to [[LU Factorization]])
* recall that $C(Q) = C(A)$ 
* because of this, there exists a third matrix $R$ that brings $A$ to $Q$ 
* or, $A = Q R$
* (so we want Gram-Schmidt applied to the columns of $A$)


How to find this $R$?
* $A = QR$, let's multiply both sides by $Q^T$:
* $Q^T A = Q^T Q R$
* since $Q^T Q = I$, we have $R = Q^T A$
* let $A = \Bigg[ \mathop{\mathbf a_1}\limits_|^| \ \mathop{\mathbf a_2}\limits_|^| \ \cdots \  \mathop{\mathbf a_n}\limits_|^| \Bigg]$ and $Q = \Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^| \ \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg]$
* thus we have &lt;math&gt;
R = Q^T A = \begin{bmatrix} 
\mathbf q_1^T \mathbf a_1 &amp; \mathbf q_1^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_1^T \mathbf a_n \\
\mathbf q_2^T \mathbf a_1 &amp; \mathbf q_2^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_2^T \mathbf a_n \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\mathbf q_n^T \mathbf a_1 &amp; \mathbf q_n^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_n^T \mathbf a_n \\
\end{bmatrix}
&lt;/math&gt;


Now recall the way we constructed $Q$
* we took $\mathbf q_1 = \mathbf a_1 / \| \mathbf a_1 \|$ and make all other $\mathbf a_i$ orthogonal to it, so $\mathbf q_2^T \mathbf a_1 = \ ... \ = \mathbf q_n^T \mathbf a_1 = 0$
* then we took $\mathbf q_1$ and $\mathbf q_2$ and made all $\mathbf a_3, ..., \mathbf a_n$ orthogonal to them, so $\mathbf q_3^T \mathbf a_2 = \ ... \ = \mathbf q_n^T \mathbf a_2 = 0$
* proceeding this way till the end we see that $R$ is upper-diagonal:
* thus we have &lt;math&gt;
R = Q^T A = \begin{bmatrix} 
\mathbf q_1^T \mathbf a_1 &amp; \mathbf q_1^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_1^T \mathbf a_n \\
0 &amp; \mathbf q_2^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_2^T \mathbf a_n \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \mathbf q_n^T \mathbf a_n \\
\end{bmatrix}
&lt;/math&gt;


Note that for the diagonal elements of $R$, $\mathbf q_i^T \mathbf a_i = \| \mathbf v_i \|$
* why? 
* http://habrastorage.org/files/4d5/edf/1db/4d5edf1db6d04f2a9b1310228db15afa.png
* $\mathbf q_i^T \mathbf a_i = \| \mathbf q_i \| \| \mathbf a_i \| \cos \theta$ by the [[Dot Product]] definition
* $\| \mathbf q_i \| = 1$ and $\cos \theta = \cfrac{\| \mathbf v_i \|}{\| \mathbf a_i \|}$, so
* $\mathbf q_i^T \mathbf a_i = \| \mathbf q_i \| \| \mathbf a_i \| \cos \theta = 1 \cdot \cancel{\| \mathbf a_i \|} \cfrac{\| \mathbf v_i \|}{ \cancel{\| \mathbf a_i \|} } = \| \mathbf v_i \|$
* this can be uses to speed up the computation a bit


=== Usage ===
This is often used for [[Linear Least Squares]] - to make the [[Normal Equation]] faster


=== Implementation code ===
==== Python ====
Implementation of the pseudo-code from the Strang's book:

&lt;pre&gt;
import numpy as np

def qr_factorization(A):
    m, n = A.shape
    Q = np.zeros((m, n))
    R = np.zeros((n, n))

    for j in range(n):
        v = A[:, j]

        for i in range(j - 1):
            q = Q[:, i]
            R[i, j] = q.dot(v)
            v = v - R[i, j] * q

        norm = np.linalg.norm(v)
        Q[:, j] = v / norm
        R[j, j] = norm
    return Q, R

A = np.random.rand(13, 10) * 1000
Q, R = qr_factorization(A)

Q.shape, R.shape
np.abs((A - Q.dot(R)).sum()) &lt; 1e-6
&lt;/pre&gt;


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Strang, G. Introduction to linear algebra.
* http://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process
* http://inst.eecs.berkeley.edu/~ee127a/book/login/l_mats_qr.html


[[Category:Linear Algebra]]</text>
      <sha1>jiqie5gn6at1pvyrin6akb7eit72aej</sha1>
    </revision>
    <revision>
      <id>777</id>
      <parentid>752</parentid>
      <timestamp>2017-06-15T15:56:51Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8953">$\require{cancel}$

== Gram-Schmidt Process ==
In Linear Algebra, Gram-Schmidt process is a method for orthogonalization: 
* given a matrix $A$ it produces an [[Orthogonal Matrix]] $Q$ from it
* $A$ must have [[Linear Independence|linearly independent]] columns



=== 2D Case ===
Suppose we have two linearly independent vectors $\mathbf a$ and $\mathbf b$
* we want to make them orthogonal $\mathbf a \Rightarrow \mathbf v_1$, $\mathbf b \Rightarrow \mathbf v_2$
* and then we normalize them: $\mathbf v_1 \Rightarrow \mathbf q_1$ and $\mathbf v_2 \Rightarrow \mathbf q_2$
* http://habrastorage.org/files/dc7/5bd/285/dc75bd285d314c4a8da6b7c6d1267716.png
* $\mathbf a$ is already fine, let's keep its direction for $\mathbf q_1$ as well
* $\mathbf b$ is not fine: we want it to be orthogonal to $\mathbf q_1$


How do we produce a vector $\mathbf v_2$ from $\mathbf b$ such that $\mathbf v_2 \; \bot \; \mathbf v_1 = \mathbf a$ 
* http://habrastorage.org/files/dcc/304/33e/dcc30433e98143b2b236fa419bc06d4d.png
* let's [[Projection onto Subspaces|project]] $\mathbf b$ on $\mathbf v_1$, and we get $P \cdot \mathbf v_1 = \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1$
* $\mathbf e$ is our projection error, so $\mathbf e = \mathbf b - P \mathbf v_1 = \mathbf b - P \mathbf v_1 = \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1$
* note that $\mathbf v_2 = \mathbf e$! it has the same length and the same direction 
* so $\mathbf v_2 = \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1$ 
* interpretation: we take the original vector $\mathbf b$ and remove the projection of this vector onto $\mathbf v_1$, and it leaves only the orthogonal part
* now $\mathbf v_1 \; \bot \mathbf v_2$
* let's check: $\mathbf v_1^T \mathbf v_2 = \mathbf v_1^T \left( \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1 \right) = \mathbf v_1^T \mathbf b - \mathbf v_1^T \cdot \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1 = \mathbf v_1^T \mathbf b - \mathbf v_1^T \mathbf b = 0$


To find the final solution, we just normalize $\mathbf v_1$ and $\mathbf v_2$:
* $\mathbf q_1 = \mathbf v_1 / \| \mathbf v_1 \|$ 
* $\mathbf q_2 = \mathbf v_2 / \| \mathbf v_2 \|$



=== 3D Case ===
What if we have 3 vectors $\mathbf a, \mathbf b, \mathbf c$?
* need to find (pair-wise) orthogonal vectors $\mathbf v_1, \mathbf v_2, \mathbf v_3$ and then normalize them
* have $\mathbf v_1 = a$, $\mathbf v_2 = \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \mathbf v_1$
* what about $\mathbf v_3$? Know that we want to have $\mathbf v_3 \; \bot \; \mathbf v_1$ and $\mathbf v_3 \; \bot \; \mathbf v_2$
* for $\mathbf v_3$, we want to subtract its components in direction $\mathbf v_1$ as well as in direction $\mathbf v_2$ 
* so $\mathbf v_3 = \mathbf c - \cfrac{\mathbf v_1^T \mathbf c}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1 - \cfrac{\mathbf v_2^T \mathbf c}{\mathbf v_2^T \mathbf v_2} \cdot \mathbf v_2$


To get $\mathbf q_1, \mathbf q_2, \mathbf q_3$, we just normalize:
* $\mathbf q_1 = \mathbf v_1 / \| \mathbf v_1 \|$ 
* $\mathbf q_2 = \mathbf v_2 / \| \mathbf v_2 \|$
* $\mathbf q_3 = \mathbf v_3 / \| \mathbf v_3 \|$



=== 3D Case Animation ===
[[File:Gram-Schmidt_orthonormalization_process.gif]]

Source: http://en.wikipedia.org/wiki/File:Gram-Schmidt_orthonormalization_process.gif



=== [[Column Space]]s ===
Claim: The column space of $A$ does not change when we orthogonalize it


Suppose that we take a matrix $A = \Bigg[ \mathop{\mathbf a_1}\limits_|^| \ \mathop{\mathbf a_2}\limits_|^| \ \cdots \  \mathop{\mathbf a_n}\limits_|^| \Bigg]$ and orthogonalize its columns  into $Q = \Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^| \ \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg]$ 
* Why $C(A) = C(Q)$?
* at each step of the Gram-Schmidt process we take linear combinations from $C(A)$!
* e.g. $\mathbf v_3 = \mathbf c - \alpha_1  \mathbf v_1 - \alpha_2  \mathbf v_2 = \mathbf c - \alpha_1\mathbf a - \alpha_2 \cdot \left(\mathbf b - \alpha_3 \mathbf a \right) = \mathbf c - \alpha_1 \mathbf a - \alpha_2 \mathbf b - \alpha_2 \alpha_3 \mathbf a$
* $\alpha_1 = \cfrac{\mathbf v_1^T \mathbf c}{\mathbf v_1^T \mathbf v_1}, \alpha_2 = \cfrac{\mathbf v_2^T \mathbf c}{\mathbf v_2^T \mathbf v_2}, \alpha_3 = \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1}$ are just scalars 


== Implementation ==
=== Java ===
The implementation is taken from Smile: https://github.com/haifengl/smile/blob/master/core/src/main/java/smile/projection/RandomProjection.java

 double[][] X;
 Math.unitize(X[0]);
 for (int i = 1; i &lt; p; i++) {
     for (int j = 0; j &lt; i; j++) {
         double t = -Math.dot(X[i], X[j]);
         Math.axpy(t, X[j], X[i]);
     }
     Math.unitize(X[i]);
 }

where
* &lt;code&gt;Math.unitize&lt;/code&gt; unit-normalizes the vector
* &lt;code&gt;Math.axpy&lt;/code&gt; updates an array by adding a multiple of another array &lt;code&gt;y = a * x + y&lt;/code&gt;.
* here &lt;code&gt;X[i]&lt;/code&gt; is $i$th '''''column''''' of $X$

=== Python ===

 def normalize(v):
     return v / np.sqrt(v.dot(v))
 
 n = len(A)
 
 A[:, 0] = normalize(A[:, 0])
 
 for i in range(1, n):
     Ai = A[:, i]
     for j in range(0, i):
         Aj = A[:, j]
         t = Ai.dot(Aj)
         Ai = Ai - t * Aj
     A[:, i] = normalize(Ai)


== QR Factorization ==
We can think of the [[Gram-Schmidt Process]] in the matrix language (like for [[Gaussian Elimination]] that brings us to [[LU Factorization]])
* recall that $C(Q) = C(A)$ 
* because of this, there exists a third matrix $R$ that brings $A$ to $Q$ 
* or, $A = Q R$
* (so we want Gram-Schmidt applied to the columns of $A$)


How to find this $R$?
* $A = QR$, let's multiply both sides by $Q^T$:
* $Q^T A = Q^T Q R$
* since $Q^T Q = I$, we have $R = Q^T A$
* let $A = \Bigg[ \mathop{\mathbf a_1}\limits_|^| \ \mathop{\mathbf a_2}\limits_|^| \ \cdots \  \mathop{\mathbf a_n}\limits_|^| \Bigg]$ and $Q = \Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^| \ \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg]$
* thus we have &lt;math&gt;
R = Q^T A = \begin{bmatrix} 
\mathbf q_1^T \mathbf a_1 &amp; \mathbf q_1^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_1^T \mathbf a_n \\
\mathbf q_2^T \mathbf a_1 &amp; \mathbf q_2^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_2^T \mathbf a_n \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\mathbf q_n^T \mathbf a_1 &amp; \mathbf q_n^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_n^T \mathbf a_n \\
\end{bmatrix}
&lt;/math&gt;


Now recall the way we constructed $Q$
* we took $\mathbf q_1 = \mathbf a_1 / \| \mathbf a_1 \|$ and make all other $\mathbf a_i$ orthogonal to it, so $\mathbf q_2^T \mathbf a_1 = \ ... \ = \mathbf q_n^T \mathbf a_1 = 0$
* then we took $\mathbf q_1$ and $\mathbf q_2$ and made all $\mathbf a_3, ..., \mathbf a_n$ orthogonal to them, so $\mathbf q_3^T \mathbf a_2 = \ ... \ = \mathbf q_n^T \mathbf a_2 = 0$
* proceeding this way till the end we see that $R$ is upper-diagonal:
* thus we have &lt;math&gt;
R = Q^T A = \begin{bmatrix} 
\mathbf q_1^T \mathbf a_1 &amp; \mathbf q_1^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_1^T \mathbf a_n \\
0 &amp; \mathbf q_2^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_2^T \mathbf a_n \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \mathbf q_n^T \mathbf a_n \\
\end{bmatrix}
&lt;/math&gt;


Note that for the diagonal elements of $R$, $\mathbf q_i^T \mathbf a_i = \| \mathbf v_i \|$
* why? 
* http://habrastorage.org/files/4d5/edf/1db/4d5edf1db6d04f2a9b1310228db15afa.png
* $\mathbf q_i^T \mathbf a_i = \| \mathbf q_i \| \| \mathbf a_i \| \cos \theta$ by the [[Dot Product]] definition
* $\| \mathbf q_i \| = 1$ and $\cos \theta = \cfrac{\| \mathbf v_i \|}{\| \mathbf a_i \|}$, so
* $\mathbf q_i^T \mathbf a_i = \| \mathbf q_i \| \| \mathbf a_i \| \cos \theta = 1 \cdot \cancel{\| \mathbf a_i \|} \cfrac{\| \mathbf v_i \|}{ \cancel{\| \mathbf a_i \|} } = \| \mathbf v_i \|$
* this can be uses to speed up the computation a bit


=== Usage ===
This is often used for [[Linear Least Squares]] - to make the [[Normal Equation]] faster


=== Implementation code ===
==== Python ====
Implementation of the pseudo-code from the Strang's book:

&lt;pre&gt;
import numpy as np

def qr_factorization(A):
    m, n = A.shape
    Q = np.zeros((m, n))
    R = np.zeros((n, n))

    for j in range(n):
        v = A[:, j]

        for i in range(j - 1):
            q = Q[:, i]
            R[i, j] = q.dot(v)
            v = v - R[i, j] * q

        norm = np.linalg.norm(v)
        Q[:, j] = v / norm
        R[j, j] = norm
    return Q, R

A = np.random.rand(13, 10) * 1000
Q, R = qr_factorization(A)

Q.shape, R.shape
np.abs((A - Q.dot(R)).sum()) &lt; 1e-6
&lt;/pre&gt;


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Strang, G. Introduction to linear algebra.
* http://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process
* http://inst.eecs.berkeley.edu/~ee127a/book/login/l_mats_qr.html


[[Category:Linear Algebra]]</text>
      <sha1>rokdtuv7hhgfh5w1iej9xttpal29vmz</sha1>
    </revision>
    <revision>
      <id>778</id>
      <parentid>777</parentid>
      <timestamp>2017-06-15T20:46:17Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9282">$\require{cancel}$

== Gram-Schmidt Process ==
In Linear Algebra, Gram-Schmidt process is a method for orthogonalization: 
* given a matrix $A$ it produces an [[Orthogonal Matrix]] $Q$ from it
* $A$ must have [[Linear Independence|linearly independent]] columns



=== 2D Case ===
Suppose we have two linearly independent vectors $\mathbf a$ and $\mathbf b$
* we want to make them orthogonal $\mathbf a \Rightarrow \mathbf v_1$, $\mathbf b \Rightarrow \mathbf v_2$
* and then we normalize them: $\mathbf v_1 \Rightarrow \mathbf q_1$ and $\mathbf v_2 \Rightarrow \mathbf q_2$
* http://habrastorage.org/files/dc7/5bd/285/dc75bd285d314c4a8da6b7c6d1267716.png
* $\mathbf a$ is already fine, let's keep its direction for $\mathbf q_1$ as well
* $\mathbf b$ is not fine: we want it to be orthogonal to $\mathbf q_1$


How do we produce a vector $\mathbf v_2$ from $\mathbf b$ such that $\mathbf v_2 \; \bot \; \mathbf v_1 = \mathbf a$ 
* http://habrastorage.org/files/dcc/304/33e/dcc30433e98143b2b236fa419bc06d4d.png
* let's [[Projection onto Subspaces|project]] $\mathbf b$ on $\mathbf v_1$, and we get $P \cdot \mathbf v_1 = \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1$
* $\mathbf e$ is our projection error, so $\mathbf e = \mathbf b - P \mathbf v_1 = \mathbf b - P \mathbf v_1 = \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1$
* note that $\mathbf v_2 = \mathbf e$! it has the same length and the same direction 
* so $\mathbf v_2 = \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1$ 
* interpretation: we take the original vector $\mathbf b$ and remove the projection of this vector onto $\mathbf v_1$, and it leaves only the orthogonal part
* now $\mathbf v_1 \; \bot \mathbf v_2$
* let's check: $\mathbf v_1^T \mathbf v_2 = \mathbf v_1^T \left( \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1 \right) = \mathbf v_1^T \mathbf b - \mathbf v_1^T \cdot \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1 = \mathbf v_1^T \mathbf b - \mathbf v_1^T \mathbf b = 0$


To find the final solution, we just normalize $\mathbf v_1$ and $\mathbf v_2$:
* $\mathbf q_1 = \mathbf v_1 / \| \mathbf v_1 \|$ 
* $\mathbf q_2 = \mathbf v_2 / \| \mathbf v_2 \|$



=== 3D Case ===
What if we have 3 vectors $\mathbf a, \mathbf b, \mathbf c$?
* need to find (pair-wise) orthogonal vectors $\mathbf v_1, \mathbf v_2, \mathbf v_3$ and then normalize them
* have $\mathbf v_1 = a$, $\mathbf v_2 = \mathbf b - \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1} \mathbf v_1$
* what about $\mathbf v_3$? Know that we want to have $\mathbf v_3 \; \bot \; \mathbf v_1$ and $\mathbf v_3 \; \bot \; \mathbf v_2$
* for $\mathbf v_3$, we want to subtract its components in direction $\mathbf v_1$ as well as in direction $\mathbf v_2$ 
* so $\mathbf v_3 = \mathbf c - \cfrac{\mathbf v_1^T \mathbf c}{\mathbf v_1^T \mathbf v_1} \cdot \mathbf v_1 - \cfrac{\mathbf v_2^T \mathbf c}{\mathbf v_2^T \mathbf v_2} \cdot \mathbf v_2$


To get $\mathbf q_1, \mathbf q_2, \mathbf q_3$, we just normalize:
* $\mathbf q_1 = \mathbf v_1 / \| \mathbf v_1 \|$ 
* $\mathbf q_2 = \mathbf v_2 / \| \mathbf v_2 \|$
* $\mathbf q_3 = \mathbf v_3 / \| \mathbf v_3 \|$



=== 3D Case Animation ===
[[File:Gram-Schmidt_orthonormalization_process.gif]]

Source: http://en.wikipedia.org/wiki/File:Gram-Schmidt_orthonormalization_process.gif



=== [[Column Space]]s ===
Claim: The column space of $A$ does not change when we orthogonalize it


Suppose that we take a matrix $A = \Bigg[ \mathop{\mathbf a_1}\limits_|^| \ \mathop{\mathbf a_2}\limits_|^| \ \cdots \  \mathop{\mathbf a_n}\limits_|^| \Bigg]$ and orthogonalize its columns  into $Q = \Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^| \ \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg]$ 
* Why $C(A) = C(Q)$?
* at each step of the Gram-Schmidt process we take linear combinations from $C(A)$!
* e.g. $\mathbf v_3 = \mathbf c - \alpha_1  \mathbf v_1 - \alpha_2  \mathbf v_2 = \mathbf c - \alpha_1\mathbf a - \alpha_2 \cdot \left(\mathbf b - \alpha_3 \mathbf a \right) = \mathbf c - \alpha_1 \mathbf a - \alpha_2 \mathbf b - \alpha_2 \alpha_3 \mathbf a$
* $\alpha_1 = \cfrac{\mathbf v_1^T \mathbf c}{\mathbf v_1^T \mathbf v_1}, \alpha_2 = \cfrac{\mathbf v_2^T \mathbf c}{\mathbf v_2^T \mathbf v_2}, \alpha_3 = \cfrac{\mathbf v_1^T \mathbf b}{\mathbf v_1^T \mathbf v_1}$ are just scalars 


== Implementation ==
=== Java ===
The implementation is taken from Smile: https://github.com/haifengl/smile/blob/master/core/src/main/java/smile/projection/RandomProjection.java

 double[][] X;
 Math.unitize(X[0]);
 for (int i = 1; i &lt; p; i++) {
     for (int j = 0; j &lt; i; j++) {
         double t = -Math.dot(X[i], X[j]);
         Math.axpy(t, X[j], X[i]);
     }
     Math.unitize(X[i]);
 }

where
* &lt;code&gt;Math.unitize&lt;/code&gt; unit-normalizes the vector
* &lt;code&gt;Math.axpy&lt;/code&gt; updates an array by adding a multiple of another array &lt;code&gt;y = a * x + y&lt;/code&gt;.
* here &lt;code&gt;X[i]&lt;/code&gt; is $i$th '''''column''''' of $X$

=== Python ===

 def normalize(v):
     return v / np.sqrt(v.dot(v))
 
 n = len(A)
 
 A[:, 0] = normalize(A[:, 0])
 
 for i in range(1, n):
     Ai = A[:, i]
     for j in range(0, i):
         Aj = A[:, j]
         t = Ai.dot(Aj)
         Ai = Ai - t * Aj
     A[:, i] = normalize(Ai)


== QR Factorization ==
We can think of the [[Gram-Schmidt Process]] in the matrix language (like for [[Gaussian Elimination]] that brings us to [[LU Factorization]])
* recall that $C(Q) = C(A)$ 
* because of this, there exists a third matrix $R$ that brings $A$ to $Q$ 
* or, $A = Q R$
* (so we want Gram-Schmidt applied to the columns of $A$)


How to find this $R$?
* $A = QR$, let's multiply both sides by $Q^T$:
* $Q^T A = Q^T Q R$
* since $Q^T Q = I$, we have $R = Q^T A$
* let $A = \Bigg[ \mathop{\mathbf a_1}\limits_|^| \ \mathop{\mathbf a_2}\limits_|^| \ \cdots \  \mathop{\mathbf a_n}\limits_|^| \Bigg]$ and $Q = \Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^| \ \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg]$
* thus we have &lt;math&gt;
R = Q^T A = \begin{bmatrix} 
\mathbf q_1^T \mathbf a_1 &amp; \mathbf q_1^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_1^T \mathbf a_n \\
\mathbf q_2^T \mathbf a_1 &amp; \mathbf q_2^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_2^T \mathbf a_n \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\mathbf q_n^T \mathbf a_1 &amp; \mathbf q_n^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_n^T \mathbf a_n \\
\end{bmatrix}
&lt;/math&gt;


Now recall the way we constructed $Q$
* we took $\mathbf q_1 = \mathbf a_1 / \| \mathbf a_1 \|$ and make all other $\mathbf a_i$ orthogonal to it, so $\mathbf q_2^T \mathbf a_1 = \ ... \ = \mathbf q_n^T \mathbf a_1 = 0$
* then we took $\mathbf q_1$ and $\mathbf q_2$ and made all $\mathbf a_3, ..., \mathbf a_n$ orthogonal to them, so $\mathbf q_3^T \mathbf a_2 = \ ... \ = \mathbf q_n^T \mathbf a_2 = 0$
* proceeding this way till the end we see that $R$ is upper-diagonal:
* thus we have &lt;math&gt;
R = Q^T A = \begin{bmatrix} 
\mathbf q_1^T \mathbf a_1 &amp; \mathbf q_1^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_1^T \mathbf a_n \\
0 &amp; \mathbf q_2^T \mathbf a_2 &amp; \cdots &amp; \mathbf q_2^T \mathbf a_n \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \mathbf q_n^T \mathbf a_n \\
\end{bmatrix}
&lt;/math&gt;


Note that for the diagonal elements of $R$, $\mathbf q_i^T \mathbf a_i = \| \mathbf v_i \|$
* why? 
* http://habrastorage.org/files/4d5/edf/1db/4d5edf1db6d04f2a9b1310228db15afa.png
* $\mathbf q_i^T \mathbf a_i = \| \mathbf q_i \| \| \mathbf a_i \| \cos \theta$ by the [[Dot Product]] definition
* $\| \mathbf q_i \| = 1$ and $\cos \theta = \cfrac{\| \mathbf v_i \|}{\| \mathbf a_i \|}$, so
* $\mathbf q_i^T \mathbf a_i = \| \mathbf q_i \| \| \mathbf a_i \| \cos \theta = 1 \cdot \cancel{\| \mathbf a_i \|} \cfrac{\| \mathbf v_i \|}{ \cancel{\| \mathbf a_i \|} } = \| \mathbf v_i \|$
* this can be uses to speed up the computation a bit


=== Usage ===
This decomposition is often used for [[Inverse Matrices|inverting the matrix]]
* often used for [[Linear Least Squares]] - to make the [[Normal Equation]] faster
* let $X = A^{-1}$, so want to solve $AX = I$ 
* decompose $QR = X$, so $QRX = I$
* multiply both sides by $Q^T$: $RX = Q^T$
* since $R$ is upper-triangular, this system is very easy to solve - just use forward substitution as in [[Gaussian Elimination]]



=== Implementation code ===
==== Python ====
Implementation of the pseudo-code from the Strang's book:

&lt;pre&gt;
import numpy as np

def qr_factorization(A):
    m, n = A.shape
    Q = np.zeros((m, n))
    R = np.zeros((n, n))

    for j in range(n):
        v = A[:, j]

        for i in range(j - 1):
            q = Q[:, i]
            R[i, j] = q.dot(v)
            v = v - R[i, j] * q

        norm = np.linalg.norm(v)
        Q[:, j] = v / norm
        R[j, j] = norm
    return Q, R

A = np.random.rand(13, 10) * 1000
Q, R = qr_factorization(A)

Q.shape, R.shape
np.abs((A - Q.dot(R)).sum()) &lt; 1e-6
&lt;/pre&gt;


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Strang, G. Introduction to linear algebra.
* http://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process
* http://inst.eecs.berkeley.edu/~ee127a/book/login/l_mats_qr.html


[[Category:Linear Algebra]]</text>
      <sha1>l5vwoflads3djwvqhhjha4jzqnydtiz</sha1>
    </revision>
  </page>
  <page>
    <title>Orthogonal Matrices</title>
    <ns>0</ns>
    <id>529</id>
    <revision>
      <id>532</id>
      <timestamp>2015-07-04T17:00:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4762">== Orthogonal Matrices ==
=== Orthonormal Vectors ===
Vectors $\mathbf q_1, \ ... \ , \mathbf q_n$ are ''orthonormal'' if they are [[Vector Orthogonality|orthogonal]] and unit vectors 
* $\mathbf q_i \; \bot \; \mathbf q_j \ \forall i \ne j$ and
* $\mathbf q_i^T \mathbf q_j = 0$ if $i \ne j$ and $\mathbf q_i^T \mathbf q_j = 1$ otherwise
* these vectors make a good [[Basis (Linear Algebra)|basis]] 


=== Orthogonal Matrix ===
What about a matrix form?
* The second part of the definition: $\mathbf q_i^T \mathbf q_j = 
\begin{cases} 
1 &amp; \text{if } i \ne j \\
0 &amp; \text{if } i = j
\end{cases}$
* how do we put it in a matrix form? 
* Consider a matrix $Q$ whose columns are vectors $\mathbf q_1, \ ... \ , \mathbf q_n$:
* let $Q = \Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^| \ \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg]$
* $Q^T Q = 
\begin{bmatrix}
- \ \mathbf q_1^T - \\
- \ \mathbf q_2^T - \\
\\ 
- \ \mathbf q_n^T -
\end{bmatrix}
\Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^| \ \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg] = \begin{bmatrix}
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; 1 &amp; \cdots &amp; 0 \\
 &amp;  &amp; \ddots &amp;  \\
0 &amp; 1 &amp; \cdots &amp; 1
\end{bmatrix}$ by our definition!
* so $Q^T Q = I$
* such $Q$'s are called ''Orthogonal Matrices'' 


A matrix $Q$ is orthogonal if 
* its columns are orthonormal vectors 
* and it's square

What's special about being square?
* if $Q^T Q = I$, then $Q^T = Q^{-1}$


== Examples ==
=== Identity Matrices ===
Identity matrices are orthogonal:
* $Q = \begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1 \\
\end{bmatrix} = I$
* $Q^T Q = I I = I$


=== [[Permutation Matrices]] ===
[[Permutation Matrices]] are orthogonal
* consider $Q = \begin{bmatrix}
0 &amp; 0 &amp; 1 \\
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
\end{bmatrix}$
* then $Q^T = \begin{bmatrix}
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1 \\
1 &amp; 0 &amp; 0 \\
\end{bmatrix}$ and indeed $Q^T Q = I$
* also note that $Q^T$ is also orthogonal 


=== [[Rotation Matrices]] ===
[[Rotation Matrices]] are also orthogonal
* let $Q = \begin{bmatrix}
\cos \theta &amp; -\sin \theta \\
\sin \theta &amp; \cos \theta \\
\end{bmatrix}$
* it's orthogonal


=== Not Orthogonal Example ===
Not orthogonal:
* $S = \begin{bmatrix}
1 &amp; 1 \\
1 &amp; -1 \\
\end{bmatrix}$
* why? $S^T S = \begin{bmatrix}
1 &amp; 1 \\
1 &amp; -1 \\
\end{bmatrix} \begin{bmatrix}
1 &amp; 1 \\
1 &amp; -1 \\
\end{bmatrix} = \begin{bmatrix}
2 &amp; 0 \\
0 &amp; 2 \\
\end{bmatrix}$
* how to fix it? they are not unit vectors, so need to normalize it:
* $Q = \cfrac{1}{\sqrt 2} \begin{bmatrix}
1 &amp; 1 \\
1 &amp; -1 \\
\end{bmatrix}$ 
* now $Q^T Q = \cfrac{1}{2} \begin{bmatrix}
2 &amp; 0 \\
0 &amp; 2 \\
\end{bmatrix} = I$
* this one is orthogonal



== Usage ==
=== Projection ===
Why is it good to have orthogonal matrices? 
* projections are easy:
* suppose we want to project onto the column space of $Q$
* so we have $P = Q (Q^T Q)^{-1} Q^T = Q I Q^T = Q Q^T$
* $Q Q^T$ is symmetric
* see [[Projection onto Subspaces#Projection onto Orthogonal Basis]]


=== [[Normal Equation]] ===
* $A^T A \mathbf{\hat x} = A^T \mathbf b$
* usual case (when $A$ is not orthogonal): $\mathbf{\hat x} = (A^T A)^{-1} A^T \mathbf b$
* orthogonal case: $\mathbf{\hat x} = (Q^T Q)^{-1} Q^T \mathbf b = Q^T \mathbf b$ - no inversion involved
* so can use [[QR Factorization|$A = QR$ Factorization]] and get $\mathbf{\hat x} = R^{-1} Q^T \mathbf b$


=== Factorizations ===
Orthogonal matrices are very nice because it's very easy to invert them
* therefore some factorizations are very popular
* e.g. [[Eigendecomposition]] or [[SVD]]


== Orthogonalization ==
How do we make matrices orthogonal? 
* [[Gram-Schmidt Process]] and [[QR Factorization]]
* this preserves the column space $C(A)$! 

Also, 
* [[Eigendecomposition]] $A = Q \Lambda Q^T$ decomposes symmetric $A$ onto orthogonal $Q$ and diagonal $\Lambda$
* [[SVD]] $A = U \Sigma V^T$ decomposes $A$ onto orthogonal $U$ and $V$ and diagonal $\Sigma$



== Properties ==
=== Transpose ===
If $Q$ is orthogonal matrix, then $Q^T$ is orthogonal as well


=== [[Matrix Multiplication]] ===
If $Q_1$ and $Q_2$ are orthogonal, so is $Q_1 \cdot Q_2$


=== Linear Transformation Properties ===
$Q$ preserves the [[Euclidean Distance|$L_2$ norm]]:
* $\| Q \mathbf x \| = \| \mathbf x \|$
* proof: $\| Q \mathbf x \|^2 = (Q \mathbf x)^T (Q \mathbf x) = \mathbf x^T Q^T Q \mathbf x = \mathbf x^T \mathbf x = \| \mathbf x \|^2$


$Q$ preserves the angle between $\mathbf x$ and $\mathbf y$
* $\langle Q \mathbf x, Q \mathbf y \rangle = \langle \mathbf x, \mathbf y \rangle$
* proof: $(Q \mathbf x)^T (Q \mathbf y) = \mathbf x^T Q^T Q \mathbf y = \mathbf x^T \mathbf y$



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* http://inst.eecs.berkeley.edu/~ee127a/book/login/l_mats_qr.html

[[Category:Linear Algebra]]</text>
      <sha1>s4c0khupodt5dp16syc9djxs4e4c1gt</sha1>
    </revision>
    <revision>
      <id>808</id>
      <parentid>532</parentid>
      <timestamp>2017-08-05T19:41:18Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4954">== Orthogonal Matrices ==
=== Orthonormal Vectors ===
Vectors $\mathbf q_1, \ ... \ , \mathbf q_n$ are ''orthonormal'' if they are [[Vector Orthogonality|orthogonal]] and unit vectors 
* $\mathbf q_i \; \bot \; \mathbf q_j \ \forall i \ne j$ and
* $\mathbf q_i^T \mathbf q_j = 0$ if $i \ne j$ and $\mathbf q_i^T \mathbf q_j = 1$ otherwise
* these vectors make a good [[Basis (Linear Algebra)|basis]] 


=== Orthogonal Matrix ===
What about a matrix form?
* The second part of the definition: &lt;math&gt;\mathbf q_i^T \mathbf q_j = 
\begin{cases} 
1 &amp; \text{if } i \ne j \\
0 &amp; \text{if } i = j
\end{cases}&lt;/math&gt;
* how do we put it in a matrix form? 
* Consider a matrix $Q$ whose columns are vectors \mathbf q_1, \ ... \ , \mathbf q_n$:
* let &lt;math&gt;Q = \Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^| \ \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg]&lt;/math&gt;
* &lt;math&gt;Q^T Q = 
\begin{bmatrix}
- \ \mathbf q_1^T - \\
- \ \mathbf q_2^T - \\
\\ 
- \ \mathbf q_n^T -
\end{bmatrix}
\Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^| \ \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg] = \begin{bmatrix}
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; 1 &amp; \cdots &amp; 0 \\
 &amp;  &amp; \ddots &amp;  \\
0 &amp; 1 &amp; \cdots &amp; 1
\end{bmatrix}&lt;/math&gt; by our definition!
* so $Q^T Q = I$
* such $Q$'s are called ''Orthogonal Matrices'' 


A matrix $Q$ is orthogonal if 
* its columns are orthonormal vectors 
* and it's square

What's special about being square?
* if $Q^T Q = I$, then $Q^T = Q^{-1}$


== Examples ==
=== Identity Matrices ===
Identity matrices are orthogonal:
* &lt;math&gt;Q = \begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1 \\
\end{bmatrix} = I&lt;/math&gt;
* $Q^T Q = I I = I$


=== [[Permutation Matrices]] ===
[[Permutation Matrices]] are orthogonal
* consider &lt;math&gt;Q = \begin{bmatrix}
0 &amp; 0 &amp; 1 \\
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
\end{bmatrix}&lt;/math&gt;
* then &lt;math&gt;Q^T = \begin{bmatrix}
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1 \\
1 &amp; 0 &amp; 0 \\
\end{bmatrix}&lt;/math&gt; and indeed $Q^T Q = I$
* also note that $Q^T$ is also orthogonal 


=== [[Rotation Matrices]] ===
[[Rotation Matrices]] are also orthogonal
* let &lt;math&gt;Q = \begin{bmatrix}
\cos \theta &amp; -\sin \theta \\
\sin \theta &amp; \cos \theta \\
\end{bmatrix}&lt;/math&gt;
* it's orthogonal


=== [[Reflection Matrices]] ===
They are also orthogonal (add example)


=== Not Orthogonal Example ===
Not orthogonal:
* &lt;math&gt;S = \begin{bmatrix}
1 &amp; 1 \\
1 &amp; -1 \\
\end{bmatrix}&lt;/math&gt;
* why? &lt;math&gt;S^T S = \begin{bmatrix}
1 &amp; 1 \\
1 &amp; -1 \\
\end{bmatrix} \begin{bmatrix}
1 &amp; 1 \\
1 &amp; -1 \\
\end{bmatrix} = \begin{bmatrix}
2 &amp; 0 \\
0 &amp; 2 \\
\end{bmatrix}&lt;/math&gt;
* how to fix it? they are not unit vectors, so need to normalize it:
* &lt;math&gt;Q = \cfrac{1}{\sqrt 2} \begin{bmatrix}
1 &amp; 1 \\
1 &amp; -1 \\
\end{bmatrix}&lt;/math&gt;
* now &lt;math&gt;Q^T Q = \cfrac{1}{2} \begin{bmatrix}
2 &amp; 0 \\
0 &amp; 2 \\
\end{bmatrix} = I&lt;/math&gt;
* this one is orthogonal



== Usage ==
=== Projection ===
Why is it good to have orthogonal matrices? 
* projections are easy:
* suppose we want to project onto the column space of $Q$
* so we have $P = Q (Q^T Q)^{-1} Q^T = Q I Q^T = Q Q^T$
* $Q Q^T$ is symmetric
* see [[Projection onto Subspaces#Projection onto Orthogonal Basis]]


=== [[Normal Equation]] ===
* $A^T A \mathbf{\hat x} = A^T \mathbf b$
* usual case (when $A$ is not orthogonal): $\mathbf{\hat x} = (A^T A)^{-1} A^T \mathbf b$
* orthogonal case: $\mathbf{\hat x} = (Q^T Q)^{-1} Q^T \mathbf b = Q^T \mathbf b$ - no inversion involved
* so can use [[QR Factorization|$A = QR$ Factorization]] and get $\mathbf{\hat x} = R^{-1} Q^T \mathbf b$


=== Factorizations ===
Orthogonal matrices are very nice because it's very easy to invert them
* therefore some factorizations are very popular
* e.g. [[Eigendecomposition]] or [[SVD]]


== Orthogonalization ==
How do we make matrices orthogonal? 
* [[Gram-Schmidt Process]] and [[QR Factorization]]
* this preserves the column space $C(A)$! 

Also, 
* [[Eigendecomposition]] $A = Q \Lambda Q^T$ decomposes symmetric $A$ onto orthogonal $Q$ and diagonal $\Lambda$
* [[SVD]] $A = U \Sigma V^T$ decomposes $A$ onto orthogonal $U$ and $V$ and diagonal $\Sigma$



== Properties ==
=== Transpose ===
If $Q$ is orthogonal matrix, then $Q^T$ is orthogonal as well


=== [[Matrix Multiplication]] ===
If $Q_1$ and $Q_2$ are orthogonal, so is $Q_1 \cdot Q_2$


=== Linear Transformation Properties ===
$Q$ preserves the [[Euclidean Distance|$L_2$ norm]]:
* $\| Q \mathbf x \| = \| \mathbf x \|$
* proof: $\| Q \mathbf x \|^2 = (Q \mathbf x)^T (Q \mathbf x) = \mathbf x^T Q^T Q \mathbf x = \mathbf x^T \mathbf x = \| \mathbf x \|^2$


$Q$ preserves the angle between $\mathbf x$ and $\mathbf y$
* $\langle Q \mathbf x, Q \mathbf y \rangle = \langle \mathbf x, \mathbf y \rangle$
* proof: $(Q \mathbf x)^T (Q \mathbf y) = \mathbf x^T Q^T Q \mathbf y = \mathbf x^T \mathbf y$



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* http://inst.eecs.berkeley.edu/~ee127a/book/login/l_mats_qr.html

[[Category:Linear Algebra]]</text>
      <sha1>opptj5vyh0au20dxlxc00uvwdxzr3dv</sha1>
    </revision>
  </page>
  <page>
    <title>Orthogonal Matrix</title>
    <ns>0</ns>
    <id>530</id>
    <redirect title="Orthogonal Matrices" />
    <revision>
      <id>533</id>
      <timestamp>2014-12-27T11:18:55Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="33">#REDIRECT [[Orthogonal Matrices]]</text>
      <sha1>jjg7k0wom5c05fdhreuxi8eqwagt74b</sha1>
    </revision>
  </page>
  <page>
    <title>Cramer's Rule</title>
    <ns>0</ns>
    <id>531</id>
    <revision>
      <id>534</id>
      <timestamp>2014-12-30T20:57:57Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6543">== Cramer's Rule ==
This is a method for finding a [[Inverse Matrices|Matrix Inverse]] and for solving a [[System of Linear Equations]].


== Finding Inverse ==
The formula is $A^{-1} = \cfrac{1}{| A |} C^T$
* $|A|$ is the [[Determinant]] of $A$ 
* $C$ is the [[Cofactors]] matrix of $A$ 


=== $2 \times 2$ case: Motivation ===
Let $A$ be an $2 \times 2$ matrix
* $A = \begin{bmatrix}
a_{11} &amp; a_{12} \\
a_{21} &amp; a_{22} \\
\end{bmatrix}$
* let's find $A^{-1}$ with Gauss-Jordan elimination (see [[Inverse Matrices]])
** $\left[ \begin{array}{cc|cc}
a_{11} &amp; a_{12} &amp; 1 &amp; 0 \\ 
a_{21} &amp; a_{22} &amp; 0 &amp; 1 \\
\end{array} \right] \sim $ row 2: $\text{row $2$} - \cfrac{a_{21}}{a_{11}} \text{row $1$}$
** $\sim \left[ \begin{array}{cc|cc}
a_{11} &amp; a_{12} &amp; 1 &amp; 0 \\ 
0 &amp; a_{22} - a_{12} \cfrac{a_{21}}{a_{11}} &amp; - \cfrac{a_{21}}{a_{11}} &amp; 1 \\
\end{array} \right] \sim $ now divide first row by $a_{11}$ and multiply second by $a_{11}$
** $\sim \left[ \begin{array}{cc|cc}
1 &amp; \cfrac{a_{12}}{a_{11}} &amp; \cfrac{1}{a_{11}} &amp; 0 \\ 
0 &amp; a_{11} a_{22} - a_{12} a_{21} &amp; - a_{21} &amp; a_{11} \\
\end{array} \right] =$ now note that $a_{11} a_{22} - a_{12} a_{21} = | A |$, so
** $ = \left[ \begin{array}{cc|cc}
1 &amp; \cfrac{a_{12}}{a_{11}} &amp; \cfrac{1}{a_{11}} &amp; 0 \\ 
0 &amp; |A| &amp; - a_{21} &amp; a_{11} \\
\end{array} \right] \sim $ let's divide row 2 by $|A|$
** $ \sim \left[ \begin{array}{cc|cc}
1 &amp; \cfrac{a_{12}}{a_{11}} &amp; \cfrac{1}{a_{11}} &amp; 0 \\ 
0 &amp; 1 &amp; - \cfrac{a_{21}}{|A|} &amp; \cfrac{a_{11}}{|A|} \\
\end{array} \right] \sim $ now for row 1: $\text{row $1$} - \cfrac{a_{12}}{a_{11}} \text{row $2$}$
** $ \sim \left[ \begin{array}{cc|cc}
1 &amp; 0 &amp; \cfrac{a_{22}}{|A|} &amp; - \cfrac{a_{12}}{|A|} \\ 
0 &amp; 1 &amp; - \cfrac{a_{21}}{|A|} &amp; \cfrac{a_{11}}{|A|} \\
\end{array} \right]$
* so $A^{-1} = \cfrac{1}{|A|} \begin{bmatrix}
a_{22} &amp; - a_{12} \\
- a_{21} &amp; a_{11} \\
\end{bmatrix}$
* now we can note that the [[Cofactors]] of $A$ are: $C_{11} = a_{22}, C_{12} = -a_{21}, C_{21} = - a_{12}, C_{22} = a_{11}$
* we can put all cofactors in one matrix $C = \begin{bmatrix}
C_{11} &amp; C_{12} \\
C_{21} &amp; C_{22} \\
\end{bmatrix} = 
\begin{bmatrix}
a_{22} &amp; -a_{21} \\
-a_{12} &amp; a_{11} \\
\end{bmatrix} =
\begin{bmatrix}
a_{22} &amp; - a_{12} \\
- a_{21} &amp; a_{11} \\
\end{bmatrix}^T$
* this is the same as in the formula for $A^{-1}$, but transposed!
* so $A^{-1} = \cfrac{1}{| A |} C^T$



=== General Case: Check ===
Does it always work? Let's check 
* if $A^{-1} = \cfrac{1}{| A |} C^T$, then $A \, C^T = |A| \, I$
* or, $\underbrace{\begin{bmatrix}
  a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n} \\
  a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n} \\
  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
  a_{n1} &amp; a_{n2} &amp; \cdots &amp; a_{nn} \\
\end{bmatrix}}_{A} 
\underbrace{\begin{bmatrix}
  C_{11} &amp; C_{21} &amp; \cdots &amp; C_{n1} \\
  C_{12} &amp; C_{22} &amp; \cdots &amp; C_{n2} \\
  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
  C_{1n} &amp; C_{2n} &amp; \cdots &amp; C_{nn} \\
\end{bmatrix}}_{C^T} = 
\underbrace{\begin{bmatrix}
  |A| &amp; 0 &amp; \cdots &amp; 0 \\
  0 &amp; |A| &amp; \cdots &amp; 0 \\
  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
  0 &amp; 0 &amp; \cdots &amp; |A| \\
\end{bmatrix}}_{|A| \, I}$
* so why do we have zeros off the diagonal?
** $\begin{bmatrix}
a_{11} &amp; a_{12} \\
a_{21} &amp; a_{22} \\
\end{bmatrix} \begin{bmatrix}
C_{11} &amp; C_{21} \\
C_{12} &amp; C_{22} \\
\end{bmatrix} = 
\begin{bmatrix}
\boxed{a_{11} C_{11}} + a_{12} C_{12} &amp; a_{11} C_{21} + a_{12} C_{22} \\
a_{21} C_{11} + a_{22} C_{12} &amp; a_{21} C_{21} + \boxed{a_{22} C_{22}} \\
\end{bmatrix}$
** need to check that $\text{row $i$} \times \text{cofactor of $i$} = |A|$
** and $\text{row $i$} \times \text{cofactors of $j$} = 0$ ($i \ne j$)
** then we'll have $|A|$ only on the diagonal


$\text{row $i$} \times \text{cofactors of $i$} = |A|$
* $\text{row $i$} = \begin{bmatrix} a_{i1} &amp; a_{i2} &amp; \cdots &amp; a_{in} \end{bmatrix}$
* $\text{cofactors of $i$} = \begin{bmatrix} C_{i1} \\ C_{i2} \\ \vdots \\ C_{in} \end{bmatrix}$
* so $\text{row $i$} \times \text{cofactors of $i$} = \sum\limits_k a_{ik} C_{ik}$
* note that this is the [[Cofactors]] formula for calculating the determinant!
* thus, $\text{row $i$} \times \text{cofactors of $i$} = |A|$


$\text{row $i$} \times \text{cofactors of $j$} = 0$ for $i \ne j$
* let's have a look what this dot product calculates
* take row $i$ of $A$ and row $j$ of $C$ (i.e. column $j$ of $C^T$)
* $\text{row $i$} \times \text{cofactors of $j$} = \begin{bmatrix} a_{i1} &amp; a_{i2} &amp; \cdots &amp; a_{in} \end{bmatrix} \begin{bmatrix} C_{j1} \\ C_{j2} \\ \vdots \\ C_{jn} \end{bmatrix} = \sum\limits_k a_{ik} C_{jk}$
* this is a cofactors formula for a new matrix $A^*$ where the row $i$ of $A$ is copied to row $j$ of $A$. So this new matrix has two equal rows, therefore $| A^* | = 0$ 
* and thus, $\text{row $i$} \times \text{cofactors of $j$} = 0$


so we showed that 
* $A \, C^T = |A| \, I$
* therefore, $A^{-1} = \cfrac{1}{| A |} C^T$


== Cramer's Rule: Solving $A \mathbf x = \mathbf b$ ==
Now since we can find the inverse of $A^{-1}$, we can solve the system $A \mathbf x = \mathbf b$
* let $A$ be $n \times n$ invertible matrix
* we know that $A^{-1} = \cfrac{1}{|A|} C^T$, so $\mathbf x = A^{-1} \mathbf b = \cfrac{1}{|A|} C^T \mathbf b$
* let's have a look at the components of $\mathbf x$
** $x_1 = \cfrac{ (C^T \mathbf b)_1 }{|A|}$ (where $(C^T \mathbf b)_1$ is the 1st element of this vector)
** $(C^T \mathbf b)_1  = (\text{column 1 of $C$})^T \mathbf b = C_{11} b_1 + C_{21} b_2 + \ ... $
** any time we multiply something by cofactors, it's the same as getting a determinant of some matrix
** in this case, we're calculating the determinant of $B_1$ - matrix $A$ with column 1 replaced with $\mathbf b$ 
** thus, $x_1 = \cfrac{|B_1|}{|A|} = \begin{vmatrix}
  b_{1} &amp; a_{12} &amp; \cdots &amp; a_{1n} \\
  b_{2} &amp; a_{22} &amp; \cdots &amp; a_{2n} \\
  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
  b_{n} &amp; a_{n2} &amp; \cdots &amp; a_{nn} \\
\end{vmatrix} / \begin{vmatrix}
  a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n} \\
  a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n} \\
  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
  a_{n1} &amp; a_{n2} &amp; \cdots &amp; a_{nn} \\
\end{vmatrix}$
* and generally, $x_i = \cfrac{|B_i|}{|A|}$, where $B_i$ is $A$ with column $i$ replaced by $\mathbf b$

This is known as the '''Cramer's Rule'''


=== Efficiency ===
This is known as not very practical method for computing the inverse or for solving the system
* some more computationally efficient methods are [[Gaussian Elimination]] (= [[LU Decomposition]])



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Strang, G. Introduction to linear algebra.
* http://en.wikipedia.org/wiki/Cramer%27s_rule


[[Category:Linear Algebra]]</text>
      <sha1>5bf8ybu0tsigm5d4lgm6m4vo39aqmlb</sha1>
    </revision>
  </page>
  <page>
    <title>LU Decomposition</title>
    <ns>0</ns>
    <id>532</id>
    <revision>
      <id>535</id>
      <timestamp>2015-04-23T16:31:04Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1152">== $LU$ Factorization ==
This is the simplest factorization that can be seen as a by-product of [[Gaussian Elimination]]

When we do elimination, we have some elimination matrices: 
* $E_1 \cdots E_k A = U$, where $E_1 \cdots E_k$ are elimination matrices for each elimination step 
* Let $E = E_1 \cdots E_k$


=== $LU$ ===
* $E_1 \cdots E_k \ A = U$
* or $EA = U$
* let $L = E^{-1}$, so we have $A = LU$
* $U$ is upper-triangular by construction - because we eliminate all elements down the main diagonal
* $L$ is lower-triangular 

$L$
* $L = E^{-1} = (E_1 \cdots E_k)^{-1} = E_k^{-1} \cdots E_1^{-1}$
* $E_i$ have zeros up the diagonal, so when we inverse them, they become lower-diagonal 
* when we multiply a bunch of lower-diagonal matrices, we get a lower-diagonal matrix


[[Permutation Matrices]]
* What if we need to permute some rows during the elimination?
* Then we have $EPA = U$ or $PA = LU$


=== $LDU$ ===
We can go further and obtain factorization $A = LU = LDU^*$, where $D$ is diagonal. I.e. we factorize $U = DU^*$


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]
[[Category:Matrix Decomposition]]</text>
      <sha1>mv4rrrojmyeyktzz4ml39qewyvby0vr</sha1>
    </revision>
    <revision>
      <id>776</id>
      <parentid>535</parentid>
      <timestamp>2017-06-15T14:26:04Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2439">== $LU$ Factorization ==
This is the simplest factorization that can be seen as a by-product of [[Gaussian Elimination]]

When we do elimination, we have some elimination matrices: 
* $E_1 \cdots E_k A = U$, where $E_1 \cdots E_k$ are elimination matrices for each elimination step 
* Let $E = E_1 \cdots E_k$


=== $LU$ ===
* $E_1 \cdots E_k \ A = U$
* or $EA = U$
* let $L = E^{-1}$, so we have $A = LU$
* $U$ is upper-triangular by construction - because we eliminate all elements down the main diagonal
* $L$ is lower-triangular 

$L$
* $L = E^{-1} = (E_1 \cdots E_k)^{-1} = E_k^{-1} \cdots E_1^{-1}$
* $E_i$ have zeros up the diagonal, so when we inverse them, they become lower-diagonal 
* when we multiply a bunch of lower-diagonal matrices, we get a lower-diagonal matrix


Types of $LU$ decomposition:
* It's possible to have ones on the main diagonal of either $L$ or $U$ 
* Doolittle decomposition - the diagonal entries of $L$ are ones
* Crout decomposition - the diagonal entries of $U$ are ones


=== $PLU$ Decomposition and Pivoting ===
* To avoid division by small numbers, we permute rows during the eliminations such that the largest element is the pivot
* We can express row permutation with the permutation matrix P
* Then $PA$ is $A$ with permuted rows, so we have $E \, (PA) = U$
* So the decomposition becomes $PA = LU$


=== $LDU$ ===
We can go further:
* and obtain factorization $A = LU = LDU^*$, where $D$ is diagonal
* I.e. we factorize $U = DU^*$
* this way both $L$ and $U$ will have ones on their diagonals - if $L$ had ones and $U$ didn't 



== [[Inverse Matrices|Matrix Inversion]] with LU Decomposition ==
To find the matrix inverse, we need to solve the equation $AX = I$, where $X = A^{-1}$
* Let's decompose $A = LU$, so we have: $LUX = I$
* Now let $UX = Y$ and thus $LY = I$
* This gives us two systems:
** first solve $LY = I$ - it's easy because $L$ is lower-triangular, so we just do the forward pass and obtain $Y$
** then we solve $UX = Y$ - it's also easy because $U$ is upper-triangular 
* after that we get $X$ which is our inverse
* if we need pivoting, then:
** we solve $PAX = PI = P$
** since $PA = LU$, we have $LUX = P$
** then we solve $LY = P$ and $UX = Y$


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* https://www.gamedev.net/resources/_/technical/math-and-physics/matrix-inversion-using-lu-decomposition-r3637

[[Category:Linear Algebra]]
[[Category:Matrix Decomposition]]</text>
      <sha1>cy2k2imi4ht2nhon3vwzn0vawk0sjks</sha1>
    </revision>
    <revision>
      <id>800</id>
      <parentid>776</parentid>
      <timestamp>2017-06-27T12:34:05Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3954">== $LU$ Factorization ==
This is the simplest factorization that can be seen as a by-product of [[Gaussian Elimination]]

When we do elimination, we have some elimination matrices: 
* $E_1 \cdots E_k A = U$, where $E_1 \cdots E_k$ are elimination matrices for each elimination step 
* Let $E = E_1 \cdots E_k$


=== $LU$ ===
* $E_1 \cdots E_k \ A = U$
* or $EA = U$
* let $L = E^{-1}$, so we have $A = LU$
* $U$ is upper-triangular by construction - because we eliminate all elements down the main diagonal
* $L$ is lower-triangular 

$L$
* $L = E^{-1} = (E_1 \cdots E_k)^{-1} = E_k^{-1} \cdots E_1^{-1}$
* $E_i$ have zeros up the diagonal, so when we inverse them, they become lower-diagonal 
* when we multiply a bunch of lower-diagonal matrices, we get a lower-diagonal matrix


Types of $LU$ decomposition:
* It's possible to have ones on the main diagonal of either $L$ or $U$ 
* Doolittle decomposition - the diagonal entries of $L$ are ones
* Crout decomposition - the diagonal entries of $U$ are ones


=== $PLU$ Decomposition and Pivoting ===
* To avoid division by small numbers, we permute rows during the eliminations such that the largest element is the pivot
* We can express row permutation with the permutation matrix P
* Then $PA$ is $A$ with permuted rows, so we have $E \, (PA) = U$
* So the decomposition becomes $PA = LU$


=== $LDU$ ===
We can go further:
* and obtain factorization $A = LU = LDU^*$, where $D$ is diagonal
* I.e. we factorize $U = DU^*$
* this way both $L$ and $U$ will have ones on their diagonals - if $L$ had ones and $U$ didn't 

== Solving [[System of Linear Equations|$A \mathbf x = \mathbf b$]] with LU Decomposition ==
Solving $A\mathbf x = \mathbf b$
* Can do that with Gaussian Elimination via LU Decomposition
* Let $LU = A$
* then $A \mathbf x = \mathbf b$ becomes $LU \mathbf x = \mathbf b$
* Now let $U \mathbf x = \mathbf y$ and $L \mathbf y = \mathbf x$
* With this substitution we need to solve two equations now
** Solve $L \mathbf y = \mathbf b$ to get $\mathbf y$ 
** Solve $U \mathbf x = \mathbf y$ to get $\mathbf x$
* These two equations are simpler than the original one because:
** $L$ is lower-diagonal, and $L \mathbf y = \mathbf b$ can be solved with &quot;Forward Substitution&quot; and 
** $U$ is upper-diagonal, and $U \mathbf x = \mathbf y$ can be solved with &quot;Back Substitution&quot;


=== Forward Substitution ===
First, we solve $L \mathbf x = \mathbf b$

$2 \times 2$ case:
* &lt;math&gt;\begin{bmatrix}
l_{11} &amp; 0 \\ 
l_{21} &amp; l_{22} \\ 
\end{bmatrix} 
\begin{bmatrix}
x_1 \\
x_2 \\
\end{bmatrix}
=
\begin{bmatrix}
b_1 \\
b_2 \\
\end{bmatrix}
&lt;/math&gt;
* $x_1 = b_1 / l_{11}$
* $x_2 = (b_2 - l_{21} x_2) / l_{22}$

General procedure:
* $x_i = (b - \sum_{j=1}^{i - 1} l_{ij} x_j) / l_{ii}$


=== Back Substitution ===
Then we solve $U \mathbf x = \mathbf b$

$2 \times 2$ case:
* &lt;math&gt;\begin{bmatrix}
u_{11} &amp; u_{12} \\ 
0 &amp; u_{22} \\ 
\end{bmatrix} 
\begin{bmatrix}
x_1 \\
x_2 \\
\end{bmatrix}
=
\begin{bmatrix}
b_1 \\
b_2 \\
\end{bmatrix}
&lt;/math&gt;

General procedure:
* $x_i = (b - \sum_{j=i+1}^{n} u_{ij} x_j) / u_{ii}$


=== [[Inverse Matrices|Matrix Inversion]] ===
To find the matrix inverse, we need to solve the equation $AX = I$, where $X = A^{-1}$
* Let's decompose $A = LU$, so we have: $LUX = I$
* Now let $UX = Y$ and thus $LY = I$
* This gives us two systems:
** first solve $LY = I$ - it's easy because $L$ is lower-triangular, so we just do the forward pass and obtain $Y$
** then we solve $UX = Y$ - it's also easy because $U$ is upper-triangular 
* after that we get $X$ which is our inverse
* if we need pivoting, then:
** we solve $PAX = PI = P$
** since $PA = LU$, we have $LUX = P$
** then we solve $LY = P$ and $UX = Y$


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* https://www.gamedev.net/resources/_/technical/math-and-physics/matrix-inversion-using-lu-decomposition-r3637
* [[Matrix Computations (book)]]

[[Category:Linear Algebra]]
[[Category:Matrix Decomposition]]</text>
      <sha1>ety0296gu0sdwpykwl8lsczt7q5d944</sha1>
    </revision>
    <revision>
      <id>801</id>
      <parentid>800</parentid>
      <timestamp>2017-06-27T13:26:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7628">== $LU$ Decomposition ==
This is the simplest matrix decomposition that can be seen as a by-product of [[Gaussian Elimination]]
* The decomposition is $LU = A$ where
* $A$ is a square matrix 
* $L$ and $U$ are [[Triangular Matrices]], $L$ is lower-triangular and $U$ is upper-triangular

When we perform [[Gaussian Elimination]], we can see each step as a single elimination matrix $E_i$ 
* $E_1 \cdots E_k A = U$, where $E_1 \cdots E_k$ are elimination matrices for each elimination step 
* Let $E = E_1 \cdots E_k$


=== $LU$ ===
The $U$ part
* $E_1 \cdots E_k \ A = U$
* or $EA = U$
* let $L = E^{-1}$, so we have $A = LU$
* $U$ is upper-triangular by construction - because we eliminate all elements down the main diagonal
* $L$ is lower-triangular 

The $L$ part
* $L = E^{-1} = (E_1 \cdots E_k)^{-1} = E_k^{-1} \cdots E_1^{-1}$
* $E_i$ have zeros up the diagonal, so when we inverse them, they become lower-diagonal 
* when we multiply a bunch of lower-diagonal matrices, we get a lower-diagonal matrix


Matrix Form
* how do we represent the zeroing process with a sequence of elimination matrices $E_i$ 
* want some matrix that behaves in the following way:
** &lt;math&gt;\begin{bmatrix}
1 &amp; 0 \\ 
-\tau &amp; 1 \\ 
\end{bmatrix} 
\begin{bmatrix}
v_1 \\
v_2 \\
\end{bmatrix}
=
\begin{bmatrix}
v_1 \\
0 \\
\end{bmatrix}
&lt;/math&gt;
* so let $E_k = I - \tau e_k^T$ where $e_k$ has 1 on the $k$th positions, and zeros elsewhere
* for larger matrices: 
* &lt;math&gt;E_k v = \begin{bmatrix}
1 &amp; 0 &amp;  \cdots &amp; 0 &amp; 0 &amp; 0 &amp;  \cdots &amp; 0 \\ 
0 &amp; 1 &amp;  \cdots &amp; 0 &amp; 0 &amp; 0 &amp;  \cdots &amp; 0 \\ 
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots &amp; \vdots &amp;  \ddots &amp; \vdots \\ 
0 &amp; 0 &amp;  \cdots &amp; 1 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 \\ 
\hline
0 &amp; 0 &amp;  \cdots &amp; -\tau_{k+1} &amp; 1 &amp; 0 &amp; \cdots &amp; 0 \\ 
0 &amp; 0 &amp;  \cdots &amp; -\tau_{k+2} &amp; 0 &amp; 1 &amp; \cdots &amp; 0 \\ 
\vdots &amp; \vdots &amp;  \ddots &amp; \vdots &amp; \vdots &amp; \vdots &amp;  \ddots &amp; \vdots \\ 
0 &amp; 0 &amp;  \cdots &amp; -\tau_{n} &amp;  0 &amp; 0 &amp; \cdots &amp; 1 \\ 
\end{bmatrix}
\begin{bmatrix}
v_1 \\
v_2 \\
\vdots \\
v_k \\
\hline
v_{k+1} \\
v_{k+2} \\
\vdots \\
v_{n} \\
\end{bmatrix}
=
\begin{bmatrix}
v_1 \\
v_2 \\
\vdots \\
v_k \\
\hline
0 \\
0 \\
\vdots \\
0 \\
\end{bmatrix}&lt;/math&gt;
* so let $\tau^{(k)} = [0, 0, 0 | \tau_{k+1}, \tau_{k+2}, ..., \tau_{n},  ]$
* and $E_k = I - \tau^{(k)} e_k^T$


Computing $L$:
* $L = E_1^{-1} E_2^{-1} \cdots E_{n-1}^{-1} = I + \sum \tau^{(k)} e_k^T$


Types of $LU$ decomposition:
* It's possible to have ones on the main diagonal of either $L$ or $U$ 
* Doolittle decomposition - the diagonal entries of $L$ are ones, so $L$ is Unit-Triangular
* Crout decomposition - the diagonal entries of $U$ are ones, so $U$ is Unit-Triangular


=== Properties ===
* $\text{det}(A) = \text{det}(LU) = \text{det}(L) \text{det}(U) = \text{det}(U) = u_{11} u_{22} ... u_{nn}$
* so can use $A = LU$ decomposition for computing the determinant


=== Pivoting and $PLU$ Decomposition ===
* During elimination we can permute rows
* We can express row permutation with the permutation matrix P
* Then $PA$ is $A$ with permuted rows, so we have $E \, (PA) = U$
* So the decomposition becomes $PA = LU$


Why permute?
* To avoid division by small numbers
* Suppose &lt;math&gt;A = \begin{bmatrix}
0.0001 &amp; 1 \\ 
1 &amp; 1 \\ 
\end{bmatrix} 
= 
\begin{bmatrix}
1 &amp; 0 \\ 
10000 &amp; 1 \\ 
\end{bmatrix} 
\begin{bmatrix}
-0.0001 &amp; 1 \\ 
0 &amp; -9999 \\ 
\end{bmatrix} 
=
LU
&lt;/math&gt; 
* if we pivot, then we have:
* &lt;math&gt;PA = \begin{bmatrix}
1 &amp; 1 \\ 
0.0001 &amp; 1 \\ 
\end{bmatrix} 
= 
\begin{bmatrix}
1 &amp; 0 \\ 
0.0001 &amp; 1 \\ 
\end{bmatrix} 
\begin{bmatrix}
1 &amp; 1 \\ 
0 &amp; 0.9999 \\ 
\end{bmatrix} 
=
LU
&lt;/math&gt; 


=== Diagonalization and $LDU$ and $LDL^T$ Decomposition ===
We can go further:
* and obtain factorization $A = LU = LDU^*$, where $D$ is diagonal
* I.e. we factorize $U = DU^*$
* this way both $L$ and $U$ will have ones on their diagonals - if $L$ had ones and $U$ didn't 

Why?
* Suppose that $A$ is [[Symmetric Matrices|Symmetric]]
* Then pivoting will destroy this nice structure
* So instead we should do $LDL^T$ decomposition
* Or something else, e.g. [[Cholesky Decomposition]]


== Solving [[System of Linear Equations|$A \mathbf x = \mathbf b$]] with LU Decomposition ==
Solving $A\mathbf x = \mathbf b$
* Can do that with Gaussian Elimination via LU Decomposition
* Let $LU = A$
* then $A \mathbf x = \mathbf b$ becomes $LU \mathbf x = \mathbf b$
* Now let $U \mathbf x = \mathbf y$ and $L \mathbf y = \mathbf x$
* With this substitution we need to solve two equations now
** Solve $L \mathbf y = \mathbf b$ to get $\mathbf y$ 
** Solve $U \mathbf x = \mathbf y$ to get $\mathbf x$
* These two equations are simpler than the original one because:
** $L$ is lower-diagonal, and $L \mathbf y = \mathbf b$ can be solved with &quot;Forward Substitution&quot; and 
** $U$ is upper-diagonal, and $U \mathbf x = \mathbf y$ can be solved with &quot;Back Substitution&quot;


=== Forward Substitution ===
First, we solve $L \mathbf x = \mathbf b$

$2 \times 2$ case:
* &lt;math&gt;\begin{bmatrix}
l_{11} &amp; 0 \\ 
l_{21} &amp; l_{22} \\ 
\end{bmatrix} 
\begin{bmatrix}
x_1 \\
x_2 \\
\end{bmatrix}
=
\begin{bmatrix}
b_1 \\
b_2 \\
\end{bmatrix}
&lt;/math&gt;
* $x_1 = b_1 / l_{11}$
* $x_2 = (b_2 - l_{21} x_2) / l_{22}$

General procedure:
* $x_i = (b - \sum_{j=1}^{i - 1} l_{ij} x_j) / l_{ii}$


=== Back Substitution ===
Then we solve $U \mathbf x = \mathbf b$

$2 \times 2$ case:
* &lt;math&gt;\begin{bmatrix}
u_{11} &amp; u_{12} \\ 
0 &amp; u_{22} \\ 
\end{bmatrix} 
\begin{bmatrix}
x_1 \\
x_2 \\
\end{bmatrix}
=
\begin{bmatrix}
b_1 \\
b_2 \\
\end{bmatrix}
&lt;/math&gt;

General procedure:
* $x_i = (b - \sum_{j=i+1}^{n} u_{ij} x_j) / u_{ii}$


=== [[Inverse Matrices|Matrix Inversion]] ===
To find the matrix inverse, we need to solve the equation $AX = I$, where $X = A^{-1}$
* Let's decompose $A = LU$, so we have: $LUX = I$
* Now let $UX = Y$ and thus $LY = I$
* This gives us two systems:
** first solve $LY = I$ - it's easy because $L$ is lower-triangular, so we just do the forward pass and obtain $Y$
** then we solve $UX = Y$ - it's also easy because $U$ is upper-triangular 
* after that we get $X$ which is our inverse
* if we need pivoting, then:
** we solve $PAX = PI = P$
** since $PA = LU$, we have $LUX = P$
** then we solve $LY = P$ and $UX = Y$


== Usages ==
In many cases expensive operations (such as matrix multiplication or inverse) can be made faster with LU Decomposition

=== Solving $A^k \mathbf x = \mathbf b$ ===
Suppose we want to solve $A^k \mathbf x = \mathbf b$
* first computing $A^k$ and then solving the system
* or can use recursion
** $A^{k} \mathbf x = \mathbf b$
** let $\mathbf y = A^{k-1} \mathbf x$
** so we have $A \mathbf y = \mathbf b$
** solve it, get $\mathbf y$
** now need to solve $A^{k-1} \mathbf x = \mathbf y$
** let $\mathbf b = \mathbf y$ and solve $A^{k-1} \mathbf x = \mathbf b$
** repeat


So, the algorithm:
* let $PA = LU$
* for $j = 1, ..., k$, do
* solve $L \mathbf y = P \mathbf b$, store $\mathbf y$
* solve $U \mathbf x = \mathbf y$, store $\mathbf x$
* let $\mathbf b = \mathbf x$


=== Solving $S = C^T A^{-1} \mathbf d$ ===
Want to compute $S = C^T A^{-1} \mathbf d$
* can avoid computing the inverse of $A$ 
* let $PA = LU$
* solve $Ly = Pd$ and then $Ux = y$
* then solve $S = S^T x$ 

In general, if you see an inverse followed by a vector, you don't need to compure the inverse:
* let $A^{-1} d = x$
* so $Ax = d$
* solve that with $LU$, get $x$ 
* compure $C^T x$ 


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* https://www.gamedev.net/resources/_/technical/math-and-physics/matrix-inversion-using-lu-decomposition-r3637
* [[Matrix Computations (book)]]

[[Category:Linear Algebra]]
[[Category:Matrix Decomposition]]</text>
      <sha1>12dax7f8e20dyyloltxo27febxlej7p</sha1>
    </revision>
    <revision>
      <id>806</id>
      <parentid>801</parentid>
      <timestamp>2017-06-28T13:56:11Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7632">== $LU$ Decomposition ==
This is the simplest matrix decomposition that can be seen as a by-product of [[Gaussian Elimination]]
* The decomposition is $LU = A$ where
* $A$ is a square matrix 
* $L$ and $U$ are [[Triangular Matrices]], $L$ is lower-triangular and $U$ is upper-triangular

When we perform [[Gaussian Elimination]], we can see each step as a single elimination matrix $E_i$ 
* $E_1 \cdots E_k A = U$, where $E_1 \cdots E_k$ are elimination matrices for each elimination step 
* Let $E = E_1 \cdots E_k$


=== $LU$ ===
The $U$ part
* $E_1 \cdots E_k \ A = U$
* or $EA = U$
* let $L = E^{-1}$, so we have $A = LU$
* $U$ is upper-triangular by construction - because we eliminate all elements down the main diagonal
* $L$ is lower-triangular 

The $L$ part
* $L = E^{-1} = (E_1 \cdots E_k)^{-1} = E_k^{-1} \cdots E_1^{-1}$
* $E_i$ have zeros up the diagonal, so when we inverse them, they become lower-diagonal 
* when we multiply a bunch of lower-diagonal matrices, we get a lower-diagonal matrix


Matrix Form
* how do we represent the zeroing process with a sequence of elimination matrices $E_i$ 
* want some matrix that behaves in the following way:
** &lt;math&gt;\begin{bmatrix}
1 &amp; 0 \\ 
-\tau &amp; 1 \\ 
\end{bmatrix} 
\begin{bmatrix}
v_1 \\
v_2 \\
\end{bmatrix}
=
\begin{bmatrix}
v_1 \\
0 \\
\end{bmatrix}
&lt;/math&gt;
* so let $E_k = I - \tau e_k^T$ where $e_k$ has 1 on the $k$th positions, and zeros elsewhere
* for larger matrices: 
* &lt;math&gt;E_k v = \begin{bmatrix}
1 &amp; 0 &amp;  \cdots &amp; 0 &amp; 0 &amp; 0 &amp;  \cdots &amp; 0 \\ 
0 &amp; 1 &amp;  \cdots &amp; 0 &amp; 0 &amp; 0 &amp;  \cdots &amp; 0 \\ 
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots &amp; \vdots &amp;  \ddots &amp; \vdots \\ 
0 &amp; 0 &amp;  \cdots &amp; 1 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 \\ 
\hline
0 &amp; 0 &amp;  \cdots &amp; -\tau_{k+1} &amp; 1 &amp; 0 &amp; \cdots &amp; 0 \\ 
0 &amp; 0 &amp;  \cdots &amp; -\tau_{k+2} &amp; 0 &amp; 1 &amp; \cdots &amp; 0 \\ 
\vdots &amp; \vdots &amp;  \ddots &amp; \vdots &amp; \vdots &amp; \vdots &amp;  \ddots &amp; \vdots \\ 
0 &amp; 0 &amp;  \cdots &amp; -\tau_{n} &amp;  0 &amp; 0 &amp; \cdots &amp; 1 \\ 
\end{bmatrix}
\begin{bmatrix}
v_1 \\
v_2 \\
\vdots \\
v_k \\
\hline
v_{k+1} \\
v_{k+2} \\
\vdots \\
v_{n} \\
\end{bmatrix}
=
\begin{bmatrix}
v_1 \\
v_2 \\
\vdots \\
v_k \\
\hline
0 \\
0 \\
\vdots \\
0 \\
\end{bmatrix}&lt;/math&gt;
* so let $\tau^{(k)} = [0, 0, 0 | \tau_{k+1}, \tau_{k+2}, ..., \tau_{n},  ]$
* and $E_k = I - \tau^{(k)} e_k^T$


Computing $L$:
* $L = E_1^{-1} E_2^{-1} \cdots E_{n-1}^{-1} = I + \sum \tau^{(k)} e_k^T$


Types of $LU$ decomposition:
* It's possible to have ones on the main diagonal of either $L$ or $U$ 
* Doolittle decomposition - the diagonal entries of $L$ are ones, so $L$ is Unit-Triangular
* Crout decomposition - the diagonal entries of $U$ are ones, so $U$ is Unit-Triangular


=== Properties ===
* $\text{det}(A) = \text{det}(LU) = \text{det}(L) \text{det}(U) = \text{det}(U) = u_{11} u_{22} ... u_{nn}$
* so can use $A = LU$ decomposition for computing the determinant


=== Pivoting and $PLU$ Decomposition ===
* During elimination we can permute rows
* We can express row permutation with the permutation matrix P
* Then $PA$ is $A$ with permuted rows, so we have $E \, (PA) = U$
* So the decomposition becomes $PA = LU$


Why permute?
* To avoid division by small numbers
* Suppose &lt;math&gt;A = \begin{bmatrix}
0.0001 &amp; 1 \\ 
1 &amp; 1 \\ 
\end{bmatrix} 
= 
\begin{bmatrix}
1 &amp; 0 \\ 
10000 &amp; 1 \\ 
\end{bmatrix} 
\begin{bmatrix}
-0.0001 &amp; 1 \\ 
0 &amp; -9999 \\ 
\end{bmatrix} 
=
LU
&lt;/math&gt; 
* if we pivot, then we have:
* &lt;math&gt;PA = \begin{bmatrix}
1 &amp; 1 \\ 
0.0001 &amp; 1 \\ 
\end{bmatrix} 
= 
\begin{bmatrix}
1 &amp; 0 \\ 
0.0001 &amp; 1 \\ 
\end{bmatrix} 
\begin{bmatrix}
1 &amp; 1 \\ 
0 &amp; 0.9999 \\ 
\end{bmatrix} 
=
LU
&lt;/math&gt; 


=== [[Diagonalization]] and $LDU$ and $LDL^T$ Decomposition ===
We can go further:
* and obtain factorization $A = LU = LDU^*$, where $D$ is diagonal
* I.e. we factorize $U = DU^*$
* this way both $L$ and $U$ will have ones on their diagonals - if $L$ had ones and $U$ didn't 

Why?
* Suppose that $A$ is [[Symmetric Matrices|Symmetric]]
* Then pivoting will destroy this nice structure
* So instead we should do $LDL^T$ decomposition
* Or something else, e.g. [[Cholesky Decomposition]]


== Solving [[System of Linear Equations|$A \mathbf x = \mathbf b$]] with LU Decomposition ==
Solving $A\mathbf x = \mathbf b$
* Can do that with Gaussian Elimination via LU Decomposition
* Let $LU = A$
* then $A \mathbf x = \mathbf b$ becomes $LU \mathbf x = \mathbf b$
* Now let $U \mathbf x = \mathbf y$ and $L \mathbf y = \mathbf x$
* With this substitution we need to solve two equations now
** Solve $L \mathbf y = \mathbf b$ to get $\mathbf y$ 
** Solve $U \mathbf x = \mathbf y$ to get $\mathbf x$
* These two equations are simpler than the original one because:
** $L$ is lower-diagonal, and $L \mathbf y = \mathbf b$ can be solved with &quot;Forward Substitution&quot; and 
** $U$ is upper-diagonal, and $U \mathbf x = \mathbf y$ can be solved with &quot;Back Substitution&quot;


=== Forward Substitution ===
First, we solve $L \mathbf x = \mathbf b$

$2 \times 2$ case:
* &lt;math&gt;\begin{bmatrix}
l_{11} &amp; 0 \\ 
l_{21} &amp; l_{22} \\ 
\end{bmatrix} 
\begin{bmatrix}
x_1 \\
x_2 \\
\end{bmatrix}
=
\begin{bmatrix}
b_1 \\
b_2 \\
\end{bmatrix}
&lt;/math&gt;
* $x_1 = b_1 / l_{11}$
* $x_2 = (b_2 - l_{21} x_2) / l_{22}$

General procedure:
* $x_i = (b - \sum_{j=1}^{i - 1} l_{ij} x_j) / l_{ii}$


=== Back Substitution ===
Then we solve $U \mathbf x = \mathbf b$

$2 \times 2$ case:
* &lt;math&gt;\begin{bmatrix}
u_{11} &amp; u_{12} \\ 
0 &amp; u_{22} \\ 
\end{bmatrix} 
\begin{bmatrix}
x_1 \\
x_2 \\
\end{bmatrix}
=
\begin{bmatrix}
b_1 \\
b_2 \\
\end{bmatrix}
&lt;/math&gt;

General procedure:
* $x_i = (b - \sum_{j=i+1}^{n} u_{ij} x_j) / u_{ii}$


=== [[Inverse Matrices|Matrix Inversion]] ===
To find the matrix inverse, we need to solve the equation $AX = I$, where $X = A^{-1}$
* Let's decompose $A = LU$, so we have: $LUX = I$
* Now let $UX = Y$ and thus $LY = I$
* This gives us two systems:
** first solve $LY = I$ - it's easy because $L$ is lower-triangular, so we just do the forward pass and obtain $Y$
** then we solve $UX = Y$ - it's also easy because $U$ is upper-triangular 
* after that we get $X$ which is our inverse
* if we need pivoting, then:
** we solve $PAX = PI = P$
** since $PA = LU$, we have $LUX = P$
** then we solve $LY = P$ and $UX = Y$


== Usages ==
In many cases expensive operations (such as matrix multiplication or inverse) can be made faster with LU Decomposition

=== Solving $A^k \mathbf x = \mathbf b$ ===
Suppose we want to solve $A^k \mathbf x = \mathbf b$
* first computing $A^k$ and then solving the system
* or can use recursion
** $A^{k} \mathbf x = \mathbf b$
** let $\mathbf y = A^{k-1} \mathbf x$
** so we have $A \mathbf y = \mathbf b$
** solve it, get $\mathbf y$
** now need to solve $A^{k-1} \mathbf x = \mathbf y$
** let $\mathbf b = \mathbf y$ and solve $A^{k-1} \mathbf x = \mathbf b$
** repeat


So, the algorithm:
* let $PA = LU$
* for $j = 1, ..., k$, do
* solve $L \mathbf y = P \mathbf b$, store $\mathbf y$
* solve $U \mathbf x = \mathbf y$, store $\mathbf x$
* let $\mathbf b = \mathbf x$


=== Solving $S = C^T A^{-1} \mathbf d$ ===
Want to compute $S = C^T A^{-1} \mathbf d$
* can avoid computing the inverse of $A$ 
* let $PA = LU$
* solve $Ly = Pd$ and then $Ux = y$
* then solve $S = S^T x$ 

In general, if you see an inverse followed by a vector, you don't need to compure the inverse:
* let $A^{-1} d = x$
* so $Ax = d$
* solve that with $LU$, get $x$ 
* compure $C^T x$ 


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* https://www.gamedev.net/resources/_/technical/math-and-physics/matrix-inversion-using-lu-decomposition-r3637
* [[Matrix Computations (book)]]

[[Category:Linear Algebra]]
[[Category:Matrix Decomposition]]</text>
      <sha1>bzj315p9mi1fn10qo4ssi0zoxyyeejs</sha1>
    </revision>
  </page>
  <page>
    <title>Determinants</title>
    <ns>0</ns>
    <id>533</id>
    <revision>
      <id>536</id>
      <timestamp>2014-12-30T21:36:59Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16211">== Determinants ==
A ''determinant'' is a value associated with a square matrix $A$
* it provides important information about [[Inverse Matrices|invertability]] of the matrix
* it's denoted as $\text{det } A$ or sometimes $| A |$


== Defining Properties ==
These properties &lt;u&gt;define&lt;/u&gt; what a determinant is (they don't say how to compute it)


=== Property 1: Determinant of $I$ ===
* $\text{det } I = 1$


=== Property 2: Sign Reversal ===
* let $A'$ be a matrix $A$ with two rows exchanged, then $\text{det } A' = \text{det } A$

Consequence of property 2:
* for a [[Permutation Matrices|Permutation Matrix]] $P$
* $\text{det } P = 1$ if if has even number of row exchanges
* and $\text{det } P = -1$ is it has odd number of exchanges


=== Property 3: Linearity ===
* determinant is a linear function of a row - if all other rows stays the same 
* 3a) $\begin{vmatrix}
t a_{11} &amp; t a_{12} &amp; t a_{13} \\ 
a_{21} &amp; a_{22} &amp; a_{23} \\ 
a_{31} &amp; a_{32} &amp; a_{33} \\ 
\end{vmatrix} = t \cdot \begin{vmatrix}
a_{11} &amp; a_{12} &amp; a_{13} \\ 
a_{21} &amp; a_{22} &amp; a_{23} \\ 
a_{31} &amp; a_{32} &amp; a_{33} \\ 
\end{vmatrix}$
* 3b) $\begin{vmatrix}
a_{11} + a'_{11} &amp; a_{12} + a'_{12} &amp; a_{13} + a'_{13} \\ 
a_{21} &amp; a_{22} &amp; a_{23} \\ 
a_{31} &amp; a_{32} &amp; a_{33} \\ 
\end{vmatrix} = \begin{vmatrix}
a_{11} &amp; a_{12} &amp; a_{13} \\ 
a_{21} &amp; a_{22} &amp; a_{23} \\ 
a_{31} &amp; a_{32} &amp; a_{33} \\ 
\end{vmatrix} + \begin{vmatrix}
a'_{11} &amp; a'_{12} &amp; a'_{13} \\ 
a_{21} &amp; a_{22} &amp; a_{23} \\ 
a_{31} &amp; a_{32} &amp; a_{33} \\ 
\end{vmatrix}$
* applies to all the rows: we always can put any row to the first position (property 2), then apply the property 3, and then put the row back 


== Other properties ==
These properties are consequences of the defining properties

=== Property 4: Equal Rows ===
* if 2 rows are equal, then $\text{det } A = 0$
* proof: if we exchange two rows, nothing happens to the matrix, but property 2 says the sign should be reversed


=== Property 5: Linear Combinations ===
* if we subtract a multiple of row $i$ from the row $k$, the determinant remains the same
* for [[Gaussian Elimination]] it means that $\text{det } A = \text{det } U$
* $\begin{vmatrix}
a_{11} &amp; a_{12} \\ 
a_{21} - c a_{11} &amp; a_{22} - c a_{12} \\ 
\end{vmatrix} \ \mathop{=}\limits^{3^{\circ}} \
\begin{vmatrix}
a_{11} &amp; a_{12} \\ 
a_{21} &amp; a_{22} \\ 
\end{vmatrix} - c \begin{vmatrix}
a_{11} &amp; a_{12} \\ 
a_{11} &amp; a_{12} \\ 
\end{vmatrix} \ \mathop{=}\limits^{4^{\circ}} \
\begin{vmatrix}
a_{11} &amp; a_{12} \\ 
a_{21} &amp; a_{22} \\ 
\end{vmatrix} - c 0 = \begin{vmatrix}
a_{11} &amp; a_{12} \\ 
a_{21} &amp; a_{22} \\ 
\end{vmatrix}$


=== Property 6: Zero Row ===
* if we have a rows full of zeros, then $\text{det } A = 0$
* $c \cdot \begin{vmatrix}
a_{11} &amp; a_{12} \\ 
0 &amp; 0 \\ 
\end{vmatrix} = \begin{vmatrix}
a_{11} &amp; a_{12} \\ 
c \cdot 0 &amp; c \cdot 0 \\ 
\end{vmatrix} = \begin{vmatrix}
a_{11} &amp; a_{12} \\ 
0 &amp; 0 \\ 
\end{vmatrix}$
* the only possible way for this to be valid is when the det is 0


=== Property 7: Determinant of $U$ ===
* for upper-triangular matrix $U$, determinant of $U$ is the product of elements on the main diagonal
* $\begin{vmatrix}
d_1 &amp; 0 &amp; 0 \\ 
a_{21} &amp; d_2 &amp; 0 \\ 
a_{31} &amp; a_{32} &amp; d_3 \\ 
\end{vmatrix} = \prod d_i$

Why?
* if we can do $LU$ factorization, then we can do $LDU$ factorization as well
* and by property 5, $\text{det } A = \text{det } U = \text{det } D$
* $\begin{vmatrix}
d_1 &amp; 0 &amp; 0 \\ 
0 &amp; d_2 &amp; 0 \\ 
0 &amp; 0 &amp; d_3 \\ 
\end{vmatrix} \ \mathop{=}\limits^{3^{\circ}} \ d_1 \cdot \begin{vmatrix}
1 &amp; 0 &amp; 0 \\ 
0 &amp; d_2 &amp; 0 \\ 
0 &amp; 0 &amp; d_3 \\ 
\end{vmatrix} = d_1 d_2 \cdot \begin{vmatrix}
1 &amp; 0 &amp; 0 \\ 
0 &amp; 1 &amp; 0 \\ 
0 &amp; 0 &amp; d_3 \\ 
\end{vmatrix} = d_1 d_2 d_3 \cdot \text{det } I = \prod d_i$


Consequence: 
* the easiest way to compute the determinant is to apply [[LU Factorization|$A = LU$ Factorization]] and then compute $\text{det } U = \prod_i d_i$
** note that you should be careful with row exchanges!
* what if some $d_i = 0$? then $\text{det } U = 0$


=== Property 8: Singularity Test ===
* when $A$ is singular, then $\text{det } A = 0$
* when $A$ is non-singular, then $\text{det } A \ne 0$
* it makes it a good test for invertability

Why? 
* directly follows from property 7
* compute $A = LU$ factorization
* if the matrix is singular, then at least one $d_i = 0$, then $\text{det } U = 0$
* if $A$ is not singular, then no pivot is 0, thus $\text{det } U \ne 0$


=== Property 9: Product Rule ===
* $\text{det } AB = \text{det } A \cdot \text{det } B$

Proof:
* consider ratio $D(A) = \cfrac{\text{det } AB}{\text{det } B}$ (for $\text{det } B \ne 0$)
* note that $D(A)$ obeys the properties 1, 2, 3 of $\text{det } A$
* property 1: if $A = I$, then $D(A) = \cfrac{\text{det } IB}{\text{det } B} = 1$
* property 2: if we exchange two rows of $A$, the same rows are exchanged for $AB$, thus $\text{det } AB$ changes the sign, and so does $D(A)$
* property 3:
** 3a) multiply row 1 of $A$ by $c$, then row 1 of $AB$ also gets multiplied by $c$
** 3b) add $[a'_{11}, \ ... \ , a'_{1n}]$ to row 1 of $A$ - then row 1 of $AB$ gets row 1 of $A' B$ (where $A'$ is $A$ with row 1 replaced)
** illustration: $\text{det } \begin{bmatrix}
a_{11} + a'_{11} &amp; a_{12} + a'_{12} \\ 
... &amp; ... \\ 
\end{bmatrix} \begin{bmatrix}
b_{11} &amp; b_{12} \\ 
b_{21} &amp; b_{22} \\ 
\end{bmatrix} = $
$\begin{vmatrix}
(a_{11} + a'_{11}) b_{11} + (a_{12} + a'_{12}) b_{21} &amp; (a_{11} + a'_{11}) b_{12} + (a_{12} + a'_{12}) b_{22}\\ 
... &amp; ... \\ 
\end{vmatrix} = $
$\begin{vmatrix}
a_{11} b_{11} + a_{12} b_{21} &amp; a_{11} b_{12} + a_{12} b_{22}\\ 
... &amp; ... \\ 
\end{vmatrix} +$
$\begin{vmatrix}
a'_{11} b_{11} + a'_{12} b_{21} &amp; a'_{11} b_{12} + a'_{12} b_{22}\\ 
... &amp; ... \\ 
\end{vmatrix}$
* thus $D(A)$ obeys the same properties as $\text{det } A$, so $D(A) = \text{det } A$ and we have $\text{det } AB = \text{det } A \cdot \text{det } B$


Consequence:
* $I = A^{-1} A$
* $\text{det }I = \text{det }A^{-1} A$
* $\text{det }A^{-1} \cdot \text{det } A = 1$
* $\text{det }A^{-1} = \cfrac{1}{\text{det } A}$


Consequence 2:
* now can take into account the permutation matrix $P$ in the $PA = LU$ decomposition
* $\text{det } PA = \text{det } LU$
* $\text{det } P \cdot \text{det } A = \text{det } L \cdot \text{det } U$
* $\text{det } P = \pm 1$, $\text{det } L = 1$ (elements on the diagonal of $L$ are 1's)
* so $\text{det } A = \text{det } P \cdot \text{det } U$ 



=== Property 10: Transposition ===
$\text{det } A^T = \text{det } A$
* The transpose of $A$ has the same determinant as $A$


Proof:
* consider $PA = LU$ factorization
* transpose: $A^T P^T = U^T L^T$
* take determinant, apply property 10 and compare  $\text{det }P \cdot \text{det }A = \text{det } L \cdot \text{det } U$ with $\text{det }A^T \cdot \text{det }P^T = \text{det }U^T  \cdot \text{det } L^T$
* $\text{det } L = \text{det } L^T = 1$ (both have 1's on the diagonal)
* $\text{det } U = \text{det } U^T = \prod d_i$ - they have the same elements on the diagonal
* finally $\text{det } P = \text{det } P^T$ because $P^T P = I$ ($P$ is [[Orthogonal Matrices|orthogonal]]) and by property 9 have $\text{det } P^T \cdot \text{det } P = 1$. That happens only when they agree on the sign. 
* thus, $\text{det } A^T = \text{det } A$


Consequence
* all the properties above are applied to rows, but the property #10 says that we can apply them to columns as well



== Calculating Determinants ==
There are several possible ways to calculate determinants:
* the Determinant Formula
* the Pivot Formula
* Cofactors



== Determinant Formula ==
Let's try to find out how we can compute the determinant using the properties


=== $2 \times 2$ case ===
* $\begin{vmatrix}
a_{11} &amp; a_{12} \\ 
a_{21} &amp; a_{22} \\ 
\end{vmatrix} = \ ...$ 
* can use the property 3 to divide the problem into smaller parts, and solve them separately
* $... \ = \begin{vmatrix}
a_{11} + 0 &amp; 0 + a_{12} \\ 
a_{21} &amp; a_{22} \\ 
\end{vmatrix} 
\ \mathop{=}\limits^{3^{\circ}} \
\begin{vmatrix}
a_{11} &amp; 0 \\ 
a_{21} &amp; a_{22} \\ 
\end{vmatrix} + \begin{vmatrix}
0 &amp; a_{12} \\ 
a_{21} &amp; a_{22} \\ 
\end{vmatrix} = 
\underbrace{\begin{vmatrix}
 a_{11} &amp; 0 \\ 
 a_{21} &amp; 0 \\ 
 \end{vmatrix}}_{0} + 
\begin{vmatrix}
a_{11} &amp; 0 \\ 
0 &amp; a_{22} \\ 
\end{vmatrix} +
\begin{vmatrix}
0 &amp; a_{12} \\ 
a_{21} &amp; 0 \\ 
\end{vmatrix} +
\underbrace{\begin{vmatrix}
0 &amp; a_{12} \\ 
0 &amp; a_{22} \\ 
\end{vmatrix}}_{0} = \ ...$ 
* by property 6 (zero row) and 10 (determinant of transpose), we know that some parts are 0. so we're left with 
* $... \ = \begin{vmatrix}
a_{11} &amp; 0 \\ 
0 &amp; a_{22} \\ 
\end{vmatrix} +
\begin{vmatrix}
0 &amp; a_{12} \\ 
a_{21} &amp; 0 \\ 
\end{vmatrix} = \ ...$
* now can change the rows of the second summand by property 2 (sign reversal) and get
* $... \ = \begin{vmatrix}
a_{11} &amp; 0 \\ 
0 &amp; a_{22} \\ 
\end{vmatrix} -
\begin{vmatrix}
a_{21} &amp; 0 \\ 
0 &amp; a_{12} \\ 
\end{vmatrix} = a_{11}a_{22} - a_{21}a_{12}$



=== $3 \times 3$ case ===
Can do the same for $3 \times 3$ matrices

* $\begin{vmatrix}
a_{11} &amp; a_{12} &amp; a_{13}\\ 
a_{21} &amp; a_{22} &amp; a_{23}\\
a_{31} &amp; a_{32} &amp; a_{33}\\
\end{vmatrix} = \ ...$
* we follow the same divide and conquer approach 
* most of the terms will go away because they will be equal to 0
* the &quot;survivers&quot; will have one non-zero entry from each row 
* so for $3 \times 3$ we have:
* $... \ = \begin{vmatrix}
a_{11} &amp; 0 &amp; 0\\ 
0 &amp; a_{22} &amp; 0\\
0 &amp; 0 &amp; a_{33}\\
\end{vmatrix} +
\begin{vmatrix}
a_{11} &amp; 0 &amp; 0\\ 
0 &amp; 0 &amp; a_{23}\\
0 &amp; a_{32} &amp; 0\\
\end{vmatrix} +
\begin{vmatrix}
0 &amp; a_{12} &amp; 0\\ 
a_{21} &amp; 0 &amp; 0\\
0 &amp; 0 &amp; a_{33}\\
\end{vmatrix} +
\begin{vmatrix}
0 &amp; a_{12} &amp; 0\\ 
0 &amp; 0 &amp; a_{23}\\
a_{31} &amp; 0 &amp; 0\\
\end{vmatrix} +
\begin{vmatrix}
0 &amp; 0 &amp; a_{13}\\ 
a_{21} &amp; 0 &amp; 0\\
0 &amp; a_{32} &amp; 0\\
\end{vmatrix} +
\begin{vmatrix}
0 &amp; 0 &amp; a_{13}\\ 
0 &amp; a_{22} &amp; 0\\
a_{31} &amp; 0 &amp; 0\\
\end{vmatrix}$
* let's have a closer look at each of them 
** $\begin{vmatrix}
a_{11} &amp; 0 &amp; 0\\ 
0 &amp; a_{22} &amp; 0\\
0 &amp; 0 &amp; a_{33}\\
\end{vmatrix} = a_{11}a_{22}a_{33}$, diagonal and nice
** $\begin{vmatrix}
a_{11} &amp; 0 &amp; 0\\ 
0 &amp; 0 &amp; a_{23}\\
0 &amp; a_{32} &amp; 0\\
\end{vmatrix} = - a_{11}a_{23}a_{32}$ - need 1 row exchange to transform it to $I$-like form 
** $\begin{vmatrix}
0 &amp; a_{12} &amp; 0\\ 
a_{21} &amp; 0 &amp; 0\\
0 &amp; 0 &amp; a_{33}\\
\end{vmatrix} = - a_{12}a_{21}a_{33}$ - also 1 flip away
** $\begin{vmatrix}
0 &amp; a_{12} &amp; 0\\ 
0 &amp; 0 &amp; a_{23}\\
a_{31} &amp; 0 &amp; 0\\
\end{vmatrix} = a_{12}a_{23}a_{31}$ - 2 exchanges, 
** $\begin{vmatrix}
0 &amp; 0 &amp; a_{13}\\ 
a_{21} &amp; 0 &amp; 0\\
0 &amp; a_{32} &amp; 0\\
\end{vmatrix} = a_{13}a_{21}a_{32}$ - 2 exchanges
** $\begin{vmatrix}
0 &amp; 0 &amp; a_{13}\\ 
0 &amp; a_{22} &amp; 0\\
a_{31} &amp; 0 &amp; 0\\
\end{vmatrix} = -a_{13}a_{22}a_{31}$ - 3 exchanges



So, the formula for $3 \times 3$:
* $\begin{vmatrix}
a_{11} &amp; a_{12} &amp; a_{13}\\ 
a_{21} &amp; a_{22} &amp; a_{23}\\
a_{31} &amp; a_{32} &amp; a_{33}\\
\end{vmatrix} = a_{11}a_{22}a_{33} + a_{12}a_{23}a_{31} +  a_{13}a_{21}a_{32} - a_{11}a_{23}a_{32} - a_{12}a_{21}a_{33} - a_{13}a_{22}a_{31}$
* or, schematically: 
* http://habrastorage.org/files/56e/046/165/56e046165e374bb99b0a48d859543370.png


=== $n \times n$ case: &quot;Big Formula&quot; ===
The big formula:
* we consider all $n!$ possible permutation matrices $P$ 
* why $n!$? we can choose an element from the row 1 in $n$ ways, an element from the row 2 in $n - 1$ ways, ..., the last - in one way
* $\text{det } A = \sum\limits_{\text{$n!$ permutations $P$}}  \text{det } P \cdot a_{1\alpha_1} a_{2\alpha_2} ... a_{n\alpha_n}$
* where $\boldsymbol \alpha = (\alpha_1, \ ... \ , \alpha_n)$ is a [[Permutation]] of $(1, \ ... \ , n)$



== The Pivot Formula ==
The easiest way is to use the properties 2, 5, 7 and 9:
* do the factorization $PA = LU$
* know that $\text{det } A = \text{det } P \cdot \text{det } U$
* if one of the pivots is 0, then $\text{det } A = 0$
* if $P$ is $\pm 1$, depending on the number of permutations, and $\text{det } U = \prod d_i$



== Cofactors ==
Cofactors give a way to break $n \times n$ determinant to $(n - 1) \times (n - 1)$ determinants


=== $3 \times 3$ Case: Intuition ===
Suppose $A$ is a $3 \times 3$ matrix 

* $\begin{vmatrix}
a_{11} &amp; a_{12} &amp; a_{13}\\ 
a_{21} &amp; a_{22} &amp; a_{23}\\
a_{31} &amp; a_{32} &amp; a_{33}\\
\end{vmatrix} = a_{11}a_{22}a_{33} + a_{12}a_{23}a_{31} +  a_{13}a_{21}a_{32} - a_{11}a_{23}a_{32} - a_{12}a_{21}a_{33} - a_{13}a_{22}a_{31}$
* let's group them
* $\text{det } A = a_{11} (a_{22}a_{33} - a_{23}a_{32}) + a_{12} (-1) (a_{21}a_{33} - a_{23} a_{33}) + a_{13} (a_{21}a_{32} - a_{22}a_{31})$
* note that now in parentheses we have determinants of smaller matrices!
** for $a_{11}$ we have $a_{22}a_{33} - a_{23}a_{32} = \begin{vmatrix}
a_{22} &amp; a_{23}\\
a_{32} &amp; a_{33}\\
\end{vmatrix}$
** for $a_{12}$ we have $- (a_{21}a_{33} - a_{23} a_{33}) = - \begin{vmatrix}
a_{21} &amp; a_{23}\\
a_{31} &amp; a_{33}\\
\end{vmatrix}$ (note the $-$ sign!)
** for $a_{13}$ we have $a_{21}a_{32} - a_{22}a_{31} = \begin{vmatrix}
a_{21} &amp; a_{22}\\
a_{31} &amp; a_{32}\\
\end{vmatrix}$
** these are co-factors of $a_{11}, a_{12}, a_{13}$ respectively
* so we can write this as 
** $\begin{vmatrix}
a_{11} &amp; a_{12} &amp; a_{13}\\ 
a_{21} &amp; a_{22} &amp; a_{23}\\
a_{31} &amp; a_{32} &amp; a_{33}\\
\end{vmatrix} = 
\begin{vmatrix}
a_{11} &amp; 0 &amp; 0\\ 
0 &amp; a_{22} &amp; a_{23}\\
0 &amp; a_{32} &amp; a_{33}\\
\end{vmatrix} -
\begin{vmatrix}
0 &amp; a_{12} &amp; 0\\ 
a_{21} &amp; 0 &amp; a_{23}\\
a_{31} &amp; 0 &amp; a_{33}\\
\end{vmatrix} +
\begin{vmatrix}
0 &amp; 0 &amp; a_{13}\\ 
a_{21} &amp; a_{22} &amp; 0\\
a_{31} &amp; a_{32} &amp; 0\\
\end{vmatrix}$


=== Cofactors ===
a ''cofactor'' of $a_{ij}$ is $C_{ij}$
* $C_{ij}$ is a determinant of a $n - 1$ matrix - it's a matrix $A$ with row $i$ and column $j$ removed
* note that we can have a minus sign before some of the cofactors
* we have $C_{ij}$ with $-$ if $i+j$ is odd, and $+$ if $i+j$ is even
* so for $3 \times 3$ matrix we take signs this way: $\begin{vmatrix}
+ &amp; - &amp; + \\ 
- &amp; + &amp; - \\
+ &amp; - &amp; + \\
\end{vmatrix}$

a ''minor'' of $a_{ij}$ is $M_{ij}$
* it's the same as cofactor, but always with the same sign


=== The Cofactor Formula ===
We can take co-factors along any row or column
* suppose we take it along row 1
* then the formula is $\text{det } A = a_{11} C_{11} + a_{12} C_{12} + \ ... \ + a_{1n} C_{1n}$



== Applications ==
What can we do with determinants?

=== [[Cramer's Rule]] ===
through the [[Cramer's Rule]]: 
* Find the [[Inverse Matrices|inverse]] and solve a [[System of Linear Equations]]

=== Volume ===
$\text{det } A$ = volume of a parallelepiped formed by vector-rows of $A$ 
* $A = \begin{bmatrix}
a_{11} &amp; a_{12} &amp; a_{13}\\ 
a_{21} &amp; a_{22} &amp; a_{23}\\
a_{31} &amp; a_{32} &amp; a_{33}\\
\end{bmatrix}$
* $\mathbf r_1 = \Big[a_{11} \ \  a_{12} \ \  a_{13} \Big]$
* $\mathbf r_2 = \Big[a_{21} \ \  a_{22} \ \  a_{23} \Big]$
* $\mathbf r_3 = \Big[a_{31} \ \  a_{32} \ \  a_{33} \Big]$


http://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/Determinant_parallelepiped.svg/285px-Determinant_parallelepiped.svg.png

$| \text{det } A|$ is the volume of the box formed by vectors $\mathbf r_1, \mathbf r_2, \mathbf r_3$ 

To check if this is indeed true, we need to verify that the volume obeys the 3 defining properties
* $A = I$ works, the volume is 1
* property 2: reversing two rows changes the sign (don't care), but the volume remains the same - true
* linearity:
** 3a. suppose we double one edge: the volume double
** 3b. see pictorially 
** http://habrastorage.org/files/43b/489/693/43b489693fac472ea3640dbbbc58644f.png


=== Area of Triangle ===
We know how to compute the area of a square 
* so we can compute the area of a triangle!
* let $A$ be $2 \times 2$ matrix, $A = \begin{bmatrix}
a_{11} &amp; a_{12} \\ 
a_{21} &amp; a_{22} \\
\end{bmatrix}$
* the area of a triangle that starts in origin is $\cfrac{1}{2} \text{det } A = \cfrac{1}{2} (a_{11} \, a_{22} - a_{12} \, a_{21}) $
* http://habrastorage.org/files/98a/35d/d61/98a35dd612914966865302c82cbd6524.png

What is it doesn't start in origin?
* http://habrastorage.org/files/c37/e3f/538/c37e3f53894b4f65a936714a1dfa8cf8.png
* then we calculate it by taking the following determinant:
* $\begin{vmatrix}
x_1 &amp; y_1 &amp; 1 \\ 
x_1 &amp; y_1 &amp; 1 \\
x_1 &amp; y_1 &amp; 1 \\
\end{vmatrix}$



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Strang, G. Introduction to linear algebra.
* Курош А.Г. Курс Высшей Алгебры


[[Category:Linear Algebra]]</text>
      <sha1>jp9lin1y74yzejpr1c4wrogo3vk0d68</sha1>
    </revision>
  </page>
  <page>
    <title>Determinant</title>
    <ns>0</ns>
    <id>534</id>
    <redirect title="Determinants" />
    <revision>
      <id>537</id>
      <timestamp>2014-12-30T21:38:02Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="26">#REDIRECT [[Determinants]]</text>
      <sha1>fc8qinw4gwlueopuch0xsthik4eoor8</sha1>
    </revision>
  </page>
  <page>
    <title>Cofactors</title>
    <ns>0</ns>
    <id>535</id>
    <redirect title="Determinants" />
    <revision>
      <id>538</id>
      <timestamp>2014-12-30T21:38:27Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="36">#REDIRECT [[Determinants#Cofactors]]</text>
      <sha1>98cyey17ik8wqwlftrhaz5rylq8mzac</sha1>
    </revision>
  </page>
  <page>
    <title>Data Mining</title>
    <ns>0</ns>
    <id>536</id>
    <revision>
      <id>539</id>
      <timestamp>2015-04-19T08:01:48Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3302">== Data Mining ==
Data mining - methods and algorithms to explore and analyze large volumes of data

Goal: to find patterns in data that are
* valid: with some certainty 
** e.g. everybody speaks English in Blois - not true
* novel: non obvious for a human
** everybody speaks French in Blois - obvious 
* useful: can do something with extracted knowledge
* understandable for humans


=== What is DM ===
What is NOT Data Mining:
* look up a phone number in a dictionary
* compute the number of customers who bought iPad in August
* can use [[SQL]] for that

What is Data Mining:
* What is the profile of the customers who bought iPad?
* Which customers will buy the new iPhone?
* Which customers will buy which products?


=== Origins ===
DM is a discipline with roots from
* [[Artificial Intelligence]]
* [[Statistics]]
* [[Machine Learning]]
* Pattern Recognition
* Cognitive Science
* [[Database|Database Systems]]


=== Main Focuses ===
DM is mostly used
* Customer Relationship Management (CRM)
** churn scoring - predict if a customer leaves to a competitor
** direct marketing - show ads only to whose who are interested
** credit scoring
** sales forecasting 
** etc
* website/search optimization
* supply chain optimization 
* many others


== Types of Data Mining ==
=== [[Rule Mining]] ===
[[Local Pattern Discovery]]
* [[Frequent Pattern Mining]]
** [[Apriori]] and [[Eclat]] algorithms for that 
* [[Association Rule Mining]]
* [[Constraint-Based Pattern Mining]]

Sequence Mining:
* [[Sequential Pattern Mining]]


=== [[Graph Mining]] ===
* Social Network Mining


=== Others ===
* [[Cluster Analysis]]
* Web Mining
* [[Text Mining]] - part of [[Natural Language Processing]] and [[Information Retrieval]]
* [[Stream Mining]]
* Tree Mining
* Preference Mining


== Data Mining Process ==
[[CRISP-DM]] (CRoss Industry Standard Process for Data Mining)
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/datamining-process.png


Business Understanding
* Define the success criteria 
* How to [[Data Integration|integrate]] the output with existing technologies?


Data Understanding
* Collect the data from [[Data Sources]]
* [[Summarizing Data]]: First Look at the Data
* [[Exploratory Data Analysis]]
* [[Univariate Analysis]] - to analyze how variable values behave in isolation
* [[Bivariate Analysis]] - to analyze how two variables interact


Data Preparation
* Need to prepare data so it can be processed by Models
* [[Data Cleaning]]
* [[Data Transformation]]
* [[Data Reduction]]


Data Modeling
* [[Multivariate Linear Regression]]
* [[Logistic Regression]]
* [[Decision Tree (Data Mining)]]
* [[SVM]]
* many others 


Evaluation
* [[Error Analysis]]
* [[Error Metrics]]
* [[Cross-Validation]]
* [[Learning Curves]]
* [[ROC Analysis]]



== Links ==
* http://en.wikipedia.org/wiki/Data_mining
* nice DM&amp;ML slides [http://www.evernote.com/shard/s344/sh/284d7df3-ef98-41d3-9de5-9cbc4ad4b800/77713ac8ce6e2d4b52e2b5c63e7fe2f5]
* Data Mining syllabus in Boston College [http://www.evernote.com/shard/s344/sh/da3d2ca3-390f-4a0b-b443-b1773c7c24d4/9ad3c26bd0ef9e637d8bdce2011db309]
* Data Mining map by Saed Sayad [http://www.saedsayad.com/data_mining_map.htm]


== Source ==
* [[Data Mining (UFRT)]]

[[Category:Data Mining]]
[[Category:Machine Learning]]</text>
      <sha1>6t69fx7k8t4o57qucgb6bn4q112msem</sha1>
    </revision>
  </page>
  <page>
    <title>Data Analysis</title>
    <ns>0</ns>
    <id>537</id>
    <revision>
      <id>540</id>
      <timestamp>2015-04-19T08:39:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3300">== Data Analysis ==
=== Data ===
Data - values of qualitative or quantitative variables belonging to a set of items 
* set of items - subjects 
* variables - measurements 


=== [[Data Preparation]] ===
Raw Data
* hard to use 
* complex format

Want to have Pre-Processed Data
* ready for analysis 
* each variable forms a column
* each observation forms a raw 
* each file stores about one kind of observation


== Types of Data Analysis ==
* Descriptive
* Exploratory
* Inferential
* Predictive
* Causal
* Mechanistic


=== [[Descriptive Analysis]] ===
* Goal: to describe a set of data 
* commonly applied to census data 


=== [[Exploratory Data Analysis]] ===
* Goal: Find relationships you didn't know about
* and ideas for the following studies 
* Exploratory analyses alone should not be used for generalizing/predicting


=== [[Inferential Statistics|Inferential Analysis]] ===
* use small data sample to say something about the bigger population


[[Predictive Analysis]]
* use data on some object to predict values for another object 


Casual Analysis 
* finds out what happens to one variable if another one changes 


Mechanistic Analysis 
* understand the exact changes in other variables 



== Structure of Data Analysis ==
Steps:
# Define the question (business/scientific)
#* Start with some general question
#* &quot;Can I automatically detect messages that are SPAM&quot;?
#* Make it concrete
#* &quot;Can I use quantitative characteristics of emails to classify them?&quot;
# Obtain the data
#* What data you can access? 
#* A lot of data can be got from [[Data Sources]] 
#* you also may buy or generate data
# [[Data Cleaning|Clean the data]] - so you can analyze it
#* Is the data you found good enough? 
#* Most often - not, so you'll have to change the data
#* may have to use [[ETL]]s for that and load the data into a [[Data Warehouse]]
# [[Exploratory Data Analysis]]
#* Playing with data in R
#* try different things: [[Plots]], [[Histograms]], etc
#* learn the main characteristics: distribution, mean, medium, outliers, etc
#* [[Univariate Analysis]], [[Bivariate Analysis]]
#* Summarizing the DAta
# Statistical prediction/modeling
#* To answer the question you asked 
#* Should be informed by the result of the previous phase
#* Methods may depend on the questions
#* Typically [[Data Mining]] and [[Machine Learning]] algorithms are used for this
#* Report all measures of uncertainty: number of mistakes you did on the [[Cross-Validation|test set]], etc
# Interpret results
#* What does it mean - in plain natural language
# Challenge results
#* What are potential failings?
#* Challenge all the steps
#* Question
#** was it right? could you have made it more specific/general?
#* Data Sources
#** was it right data? did you get the right samples? the right population?
#* Processing
#** correctly identified the variables?
#* Analysis
#** Did we pick the right model? Could the results be better with another model?
# Synthesize/write up results
#* In plain language - using the data to answer the question
#* should read like a story
# Create reproducible code
#* so you can share your analysis with other people



== Links ==
* http://projecttemplate.net/ -  a pre-organized set of files for data analysis


== Source ==
* [[Data Analysis (coursera)]]

[[Category:Data Analysis]]</text>
      <sha1>pwm9rzevnf6pgycri1c452qfgcien0o</sha1>
    </revision>
  </page>
  <page>
    <title>Descriptive Analysis</title>
    <ns>0</ns>
    <id>538</id>
    <revision>
      <id>541</id>
      <timestamp>2015-04-19T08:47:30Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1263">== Descriptive Analysis ==
Descriptive statistics - how to summarize data with numbers or plots 


=== Summaries ===
* Simple summaries - [[Summary Statistics]] 
* [[Exploratory Analysis]] - mostly visual analysis - simple-to-understand graphs.


== [[Univariate Analysis]] ==
Univariate analysis is describing the distribution of a single variable
* central tendency (e.g. the mean, median, and mode) 
* dispersion, e.g. 
** the range and quantiles of the data set
** measures of spread variance and standard deviation
* the shape of the distribution 
** as skewness and kurtosis. 
** graphical or tabular format, including histograms and stem-and-leaf display.


== [[Bivariate Analysis]] ==
Descriptive statistics may be used to describe the relationship between pairs of variables

In this case, descriptive statistics include:
* Cross-Tabulations and Contingency Tables
* Graphical representation via [[Scatter Plot]]s and other [[Plots]]
* Quantitative measures of dependence
* Descriptions of conditional distributions



== Sources ==
* http://en.wikipedia.org/wiki/Descriptive_statistics
* [http://www.pitt.edu/~super1/lecture/lec0421/index.htm Descriptive Statistics lecture]
* [[Data Mining (UFRT)]]

[[Category:Data Mining]]
[[Category:Data Analysis]]</text>
      <sha1>0c0k5yyhjc40uhd5i6lxggi6eoxo8g3</sha1>
    </revision>
  </page>
  <page>
    <title>Exact Binomial Proportion Tests</title>
    <ns>0</ns>
    <id>539</id>
    <revision>
      <id>542</id>
      <timestamp>2015-04-19T08:49:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1869">== Exact Binomial Test ==
This is a [[Statistical Test]] for proportions that uses the [[Binomial Distribution]] as the null (sampling) distribution. 

It doesn't use the [[Binomial Distribution#Normal Approximation|Normal Approximation]]
* because sometimes it's possible to use the Binomial model directly 
* or because it's not possible to use the Normal Model: some conditions are not met


=== Binomial Model ===
Recall the formula:
* $P(\text{success}) = { n \choose k } p^k (1 - p)^{n - k}$
* this is the null distribution of our test 


Test
* the tail area of the null distribution:
** add up the probabilities (using the formula) for all $k$ that support the alternative hypothesis $H_A$
* one-sided test - use single tail area
* two-sided - compute single tail and double it



== Examples ==
=== Example 1: Medical Consultant (One-Sample) ===
* medical consultant helps patients 
* he claims that with his help the ratio of complications is lower than usually 
** (i.e. lower than 0.10)
* is it true?


We want to test a hypothesis: 
* $H_0: p_A = 0.10$ - ratio of complications without a specialist 
* $H_A: p_A &lt; 0.10$ - specialist helps, the complications ratio is lower than usual 

Observed data:
* 3 complications in 62 cases
* $\hat{p} = 0.048$ 
* is it only due to chance? 


Normal Model
* the Success-Failure condition is not met: $p_A \cdot 62 = 0.10 \approx 6.2 &lt; 10$
** under $H_0$ we'd expect to see only 6.2 complications 
* thus cannot use [[Binomial Distribution#Normal Approximation|Normal Approximation]] and perform a [[Binomial Proportion Tests|Binomial Proportion Test]]


Apply the Binomial Model:
* $p\text{-val} = \sum_{j = 0}^3  { n \choose j } p^j (1 - p)^{n - j} = 0.0015 + 0.01 + 0.034 + 0.0355 = 0.121$
* we don't reject the $H_0$ at $\alpha = 0.05$

check! sim got 0.04


[[Category:Statistics]]
[[Category:Statistical Tests]]</text>
      <sha1>0rt0w8fuvid22ziq7wq7b1g3qmj7031</sha1>
    </revision>
  </page>
  <page>
    <title>Exploratory Data Analysis</title>
    <ns>0</ns>
    <id>540</id>
    <revision>
      <id>543</id>
      <timestamp>2015-04-19T08:50:05Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="902">== Exploratory Data Analysis ==
This is a stage in [[Data Analysis]]/[[Data Mining]]
* to get initial understating of the data source
* e.g. understand the [[Distribution]] of the values in this data
* typically using visual tools: [[Plots]] and graph


However other things can also be done at this stage
* [[Summary Statistics]]
* [[Univariate Analysis]] - to analyze how variable values behave in isolation
* [[Bivariate Analysis]] - to analyze how two variables interact
** [[Correlation]]
** [[Chi-Square Test of Independence]] to see if two variables are dependent
* also simple forms of [[Cluster Analysis]] to spot patterns at earlier stages

== [[Plots]] ==
Main plots used at this stage
* [[Bar Chart]]s
* [[Box Plot]]s
* [[Histogram]]s
* [[Piechart]]s
* [[Density Plot]]s
* [[Scatter Plot]]s


== Sources ==
* [[Data Analysis (coursera)]]
* [[Data Mining (UFRT)]]

[[Category:Data Analysis]]</text>
      <sha1>fowvlg0akmmtw2cma1j90li6ajuu50i</sha1>
    </revision>
  </page>
  <page>
    <title>Inferential Statistics</title>
    <ns>0</ns>
    <id>541</id>
    <revision>
      <id>544</id>
      <timestamp>2015-04-19T08:51:35Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1154">== Inferential Statistics ==
It's a part of [[Statistics]] that, based on a small [[Sampling|sample]] infers predictions about the population
* [[Descriptive Statistics]] is another part that just describes samples and doesn't infer anything about the general population


&quot;Statistical Inference&quot; is concerned mainly with assessing the quality of parameter estimates 
* using some methods we estimate parameters and build statistical models from the sample 
* and we want to know how good the estimates/models are


=== Variability in Estimates ===
* We estimate the parameters based on sampled data 
* So with different samples (from the same population) we get different estimates of the same parameter
* A one-number estimate of some population parameter is called [[Point Estimate]]
* The distribution of this parameter estimate is called [[Sampling Distribution]] 
* and the measure of variability is called [[Standard Error]]

Main tools
* [[Confidence Intervals]]
* [[Hypothesis Testing]]


== Sources ==
* http://en.wikipedia.org/wiki/Statistical_inference
* [[OpenIntro Statistics (book)]]

[[Category:Statistics]]
[[Category:Statistical Tests]]</text>
      <sha1>7tywy2hm5555jsdq38xn4f4s2v5g6ja</sha1>
    </revision>
  </page>
  <page>
    <title>Lattice</title>
    <ns>0</ns>
    <id>542</id>
    <revision>
      <id>545</id>
      <timestamp>2015-04-19T08:52:29Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3528">== Lattice ==
a Lattice is a partially ordered set in which every two elements have 
* a supremum (also called a least upper bound or join) and 
* an infimum (also called a greatest lower bound or meet). 


== Hasse Diagram ==
Hasse Diagram [http://en.wikipedia.org/wiki/Hasse_diagram]
* a way of representing finite partially ordered sets 


Layer approach
* page 33 - onwards [http://phoenix.inf.upol.cz/~outrata/download/texts/LatDrawing-slides.pdf] - software for drawing 


=== Drawing Powerset with [[Dot]] ===
Generating it in python:
&lt;pre&gt;
from itertools import chain,combinations,product
from collections import defaultdict

# from https://docs.python.org/2/library/itertools.html#recipes
def powerset(iterable):
    s = list(iterable)
    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))

st = 'abcdef'
ps = {''.join(x): set(x) for x in powerset(st)}


dep = defaultdict(list)
for (s1, s2) in product(ps, ps):
    if len(s1) + 1 == len(s2) and ps[s1].issubset(ps[s2]):
        dep[s1].append(s2)

def join_quoted(it): return ','.join(['&quot;%s&quot;' % s for s in it])

for d in sorted(dep, key=len):
    print ' ', '&quot;%s&quot;' % d, '-&gt;', join_quoted(dep[d])
&lt;/pre&gt;


Drawing it with dot:
&lt;pre&gt;
digraph A {
  node[shape=none, fontsize=10, width=0.3, fixedsize=true]
  edge[arrowsize=.4,color=grey]
  nodesep=0.05

  &quot;{}&quot; -&gt; &quot;a&quot;,&quot;c&quot;,&quot;b&quot;,&quot;e&quot;,&quot;d&quot;,&quot;f&quot;
  &quot;c&quot; -&gt; &quot;ac&quot;,&quot;cf&quot;,&quot;ce&quot;,&quot;cd&quot;,&quot;bc&quot;
  &quot;b&quot; -&gt; &quot;ab&quot;,&quot;bd&quot;,&quot;be&quot;,&quot;bf&quot;,&quot;bc&quot;
  &quot;a&quot; -&gt; &quot;ac&quot;,&quot;ab&quot;,&quot;ae&quot;,&quot;ad&quot;,&quot;af&quot;
  &quot;e&quot; -&gt; &quot;ae&quot;,&quot;ef&quot;,&quot;ce&quot;,&quot;be&quot;,&quot;de&quot;
  &quot;d&quot; -&gt; &quot;ad&quot;,&quot;cd&quot;,&quot;bd&quot;,&quot;df&quot;,&quot;de&quot;
  &quot;f&quot; -&gt; &quot;af&quot;,&quot;ef&quot;,&quot;cf&quot;,&quot;bf&quot;,&quot;df&quot;
  &quot;ac&quot; -&gt; &quot;abc&quot;,&quot;acf&quot;,&quot;ace&quot;,&quot;acd&quot;
  &quot;ab&quot; -&gt; &quot;abc&quot;,&quot;abd&quot;,&quot;abe&quot;,&quot;abf&quot;
  &quot;ae&quot; -&gt; &quot;abe&quot;,&quot;ade&quot;,&quot;ace&quot;,&quot;aef&quot;
  &quot;ad&quot; -&gt; &quot;abd&quot;,&quot;adf&quot;,&quot;ade&quot;,&quot;acd&quot;
  &quot;af&quot; -&gt; &quot;abf&quot;,&quot;adf&quot;,&quot;acf&quot;,&quot;aef&quot;
  &quot;ef&quot; -&gt; &quot;cef&quot;,&quot;bef&quot;,&quot;aef&quot;,&quot;def&quot;
  &quot;cf&quot; -&gt; &quot;cef&quot;,&quot;acf&quot;,&quot;cdf&quot;,&quot;bcf&quot;
  &quot;ce&quot; -&gt; &quot;cde&quot;,&quot;cef&quot;,&quot;ace&quot;,&quot;bce&quot;
  &quot;cd&quot; -&gt; &quot;cde&quot;,&quot;cdf&quot;,&quot;bcd&quot;,&quot;acd&quot;
  &quot;bd&quot; -&gt; &quot;bde&quot;,&quot;abd&quot;,&quot;bdf&quot;,&quot;bcd&quot;
  &quot;bf&quot; -&gt; &quot;abf&quot;,&quot;bdf&quot;,&quot;bcf&quot;,&quot;bef&quot;
  &quot;de&quot; -&gt; &quot;cde&quot;,&quot;bde&quot;,&quot;ade&quot;,&quot;def&quot;
  &quot;bc&quot; -&gt; &quot;abc&quot;,&quot;bcd&quot;,&quot;bce&quot;,&quot;bcf&quot;
  &quot;df&quot; -&gt; &quot;adf&quot;,&quot;bdf&quot;,&quot;cdf&quot;,&quot;def&quot;
  &quot;be&quot; -&gt; &quot;bde&quot;,&quot;abe&quot;,&quot;bce&quot;,&quot;bef&quot;
  &quot;cde&quot; -&gt; &quot;acde&quot;,&quot;bcde&quot;,&quot;cdef&quot;
  &quot;bef&quot; -&gt; &quot;abef&quot;,&quot;bdef&quot;,&quot;bcef&quot;
  &quot;bde&quot; -&gt; &quot;bdef&quot;,&quot;abde&quot;,&quot;bcde&quot;
  &quot;abc&quot; -&gt; &quot;abcd&quot;,&quot;abce&quot;,&quot;abcf&quot;
  &quot;abd&quot; -&gt; &quot;abcd&quot;,&quot;abde&quot;,&quot;abdf&quot;
  &quot;abe&quot; -&gt; &quot;abef&quot;,&quot;abde&quot;,&quot;abce&quot;
  &quot;abf&quot; -&gt; &quot;abef&quot;,&quot;abdf&quot;,&quot;abcf&quot;
  &quot;adf&quot; -&gt; &quot;acdf&quot;,&quot;abdf&quot;,&quot;adef&quot;
  &quot;ade&quot; -&gt; &quot;acde&quot;,&quot;abde&quot;,&quot;adef&quot;
  &quot;cef&quot; -&gt; &quot;acef&quot;,&quot;cdef&quot;,&quot;bcef&quot;
  &quot;bdf&quot; -&gt; &quot;bcdf&quot;,&quot;bdef&quot;,&quot;abdf&quot;
  &quot;cdf&quot; -&gt; &quot;bcdf&quot;,&quot;acdf&quot;,&quot;cdef&quot;
  &quot;acf&quot; -&gt; &quot;acdf&quot;,&quot;acef&quot;,&quot;abcf&quot;
  &quot;ace&quot; -&gt; &quot;acde&quot;,&quot;acef&quot;,&quot;abce&quot;
  &quot;bcd&quot; -&gt; &quot;bcdf&quot;,&quot;abcd&quot;,&quot;bcde&quot;
  &quot;bce&quot; -&gt; &quot;bcde&quot;,&quot;bcef&quot;,&quot;abce&quot;
  &quot;bcf&quot; -&gt; &quot;bcdf&quot;,&quot;bcef&quot;,&quot;abcf&quot;
  &quot;acd&quot; -&gt; &quot;acde&quot;,&quot;acdf&quot;,&quot;abcd&quot;
  &quot;aef&quot; -&gt; &quot;abef&quot;,&quot;acef&quot;,&quot;adef&quot;
  &quot;def&quot; -&gt; &quot;bdef&quot;,&quot;cdef&quot;,&quot;adef&quot;
  &quot;abef&quot; -&gt; &quot;abdef&quot;,&quot;abcef&quot;
  &quot;bdef&quot; -&gt; &quot;abdef&quot;,&quot;bcdef&quot;
  &quot;acde&quot; -&gt; &quot;abcde&quot;,&quot;acdef&quot;
  &quot;acdf&quot; -&gt; &quot;abcdf&quot;,&quot;acdef&quot;
  &quot;acef&quot; -&gt; &quot;abcef&quot;,&quot;acdef&quot;
  &quot;abcd&quot; -&gt; &quot;abcde&quot;,&quot;abcdf&quot;
  &quot;abde&quot; -&gt; &quot;abcde&quot;,&quot;abdef&quot;
  &quot;abdf&quot; -&gt; &quot;abdef&quot;,&quot;abcdf&quot;
  &quot;bcef&quot; -&gt; &quot;abcef&quot;,&quot;bcdef&quot;
  &quot;bcde&quot; -&gt; &quot;abcde&quot;,&quot;bcdef&quot;
  &quot;bcdf&quot; -&gt; &quot;bcdef&quot;,&quot;abcdf&quot;
  &quot;cdef&quot; -&gt; &quot;bcdef&quot;,&quot;acdef&quot;
  &quot;abce&quot; -&gt; &quot;abcde&quot;,&quot;abcef&quot;
  &quot;adef&quot; -&gt; &quot;abdef&quot;,&quot;acdef&quot;
  &quot;abcf&quot; -&gt; &quot;abcef&quot;,&quot;abcdf&quot;
  &quot;abdef&quot; -&gt; &quot;abcdef&quot;
  &quot;abcef&quot; -&gt; &quot;abcdef&quot;
  &quot;bcdef&quot; -&gt; &quot;abcdef&quot;
  &quot;abcde&quot; -&gt; &quot;abcdef&quot;
  &quot;abcdf&quot; -&gt; &quot;abcdef&quot;
  &quot;acdef&quot; -&gt; &quot;abcdef&quot;
}
&lt;/pre&gt;

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/ufrt/kddm/language-lattice.png


== Sources ==
* http://en.wikipedia.org/wiki/Lattice_(order)
* http://en.wikipedia.org/wiki/Hasse_diagram

[[Category:Dot]]
[[Category:Python]]</text>
      <sha1>jrj51nhjxy09tnxwqoccoejonvsy9ff</sha1>
    </revision>
  </page>
  <page>
    <title>Statistical Power</title>
    <ns>0</ns>
    <id>543</id>
    <revision>
      <id>546</id>
      <timestamp>2015-04-19T10:57:41Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3744">== Statistical Power ==
How to detect a false $H_0$? 
* ''The power of a test'' is the probability of making a correct decision (by rejecting the $H_0$) when the $H_0$ is false. 
* The higher the power, the more sensitive the test in detecting the false hypothesis.

How to have higher power? 
* the further the alternative value is away from the $H_0$, the higher the power
* A higher level of significance $\alpha$ gives higher power
* less variability - less power
* the larger the sample size - the greater the power

To determine the sample size needed for a study set $\alpha$ and the desired power, decide of the $H_A$, estimate $\sigma$ and calculate the sample size




=== Power Of Test ===
Consider this test:
* $H_0$: average blood pressure of employers is the same as national average,
** i.e. $H_0: \mu = 130$
* $H_A$: it's different
** $H_A: \mu \ne 130$

Suppose that $H_A$ is actually true
* what is our chance to make [[Type II Errors]]? - i.e. fail to reject $H_0$ when we should reject it 


Suppose that the actual average is 132: i.e. $\mu = 132$
we sample 100 individuals 
then the true sampling distribution of $\bar{x}$ is $N(132, 2.5)$
since $\text{SE} = \cfrac{25}{\sqrt{100}}$
what is the probability of successfully rejecting $H_0$?

We can divide it onto two probability questions:

* what are possible values of $\bar{x}$ sufficient to reject $H_0$? (under $H_0$!)
* use this hypothetical [[Sampling Distribution]] to find the probability of observing such values of $\bar{x}$ (from the 1st step)


Step 1
The null distribution is $N(130, 2.5)$
the 2.5% tails are those with $Z = \pm 1.96$

$-1.96 = z_1 = \cfrac{x_1 - 130}{2.5}
$x_1 = 125.1$


$+1.96 = z_2 = \cfrac{x_2 - 130}{2.5}
$x_2 = 134.9$

http://habrastorage.org/files/a3a/866/c33/a3a866c339cb4a35b54543a63b0ac593.png


Step 2

Now we compute the probability of rejecting $H_0$ if $\bar{x}$ actually came from $N(132, 2.5)$

$z_\text{left} = \cfrac{125.1 - 132}{2.5} = -2.76$
area: 0.003
$z_\text{right} = \cfrac{134.9 - 132}{2.5} = 1.16$
area: 0.123

http://habrastorage.org/files/aff/5d0/286/aff5d02862104e998bcab1248b983de3.png

so the probability of rejecting $H_0$ if the true mean is 132 is 
0.004 + 0.123 = 0.126

This is the power of a test 
the probability of rejecting the $H_0$


The power varies depending on what we suppose the truth is 

If the power of a test is 0.979, what's the type 2 error rate? 
Type 2 error rate is the probability of failing to reject $H_0$ 
so type 2 error rate is 1 - 0.979 = 0.021


&lt;pre&gt;
x = seq(120, 140, 0.1)
null.mu = 130; se = 2.5
null.y = dnorm(x, mean=null.mu, sd=se)

plot(x, null.y, type='l', lty=2, bty='n',
     ylab='Probability')

x1 = 125.1; x2 = 134.9
abline(v=c(null.mu, x1, x2), lty=2)


real.mu = 132
real.y = dnorm(x, mean=real.mu, sd=se)

lines(x, real.y, col='red', lwd=2)
abline(v=real.mu, col='red', lwd=2)

x1.left = max(which(x &lt;= x1))
polygon(x=x[c(1, 1:x1.left, x1.left)],
        y=c(0, real.y[1:x1.left], 0), 
        col=adjustcolor('red', 0.5), border=NA)

x2.left = min(which(x &gt;= x2))
x2.right = length(x)
polygon(x=x[c(x2.left, x2.left:x2.right, x2.right)],
        y=c(0, real.y[x2.left:x2.right], 0), 
        col=adjustcolor('red', 0.5), border=NA)
&lt;/pre&gt;


== Power Analysis ==
{{ TODO | what's that? }}
* e.g. see here [http://stats.stackexchange.com/questions/108186]
* http://www.statmethods.net/stats/power.html - in R
* http://www.marketingdistillery.com/2014/08/10/multiple-abn-tests-in-marketing-with-anova-and-r/ - sample size 


== Visualization ==
* http://homepage.stat.uiowa.edu/~mbognar/applets/power.html


== Sources ==
* [[OpenIntro Statistics (book)]]
* [[Statistics: Making Sense of Data (coursera)]]

[[Category:Statistics]]
[[Category:Statistical Tests]]</text>
      <sha1>22gnm8iypsh7jnykz9jmv0skj2v8r3a</sha1>
    </revision>
  </page>
  <page>
    <title>Simulation For Proportions</title>
    <ns>0</ns>
    <id>544</id>
    <revision>
      <id>547</id>
      <timestamp>2015-04-19T10:59:48Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4033">== Simulation For Proportions ==
Sometimes [[Statistical Inference]] can be done without applying theoretical models, but instead with using brute force: generating the data ourselves.


Consider Proportions test 
* there are a set of assumptions that have to be met to use the [[Binomial Distribution#Normal Approximation|Normal Approximation]]
* what if one of them is not met, e.g. Success-Failure condition?
* use [[Exact Binomial Proportion Tests]] - apply the Binomial Model directly
* or simulate draws from the binomial model and obtain the [[Sampling Distribution]] (or the null distribution)




== One-Sample Test ==
It's the same as One-Sample test for the normal approximation models:
* we have a sample and want to check if the true proportion parameter agree with some hypothetical parameter $p_0$
* and then we want to check if the data we observed align with this hypothesis

Test
* $H_0: p = p_0$
* $H_A: p \ne p_0$ or $H_A: p &lt; p_0$ or * $H_A: p &gt; p_0$ 
* $p$ - the true proportion, $p_0$ - the null value 


But instead of using some theoretical model, 
* we ourselves generate the null distribution 
* and then see how unusual the observed value is w.r.t. the generated null distr.


=== Example ===
Consider the following example: 
* medical consultant helps patients 
* he claims that with his help the ratio of complications is lower than usually 
** (i.e. lower than 0.10)
* is it true?


We want to test a hypothesis: 
* $H_0: p_A = 0.10$ - ratio of complications without a specialist 
* $H_A: p_A &lt; 0.10$ - specialist helps, the complications ratio is lower than usual 
* note that we can't really check the claim because we have [[Observational Studies]] - to really check the claim we need to conduct a [[Statistical Experiment]]

Observed data:
* 3 complications in 62 cases
* $\hat{p} = 0.048$ 
* is it only due to chance? 


Normal Model
* the Success-Failure condition is not met: $p_A \cdot 62 = 0.10 \approx 6.2 &lt; 10$
** under $H_0$ we'd expect to see only 6.2 complications 
* thus cannot use [[Binomial Distribution#Normal Approximation|Normal Approximation]] and perform a [[Binomial Proportion Tests|Binomial Proportion Test]]


What we can do? 
* There is still a way to evaluate the $p$-value for this $p_A = 0.10$ - via simulations
* Simulate many draws from the population and build a Sampling Distribution (under $H_0$)
* then compute the probability of observing such  $\hat{p}$ in this distribution


Test
* Assume that the help of the specialist gives nothing
* i.e. 10% of cases will still have complications 
* under this assumptions we try to simulate 62 clients 


Simulation
* repeat many times (e.g. 5-10k) to build a [[Sampling Distribution]]
** draw a sample from the [[Binomial Distribution]] with $p=0.10$ and $n=62$
** calculate $\hat{p}_\text{sim}$ from this sample
* draw a histogram 
* and shade bars that support the $H_A$ - ones with $hat{p}_\text{sim} &lt; 0.048$
* the shaded area represents the $p$-value - the probability of observing such small $\hat{p}$ only due to chance 



This is the histogram of the Sampling Distribution we obtained:
* http://habrastorage.org/files/3d9/618/2be/3d96182be8a746c29217bee8274b6c33.png


From 10k draws 487 turned out to be below $\hat{p}$
* which means $p$-value is $487/10000 = 0.0487 &lt; 0.05$
* so we reject $H_0$ in favor of $H_A$ and conclude that there's indeed some relation between the participation of the consultant and the complications ratio


R code:

&lt;pre&gt;
n = 62
p = 0.10
m = 10000

set.seed(31313)
samp.dist = rbinom(n=m, size=n, prob=p) / n

p.hat = 0.048
sum(samp.dist &lt;= p.hat) 
p.val = sum(samp.dist &lt;= p.hat) / length(samp.dist)
p.val

ac = cut(samp.dist, breaks=18)
means = tapply(samp.dist, ac, mean)
levels(ac) = round(means, digits=3)

tbl = table(ac) / length(samp.dist)
tbl
cl = rep('grey', length(tbl))
cl[1:4] = 'black'

barplot(tbl, col=cl, las=2)
&lt;/pre&gt;



== Sources ==
* [[OpenIntro Statistics (book)]]


[[Category:Simulations]]
[[Category:Statistics]]
[[Category:Statistical Tests]]
[[Category:R]]</text>
      <sha1>jk2anjk9vxymtwhknwlyhoxazknx9zv</sha1>
    </revision>
  </page>
  <page>
    <title>Statistical Simulation</title>
    <ns>0</ns>
    <id>545</id>
    <revision>
      <id>548</id>
      <timestamp>2015-04-19T11:03:39Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="817">{{stub}}

== Statistical Simulation ==
Sometimes it's not possible to use classical configurations to make inferences about things, e.g. our sample size is small 

when the traditional methods don't work, 
but the know the truth about the word and can control it though computerized stimulations 

When (Nearly) Normal models don't work

Sometimes [[Statistical Inference]] can be done without applying theoretical models, but instead with using brute force: generating the data ourselves.




Links:
* http://stats.stackexchange.com/questions/22293/explanation-of-statistical-simulation
* http://stats.stackexchange.com/questions/38593/using-computer-simulations-to-better-understand-statistical-concepts-at-the-grad


== Sources ==
* [[OpenIntro Statistics (book)]]

[[Category:Simulations]]
[[Category:Statistics]]</text>
      <sha1>r0gelma5tup0w2vbqmxm0g9cqys0ioe</sha1>
    </revision>
  </page>
  <page>
    <title>Chi-Squared Distribution</title>
    <ns>0</ns>
    <id>546</id>
    <revision>
      <id>549</id>
      <timestamp>2015-04-19T11:05:25Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="609">{{stub}}

== Chi-Squared Distribution ==
* always positive 
* typically right-skewed 
* one param: $\text{df}$

http://habrastorage.org/files/936/3c9/506/9363c9506c8f4953973be84906eb1e6a.png


* when df becomes larger, the center moves, i.e. the mean value grows as well
* mean = df
* variability increases as df increases 
* shape becomes less skewed, more symmetric 
* for Chi-Squared tests typically need only upper-tail values


Visualization 
* http://homepage.stat.uiowa.edu/~mbognar/applets/chisq.html

== Sources ==
* [[OpenIntro Statistics (book)]]

[[Category:Statistics]]
[[Category:Distributions]]</text>
      <sha1>5misgabr9zrzlwiipvf7dc3t111pmdx</sha1>
    </revision>
  </page>
  <page>
    <title>Cramer's Coefficient</title>
    <ns>0</ns>
    <id>547</id>
    <revision>
      <id>550</id>
      <timestamp>2015-04-19T11:11:49Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2656">{{draft}}

== Cramer's Coefficient ==
Note about [[Chi-Squared Test of Independence|$\chi^2$ Test of Independence]]:
* when the size of a data set increases, the gap between observed and expected values also increases
* even if the distribution remains unchanged
* thus we reject the independence hypothesis as the size grows 
* Crammer's Coefficient provides a solution for that


=== Definition ===
The Cramer's coefficient $v$
* $V = \sqrt{ \cfrac{\chi^2}{\chi^2_\text{max} } }$
* with $\chi^2_\text{max} = N \times ( \min(N, P) - 1 )$ where
** $N$ is the number of tuples and $P$ the number of attributes 
* $V \in [0, 1]$
* 0 - maximal independence, and 1 - maximal correlation


== Example ==
Consider the same example as for [[chi-square Test of Independence|$\chi^2$ Test]]

&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;

{| class=&quot;wikitable&quot;
|+ Small Dataset
! Male || Female || Total 
|-
! Blois 
| 55 || 45 || 100 
|-
! Tours 
| 20 || 30 || 50 
|-
| Total || 75 || 75 || 150 
|}

&lt;/td&gt;
&lt;td&gt;

{| class=&quot;wikitable&quot;
|+ Bigger Dataset 
! Male || Female || Total 
|-
! Blois 
| 550 || 450 || 1000 
|-
! Tours 
| 200 || 300 || 500 
|-
| Total || 750 || 750 || 1500 
|}

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;


$V = \sqrt{ 3 / 150 } = \sqrt{ 30 / 1500 } \approx 0.14 $


== [[R]] ==
{{ TODO | Expand it}}

&lt;pre&gt;
cv.test = function(x,y) {
  CV = sqrt(chisq.test(x, y, correct=FALSE)$statistic /
    (length(x) * (min(length(unique(x)),length(unique(y))) - 1)))
  print.noquote(&quot;Cramér V / Phi:&quot;)
  return(as.numeric(CV))
}
&lt;/pre&gt;

So we can get Cramer's V as

&lt;pre&gt;
helpdata = read.csv(&quot;http://www.math.smith.edu/r/data/help.csv&quot;)
with(helpdata, cv.test(female, homeless)
&lt;/pre&gt;

or 

&lt;pre&gt;cv.test &lt;- function(x) {
  CV &lt;- sqrt(chisq.test(x, correct=FALSE)$statistic / (sum(x) * min(dim(x) - 1 )))

  ### The result of the Pearson chi-square (without the Yates correction) is divided by the sum of table cells and...
  ### ...multiplied by the smalles number of (row or column) cells minus 1.
  ### The $statistic sends the correct value (the X^2 only) into the sqrt function

  print.noquote(&quot;Cramér V / Phi:&quot;)
  return(as.numeric(CV))
}
&lt;/pre&gt;


== Links ==
* http://en.wikipedia.org/wiki/Phi_coefficient
* http://sas-and-r.blogspot.fr/2011/06/example-839-calculating-cramers-v.html
* http://home.hib.no/ansatte/gbj/cramer_v.htm
* http://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V
* !!! http://stats.stackexchange.com/questions/105795/understanding-chi2-and-cram%C3%A9rs-v-results/105827#105827


== Sources ==
* [[Data Mining (UFRT)]]
* http://en.wikipedia.org/wiki/Analysis_of_variance

[[Category:Correlation]]
[[Category:Statistics]]
[[Category:Statistical Tests]]
[[Category:Data Analysis]]</text>
      <sha1>i21k2ybqz0vk16mwhmqckqgoh3y62if</sha1>
    </revision>
  </page>
  <page>
    <title>Meta Learning</title>
    <ns>0</ns>
    <id>548</id>
    <revision>
      <id>551</id>
      <timestamp>2015-04-19T11:15:54Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1316">== Meta Learning ==
In Machine Learning there are so-called ''meta''-tasks: 
* [[Model Selection]]
* [[Parameter Tuning]]
* Estimating model's ability to generalize to new data


Meta Learning is a set of Machine Learning techniques for addressing these tasks. The most popular are
* [[Cross-Validation]] for estimating the prediction quality of models 
* [[Ensemble Learning]] for creating stronger models by combining several weaker ones

These techniques generate samples from the data and then train and evaluate models based on these samples

They all have two common steps:
* samples are generated from the input data
* Machine Learning models are trained on these samples 


== Scalable Meta Learning ==
See the paper by S. Schelter: 
* Schelter, Sebastian, et al. &quot;Efficient Sample Generation for Scalable Meta Learning.&quot; ([http://ssc.io/wp-content/uploads/2014/11/ICDE15_research_150.pdf pdf]


== Links ==
* http://en.wikipedia.org/wiki/Meta_learning_(computer_science)
* http://www.scholarpedia.org/article/Metalearning for thorough treatment 


== Sources ==
* Schelter, Sebastian, et al. &quot;Efficient Sample Generation for Scalable Meta Learning.&quot; ([http://ssc.io/wp-content/uploads/2014/11/ICDE15_research_150.pdf pdf] [http://www.icde2015.kr/media/posters/150.pdf poster])

[[Category:Machine Learning]]</text>
      <sha1>pzbpfbhgruiaf5a1r9rbedwzmiur3rr</sha1>
    </revision>
  </page>
  <page>
    <title>Latent Semantic Analysis</title>
    <ns>0</ns>
    <id>549</id>
    <revision>
      <id>552</id>
      <timestamp>2015-07-04T19:04:20Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15651">== Latent Semantic Analysis ==
Latent Semantic Analysis (LSA) is an [[NLP]] method: 
* mathematical/statistical method for modeling the meaning of words/passages by analysis of text via extracting and inferring relations of expected contextual usage of words in texts 
* idea: words that are used in the same contexts tend to have the same meaning



=== Problems with Text ===
Issues with text data:
* synonymy: many ways to refer to the same object 
* synonymy tends to decrease [[Precision and Recall|recall]]
* polysemy: many words have more than one distinct meaning (e.g. &quot;chip&quot;, &quot;trunk&quot;)
* polysemy tends to decrease [[Precision and Recall|precision]]


Overcoming Synonymy:
* term extraction, thesauri construction

Overcoming Polysemy: 
* using controlled vocabulary
* or use [[Word Sense Disambiguation]]


=== WEIRD ===
WEIRD (Koll1979) is the first IR system that dealt with these problems automatically, not with some controlled vocabulary
* the goal of WIERD: to go from term matching to concept matching
* can use statistical analysis to empirically find relations among terms 
* so it analyzed term-to-term co-occurrence matrix 
* can use [[Factor Analysis]] to identify the right basis for terms s.t. there's little or no loss of information
* in WEIRD only 7 dimensions were used - based on 7 completely non-overlapping documents found in the collection


The space built by WEIRD acts like an implicit thesaurus 
* synonyms will map to the same concept 


=== LSA ===
LSA/LSI solves these problems as well
* it goes further than WIERD: it uses all documents to build a space 
* it does that by applying SVD as a [[Dimensionality Reduction]] - which reveals latent structure and &quot;denoises&quot; the data
* Similarity estimates derived by LSA are not just frequencies or co-occurrences counts: it can infer deeper relations: hence &quot;Latent&quot; and &quot;Semantic&quot; 
* so LSA learns the latent semantic structure of the vocabulary


=== LSI ===
Latent Semantic Analysis (LSA) $\approx$ Latent Semantic Indexing (LSI) 
* LSI is the alias of LSA for [[Information Retrieval]]
* indexing and retrieval method that uses [[Singular Value Decomposition|SVD]] to identify patterns in relations between terms and concepts
* instead of literal match between query and documents (e.g. using cosine in the traditional vector space morels), convert both into the Semantic Space and calculate the cosine there






== LSA Steps ==
3 major steps (by Evangelopoulos2012)

* Prepare documents 
* Construct [[Vector Space Models|Term-Document matrix]] $D$
* Reduce dimensionality of $D$ via [[SVD]]


=== Document preparation ===
* [[Feature Selection|Term selection]]: exclude [[Stop Words]] and low and high frequency terms
* [[Stemming|Stem]] or [[Lemmatization|Lemmatize]] could also be helpful
* see [[NLP Pipeline]]


=== Representation: [[Vector Space Models]] ===
Construct a matrix $D$
* $D$ is Term-Document Matrix if rows of $D$ - terms, columns of $D$ - documents/passages
* $D$ is Document-Term Matrix if rows of $D$ - documents/passages, and columns of $D$ - terms
* each cell - typically a frequency with which a word occurs in a doc
* also apply weighting: TF or [[TF-IDF]] 


=== [[SVD]] and [[Dimensionality Reduction]] ===
Let $D$ be an $t \times p$ Term-Passage matrix 
* $t$ rows are terms, $p$ columns are passages, $\text{rank } D = r$
* then SVD decomposition is $D = T \cdot \Sigma \cdot P^T$ 
* $T$ is $t \times r$ [[Orthogonal Matrix]], contains left singular vectors, corresponds to term vectors
* $\Sigma$ is $r \times r$ a diagonal matrix of singular values
* $P$ is $r \times p$ [[Orthogonal Matrix]], contains right singular vectors, corresponds to passage vectors
* and then $T \sqrt\Sigma$ are loadings for terms and $P \sqrt\Sigma$ - for passages



Now reduce the dimensionality:
* want to combine the surface text information into some deeper abstraction
* finding the optimal dimensionality for final representation in the Semantic Space is important to properly capture mutual usage of words
* the &quot;True Semantic Space&quot; should address the Text Problems


So, Apply reduced-rank [[SVD]]
* $D \approx T_k \cdot \Sigma_k \cdot P^T_k$
* keep only $k$ largest singular values
* the result: best $k$-dim approximation of the original matrix $D$
* for NLP $k = 300 \pm 50$ usually works the best 
* but it should be [[Model Selection|tuned]] because it heavily depends on the domain


== Semantic Space ==
LSA constructs a semantic space via SVD:
* $T$ is $t \times r$ [[Orthogonal Matrix]], contains left singular vectors, corresponds to term vectors
* $\Sigma$ is $r \times r$ a diagonal matrix of singular values
* $P$ is $r \times p$ [[Orthogonal Matrix]], contains right singular vectors, corresponds to passage vectors
* and then $T \sqrt\Sigma$ are loadings for terms and $P \sqrt\Sigma$ - for passages


Language-theoretic interpretation: 
* LSA vectors approximate:
* the meaning of a word as its average effect of the meaning of passages in which they occur
* the meaning of a passage as meaning of its words 


After doing the SVD, we get the reduced space - this is the semantic space
* the effect of reducing the dimensionality:
* removed the noise effect of synomymy and polysemy 


=== Comparisons in the Semantic Space ===
So we approximated $D$ as $D \approx \hat D = T_k \Sigma_k P_k^T$
* lets omit index $k$: so below by $T$ we will assume $T_k$


Term comparisons:
* How similar are terms $\mathbf t_i$ and $\mathbf t_j$? 
* In $D$ we would compare rows of $D$. How to compare them in the semantic space?
* $\hat D \hat D^T$ gives a term-term [[Gram Matrix]] 
** $\hat D \hat D^T = T \Sigma \Sigma^T T^T = T \Sigma \, (T \Sigma)^T$
** thus $\big[\hat D \hat D^T\big]_{ij}$ is the dot product between $i$th and $j$th rows of $T \Sigma$
* rows of $T \Sigma$ are coordinates for terms in the semantic space


Document comparisons:
* how similar are documents $\mathbf p_i$ and $\mathbf p_j$ in the semantic space? 
* $\hat D^T \hat D$ gives a document-document [[Gram Matrix]] 
* $\hat D^T \hat D = P \Sigma \Sigma^T P^T = P \Sigma \,  (P \Sigma)^T$
* so to compute document $i$ and $j$ you compute the dot product between $i$th and $j$th rows of $P \Sigma$



=== Generalization to Unseen Documents ===
What about objects that didn't originally appear in the training set? 
* e.g. a query $\mathbf q$ 
* how do we represent $\mathbf q$ in the semantic space? 
* first, let's see how original documents $\mathbf p_i$ are represented in this space


$\hat D = T \Sigma P^T$
* multiply by $(T \Sigma)^{-1}$ on the left
* $(T \Sigma)^{-1} \hat D = P^T$
* $\Sigma^{-1} T^T \hat D = P^T$
* $P = D^T T \Sigma^{-1}$
* if $\mathbf d_i$ be some document in the original space (column of $\hat D$) and $\mathbf p_i$ the corresponding representation of $\mathbf d_i$ in the document basis, then
* $\mathbf p_i = \mathbf d_i^T T \Sigma^{-1}$


This, can represent $\mathbf q$ the same way:
* $\hat{\mathbf q} = \mathbf q^T T \Sigma^{-1}$
* where $\hat{\mathbf q}$ is the representation of $\mathbf q$ in the document basis
* to compare $\hat{\mathbf q}$ all we need to do is to scale it by $\Sigma$ and then compute a dot product



== Example ==
=== Article Titles Example ===
Let's consider titles of some articles (from Deerwester90):

* $c_1$: &quot;Humanmachine interface for ABC computer applications&quot;
* $c_2$: &quot;A survey of user opinion of computer system response time&quot;
* $c_3$: &quot;The EPS user interface management system&quot;
* $c_4$: &quot;Systemand human system engineering testing of EPS&quot;
* $c_5$: &quot;Relation of user perceived response time to error measurement&quot;
* $m_1$: &quot;The generation of random, binary, ordered trees&quot;
* $m_2$: &quot;The intersection graph of paths in trees&quot;
* $m_3$: &quot;Graph minors IV: Widths of trees and well-quasi-ordering&quot;
* $m_4$: &quot;Graph minors: A survey&quot;

Matrix:

$D = \left[\begin{array}{c|cccccccc}
&amp; c_1 &amp; c_2 &amp; c_3 &amp; c_4 &amp; c_5 &amp; m_1 &amp; m_2 &amp; m_3 &amp; m_4 \\
\hline
\text{human} &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
\text{interface} &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
\text{computer} &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
\text{user} &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
\text{system} &amp; 0 &amp; 1 &amp; 1 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
\text{response} &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
\text{time} &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
\text{EPS} &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
\text{survey} &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
\text{trees} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 \\
\text{graph} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 \\
\text{minors} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\
\end{array}\right]$


Note:
* row vectors for &quot;human&quot; and &quot;user&quot; are orthogonal: their dot product is zero, but they are supposed to be similar, so it must be positive
* also, &quot;human&quot; and &quot;minors&quot; are orthogonal, but they are not similar, so it must be negative

Let's apply SVD: 
* $D = W \Sigma P$
* 2-dim approximation: $D_2 = W_2 \Sigma_2 P_2$

$D_2 = \left[\begin{array}{c|cccccccc}
&amp; c_1 &amp; c_2 &amp; c_3 &amp; c_4 &amp; c_5 &amp; m_1 &amp; m_2 &amp; m_3 &amp; m_4 \\
\hline
\text{human} &amp; 0.16 &amp;  0.4  &amp;  0.38 &amp;  0.47 &amp;  0.18 &amp; -0.05 &amp; -0.12 &amp; -0.16 &amp; -0.09 \\
\text{interface} &amp; 0.14 &amp;  0.37 &amp;  0.33 &amp;  0.4  &amp;  0.16 &amp; -0.03 &amp; -0.07 &amp; -0.1  &amp; -0.04 \\
\text{computer} &amp; 0.15 &amp;  0.51 &amp;  0.36 &amp;  0.41 &amp;  0.24 &amp;  0.02 &amp;  0.06 &amp;  0.09 &amp;  0.12 \\
\text{user} &amp; 0.26 &amp;  0.84 &amp;  0.61 &amp;  0.7  &amp;  0.39 &amp;  0.03 &amp;  0.08 &amp;  0.12 &amp;  0.19 \\
\text{system} &amp; 0.45 &amp;  1.23 &amp;  1.05 &amp;  1.27 &amp;  0.56 &amp; -0.07 &amp; -0.15 &amp; -0.21 &amp; -0.05 \\
\text{response} &amp; 0.16 &amp;  0.58 &amp;  0.38 &amp;  0.42 &amp;  0.28 &amp;  0.06 &amp;  0.13 &amp;  0.19 &amp;  0.22 \\
\text{time} &amp; 0.16 &amp;  0.58 &amp;  0.38 &amp;  0.42 &amp;  0.28 &amp;  0.06 &amp;  0.13 &amp;  0.19 &amp;  0.22 \\
\text{EPS} &amp; 0.22 &amp;  0.55 &amp;  0.51 &amp;  0.63 &amp;  0.24 &amp; -0.07 &amp; -0.14 &amp; -0.2  &amp; -0.11 \\
\text{survey} &amp; 0.1  &amp;  0.53 &amp;  0.23 &amp;  0.21 &amp;  0.27 &amp;  0.14 &amp;  0.31 &amp;  0.44 &amp;  0.42 \\
\text{trees} &amp;-0.06 &amp;  0.23 &amp; -0.14 &amp; -0.27 &amp;  0.14 &amp;  0.24 &amp;  0.55 &amp;  0.77 &amp;  0.66 \\
\text{graph} &amp;-0.06 &amp;  0.34 &amp; -0.15 &amp; -0.3  &amp;  0.2  &amp;  0.31 &amp;  0.69 &amp;  0.98 &amp;  0.85 \\
\text{minors} &amp;-0.04 &amp;  0.25 &amp; -0.1  &amp; -0.21 &amp;  0.15 &amp;  0.22 &amp;  0.5  &amp;  0.71 &amp;  0.62 \\
\end{array}\right]$



What's the effect of dimensionality reduction here?
* words appear less or more frequent than originally
* consider two cells: (&quot;survey&quot;, $m_4$) and (&quot;trees&quot;, $m_4$)
* original document: 1 and 0
* reduced document: 0.42 and 0.66
* because $m_4$ contains &quot;graph&quot; and &quot;minor&quot;, the 0 for &quot;trees&quot; was replaced by 0.42 - they are related terms
* so it can be seen as estimate of how many times word &quot;trees&quot; would occur in other samples that contain &quot;graph&quot; and &quot;minor&quot;
* the count for &quot;survey&quot; went down - it's not expected in this context

So in the reconstructed space:
* dot product between &quot;user&quot; and &quot;human&quot; is positive
* dot product between &quot;human&quot; and &quot;minors&quot; is negative
* it tells us way better whether terms are similar or not even when they never co-occur together


Taking 2 principal components is the same as taking only 2 abstract concepts
* each word in the vocabulary has some amount of these 2 concepts (we see how much by looking at 1st and 2nd column of $W$)


The idea:
* we don't want to reconstruct the underlying data perfectly, but instead we hope to find the correlation and the abstract concepts



=== Python code ===
&lt;pre&gt;
import numpy as np
import numpy.linalg as la
 
D = [[1, 0, 0, 1, 0, 0, 0, 0, 0],
     [1, 0, 1, 0, 0, 0, 0, 0, 0],
     [1, 1, 0, 0, 0, 0, 0, 0, 0],
     [0, 1, 1, 0, 1, 0, 0, 0, 0],
     [0, 1, 1, 2, 0, 0, 0, 0, 0],
     [0, 1, 0, 0, 1, 0, 0, 0, 0],
     [0, 1, 0, 0, 1, 0, 0, 0, 0],
     [0, 0, 1, 1, 0, 0, 0, 0, 0],
     [0, 1, 0, 0, 0, 0, 0, 0, 1],
     [0, 0, 0, 0, 0, 1, 1, 1, 0],
     [0, 0, 0, 0, 0, 0, 1, 1, 1],
     [0, 0, 0, 0, 0, 0, 0, 1, 1]]
D = np.array(D)
 
rows = ['human', 'interface', 'computer', 'user', 'system', 
        'response', 'time', 'EPS', 'survey', 'trees', 'graph', 'minors']
idx = {n: i for (i, n) in enumerate(rows)}
 
D[idx['human']].dot(D[idx['user']]) # 0
D[idx['human']].dot(D[idx['minors']]) # 0
 
 
T, S, P = la.svd(D) # T=terms, P=passages
 
np.set_printoptions(precision=2, suppress=True)
print T[:, 0:2], S[0:2], P[0:2, :]
 
D_hat = T[:, 0:2].dot(np.diag(S[0:2])).dot(P[0:2, :])
 
D_hat[idx['human']].dot(D_hat[idx['user']]) # 0.955
D_hat[idx['human']].dot(D_hat[idx['minors']]) # -0.251
&lt;/pre&gt;


Can do the same without building $\hat D$:


&lt;pre&gt;
T = T[:, 0:2]
S = np.diag(S[0:2])
P = P[0:2, :].T

human = T.dot(S)[idx['human']]
user = T.dot(S)[idx['user']]
human.dot(user) # same result: 0.955
&lt;/pre&gt;


Finally, let's calculate cosine between human and user:

&lt;pre&gt;
human.dot(user) / (la.norm(human) * la.norm(user))
# 0.88784582874340123
&lt;/pre&gt;




== Practical Notes ==
=== Applications ===
* [[Document Classification]]
* [[Document Clustering]]
* Text search in [[Information Retrieval]]


=== Limitations ===
* makes no use of words order, punctuation
* if the original terms are already descriptive enough (e.g. for [[Document Classification]]), they may be lost during the transformation


=== When Not Good ===
* Sometimes Semantic Spaces alone are not good
* but we can mix the original vector space and the semantic space together 


=== Mean Centering ===
LSA and [[Principal Component Analysis]] are related via [[SVD]]
* but for PCA we often do mean centering. Why not here? 
* Angle (and cosine) is not preserved when doing mean-correction, so it may affect pair-wise similarities 
* https://habrastorage.org/files/60e/825/3b3/60e8253b34ba496da20ed47df2e21bf2.png
* Term-Document matrices are typically very sparse, and if we mean-center, we'll lose the sparsity
* because of the sparsity, the mean of rows is very close to 0 anyway
* also, see here: http://stats.stackexchange.com/questions/152879/latent-semantic-indexing-and-data-centering





== Extensions of LSA ==
* add probability over documents: [[Probabilistic LSA]]
* and a similar technique: [[Latent Dirichlet Allocation]]
* can also use [[Non-Negative Matrix Factorization]] to discover latent structure of data



== Links ==
* Soft for doing LSA: gensim https://radimrehurek.com/gensim/ (also for [[Topic Modeling]])

== Sources ==
* Koll, Matthew B. &quot;WEIRD: An approach to concept-based information retrieval.&quot; 1979.
* Landauer, Thomas K., Peter W. Foltz, and Darrell Laham. &quot;An introduction to latent semantic analysis.&quot; 1998. [http://tottdp.googlecode.com/files/LandauerFoltz-Laham1998.pdf]
* http://www.scholarpedia.org/article/Latent_semantic_analysis
* http://edutechwiki.unige.ch/en/Latent_semantic_analysis_and_indexing
* Evangelopoulos, Nicholas, Xiaoni Zhang, and Victor R. Prybutok. &quot;Latent semantic analysis: five methodological recommendations.&quot; (2012). [http://digital.library.unt.edu/ark:/67531/metadc288006/m2/1/high_res_d/Evangelopoulos2012_EJIS-Pre-print.pdf] [http://scholar.google.com/scholar?cluster=13322286620975267196&amp;hl=ru&amp;as_sdt=0,5]
* Deerwester, Scott C., et al. &quot;Indexing by latent semantic analysis.&quot; 1990. [http://www.cob.unt.edu/itds/faculty/evangelopoulos/dsci5910/LSA_Deerwester1990.pdf]
* Berry, Michael W., Susan T. Dumais, and Gavin W. O'Brien. &quot;Using linear algebra for intelligent information retrieval.&quot; (1995). [http://machinelearningtext.pbworks.com/w/file/fetch/47378285/lsiPaper_ut-cs-94-270.pdf]
* Korenius, Tuomo, Jorma Laurikkala, and Martti Juhola. &quot;On principal component analysis, cosine and Euclidean measures in information retrieval.&quot; 2007. [http://www.sciencedirect.com/science/article/pii/S0020025507002630] 
* Zhukov, Leonid, and David Gleich. &quot;Topic identification in soft clustering using PCA and ICA&quot;. 2004. [http://leonidzhukov.ru/papers/soft-clustering-pca-ica.pdf]


[[Category:Document Clustering]]
[[Category:NLP]]
[[Category:Information Retrieval]]</text>
      <sha1>6t2bhldi2l6cuhip0aqqjz7r9wjxf07</sha1>
    </revision>
  </page>
  <page>
    <title>Function Spaces</title>
    <ns>0</ns>
    <id>550</id>
    <revision>
      <id>553</id>
      <timestamp>2015-04-24T08:39:48Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="765">{{stub}}

== Function Spaces ==
A function space is a [[Vector Spaces|vector space]] where &quot;vectors&quot; are functions


Properties:
* functions are not just $n$ points like vectors, but they are the entire continuum 
* this is a vector space, but &quot;vectors&quot; are functions: they have inner product with $\int$ instead of $\sum$, and they also have orthogonality
* [[Inner Product]]: $\langle f, g \rangle = \int\limits_{-\infty}^{\infty} f(x) \, g(x) \, dx$
* [[Orthogonal Functions]]: if the inner product of $f$ and $g$ is 0 then $f$ and $g$ are orthogonal
* this is an inner product for functions: we multiply the values for every $x$ and sum them using integral 


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Calculus]]
[[Category:Linear Algebra]]</text>
      <sha1>igc4zivxrvn749lqsjknc3iwkzarafg</sha1>
    </revision>
  </page>
  <page>
    <title>Orthogonal Functions</title>
    <ns>0</ns>
    <id>551</id>
    <revision>
      <id>554</id>
      <timestamp>2015-04-24T08:40:45Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="850">{{stub}}

== Orthogonal Functions ==
Two functions $f$ and $g$ are orthogonal if their inner product is 0
* how do we define inner product for functions?
* the same way we do for vectors

* Vectors: $\langle \mathbf v, \mathbf w \rangle = \mathbf v^T \mathbf w = v_1 w_1 + \ ... \ + v_n w_n$ (see [[Vector Orthogonality]])
* Functions? $\langle f, g \rangle = \int\limits_{-\infty}^{\infty} f(x) \, g(x) \, dx$
* functions are not just $n$ points like vectors, but they are the entire continuum 
* this is an inner product for functions: we multiply the values for every $x$ and sum them using integral 
* this is a vector space, but &quot;vectors&quot; are functions: they have inner product with $\int$ instead of $\sum$, and they also have orthogonality


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Calculus]]
[[Category:Linear Algebra]]</text>
      <sha1>k5ooyb1q2ystwu1tcj26bj780d75ewi</sha1>
    </revision>
  </page>
  <page>
    <title>Stochastic Matrices</title>
    <ns>0</ns>
    <id>552</id>
    <revision>
      <id>555</id>
      <timestamp>2015-05-08T18:55:42Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3110">== Stochastic Matrices ==
Stochastic matrices (or Markov matrices) - matrices used to describe transitions in [[Markov Chains]]

A stochastic matrix is a matrix $A$ which
* is square $n \times n$
* for all entires $0 \leqslant a_{ij} \leqslant 1$
* sum over columns is 1


== Properties ==
* for any $k$, $A^k$ is also stochastic 
* its largest [[Eigenvalues and Eigenvectors|eigenvalue]] is $\lambda_1 = 1$
* all other eigenvalues are $| \lambda_i | \leqslant 1$, and usually it's strictly less

=== $\lambda_1 = 1$ ===
Let take any stochastic $A$ 
* suppose $\lambda = 1$ is an eigenvalue
* then $A - \lambda I = A - I$ must be singular
* sum of columns of $A$ is 1. But when we subtract $1$ from diagonal, the sum is 0 for all columns
* so columns are now linearly dependent, and it means that rows are also linearly dependent
* then $(1,1,1) \in N(A^T)$ (left [[Nullspace]] of $A$)
* and the [[Nullspace]] $N(A)$ also contains something: it contains the eigenvector $\mathbf v_1$ that corresponds to $\lambda_1 = 0$

If $\lambda_1 &lt; 0$, then $A^k$ for large $k$ will converge to $\mathbf O$ - a matrix with all zeros.

 

=== Eigenvalues ===
* for stochastic matrices, eigenvalues of $A$ are the same as eigenvalues of $A^T$
* $\text{det } (A - \lambda I) = 0$
* $\text{det } (A - \lambda I)^T = \text{det } (A^T - \lambda I) = 0$


=== [[Recurrent Equation]] ===
* $\mathbf u_k = A^k \mathbf u_0$
* Let's use the eigenvectors $\mathbf v_1 , \ ... \ , \mathbf v_n$ of $A$ as basis 
* then $\mathbf u_k = A^k \mathbf u_0 = c_1 \lambda_1^k \mathbf v_1 + c_2 \lambda_2^k \mathbf v_2 + \ ... \ c_n \lambda_n^k \mathbf v_n$
* $\lambda_1 = 1$ and the rest are less than 1, so for large $k$ we have 
* $\mathbf u_k \approx c_1 \mathbf v_1$
* $c_1 \mathbf v_1$ is the ''steady state''
* This an application of the [[Power Iteration]] method



== Example ==
=== Example 1 ===
* $A = \begin{bmatrix} 0.8 &amp; 0.3 \\ 0.2 &amp; 0.7 \end{bmatrix}$
* $\lambda_1 = 1, \lambda_2 = 0.5$
* eigenvectors $\mathbf v_1 = (0.6, 0.4)$ and $(1, -1)$
* let's apply [[Eigendecomposition]] of $A$:
* $A = S \Lambda S^{-1}$: $\begin{bmatrix} 0.8 &amp; 0.3 \\ 0.2 &amp; 0.7 \end{bmatrix} =
\begin{bmatrix} 0.6 &amp; 1 \\ 0.4 &amp; -1 \end{bmatrix} \, 
\begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 0.5 \end{bmatrix} \,
\begin{bmatrix} 1 &amp; 1 \\ 0.4 &amp; -0.6 \end{bmatrix}$

Steady state:
* $A^2$ has the same $S$: $A^2 = S \Lambda S^{-1} \, S \Lambda S^{-1} = S \Lambda^2 S^{-1}$
* $A^k = S \Lambda^k S^{-1}$
* Thus, $A^k =
\begin{bmatrix} 0.6 &amp; 1 \\ 0.4 &amp; -1 \end{bmatrix} \, 
\begin{bmatrix} 1^k &amp; 0 \\ 0 &amp; (0.5)^k \end{bmatrix} \,
\begin{bmatrix} 1 &amp; 1 \\ 0.4 &amp; -0.6 \end{bmatrix}$
* as $k$ increases, $0.5^k$ becomes very small, so
* as $k \to \infty$, $A^k \to
\begin{bmatrix} 0.6 &amp; 1 \\ 0.4 &amp; -1 \end{bmatrix} \, 
\begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 0 \end{bmatrix} \,
\begin{bmatrix} 1 &amp; 1 \\ 0.4 &amp; -0.6 \end{bmatrix} = 
\begin{bmatrix} 0.6 &amp; 0.6 \\ 0.4 &amp; 0.4 \end{bmatrix}$



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Strang, G. Introduction to linear algebra.
* http://en.wikipedia.org/wiki/Stochastic_matrix


[[Category:Probability]]
[[Category:Linear Algebra]]</text>
      <sha1>3gtzg598rerghlnbq9ogcr0vsj5763d</sha1>
    </revision>
  </page>
  <page>
    <title>Fourier Transformation</title>
    <ns>0</ns>
    <id>553</id>
    <revision>
      <id>556</id>
      <timestamp>2015-04-24T16:48:33Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5501">== Fourier Transformation ==
Goal: to expand a function $f(x)$
* i.e. write it as a linear combination 
* $f(x) = a_0 + a_1 \cos x + b_1 \sin x + a_2 \cos 2x + b_2 \sin 2x + \ ...$


=== Basis ===
These functions $\cos nx$ and $\sin nx$ are [[Orthogonal Functions|orthogonal]]
* they form an orthogonal basis
* so basis is $\big[ 1, \cos x, \sin x, \cos 2x, \sin 2x, \ ... \big]$
* inner product in functions space is $\langle f, g \rangle = \int\limits_0^{2\pi} f(x) g(x) \, dx$
** because these functions are all periodic and analytical, we take the integral only over $[0, 2 \pi]$
* e.g. $\int \sin x \, \cos x \, dx = 0.5 (\sin x)^2 \mathop{|}\limits_0^{2\pi} = 0$
* so we have orthogonal $\infty$-dimensional basis for this functional space
* and we want to express some function $f(x)$ in this basis 


=== Coefficients ===
Let's start with $a_0$ 
* $f(x) = a_0 1 + a_1 \cos x + b_1 \sin x + a_2 \cos 2x + b_2 \sin 2x + \ ...$
* let's multiply by \cos x and integrate 
* $\int f(x) \cos x \, dx = 0 + a_1 \underbrace{\int \cos x \, \cos x \, dx}_{\pi} + 0 + 0 + \ ...$
* $\int f(x) \cos x \, dx = a_1 \pi$
* so, $a_1 = \cfrac{1}{\pi} \int f(x) \cos x \, dx$

We can do it for all the coefficients 
* this is called &quot;Euler's formula&quot;


== Discrete Fourier Transform ==
=== Fourier Matrix ===
Let $F_n$ be a Fourier matrix:
* $F_n = \begin{bmatrix} 
1 &amp; 1 &amp; 1 &amp; \cdots &amp; 1 \\
1 &amp; w^2 &amp; w^2 &amp; \cdots &amp; w^{n - 1} \\
1 &amp; w^3 &amp; w^4 &amp; \cdots &amp; w^{2(n-1)} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; w^{n-1} &amp; w^{2(n-1)} &amp; \cdots &amp; w^{(n-1)^2} \\
\end{bmatrix}$
* each element is $(F_n)_{ij} = w^{ij}$ for all $i,j$ (indexes of $F_n$)
* matrix $F_n$ is a [[Symmetric Matrix|symmetric]]

where $w \in \mathbb C$:
* $w^n = 1$, so $w = \sqrt[n]{1}$
* $w = \exp \left( i \ \cfrac{2\pi}{n} \right) = \cos \cfrac{2\pi}{n} + i \, \sin \cfrac{2\pi}{n}$
* e.g. $w^2 = \exp \left( 2 \ \cfrac{2\pi}{n} \right)$
* $w$ is $n$th root of 1 (&quot;roots of unity&quot;)


Example 
* $n = 6, w = \exp \left( 2 \ \cfrac{2\pi}{6} \right) = \exp \left( \cfrac{2\pi}{3} \right)$
* http://habrastorage.org/files/6f0/506/22c/6f050622c0eb47e4bd5eeb8c3dfcd463.png

$n = 4$
* $w = \exp \left( i \ \cfrac{2\pi}{4} \right) = i$
* so we have $1, i, i^2 = -1, i^3 = 1$
* thus, $F_4 = \begin{bmatrix} 
1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; w^2 &amp; w^3 &amp; w^4 \\
1 &amp; w^3 &amp; w^4 &amp; w^5 \\
1 &amp; w^5 &amp; w^5 &amp; w^6 \\
\end{bmatrix} = \begin{bmatrix} 
1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; i^2 &amp; i^3 &amp; i^4 \\
1 &amp; i^3 &amp; i^4 &amp; i^5 \\
1 &amp; i^5 &amp; i^5 &amp; i^6 \\
\end{bmatrix} = \begin{bmatrix} 
1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; i &amp; -1 &amp; -i \\
1 &amp; -1 &amp; 1 &amp; -1 \\
1 &amp; -i &amp; -1 &amp; i \\
\end{bmatrix}$
* for 4-point Fourier transform: for a vector with 4 components 



Columns of $F_n$ are orthogonal
* Let's check it for $n=4$:
* $\overline{\Big[ 1 \ i \ -1 \ -i \Big]} \begin{bmatrix} 1 \\ -i \\ -1 \\ i \end{bmatrix} = 1 + 1 - 1 - 1 = 0$
* but they are not orthonormal
* e.g. for $F_4$ all columns have length 2
* so let's define a Fourier Matrix $W_4$ as $W_4 = \cfrac{1}{2} F_4$
* now $W_4^H W_4 = I$
* so let $W_n = \cfrac{1}{\sqrt{n}} F_n$
* we call this $W_n$ a ''Fourier Matrix''


=== Discrete Fourier Transform ===
So, given a matrix $W_n$ and a vector $\mathbf u \in \mathbb C^{n}$ (or in $\mathbb R^{n}$)
* $\mathbf u \cdot W_n$ is the direct transformation
* $\mathbf u \cdot W_n^{-1}$ is the inverse transformation



=== Fast Fourier Transform ===
The idea of FFT 
* There's a connection between $W_6$ and $W_3$, $W_8$ and $W_4$, $W_{2n}$ and $W_n$

Example:
* suppose we have $W_{64}$, it's a $64 \times 64$ matrix
* $w$ is 64th root of 1
* in $W_{32}$, $w$ is 32th root of 1
* so $w_{64}^2 = w_{32}$
* http://habrastorage.org/files/96f/2c3/858/96f2c3858129488290280b709be08893.png

How can we use this fact? 
* we want to go from $W_64$ to a matrix $\left[ \begin{array}{c|c}
W_{32} &amp; 0 \\
\hline
0 &amp; W_{32} \\
\end{array} \right]$ 
* i.e. factorize $W_{64}$ in terms of $W_{32}$
* can factorize it as $W_{64} = \begin{bmatrix}
I_{32} &amp; D_{32} \\
I_{32} &amp; -D_{32} 
\end{bmatrix} 
\begin{bmatrix}
W_{32} &amp; 0 \\
0 &amp; W_{32}
\end{bmatrix} 
P_{64}$
** where $P_n$ is a $n \times n$ [[Permutation Matrices|permutation matrix]] $P_n = \begin{bmatrix}
1 &amp;   &amp;   &amp;   &amp; \cdots &amp;   &amp;    \\
  &amp;   &amp; 1 &amp;   &amp; \cdots &amp;   &amp;   \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
  &amp;   &amp;   &amp;   &amp; \cdots &amp; 1 &amp;   \\
\hline
  &amp; 1 &amp;   &amp;   &amp; \cdots &amp;   &amp;    \\
  &amp;   &amp;   &amp; 1 &amp; \cdots &amp;   &amp;   \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
  &amp;   &amp;   &amp;   &amp; \cdots &amp;   &amp; 1 \\
\end{bmatrix}$
** first, in $P$ we have rows with even columns containing $1$, and then, in the second half, rows that contain $1$ in odd columns (here we start indexing columns from 0)
** $P_n$ takes even-numbered components first, and then odd-numbered
** $D_n$ is a diagonal matrix, 
** $D_n = \begin{bmatrix}
1 &amp;   &amp;      &amp;        &amp;   \\
  &amp; w &amp;      &amp;        &amp;   \\
  &amp;   &amp; w^2  &amp;        &amp;   \\
  &amp;   &amp;      &amp; \ddots  &amp;   \\
  &amp;   &amp;      &amp;        &amp; w^{n/2 - 1}
\end{bmatrix}$
* now we can break $W_{32}$ down in the same way!
** $W_{32} = \begin{bmatrix}
I_{16} &amp;  D_{16} \\
I_{16} &amp; -D_{16} 
\end{bmatrix} 
\begin{bmatrix}
W_{16} &amp; 0 \\
0 &amp; W_{16}
\end{bmatrix} 
P_{32}$
* use recursion


This way we reduce computation from $O(n^2)$ to $\cfrac{n}{2} \, \log_2 n$


== Links ==
* http://www.katjaas.nl/fourier/fourier.html

== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* http://en.wikipedia.org/wiki/DFT_matrix

[[Category:Calculus]]
[[Category:Linear Algebra]]
[[Category:Signal Processing]]</text>
      <sha1>na31l1iker42yqhxcsp4lakqzxsdiys</sha1>
    </revision>
    <revision>
      <id>802</id>
      <parentid>556</parentid>
      <timestamp>2017-06-27T13:54:11Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5528">== Fourier Transformation ==
Goal: to expand a function $f(x)$
* i.e. write it as a linear combination 
* $f(x) = a_0 + a_1 \cos x + b_1 \sin x + a_2 \cos 2x + b_2 \sin 2x + \ ...$


=== Basis ===
These functions $\cos nx$ and $\sin nx$ are [[Orthogonal Functions|orthogonal]]
* they form an orthogonal basis
* so basis is $\big[ 1, \cos x, \sin x, \cos 2x, \sin 2x, \ ... \big]$
* inner product in functions space is $\langle f, g \rangle = \int\limits_0^{2\pi} f(x) g(x) \, dx$
** because these functions are all periodic and analytical, we take the integral only over $[0, 2 \pi]$
* e.g. $\int \sin x \, \cos x \, dx = 0.5 (\sin x)^2 \mathop{|}\limits_0^{2\pi} = 0$
* so we have orthogonal $\infty$-dimensional basis for this functional space
* and we want to express some function $f(x)$ in this basis 


=== Coefficients ===
Let's start with $a_0$ 
* $f(x) = a_0 1 + a_1 \cos x + b_1 \sin x + a_2 \cos 2x + b_2 \sin 2x + \ ...$
* let's multiply by \cos x and integrate 
* $\int f(x) \cos x \, dx = 0 + a_1 \underbrace{\int \cos x \, \cos x \, dx}_{\pi} + 0 + 0 + \ ...$
* $\int f(x) \cos x \, dx = a_1 \pi$
* so, $a_1 = \cfrac{1}{\pi} \int f(x) \cos x \, dx$

We can do it for all the coefficients 
* this is called &quot;Euler's formula&quot;


== Discrete Fourier Transform ==
=== Fourier Matrix ===
Let $F_n$ be a Fourier matrix:
* &lt;math&gt;F_n = \begin{bmatrix} 
1 &amp; 1 &amp; 1 &amp; \cdots &amp; 1 \\
1 &amp; w^2 &amp; w^2 &amp; \cdots &amp; w^{n - 1} \\
1 &amp; w^3 &amp; w^4 &amp; \cdots &amp; w^{2(n-1)} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; w^{n-1} &amp; w^{2(n-1)} &amp; \cdots &amp; w^{(n-1)^2} \\
\end{bmatrix}&lt;/math&gt;
* each element is $(F_n)_{ij} = w^{ij}$ for all $i,j$ (indexes of $F_n$)
* matrix $F_n$ is a [[Symmetric Matrices|symmetric]]

where $w \in \mathbb C$:
* $w^n = 1$, so $w = \sqrt[n]{1}$
* $w = \exp \left( i \ \cfrac{2\pi}{n} \right) = \cos \cfrac{2\pi}{n} + i \, \sin \cfrac{2\pi}{n}$
* e.g. $w^2 = \exp \left( 2 \ \cfrac{2\pi}{n} \right)$
* $w$ is $n$th root of 1 (&quot;roots of unity&quot;)


Example 
* $n = 6, w = \exp \left( 2 \ \cfrac{2\pi}{6} \right) = \exp \left( \cfrac{2\pi}{3} \right)$
* http://habrastorage.org/files/6f0/506/22c/6f050622c0eb47e4bd5eeb8c3dfcd463.png

$n = 4$
* $w = \exp \left( i \ \cfrac{2\pi}{4} \right) = i$
* so we have $1, i, i^2 = -1, i^3 = 1$
* thus, &lt;math&gt;F_4 = \begin{bmatrix} 
1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; w^2 &amp; w^3 &amp; w^4 \\
1 &amp; w^3 &amp; w^4 &amp; w^5 \\
1 &amp; w^5 &amp; w^5 &amp; w^6 \\
\end{bmatrix} = \begin{bmatrix} 
1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; i^2 &amp; i^3 &amp; i^4 \\
1 &amp; i^3 &amp; i^4 &amp; i^5 \\
1 &amp; i^5 &amp; i^5 &amp; i^6 \\
\end{bmatrix} = \begin{bmatrix} 
1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; i &amp; -1 &amp; -i \\
1 &amp; -1 &amp; 1 &amp; -1 \\
1 &amp; -i &amp; -1 &amp; i \\
\end{bmatrix}&lt;/math&gt;
* for 4-point Fourier transform: for a vector with 4 components 



Columns of $F_n$ are orthogonal
* Let's check it for $n=4$:
* &lt;math&gt;\overline{\Big[ 1 \ i \ -1 \ -i \Big]} \begin{bmatrix} 1 \\ -i \\ -1 \\ i \end{bmatrix} = 1 + 1 - 1 - 1 = 0&lt;/math&gt;
* but they are not orthonormal
* e.g. for $F_4$ all columns have length 2
* so let's define a Fourier Matrix $W_4$ as $W_4 = \cfrac{1}{2} F_4$
* now $W_4^H W_4 = I$
* so let $W_n = \cfrac{1}{\sqrt{n}} F_n$
* we call this $W_n$ a ''Fourier Matrix''


=== Discrete Fourier Transform ===
So, given a matrix $W_n$ and a vector $\mathbf u \in \mathbb C^{n}$ (or in $\mathbb R^{n}$)
* $\mathbf u \cdot W_n$ is the direct transformation
* $\mathbf u \cdot W_n^{-1}$ is the inverse transformation



=== Fast Fourier Transform ===
The idea of FFT 
* There's a connection between $W_6$ and $W_3$, $W_8$ and $W_4$, $W_{2n}$ and $W_n$

Example:
* suppose we have $W_{64}$, it's a $64 \times 64$ matrix
* $w$ is 64th root of 1
* in $W_{32}$, $w$ is 32th root of 1
* so $w_{64}^2 = w_{32}$
* http://habrastorage.org/files/96f/2c3/858/96f2c3858129488290280b709be08893.png

How can we use this fact? 
* we want to go from $W_64$ to a matrix &lt;math&gt;\left[ \begin{array}{c|c}
W_{32} &amp; 0 \\
\hline
0 &amp; W_{32} \\
\end{array} \right]&lt;/math&gt;
* i.e. factorize $W_{64}$ in terms of $W_{32}$
* can factorize it as &lt;math&gt;W_{64} = \begin{bmatrix}
I_{32} &amp; D_{32} \\
I_{32} &amp; -D_{32} 
\end{bmatrix} 
\begin{bmatrix}
W_{32} &amp; 0 \\
0 &amp; W_{32}
\end{bmatrix} 
P_{64}&lt;/math&gt;
** where $P_n$ is a $n \times n$ [[Permutation Matrices|permutation matrix]] &lt;math&gt;P_n = \begin{bmatrix}
1 &amp;   &amp;   &amp;   &amp;        &amp;   &amp;   \\
  &amp;   &amp; 1 &amp;   &amp;        &amp;   &amp;   \\
  &amp;   &amp;   &amp;   &amp; \ddots &amp;   &amp;   \\
  &amp;   &amp;   &amp;   &amp;        &amp; 1 &amp;   \\
\hline
  &amp; 1 &amp;   &amp;   &amp;        &amp;   &amp;   \\
  &amp;   &amp;   &amp; 1 &amp;        &amp;   &amp;   \\
  &amp;   &amp;   &amp;   &amp; \ddots &amp;   &amp;   \\
  &amp;   &amp;   &amp;   &amp;        &amp;   &amp; 1 \\
\end{bmatrix}&lt;/math&gt;
** first, in $P$ we have rows with even columns containing $1$, and then, in the second half, rows that contain $1$ in odd columns (here we start indexing columns from 0)
** $P_n$ takes even-numbered components first, and then odd-numbered
** $D_n$ is a diagonal matrix, 
** &lt;math&gt;D_n = \begin{bmatrix}
1 &amp;   &amp;      &amp;        &amp;   \\
  &amp; w &amp;      &amp;        &amp;   \\
  &amp;   &amp; w^2  &amp;        &amp;   \\
  &amp;   &amp;      &amp; \ddots  &amp;   \\
  &amp;   &amp;      &amp;        &amp; w^{n/2 - 1}
\end{bmatrix}&lt;/math&gt;
* now we can break $W_{32}$ down in the same way!
** &lt;math&gt;W_{32} = \begin{bmatrix}
I_{16} &amp;  D_{16} \\
I_{16} &amp; -D_{16} 
\end{bmatrix} 
\begin{bmatrix}
W_{16} &amp; 0 \\
0 &amp; W_{16}
\end{bmatrix} 
P_{32}&lt;/math&gt;
* use recursion


This way we reduce computation from $O(n^2)$ to $\cfrac{n}{2} \, \log_2 n$


== Links ==
* http://www.katjaas.nl/fourier/fourier.html

== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* http://en.wikipedia.org/wiki/DFT_matrix

[[Category:Calculus]]
[[Category:Linear Algebra]]
[[Category:Signal Processing]]</text>
      <sha1>g8k50uxsrezoza4sbwlzlf31u015gj7</sha1>
    </revision>
  </page>
  <page>
    <title>Positive-Definite Matrices</title>
    <ns>0</ns>
    <id>554</id>
    <revision>
      <id>557</id>
      <timestamp>2015-05-08T16:44:10Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5735">== Positive-Definite Matrices ==
=== Energy-Based Definition ===
In [[Linear Algebra]], a matrix an $n \times n$ matrix is Positive-definite matrix (PDM) if 
* $\mathbf v^T A \mathbf v &gt; 0$ for all $\mathbf v \in \mathbb R^n$
* This is the energy based definition


Why ''energy''?
* because $\mathbf v^T A \mathbf v$ or $\frac{1}{2} \mathbf v^T A \mathbf v$ is called the ''energy'' of the system $A$


== Positive Semi-Definite Matrices ==
* A matrix is semi-positive definite if 
* $\mathbf v^T A \mathbf v \geqslant 0$ for all $\mathbf v \ne \mathbf 0 \in \mathbb R^n$ 
* so some eigenvectors can be 0


== Motivating Example ==
* Let $A = \begin{bmatrix} 
2 &amp; 6 \\
6 &amp; 18 \\
\end{bmatrix}$ 
* then for any $\mathbf x = (x_1, x_2)$ we want to check 
* $\big[x_1 \ x_2 \big] \begin{bmatrix} 
2 &amp; 6 \\
6 &amp; 18 \\
\end{bmatrix} \begin{bmatrix} 
x_1 \\
x_2 \\
\end{bmatrix} = 2 \, x_1^2 + 12 \, x_1 x_2 + 18 \, x_2^2$
* note that this is not a linear anymore: 
* we have an equation $a x_1^2 + 2b \, x_1 x_2 + c \, x_2^2$
* this is a [[Quadratic Form]] 
* we want to know if this quantity is always positive or not 
* are there such $x_1, x_2$ that $a x_1^2 + 2b \, x_1 x_2 + c \, x_2^2 &lt; 0$?

So we have a function $f(\mathbf x) = \mathbf x^T A \, \mathbf x$ and we want to check if it's always positive for any $\mathbf x$


Another example
* let $A_1 = \begin{bmatrix} 
2 &amp; 6 \\
6 &amp; 7 \\
\end{bmatrix}$
* then $f(\mathbf x) = \mathbf x^T A_1 \, \mathbf x = 2 x_1^2 + 12 x_1 x_2 + 7 x_2^2$
* there exists $\mathbf x$ such that $f(\mathbf x) &lt; 0$, e.g. $(1, -1)$
* in this system, there's a [[Saddle Point]] - a max for one direction and min for another
* http://habrastorage.org/files/806/5cd/ad5/8065cdad5e2c4642bc8a9b74feb907d9.png


Consider an alternative:
* $A_2  = \begin{bmatrix} 
2 &amp; 6 \\
6 &amp; 20 \\
\end{bmatrix}$
* $f(\mathbf x) = \mathbf x^T A_2 \, \mathbf x = 2 x_1^2 + 12 x_1 x_2 + 20 x_2^2$
* here squares always overwhelm $12 x_1 x_2$
* http://habrastorage.org/files/07a/cbc/a56/07acbca564ff4962993cf450951146bf.png


We say that $A_1$ is ''indefinite'', and $A_2$ is ''positive-definite''


&lt;img src=&quot;http://brickisland.net/cs177/wp-content/uploads/2011/11/ddg_definiteness.svg&quot; /&gt;

Source: [http://brickisland.net/cs177fa12/?p=302]


=== Finding Minima ===
Recall from [[Calculus]]:
* 1st [[Derivative]] is needed for finding extremum, but you don't know if it's min or max
* so you have to look for the 2nd derivative to learn if it's positive or negative
* you want to find $\cfrac{du}{dx} = 0$ and $\cfrac{d^2 \, u}{d \, x^2} &gt; 0$

Consider $A_2$ again:
* $f(\mathbf x) = \mathbf x^T A_1 \, \mathbf x = 2 x_1^2 + 12 x_1 x_2 + 20 x_2^2$
* Let's complete the square: $2 \, (x_1 + 3 \, x_2)^2 + 2 \, x_2^2$
* now it's easy to see that this function is indeed always positive: we completed the square and there are no negative terms

What about $A_1$?
* $f(\mathbf x) = \mathbf x^T A_1 \, \mathbf x = 2 x_1^2 + 12 x_1 x_2 + 7 x_2^2$
* let's try to complete the square: $2 \, (x_1 + 3 \, x_2)^2 - 11 \, x_2^2$
* we have a minus!


=== Matrix vs Function ===
Let's have a look again at $A_2$:
* $f(\mathbf x) = \mathbf x^T A_1 \, \mathbf x = 2 x_1^2 + 12 x_1 x_2 + 20 x_2^2 = 2 \, (x_1 + 3 \, x_2)^2 + 2 \, x_2^2$
* the numbers in the completed square form come from [[Gaussian Elimination]]!
* Let's do $A = LU$ transformation:
** $L = \begin{bmatrix} 
1 &amp; 0 \\
3 &amp; 1 \\
\end{bmatrix}, U = \begin{bmatrix} 
\boxed 2 &amp; 6 \\
0 &amp; \boxed 2 \\
\end{bmatrix}$
* multipliers before squares come from pivots of $U$: 
** $\boxed{2} \, (x_1 + 3 \, x_2)^2 + \boxed 2 \, x_2^2$
* coefficients inside each square come from $L$
** $2 \, (1 \, x_1 + 3 \, x_2)^2 + 2 \, (0\, x_1 + 1 \, x_2)^2$
* so positive pivots of $U$ are good


=== Derivative Matrix ===
So a matrix of second derivatives ([[Hessian Matrix]]) is
* $\begin{bmatrix} 
\cfrac{\partial x_1^2}{\partial^2 x_1} &amp; \cfrac{\partial x_1 \partial x_2}{\partial x_1 \partial x_2} \\
\cfrac{\partial x_2 \partial x_1}{\partial x_2 \partial x_1} &amp; \cfrac{\partial x_2^2}{\partial^2 x_2} \\
\end{bmatrix}$
* we want it to be positive-definite
* then the function $f(\mathbf x) = \mathbf x^T A \, \mathbf x$ is positive-definite


== Checking for Positiveness ==
So, how to check for positive definitiveness? 
* using the definition: check that $\mathbf v^T A \mathbf v &gt; 0$ for all $\mathbf v$
* check that all eigenvalues are positive
* or that all pivots of $L$ in $A = LU$ are positive
* or that all [[Determinants]] and sub-determinants are positive 



Checking using positiveness of eigenvalues:
* if for all $\mathbf v$, $\mathbf v^T A \, \mathbf v &gt; 0$, 
* $A \mathbf v = \lambda \mathbf v$, multiply by $\mathbf v^T$ on the left
* $\mathbf v^T A \, \mathbf v = \lambda \mathbf v^T \mathbf v$
* $\mathbf v^T A \, \mathbf v = \lambda \| \mathbf v \|^2$
* $\| \mathbf v \|^2$ is always positive, so it means that if $\lambda &gt; 0$, then so is $\mathbf v^T A \, \mathbf v$
* therefore we can check if all eigenvalues are positive 



== Properties ==
=== Sum ===
If $A$ and $B$ are both PDM
* then so is $A + B$
* because the energies add when we add matrices:
* $\mathbf v^T A \, \mathbf v + \mathbf v^T B \, \mathbf v$


=== Inverse ===
* if $A$ is PDM, the inverse is also PDM
* eigenvalues of the inverse are $\lambda^*_i = \frac{1}{\lambda_i}$
* so eigenvalues are also positive
* but careful with semi-positive definite matrices: they do not have an inverse!



=== $R^T R$ and $R R^T$ Matrices ===
They are always semi-positive definite
* see [[Gram Matrices]]





== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Jauregui, Jeff. &quot;Principal component analysis with linear algebra.&quot; (2012). [http://www.math.union.edu/~jaureguj/PCA.pdf]

[[Category:Linear Algebra]]</text>
      <sha1>54ib68dik8rlg25ehirgprwk71vg4ez</sha1>
    </revision>
    <revision>
      <id>664</id>
      <parentid>557</parentid>
      <timestamp>2015-11-13T21:08:56Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5797">== Positive-Definite Matrices ==
=== Energy-Based Definition ===
In [[Linear Algebra]], a matrix an $n \times n$ matrix is Positive-definite matrix (PDM) if 
* $\mathbf v^T A \mathbf v &gt; 0$ for all $\mathbf v \in \mathbb R^n$
* This is the energy based definition


Why ''energy''?
* because $\mathbf v^T A \mathbf v$ or $\frac{1}{2} \mathbf v^T A \mathbf v$ is called the ''energy'' of the system $A$


== Positive Semi-Definite Matrices ==
* A matrix is semi-positive definite if 
* $\mathbf v^T A \mathbf v \geqslant 0$ for all $\mathbf v \ne \mathbf 0 \in \mathbb R^n$ 
* so some eigenvectors can be 0


== Motivating Example ==
* Let &lt;math&gt;A = \begin{bmatrix} 
2 &amp; 6 \\
6 &amp; 18 \\
\end{bmatrix}&lt;/math&gt;
* then for any $\mathbf x = (x_1, x_2)$ we want to check 
* &lt;math&gt;\big[x_1 \ x_2 \big] \begin{bmatrix} 
2 &amp; 6 \\
6 &amp; 18 \\
\end{bmatrix} \begin{bmatrix} 
x_1 \\
x_2 \\
\end{bmatrix} = 2 \, x_1^2 + 12 \, x_1 x_2 + 18 \, x_2^2&lt;/math&gt;
* note that this is not a linear anymore: 
* we have an equation $a x_1^2 + 2b \, x_1 x_2 + c \, x_2^2$
* this is a [[Quadratic Form]] 
* we want to know if this quantity is always positive or not 
* are there such $x_1, x_2$ that $a x_1^2 + 2b \, x_1 x_2 + c \, x_2^2 &lt; 0$?

So we have a function $f(\mathbf x) = \mathbf x^T A \, \mathbf x$ and we want to check if it's always positive for any $\mathbf x$


Another example
* let &lt;math&gt;A_1 = \begin{bmatrix} 
2 &amp; 6 \\
6 &amp; 7 \\
\end{bmatrix}&lt;/math&gt;
* then $f(\mathbf x) = \mathbf x^T A_1 \, \mathbf x = 2 x_1^2 + 12 x_1 x_2 + 7 x_2^2$
* there exists $\mathbf x$ such that $f(\mathbf x) &lt; 0$, e.g. $(1, -1)$
* in this system, there's a [[Saddle Point]] - a max for one direction and min for another
* http://habrastorage.org/files/806/5cd/ad5/8065cdad5e2c4642bc8a9b74feb907d9.png


Consider an alternative:
* &lt;math&gt;A_2  = \begin{bmatrix} 
2 &amp; 6 \\
6 &amp; 20 \\
\end{bmatrix}&lt;/math&gt;
* $f(\mathbf x) = \mathbf x^T A_2 \, \mathbf x = 2 x_1^2 + 12 x_1 x_2 + 20 x_2^2$
* here squares always overwhelm $12 x_1 x_2$
* http://habrastorage.org/files/07a/cbc/a56/07acbca564ff4962993cf450951146bf.png


We say that $A_1$ is ''indefinite'', and $A_2$ is ''positive-definite''


&lt;img src=&quot;http://brickisland.net/cs177/wp-content/uploads/2011/11/ddg_definiteness.svg&quot; /&gt;

Source: [http://brickisland.net/cs177fa12/?p=302]


=== Finding Minima ===
Recall from [[Calculus]]:
* 1st [[Derivative]] is needed for finding extremum, but you don't know if it's min or max
* so you have to look for the 2nd derivative to learn if it's positive or negative
* you want to find $\cfrac{du}{dx} = 0$ and $\cfrac{d^2 \, u}{d \, x^2} &gt; 0$

Consider $A_2$ again:
* $f(\mathbf x) = \mathbf x^T A_1 \, \mathbf x = 2 x_1^2 + 12 x_1 x_2 + 20 x_2^2$
* Let's complete the square: $2 \, (x_1 + 3 \, x_2)^2 + 2 \, x_2^2$
* now it's easy to see that this function is indeed always positive: we completed the square and there are no negative terms

What about $A_1$?
* $f(\mathbf x) = \mathbf x^T A_1 \, \mathbf x = 2 x_1^2 + 12 x_1 x_2 + 7 x_2^2$
* let's try to complete the square: $2 \, (x_1 + 3 \, x_2)^2 - 11 \, x_2^2$
* we have a minus!


=== Matrix vs Function ===
Let's have a look again at $A_2$:
* $f(\mathbf x) = \mathbf x^T A_1 \, \mathbf x = 2 x_1^2 + 12 x_1 x_2 + 20 x_2^2 = 2 \, (x_1 + 3 \, x_2)^2 + 2 \, x_2^2$
* the numbers in the completed square form come from [[Gaussian Elimination]]!
* Let's do $A = LU$ transformation:
** &lt;math&gt;L = \begin{bmatrix} 
1 &amp; 0 \\
3 &amp; 1 \\
\end{bmatrix}, U = \begin{bmatrix} 
\boxed 2 &amp; 6 \\
0 &amp; \boxed 2 \\
\end{bmatrix}&lt;/math&gt;
* multipliers before squares come from pivots of $U$: 
** $\boxed{2} \, (x_1 + 3 \, x_2)^2 + \boxed 2 \, x_2^2$
* coefficients inside each square come from $L$
** $2 \, (1 \, x_1 + 3 \, x_2)^2 + 2 \, (0\, x_1 + 1 \, x_2)^2$
* so positive pivots of $U$ are good


=== Derivative Matrix ===
So a matrix of second derivatives ([[Hessian Matrix]]) is
* &lt;math&gt;\begin{bmatrix} 
\cfrac{\partial x_1^2}{\partial^2 x_1} &amp; \cfrac{\partial x_1 \partial x_2}{\partial x_1 \partial x_2} \\
\cfrac{\partial x_2 \partial x_1}{\partial x_2 \partial x_1} &amp; \cfrac{\partial x_2^2}{\partial^2 x_2} \\
\end{bmatrix}&lt;/math&gt;
* we want it to be positive-definite
* then the function $f(\mathbf x) = \mathbf x^T A \, \mathbf x$ is positive-definite


== Checking for Positiveness ==
So, how to check for positive definitiveness? 
* using the definition: check that $\mathbf v^T A \mathbf v &gt; 0$ for all $\mathbf v$
* check that all eigenvalues are positive
* or that all pivots of $L$ in $A = LU$ are positive
* or that all [[Determinants]] and sub-determinants are positive 



Checking using positiveness of eigenvalues:
* if for all $\mathbf v$, $\mathbf v^T A \, \mathbf v &gt; 0$, 
* $A \mathbf v = \lambda \mathbf v$, multiply by $\mathbf v^T$ on the left
* $\mathbf v^T A \, \mathbf v = \lambda \mathbf v^T \mathbf v$
* $\mathbf v^T A \, \mathbf v = \lambda \| \mathbf v \|^2$
* $\| \mathbf v \|^2$ is always positive, so it means that if $\lambda &gt; 0$, then so is $\mathbf v^T A \, \mathbf v$
* therefore we can check if all eigenvalues are positive 



== Properties ==
=== Sum ===
If $A$ and $B$ are both PDM
* then so is $A + B$
* because the energies add when we add matrices:
* $\mathbf v^T A \, \mathbf v + \mathbf v^T B \, \mathbf v$


=== Inverse ===
* if $A$ is PDM, the inverse is also PDM
* eigenvalues of the inverse are $\lambda^*_i = \frac{1}{\lambda_i}$
* so eigenvalues are also positive
* but careful with semi-positive definite matrices: they do not have an inverse!


=== $R^T R$ and $R R^T$ Matrices ===
They are always semi-positive definite
* see [[Gram Matrices]]



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Jauregui, Jeff. &quot;Principal component analysis with linear algebra.&quot; (2012). [http://www.math.union.edu/~jaureguj/PCA.pdf]

[[Category:Linear Algebra]]</text>
      <sha1>c64fuv4y79i7pvis1q4e7efmgv1f7id</sha1>
    </revision>
  </page>
  <page>
    <title>Four Fundamental Subspaces</title>
    <ns>0</ns>
    <id>555</id>
    <revision>
      <id>558</id>
      <timestamp>2015-04-25T15:00:17Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2575">== Four Fundamental Subspaces ==
A matrix $A$ has four subspaces: 
* [[Column Space]] $C(A)$
* [[Nullspace]] $N(A)$
* [[Row Space]] $C(A^T)$ of $A$ is the same as Column Space of $A^T$
* Nullspace of $A^T$ (also called &quot;Left Nullspace&quot;)


&lt;img width=&quot;40%&quot; src=&quot;http://alexeygrigorev.com/projects/imsem-ws14-lina/img-svg/diagram0.svg&quot; /&gt;


== Some Properties ==
Suppose we have an $m \times n$ matrix of rank $r$ 

=== [[Orthogonality]] ===
* Nullspace of $A$ is orthogonal to the row space: $N(A) \; \bot \; C(A^T)$
* Left nullspace of $A$ is orthogonal to the column space:  $N(A^T) \; \bot \; C(A)$
* see the proof in [[Space Orthogonality#Row space and Nullspace]]


=== [[Column Space]] ===
* $\text{dim } C(A) = r$, there are $r$ pivot columns
* basis: columns of $A$ 


=== [[Row Space]] ===
* $\text{dim } C(A^T) = r = \text{dim } C(A)$, there are $r$ pivot rows - the same dim as for Column Space
* Let $R$ be [[Row Reduced Echelon Form]] of $A$, then $C(A^T) = C(R^T)$
* basis: first $r$ rows of $R$


=== [[Nullspace]] ===
* $\text{dim } N(A) = n - r$ - the number of free variables
* basis: special solutions for [[Homogeneous Systems of Linear Equations|$A\mathbf x = \mathbf 0$]]


=== [[Nullspace#Left Nullspace|Left Nullspace]] ===
* This is the nullspace of $A^T$ ($A^T$ is $n \times m$ matrix of rank $r$)
* $\text{dim } N(A^T) = m - r$ - there are $m$ columns, $m$ variables, and $m - r$ free variables


== [[Singular Value Decomposition]] ==
We know how to find the basis for all the subspaces
* e.g. from using [[Gaussian Elimination]] transform the matrix to the echelon form and find them
* but these bases are not &quot;perfect&quot;. We want to use [[Orthogonal Vectors]] instead


SVD finds these bases:
* if $A V = U \Sigma$ then
* $\mathbf v_1, \ ... \ , \mathbf v_r$ is the basis for the row space $C(A^T)$
* $\mathbf v_{r+1}, \ ... \ , \mathbf v_{n}$ is the basis for the nullspace $N(A)$
* $\mathbf u_1, \ ... \ , \mathbf u_r$ is the basis for the column space $C(A)$
* $\mathbf u_{r+1}, \ ... \ , \mathbf u_{m}$ is the basis for the left nullspace $N(A^T)$


&lt;img width=&quot;50%&quot; src=&quot;http://alexeygrigorev.com/projects/imsem-ws14-lina/img-svg/diagram3-svd.svg&quot; /&gt;




== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* The fundamental theorem of linear algebra, G. Strang [http://www.engineering.iastate.edu/~julied/classes/CE570/Notes/strangpaper.pdf]
* The Four Fundamental Subspaces: 4 Lines, G. Strang, [http://web.mit.edu/18.06/www/Essays/newpaper_ver3.pdf]
* [[Seminar Hot Topics in Information Management IMSEM (TUB)]]

[[Category:Linear Algebra]]</text>
      <sha1>3rg25mqmy7a49uxnd1hb4zod2s1tjl9</sha1>
    </revision>
    <revision>
      <id>786</id>
      <parentid>558</parentid>
      <timestamp>2017-06-27T10:43:08Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3180">== Four Fundamental Subspaces ==
A matrix $A$ has four subspaces: 
* [[Column Space]] $C(A)$ or $\text{ran}(A)$: Range of $A$
* [[Nullspace]] $N(A)$ or $\text{null}(A)$
* [[Row Space]] $C(A^T)$ of $A$ is the same as Column Space of $A^T$
* Nullspace of $A^T$ (also called &quot;Left Nullspace&quot;)


&lt;img width=&quot;40%&quot; src=&quot;http://alexeygrigorev.com/projects/imsem-ws14-lina/img-svg/diagram0.svg&quot; /&gt;


== Some Properties ==
Suppose we have an $m \times n$ matrix of rank $r$ 

=== [[Orthogonality]] ===
* Nullspace of $A$ is orthogonal to the row space: $N(A) \; \bot \; C(A^T)$
* Left nullspace of $A$ is orthogonal to the column space:  $N(A^T) \; \bot \; C(A)$
* see the proof in [[Space Orthogonality#Row space and Nullspace]]


== The Four Spaces ==
=== [[Column Space]] ===
* $\text{dim } C(A) = r$, there are $r$ pivot columns
* basis: columns of $A$ 
* also called &quot;range&quot;
* $\text{ran}(A) = \{ \mathbf y \in \mathbb R^m \ : \ \mathbf y = A \mathbf x \ \forall \mathbf x \in \mathbb R^n   \}$
* if we think about [[Linear Transformation]] $T_{A}$ formed by $A$, this is what it does to an $n$-dimensional vector $\mathbf x$: it brings it to an $m$-dinesional vector $\mathbf y$
* all such vectors $\mathbf y$ form the column space of $A$


=== [[Row Space]] ===
* $\text{dim } C(A^T) = r = \text{dim } C(A)$, there are $r$ pivot rows - the same dim as for Column Space
* Let $R$ be [[Row Reduced Echelon Form]] of $A$, then $C(A^T) = C(R^T)$
* basis: first $r$ rows of $R$


=== [[Nullspace]] ===
* $\text{dim } N(A) = n - r$ - the number of free variables
* basis: special solutions for [[Homogeneous Systems of Linear Equations|$A\mathbf x = \mathbf 0$]]
* $N(A) = \text{null}(A) = \{ \mathbf x \in \mathbb R^n \ : \ A \mathbf x = \mathbf 0 \}$


=== [[Nullspace#Left Nullspace|Left Nullspace]] ===
* This is the nullspace of $A^T$ ($A^T$ is $n \times m$ matrix of rank $r$)
* $\text{dim } N(A^T) = m - r$ - there are $m$ columns, $m$ variables, and $m - r$ free variables


== [[Singular Value Decomposition]] ==
We know how to find the basis for all the subspaces
* e.g. from using [[Gaussian Elimination]] transform the matrix to the echelon form and find them
* but these bases are not &quot;perfect&quot;. We want to use [[Space Orthogonality|Orthogonal Vectors]] instead


SVD finds these bases:
* if $A V = U \Sigma$ then
* $\mathbf v_1, \ ... \ , \mathbf v_r$ is the basis for the row space $C(A^T)$
* $\mathbf v_{r+1}, \ ... \ , \mathbf v_{n}$ is the basis for the nullspace $N(A)$
* $\mathbf u_1, \ ... \ , \mathbf u_r$ is the basis for the column space $C(A)$
* $\mathbf u_{r+1}, \ ... \ , \mathbf u_{m}$ is the basis for the left nullspace $N(A^T)$


&lt;img width=&quot;50%&quot; src=&quot;http://alexeygrigorev.com/projects/imsem-ws14-lina/img-svg/diagram3-svd.svg&quot; /&gt;




== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* The fundamental theorem of linear algebra, G. Strang [http://www.engineering.iastate.edu/~julied/classes/CE570/Notes/strangpaper.pdf]
* The Four Fundamental Subspaces: 4 Lines, G. Strang, [http://web.mit.edu/18.06/www/Essays/newpaper_ver3.pdf]
* [[Seminar Hot Topics in Information Management IMSEM (TUB)]]
* [[Matrix Computations (book)]]

[[Category:Linear Algebra]]</text>
      <sha1>6n4235okrcgjpvwb7hi0uuenk31pexc</sha1>
    </revision>
  </page>
  <page>
    <title>OLS Regression</title>
    <ns>0</ns>
    <id>556</id>
    <revision>
      <id>559</id>
      <timestamp>2015-04-25T19:31:55Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4608">== Ordinary Least Squares Regression ==
* This is a technique for computing coefficients for [[Multivariate Linear Regression]].
* the solution is obtained via minimizing the squared error, therefore it's called ''Linear Least Squares''
* two solutions: [[Normal Equation]] and [[Gradient Descent]]
* this is the the typical way of solving the [[Multivariate Linear Regression]], therefore it's often called '''OLS Regression'''


== Regression Problem ==
Suppose we have
* $m$ training examples $(\mathbf x_i, y_i)$
* $n$ features, $\mathbf x_i = \big[x_{i1}, \ ... \ , x_{in} \big]^T \in \mathbb{R}^n$
* We can put all such $\mathbf x_i$ as rows of a matrix $X$ (sometimes called a ''design matrix'')
* $X = \begin{bmatrix}
- \ \mathbf x_1^T - \\ 
  \vdots  \\ 
- \ \mathbf x_m^T -   \\ 
\end{bmatrix} = \begin{bmatrix}
x_{11} &amp; \cdots &amp; x_{1n}  \\ 
 &amp;  \ddots &amp;  \\ 
x_{m1} &amp; \cdots &amp; x_{mn}  \\ 
\end{bmatrix}$
* the observed values: $\mathbf y = \begin{bmatrix}
y_1 \\ \vdots \\ y_m
\end{bmatrix} \in \mathbb{R}^{m}$
* Thus, we expressed our problem in the matrix form: $X \mathbf w = \mathbf y$
* Note that there's usually additional feature $x_{i0} = 1$ - the slope, 
** so $\mathbf x_i \in \mathbb{R}^{n+1}$ and $X = \begin{bmatrix}
- \ \mathbf x_1^T - \\ 
- \ \mathbf x_2^T - \\ 
 \vdots  \\ 
- \ \mathbf x_m^T -   \\ 
\end{bmatrix} = \begin{bmatrix}
x_{10} &amp; x_{11} &amp; \cdots &amp; x_{1n}  \\ 
x_{20} &amp; x_{21} &amp; \cdots &amp; x_{2n}  \\ 
 &amp; &amp;  \ddots &amp;  \\ 
x_{m0} &amp; x_{m1} &amp; \cdots &amp; x_{mn}  \\ 
\end{bmatrix} \in \mathbb R^{m \times n + 1}$


Thus we have a system 
* $X \mathbf w = \mathbf y$
* how do we solve it, and if there's no solution, how do we find the best possible $\mathbf w$?



== Least Squares ==
=== Normal Equation ===
There's no solution to the system, so we try to fit the data as good as possible 
* Let $\mathbf w$ be the best fit solution to $X \mathbf w \approx \mathbf y$
* we'll try to minimize the error $\mathbf e = \mathbf y - X \mathbf w$ (also called [[Residual Analysis|residuals]])
* we take the square of this error, so the objective is 
* $J(\mathbf w) = \| \mathbf e \|^2 = \| \mathbf y - X \mathbf w \|^2$


The solution:
* $\mathbf w = (X^T X)^{-1} X^T \mathbf y = X^+ \mathbf y$ 
* where $X^+ = (X^T X)^{-1} X^T$ is the [[General Inverse|Pseudoinverse]] of $X$


From the [[Linear Algebra]] point of view:
* we need to solve $X \mathbf w = \mathbf y$
* if $\mathbf y \not \in C(X)$ ([[Column Space]]) then there's no solution
* How to solve it approximately? [[Projection onto Subspaces|Project]] on $C(A)$!
* again, it gives us the [[Normal Equation]]: $X^T X \mathbf w = X^T \mathbf y$


=== [[Gradient Descent]] ===
Alternatively, we can use Gradient Descent:
* objective is $J(\mathbf w) = \| \mathbf y - X \mathbf w \|^2$
* the derivative w.r.t. $\mathbf w$ is $\cfrac{\partial J(\mathbf w)}{\partial \mathbf w} = 2 X^T X \mathbf w - 2 X^T \mathbf y$
* so the update rule is $\mathbf w \leftarrow \mathbf w - \alpha 2 (X^T X \mathbf w - X^T \mathbf y)$
* where $\alpha$ is the learning rate



== Example ==
Suppose we have the following dataset: 
* ${\cal D} = \{ (1,1), (2,2), (3,2) \}$
* the matrix form is $\begin{bmatrix}
1 &amp; 1\\ 
1 &amp; 2\\ 
1 &amp; 3\\
\end{bmatrix}
\begin{bmatrix}
w_0 \\ w_1
\end{bmatrix} = 
\begin{bmatrix} 
1 \\ 2 \\ 2
\end{bmatrix}$
* no line goes through these points at once
* so we solve $X^T X \mathbf{\hat w} = X^T \mathbf y$ 
* $\begin{bmatrix}
1 &amp; 1 &amp; 1 \\ 
1 &amp; 2 &amp; 3 \\ 
\end{bmatrix} \begin{bmatrix}
1 &amp; 1\\ 
1 &amp; 2\\ 
1 &amp; 3\\
\end{bmatrix} = \begin{bmatrix}
3 &amp; 6\\ 
6 &amp; 14\\
\end{bmatrix}$
* this system is invertible, so we solve it and get $\hat w_0 = 2/3, \hat w_1 = 1/2$
* thus the best line is $h(t) = w_0 + w_1 t = 2/3 + 1/2 t$


http://habrastorage.org/files/ae0/b63/5a2/ae0b635a2e81493bb363d898b0e6369c.png



== Normal Equation vs [[Gradient Descent]] ==
[[Gradient Descent]]:
* need to choose learning rate $\alpha$
* need to do many iterations
* works well with large $n$


[[Normal Equation]]:
* don't need to choose $\alpha$
* don't need to iterate - computed in one step
* slow if $n$ is large $(n \geqslant 10^4)$
* need to compute $(X^T X)^{-1}$ - very slow
* if $(X^T X)$ is not-invertible - we have problems


== See Also ==
* [[Multivariate Linear Regression]]
* [[Gradient Descent]]


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* [[Machine Learning (coursera)]]
* [[Seminar Hot Topics in Information Management IMSEM (TUB)]]
* http://en.wikipedia.org/wiki/Linear_least_squares_%28mathematics%29


[[Category:Machine Learning]]
[[Category:Regression]]
[[Category:Linear Algebra]]
[[Category:Statistics]]</text>
      <sha1>1qmibynhfjqsz7bfx556c0vyrq1fk9d</sha1>
    </revision>
    <revision>
      <id>792</id>
      <parentid>559</parentid>
      <timestamp>2017-06-27T12:03:43Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <comment>Alexey moved page [[OLS Regression]] to [[Ordinary Least Squares]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4608">== Ordinary Least Squares Regression ==
* This is a technique for computing coefficients for [[Multivariate Linear Regression]].
* the solution is obtained via minimizing the squared error, therefore it's called ''Linear Least Squares''
* two solutions: [[Normal Equation]] and [[Gradient Descent]]
* this is the the typical way of solving the [[Multivariate Linear Regression]], therefore it's often called '''OLS Regression'''


== Regression Problem ==
Suppose we have
* $m$ training examples $(\mathbf x_i, y_i)$
* $n$ features, $\mathbf x_i = \big[x_{i1}, \ ... \ , x_{in} \big]^T \in \mathbb{R}^n$
* We can put all such $\mathbf x_i$ as rows of a matrix $X$ (sometimes called a ''design matrix'')
* $X = \begin{bmatrix}
- \ \mathbf x_1^T - \\ 
  \vdots  \\ 
- \ \mathbf x_m^T -   \\ 
\end{bmatrix} = \begin{bmatrix}
x_{11} &amp; \cdots &amp; x_{1n}  \\ 
 &amp;  \ddots &amp;  \\ 
x_{m1} &amp; \cdots &amp; x_{mn}  \\ 
\end{bmatrix}$
* the observed values: $\mathbf y = \begin{bmatrix}
y_1 \\ \vdots \\ y_m
\end{bmatrix} \in \mathbb{R}^{m}$
* Thus, we expressed our problem in the matrix form: $X \mathbf w = \mathbf y$
* Note that there's usually additional feature $x_{i0} = 1$ - the slope, 
** so $\mathbf x_i \in \mathbb{R}^{n+1}$ and $X = \begin{bmatrix}
- \ \mathbf x_1^T - \\ 
- \ \mathbf x_2^T - \\ 
 \vdots  \\ 
- \ \mathbf x_m^T -   \\ 
\end{bmatrix} = \begin{bmatrix}
x_{10} &amp; x_{11} &amp; \cdots &amp; x_{1n}  \\ 
x_{20} &amp; x_{21} &amp; \cdots &amp; x_{2n}  \\ 
 &amp; &amp;  \ddots &amp;  \\ 
x_{m0} &amp; x_{m1} &amp; \cdots &amp; x_{mn}  \\ 
\end{bmatrix} \in \mathbb R^{m \times n + 1}$


Thus we have a system 
* $X \mathbf w = \mathbf y$
* how do we solve it, and if there's no solution, how do we find the best possible $\mathbf w$?



== Least Squares ==
=== Normal Equation ===
There's no solution to the system, so we try to fit the data as good as possible 
* Let $\mathbf w$ be the best fit solution to $X \mathbf w \approx \mathbf y$
* we'll try to minimize the error $\mathbf e = \mathbf y - X \mathbf w$ (also called [[Residual Analysis|residuals]])
* we take the square of this error, so the objective is 
* $J(\mathbf w) = \| \mathbf e \|^2 = \| \mathbf y - X \mathbf w \|^2$


The solution:
* $\mathbf w = (X^T X)^{-1} X^T \mathbf y = X^+ \mathbf y$ 
* where $X^+ = (X^T X)^{-1} X^T$ is the [[General Inverse|Pseudoinverse]] of $X$


From the [[Linear Algebra]] point of view:
* we need to solve $X \mathbf w = \mathbf y$
* if $\mathbf y \not \in C(X)$ ([[Column Space]]) then there's no solution
* How to solve it approximately? [[Projection onto Subspaces|Project]] on $C(A)$!
* again, it gives us the [[Normal Equation]]: $X^T X \mathbf w = X^T \mathbf y$


=== [[Gradient Descent]] ===
Alternatively, we can use Gradient Descent:
* objective is $J(\mathbf w) = \| \mathbf y - X \mathbf w \|^2$
* the derivative w.r.t. $\mathbf w$ is $\cfrac{\partial J(\mathbf w)}{\partial \mathbf w} = 2 X^T X \mathbf w - 2 X^T \mathbf y$
* so the update rule is $\mathbf w \leftarrow \mathbf w - \alpha 2 (X^T X \mathbf w - X^T \mathbf y)$
* where $\alpha$ is the learning rate



== Example ==
Suppose we have the following dataset: 
* ${\cal D} = \{ (1,1), (2,2), (3,2) \}$
* the matrix form is $\begin{bmatrix}
1 &amp; 1\\ 
1 &amp; 2\\ 
1 &amp; 3\\
\end{bmatrix}
\begin{bmatrix}
w_0 \\ w_1
\end{bmatrix} = 
\begin{bmatrix} 
1 \\ 2 \\ 2
\end{bmatrix}$
* no line goes through these points at once
* so we solve $X^T X \mathbf{\hat w} = X^T \mathbf y$ 
* $\begin{bmatrix}
1 &amp; 1 &amp; 1 \\ 
1 &amp; 2 &amp; 3 \\ 
\end{bmatrix} \begin{bmatrix}
1 &amp; 1\\ 
1 &amp; 2\\ 
1 &amp; 3\\
\end{bmatrix} = \begin{bmatrix}
3 &amp; 6\\ 
6 &amp; 14\\
\end{bmatrix}$
* this system is invertible, so we solve it and get $\hat w_0 = 2/3, \hat w_1 = 1/2$
* thus the best line is $h(t) = w_0 + w_1 t = 2/3 + 1/2 t$


http://habrastorage.org/files/ae0/b63/5a2/ae0b635a2e81493bb363d898b0e6369c.png



== Normal Equation vs [[Gradient Descent]] ==
[[Gradient Descent]]:
* need to choose learning rate $\alpha$
* need to do many iterations
* works well with large $n$


[[Normal Equation]]:
* don't need to choose $\alpha$
* don't need to iterate - computed in one step
* slow if $n$ is large $(n \geqslant 10^4)$
* need to compute $(X^T X)^{-1}$ - very slow
* if $(X^T X)$ is not-invertible - we have problems


== See Also ==
* [[Multivariate Linear Regression]]
* [[Gradient Descent]]


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* [[Machine Learning (coursera)]]
* [[Seminar Hot Topics in Information Management IMSEM (TUB)]]
* http://en.wikipedia.org/wiki/Linear_least_squares_%28mathematics%29


[[Category:Machine Learning]]
[[Category:Regression]]
[[Category:Linear Algebra]]
[[Category:Statistics]]</text>
      <sha1>1qmibynhfjqsz7bfx556c0vyrq1fk9d</sha1>
    </revision>
    <revision>
      <id>794</id>
      <parentid>792</parentid>
      <timestamp>2017-06-27T12:06:30Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4663">== Ordinary Least Squares Regression ==
* This is a technique for computing coefficients for [[Multivariate Linear Regression]].
* the solution is obtained via minimizing the squared error, therefore it's called ''Linear Least Squares''
* two solutions: [[Normal Equation]] and [[Gradient Descent]]
* this is the the typical way of solving the [[Multivariate Linear Regression]], therefore it's often called '''OLS Regression'''


== Regression Problem ==
Suppose we have
* $m$ training examples $(\mathbf x_i, y_i)$
* $n$ features, $\mathbf x_i = \big[x_{i1}, \ ... \ , x_{in} \big]^T \in \mathbb{R}^n$
* We can put all such $\mathbf x_i$ as rows of a matrix $X$ (sometimes called a ''design matrix'')
* &lt;math&gt;X = \begin{bmatrix}
- \ \mathbf x_1^T - \\ 
  \vdots  \\ 
- \ \mathbf x_m^T -   \\ 
\end{bmatrix} = \begin{bmatrix}
x_{11} &amp; \cdots &amp; x_{1n}  \\ 
 &amp;  \ddots &amp;  \\ 
x_{m1} &amp; \cdots &amp; x_{mn}  \\ 
\end{bmatrix}&lt;/math&gt;
* the observed values: &lt;math&gt;\mathbf y = \begin{bmatrix}
y_1 \\ \vdots \\ y_m
\end{bmatrix} \in \mathbb{R}^{m}&lt;/math&gt;
* Thus, we expressed our problem in the matrix form: $X \mathbf w = \mathbf y$
* Note that there's usually additional feature $x_{i0} = 1$ - the slope, 
** so $\mathbf x_i \in \mathbb{R}^{n+1}$ and &lt;math&gt;X = \begin{bmatrix}
- \ \mathbf x_1^T - \\ 
- \ \mathbf x_2^T - \\ 
 \vdots  \\ 
- \ \mathbf x_m^T -   \\ 
\end{bmatrix} = \begin{bmatrix}
x_{10} &amp; x_{11} &amp; \cdots &amp; x_{1n}  \\ 
x_{20} &amp; x_{21} &amp; \cdots &amp; x_{2n}  \\ 
 &amp; &amp;  \ddots &amp;  \\ 
x_{m0} &amp; x_{m1} &amp; \cdots &amp; x_{mn}  \\ 
\end{bmatrix} \in \mathbb R^{m \times n + 1}&lt;/math&gt;


Thus we have a system 
* $X \mathbf w = \mathbf y$
* how do we solve it, and if there's no solution, how do we find the best possible $\mathbf w$?



== Least Squares ==
=== Normal Equation ===
There's no solution to the system, so we try to fit the data as good as possible 
* Let $\mathbf w$ be the best fit solution to $X \mathbf w \approx \mathbf y$
* we'll try to minimize the error $\mathbf e = \mathbf y - X \mathbf w$ (also called [[Residual Analysis|residuals]])
* we take the square of this error, so the objective is 
* $J(\mathbf w) = \| \mathbf e \|^2 = \| \mathbf y - X \mathbf w \|^2$


The solution:
* $\mathbf w = (X^T X)^{-1} X^T \mathbf y = X^+ \mathbf y$ 
* where $X^+ = (X^T X)^{-1} X^T$ is the [[General Inverse|Pseudoinverse]] of $X$


From the [[Linear Algebra]] point of view:
* we need to solve $X \mathbf w = \mathbf y$
* if $\mathbf y \not \in C(X)$ ([[Column Space]]) then there's no solution
* How to solve it approximately? [[Projection onto Subspaces|Project]] on $C(A)$!
* again, it gives us the [[Normal Equation]]: $X^T X \mathbf w = X^T \mathbf y$


=== [[Gradient Descent]] ===
Alternatively, we can use Gradient Descent:
* objective is $J(\mathbf w) = \| \mathbf y - X \mathbf w \|^2$
* the derivative w.r.t. $\mathbf w$ is $\cfrac{\partial J(\mathbf w)}{\partial \mathbf w} = 2 X^T X \mathbf w - 2 X^T \mathbf y$
* so the update rule is $\mathbf w \leftarrow \mathbf w - \alpha 2 (X^T X \mathbf w - X^T \mathbf y)$
* where $\alpha$ is the learning rate



== Example ==
Suppose we have the following dataset: 
* ${\cal D} = \{ (1,1), (2,2), (3,2) \}$
* the matrix form is &lt;math&gt;\begin{bmatrix}
1 &amp; 1\\ 
1 &amp; 2\\ 
1 &amp; 3\\
\end{bmatrix}
\begin{bmatrix}
w_0 \\ w_1
\end{bmatrix} = 
\begin{bmatrix} 
1 \\ 2 \\ 2
\end{bmatrix}&lt;/math&gt;
* no line goes through these points at once
* so we solve $X^T X \mathbf{\hat w} = X^T \mathbf y$ 
* &lt;math&gt;\begin{bmatrix}
1 &amp; 1 &amp; 1 \\ 
1 &amp; 2 &amp; 3 \\ 
\end{bmatrix} \begin{bmatrix}
1 &amp; 1\\ 
1 &amp; 2\\ 
1 &amp; 3\\
\end{bmatrix} = \begin{bmatrix}
3 &amp; 6\\ 
6 &amp; 14\\
\end{bmatrix}&lt;/math&gt;
* this system is invertible, so we solve it and get $\hat w_0 = 2/3, \hat w_1 = 1/2$
* thus the best line is $h(t) = w_0 + w_1 t = 2/3 + 1/2 t$


http://habrastorage.org/files/ae0/b63/5a2/ae0b635a2e81493bb363d898b0e6369c.png



== Normal Equation vs [[Gradient Descent]] ==
[[Gradient Descent]]:
* need to choose learning rate $\alpha$
* need to do many iterations
* works well with large $n$


[[Normal Equation]]:
* don't need to choose $\alpha$
* don't need to iterate - computed in one step
* slow if $n$ is large $(n \geqslant 10^4)$
* need to compute $(X^T X)^{-1}$ - very slow
* if $(X^T X)$ is not-invertible - we have problems


== See Also ==
* [[Multivariate Linear Regression]]
* [[Gradient Descent]]


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* [[Machine Learning (coursera)]]
* [[Seminar Hot Topics in Information Management IMSEM (TUB)]]
* http://en.wikipedia.org/wiki/Linear_least_squares_%28mathematics%29


[[Category:Machine Learning]]
[[Category:Regression]]
[[Category:Linear Algebra]]
[[Category:Statistics]]</text>
      <sha1>ng7av0bjnr7hxlmb0byrub0m7h9ffyu</sha1>
    </revision>
    <revision>
      <id>796</id>
      <parentid>794</parentid>
      <timestamp>2017-06-27T12:16:42Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <comment>Alexey moved page [[Ordinary Least Squares]] to [[OLS Regression]] over redirect</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4663">== Ordinary Least Squares Regression ==
* This is a technique for computing coefficients for [[Multivariate Linear Regression]].
* the solution is obtained via minimizing the squared error, therefore it's called ''Linear Least Squares''
* two solutions: [[Normal Equation]] and [[Gradient Descent]]
* this is the the typical way of solving the [[Multivariate Linear Regression]], therefore it's often called '''OLS Regression'''


== Regression Problem ==
Suppose we have
* $m$ training examples $(\mathbf x_i, y_i)$
* $n$ features, $\mathbf x_i = \big[x_{i1}, \ ... \ , x_{in} \big]^T \in \mathbb{R}^n$
* We can put all such $\mathbf x_i$ as rows of a matrix $X$ (sometimes called a ''design matrix'')
* &lt;math&gt;X = \begin{bmatrix}
- \ \mathbf x_1^T - \\ 
  \vdots  \\ 
- \ \mathbf x_m^T -   \\ 
\end{bmatrix} = \begin{bmatrix}
x_{11} &amp; \cdots &amp; x_{1n}  \\ 
 &amp;  \ddots &amp;  \\ 
x_{m1} &amp; \cdots &amp; x_{mn}  \\ 
\end{bmatrix}&lt;/math&gt;
* the observed values: &lt;math&gt;\mathbf y = \begin{bmatrix}
y_1 \\ \vdots \\ y_m
\end{bmatrix} \in \mathbb{R}^{m}&lt;/math&gt;
* Thus, we expressed our problem in the matrix form: $X \mathbf w = \mathbf y$
* Note that there's usually additional feature $x_{i0} = 1$ - the slope, 
** so $\mathbf x_i \in \mathbb{R}^{n+1}$ and &lt;math&gt;X = \begin{bmatrix}
- \ \mathbf x_1^T - \\ 
- \ \mathbf x_2^T - \\ 
 \vdots  \\ 
- \ \mathbf x_m^T -   \\ 
\end{bmatrix} = \begin{bmatrix}
x_{10} &amp; x_{11} &amp; \cdots &amp; x_{1n}  \\ 
x_{20} &amp; x_{21} &amp; \cdots &amp; x_{2n}  \\ 
 &amp; &amp;  \ddots &amp;  \\ 
x_{m0} &amp; x_{m1} &amp; \cdots &amp; x_{mn}  \\ 
\end{bmatrix} \in \mathbb R^{m \times n + 1}&lt;/math&gt;


Thus we have a system 
* $X \mathbf w = \mathbf y$
* how do we solve it, and if there's no solution, how do we find the best possible $\mathbf w$?



== Least Squares ==
=== Normal Equation ===
There's no solution to the system, so we try to fit the data as good as possible 
* Let $\mathbf w$ be the best fit solution to $X \mathbf w \approx \mathbf y$
* we'll try to minimize the error $\mathbf e = \mathbf y - X \mathbf w$ (also called [[Residual Analysis|residuals]])
* we take the square of this error, so the objective is 
* $J(\mathbf w) = \| \mathbf e \|^2 = \| \mathbf y - X \mathbf w \|^2$


The solution:
* $\mathbf w = (X^T X)^{-1} X^T \mathbf y = X^+ \mathbf y$ 
* where $X^+ = (X^T X)^{-1} X^T$ is the [[General Inverse|Pseudoinverse]] of $X$


From the [[Linear Algebra]] point of view:
* we need to solve $X \mathbf w = \mathbf y$
* if $\mathbf y \not \in C(X)$ ([[Column Space]]) then there's no solution
* How to solve it approximately? [[Projection onto Subspaces|Project]] on $C(A)$!
* again, it gives us the [[Normal Equation]]: $X^T X \mathbf w = X^T \mathbf y$


=== [[Gradient Descent]] ===
Alternatively, we can use Gradient Descent:
* objective is $J(\mathbf w) = \| \mathbf y - X \mathbf w \|^2$
* the derivative w.r.t. $\mathbf w$ is $\cfrac{\partial J(\mathbf w)}{\partial \mathbf w} = 2 X^T X \mathbf w - 2 X^T \mathbf y$
* so the update rule is $\mathbf w \leftarrow \mathbf w - \alpha 2 (X^T X \mathbf w - X^T \mathbf y)$
* where $\alpha$ is the learning rate



== Example ==
Suppose we have the following dataset: 
* ${\cal D} = \{ (1,1), (2,2), (3,2) \}$
* the matrix form is &lt;math&gt;\begin{bmatrix}
1 &amp; 1\\ 
1 &amp; 2\\ 
1 &amp; 3\\
\end{bmatrix}
\begin{bmatrix}
w_0 \\ w_1
\end{bmatrix} = 
\begin{bmatrix} 
1 \\ 2 \\ 2
\end{bmatrix}&lt;/math&gt;
* no line goes through these points at once
* so we solve $X^T X \mathbf{\hat w} = X^T \mathbf y$ 
* &lt;math&gt;\begin{bmatrix}
1 &amp; 1 &amp; 1 \\ 
1 &amp; 2 &amp; 3 \\ 
\end{bmatrix} \begin{bmatrix}
1 &amp; 1\\ 
1 &amp; 2\\ 
1 &amp; 3\\
\end{bmatrix} = \begin{bmatrix}
3 &amp; 6\\ 
6 &amp; 14\\
\end{bmatrix}&lt;/math&gt;
* this system is invertible, so we solve it and get $\hat w_0 = 2/3, \hat w_1 = 1/2$
* thus the best line is $h(t) = w_0 + w_1 t = 2/3 + 1/2 t$


http://habrastorage.org/files/ae0/b63/5a2/ae0b635a2e81493bb363d898b0e6369c.png



== Normal Equation vs [[Gradient Descent]] ==
[[Gradient Descent]]:
* need to choose learning rate $\alpha$
* need to do many iterations
* works well with large $n$


[[Normal Equation]]:
* don't need to choose $\alpha$
* don't need to iterate - computed in one step
* slow if $n$ is large $(n \geqslant 10^4)$
* need to compute $(X^T X)^{-1}$ - very slow
* if $(X^T X)$ is not-invertible - we have problems


== See Also ==
* [[Multivariate Linear Regression]]
* [[Gradient Descent]]


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* [[Machine Learning (coursera)]]
* [[Seminar Hot Topics in Information Management IMSEM (TUB)]]
* http://en.wikipedia.org/wiki/Linear_least_squares_%28mathematics%29


[[Category:Machine Learning]]
[[Category:Regression]]
[[Category:Linear Algebra]]
[[Category:Statistics]]</text>
      <sha1>ng7av0bjnr7hxlmb0byrub0m7h9ffyu</sha1>
    </revision>
  </page>
  <page>
    <title>Linear Least Squares</title>
    <ns>0</ns>
    <id>557</id>
    <redirect title="Ordinary Least Squares" />
    <revision>
      <id>560</id>
      <timestamp>2015-04-25T19:31:55Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="50">#перенаправление [[OLS Regression]]</text>
      <sha1>jx4yrm9ckgfja2gymaj24jmfhoodcar</sha1>
    </revision>
    <revision>
      <id>791</id>
      <parentid>560</parentid>
      <timestamp>2017-06-27T12:03:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Redirected page to [[Ordinary Least Squares]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="36">#REDIRECT [[Ordinary Least Squares]]</text>
      <sha1>0qm5f1zwlpr920vwyri5ykiwnqbd23f</sha1>
    </revision>
  </page>
  <page>
    <title>Matrix Vector Spaces</title>
    <ns>0</ns>
    <id>558</id>
    <revision>
      <id>561</id>
      <timestamp>2015-04-26T09:12:05Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2231">== Matrix Spaces ==
A Matrix space is a [[Vector Space]] where elements are matrices


E.g. Space $M$ - $3 \times 3$ matrices 
* any $3 \times 3$ matrix an element of this space $M$ (&quot;vector&quot; in $M$)
* we can multiply by a scalar and add two matrices - which is why we can call it &quot;vector space&quot;


=== [[Vector Subspaces|Subspaces]] ===
Subspaces of the matrix space should form a space on their own. 
* What are subspaces of the matrix space? 
* All upper-triangular matrices
* all symmetric matrices
* diagonal matrices (upper-triangular $\cup$ symmetric)


=== [[Basis (Linear Algebra)|Bases]] ===
What about bases for such spaces?

E.g. $M$: $3 \times 3$ matrices:
* $\begin{bmatrix}
1 &amp; 0 &amp; 0 \\ 
0 &amp; 0 &amp; 0 \\ 
0 &amp; 0 &amp; 0 \\
\end{bmatrix}, 
\begin{bmatrix}
0 &amp; 1 &amp; 0 \\ 
0 &amp; 0 &amp; 0 \\ 
0 &amp; 0 &amp; 0 \\
\end{bmatrix},
\begin{bmatrix}
0 &amp; 0 &amp; 1 \\ 
0 &amp; 0 &amp; 0 \\ 
0 &amp; 0 &amp; 0 \\
\end{bmatrix}, ... ,
\begin{bmatrix}
0 &amp; 0 &amp; 0 \\ 
0 &amp; 0 &amp; 0 \\ 
0 &amp; 0 &amp; 1 \\
\end{bmatrix}$
* $\text{dim}\big( M \big) = 9$


$S$ - subspace of $M$, symmetric $3 \times 3$ matrices 
* $\text{dim}\big( S \big) = 6$ - because only 6 elements change in this subspace 


$U$ - subspace of $M$ with upper-diagonal matrices 
* $\text{dim}\big( U\big) = 6$ as well - same reason (but have zeros for the upper corner)

$S \cup U$ - symmetric and upper-diagonal $\Rightarrow$ diagonal matrices
* $\text{dim}\big( S \cup U\big) = 3$ 

$S \cap U$
* not a subspace:
* $S$ is 6-dim, $U$ is 3-dim


$S + U$
* any matrix from $S$ plus any matrix from $U$ 
* this way we can get possible matrix
* so it's also a subspace 
* $\text{dim}\big( S + U\big) = 9$


rule:
* $\text{dim}\big( S \big) + \text{dim}\big( U \big) = \text{dim}\big( S \cap U \big) + \text{dim}\big( S + U \big)$



== [[Inner Product]] ==
How do we define the inner product?
* Element-wise: $\langle A, B \rangle = \sum_{ij} a_{ij} b_{ij}$
* then the norm based on this product is $\| A \|_F = \langle A, A \rangle$, it's called the [[Frobenius Norm]].




== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Kalman, Dan. &quot;A singularly valuable decomposition: the SVD of a matrix.&quot; (1996). [http://www.math.washington.edu/~morrow/498_13/svd.pdf]

[[Category:Linear Algebra]]
[[Category:Vector Spaces]]</text>
      <sha1>g0vbpcf7qt109tr9ohez3ynkivo7tdc</sha1>
    </revision>
  </page>
  <page>
    <title>Reduced Rank Approximation</title>
    <ns>0</ns>
    <id>559</id>
    <revision>
      <id>562</id>
      <timestamp>2015-04-26T13:01:11Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6376">== Reduced Rank Approximation ==
Given an $m \times n$ matrix $A$, the goal is to describe $A$ using fewer than $m \times n$ entries
* also called '''Total Least Squares''' because we want to approximate matrix $A$ with matrix $B$ by minimizing $\| A - B \|^2_F$
* in the [[Matrix Vector Spaces]] with [[Frobenius Norm]]



=== Redundancy of Matrix ===
* [[Rank (Matrix)|rank]] of $A$ specifies the number of linearly independent columns/rows
* so it's a good measure of redundancy
* if the rank is low, $A$ has a lot of redundancy
* such matrices can be expressed more efficiently than just a table of entries 
* for example, [[Outer Product|Rank One Matrices]] are very redundant: instead of $mn$ entries they can be represented by $m + n$ entries


== Approximation with [[SVD]] ==
=== Best Approximation ===
Finding the approximation
* Suppose our matrix doesn't have rank-1, 
* but we want to find the best rank-1 approximation to this matrix 
* so we want to express $A$ in terms of two vectors and their [[Outer Product]]


How do we define &quot;best&quot;?
* let matrix $B$ be the best rank-one approximation of $A$ if $\| B - A \|^2$ is minimum 
* so $B$ is the best in terms of &quot;Total Least Squares&quot;
* norm for a matrix? Use [[Frobenious Norm]]
* so use element-wise [[Inner Product]] $\langle A, B \rangle = \sum_{ij} a_{ij} b_{ij}$ and norm is $\| A \|_F = \langle A, A \rangle$.



Let's apply [[SVD]]:
* $A = U \Sigma V^T = \sum_i \sigma_i \mathbf u_i \mathbf v_i^T$
* $\| A \|^2_F = \sum_i \| \sigma_i \mathbf u_i \mathbf v_i^T \|^2_F$ 
** {{ TODO | why??? prove it }}
** the terms are orthogonal w.r.t. matrix inner product
* SVD is orthogonal decomposition into rank-1 matrices
* also because norm of rank-1 matrix is $\| \mathbf u_i \mathbf v_i^T \|^2_F = \| \mathbf u_i  \|^2 \|\mathbf v_i  \|^2$ and $\mathbf v_i$ and $\mathbf u_i$ are orthonormal, we have 
* $\| A \|^2_F = \sum_i \sigma_i^2$ 



=== Approximation ===
Let's express $A$ as $A = S_k + E_k$
* where $S_k = \sum_{i = 1}^k \sigma_i \mathbf u_i \mathbf v_i^T$ - first $k$ vectors
* and $E_k = \sum_{i = k+1}^r \sigma_i \mathbf u_i \mathbf v_i^T$ - remaining $k$ vectors
* then $\| A \|_F^2 = \| S_k \|_F^2 + \| E_k \|_F^2 $ for any $k$ 
* also, $\| S_k \|_F^2 = \sum_{i = 1}^k \sigma_i^2$ and  $\| E_k \|_F^2 = \sum_{i = k+1}^r \sigma_i^2$


=== Rank-1 Approximation ===
'''Theorem'''
: The best rank-1 approximation of $A$ is $\sigma_1 \mathbf u_1 \mathbf v_1^T$

Proof
* $S_1 = \sigma_1 \mathbf u_1 \mathbf v_1^T$ and $E_1 = \sigma_2^2 + \ ... \ + \sigma_r^2$
* show that $E_1$ is the best achievable error
* let $A_1$ be any rank-1 approximation, so it's error is $\| A - A_1 \|^2$
* this norm is preserved under multiplication by orthogonal matrices (see [[Froubenius Norm]])
* so $\| A - A_1 \|^2 = \| U \Sigma V^T - A_1 \|^2 = \| \Sigma V^T - U^T A_1 \|^2 = \| \Sigma - U^T A_1 V \|^2$
* let's write $U^T A_1 V$ as $\alpha \mathbf x \mathbf y^T$ with $\alpha &gt; 0$ and unit vectors $\mathbf x \in \mathbb R^m$ and $\mathbf y \in \mathbb R^n$ 
* so, $\| \Sigma - U^T A_1 V \|^2_F = \| \Sigma \|^2_F - 2 \alpha \Sigma \mathbf x \mathbf y^T + \alpha^2 \| \mathbf x \mathbf y^T \|^2_F$
* $\| \mathbf x \mathbf y^T \|^2_F = 1$ because both $\mathbf x$ and $\mathbf y$ are unit vectors
* $\Sigma \mathbf x \mathbf y^T = \sum_{i=1}^r \sigma_i x_i y_i \leqslant \sum_{i=1}^r \sigma_i | x_i | \, | y_i | \leqslant \sigma_1 \sum_{i=1}^r  | x_i | \, | y_i |$ 
** recall that in SVD $\sigma_1$ the biggest singular value
* let $\mathbf x^* = (|x_1|, \ ... \ , |x_r|)$ and $\mathbf y^* = (|y_1|, \ ... \ , |y_r|)$
* so $\sum_{i=1}^r  | x_i | \, | y_i | = \langle \mathbf x^*, \mathbf y^* \rangle$ 
* by [[Cauchy-Schwartz Inequality]] we have $\langle \mathbf x^*, \mathbf y^* \rangle \leqslant \| \mathbf x^* \| \,  \| \mathbf y^* \| \leqslant \| \mathbf x \| \,  \| \mathbf y \|= 1$
* so $\sigma_1 \langle \mathbf x^*, \mathbf y^* \rangle \leqslant \sigma_1$
* and $\Sigma \mathbf x \mathbf y^T \leqslant \sigma_1$
* $\| \Sigma - U^T A_1 V \|^2_F = \| \Sigma \|^2_F - 2 \alpha \Sigma \mathbf x \mathbf y^T + \alpha^2 \| \mathbf x \mathbf y^T \|^2_F \geqslant \| \Sigma \|^2_F - 2 \alpha\sigma_1$
* complete the square and get $\| \Sigma \|^2_F - 2 \alpha\sigma_1 = \| \Sigma \|^2_F - (\alpha - \sigma_1)^2 - \sigma_1^2$
* apparently it's maximal when $\alpha = \sigma_1$
* so $\| \Sigma - U^T A_1 V \|^2_F \geqslant \| \Sigma \|^2_F - \sigma_1^2 = E_2$
* the exact minimum is obtained when $\alpha = \sigma_1, \mathbf x = \mathbf e_1 \in \mathbb R^m, \mathbf y = e_1 \in \mathbb R^n$
* finally, $A_1 = \alpha (U \mathbf x) (V \mathbf y)^T = \sigma \mathbf u_1 \mathbf v_1^T$

$\square$


=== Greedy Approach to Rank-$k$ Approximation ===
Greedy approach:
* find rank-1 $A_1$ for which $E_1 = A - A_1$ has minimal norm
* next choose rank-1 matrix $A_2$ for which $E_2 = E_1 - A_2 = E - A_1 - A_2$ has the minimal norm
** $A_1 + A_2$ is rank-2 approximation
* at each step choose such $A_i$ that minimizes the norm of $E_i = E_{i-1} - A_i$
* after $k$ steps we have rank-$k$ approximation to $A \approx A_1 + \ ... \ + A_k$


Step 1:
* find best rank-1 approximation
* already know how to do this


Step 2:
* now $E_1 = \sum_{i=2}^r \sigma_i \mathbf u_i \mathbf v_i^T$
* and SVD of $E_1$ will give the same! 
* so the best rank-1 approximation to $E_1$ is $\sigma_2 \mathbf u_2 \mathbf v_2^T$


Can repeat this argument for all $E_i$


=== Best Rank-$k$ Approximation ===
Actually, the greedy approach gives the best possible approximation

Proof: 
* Lawson, Charles L., and Richard J. Hanson. Solving least squares problems. Vol. 161. Englewood Cliffs, NJ: Prentice-hall, 1974.


== [[Fourier Transformation]] vs Reduced Rank Approximation ==
DFT
* it's about representing a data vector in a special orthogonal basis
* the basis is sines and cosines
* So, the Fourier Decomposition represents data as a sum of basic functions with specific amplitudes
* often there are only a few principal frequencies that account for most variability in the data
* and the rest can be discarded 

RRA with SVD
* it's the same as DFT
* but here we find the best basis ourselves with SVD
* so we can see SVD as adaptive generalization of DFT



== Sources ==
* Kalman, Dan. &quot;A singularly valuable decomposition: the SVD of a matrix.&quot; (1996). [http://www.math.washington.edu/~morrow/498_13/svd.pdf]


[[Category:Linear Algebra]]</text>
      <sha1>8xx7yqixlyijtyf3flpa7fenwlq86py</sha1>
    </revision>
  </page>
  <page>
    <title>SVD</title>
    <ns>0</ns>
    <id>560</id>
    <redirect title="Singular Value Decomposition" />
    <revision>
      <id>563</id>
      <timestamp>2015-04-26T13:05:49Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="42">#REDIRECT [[Singular Value Decomposition]]</text>
      <sha1>6q17p63mvbg0vq8tlksg5rv1y45yq8e</sha1>
    </revision>
  </page>
  <page>
    <title>Singular Value Decomposition</title>
    <ns>0</ns>
    <id>561</id>
    <revision>
      <id>564</id>
      <timestamp>2015-05-08T20:07:24Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15436">== Singular Value Decomposition ==
SVD is a decomposition of rectangular $m \times n$ matrix $A$ as
* $A = U \Sigma V^T$ where
* $U$ is an $m \times m$ orthogonal matrix with [[Eigenvectors]] of $A A^T$
* $\Sigma$ is an diagonal $m \times n$  matrix with [[Eigenvalues]] of both $A^T A$ and $A A^T$
* $V$ is an $n \times n$ orthogonal matrix with [[Eigenvalues]] of $A^T A$





=== Orthogonal Basis for the [[Four Fundamental Subspaces]] ===
But it's not only a decomposition, but a way of finding the bases for the [[Four Fundamental Subspaces]] of $A$:


&lt;img width=&quot;50%&quot; src=&quot;http://alexeygrigorev.com/projects/imsem-ws14-lina/img-svg/diagram3-svd.svg&quot; /&gt;


* Singular vectors $\mathbf v_1, \ ... \ , \mathbf v_r$ are in the row space of $A$ 
* applying $A$ to $\mathbf v_i$ gives $A \mathbf v_i = \sigma_i \mathbf u_i$
* $\mathbf u_1, \ ... \ , \mathbf u_r$ are in the column space of $A$ 
* Singular values $\sigma_1, \ ... \ , \sigma_r$ are all positive numbers
* so $V$ and $U$ diagonalize $A$:
* $A \mathbf v_i = \sigma_i \mathbf u_i$ $\Rightarrow$ $A V = \Sigma U$
* The singular values $\sigma_i$ in $\Sigma$ are arranged in monotonic non-increasing order


== EVD vs SVD ==
=== Eigenvalue Decomposition ===
Problems with general [[Eigendecomposition]] $A = S \, \Lambda \, S^{-1}$:
* doesn't work with rectangular matrices 
* eigenvalues in $S$ are usually not orthonormal (unless $A$ is symmetric)


Our goal:
* $A = U \Sigma V^T$
* we want to find the orthogonal basis in the [[Row Space]] $C(A^T)$ of $A$ 
* and we then map this basis to some orthogonal basis in the [[Column Space]] $C(A)$ of $A$
* these vectors are called ''singular vectors''


Solution:
* choose basis from $AA^T$ and $A^T A$ - they are symmetric and have orthonormal basis


=== [[Spectral Theorem]] ===
SVD extends the [[Spectral Theorem]] 
* it's EVD for all symmetric positive-definite matrices
* we extend EVD to all rectangular matrices $A$ 



== Finding SVD ==
Goal:
* find orthonormal bases in the row space of $A$ as well as in the column space of $A$ 
* s.t. $A$ maps from row space basis to the column space basis 
* and the matrix $A$ is diagonal w.r.t. this basis


=== Orthogonalization  ===
Finding orthogonal basis for the rowspace $C(A^T)$ 
* let $r$ be the [[Rank (Matrix)|rank]] of $A$ 
* select orthonormal basis $\mathbf v_1, \ ... \ , \mathbf v_r$ in $\mathbb R^n$ s.t. it spans the [[Row Space]] of $A$
* e.g. using the [[Gram-Schmidt Process]] on the rows of $A^T$
* continue the process to find $\mathbf v_{r+1}, \ ... \ , \mathbf v_n$ in $\mathbb R^n$ s.t it spans the [[Nullspace]] of $A$


Then for $i = 1 .. r$ define $\mathbf u_i$ as $A \mathbf v_i$
* i.e. $A \mathbf v_i = \sigma_i \mathbf u_i$
* extend this to a basis in $\mathbb R^m$ 
* relative to these bases, $A$ will have diagonal representation


Here $\{ \ \mathbf v_i \ \}$ are orthogonal by construction
* but $\{ \ \mathbf u_i \ \}$ aren't necessarily orthogonal 
* we want to find such $\{ \ \mathbf v_i \ \}$ that $\{ \ \mathbf u_i \ \}$ are also orthogonal


We can use [[Eigendecomposition|EVD]] to find the right basis
* Let $\{ \ \mathbf v_i \ \}$ be eigenvectors of $A^T A$ with $\lambda_i$ being corresponding eigenvalues
* so $A^T A \mathbf v_i = \lambda_i \mathbf v_i$ and EVD is $A^T A = V \Lambda V^T$ (with $\mathbf v_i$ being the columns of $V$) 


Will it give the right bases?
* the [[Inner Product]] $\langle A \mathbf v_i, A \mathbf v_j \rangle$ is $(A \mathbf v_i)^T (A \mathbf v_j) = \mathbf v_i^T A^T A \mathbf v_j = \mathbf v_i^T (A^T A \mathbf v_j) = \mathbf v_i^T \lambda_j \mathbf v_j = \lambda_j \mathbf v_i^T  \mathbf v_j$
* if $i \ne j$, then $\mathbf v_i^T  \mathbf v_j =0$ 
* so the image $\big\{ A \mathbf v_1, \ ... \ , A \mathbf v_n \big\}$ is also orthogonal 


Finding the orthonormal $\{ \ \mathbf u_i \ \}$
* vectors $A \mathbf v_i$ are orthogonal, but not orthonormal 
* $\| A \mathbf v_i \|^2 = \langle A \mathbf v_i, A \mathbf v_i \rangle = \mathbf v_i^T A^T A \mathbf v_i = \mathbf v_i^T \lambda_i \mathbf v_i = \lambda_i$
* let $\mathbf u_i = \cfrac{A \mathbf v_i}{\| A \mathbf v_i \|} = \cfrac{1}{\sqrt{\lambda_i}} A \mathbf v_i$ for $i = 1 .. r$
* if $r &lt; m$, we extend this basis for $\mathbb R^m$


This completes the construction for the bases
* Let $\sigma_i = \sqrt{\lambda_i}$. Then $\mathbf u_i = \cfrac{1}{\sigma_i} A \mathbf v_i$
* or $A \mathbf v_i = \sigma_i \mathbf u_i$
* Put $\{ \mathbf v_1, \ ... \ , \mathbf v_r \}$ in columns of $V$ and $\{ \mathbf u_1, \ ... \ , \mathbf u_r \}$ in columns of $U$ 
* so we'll have $A V = U \Sigma$
* thus, SVD is $A = U \Sigma V^T$


Summary: 
* $A$ is $m \times n$ real matrix 
* express $A = U \Sigma V^T$ 
* $V$ is obtained from diagonal factorization $A^T A = V \Lambda V^T$
* $U$ is normalized image $\big\{ A \mathbf v_1, \ ... \ , A \mathbf v_n \big\}$
* non-zero entries $\sigma_i$ of $\Sigma$ are square roots of $\lambda_i$ from $\Lambda$: $\sigma_i = \sqrt{\lambda_i}$


This construction shows that SVD exists, but it doesn't mean that it's the most effective way of implementing it 
* the computation of $A^T A$ can lead to loss of precision (because of the way numbers are stored in memory)
* there are direct methods of computing SVD on $A$, without having to compute $A^T A$



There's duality: we can do the save for $AA^T$:
* EVD is $AA^T = U \Lambda U^T$, $\mathbf u_i$ are columns of $U$ 
* let's apply $A^T$ to these $\mathbf u_i$
* The image of this tranformation is also orthogonal: $\langle A^T \mathbf u_i, A^T \mathbf u_j \rangle = \lambda_i$ if $i = j$ and $0$ otherwise
* we normalize $A^T \mathbf u_i$ by $\sigma_i = \sqrt{\lambda_i}$
* so it's completely the same, but coming from the column space side


=== $\Sigma$: Eigenvalues of $A^T A$ and $AA^T$ ===
What is more, the eigenvalues of $A^T A$ and $AA^T$ are the same!

Let's first show that if $\lambda$ is eigenvalue for $A^T A$, then it's an eigenvalue for $AA^T$
* let $\lambda \ne 0$ be an eigenvalue of $A^T A$ with corresponding eigenvector $\mathbf v \ne \mathbf 0$
* then $A^T A \mathbf v = \lambda \mathbf v$. Multiply by $A$ on the left:
* $A A^T A \mathbf v = \lambda A \mathbf v$
* let $\mathbf u = A \mathbf v$, then $A A^T \mathbf u = \lambda \mathbf u$
* so $\lambda$ is an eigenvalue for $A A^T$ as well, with eigenvector $\mathbf u = A \mathbf v$


Now show that if $\lambda$ is eigenvalue for $AA^T$ then it's also eigenvalue for $A^T A$
* same idea as before
* let $\lambda \ne 0$ be an eigenvalue of $A A^T$ with corresponding eigenvector $\mathbf u \ne \mathbf 0$
* then $A A^T \mathbf u = \lambda \mathbf u$. Multiply by $A^T$ on the left
* $A^T A A^T \mathbf u = \lambda A^T \mathbf u$
* by letting $\mathbf v = A^T \mathbf u$ we have  $A^T A \mathbf v = \lambda \mathbf v$
* so $\lambda$ is an eigenvalue for $A A^T$ as well, with eigenvector $\mathbf v = A^T \mathbf u$

$\square$


Calculating eigenvalues
* So, for example, if $A$ is $500 \times 2$, then $AA^T$ is $500 \times 500$ and $A^T A$ is $2 \times 2$
* we calculate eigenvalues for $A^T A$, (there are 2 of them)
* and we know that $AA^T$ has the same 2 eigenvalues - with the rest 498 being 0



=== Reconstructing EVD from SVD ===
We saw how to construct SVD using EVD, but we can also reconstruct EVD from SVD 

* let $A = U \Sigma V^T$, then
* $A^T A = V \Sigma^T \Sigma V^T = V \Sigma^2 V^T$ is EVD of $A^T A$
* $A A^T = U \Sigma \Sigma^T U^T = U \Sigma^2 U^T$ is EVD of $A A^T$
* where $\Sigma^T \Sigma = \Sigma \Sigma^T = \Sigma^2 = \text{diag}(\sigma_1^2, \ ... \ , \sigma_r^2)$


If $A$ is square and symmetric, then $A = A^T$ and $A^T A = A A^T = A^2$ 
* and any eigenvector $\mathbf v$ of $A$ with eigenvalue $\lambda$ is eigenvector of $A^2$ with eigenvalue $\lambda^2$
* so $U = V$ and EVD = SVD when $A$ is positive semi-definite (no negative eigenvalues)



== Geometric Interpretation ==
Let's understand how $A$ deforms the space 
* consider a unit sphere in $\mathbb R^n$ 
* a vector $\mathbf x \in \mathbb R^n$ is represented as $\mathbf x = \sum x_i \mathbf v_i$
* because it's a sphere, $\sum x_i^2 = 1$
* then the image $A \mathbf x = \sum x_i A \mathbf v_i = \sum x_i A \mathbf v_i = \sum \sigma_i x_i \mathbf u_i$
* let $y_i = x_i \sigma_i$
* then $A \mathbf x = \sum y_i \mathbf u_i$
* $\sum\limits_{i = 1}^r \cfrac{y_i^2}{\sigma_i^2} = \sum\limits_{i = 1}^r x_i^2 \leqslant 1$
* if $A$ has full rank, then the sum is strictly $1$

So $A$ maps the unit sphere in $\mathbb R^n$ to some $r$-dimensional ellipsoid in $\mathbb R^m$ with axes in directions $\mathbf u_i$, each with magnitudes $\sigma_i$


* Linear transformation:
* So first it collapses $n - r$ dimensions of the domain 
* then it distorts the remaining dimensions stretching and squeezing the $r$-dim unit sphere into an ellipsoid
* finally it embeds the ellipsoid into $\mathbb R^m$ 
* http://habrastorage.org/files/b78/2d1/d28/b782d1d2846a44e5bd58780eb89589a0.png
* From (Kalman96)
* $n = m = 3$, $r = 2$



Another way:
* http://habrastorage.org/files/3ca/397/588/3ca39758812f4e159a9785ef44e92fe1.png
* From (Strang93)


== Representation ==
=== Partitioned Matrices ===
Let's have a look at $A = U \Sigma V^T$ for $m \times n$ matrix $A$: 
* $A = \left[ \begin{array}{cccc|ccc} 
| &amp; | &amp; &amp; | &amp; | &amp; &amp; | \\
| &amp; | &amp; &amp; | &amp; | &amp; &amp; | \\
\mathbf u_1 &amp; \mathbf u_2 &amp; \cdots &amp; \mathbf u_r &amp; \mathbf u_{r+1} &amp; \cdots &amp; \mathbf u_m \\ 
| &amp; | &amp; &amp; | &amp; | &amp; &amp; | \\
| &amp; | &amp; &amp; | &amp; | &amp; &amp; | \\
\end{array} \right]
\left[ \begin{array}{cccc|ccc} 
\sigma_1            &amp;        &amp;           &amp;        &amp; \\
&amp;          \sigma_2 &amp;        &amp;           &amp;        &amp; \\
&amp;          &amp;          \ddots   &amp;           &amp;        &amp; \\
&amp;          &amp;          &amp;        \sigma_r  &amp;        &amp; \\
\hline
&amp;          &amp;          &amp;        &amp;           0        &amp; \\
&amp;          &amp;          &amp;        &amp;           &amp; \ddots &amp; \\
&amp;          &amp;          &amp;        &amp;           &amp;        &amp; 0 \\
\end{array} \right]
\begin{bmatrix} 
- &amp; \mathbf v_1^T &amp; - \\
  &amp; \vdots &amp;  \\
- &amp; \mathbf v_1^T &amp; - \\
\hline
- &amp; \mathbf v_{r+1}^T &amp; - \\
  &amp; \vdots &amp;  \\
- &amp; \mathbf v_n^T &amp; - \\
\end{bmatrix}$ 
* Then using [[Matrix Multiplication]] for block-partitioned matrices, we see that 
* $A = \begin{bmatrix} 
| &amp; | &amp; &amp; | \\
\mathbf u_1 &amp; \mathbf u_2 &amp; \cdots &amp; \mathbf u_r \\ 
| &amp; | &amp; &amp; | \\
\end{bmatrix}
\begin{bmatrix} 
\sigma_1            &amp;        &amp; \\
&amp;          \sigma_2 &amp;        &amp; \\
&amp;          &amp;          \ddots   &amp; \\
&amp;          &amp;          &amp;        \sigma_r \\
\end{bmatrix}
\begin{bmatrix} 
- &amp; \mathbf v_1^T &amp; - \\
  &amp; \vdots &amp;  \\
- &amp; \mathbf v_1^T &amp; - \\
\end{bmatrix}
+
\begin{bmatrix} 
| &amp; &amp; | \\
\mathbf u_{r+1} &amp; \cdots &amp; \mathbf u_m \\ 
| &amp; &amp; | \\
\end{bmatrix}
\begin{bmatrix} 
0 &amp;        &amp;   \\
  &amp; \ddots &amp;   \\
  &amp;        &amp; 0 \\
\end{bmatrix}
\begin{bmatrix} 
- &amp; \mathbf v_{r+1}^T &amp; - \\
  &amp; \vdots &amp;  \\
- &amp; \mathbf v_n^T &amp; - \\
\end{bmatrix}$
* so, $A = 
\begin{bmatrix} 
| &amp; | &amp; &amp; | \\
\mathbf u_1 &amp; \mathbf u_2 &amp; \cdots &amp; \mathbf u_r \\ 
| &amp; | &amp; &amp; | \\
\end{bmatrix}
\begin{bmatrix} 
\sigma_1            &amp;        &amp; \\
&amp;          \sigma_2 &amp;        &amp; \\
&amp;          &amp;          \ddots   &amp; \\
&amp;          &amp;          &amp;        \sigma_r \\
\end{bmatrix}
\begin{bmatrix} 
- &amp; \mathbf v_1^T &amp; - \\
  &amp; \vdots &amp;  \\
- &amp; \mathbf v_1^T &amp; - \\
\end{bmatrix}
$

* so only first $r$ $\mathbf v_i$'s and $\mathbf u_i$'s contribute something
* now $U$ and $V$ become rectangular and $\Sigma$ square:


SVD is $A = U \Sigma V^T$
* $U$ is $m \times r$ matrix s.t. $U^T U = I$
* $\Sigma$ is $r \times r$ diagonal matrix $\text{diag}(\sigma_1, \ ... \ , \sigma_r)$
* $V$ is $n \times r$ matrix s.t. $V^T V = I$


=== [[Outer Product]] Form ===
A matrix multiplication $AB$ can be expressed as a sum of outer products:
* let $A$ be $n \times k$ matrix and $B$ be $k \times m$ matrix
* then $AB = \sum\limits_{i=1}^k \mathbf a_i \mathbf b_i^T$
* where $\mathbf a_i$ are columns of $A$ and $\mathbf b_i$ are rows of $B$

Thus we can represent $A = U \Sigma V^T$ as sum of outer products:
* $A = \sum\limits_{i = 1}^r \sigma_i \mathbf u_i \mathbf v_i^T$

It gives another way of thinking about the Linear Tranformation $f(\mathbf x) = A \mathbf x$
* $A \mathbf x = (\sum \sigma_i \mathbf u_i \mathbf v_i^T) \mathbf x = \sum \sigma_i \mathbf u_i (\mathbf v_i^T \mathbf x) = \sum \sigma_i (\mathbf v_i^T \mathbf x) \mathbf u_i$
* so we express $A \mathbf x$ as a linear combination of $\{ \ \mathbf u_i \ \}$


=== Truncated SVD ===
Usual SVD:
* $A = U \Sigma V$ 
* $\sigma_i$ in $\text{diag}(\Sigma)$ are in non-increasing order
* so we can keep only first $k$ singular values of $\Sigma$ (and set the rest to 0) and get the best rank-$k$ approximation of $A$ 
* this is the best approximation in terms of Total Least Squares (see [[Reduced Rank Approximation]])


In terms of sum of rank-1 matrices, we can approximate $A$ by
* $A_k = \sum_{i = 1}^k \sigma_i \mathbf u_i \mathbf v_i^T$



== Properties &amp; Questions ==
=== Column Space and Row Space ===
Given SVD $A V = U \Sigma$, why $U$ in is the column space of $A$ and $V$ is the row space?
* For all $i$: $A \mathbf v_i = \sigma_i \mathbf u_i$. Since there's a solution, then $\sigma_i \mathbf u_i \in C(A)$
* for all $i$: $A^T \mathbf u_i = \sigma_i \mathbf v_i$. Then $\sigma_i \mathbf u_i \in C(A^T)$ which is the row space of $A$ 


== Applications ==
=== [[Dimensionality Reduction]] ===
[[Principal Component Analysis]]
* PCA is often implemented through SVD


Data Compression
* Truncated SVD gives the best rank-$k$ approximation to the original matrix $A$ 
* when using [[Frobenius Norm]] in the [[Matrix Vector Spaces|Matrix Vector Space]]
* the problem is [[Reduced Rank Approximation]] (sometimes Total Least Squares)


It's like Discrete [[Fourier Transformation]]:
* in DFT we represent a data vector in orthogonal basis of sines and cosines
* often there are only a few principal frequencies that account for most variability in the data and the rest can be discarded 
* SVD does the same, but it find the best orthogonal basis instead of using a predefined one
* so we can see SVD as adaptive generalization of DFT


Image Compression
* images can be represented as Matrices, so we can apply SVD and PCA to them
* http://habrastorage.org/files/855/a65/c62/855a65c624dc4174b526fb5e03b98555.png
* source: SVD at work [http://web.mit.edu/18.06/www/Fall03/svd.pdf] from [http://web.mit.edu/18.06/www/extras.shtml]




=== [[Latent Semantic Analysis]] ===
* When used as a Dimensionality Reduction technique for Term-Document matrix
* it helps revealing some hidden semantic patterns


=== [[Linear Least Squares]] ===
As a technique for faster [[Normal Equation]] computation
* but generally [[QR Decomposition]] is better, but sometimes less stable


=== Others ===
There are many other applications


== See Also ==
* [[Eigendecomposition]] and [[Spectral Theorem]]
* Note that $A A^T$ and $A^T A$ are called [[Gram Matrices]]


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Strang, G. Introduction to linear algebra.
* Jauregui, Jeff. &quot;Principal component analysis with linear algebra.&quot; (2012). [http://www.math.union.edu/~jaureguj/PCA.pdf]
* Kalman, Dan. &quot;A singularly valuable decomposition: the SVD of a matrix.&quot; (1996). [http://www.math.washington.edu/~morrow/498_13/svd.pdf]
* Strang, Gilbert. &quot;The fundamental theorem of linear algebra.&quot; (1993). [http://www.engineering.iastate.edu/~julied/classes/CE570/Notes/strangpaper.pdf]


[[Category:Linear Algebra]]
[[Category:Matrix Decomposition]]</text>
      <sha1>99x4ev8w4bjmbdcegxpdzwovq3zkntu</sha1>
    </revision>
    <revision>
      <id>663</id>
      <parentid>564</parentid>
      <timestamp>2015-11-08T07:55:13Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>/* Partitioned Matrices */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15467">== Singular Value Decomposition ==
SVD is a decomposition of rectangular $m \times n$ matrix $A$ as
* $A = U \Sigma V^T$ where
* $U$ is an $m \times m$ orthogonal matrix with [[Eigenvectors]] of $A A^T$
* $\Sigma$ is an diagonal $m \times n$  matrix with [[Eigenvalues]] of both $A^T A$ and $A A^T$
* $V$ is an $n \times n$ orthogonal matrix with [[Eigenvalues]] of $A^T A$





=== Orthogonal Basis for the [[Four Fundamental Subspaces]] ===
But it's not only a decomposition, but a way of finding the bases for the [[Four Fundamental Subspaces]] of $A$:


&lt;img width=&quot;50%&quot; src=&quot;http://alexeygrigorev.com/projects/imsem-ws14-lina/img-svg/diagram3-svd.svg&quot; /&gt;


* Singular vectors $\mathbf v_1, \ ... \ , \mathbf v_r$ are in the row space of $A$ 
* applying $A$ to $\mathbf v_i$ gives $A \mathbf v_i = \sigma_i \mathbf u_i$
* $\mathbf u_1, \ ... \ , \mathbf u_r$ are in the column space of $A$ 
* Singular values $\sigma_1, \ ... \ , \sigma_r$ are all positive numbers
* so $V$ and $U$ diagonalize $A$:
* $A \mathbf v_i = \sigma_i \mathbf u_i$ $\Rightarrow$ $A V = \Sigma U$
* The singular values $\sigma_i$ in $\Sigma$ are arranged in monotonic non-increasing order


== EVD vs SVD ==
=== Eigenvalue Decomposition ===
Problems with general [[Eigendecomposition]] $A = S \, \Lambda \, S^{-1}$:
* doesn't work with rectangular matrices 
* eigenvalues in $S$ are usually not orthonormal (unless $A$ is symmetric)


Our goal:
* $A = U \Sigma V^T$
* we want to find the orthogonal basis in the [[Row Space]] $C(A^T)$ of $A$ 
* and we then map this basis to some orthogonal basis in the [[Column Space]] $C(A)$ of $A$
* these vectors are called ''singular vectors''


Solution:
* choose basis from $AA^T$ and $A^T A$ - they are symmetric and have orthonormal basis


=== [[Spectral Theorem]] ===
SVD extends the [[Spectral Theorem]] 
* it's EVD for all symmetric positive-definite matrices
* we extend EVD to all rectangular matrices $A$ 



== Finding SVD ==
Goal:
* find orthonormal bases in the row space of $A$ as well as in the column space of $A$ 
* s.t. $A$ maps from row space basis to the column space basis 
* and the matrix $A$ is diagonal w.r.t. this basis


=== Orthogonalization  ===
Finding orthogonal basis for the rowspace $C(A^T)$ 
* let $r$ be the [[Rank (Matrix)|rank]] of $A$ 
* select orthonormal basis $\mathbf v_1, \ ... \ , \mathbf v_r$ in $\mathbb R^n$ s.t. it spans the [[Row Space]] of $A$
* e.g. using the [[Gram-Schmidt Process]] on the rows of $A^T$
* continue the process to find $\mathbf v_{r+1}, \ ... \ , \mathbf v_n$ in $\mathbb R^n$ s.t it spans the [[Nullspace]] of $A$


Then for $i = 1 .. r$ define $\mathbf u_i$ as $A \mathbf v_i$
* i.e. $A \mathbf v_i = \sigma_i \mathbf u_i$
* extend this to a basis in $\mathbb R^m$ 
* relative to these bases, $A$ will have diagonal representation


Here $\{ \ \mathbf v_i \ \}$ are orthogonal by construction
* but $\{ \ \mathbf u_i \ \}$ aren't necessarily orthogonal 
* we want to find such $\{ \ \mathbf v_i \ \}$ that $\{ \ \mathbf u_i \ \}$ are also orthogonal


We can use [[Eigendecomposition|EVD]] to find the right basis
* Let $\{ \ \mathbf v_i \ \}$ be eigenvectors of $A^T A$ with $\lambda_i$ being corresponding eigenvalues
* so $A^T A \mathbf v_i = \lambda_i \mathbf v_i$ and EVD is $A^T A = V \Lambda V^T$ (with $\mathbf v_i$ being the columns of $V$) 


Will it give the right bases?
* the [[Inner Product]] $\langle A \mathbf v_i, A \mathbf v_j \rangle$ is $(A \mathbf v_i)^T (A \mathbf v_j) = \mathbf v_i^T A^T A \mathbf v_j = \mathbf v_i^T (A^T A \mathbf v_j) = \mathbf v_i^T \lambda_j \mathbf v_j = \lambda_j \mathbf v_i^T  \mathbf v_j$
* if $i \ne j$, then $\mathbf v_i^T  \mathbf v_j =0$ 
* so the image $\big\{ A \mathbf v_1, \ ... \ , A \mathbf v_n \big\}$ is also orthogonal 


Finding the orthonormal $\{ \ \mathbf u_i \ \}$
* vectors $A \mathbf v_i$ are orthogonal, but not orthonormal 
* $\| A \mathbf v_i \|^2 = \langle A \mathbf v_i, A \mathbf v_i \rangle = \mathbf v_i^T A^T A \mathbf v_i = \mathbf v_i^T \lambda_i \mathbf v_i = \lambda_i$
* let $\mathbf u_i = \cfrac{A \mathbf v_i}{\| A \mathbf v_i \|} = \cfrac{1}{\sqrt{\lambda_i}} A \mathbf v_i$ for $i = 1 .. r$
* if $r &lt; m$, we extend this basis for $\mathbb R^m$


This completes the construction for the bases
* Let $\sigma_i = \sqrt{\lambda_i}$. Then $\mathbf u_i = \cfrac{1}{\sigma_i} A \mathbf v_i$
* or $A \mathbf v_i = \sigma_i \mathbf u_i$
* Put $\{ \mathbf v_1, \ ... \ , \mathbf v_r \}$ in columns of $V$ and $\{ \mathbf u_1, \ ... \ , \mathbf u_r \}$ in columns of $U$ 
* so we'll have $A V = U \Sigma$
* thus, SVD is $A = U \Sigma V^T$


Summary: 
* $A$ is $m \times n$ real matrix 
* express $A = U \Sigma V^T$ 
* $V$ is obtained from diagonal factorization $A^T A = V \Lambda V^T$
* $U$ is normalized image $\big\{ A \mathbf v_1, \ ... \ , A \mathbf v_n \big\}$
* non-zero entries $\sigma_i$ of $\Sigma$ are square roots of $\lambda_i$ from $\Lambda$: $\sigma_i = \sqrt{\lambda_i}$


This construction shows that SVD exists, but it doesn't mean that it's the most effective way of implementing it 
* the computation of $A^T A$ can lead to loss of precision (because of the way numbers are stored in memory)
* there are direct methods of computing SVD on $A$, without having to compute $A^T A$



There's duality: we can do the save for $AA^T$:
* EVD is $AA^T = U \Lambda U^T$, $\mathbf u_i$ are columns of $U$ 
* let's apply $A^T$ to these $\mathbf u_i$
* The image of this tranformation is also orthogonal: $\langle A^T \mathbf u_i, A^T \mathbf u_j \rangle = \lambda_i$ if $i = j$ and $0$ otherwise
* we normalize $A^T \mathbf u_i$ by $\sigma_i = \sqrt{\lambda_i}$
* so it's completely the same, but coming from the column space side


=== $\Sigma$: Eigenvalues of $A^T A$ and $AA^T$ ===
What is more, the eigenvalues of $A^T A$ and $AA^T$ are the same!

Let's first show that if $\lambda$ is eigenvalue for $A^T A$, then it's an eigenvalue for $AA^T$
* let $\lambda \ne 0$ be an eigenvalue of $A^T A$ with corresponding eigenvector $\mathbf v \ne \mathbf 0$
* then $A^T A \mathbf v = \lambda \mathbf v$. Multiply by $A$ on the left:
* $A A^T A \mathbf v = \lambda A \mathbf v$
* let $\mathbf u = A \mathbf v$, then $A A^T \mathbf u = \lambda \mathbf u$
* so $\lambda$ is an eigenvalue for $A A^T$ as well, with eigenvector $\mathbf u = A \mathbf v$


Now show that if $\lambda$ is eigenvalue for $AA^T$ then it's also eigenvalue for $A^T A$
* same idea as before
* let $\lambda \ne 0$ be an eigenvalue of $A A^T$ with corresponding eigenvector $\mathbf u \ne \mathbf 0$
* then $A A^T \mathbf u = \lambda \mathbf u$. Multiply by $A^T$ on the left
* $A^T A A^T \mathbf u = \lambda A^T \mathbf u$
* by letting $\mathbf v = A^T \mathbf u$ we have  $A^T A \mathbf v = \lambda \mathbf v$
* so $\lambda$ is an eigenvalue for $A A^T$ as well, with eigenvector $\mathbf v = A^T \mathbf u$

$\square$


Calculating eigenvalues
* So, for example, if $A$ is $500 \times 2$, then $AA^T$ is $500 \times 500$ and $A^T A$ is $2 \times 2$
* we calculate eigenvalues for $A^T A$, (there are 2 of them)
* and we know that $AA^T$ has the same 2 eigenvalues - with the rest 498 being 0



=== Reconstructing EVD from SVD ===
We saw how to construct SVD using EVD, but we can also reconstruct EVD from SVD 

* let $A = U \Sigma V^T$, then
* $A^T A = V \Sigma^T \Sigma V^T = V \Sigma^2 V^T$ is EVD of $A^T A$
* $A A^T = U \Sigma \Sigma^T U^T = U \Sigma^2 U^T$ is EVD of $A A^T$
* where $\Sigma^T \Sigma = \Sigma \Sigma^T = \Sigma^2 = \text{diag}(\sigma_1^2, \ ... \ , \sigma_r^2)$


If $A$ is square and symmetric, then $A = A^T$ and $A^T A = A A^T = A^2$ 
* and any eigenvector $\mathbf v$ of $A$ with eigenvalue $\lambda$ is eigenvector of $A^2$ with eigenvalue $\lambda^2$
* so $U = V$ and EVD = SVD when $A$ is positive semi-definite (no negative eigenvalues)



== Geometric Interpretation ==
Let's understand how $A$ deforms the space 
* consider a unit sphere in $\mathbb R^n$ 
* a vector $\mathbf x \in \mathbb R^n$ is represented as $\mathbf x = \sum x_i \mathbf v_i$
* because it's a sphere, $\sum x_i^2 = 1$
* then the image $A \mathbf x = \sum x_i A \mathbf v_i = \sum x_i A \mathbf v_i = \sum \sigma_i x_i \mathbf u_i$
* let $y_i = x_i \sigma_i$
* then $A \mathbf x = \sum y_i \mathbf u_i$
* $\sum\limits_{i = 1}^r \cfrac{y_i^2}{\sigma_i^2} = \sum\limits_{i = 1}^r x_i^2 \leqslant 1$
* if $A$ has full rank, then the sum is strictly $1$

So $A$ maps the unit sphere in $\mathbb R^n$ to some $r$-dimensional ellipsoid in $\mathbb R^m$ with axes in directions $\mathbf u_i$, each with magnitudes $\sigma_i$


* Linear transformation:
* So first it collapses $n - r$ dimensions of the domain 
* then it distorts the remaining dimensions stretching and squeezing the $r$-dim unit sphere into an ellipsoid
* finally it embeds the ellipsoid into $\mathbb R^m$ 
* http://habrastorage.org/files/b78/2d1/d28/b782d1d2846a44e5bd58780eb89589a0.png
* From (Kalman96)
* $n = m = 3$, $r = 2$



Another way:
* http://habrastorage.org/files/3ca/397/588/3ca39758812f4e159a9785ef44e92fe1.png
* From (Strang93)


== Representation ==
=== Partitioned Matrices ===
Let's have a look at $A = U \Sigma V^T$ for $m \times n$ matrix $A$: 
* &lt;math&gt;A = \left[ \begin{array}{cccc|ccc} 
| &amp; | &amp; &amp; | &amp; | &amp; &amp; | \\
| &amp; | &amp; &amp; | &amp; | &amp; &amp; | \\
\mathbf u_1 &amp; \mathbf u_2 &amp; \cdots &amp; \mathbf u_r &amp; \mathbf u_{r+1} &amp; \cdots &amp; \mathbf u_m \\ 
| &amp; | &amp; &amp; | &amp; | &amp; &amp; | \\
| &amp; | &amp; &amp; | &amp; | &amp; &amp; | \\
\end{array} \right]
\left[ \begin{array}{cccc|ccc} 
\sigma_1            &amp;        &amp;           &amp;        &amp; \\
&amp;          \sigma_2 &amp;        &amp;           &amp;        &amp; \\
&amp;          &amp;          \ddots   &amp;           &amp;        &amp; \\
&amp;          &amp;          &amp;        \sigma_r  &amp;        &amp; \\
\hline
&amp;          &amp;          &amp;        &amp;           0        &amp; \\
&amp;          &amp;          &amp;        &amp;           &amp; \ddots &amp; \\
&amp;          &amp;          &amp;        &amp;           &amp;        &amp; 0 \\
\end{array} \right]
\begin{bmatrix} 
- &amp; \mathbf v_1^T &amp; - \\
  &amp; \vdots &amp;  \\
- &amp; \mathbf v_1^T &amp; - \\
\hline
- &amp; \mathbf v_{r+1}^T &amp; - \\
  &amp; \vdots &amp;  \\
- &amp; \mathbf v_n^T &amp; - \\
\end{bmatrix}&lt;/math&gt;
* Then using [[Matrix Multiplication]] for block-partitioned matrices, we see that 
* &lt;math&gt;A = \begin{bmatrix} 
| &amp; | &amp; &amp; | \\
\mathbf u_1 &amp; \mathbf u_2 &amp; \cdots &amp; \mathbf u_r \\ 
| &amp; | &amp; &amp; | \\
\end{bmatrix}
\begin{bmatrix} 
\sigma_1            &amp;        &amp; \\
&amp;          \sigma_2 &amp;        &amp; \\
&amp;          &amp;          \ddots   &amp; \\
&amp;          &amp;          &amp;        \sigma_r \\
\end{bmatrix}
\begin{bmatrix} 
- &amp; \mathbf v_1^T &amp; - \\
  &amp; \vdots &amp;  \\
- &amp; \mathbf v_1^T &amp; - \\
\end{bmatrix}
+
\begin{bmatrix} 
| &amp; &amp; | \\
\mathbf u_{r+1} &amp; \cdots &amp; \mathbf u_m \\ 
| &amp; &amp; | \\
\end{bmatrix}
\begin{bmatrix} 
0 &amp;        &amp;   \\
  &amp; \ddots &amp;   \\
  &amp;        &amp; 0 \\
\end{bmatrix}
\begin{bmatrix} 
- &amp; \mathbf v_{r+1}^T &amp; - \\
  &amp; \vdots &amp;  \\
- &amp; \mathbf v_n^T &amp; - \\
\end{bmatrix}&lt;/math&gt;
* so, &lt;math&gt;A = 
\begin{bmatrix} 
| &amp; | &amp; &amp; | \\
\mathbf u_1 &amp; \mathbf u_2 &amp; \cdots &amp; \mathbf u_r \\ 
| &amp; | &amp; &amp; | \\
\end{bmatrix}
\begin{bmatrix} 
\sigma_1            &amp;        &amp; \\
&amp;          \sigma_2 &amp;        &amp; \\
&amp;          &amp;          \ddots   &amp; \\
&amp;          &amp;          &amp;        \sigma_r \\
\end{bmatrix}
\begin{bmatrix} 
- &amp; \mathbf v_1^T &amp; - \\
  &amp; \vdots &amp;  \\
- &amp; \mathbf v_1^T &amp; - \\
\end{bmatrix}
&lt;/math&gt;

* so only first $r$ $\mathbf v_i$'s and $\mathbf u_i$'s contribute something
* now $U$ and $V$ become rectangular and $\Sigma$ square:


SVD is $A = U \Sigma V^T$
* $U$ is $m \times r$ matrix s.t. $U^T U = I$
* $\Sigma$ is $r \times r$ diagonal matrix $\text{diag}(\sigma_1, \ ... \ , \sigma_r)$
* $V$ is $n \times r$ matrix s.t. $V^T V = I$

=== [[Outer Product]] Form ===
A matrix multiplication $AB$ can be expressed as a sum of outer products:
* let $A$ be $n \times k$ matrix and $B$ be $k \times m$ matrix
* then $AB = \sum\limits_{i=1}^k \mathbf a_i \mathbf b_i^T$
* where $\mathbf a_i$ are columns of $A$ and $\mathbf b_i$ are rows of $B$

Thus we can represent $A = U \Sigma V^T$ as sum of outer products:
* $A = \sum\limits_{i = 1}^r \sigma_i \mathbf u_i \mathbf v_i^T$

It gives another way of thinking about the Linear Tranformation $f(\mathbf x) = A \mathbf x$
* $A \mathbf x = (\sum \sigma_i \mathbf u_i \mathbf v_i^T) \mathbf x = \sum \sigma_i \mathbf u_i (\mathbf v_i^T \mathbf x) = \sum \sigma_i (\mathbf v_i^T \mathbf x) \mathbf u_i$
* so we express $A \mathbf x$ as a linear combination of $\{ \ \mathbf u_i \ \}$


=== Truncated SVD ===
Usual SVD:
* $A = U \Sigma V$ 
* $\sigma_i$ in $\text{diag}(\Sigma)$ are in non-increasing order
* so we can keep only first $k$ singular values of $\Sigma$ (and set the rest to 0) and get the best rank-$k$ approximation of $A$ 
* this is the best approximation in terms of Total Least Squares (see [[Reduced Rank Approximation]])


In terms of sum of rank-1 matrices, we can approximate $A$ by
* $A_k = \sum_{i = 1}^k \sigma_i \mathbf u_i \mathbf v_i^T$



== Properties &amp; Questions ==
=== Column Space and Row Space ===
Given SVD $A V = U \Sigma$, why $U$ in is the column space of $A$ and $V$ is the row space?
* For all $i$: $A \mathbf v_i = \sigma_i \mathbf u_i$. Since there's a solution, then $\sigma_i \mathbf u_i \in C(A)$
* for all $i$: $A^T \mathbf u_i = \sigma_i \mathbf v_i$. Then $\sigma_i \mathbf u_i \in C(A^T)$ which is the row space of $A$ 


== Applications ==
=== [[Dimensionality Reduction]] ===
[[Principal Component Analysis]]
* PCA is often implemented through SVD


Data Compression
* Truncated SVD gives the best rank-$k$ approximation to the original matrix $A$ 
* when using [[Frobenius Norm]] in the [[Matrix Vector Spaces|Matrix Vector Space]]
* the problem is [[Reduced Rank Approximation]] (sometimes Total Least Squares)


It's like Discrete [[Fourier Transformation]]:
* in DFT we represent a data vector in orthogonal basis of sines and cosines
* often there are only a few principal frequencies that account for most variability in the data and the rest can be discarded 
* SVD does the same, but it find the best orthogonal basis instead of using a predefined one
* so we can see SVD as adaptive generalization of DFT


Image Compression
* images can be represented as Matrices, so we can apply SVD and PCA to them
* http://habrastorage.org/files/855/a65/c62/855a65c624dc4174b526fb5e03b98555.png
* source: SVD at work [http://web.mit.edu/18.06/www/Fall03/svd.pdf] from [http://web.mit.edu/18.06/www/extras.shtml]




=== [[Latent Semantic Analysis]] ===
* When used as a Dimensionality Reduction technique for Term-Document matrix
* it helps revealing some hidden semantic patterns


=== [[Linear Least Squares]] ===
As a technique for faster [[Normal Equation]] computation
* but generally [[QR Decomposition]] is better, but sometimes less stable


=== Others ===
There are many other applications


== See Also ==
* [[Eigendecomposition]] and [[Spectral Theorem]]
* Note that $A A^T$ and $A^T A$ are called [[Gram Matrices]]


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Strang, G. Introduction to linear algebra.
* Jauregui, Jeff. &quot;Principal component analysis with linear algebra.&quot; (2012). [http://www.math.union.edu/~jaureguj/PCA.pdf]
* Kalman, Dan. &quot;A singularly valuable decomposition: the SVD of a matrix.&quot; (1996). [http://www.math.washington.edu/~morrow/498_13/svd.pdf]
* Strang, Gilbert. &quot;The fundamental theorem of linear algebra.&quot; (1993). [http://www.engineering.iastate.edu/~julied/classes/CE570/Notes/strangpaper.pdf]


[[Category:Linear Algebra]]
[[Category:Matrix Decomposition]]</text>
      <sha1>2bkvue5en9zy95ku5y4hnxjuglf5v1u</sha1>
    </revision>
  </page>
  <page>
    <title>QR Factorization</title>
    <ns>0</ns>
    <id>562</id>
    <revision>
      <id>565</id>
      <timestamp>2015-04-26T15:14:17Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="52">#перенаправление [[QR Decomposition]]</text>
      <sha1>1gp260jxcqya1g6jftqknksoqx5henr</sha1>
    </revision>
  </page>
  <page>
    <title>Frobenius Norm</title>
    <ns>0</ns>
    <id>563</id>
    <revision>
      <id>566</id>
      <timestamp>2015-05-22T19:30:11Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4610">== Frobenius Norm ==
Is a norm for [[Matrix Vector Spaces]]: a vector space of matrices
* Define [[Inner Product]] element-wise: $\langle A, B \rangle = \sum_{ij} a_{ij} b_{ij}$
* then the norm based on this product is $\| A \|_F = \langle A, A \rangle$
* this norm is ''Frobenius Norm''


Orthogonality:
* Matrices $A$ and $B$ are orthogonal if $\langle A, B \rangle = 0$


== Norm of [[Matrix Multiplication]] ==
=== [[Outer Product|Rank-1 Matrices]] ===
What about the norm of two rank-1 matrices?
* let $A = \mathbf x \mathbf y^T$ and $B = \mathbf u \mathbf v^T$ 
* then $\langle A, B \rangle = \langle \mathbf x \mathbf y^T, \mathbf u \mathbf v^T \rangle$
* $\mathbf x \mathbf y^T = \begin{bmatrix}
| &amp; &amp; | \\
\mathbf x y_1 &amp; \cdots &amp; \mathbf x y_n \\ 
| &amp; &amp; | \\
\end{bmatrix}$ and $\mathbf u \mathbf v^T = \begin{bmatrix}
| &amp; &amp; | \\
\mathbf u v_1 &amp; \cdots &amp; \mathbf u v_n \\ 
| &amp; &amp; | \\
\end{bmatrix}$
* thus, $\langle \mathbf x \mathbf y^T, \mathbf u \mathbf v^T \rangle = \sum\limits_i \langle \mathbf x y_i , \mathbf u v_i \rangle = \langle \mathbf x, \mathbf u \rangle \sum_i y_i v_i = \langle \mathbf x, \mathbf u \rangle  \langle \mathbf y, \mathbf v \rangle$


Orthogonality
* so two rank-1 matrices will be orthogonal if $\mathbf x \; \bot \; \mathbf u$ or $\mathbf y \; \bot \; \mathbf v$


=== General Case ===
* Let $X$ and $Y$ be two matrices
* and $\mathbf x_i$ be the columns of $X$ and $\mathbf y_i^T$ be the rows of $Y$
* then norm of the multiplication is $\| XY \|_F = \langle XY, XY \rangle = (\sum_i \mathbf x_i \mathbf y_i^T) (\sum_j \mathbf x_j \mathbf y_j^T) = \sum_{ij} \langle \mathbf x_i \mathbf x_j \rangle \langle \mathbf y_i \mathbf y_j \rangle = \sum_i \| \mathbf x_i \|^2 \| \mathbf y_i \|^2 + \sum_{i \ne j} \langle \mathbf x_i \mathbf x_j \rangle \langle \mathbf y_i \mathbf y_j \rangle$


if $\mathbf x_i$ are orthogonal, then
* $\| XY \|_F = \sum_i \| \mathbf x_i \|^2 \| \mathbf y_i \|^2$ (cross terms are 0 because of orthogonality)


if $\mathbf x_i$ are orthonormal, then
* $X$ is an [[Orthogonal Matrix]]
* $\| XY \|_F = \sum_i \| \mathbf y_i \|^2 = \| Y \|^2_F$


Same applies if $\mathbf y_i$ are orthogonal/orthonormal 



== Norm of Matrices ==
=== [[Outer Product|Rank-1 Matrices]] ===
Suppose $A$ is a rank-1 matrix, i.e. $A = \mathbf x \mathbf y^T$
* $A = \mathbf x \mathbf y^T = \begin{bmatrix}
| &amp; &amp; | \\
\mathbf x y_i &amp; \cdots &amp; \mathbf x y_n \\
| &amp; &amp; | \\
\end{bmatrix} = 
\begin{bmatrix}
- &amp; x_1 \mathbf y &amp; - \\
 &amp; \vdots &amp;  \\
- &amp; x_n \mathbf y &amp; - 
\end{bmatrix} =
\begin{bmatrix}
x_1 y_1 &amp; \cdots &amp; x_1 y_n \\
\vdots &amp; \ddots &amp; \vdots \\
x_n y_1 &amp; \cdots &amp; x_n y_n \\
\end{bmatrix}$ 
* thus $\| A \|^2_F = \sum_i \| y_i \mathbf x \|^2 = \sum_i \| x_i \mathbf y \|^2 = \sum_{ij} (x_i y_j)^2$
* can simplify it further: $\| A \|^2_F = \sum_i \| y_i \mathbf x \|^2 = \sum_i y_i^2 \| \mathbf x \|^2 = \| \mathbf x \|^2 \sum_i y_i^2 = \| \mathbf x \|^2 \| \mathbf y \|^2$



=== General Case ===
* If $A$ is an $m \times n$ matrix 
* and $\mathbf a_i$ are columns of $A$ and $\mathbf r_j$ are rows of $A$, then
* $\| A \|^2_F = \sum_{ij} A_{ij} = \sum_i \| \mathbf a_i \|^2 = \sum_j \| \mathbf r_j \|^2$


Using [[SVD]], we can find another way:
* SVD of $A$ is $A V = U \Sigma$
* then $\| A V \|_F^2 = \| U \Sigma \|_F^2$
* both $V$ and $U$ are orthonormal, thus by norm multiplication have 
* then $\| A \|_F^2 = \| \Sigma \|_F^2$
* or, $\| A \|_F^2 = \sum_{i=1}^r \sigma_i^2$ - sum of singular values, and $\| A \|_F = \sqrt{\sum_{i=1}^r \sigma_i^2}$


== Properties ==
For any matrix $A$, $\| A \|_F = \sqrt{\text{tr}(AA^T)} = \sqrt{\text{tr}(A^T A)}$
* $\| A \|_F^2 = \sum_{i=1}^n \| \mathbf a_i \|^2$ where $\mathbf a_i$ are columns of $A$ 
* consider $A^T A$: on the main diagonal we have $\mathbf a_i^T \mathbf a_i = \| \mathbf a_i \|^2$
* so $\| A \|_F^2 = \text{tr}(A^T A)$
* can show the same way for rows of $A$ via $A A^T$


Can also apply SVD to show that:
* let $A = U \Sigma V^T$ be SVD of A
* then $\| A \|_F^2 = \| \Sigma \|_F^2 = \sum\limits_{i=1}^r \sigma_i^2$
* $\sigma_i^2$ are [[Eigenvalues]] of $AA^T$ and $A^TA$
* then, $\sum \sigma_i^2 = \text{tr}(A A^T) = \text{tr}(A^T A)$ 
* so it also shows that sum of eigenvalues is the trace of the matrix


== Application ==
This is used for [[Reduced Rank Approximation]] to show that [[SVD]] gives the best approximation in terms of Total Least Squares


== Sources ==
* Kalman, Dan. &quot;A singularly valuable decomposition: the SVD of a matrix.&quot; (1996). [http://www.math.washington.edu/~morrow/498_13/svd.pdf]


[[Category:Linear Algebra]]
[[Category:Vector Spaces]]
[[Category:Norms]]</text>
      <sha1>4le74lst15ghnsbtq8m34ak1qo23eiv</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Vector Spaces</title>
    <ns>14</ns>
    <id>564</id>
    <revision>
      <id>567</id>
      <timestamp>2015-04-26T16:03:33Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27">[[Category:Linear Algebra]]</text>
      <sha1>1o0hp9w6lazhtrq9wq68p3anq0bhkp4</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Norms</title>
    <ns>14</ns>
    <id>565</id>
    <revision>
      <id>568</id>
      <timestamp>2015-04-26T16:03:42Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27">[[Category:Linear Algebra]]</text>
      <sha1>1o0hp9w6lazhtrq9wq68p3anq0bhkp4</sha1>
    </revision>
  </page>
  <page>
    <title>Outer Product</title>
    <ns>0</ns>
    <id>566</id>
    <revision>
      <id>569</id>
      <timestamp>2015-04-26T16:11:55Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1199">== Rank One Matrices ==
Suppose we have two vectors $\mathbf u \in \mathbb R^m$ and $\mathbf v \in \mathbb R^n$. Then multiplication $\mathbf u \times \mathbf v^T$ gives us a matrix $A = \mathbf u \cdot \mathbf v^T$, $A \in \mathbb R^{m \times n}$
* This multiplication produces [[Rank (Matrix)|rank]]-1 matrices


=== Rank 1 Matrices ===
$\mathbf u \times \mathbf v^T = \begin{bmatrix}
a \\ b \\ c
\end{bmatrix} \big[1 \ 2 \big] = \begin{bmatrix}
1a &amp; 2a \\ 
1b &amp; 2b \\ 
1c &amp; 2c
\end{bmatrix}$


== Subspaces ==
This matrix $A$ is a special matrix: 
* all these rows lie on the same line
* all these columns are same directions 

[[Four Fundamental Subspaces|Subspaces]]:
* [[Row Space]]: all combinations of $\mathbf v$ 
* [[Column Space]]: all combinations of  $\mathbf u$


== [[Projection Matrices]] == 
Suppose we want to project to a line $\mathbf u$ 
* then the Projection Matrix $P$ is $P = \cfrac{\mathbf u \mathbf u^T}{\| \mathbf u\|^2} = \mathbf u \mathbf u^T$
* if $\mathbf u$ is a unit vector, e.g. $\| \mathbf u \|^2 = 1$
* then the projection matrix is just an outer product of $\mathbf u$ with itself


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>cndf8ufhkmjwwdtpebjfdmnma9ns99v</sha1>
    </revision>
  </page>
  <page>
    <title>Row Space</title>
    <ns>0</ns>
    <id>567</id>
    <revision>
      <id>570</id>
      <timestamp>2015-04-26T16:14:58Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1155">== Row Space ==
This is one of the [[Four Fundamental Subspaces]]

A ''Row Space'' $C(A^T)$ of a matrix $A$ is all linear combinations of rows of $A$, or all combinations of columns of $A^T$


Row Space
* $\text{dim } C(A^T) = r = \text{dim } C(A)$, there are $r$ pivot rows - the same dim as for Column Space
* basis: maximal system of linearly independent vectors from $A^T$ 
* when we get [[Row Reduced Echelon Form]] $R$ by applying [[Gaussian Elimination]] to $A$, the column space changes, so $C(A) \ne C(R)$
* but because we did row operations the row space should remain the same: it changed only the column space
* so $C(A^T) = C(R^T)$
* alternatively, we can take first $r$ rows of $R$ for the basis 


Why the row space remains the same? 
* all the operations were performed on rows - and we  allowed to do only linear combinations 
* so each linear operation gives us rows from the same space 
* we may change the basis, but the space remains the same 
* and cleanest form of the row space is the rows from $R$ 


== See Also ==
* [[Four Fundamental Subspaces]]


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>da8osgef72a5rzg1ow8lcarmm2327zk</sha1>
    </revision>
  </page>
  <page>
    <title>Linear Independence</title>
    <ns>0</ns>
    <id>568</id>
    <revision>
      <id>571</id>
      <timestamp>2015-04-26T16:16:52Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1903">== Linear Independence ==
Vectors $\mathbf x_1, \mathbf x_2, ... , \mathbf x_n$ are ''linearly independent'' if no linear combinations gives a zero vector $\mathbf 0$ 
* $c_1 \mathbf x_1 + c_2 \mathbf x_2 + ... + c_n \mathbf x_n \ne \mathbf 0$ 
* only when $\forall i: c_i = 0$ it's true that $\sum c_i \mathbf x_i = 0$


=== Examples ===
Example 1
* suppose we have a vector $v_1$ and a vector $v_2 = c \cdot v_1$
* http://habrastorage.org/files/807/633/b50/807633b501c745a595e6a0a12277cedb.png
* this system is dependent 

Zero vector always means a dependence 
* suppose we have vector $v_1 \ne \mathbf 0$ and $v_2 = \mathbf 0$
* $0 \mathbf v_1 + c \mathbf v_2 = \mathbf 0$ for any $c$ 


Example 2 
* suppose we have a system of two independent vectors $v_1$ and $v_2$ in $\mathbb R^2$ 
* http://habrastorage.org/files/946/d4f/5d4/946d4f5d4d424e449407115d672c2a69.png
* what happens if we add 3rd vectors $v_3$? 
* http://habrastorage.org/files/13e/fdc/9f5/13efdc9f56154152b8a62bcc7061f8d6.png
* the system is no longer dependent - we always can express $v_3$ in terms of $v_1$ and $v_2$ and when we add them, we'll have 0
* so if the number of vectors is greater than the dimensionality of these vectors, the system cannot be independent


=== Matrices ===
Columns of a matrix $A$ are independent if the [[Nullspace]] $N(A)$ contains only $\mathbf 0$
* otherwise the columns are dependents
* Why? recall that $N(A)$ contains the solutions to the [[Homogeneous Systems of Linear Equations|system $A\mathbf x = \mathbf 0$]] 
** so there's a combination of columns with coefficients $\mathbf x$ that is equal to $\mathbf 0$ 
* It's related to [[Rank (Matrix)|rank]] as well: 
** if $r = n$,  then there are no free variables and $N(A) = \{ \, \mathbf 0 \, \}$
** if $r &lt; n$, there are free variables and $| N(A) | &gt; 1$



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>4c21phqhjfaotbcm2xrq7mbxmdhthbe</sha1>
    </revision>
    <revision>
      <id>788</id>
      <parentid>571</parentid>
      <timestamp>2017-06-27T10:50:28Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2275">== Linear Independence ==
Vectors $\mathbf x_1, \mathbf x_2, ... , \mathbf x_n$ are ''linearly independent'' if no linear combinations gives a zero vector $\mathbf 0$ 
* $c_1 \mathbf x_1 + c_2 \mathbf x_2 + ... + c_n \mathbf x_n \ne \mathbf 0$ 
* only when $\forall i: c_i = 0$ it's true that $\sum c_i \mathbf x_i = 0$


=== Examples ===
Example 1
* suppose we have a vector $v_1$ and a vector $v_2 = c \cdot v_1$
* http://habrastorage.org/files/807/633/b50/807633b501c745a595e6a0a12277cedb.png
* this system is dependent: $v_2$ points in the same direction as $v_1$ 

Zero vector always means a dependence 
* suppose we have vector $v_1 \ne \mathbf 0$ and $v_2 = \mathbf 0$
* $0 \mathbf v_1 + c \mathbf v_2 = \mathbf 0$ for any $c$ 


Example 2 
* suppose we have a system of two independent vectors $v_1$ and $v_2$ in $\mathbb R^2$ 
* http://habrastorage.org/files/946/d4f/5d4/946d4f5d4d424e449407115d672c2a69.png
* what happens if we add 3rd vectors $v_3$? 
* http://habrastorage.org/files/13e/fdc/9f5/13efdc9f56154152b8a62bcc7061f8d6.png
* the system is no longer dependent - we always can express $v_3$ in terms of $v_1$ and $v_2$ and when we add them, we'll have 0
* so if the number of vectors is greater than the dimensionality of these vectors, the system cannot be independent


=== Matrices ===
Columns of a matrix $A$ are independent if the [[Nullspace]] $N(A)$ contains only $\mathbf 0$
* otherwise the columns are dependents
* Why? recall that $N(A)$ contains the solutions to the [[Homogeneous Systems of Linear Equations|system $A\mathbf x = \mathbf 0$]] 
** so there's a combination of columns with coefficients $\mathbf x$ that is equal to $\mathbf 0$ 
* It's related to [[Rank (Matrix)|rank]] as well: 
** if $r = n$,  then there are no free variables and $N(A) = \{ \, \mathbf 0 \, \}$
** if $r &lt; n$, there are free variables and $| N(A) | &gt; 1$


== Maximal Linearly Independent Subset ==
Suppose we have a set of vectors $A = \{ \mathbf a_i \}$
* subset $A^*$ is maximal linearly independent subset of $A$ if
* all vectors in $A^*$ are linearly independent 
* it's not contained in any other subset of linearly idependent vectors from $A$


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* [[Matrix Computations (book)]]

[[Category:Linear Algebra]]</text>
      <sha1>rvpjpw091yp9is4fh04e747swq22p3r</sha1>
    </revision>
  </page>
  <page>
    <title>Matrix</title>
    <ns>0</ns>
    <id>569</id>
    <revision>
      <id>572</id>
      <timestamp>2015-04-26T16:23:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1695">{{stub}}

== Matrix ==
In [[Linear Algebra]] a $m \times n$ matrix $A$ is a rectangular array with $m$ rows and $n$ columns:

$A = \begin{bmatrix}
a_{11} &amp; a_{12} &amp; ... &amp; a_{1n}\\ 
a_{21} &amp; a_{22} &amp; ... &amp; a_{2n}\\ 
... &amp; ... &amp;  ... &amp; ... \\ 
a_{m1} &amp; a_{m2} &amp; ... &amp; a_{mn}
\end{bmatrix}$

$\{a_{ij}\}$ (or $(A)_{ij}$) are components of the matrix $A$

if $m = n$, then $A$ is called ''rectangular''

$(a_{11}, a_{22}, ..., a_{nn})$ are diagonal elements


== Operations ==
* [[Matrix Multiplication]]: Can multiply a matrix by a scalar, by a vector or by another matrix
* [[Matrix Transposition]]
* [[Inverse Matrices|Inversion]] 
* ...


== Types ==
Matrices can be:
* square $n \times n$ and rectangular $m \times n$ 
* [[Outer Product|Rank-1 Matrices]]
* Identity matrices 
* [[Symmetric Matrices]]
* [[Orthogonal Matrices]]
* [[Rotation Matrices]]
* [[Similar Matrices]]
* [[Positive-Definite Matrices]]


== Decompositions ==
* [[LU Decomposition]]: $A = LU$ where $L$ is lower triangular and $U$ is upper triangular
* [[QR Decomposition]]: $A = QR$ where $Q$ 
* [[Eigendecomposition]]: $A = S \Lambda S^{-1}$ with diagonal $\Lambda$ 
* special case of EVD: [[Spectral Theorem]]: $A = Q \Lambda Q^T$ with diagonal $\Lambda$ and Orthogonal $Q$
* [[Singular Value Decomposition]]: $A = U \Sigma V^T$ with diagonal $\Sigma$ and orthogonal $U$ and $V$ 


== Matrices as Vectors ==
We can see matrices as vectors, and they also can form [[Vector Spaces]]
* see [[Matrix Vector Spaces]]
* they have inner product (element-wise) and norm ([[Frobenius Norm]])


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Курош А.Г. Курс Высшей Алгебры

[[Category:Linear Algebra]]</text>
      <sha1>2dhexou6cbusu4uj2r6krbm0lnolaz5</sha1>
    </revision>
  </page>
  <page>
    <title>Spectral Theorem</title>
    <ns>0</ns>
    <id>570</id>
    <revision>
      <id>573</id>
      <timestamp>2015-04-26T16:24:30Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1734">== Spectral Theorem ==
Spectral Theorem is also sometimes called Principal Axis Theorem
* In [[Linear Algebra]] a Spectrum is a set of [[Eigenvalues and Eigenvectors|Eigenvectors]] of a matrix 


'''Theorem''':
* Every [[Symmetric Matrices|Symmetric Matrix]] can be factorized as $A = Q \Lambda Q^T$
* with real eigenvalues $\Lambda$ and orthonormal eigenvectors in the columns of $Q$


The factorization is [[Eigendecomposition]]
* Spectral Theorem is a special case for symmetric matrices
* See the proof in the [[Symmetric Matrices]] article


=== Sum of [[Outer Product|Rank One]] Matrices ===
We can look differently at the results of [[Eigendecomposition]] of $A$ 

* $A = Q \Lambda Q^T = \begin{bmatrix} 
| &amp; &amp; | \\
\mathbf q_1 &amp; \cdots &amp; \mathbf q_n \\
| &amp; &amp; | \\
\end{bmatrix} 
\begin{bmatrix} 
\lambda_1 &amp; &amp;  \\
 &amp; \ddots &amp;  \\
 &amp; &amp; \lambda_n  \\
\end{bmatrix}
\begin{bmatrix} 
- &amp; \mathbf q_1^T &amp; - \\
 &amp; \vdots &amp; \\
- &amp; \mathbf q_n^T &amp; - \\
\end{bmatrix}$
* can represent it as $A = Q \Lambda Q^T = \sum \lambda_i \mathbf q_i  \mathbf q_i^T$ - sum of [[Outer Product]]s
* each of these outer products can be seen as a [[Projection Matrices|Projection Matrix]]
* a projection matrix is $P_i = \cfrac{\mathbf q_i \mathbf q_i^T}{\| \mathbf q_i \|^2} = \mathbf q_i \mathbf q_i^T$
* so symmetric matrix can be represented as a combination of mutually orthogonal projection matrices


== Applications ==
[[Principal Component Analysis]]
* The Spectral Theorem guarantees that we will find an orthogonal basis in PCA
* Because the [[Covariance Matrix]] $C = \cfrac{1}{n - 1} X^T X$ is symmetric and [[Positive-Definite Matrices|Positive-Definite]]


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>oc3svv4pg6sjs9lqc7g2j2hs99cnz9g</sha1>
    </revision>
    <revision>
      <id>665</id>
      <parentid>573</parentid>
      <timestamp>2015-11-13T21:26:34Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1745">== Spectral Theorem ==
Spectral Theorem is also sometimes called Principal Axis Theorem
* In [[Linear Algebra]] a Spectrum is a set of [[Eigenvalues and Eigenvectors|Eigenvectors]] of a matrix 


'''Theorem''':
* Every [[Symmetric Matrices|Symmetric Matrix]] can be factorized as $A = Q \Lambda Q^T$
* with real eigenvalues $\Lambda$ and orthonormal eigenvectors in the columns of $Q$


The factorization is [[Eigendecomposition]]
* Spectral Theorem is a special case for symmetric matrices
* See the proof in the [[Symmetric Matrices]] article


=== Sum of [[Outer Product|Rank One]] Matrices ===
We can look differently at the results of [[Eigendecomposition]] of $A$ 

* &lt;math&gt;A = Q \Lambda Q^T = \begin{bmatrix} 
| &amp; &amp; | \\
\mathbf q_1 &amp; \cdots &amp; \mathbf q_n \\
| &amp; &amp; | \\
\end{bmatrix} 
\begin{bmatrix} 
\lambda_1 &amp; &amp;  \\
 &amp; \ddots &amp;  \\
 &amp; &amp; \lambda_n  \\
\end{bmatrix}
\begin{bmatrix} 
- &amp; \mathbf q_1^T &amp; - \\
 &amp; \vdots &amp; \\
- &amp; \mathbf q_n^T &amp; - \\
\end{bmatrix}&lt;/math&gt;
* can represent it as $A = Q \Lambda Q^T = \sum \lambda_i \mathbf q_i  \mathbf q_i^T$ - sum of [[Outer Product]]s
* each of these outer products can be seen as a [[Projection Matrices|Projection Matrix]]
* a projection matrix is $P_i = \cfrac{\mathbf q_i \mathbf q_i^T}{\| \mathbf q_i \|^2} = \mathbf q_i \mathbf q_i^T$
* so symmetric matrix can be represented as a combination of mutually orthogonal projection matrices


== Applications ==
[[Principal Component Analysis]]
* The Spectral Theorem guarantees that we will find an orthogonal basis in PCA
* Because the [[Covariance Matrix]] $C = \cfrac{1}{n - 1} X^T X$ is symmetric and [[Positive-Definite Matrices|Positive-Definite]]


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>ss05u05wm3z1w6xrjijgoyjjggnrdak</sha1>
    </revision>
    <revision>
      <id>812</id>
      <parentid>665</parentid>
      <timestamp>2017-08-10T20:05:41Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1744">== Spectral Theorem ==
Spectral Theorem is also sometimes called Principal Axis Theorem
* In [[Linear Algebra]] a Spectrum is a set of [[Eigenvalues and Eigenvectors|Eigenvalues]] of a matrix 


'''Theorem''':
* Every [[Symmetric Matrices|Symmetric Matrix]] can be factorized as $A = Q \Lambda Q^T$
* with real eigenvalues $\Lambda$ and orthonormal eigenvectors in the columns of $Q$


The factorization is [[Eigendecomposition]]
* Spectral Theorem is a special case for symmetric matrices
* See the proof in the [[Symmetric Matrices]] article


=== Sum of [[Outer Product|Rank One]] Matrices ===
We can look differently at the results of [[Eigendecomposition]] of $A$ 

* &lt;math&gt;A = Q \Lambda Q^T = \begin{bmatrix} 
| &amp; &amp; | \\
\mathbf q_1 &amp; \cdots &amp; \mathbf q_n \\
| &amp; &amp; | \\
\end{bmatrix} 
\begin{bmatrix} 
\lambda_1 &amp; &amp;  \\
 &amp; \ddots &amp;  \\
 &amp; &amp; \lambda_n  \\
\end{bmatrix}
\begin{bmatrix} 
- &amp; \mathbf q_1^T &amp; - \\
 &amp; \vdots &amp; \\
- &amp; \mathbf q_n^T &amp; - \\
\end{bmatrix}&lt;/math&gt;
* can represent it as $A = Q \Lambda Q^T = \sum \lambda_i \mathbf q_i  \mathbf q_i^T$ - sum of [[Outer Product]]s
* each of these outer products can be seen as a [[Projection Matrices|Projection Matrix]]
* a projection matrix is $P_i = \cfrac{\mathbf q_i \mathbf q_i^T}{\| \mathbf q_i \|^2} = \mathbf q_i \mathbf q_i^T$
* so symmetric matrix can be represented as a combination of mutually orthogonal projection matrices


== Applications ==
[[Principal Component Analysis]]
* The Spectral Theorem guarantees that we will find an orthogonal basis in PCA
* Because the [[Covariance Matrix]] $C = \cfrac{1}{n - 1} X^T X$ is symmetric and [[Positive-Definite Matrices|Positive-Definite]]


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>l8eaeu0k382rozfbi79ciahxjs6ff68</sha1>
    </revision>
  </page>
  <page>
    <title>Eigendecomposition</title>
    <ns>0</ns>
    <id>571</id>
    <revision>
      <id>574</id>
      <timestamp>2015-04-26T16:26:25Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6231">== Eigen Decomposition ==
Eigen Decomposition or, sometimes, Eigenvalue Decomposition (shortcut EVD)
* is a way of diagonalizing a square $n \times n$ matrix $A$ 


We can turn a matrix into a diagonal one by using eigenvectors
* $A$ is square 


Eigenvalue decomposition is a decomposition of a matrix into a &quot;canonical form&quot;
* we want to constrict a diagonal matrix from a given one
* a matrix $A$ is ''diagonalizable'' if it's [[Similar Matrices|similar]] to a diagonal matrix
** (a matrix $A$ is similar to $B$ if there exists an invertible $M$ s.t. $B = M^{-1} A \, M$)
* $A$ is diagonalizable if there exists [[Inverse Matrices|invertible matrix]] $P$ s.t.  $P^{-1} A \, P$ is diagonal



Why can we do it?
* if all eigenvalues $\lambda_1, \ ... \ , \lambda_n$ are different 
* then all eigenvalues $\mathbf x_1, \ ... \ , \mathbf x_n$ are linearly independent
* so any matrix with distinct eigenvalues can be decomposed by eigenvalue decomposition
* see proof in [[Eigenvalues and Eigenvectors]]


Diagonalization:
* $S^{-1} A S = \Lambda$
* $\text{diag } \Lambda = (\lambda_1, \ ... \ , \lambda_n)$


Eigenvalue Decomposition:
* if $A$ is symmetric, then there exists $S$ and $\Lambda$ s.t.
* $A = S \Lambda S^T$
* because for symmetric $A$ the eigenvectors in $S$ are orthonormal, so $S$ is [[Orthogonal Matrices|Orthogonal]]



=== Intuition ===
Suppose we have $n$ linearly independent [[Eigenvalues and Eigenvectors|eigenvectors]] $\mathbf x_i$ of $A$
* let's put them in columns of a matrix $S$ - eigenvector matrix 
* $S = \begin{bmatrix}
| &amp; &amp; | \\
\mathbf x_1 &amp; ... &amp; \mathbf x_n \\
| &amp; &amp; | \\
\end{bmatrix}$


Now what if we multiply $AS$? 
* since all these $\mathbf x_i$ are eigenvectors, $A \mathbf x_i = \lambda_i \mathbf x_i$ 
* thus, $AS = A \begin{bmatrix}
| &amp; | &amp; &amp; | \\
\mathbf x_1 &amp; \mathbf x_2 &amp; ... &amp; \mathbf x_n \\
| &amp; | &amp; &amp; | \\
\end{bmatrix} = \begin{bmatrix}
| &amp; | &amp; &amp; | \\
\lambda_1 \, \mathbf x_1 &amp; \lambda_2 \, \mathbf x_2 &amp; ... &amp; \lambda_m \, \mathbf x_n \\
| &amp; | &amp; &amp; | \\
\end{bmatrix}$ 
* ok, now let's take the $\lambda_i$'s out: $\begin{bmatrix}
| &amp; &amp; | \\
\lambda_1 \, \mathbf x_1 &amp;  \lambda_2 \, \mathbf x_2 &amp; ... &amp; \lambda_m \, \mathbf x_n \\
| &amp; &amp; | \\
\end{bmatrix} = \begin{bmatrix}
| &amp; | &amp; &amp; | \\
\mathbf x_1 &amp; \mathbf x_2 &amp; ... &amp; \mathbf x_n \\
| &amp; | &amp;  &amp; | \\
\end{bmatrix} 
\begin{bmatrix}
\lambda_1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \lambda_2 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \lambda_n \\
\end{bmatrix}$
* let's call this diagonal matrix $\Lambda = \begin{bmatrix}
\lambda_1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \lambda_2 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \lambda_n \\
\end{bmatrix}$
* so $AS = S \Lambda$


=== Decomposition ===
* if $S$ is invertible (or all $\mathbf x_i$ are independent), then
* $\Lambda = S^{-1} A \, S$ - this is called ''diagonalization'' of $A$ 
* and $A = S \Lambda S^{-1}$ - another factorization of $A$ 
* if $A$ is diagonal, then $\Lambda = A$, but if it's triangular, we still need to calculate $\Lambda$


=== [[Symmetric Matrices]] ===
For symmetric $A$
* its eigenvalues are orthonormal,
* so the matrix $S$ is [[Orthogonal Matrices|orthogonal]]
* thus, $A = S \Lambda S^{-1} = S \Lambda S^T$
* So we write $A = Q \Lambda Q^T$, where $Q$ is orthogonal



== Use Cases ==
=== Calculating Powers: $A^k$ ===
* if $A \mathbf x = \lambda \mathbf x$ then 
* $A^2 \mathbf x = \lambda A \mathbf x = \lambda^2 \mathbf x$
* so $\lambda$s are squared when $A$ is squared 

same for diagonalizable matrices:
* $A^2 = A A = (S \Lambda S^{-1}) (S \Lambda S^{-1}) = S \Lambda^2 S^{-1}$
* and $A^k = S \Lambda^k S^{-1}$
* so this factorization is better for powers than [[LU Factorization]]

This is useful for calculating the steady state probabilities of [[Markov Chains]] - by calculating the powers of [[Stochastic Matrices]] - matrix representation of a Markov Chain


=== [[Recurrence Equation]] ===
Suppose you are given a vector $\mathbf u_0$ and a recurrent formula $\mathbf u_{k+1} = A \mathbf u_{k}$
* how would you find $\mathbf u_{100}$?
* can repeat it 100 times 
* or, note that $\mathbf u_{100} = A \mathbf u_{99} = A^2 \mathbf u_{98} = \ ... \ =  A^{100} \mathbf u_{0}$

* Suppose $A$ is invertible. 
* Then one possible basis for $A$ is its eigenvectors $\mathbf v_i$
* let's express $\mathbf u_0$ in this basis: $\mathbf u_0 = c_1 \mathbf v_1 + \ ... \ + c_n \mathbf v_n = S \mathbf c$
* now let's multiply both parts by $A$:  
** $A \mathbf u_0 = A c_1 \mathbf v_1 + \ ... \ + A c_n \mathbf v_n = A S \mathbf c$
** $A \mathbf u_0 = c_1 \lambda_1 \mathbf v_1 + \ ... \ + c_n \lambda_n \mathbf v_n = \Lambda S \mathbf c$
* then $\mathbf u_{100} = c_1 \lambda_1^{100} \mathbf v_1 + \ ... \ + c_n \lambda_n^{100} \mathbf v_n = \Lambda^{100} S \mathbf c$


=== [[Fibonacci Numbers]] ===
* Fibonacci numbers is a sequence 0, 1, 1, 2, 3, 5, 8, 13... 
* $F_{k + 2} = F_{k+ 1} + F_{k}$
* it's a second order Recurrence Equation
* Let's build a system: $\begin{cases}
F_{k+2} = F_{k+1} + F_{k} \\
F_{k+1} = F_{k+1} \\
\end{cases}$
* so let $\mathbf u_k = \begin{bmatrix} F_{k+1} \\ F_{k} \end{bmatrix}$, 
* then $\mathbf u_{k + 1} = \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 0 \end{bmatrix} \begin{bmatrix} F_{k+1} \\ F_{k} \end{bmatrix} = A \, \mathbf u_k$
* so we have the recurrence equation $\mathbf u_{k+1} = A \mathbf u_k$
* note that $A$ is symmetric, so it's diagonalizable 
* let's find eigenvalues:
** $| A - \lambda I | = \begin{vmatrix}
1 - \lambda &amp; 1 \\ 
1  &amp; -\lambda 
\end{vmatrix} = \lambda^2 - \lambda - 1 = 0$ 
** or $\lambda_{1,2} = \cfrac{1 \pm \sqrt{1+4}}{2} = \cfrac{1 \pm \sqrt{5}}{2}$ 
** $\lambda_1 = 0.5 (1 + \sqrt{5}) \approx  1.618$
** $\lambda_1 = 0.5 (1 - \sqrt{5}) \approx -0.618$
* so, $\mathbf u_{100} = c_1 \lambda_1^{100} \mathbf v_1 + c_2 \lambda_2^{100} \mathbf v_2$
** $\lambda_1 &gt; 1$ so powers of it grow faster, and $|\lambda_2| &lt; 1$, so its powers decay
** thus $\lambda_1$ controls everything
* and we can approximate $F_{100} \approx c_1 \lambda_1^{100}$




== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* http://en.wikipedia.org/wiki/Diagonalizable_matrix
* Strang, G. Introduction to linear algebra.


[[Category:Linear Algebra]]
[[Category:Matrix Decomposition]]</text>
      <sha1>lj48orfdc1t12hpcpi7t73oyq511tuo</sha1>
    </revision>
    <revision>
      <id>666</id>
      <parentid>574</parentid>
      <timestamp>2015-11-13T21:31:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6301">== Eigen Decomposition ==
Eigen Decomposition or, sometimes, Eigenvalue Decomposition (shortcut EVD)
* is a way of diagonalizing a square $n \times n$ matrix $A$ 


We can turn a matrix into a diagonal one by using eigenvectors
* $A$ is square 


Eigenvalue decomposition is a decomposition of a matrix into a &quot;canonical form&quot;
* we want to constrict a diagonal matrix from a given one
* a matrix $A$ is ''diagonalizable'' if it's [[Similar Matrices|similar]] to a diagonal matrix
** (a matrix $A$ is similar to $B$ if there exists an invertible $M$ s.t. $B = M^{-1} A \, M$)
* $A$ is diagonalizable if there exists [[Inverse Matrices|invertible matrix]] $P$ s.t.  $P^{-1} A \, P$ is diagonal



Why can we do it?
* if all eigenvalues $\lambda_1, \ ... \ , \lambda_n$ are different 
* then all eigenvalues $\mathbf x_1, \ ... \ , \mathbf x_n$ are linearly independent
* so any matrix with distinct eigenvalues can be decomposed by eigenvalue decomposition
* see proof in [[Eigenvalues and Eigenvectors]]


Diagonalization:
* $S^{-1} A S = \Lambda$
* $\Lambda = \text{diag } (\lambda_1, \ ... \ , \lambda_n)$


Eigenvalue Decomposition:
* if $A$ is symmetric, then there exists $S$ and $\Lambda$ s.t.
* $A = S \Lambda S^T$
* because for symmetric $A$ the eigenvectors in $S$ are orthonormal, so $S$ is [[Orthogonal Matrices|Orthogonal]]



=== Intuition ===
Suppose we have $n$ linearly independent [[Eigenvalues and Eigenvectors|eigenvectors]] $\mathbf x_i$ of $A$
* let's put them in columns of a matrix $S$ - eigenvector matrix 
* &lt;math&gt;S = \begin{bmatrix}
| &amp; &amp; | \\
\mathbf x_1 &amp; ... &amp; \mathbf x_n \\
| &amp; &amp; | \\
\end{bmatrix}&lt;/math&gt;


Now what if we multiply $AS$? 
* since all these $\mathbf x_i$ are eigenvectors, $A \mathbf x_i = \lambda_i \mathbf x_i$ 
* thus, &lt;math&gt;AS = A \begin{bmatrix}
| &amp; | &amp; &amp; | \\
\mathbf x_1 &amp; \mathbf x_2 &amp; ... &amp; \mathbf x_n \\
| &amp; | &amp; &amp; | \\
\end{bmatrix} = \begin{bmatrix}
| &amp; | &amp; &amp; | \\
\lambda_1 \, \mathbf x_1 &amp; \lambda_2 \, \mathbf x_2 &amp; ... &amp; \lambda_m \, \mathbf x_n \\
| &amp; | &amp; &amp; | \\
\end{bmatrix}&lt;/math&gt;
* ok, now let's take the $\lambda_i$'s out: &lt;math&gt;\begin{bmatrix}
| &amp; &amp; | \\
\lambda_1 \, \mathbf x_1 &amp;  \lambda_2 \, \mathbf x_2 &amp; ... &amp; \lambda_m \, \mathbf x_n \\
| &amp; &amp; | \\
\end{bmatrix} = \begin{bmatrix}
| &amp; | &amp; &amp; | \\
\mathbf x_1 &amp; \mathbf x_2 &amp; ... &amp; \mathbf x_n \\
| &amp; | &amp;  &amp; | \\
\end{bmatrix} 
\begin{bmatrix}
\lambda_1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \lambda_2 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \lambda_n \\
\end{bmatrix}&lt;/math&gt;
* let's call this diagonal matrix &lt;math&gt;\Lambda = \begin{bmatrix}
\lambda_1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \lambda_2 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \lambda_n \\
\end{bmatrix}&lt;/math&gt;
* so $AS = S \Lambda$


=== Decomposition ===
* if $S$ is invertible (or all $\mathbf x_i$ are independent), then
* $\Lambda = S^{-1} A \, S$ - this is called ''diagonalization'' of $A$ 
* and $A = S \Lambda S^{-1}$ - another factorization of $A$ 
* if $A$ is diagonal, then $\Lambda = A$, but if it's triangular, we still need to calculate $\Lambda$


=== [[Symmetric Matrices]] ===
For symmetric $A$
* its eigenvalues are orthonormal,
* so the matrix $S$ is [[Orthogonal Matrices|orthogonal]]
* thus, $A = S \Lambda S^{-1} = S \Lambda S^T$
* So we write $A = Q \Lambda Q^T$, where $Q$ is orthogonal



== Use Cases ==
=== Calculating Powers: $A^k$ ===
* if $A \mathbf x = \lambda \mathbf x$ then 
* $A^2 \mathbf x = \lambda A \mathbf x = \lambda^2 \mathbf x$
* so $\lambda$s are squared when $A$ is squared 

same for diagonalizable matrices:
* $A^2 = A A = (S \Lambda S^{-1}) (S \Lambda S^{-1}) = S \Lambda^2 S^{-1}$
* and $A^k = S \Lambda^k S^{-1}$
* so this factorization is better for powers than [[LU Factorization]]

This is useful for calculating the steady state probabilities of [[Markov Chains]] - by calculating the powers of [[Stochastic Matrices]] - matrix representation of a Markov Chain


=== [[Recurrence Equation]] ===
Suppose you are given a vector $\mathbf u_0$ and a recurrent formula $\mathbf u_{k+1} = A \mathbf u_{k}$
* how would you find $\mathbf u_{100}$?
* can repeat it 100 times 
* or, note that $\mathbf u_{100} = A \mathbf u_{99} = A^2 \mathbf u_{98} = \ ... \ =  A^{100} \mathbf u_{0}$

* Suppose $A$ is invertible. 
* Then one possible basis for $A$ is its eigenvectors $\mathbf v_i$
* let's express $\mathbf u_0$ in this basis: $\mathbf u_0 = c_1 \mathbf v_1 + \ ... \ + c_n \mathbf v_n = S \mathbf c$
* now let's multiply both parts by $A$:  
** $A \mathbf u_0 = A c_1 \mathbf v_1 + \ ... \ + A c_n \mathbf v_n = A S \mathbf c$
** $A \mathbf u_0 = c_1 \lambda_1 \mathbf v_1 + \ ... \ + c_n \lambda_n \mathbf v_n = \Lambda S \mathbf c$
* then $\mathbf u_{100} = c_1 \lambda_1^{100} \mathbf v_1 + \ ... \ + c_n \lambda_n^{100} \mathbf v_n = \Lambda^{100} S \mathbf c$


=== [[Fibonacci Numbers]] ===
* Fibonacci numbers is a sequence 0, 1, 1, 2, 3, 5, 8, 13... 
* $F_{k + 2} = F_{k+ 1} + F_{k}$
* it's a second order Recurrence Equation
* Let's build a system: &lt;math&gt;\begin{cases}
F_{k+2} = F_{k+1} + F_{k} \\
F_{k+1} = F_{k+1} \\
\end{cases}&lt;/math&gt;
* so let $\mathbf u_k = \begin{bmatrix} F_{k+1} \\ F_{k} \end{bmatrix}$, 
* then $\mathbf u_{k + 1} = \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 0 \end{bmatrix} \begin{bmatrix} F_{k+1} \\ F_{k} \end{bmatrix} = A \, \mathbf u_k$
* so we have the recurrence equation $\mathbf u_{k+1} = A \mathbf u_k$
* note that $A$ is symmetric, so it's diagonalizable 
* let's find eigenvalues:
** &lt;math&gt;| A - \lambda I | = \begin{vmatrix}
1 - \lambda &amp; 1 \\ 
1  &amp; -\lambda 
\end{vmatrix} = \lambda^2 - \lambda - 1 = 0&lt;/math&gt;
** or $\lambda_{1,2} = \cfrac{1 \pm \sqrt{1+4}}{2} = \cfrac{1 \pm \sqrt{5}}{2}$ 
** $\lambda_1 = 0.5 \, (1 + \sqrt{5}) \approx  1.618$
** $\lambda_1 = 0.5 \, (1 - \sqrt{5}) \approx -0.618$
* so, $\mathbf u_{100} = c_1 \lambda_1^{100} \mathbf v_1 + c_2 \lambda_2^{100} \mathbf v_2$
** $\lambda_1 &gt; 1$ so powers of it grow faster, and $|\lambda_2| &lt; 1$, so its powers decay
** thus $\lambda_1$ controls everything
* and we can approximate $F_{100} \approx c_1 \lambda_1^{100}$




== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* http://en.wikipedia.org/wiki/Diagonalizable_matrix
* Strang, G. Introduction to linear algebra.


[[Category:Linear Algebra]]
[[Category:Matrix Decomposition]]</text>
      <sha1>adub97njr3jnpjrwztsnrlic70bwe5x</sha1>
    </revision>
    <revision>
      <id>807</id>
      <parentid>666</parentid>
      <timestamp>2017-06-28T13:59:55Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6370">== Eigen Decomposition ==
Eigen Decomposition or, sometimes, Eigenvalue Decomposition (shortcut EVD)
* is a way of [[Diagonalization|diagonalizing]] a square $n \times n$ matrix $A$ 
* We can turn a matrix into a diagonal one by using eigenvectors


Eigenvalue decomposition is a decomposition of a matrix into a &quot;canonical form&quot;
* we want to constrict a diagonal matrix from a given one
* a matrix $A$ is ''diagonalizable'' if it's [[Similar Matrices|similar]] to a diagonal matrix
** (a matrix $A$ is similar to $B$ if there exists an invertible $M$ s.t. $B = M^{-1} A \, M$)
* $A$ is diagonalizable if there exists [[Inverse Matrices|invertible matrix]] $P$ s.t.  $P^{-1} A \, P$ is diagonal


Why can we do it?
* if all eigenvalues $\lambda_1, \ ... \ , \lambda_n$ are different 
* then all eigenvalues $\mathbf x_1, \ ... \ , \mathbf x_n$ are linearly independent
* so any matrix with distinct eigenvalues can be decomposed by eigenvalue decomposition
* see proof in [[Eigenvalues and Eigenvectors]]


=== [[Diagonalization]] ===
We can diagonalize $A$: 
* $S^{-1} A S = \Lambda$
* $\Lambda = \text{diag} (\lambda_1, \ ... \ , \lambda_n)$


Eigenvalue Decomposition:
* if $A$ is symmetric, then there exists $S$ and $\Lambda$ s.t.
* $A = S \Lambda S^T$
* because for symmetric $A$ the eigenvectors in $S$ are orthonormal, so $S$ is [[Orthogonal Matrices|Orthogonal]]



=== Intuition ===
Suppose we have $n$ linearly independent [[Eigenvalues and Eigenvectors|eigenvectors]] $\mathbf x_i$ of $A$
* let's put them in columns of a matrix $S$ - eigenvector matrix 
* &lt;math&gt;S = \begin{bmatrix}
| &amp; &amp; | \\
\mathbf x_1 &amp; ... &amp; \mathbf x_n \\
| &amp; &amp; | \\
\end{bmatrix}&lt;/math&gt;


Now what if we multiply $AS$? 
* since all these $\mathbf x_i$ are eigenvectors, $A \mathbf x_i = \lambda_i \mathbf x_i$ 
* thus, &lt;math&gt;AS = A \begin{bmatrix}
| &amp; | &amp; &amp; | \\
\mathbf x_1 &amp; \mathbf x_2 &amp; ... &amp; \mathbf x_n \\
| &amp; | &amp; &amp; | \\
\end{bmatrix} = \begin{bmatrix}
| &amp; | &amp; &amp; | \\
\lambda_1 \, \mathbf x_1 &amp; \lambda_2 \, \mathbf x_2 &amp; ... &amp; \lambda_m \, \mathbf x_n \\
| &amp; | &amp; &amp; | \\
\end{bmatrix}&lt;/math&gt;
* ok, now let's take the $\lambda_i$'s out: &lt;math&gt;\begin{bmatrix}
| &amp; &amp; | \\
\lambda_1 \, \mathbf x_1 &amp;  \lambda_2 \, \mathbf x_2 &amp; ... &amp; \lambda_m \, \mathbf x_n \\
| &amp; &amp; | \\
\end{bmatrix} = \begin{bmatrix}
| &amp; | &amp; &amp; | \\
\mathbf x_1 &amp; \mathbf x_2 &amp; ... &amp; \mathbf x_n \\
| &amp; | &amp;  &amp; | \\
\end{bmatrix} 
\begin{bmatrix}
\lambda_1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \lambda_2 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \lambda_n \\
\end{bmatrix}&lt;/math&gt;
* let's call this diagonal matrix &lt;math&gt;\Lambda = \begin{bmatrix}
\lambda_1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \lambda_2 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \lambda_n \\
\end{bmatrix}&lt;/math&gt;
* so $AS = S \Lambda$


=== Decomposition ===
* if $S$ is invertible (or all $\mathbf x_i$ are independent), then
* $\Lambda = S^{-1} A \, S$ - this is called ''diagonalization'' of $A$ 
* and $A = S \Lambda S^{-1}$ - another factorization of $A$ 
* if $A$ is diagonal, then $\Lambda = A$, but if it's triangular, we still need to calculate $\Lambda$


=== [[Symmetric Matrices]] ===
For symmetric $A$
* its eigenvalues are orthonormal,
* so the matrix $S$ is [[Orthogonal Matrices|orthogonal]]
* thus, $A = S \Lambda S^{-1} = S \Lambda S^T$
* So we write $A = Q \Lambda Q^T$, where $Q$ is orthogonal



== Use Cases ==
=== Calculating Powers: $A^k$ ===
* if $A \mathbf x = \lambda \mathbf x$ then 
* $A^2 \mathbf x = \lambda A \mathbf x = \lambda^2 \mathbf x$
* so $\lambda$s are squared when $A$ is squared 

same for diagonalizable matrices:
* $A^2 = A A = (S \Lambda S^{-1}) (S \Lambda S^{-1}) = S \Lambda^2 S^{-1}$
* and $A^k = S \Lambda^k S^{-1}$
* so this factorization is better for powers than [[LU Factorization]]

This is useful for calculating the steady state probabilities of [[Markov Chains]] - by calculating the powers of [[Stochastic Matrices]] - matrix representation of a Markov Chain


=== [[Recurrence Equation]] ===
Suppose you are given a vector $\mathbf u_0$ and a recurrent formula $\mathbf u_{k+1} = A \mathbf u_{k}$
* how would you find $\mathbf u_{100}$?
* can repeat it 100 times 
* or, note that $\mathbf u_{100} = A \mathbf u_{99} = A^2 \mathbf u_{98} = \ ... \ =  A^{100} \mathbf u_{0}$

* Suppose $A$ is invertible. 
* Then one possible basis for $A$ is its eigenvectors $\mathbf v_i$
* let's express $\mathbf u_0$ in this basis: $\mathbf u_0 = c_1 \mathbf v_1 + \ ... \ + c_n \mathbf v_n = S \mathbf c$
* now let's multiply both parts by $A$:  
** $A \mathbf u_0 = A c_1 \mathbf v_1 + \ ... \ + A c_n \mathbf v_n = A S \mathbf c$
** $A \mathbf u_0 = c_1 \lambda_1 \mathbf v_1 + \ ... \ + c_n \lambda_n \mathbf v_n = \Lambda S \mathbf c$
* then $\mathbf u_{100} = c_1 \lambda_1^{100} \mathbf v_1 + \ ... \ + c_n \lambda_n^{100} \mathbf v_n = \Lambda^{100} S \mathbf c$


=== [[Fibonacci Numbers]] ===
* Fibonacci numbers is a sequence 0, 1, 1, 2, 3, 5, 8, 13... 
* $F_{k + 2} = F_{k+ 1} + F_{k}$
* it's a second order Recurrence Equation
* Let's build a system: &lt;math&gt;\begin{cases}
F_{k+2} = F_{k+1} + F_{k} \\
F_{k+1} = F_{k+1} \\
\end{cases}&lt;/math&gt;
* so let $\mathbf u_k = \begin{bmatrix} F_{k+1} \\ F_{k} \end{bmatrix}$, 
* then $\mathbf u_{k + 1} = \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 0 \end{bmatrix} \begin{bmatrix} F_{k+1} \\ F_{k} \end{bmatrix} = A \, \mathbf u_k$
* so we have the recurrence equation $\mathbf u_{k+1} = A \mathbf u_k$
* note that $A$ is symmetric, so it's diagonalizable 
* let's find eigenvalues:
** &lt;math&gt;| A - \lambda I | = \begin{vmatrix}
1 - \lambda &amp; 1 \\ 
1  &amp; -\lambda 
\end{vmatrix} = \lambda^2 - \lambda - 1 = 0&lt;/math&gt;
** or $\lambda_{1,2} = \cfrac{1 \pm \sqrt{1+4}}{2} = \cfrac{1 \pm \sqrt{5}}{2}$ 
** $\lambda_1 = 0.5 \, (1 + \sqrt{5}) \approx  1.618$
** $\lambda_1 = 0.5 \, (1 - \sqrt{5}) \approx -0.618$
* so, $\mathbf u_{100} = c_1 \lambda_1^{100} \mathbf v_1 + c_2 \lambda_2^{100} \mathbf v_2$
** $\lambda_1 &gt; 1$ so powers of it grow faster, and $|\lambda_2| &lt; 1$, so its powers decay
** thus $\lambda_1$ controls everything
* and we can approximate $F_{100} \approx c_1 \lambda_1^{100}$



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* http://en.wikipedia.org/wiki/Diagonalizable_matrix
* Strang, G. Introduction to linear algebra.
* [[Matrix Computations (book)]]


[[Category:Linear Algebra]]
[[Category:Matrix Decomposition]]</text>
      <sha1>ry6mlchqbet8iqt17z382zq7w68onqc</sha1>
    </revision>
  </page>
  <page>
    <title>Recurrence Equation</title>
    <ns>0</ns>
    <id>572</id>
    <revision>
      <id>575</id>
      <timestamp>2015-04-26T16:28:22Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="398">{{stub}}

== Recurrence Equations ==
A ''difference equation'', or ''recurrence equation'', 

Examples:
* Fibonacci Numbers:
* $F_n = F_{n - 1} + F_{n-2}$


[[Eigendecomposition]] is a good way of solving these equations 


Links:
* https://ccrma.stanford.edu/~jos/fp/Difference_Equation_I.html
* http://en.wikipedia.org/wiki/Recurrence_relation


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]</text>
      <sha1>4md0r63qg5rvhnpg0cynt40mzlcm75s</sha1>
    </revision>
  </page>
  <page>
    <title>Eigenvalues and Eigenvectors</title>
    <ns>0</ns>
    <id>573</id>
    <revision>
      <id>576</id>
      <timestamp>2015-04-26T16:39:57Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8008">== Eigenvalues and Eigenvectors ==
Eigenvalues and eigenvectors are important in dynamic problems



=== Introduction ===
Suppose we have a [[Matrix]] $A$. What does it do with a vector?
* Suppose we multiply $A$ by a vector $\mathbf x$ - and we get a vector $A \mathbf x$
* what if $A \mathbf x$ is in the same direction as $\mathbf x$? 
* http://habrastorage.org/files/a57/974/fa1/a57974fa1416425bb4f296df8ea6b507.png
* i.e. if it's the same direction, then $A \mathbf x = \lambda \mathbf x$ for some $\lambda$
* such $\mathbf x$ is called ''eigenvector'' and $\lambda$ is called ''eigenvalue''


What if $\lambda = 0$? 
* $A \mathbf x = 0 \mathbf x = \mathbf 0$
* i.e. $\mathbf x \in N(A)$ - the eigenvector $\mathbf x$ belongs to the [[Nullspace]]
* so if $A$ is singular, then $\lambda = 0$ is its eigenvalue



=== Example: Projection Matrices ===
Sometimes we can find the eigenvalues by thinking geometrically
* suppose we have a [[Projection Matrices|Projection Matrix]] $P$ 
* http://habrastorage.org/files/7d3/f88/ed9/7d3f88ed987c48e7bebacc5a3f336e21.png
* for a vector $\mathbf b$ that's not on the place formed by $C(P)$, $\mathbf b$ is not an eigenvector - $P \mathbf b$ is a projection, so they point to different directions
* suppose there's a vector $\mathbf x_1$ on the plane. $P \mathbf x_1 = \mathbf x_1$, so all such $\mathbf x_1$ on the plane are eigenvectors with eigenvalues $\lambda = 1$
* are there other eigenvectors? take any $\mathbf x_2$ orthogonal to the plane: $P \mathbf x_2 = 0 \mathbf x_2 = \mathbf 0$, so $\lambda = 0$
* so we have two eigenvalues $\lambda = 0$ and $\lambda = 1$


== Solving $A \mathbf x = \lambda \mathbf x$ ==
* Cannot use [[Gaussian Elimination]] here 
* we have two unknowns: $\lambda$ and $\mathbf x$

$A \mathbf x = \lambda \mathbf x$
* let's rewrite it as $(A - \lambda I) \mathbf x = \mathbf 0$
* for $\mathbf x \ne \mathbf 0$ 
* so the matrix $A - \lambda I$ is singular, thus its [[Determinant]] is zero: 
* $\text{det}(A - \lambda I) = 0$ - this is called the ''characteristic equation''
* this equation has $n$ roots, so you'll find $n$ eigenvalues $\lambda_i$
* then for each $\lambda_i$ we solve the system $A \mathbf x = \lambda_i \mathbf x$ in order to get eigenvectors


$(A - \lambda I) \mathbf x = \mathbf 0$
This eigenvectors are in the [[Nullspace]] of $(A - \lambda I)$


Eigenvalues are sometimes called &quot;singular values&quot; because 
if $\lambda$ is an eigenvalue, then $A - \lambda I$ is singular



== Example ==
=== Example 1 ===
Let $A = \begin{bmatrix}
3 &amp; 1 \\
1 &amp; 3 \\
\end{bmatrix}$ 
* $\text{det}(A - \lambda I) = \begin{bmatrix}
3 - \lambda &amp; 1 \\
1 &amp; 3- \lambda \\
\end{bmatrix} = (3 - \lambda)^2 - 1 = 0$
* or $(3 - \lambda)^2 = 1$ 
* $3 - \lambda = \pm 1$
* $\lambda_1 = 4, \lambda_2 = 2$

Now can find eigenvectors
* $(A - \lambda_1 I) \mathbf x_1 = (A - 4 I) \mathbf x_1 = 0$, so $x_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix} \in N(A - 4 I)$
* $(A - \lambda_2 I) \mathbf x_2 = (A - 2 I) \mathbf x_2 = 0$, so $x_2 = \begin{bmatrix} -1 \\ 1 \end{bmatrix} \in N(A - 2 I)$


=== Example 2: [[Rotation Matrices|Rotation Matrix]] ===
Let $Q = \begin{bmatrix}
0 &amp; -1 \\
1 &amp; 0 \\
\end{bmatrix}$
* know that $\text{tr } Q = \sum_i \lambda_i$, so $\lambda_1 + \lambda_2 = 0$
* $\text{det } Q = \lambda_1 \, \lambda_2 = 1$ 
* how it's possible?
* $\text{det } Q = \begin{vmatrix}
-\lambda &amp; -1 \\
1 &amp; -\lambda \\
\end{vmatrix} = \lambda^2 + 1$
* so $\lambda_1 = i$ and $\lambda_2 = -i$ - complex numbers
* note that they are complex conjugates 
* this doesn't happen for Symmetric matrices - they always have real eigenvalues



== Properties ==
[[Gaussian Elimination]] changes the eigenvalues of $A$ 
* Triangular $U$ has its eigenvalues on the diagonal - but they are not eigenvalues of $A$


eigenvectors can be multiplied by any non-negative constant and will still remain eigenvectors
* so it's good to make these vectors unit vectors


=== Trace and Determinant ===
$\text{tr } A = \sum\limits_i \lambda_i$
* $\text{tr } A$ is a [[Trace (Matrix)|Trace]] of $A$


$\text{det } A = \prod\limits_i \lambda_i$
* $\text{det } A$ is a [[Determinant]] of $A$


{{ TODO | prove it }}



=== Eigenvectors and Eigenvalues of $A^k$ ===
if $A \mathbf x = \lambda \mathbf x$ then 
* $A^2 \mathbf x = \lambda A \mathbf x = \lambda^2 \mathbf x$
* so $\lambda$s are squared when $A$ is squared 
* the eigenvectors stay the same
* For $A^k$ the eigenvalues are $\lambda_i^k$ 
* Eigenvectors stay the same and don't mix up, only eigenvalues grow


=== Linear Independence ===
If all eigenvalues $\lambda_1, \ ... \ , \lambda_n$ are different then all eigenvectors $\mathbf x_1, \ ... \ , \mathbf x_n$ are linearly independent
* so any matrix with distinct eigenvalues can be [[Eigendecomposition|diagonalized]]


'''Thm.''' $\mathbf x_1, \ ... \ , \mathbf x_n$ that correspond to distinct eigenvalues are linearly independent. 


Proof
* Let $\mathbf x_1, \mathbf x_2, \ ... \ , \mathbf x_n$ be eigenvectors of some matrix $A$ (so none of them are $\mathbf 0$)
* and also assume that eigenvalues are distinct, i.e. $\lambda_1 \ne \lambda_2 \ne \ ... \ \ne \lambda_n$


$n = 2$ case:
* consider a linear combination $c_1 \mathbf x_1 + c_2 \mathbf x_2 = \mathbf 0$
* multiply it by $A$: 
** $c_1 A \, \mathbf x_1 + c_2 A \, \mathbf x_2 = c_1 \lambda_1 \mathbf x_1 + c_2 \lambda_1 \mathbf x_2 = \mathbf 0$
* then multiply $c_1 \mathbf x_1 + c_2 \mathbf x_2 = \mathbf 0$ by $\lambda_2$: 
** $c_1 \lambda_2 \mathbf x_1 + c_2 \lambda_2 \mathbf x_2 = \mathbf 0$
* subtract equation 1 from 2 to get the following:
** $(\lambda_1 - \lambda_2) c_1 \mathbf x_1 = \mathbf 0$
** since $\lambda_1 \ne \lambda_2$ and $x_1 \ne \mathbf 0$, so it means that $c_1 = 0$
* by similar argument we see that $c_2 = 0$ 
* thus $c_1 \mathbf x_1 + c_2 \mathbf x_2 = \mathbf 0$ because $c_1 = c_2 = 0$
* or, $\mathbf x_1$ and $\mathbf x_2$ are linearly independent


General case:
* consider $c_1 \mathbf x_1 + \ ... \ + c_n \mathbf x_n = \mathbf 0$
* multiply by $A$ to get $c_1 \lambda_1 \mathbf x_1 + \ ... \ + c_n \lambda_n \mathbf x_n = \mathbf 0$
* multiply by $\lambda_n$ to get $c_1 \lambda_n \mathbf x_1 + \ ... \ + c_n \lambda_n \mathbf x_n = \mathbf 0$
* subtract them, get $\mathbf x_n$ removed and have the following:
** $c_1 (\lambda_1 - \lambda_n) \mathbf x_1 + \ ... \ + c_{n - 1} (\lambda_{n - 1} - \lambda_n) \mathbf x_{n - 1} = \mathbf 0$
* do the same again: multiply it with $A$ and with $\lambda_{n-1}$ to get
** $c_1 (\lambda_1 - \lambda_n) \lambda_1 \mathbf x_1 + \ ... \ + c_{n - 1} (\lambda_{n - 1} - \lambda_n) \lambda_{n - 1} \mathbf x_{n - 1} = \mathbf 0$
** $c_1 (\lambda_1 - \lambda_n) \lambda_{n - 1} \mathbf x_1 + \ ... \ + c_{n - 1} (\lambda_{n - 1} - \lambda_n) \lambda_{n - 1} \mathbf x_{n - 1} = \mathbf 0$
** subtract to get rid of $\mathbf x_{n - 1}$ 
* eventually, have this:
* $(\lambda_1 - \lambda_2) \cdot (\lambda_1 - \lambda_3) \cdot \ ... \ \cdot (\lambda_1 - \lambda_{n}) \cdot c_1 \mathbf x_{n} = \mathbf 0$
* since all $\lambda_i$ are distinct and $x_{n} \ne \mathbf 0$, conclude that $c_1 = 0$
* can show the same for the rest $c_2, \ ... \ , c_n$
* thus $\mathbf x_1, \mathbf x_2, \ ... \ , \mathbf x_n$ are linearly independent


$\square$

== Eigenvector Matrix ==
Suppose we have $n$ linearly independent eigenvectors $\mathbf x_i$ of $A$
* let's put them in columns of a matrix $S$ - eigenvector matrix 

$S = \Bigg[ \mathop{\mathbb x_1}\limits_|^| \ \mathop{\mathbb x_2}\limits_|^| \ \cdots \  \mathop{\mathbb x_n}\limits_|^|  \Bigg]$

This matrix is used for [[Eigendecompostion|Matrix Diagonalization]]


== Usage ==
* Matrix decomposition: [[Eigendecomposition]] ([[Spectral Theorem]]) and [[SVD]]
** Eigenvectors give a good basis, especially for [[Symmetric Matrices]]: they are orthogonal 
* [[Principal Component Analysis]]
* [[Markov Chains]] and [[PageRank]] 
* many many others



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Strang, G. Introduction to linear algebra.

[[Category:Linear Algebra]]</text>
      <sha1>e4ko62t029i2wwsue9g13mebv9tolhk</sha1>
    </revision>
    <revision>
      <id>783</id>
      <parentid>576</parentid>
      <timestamp>2017-06-26T14:38:07Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9671">== Eigenvalues and Eigenvectors ==
Eigenvalues and eigenvectors are important in dynamic problems


Suppose we have a [[Matrix]] $A$. What does it do with a vector?
* Suppose we multiply $A$ by a vector $\mathbf x$ - and we get a vector $A \mathbf x$
* what if $A \mathbf x$ is in the same direction as $\mathbf x$? 
* http://habrastorage.org/files/a57/974/fa1/a57974fa1416425bb4f296df8ea6b507.png
* i.e. if it's the same direction, then $A \mathbf x = \lambda \mathbf x$ for some $\lambda$
* such $\mathbf x$ is called ''eigenvector'' and $\lambda$ is called ''eigenvalue''


What if $\lambda = 0$? 
* $A \mathbf x = 0 \mathbf x = \mathbf 0$
* i.e. $\mathbf x \in N(A)$ - the eigenvector $\mathbf x$ belongs to the [[Nullspace]]
* so if $A$ is singular, then $\lambda = 0$ is its eigenvalue


=== Example: Projection Matrices ===
Sometimes we can find the eigenvalues by thinking geometrically
* suppose we have a [[Projection Matrices|Projection Matrix]] $P$ 
* http://habrastorage.org/files/7d3/f88/ed9/7d3f88ed987c48e7bebacc5a3f336e21.png
* for a vector $\mathbf b$ that's not on the place formed by $C(P)$, $\mathbf b$ is not an eigenvector - $P \mathbf b$ is a projection, so they point to different directions
* suppose there's a vector $\mathbf x_1$ on the plane. $P \mathbf x_1 = \mathbf x_1$, so all such $\mathbf x_1$ on the plane are eigenvectors with eigenvalues $\lambda = 1$
* are there other eigenvectors? take any $\mathbf x_2$ orthogonal to the plane: $P \mathbf x_2 = 0 \mathbf x_2 = \mathbf 0$, so $\lambda = 0$
* so we have two eigenvalues $\lambda = 0$ and $\lambda = 1$


== Solving $A \mathbf x = \lambda \mathbf x$ ==
* Cannot use [[Gaussian Elimination]] here 
* we have two unknowns: $\lambda$ and $\mathbf x$

$A \mathbf x = \lambda \mathbf x$
* let's rewrite it as $A \mathbf x - \lambda \mathbf x = (A - \lambda I) \mathbf x = \mathbf 0$
* so, $(A - \lambda I) \mathbf x = \mathbf 0$ for $\mathbf x \ne \mathbf 0$ 
* we want the vector to be non-zero, and it's only possible when the matrix $A - \lambda I$ is singular: that is, the columns of this matrix should be linearly dependent, so it's possible to get the zero verctor
* the matrix $A - \lambda I$ is singular when its [[Determinant]] is zero
* this, we need to solve $\text{det}(A - \lambda I) = 0$ - this is called the ''characteristic equation'' of $A$ 
* this equation is an $n$th order polynomial and has $n$ roots, so you'll find $n$ eigenvalues $\lambda_i$
* Eigenvalues are sometimes called &quot;singular values&quot; because if $\lambda$ is an eigenvalue, then $A - \lambda I$ is singular


Finding the eigenvector
* Look at the $(A - \lambda I) \mathbf x = \mathbf 0$
* The corresponding eigenvector $\mathbf x$ is in the [[Nullspace]] of $A - \lambda I$
* So we need to solve this equation to get the vector
* Since the matrix is singular, there are multiple such eigenvectors - same direction, but different scale
* We just fix some scale and find the direction



== Examples ==
=== Example 1 ===
Let &lt;math&gt;A = \begin{bmatrix}
3 &amp; 1 \\
1 &amp; 3 \\
\end{bmatrix}&lt;/math&gt;
* &lt;math&gt;\text{det}(A - \lambda I) = \begin{bmatrix}
3 - \lambda &amp; 1 \\
1 &amp; 3- \lambda \\
\end{bmatrix} = (3 - \lambda)^2 - 1 = 0&lt;/math&gt;
* or $(3 - \lambda)^2 = 1$ 
* $3 - \lambda = \pm 1$
* $\lambda_1 = 4, \lambda_2 = 2$

Now can find eigenvectors
* $(A - \lambda_1 I) \mathbf x_1 = (A - 4 I) \mathbf x_1 = 0$, so $x_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix} \in N(A - 4 I)$
* $(A - \lambda_2 I) \mathbf x_2 = (A - 2 I) \mathbf x_2 = 0$, so $x_2 = \begin{bmatrix} -1 \\ 1 \end{bmatrix} \in N(A - 2 I)$


=== Example 2 ===
Let &lt;math&gt;A = \begin{bmatrix}
0 &amp; 1 \\
-2 &amp; 3 \\
\end{bmatrix}&lt;/math&gt;
* need to solve $\text{det } A = 0$:
* $- \lambda (3 - \lambda) + 2 = 0$
* $\lambda_{1,2} = \cfrac{-b \pm \sqrt{b^2 - 4ac}}{2a} = \cfrac{3 \pm \sqrt{9 - 4 \cdot 2}}{2} = \cfrac{3 \pm 1}{2}$
* so $\lambda_1 = 1$ and $\lambda_2 = 2$

Eigenvector $A \mathbf v_1 = \lambda_1 \mathbf v_1$ 
* $(A - \lambda_1 I) \mathbf v_1 = \mathbf 0$
* &lt;math&gt;\begin{bmatrix}
0 - 1 &amp; 1 \\
-2 &amp; 3 - 1 \\
\end{bmatrix} = \begin{bmatrix}
-1 &amp; 1 \\
-2 &amp; 2 \\
\end{bmatrix}&lt;/math&gt;, &lt;math&gt;\begin{bmatrix}
-1 &amp; 1 \\
-2 &amp; 2 \\
\end{bmatrix} \mathbf v_1 = \mathbf 0&lt;/math&gt;
* Reduce the matrix to upper triangular form - and then we see that there's zeros on the last row (the matrix is singular)
** &lt;math&gt;\begin{bmatrix}
-1 &amp; 1 \\
0 &amp; 0 \\
\end{bmatrix}&lt;/math&gt;
** can fix some value of $v_{12}$, e.g. $v_{12} = 1$
** then $v_{11} = 1$
* so &lt;math&gt;\mathbf v_1 = c \cdot \begin{bmatrix}
1 \\
1 \\
\end{bmatrix}&lt;/math&gt; where $c$ is some constant 


=== Example 3: [[Rotation Matrices|Rotation Matrix]] ===
Let &lt;math&gt;Q = \begin{bmatrix}
0 &amp; -1 \\
1 &amp; 0 \\
\end{bmatrix}&lt;/math&gt;
* know that $\text{tr } Q = \sum_i \lambda_i$, so $\lambda_1 + \lambda_2 = 0$
* &lt;math&gt;\text{det } Q = \lambda_1 \, \lambda_2 = 1&lt;/math&gt;
* how it's possible?
* &lt;math&gt;\text{det } Q = \begin{vmatrix}
-\lambda &amp; -1 \\
1 &amp; -\lambda \\
\end{vmatrix} = \lambda^2 + 1&lt;/math&gt;
* so $\lambda_1 = i$ and $\lambda_2 = -i$ - complex numbers
* note that they are complex conjugates 
* this doesn't happen for Symmetric matrices - they always have real eigenvalues



== Properties ==
* [[Gaussian Elimination]] changes the eigenvalues of $A$ 
** Triangular $U$ has its eigenvalues on the diagonal - but they are not eigenvalues of $A$
* eigenvectors can be multiplied by any non-negative constant and will still remain eigenvectors
** so it's good to make these vectors unit vectors


=== Trace and Determinant ===
* $\text{tr } A = \sum\limits_i \lambda_i$
** $\text{tr } A$ is a [[Trace (Matrix)|Trace]] of $A$
* $\text{det } A = \prod\limits_i \lambda_i$
** $\text{det } A$ is a [[Determinant]] of $A$

{{ TODO | prove it }}


=== Eigenvectors and Eigenvalues of $A^k$ ===
if $A \mathbf x = \lambda \mathbf x$ then 
* $A^2 \mathbf x = \lambda A \mathbf x = \lambda^2 \mathbf x$
* so $\lambda$s are squared when $A$ is squared 
* the eigenvectors stay the same
* For $A^k$ the eigenvalues are $\lambda_i^k$ 
* Eigenvectors stay the same and don't mix up, only eigenvalues grow
* this is used in [[Power Iteration]] and other methods for finding approximate values of eigenvalues and eigenvectors


=== Linear Independence ===
If all eigenvalues $\lambda_1, \ ... \ , \lambda_n$ are different then all eigenvectors $\mathbf x_1, \ ... \ , \mathbf x_n$ are linearly independent
* so any matrix with distinct eigenvalues can be [[Eigendecomposition|diagonalized]]


'''Thm.''' $\mathbf x_1, \ ... \ , \mathbf x_n$ that correspond to distinct eigenvalues are linearly independent. 


Proof
* Let $\mathbf x_1, \mathbf x_2, \ ... \ , \mathbf x_n$ be eigenvectors of some matrix $A$ (so none of them are $\mathbf 0$)
* and also assume that eigenvalues are distinct, i.e. $\lambda_1 \ne \lambda_2 \ne \ ... \ \ne \lambda_n$


$n = 2$ case:
* consider a linear combination $c_1 \mathbf x_1 + c_2 \mathbf x_2 = \mathbf 0$
* multiply it by $A$: 
** $c_1 A \, \mathbf x_1 + c_2 A \, \mathbf x_2 = c_1 \lambda_1 \mathbf x_1 + c_2 \lambda_1 \mathbf x_2 = \mathbf 0$
* then multiply $c_1 \mathbf x_1 + c_2 \mathbf x_2 = \mathbf 0$ by $\lambda_2$: 
** $c_1 \lambda_2 \mathbf x_1 + c_2 \lambda_2 \mathbf x_2 = \mathbf 0$
* subtract equation 1 from 2 to get the following:
** $(\lambda_1 - \lambda_2) c_1 \mathbf x_1 = \mathbf 0$
** since $\lambda_1 \ne \lambda_2$ and $x_1 \ne \mathbf 0$, so it means that $c_1 = 0$
* by similar argument we see that $c_2 = 0$ 
* thus $c_1 \mathbf x_1 + c_2 \mathbf x_2 = \mathbf 0$ because $c_1 = c_2 = 0$
* or, $\mathbf x_1$ and $\mathbf x_2$ are linearly independent


General case:
* consider $c_1 \mathbf x_1 + \ ... \ + c_n \mathbf x_n = \mathbf 0$
* multiply by $A$ to get $c_1 \lambda_1 \mathbf x_1 + \ ... \ + c_n \lambda_n \mathbf x_n = \mathbf 0$
* multiply by $\lambda_n$ to get $c_1 \lambda_n \mathbf x_1 + \ ... \ + c_n \lambda_n \mathbf x_n = \mathbf 0$
* subtract them, get $\mathbf x_n$ removed and have the following:
** $c_1 (\lambda_1 - \lambda_n) \mathbf x_1 + \ ... \ + c_{n - 1} (\lambda_{n - 1} - \lambda_n) \mathbf x_{n - 1} = \mathbf 0$
* do the same again: multiply it with $A$ and with $\lambda_{n-1}$ to get
** $c_1 (\lambda_1 - \lambda_n) \lambda_1 \mathbf x_1 + \ ... \ + c_{n - 1} (\lambda_{n - 1} - \lambda_n) \lambda_{n - 1} \mathbf x_{n - 1} = \mathbf 0$
** $c_1 (\lambda_1 - \lambda_n) \lambda_{n - 1} \mathbf x_1 + \ ... \ + c_{n - 1} (\lambda_{n - 1} - \lambda_n) \lambda_{n - 1} \mathbf x_{n - 1} = \mathbf 0$
** subtract to get rid of $\mathbf x_{n - 1}$ 
* eventually, have this:
* $(\lambda_1 - \lambda_2) \cdot (\lambda_1 - \lambda_3) \cdot \ ... \ \cdot (\lambda_1 - \lambda_{n}) \cdot c_1 \mathbf x_{n} = \mathbf 0$
* since all $\lambda_i$ are distinct and $x_{n} \ne \mathbf 0$, conclude that $c_1 = 0$
* can show the same for the rest $c_2, \ ... \ , c_n$
* thus $\mathbf x_1, \mathbf x_2, \ ... \ , \mathbf x_n$ are linearly independent


$\square$

== Eigenvector Matrix ==
Suppose we have $n$ linearly independent eigenvectors $\mathbf x_i$ of $A$
* let's put them in columns of a matrix $S$ - eigenvector matrix 

$S = \Bigg[ \mathop{\mathbb x_1}\limits_|^| \ \mathop{\mathbb x_2}\limits_|^| \ \cdots \  \mathop{\mathbb x_n}\limits_|^|  \Bigg]$

This matrix is used for [[Eigendecompostion|Matrix Diagonalization]]


== Usage ==
* Matrix decomposition: [[Eigendecomposition]] ([[Spectral Theorem]]) and [[SVD]]
** Eigenvectors give a good basis, especially for [[Symmetric Matrices]]: they are orthogonal 
* [[Principal Component Analysis]]
* [[Markov Chains]] and [[PageRank]] 
* many many others



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Strang, G. Introduction to linear algebra.

[[Category:Linear Algebra]]</text>
      <sha1>0gvteyhrtqmaiwy34fxw1i5e3vb1u97</sha1>
    </revision>
  </page>
  <page>
    <title>Eigenvectors</title>
    <ns>0</ns>
    <id>574</id>
    <redirect title="Eigenvalues and Eigenvectors" />
    <revision>
      <id>577</id>
      <timestamp>2015-04-26T16:40:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="42">#REDIRECT [[Eigenvalues and Eigenvectors]]</text>
      <sha1>e4n2u3ppig95pczrwnf7u8m4cbtpvhu</sha1>
    </revision>
  </page>
  <page>
    <title>Eigenvalues</title>
    <ns>0</ns>
    <id>575</id>
    <redirect title="Eigenvalues and Eigenvectors" />
    <revision>
      <id>578</id>
      <timestamp>2015-04-26T16:40:50Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="42">#REDIRECT [[Eigenvalues and Eigenvectors]]</text>
      <sha1>e4n2u3ppig95pczrwnf7u8m4cbtpvhu</sha1>
    </revision>
  </page>
  <page>
    <title>Symmetric Matrices</title>
    <ns>0</ns>
    <id>576</id>
    <revision>
      <id>579</id>
      <timestamp>2015-05-08T16:13:17Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5645">== Symmetric Matrices ==
A matrix $A$ is symmetric if $A^T = A$ holds. 
* thus, $A$ must be a square matrix




== Properties ==
What's special about $A \mathbf x = \lambda \mathbf x$? when $A$ is symmetric?
* $A$ has real eigenvalues, and orthonormal eigenvectors
* therefore [[Eigendecomposition]] of $A$ is $A = Q \Lambda Q^T$ instead of $A = S \Lambda S^{-1}$
* this fact is sometimes referred as the [[Spectral Theorem]]


=== Orthogonal Eigenvectors ===
* [[Eigendecomposition|diagonalize]] $A = S \Lambda S^{-1}$
* $A^T = (S \Lambda S^{-1})^T = (S^{-1})^T \Lambda^T S^T = (S^{-1})^T \Lambda \, S^T$
* since $A = A^T$, we have:
* $S \Lambda S^{-1} = (S^{-1})^T \Lambda \, S^T$
* so maybe $S^{-1} = S^T$? Then $S$ is an [[Orthogonal Matrix]]
* thus, the eigenvectors $\mathbf v_1 , \ ... \ , \mathbf v_n$ are orthonormal
* So we write $A = Q \Lambda Q^T$


Let's show that
* Suppose $A$ has two eigenvalues $\lambda_1 \ne \lambda_2$ and their eigenvalues are $\mathbf v_1$ and $\mathbf v_2$
* so $A \mathbf v_1 = \lambda_1 \mathbf v_1$ and $A \mathbf v_2 = \lambda_2 \mathbf v_2$
* $A \mathbf v_1 = \lambda_1 \mathbf v_1$ multiply by $\mathbf v_2$ on the left:
** $(A \mathbf v_1)^T \mathbf v_2 = \lambda_1 \mathbf v_1^T \mathbf v_2$
** $\mathbf v_1^T A^T \mathbf v_2 = \lambda_1 \mathbf v_1^T \mathbf v_2$
* $A$ is symmetric, so
** $\mathbf v_1^T A^T \mathbf v_2 = \mathbf v_1^T A \mathbf v_2 = \lambda_1 \mathbf v_1^T \mathbf v_2$
* we have $\mathbf v_1^T A \mathbf v_2 = \lambda_1 \mathbf v_1^T \mathbf v_2$
** since $A \mathbf v_2 = \lambda_2 \mathbf v_2$,
** $\lambda_2 \mathbf v_1^T \mathbf v_2 = \lambda_1 \mathbf v_1^T \mathbf v_2$
* but we assumed that $\lambda_1 \ne \lambda_2$! 
** so the only way it can be true is when $\mathbf v_1^T \mathbf v_2 = 0$
* thus, $\mathbf v_1 \; \bot \; \mathbf v_2$

$\square$



=== Real Eigenvalues ===
* $A \mathbf x = \lambda \mathbf x$
* let's take a [[Complex Conjugate]]: for $c = a + ib$ a conjugate is $\overline {c} = \overline{a + ib} = a - ib$
* $A$ is real, so $\overline A = A$
* thus, we have $A \overline {\mathbf x} = \overline {\lambda \mathbf x}$
* so if $A$ has eigenvalue $\lambda$ and eigenvector $\mathbf x$, then $\overline \lambda$ and $\overline {\mathbf x}$ are also eigenvalue and eigenvector - for real matrices $A$
* we want to show that $\overline \lambda = \lambda$ and $\overline {\mathbf x} = \mathbf x$, i.e. they are not complex


Let's show that: 
* Transpose $A \overline {\mathbf x} = \overline {\lambda \mathbf x}$: 
** $\overline {\mathbf x}^T A^T = \overline {\lambda \mathbf x}^T$
* Since $A$ is symmetric, $\overline {\mathbf x}^T A = \overline {\lambda \mathbf x}^T$
** Multiply both sides by $\mathbf x$ on the left: 
** $\overline {\mathbf x}^T A \, \mathbf x = \overline {\lambda \mathbf x}^T \mathbf x$
* now take $A \mathbf x = \lambda \mathbf x$ and multiply both sides by $\overline {\mathbf x}^T$ on the right:
** $\overline {\mathbf x}^T A \mathbf x = \overline {\mathbf x}^T \lambda \, \mathbf x$
* so  $\overline {\mathbf x}^T A \mathbf x = \overline {\lambda \mathbf x}^T \mathbf x$ and $\overline {\mathbf x}^T A \mathbf x = \overline {\mathbf x}^T \lambda \mathbf x$
** they have the same right hand side
** thus $\overline \lambda \overline {\mathbf x}^T \mathbf x = \lambda \overline {\mathbf x}^T  \mathbf x$
** given that $\overline {\mathbf x}^T  \mathbf x \ne 0$, we divide by it and have:
* $\overline \lambda = \lambda$, or, $\lambda \in \mathbb R$


Let's have a look at $\overline {\mathbf x}^T  \mathbf x$ (when $\ne 0$):
* $\Big[ \overline x_1 \ \overline x_2 \ \cdots \ \overline x_n \Big] \begin{bmatrix}  x_1  \\ \vdots \\ x_n \end{bmatrix} = \sum \overline x_i x_i$
* for a complex number $c$, $c \cdot \overline c = (a - ib) \cdot (a + ib) = a^2 + b^2 \in \mathbb R$
* so it's a sum of real numbers! sum of squared lengths of each component of $\mathbf x$
* which means that the entire dot product is in $\mathbb R$

$\square$


=== Eigenvalues are Non-Negative ===
* Eigenvalues are non-negative
* If $A$ is positive-definite, then all eigenvalues are positive


=== [[Positive-Definite Matrices|Positive-definiteness]] ===
A symmetric matrix is positive-definite when
* all eigenvalues of $A$ are greater than zero
* so pivots are greater then zero as well


=== [[Four Fundamental Subspaces|Subspaces]] ===
If $A$ is symmetric,
* then its row space is the same as column space
* i.e. $C(A) = C(A^T)$


=== Other properties ===
E.g. the identity matrix $I$: all eigenvalues $\lambda_i = 1$ and every vector is eigenvectors 



== [[Spectral Theorem]] ==
We can apply [[Eigendecomposition]] to $A$ and get
* $A = Q \Lambda Q^T = \sum \lambda_i \mathbf q_i  \mathbf q_i^T$ - sum of [[Outer Product]]s
* each of these outer products can be seen as a [[Projection Matrices|Projection Matrix]]
* so symmetric matrix can be represented as a combination of mutually orthogonal projection matrices



== Examples ==
=== [[Gram Matrices]] ===
$A A^T$ and $A^T A$ Symmetric
* moreover, every symmetric matrix $B$ can be represented as $A A^T$ or $A^T A$:
* Eigendecomposition of $B = Q \Lambda Q^T = Q \sqrt{\Lambda} \sqrt{\Lambda^T} Q^T = (Q \sqrt{\Lambda}) (Q \sqrt{\Lambda})^T = A A^T$ where $A = Q \sqrt{\Lambda}$
* also [[Cholesky Decomposition]] would show the same
* if $B$ is positive-definite, then such $A$ is non-singular


=== Others ===
Identity and square diagonal matrices are symmetric



== Links ==
* https://inst.eecs.berkeley.edu/~ee127a/book/login/l_sym_psd.html

== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* http://www.math.ucsd.edu/~njw/Teaching/Math271C/Lecture_03.pdf

[[Category:Linear Algebra]]</text>
      <sha1>8hihd0jsh34kbeowypstdpg5x9n13vo</sha1>
    </revision>
  </page>
  <page>
    <title>Basis (Linear Algebra)</title>
    <ns>0</ns>
    <id>577</id>
    <revision>
      <id>580</id>
      <timestamp>2015-04-26T17:11:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2074">== Basis (Linear Algebra) ==
In Linear Algebra, ''basis'' is a set of [[Linear Independence|linearly independent]] vectors $\mathbf v_1, ...,  \mathbf v_n$ 


=== Spanning a Space ===
Vectors $\mathbf v_1, ...,  \mathbf v_l$  ''span a (sub)space'' $\iff$ this space consists of all possible linear combinations of these vectors 
* columns of a matrix $A$ span it's column space $C(A)$
* are such $\mathbf v_i$ independent? - depends 


=== Basis ===
Basis of a vector space is a sequence of vectors $\mathbf v_1, \mathbf v_2, ...,  \mathbf v_d$ that  
* are linearly independent and 
* span the entire space 


== Examples ==
Standard Basis: 
* the identity $I_d$,
* e.g. for $\mathbb R^3$, $\mathbf e_1 = \begin{bmatrix}
1 \\ 0 \\ 0 
\end{bmatrix}$, $\mathbf e_2 = \begin{bmatrix}
0 \\ 1 \\ 0 
\end{bmatrix}$, $\mathbf e_3 = \begin{bmatrix}
0 \\ 0 \\ 1 
\end{bmatrix}$


Non-Example:
* $\begin{bmatrix}
1 \\ 1 \\ 2 
\end{bmatrix}$, $\begin{bmatrix}
2 \\ 2 \\ 5 
\end{bmatrix}$, linearly independent, but don't span $\mathbb R^3$
* $\begin{bmatrix}
1 \\ 1 \\ 2 
\end{bmatrix}$, $\begin{bmatrix}
2 \\ 2 \\ 5 
\end{bmatrix}$, $\begin{bmatrix}
3 \\ 3 \\ 7 
\end{bmatrix}$, the 3rd vector is a linear combination of first 2 
* the first case is 2 vectors on a plane, and 2nd is 3 vectors on a plane
* http://habrastorage.org/files/328/4c6/a34/3284c6a346ff491e8ac295ec82ea1f91.png


Another example: 
* $\begin{bmatrix}
1 \\ 1 \\ 2 
\end{bmatrix}$, $\begin{bmatrix}
2 \\ 2 \\ 5 
\end{bmatrix}$, $\begin{bmatrix}
3 \\ 1 \\ 8 
\end{bmatrix}$
* if we put the vectors as columns of a matrix, then the rank should be equal to the number of vectors 
* $\begin{bmatrix}
1 &amp; 2 &amp; 3\\
1 &amp; 2 &amp; 1\\ 
2 &amp; 5 &amp; 8 \\
\end{bmatrix}$, rank is 3



Also,
* take any invertible $n \times n$ matrix, take the columns from it and get a basis


== Dimension ==
Every space has some basis, and each basis of this space has the same number of vectors. The number of vectors in the basis is the ''dimension'' of this space.


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>kvc3bzjnt0ei7noc6yse2r2nw5y0wp8</sha1>
    </revision>
    <revision>
      <id>824</id>
      <parentid>580</parentid>
      <timestamp>2019-08-17T16:50:54Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2217">== Basis (Linear Algebra) ==
In Linear Algebra, ''basis'' is a set of [[Linear Independence|linearly independent]] vectors $\mathbf v_1, ...,  \mathbf v_n$ 


=== Spanning a Space ===
Vectors $\mathbf v_1, ...,  \mathbf v_l$  ''span a (sub)space'' $\iff$ this space consists of all possible linear combinations of these vectors 
* columns of a matrix $A$ span it's column space $C(A)$
* are such $\mathbf v_i$ independent? - depends 


=== Basis ===
Basis of a vector space is a sequence of vectors $\mathbf v_1, \mathbf v_2, ...,  \mathbf v_d$ that  
* are linearly independent and 
* span the entire space 


== Examples ==
Standard Basis: 
* the identity $I_d$,
* e.g. for &lt;math&gt;\mathbb R^3&lt;/math&gt;, &lt;math&gt;\mathbf e_1 = \begin{bmatrix}
1 \\ 0 \\ 0 
\end{bmatrix}&lt;/math&gt;, &lt;math&gt;\mathbf e_2 = \begin{bmatrix}
0 \\ 1 \\ 0 
\end{bmatrix}&lt;/math&gt;, &lt;math&gt;\mathbf e_3 = \begin{bmatrix}
0 \\ 0 \\ 1 
\end{bmatrix}&lt;/math&gt;


Non-Example:
* &lt;math&gt;\begin{bmatrix}
1 \\ 1 \\ 2 
\end{bmatrix}&lt;/math&gt;, &lt;math&gt;\begin{bmatrix}
2 \\ 2 \\ 5 
\end{bmatrix}&lt;/math&gt;, linearly independent, but don't span $\mathbb R^3$
* &lt;math&gt;\begin{bmatrix}
1 \\ 1 \\ 2 
\end{bmatrix}&lt;/math&gt;, &lt;math&gt;\begin{bmatrix}
2 \\ 2 \\ 5 
\end{bmatrix}&lt;/math&gt;, &lt;math&gt;\begin{bmatrix}
3 \\ 3 \\ 7 
\end{bmatrix}&lt;/math&gt;, the 3rd vector is a linear combination of first 2 
* the first case is 2 vectors on a plane, and 2nd is 3 vectors on a plane
* http://habrastorage.org/files/328/4c6/a34/3284c6a346ff491e8ac295ec82ea1f91.png


Another example: 
* &lt;math&gt;\begin{bmatrix}
1 \\ 1 \\ 2 
\end{bmatrix}&lt;/math&gt;, &lt;math&gt;\begin{bmatrix}
2 \\ 2 \\ 5 
\end{bmatrix}&lt;/math&gt;, &lt;math&gt;\begin{bmatrix}
3 \\ 1 \\ 8 
\end{bmatrix}&lt;/math&gt;
* if we put the vectors as columns of a matrix, then the rank should be equal to the number of vectors 
* &lt;math&gt;\begin{bmatrix}
1 &amp; 2 &amp; 3\\
1 &amp; 2 &amp; 1\\ 
2 &amp; 5 &amp; 8 \\
\end{bmatrix}&lt;/math&gt;, rank is 3



Also,
* take any invertible $n \times n$ matrix, take the columns from it and get a basis


== Dimension ==
Every space has some basis, and each basis of this space has the same number of vectors. The number of vectors in the basis is the ''dimension'' of this space.


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>k6ympmboz2tcy0hkwg90fte2au9lm7b</sha1>
    </revision>
  </page>
  <page>
    <title>Similar Matrices</title>
    <ns>0</ns>
    <id>578</id>
    <revision>
      <id>581</id>
      <timestamp>2015-04-26T17:13:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2228">== Similar Matrices ==
We say that two $n \times n$ matrices $A$ and $B$ are ''similar''
* if for some invertible $M$ we can write $B = M^{-1} A \, M$




== Families ==
Suppose $A$ has all its [[Eigenvalues and Eigenvectors|eigenvalues]]
* then if we [[Eigendecomposition|diagonalize]] $A$, we have $S^{-1} A \, S = \Lambda$
* so $A$ is similar to $\Lambda$
* Here $M = \Lambda$ 
* we may take another $M \ne \Lambda$ and will get another matrix similar to $A$ (not necessarily diagonal)


A family of similar matrices for $A$ is a set of matrices similar for $A$ for different $M$ 



== Why Similar? ==
What is similar about such $A$ and $B$? 
* they have the same eigenvalues!

Let's check it:
* let $A \mathbf x = \lambda \mathbf x$
* and $B = M^{-1} A \, M$
* then $A \mathbf x = A I \mathbf x = A M M^{-1} \mathbf x = \lambda \mathbf x$
* now let's multiply by $M^{-1}$ on the left:
* $\underbrace{M^{-1} A \, M}_{B} \, M^{-1} \mathbf x = M^{-1} \lambda \mathbf x$
* $B M^{-1} \mathbf x = M^{-1} \lambda \mathbf x$
* Let $\mathbf x^*$ be $M^{-1} \mathbf x$, so we have 
* $B \mathbf x^* = \lambda \mathbf x^*$
* so matrices $A$ and $B$ share the same eigenvalue $\lambda$, but the eigenvectors $\mathbf x \ne \mathbf x^*$



For diagonalization
* $A = S^{-1} \Lambda \, S$ eigenvalues stay the same, but eigenvectors become unit vectors 


What if for some $i \ne j$, $\lambda_i = \lambda_j$?
* there might be not enough eigenvectors to span $\mathbb R^n$
* i.e. columns of $A$ are not linearly independent


=== Other Things ===
There are other things that make these matrices similar.

$M$ does not change:
* eigenvalues $\lambda_i$ (as discussed earlier)
* [[Trace (Matrix)|Trace]] and [[Determinant]] (because $\text{tr}(A) = \sum \lambda_i$ and $\text{det}(A) = \prod \lambda_i$)
* rank, and therefore number of independent eigenvectors


$M$ '''does''' change
* eivenvectors
* [[Nullspace]] and left nullspace
* [[Row Space]] and [[Column Space]]
* Singular Values (see [[SVD]]): they depend on $A^T A$



== Jordan Form ==
Suppose $A$ has a family of similar matrices
* then the Jordan Form is the most diagonal matrix of the family


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>oglna275f05m7r2e8kngzlzyem2yj2a</sha1>
    </revision>
    <revision>
      <id>803</id>
      <parentid>581</parentid>
      <timestamp>2017-06-28T13:15:39Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2753">== Similar Matrices ==
We say that two $n \times n$ matrices $A$ and $B$ are ''similar''
* if for some invertible $M$ we can write $B = M^{-1} A \, M$


== Invariant Subspaces ==
Invariant subspace 
* we know that if $x$ is the [[Eigenvalues and Eigenvectors|eigenvector]] of $A$, then $Ax = \lambda x$
* $A$ only &quot;streches&quot; $x$ - but it remains in the same 1-dimensional subspace
* so such subspace $S$ formed by $x$ is invariant:
* if $x \in S \Rightarrow Ax \in S$

Invariant column space
* If there exists such $M$ that $AM = MB$ 
* then the $\text{range}(A)$ (the [[Column Space]] of $A$) is invariant 



== Families ==
Suppose $A$ has all its [[Eigenvalues and Eigenvectors|eigenvalues]]
* then if we [[Eigendecomposition|diagonalize]] $A$, we have $S^{-1} A \, S = \Lambda$
* so $A$ is similar to $\Lambda$
* Here $M = \Lambda$ 
* we may take another $M \ne \Lambda$ and will get another matrix similar to $A$ (not necessarily diagonal)

A ''family'' of similar matrices for $A$ is a set of all matrices similar for $A$ (for different $M$s)


== Why Similar? ==
What is similar about such $A$ and $B$? 
* they have the same eigenvalues!

Let's check it:
* let $A \mathbf x = \lambda \mathbf x$
* and $B = M^{-1} A \, M$
* then $A \mathbf x = A I \mathbf x = A M M^{-1} \mathbf x = \lambda \mathbf x$
* now let's multiply by $M^{-1}$ on the left:
* $\underbrace{M^{-1} A \, M}_{B} \, M^{-1} \mathbf x = M^{-1} \lambda \mathbf x$
* $B M^{-1} \mathbf x = M^{-1} \lambda \mathbf x$
* Let $\mathbf x^*$ be $M^{-1} \mathbf x$, so we have 
* $B \mathbf x^* = \lambda \mathbf x^*$
* so matrices $A$ and $B$ share the same eigenvalue $\lambda$
* but not the eigenvector! $\mathbf x \ne \mathbf x^*$


=== Diagonalization ===
For diagonalization
* $A = S^{-1} \Lambda \, S$ eigenvalues stay the same, but eigenvectors become unit vectors 

What if for some $i \ne j$, $\lambda_i = \lambda_j$?
* there might be not enough eigenvectors to span $\mathbb R^n$
* i.e. columns of $A$ are not linearly independent


=== Other Things ===
There are other things that make these matrices similar.

$M$ does not change:
* eigenvalues $\lambda_i$ (as discussed earlier)
* [[Trace (Matrix)|Trace]] and [[Determinant]] (because $\text{tr}(A) = \sum \lambda_i$ and $\text{det}(A) = \prod \lambda_i$)
* rank, and therefore number of independent eigenvectors


$M$ '''does''' change
* eivenvectors
* [[Nullspace]] and left nullspace
* [[Row Space]] and [[Column Space]]
* Singular Values (see [[SVD]]): they depend on $A^T A$



== Jordan Form ==
Suppose $A$ has a family of similar matrices
* then the Jordan Form is the most diagonal matrix of the family



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* [[Matrix Computations (book)]]

[[Category:Linear Algebra]]</text>
      <sha1>7sg7yb0x0jvuhnrbnkp2ohb2prict33</sha1>
    </revision>
  </page>
  <page>
    <title>Complex Vector Space</title>
    <ns>0</ns>
    <id>579</id>
    <revision>
      <id>582</id>
      <timestamp>2015-04-26T17:22:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2396">== Complex Vector Space ==
A $\mathbf z$ is a complex vector (denoted by $\mathbf z \in \mathbb C^n$)
* when it's components $z_i$ are [[Complex Numbers]]
* complex vectors also form a [[Vector Space]]


== Norm ==
How do we define the length of a complex vector? 
* $\| \mathbf z \|^2 = \langle \mathbf z, \mathbf z \rangle = \mathbf z^T \mathbf z$ is no good:
** length should be positive
** consider, for example, vector $(1, i)$
** $\| (1, i) \|^2$ would be $1^2 + i^2 = 0$
* what we really want is $\langle \mathbf z, \mathbf z \rangle = \overline {\mathbf z}^T \mathbf z$
** where $\overline {\mathbf z}$ is a [[Complex Conjugate]], i.e. $\overline {\mathbf z} = (\overline z_1, \ ... \ , \overline z_n)$
** this way each component of $\langle \mathbf z, \mathbf z \rangle$ contributes a strictly positive number to the overall dot product
** so $\| (1, i) \|^2$ is $1 - i^2 = 2$
** thus, $\| (1, i) \| = \sqrt{2}$


=== Hermitian ===
The way to transpose and take the conjugate at the same time
* $\mathbf z^H$ is $\overline {\mathbf z}^T$
* so we say $\| \mathbf z \|^2 = \mathbf z^H \mathbf z = \sum | z_i |^2$
* hermitian operator also applies to matrices
* $A^H$ is $\overline A^T$


=== Inner Product ===
The same for the dot product
* $\langle x, y \rangle$  is not $\mathbf x^T \mathbf y$
* it's $\langle x, y \rangle = \mathbf x^H \mathbf y$


== Symmetric Matrices ==
What about symmetric matrices in $\mathbb C^{n \times n}$?
* The definition that $A$ is symmetric if $A^T = A$ is for $\mathbb R$, not $\mathbb C$
* the complex version of symmetry is $\overline {A}^T = A$, or $A^H = A$ 0 using the Hermitian operator
* note that diagonal of a symmetric matrix must be real, because otherwise real values are complex conjugates of each others


=== Unitary Matrices ===
Can a complex matrix be [[Orthogonal Matrices|orthogonal]]? 
* $Q^T Q = I$ is orthogonal matrix for $\mathbb R$
* what about $\mathbb C$?
* yes, it's possible: $Q^H Q = I$ and all it's columns $\mathbf q_1, \ ... \ , \mathbf q_n$ are orthonormal 
* vectors $\mathbf q_1, \ ... \ , \mathbf q_n$ are orthonormal when $\mathbf q_i^H \mathbf q_j = \begin{cases}
1 &amp; \text{ if } i = j \\ 
0 &amp; \text{ if } i \ne j 
\end{cases}$
* but here instead of &quot;orthogonal&quot; they are usually called &quot;unitary&quot; matrices


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]


[[Category:Vector Spaces]]
[[Category:Linear Algebra]]</text>
      <sha1>kw5ew1pmljxn7kk90pjnmshhyacxk3a</sha1>
    </revision>
  </page>
  <page>
    <title>Math ML</title>
    <ns>0</ns>
    <id>580</id>
    <revision>
      <id>583</id>
      <timestamp>2015-04-27T14:53:17Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5599">{{ draft}}

== MathML ==
MathML Mathematical Markup Language - is a standard for mathematical expressions defined by W3C that browsers should support to render math formulas 


There are two types of MathML: 
* presentation - how browsers show draw a mathematical expression
* meaning - what is the meaning of this expression? 


== Presentation Elements ==
The presentation elements are meant to express the syntactic structure of mathematical notation
* MathML expressions trees with nested layout.


A ''token'' in MathML is an individual symbol, name or number. Tokens are grouped together to form MathML expressions. 

Tokens can be:
* identifier, variable or function names
* numbers 
* operators (including brackets - so called &quot;fences&quot;)
* text and whitespaces 

A &quot;symbol&quot; is not necessarily one character: it could be a string such as &lt;code&gt;&lt;mi&gt;sin&lt;/mi&gt;&lt;/code&gt; or &lt;code&gt;&lt;mn&gt;24&lt;/mn&gt;&lt;/code&gt;. In MathML they are treated as single tokens.


As in mathematics, MathML expressions are constructed recursively from smaller expressions or single tokens. Complex expressions are created with so-called &quot;layout&quot; constructor elements, while tokens are created with token elements.

Let us consider an example. A mathematical expression $(a + b)^2$ can be represented in MathML as follows:

&lt;pre&gt;
&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;
  &lt;msup&gt;
    &lt;mrow&gt;
      &lt;mo&gt;(&lt;/mo&gt;
      &lt;mrow&gt;
        &lt;mi&gt;a&lt;/mi&gt;
        &lt;mo&gt;+&lt;/mo&gt;
        &lt;mi&gt;b&lt;/mi&gt;
      &lt;mrow&gt;
      &lt;mo&gt;)&lt;/mo&gt;
    &lt;/mrow&gt;
    &lt;mn&gt;2&lt;/mn&gt;
  &lt;/msup&gt;
&lt;/math&gt;
&lt;/pre&gt;


It has the tree structure and recursive. If we take another mathematical expression $\cfrac{3}{(a + b)^2}$. It is a fraction and we see that its denominator is the same as the previous expression. This is also true for the MathML representation:


&lt;pre&gt;
&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;
  &lt;mfrac&gt;
    &lt;mn&gt;3&lt;/mn&gt;
    &lt;msup&gt;
      &lt;mrow&gt;
        &lt;mo&gt;(&lt;/mo&gt;
        &lt;mrow&gt;
          &lt;mi&gt;a&lt;/mi&gt;
          &lt;mo&gt;+&lt;/mo&gt;
          &lt;mi&gt;b&lt;/mi&gt;
        &lt;mrow&gt;
        &lt;mo&gt;)&lt;/mo&gt;
      &lt;/mrow&gt;
      &lt;mn&gt;2&lt;/mn&gt;
    &lt;/msup&gt;
  &lt;/mfrac&gt;
&lt;/math&gt;
&lt;/pre&gt;


=== Token Elements ===
Token elements are needed for representing tokens: the smallest units of mathematical notation that convey some meaning. 

There are several token elements:
* &lt;code&gt;mi&lt;/code&gt; identifier
* &lt;code&gt;mn&lt;/code&gt; number
* &lt;code&gt;mo&lt;/code&gt; operator, fence, or separator
* &lt;code&gt;mtext&lt;/code&gt; text
* &lt;code&gt;mspace&lt;/code&gt; space
* &lt;code&gt;ms&lt;/code&gt; string literal


Often tokens are just single characters, like &lt;code&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;/code&gt; or &lt;code&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;/code&gt;, but there are cases when tokes are multi-character, e.g. &lt;code&gt;&lt;mi&gt;sin&lt;/mi&gt;&lt;/code&gt; or &lt;code&gt;&lt;mi&gt;span&lt;/mi&gt;&lt;/code&gt;. 

In MathML &lt;code&gt;mi&lt;/code&gt; elements represent some symbolic name or text that should be rendered as identifiers. Identifiers could be variables, function names, and symbolic constants.


Transitional mathematical notation often involve some special typographical properties of fonts, e.g. using bold symbols e.g. $\mathbf x$ to denote vectors or capital script symbols e.g. $\mathcal G$ to denote groups and sets. To address this, there is a special attribute &quot;mathvariant&quot; that can take values such as &quot;bold&quot;, &quot;script&quot; and others. 


Numerical literals are represented with &lt;code&gt;mn&lt;/code&gt; elements. Typically they are sequences of digits, sometimes with a decimal point, representing an unsigned integer or real number, e.g. &lt;code&gt;&lt;mn&gt;50&lt;/mn&gt;&lt;/code&gt; or &lt;code&gt;&lt;mn&gt;50.00&lt;/mn&gt;&lt;/code&gt;. 


Finally, operators are represented with &lt;code&gt;mo&lt;/code&gt; elements. Operators are ...



=== Layout Elements ===
Layout elements are needed to form complex mathematical expressions from simple ones. They group elements in some particular way. For example:

* &lt;code&gt;mrow&lt;/code&gt; groups any number of sub-expressions horizontally
* &lt;code&gt;mfrac&lt;/code&gt; form sa fraction from two sub-expressions
* &lt;code&gt;msqrt&lt;/code&gt; forms a square root (radical without an index)

Some layout elements are used to add subscripts and superscripts:
* &lt;code&gt;msub&lt;/code&gt; attach a subscript to a base
* &lt;code&gt;msup&lt;/code&gt; attach a superscript to a base
* &lt;code&gt;msubsup&lt;/code&gt; attach a subscript-superscript pair to a base

And special kinds of scripts (TODO: describe in more details)
* &lt;code&gt;munder&lt;/code&gt; attach an underscript to a base
* &lt;code&gt;mover&lt;/code&gt; attach an overscript to a base
* &lt;code&gt;munderover&lt;/code&gt; attach an underscript-overscript pair to a base


For example, $\vec v$ will be rendered as 

&lt;pre&gt;
&lt;math xmlns='http://www.w3.org/1998/Math/MathML'&gt;
  &lt;mover&gt;
    &lt;mi&gt;v&lt;/mi&gt;
    &lt;mo&gt;&amp;rarr;&lt;/mo&gt;
  &lt;/mover&gt;
&lt;/math&gt;
&lt;/pre&gt;


This is how we would represent $\hat{ \mathbf x}$ (a bold x with a hat) in MathML:

&lt;pre&gt;
&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;
  &lt;mrow&gt;
    &lt;mover&gt;
      &lt;mrow&gt;
        &lt;mi mathvariant=&quot;bold&quot;&gt;x&lt;/mi&gt;
      &lt;/mrow&gt;
      &lt;mo&gt;&amp;#x005E;&lt;!-- ^ --&gt;&lt;/mo&gt;
    &lt;/mover&gt;
  &lt;/mrow&gt;
&lt;/math&gt;
&lt;/pre&gt;


There are more complex elements such as &lt;code&gt;mtable&lt;/code&gt;.


MathML presentation elements only suggest specific ways of rendering



=== Math Entities ===
Certain characters are used to name identifiers or operators that in traditional notation render the same as other symbols or usually rendered invisibly. 

entities &lt;code&gt;&amp;InvisibleTimes;&lt;/code&gt; &lt;code&gt;&amp;rarr;&lt;/code&gt;

The complete list of MathML entities is described in [http://www.w3.org/TR/MathML3/appendixg.html#Entities Entities]. 



== Sources ==
* http://www.w3.org/TR/MathML3/
* Miner, Robert, and Jeff Schaefer. &quot;A gentle introduction to MathML.&quot; (1998). [http://www.dessci.com/en/reference/mathml/]


[[Category:Mathematics]]
[[Category:XML]]
[[Category:Thesis]]</text>
      <sha1>mforzwhct360nwbippxcslx579aev0i</sha1>
    </revision>
  </page>
  <page>
    <title>Cross Validation</title>
    <ns>0</ns>
    <id>581</id>
    <redirect title="Cross-Validation" />
    <revision>
      <id>584</id>
      <timestamp>2015-04-28T20:06:43Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="30">#REDIRECT [[Cross-Validation]]</text>
      <sha1>pnb21l5iu089cfdiw9a3jqs55jynfb5</sha1>
    </revision>
  </page>
  <page>
    <title>Document Classification</title>
    <ns>0</ns>
    <id>582</id>
    <revision>
      <id>585</id>
      <timestamp>2015-04-28T20:42:28Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5711">== Document Classification ==
Document/Text Classification/Categorization is an [[NLP]]/[[Text Mining]] task of labeling unseen documents with categories from some predefined set
* not to be confused with [[Document Clustering]] - an [[Unsupervised Learning]] technique
* typically use [[Machine Learning]] for classification


=== Formulation ===
Document Classification, most general formulation:
* a task of assigning a boolean value to each pair $\langle d_j, c_i \rangle \in D \times C$
* $D$ - domain of documents
* $C = \{ c_1, \ ... \ , c_K \}$ - predefined categories
* we assign TRUE to $\langle d_j, c_i \rangle$ if document $d_j$ belongs to category $c_i$
* the task is to approximate the unknown target function $\Phi: D \times C \to \{ \text{T}, \text{F} \}$


Types 
* non overlapping categories, i.e. can assign only one label to each document. 
** the unknown function becomes $\Phi: D \to C$
* overlapping - can assign several labels


Hard categorization vs Ranking
* instead of assigning true/false we can rank each category 



== Features ==
=== [[Vector Space Model]] ===
How do we come up with features?
* text cannot be fed to the classifier directly 
* so need to do some [[Information Retrieval|indexing]] to map a document $d_j$ to some representation
* for example, to [[Vector Space Model]]: represent document as a vector of term weights - &quot;features&quot;
* $d_j = \langle w_{1j}, \ ... \ , w_{nj} \rangle$, with $w_{ij}$ telling how much term $t_i$ contributes to the semantics of document $d_j$ 


=== [[TF-IDF]] ===
Weights are often term frequencies or [[TF-IDF]]:
* $\text{tf-idf}(t_k, d_j) = \text{tf}(t_k, d_j) \cdot \log \cfrac{N}{\text{df}(t_k)}$
* $\text{tf}(t_k, d_j)$ term frequency: how many times term $t_k$ appeared in document $d_j$
* $\text{df}(t_k)$ document frequency: how many documents in the training set contain term $t_k$
* $N$ number of documents in the training set


Why TF-IDF is good for classification:
* the more often a term occurs in a document, the more representative it is of this document
* the more documents contain a term, the lest discriminating it becomes


=== [[Dimensionality Reduction]] ===
* Given a vocabulary/term set $V$ of size $| V |$ 
* the goal is to find $V'$ s.t. $| V' | \ll | V |$ ($V'$ is called &quot;reduced vocabulary&quot; or &quot;reduced term set&quot;)
* DR techniques tend to reduce [[Overfitting]]: 
** if dimensionality of data is $|V'|$ and there are $N$ examples in the training set
** then it's good to have $|V'| \approx N$ to avoid overfitting


We can divide dimensionality reduction techniques by locality: 
* local dimensionality reduction
** applied to each category $c_i$ 
**  choose a reduced set $| V'_i | \ll | V_i |$  for each category
* global: choose $| V' |$ using all categories 



There are two (very different) types of dimensionality reduction
* by term selection ([[Feature Selection]]): select $V' \subset V$ 
* by term extraction: terms in $V'$ are not necessarily the same as in $V$ 



Usual IR and indexing techniques for reducing dimensionality are 
* [[Stop Words]] Removal
* [[Stemming]] or [[Lemmatization]]


[[Stop Words]] Removal
* Before indexing some ''function words'' are sometimes removed 
* for example [[Stop Words]] - topic neutral words such as articles, prepositions, conjunctions
* cases when stop words are not removed: author identification (&quot;the little words give authors away&quot;)


[[Stemming]]
* Stemming is grouping words that share the same morphological root 
* it's controversial whether it's helpful for document classification or not
* usually it's used: it reduces the dimensionality 
* sometimes [[Lemmatization]] is applied instead, but it's more involved



Note that DR techniques sometimes may remove important information when removing terms

How to select terms?
* [[Subset Selection]]: usually not used because $| V |$ is too large
* [[Feature Filtering]]: rank terms according to their &quot;usefulness&quot; and keep only some of them
* Document Frequency: Keep only terms that occur in higher number of documents
** e.g. remove words that occur only in 3 documents or less


Term Extraction techniques:
* these techniques create &quot;artificial&quot; terms that aren't really terms - they are generated, and not the ones that actually occurred in the text
* The original terms don't have the optimal dimensionality for document content representation
** because of the problems of polysemy, homonymy and synonymy 
* so we want to find better representation that doesn't suffer from these issues
* methods: 
* [[Term Clustering]] cluster terms and use centroids instead of words
* [[Latent Semantic Analysis]] apply [[SVD]] to Term-Document matrix 



== [[Classification]] ==
Good classifiers for text:
* [[Naive Bayes Classifier]]
* [[Decision Tree (Data Mining)]]
* [[Support Vector Machines]]


== Evaluation ==
[[Precision and Recall]] metrics can be extended to [[Multi-Class Problems|Evaluation of Multiclass Classifiers]]
* similar to the [[One-vs-All Classification]] technique
* ways of averaging the results: 
** micro: first calculate TP, FP, FN, FN for each category separately, and then use usual formulas for precision and recall
** and macro averaging: calculate precision and recall for each category separately, and then average


[[F Measure]]
* usually is a way of combining precision and recall
* depending on how P and R were calculated, there are $F_\beta$-micro and $F_\beta$-macro measures


== Sources ==
* Sebastiani, Fabrizio. &quot;Machine learning in automated text categorization.&quot; (2002). [http://arxiv.org/pdf/cs/0110053.pdf]



[[Category:NLP]]
[[Category:Text Mining]]
[[Category:Machine Learning]]
[[Category:Supervised Learning]]
[[Category:Classification]]</text>
      <sha1>h0lsz7o7t3q4xoaexkbojjlkjr5ogrc</sha1>
    </revision>
  </page>
  <page>
    <title>Precision and Recall</title>
    <ns>0</ns>
    <id>583</id>
    <revision>
      <id>586</id>
      <timestamp>2015-07-03T15:30:20Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12094">== Precision and Recall ==
Precision and Recall are quality metrics used across many domains:
* originally it's from [[Information Retrieval]]
* also used in [[Machine Learning]]



== Precision and Recall for [[Information Retrieval]] ==
IR system has to be:
* precise: all returned document should be relevant 
* efficient: all relevant document should be returned


Given a test collection, the quality of an IR system is evaluated with:
* ''Precision'': % of relevant documents in the result
* ''Recall'': % of retrieved relevant documents


More formally, 
* given a collection of documents $C$ 
* If $X \subseteq C$ is the output of the IR system  and $Y \subseteq C$ is the list of all relevant documents then define
* ''precision'' as $P = \cfrac{|X \cup Y|}{| X|}$ and ''recall'' as $R = \cfrac{|X \cup Y|}{| Y |}$
* both $P$ and $R$ are defined w.r.t a set of retrieved documents 



=== Precision/Recall Curves ===
* If we retrieve more document, we improve recall (if return all docs, $R = 1$)
* if we retrieve fewer documents, we improve precision, but reduce recall
* so there's a trade-off between them


Let $k$ be the number of retrieved documents 
* then by varying $k$ from $0$ to $N = |C|$ we can draw $P$ vs $R$ and obtain the Precision/recall curve:
* https://habrastorage.org/files/26b/c1e/a38/26bc1ea381424262b9d966c63f418661.png source: [http://www.searchtechnologies.com/precision-recall]
* the closer the curve to the $(1, 1)$ point - the better the IR system performance
* https://habrastorage.org/files/010/ded/77e/010ded77e8d0454b99f0cafd3d962613.png source: [[Information Retrieval (UFRT)]] lecture 2


Area under P/R Curve:
* Analogously to [[ROC Analysis|ROC Curves]] we can calculate the area under the P/R Curve
* the closer AUPR to 1 the better 



=== Average Precision ===
Top-$k$-precision is insensitive to change of ranks of relevant documents among top $k$ 

how to measure overall performance of an IR system? 

$\text{avg P} = \cfrac{1}{K} \sum_{k = 1}^K \cfrac{k}{r_k}$ 
* where $r_i$ is the rank of $k$th relevant document in the result 

Since in a test collection we usually have a set of queries, we calcuate the average over them 
and get Mean Average Precision: MAP



== Precision and Recall for [[Classification]] ==
The precision and recall metrics can also be applied to [[Machine Learning]]: to binary classifiers


{| class=&quot;wikitable&quot; align=&quot;center&quot; style=&quot;text-align:center; border:none; background:transparent;&quot;
|+ Diagnostic Testing Measures  [http://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram]
| colspan=&quot;2&quot; rowspan=&quot;2&quot; style=&quot;border:none;&quot;|
! colspan=&quot;2&quot; | Actual Class $y$
|-
| Positive
| Negative
|-
! rowspan=&quot;2&quot; | $h_{\theta}(x)$ &lt;br/&gt; Test&lt;br /&gt;outcome
| Test&lt;br /&gt;outcome&lt;br /&gt;positive
|style=&quot;background:#ccffcc;&quot;| '''True positive'''&lt;br/&gt; ($\text{TP}$)
|style=&quot;background:#eedddd;&quot;| '''False positive'''&lt;br /&gt;($\text{FP}$, Type I error)
| Precision =&lt;br /&gt; $\cfrac{\# \text{TP}}{\# \text{TP} + \# \text{FP}}$
|-
| Test&lt;br /&gt;outcome&lt;br /&gt;negative
|style=&quot;background:#eedddd;&quot;| '''False negative'''&lt;br /&gt;($\text{FN}$, Type II error)
|style=&quot;background:#ccffcc;&quot;| '''True negative'''&lt;br /&gt; ($\text{TN}$)
| Negative predictive value =&lt;br /&gt; $\cfrac{\# \text{TN}}{\# \text{FN} + \# \text{TN}}$
|-
|colspan=&quot;2&quot; style=&quot;border:none;&quot; |
| Sensitivity =&lt;br /&gt; $\cfrac{\# \text{TP}}{\# \text{TP} + \# \text{FN}}$
| Specificity =&lt;br /&gt; $\cfrac{\# \text{TN}}{\# \text{FP} + \# \text{TN}}$
| Accuracy =&lt;br /&gt; $\cfrac{\# \text{TP} + \# \text{TN}}{\# \text{TOTAL}}$
|}


Main values of this matrix:
* '''True Positive''' - we predicted &quot;+&quot; and the true class is &quot;+&quot;
* '''True Negative''' - we predicted &quot;-&quot; and the true class is &quot;-&quot;
* '''False Positive''' - we predicted &quot;+&quot; and the true class is &quot;-&quot; (Type I error)
* '''False Negative''' - we predicted &quot;-&quot; and the true class is &quot;+&quot; (Type II error)


Two Classes: $C_+$ and $C_-$


=== Precision ===
Precision
* $\pi = P\big(f(\mathbf x) = C_+ \, \big| \, h_{\theta}(\mathbf x) =  C_+ \big)$
* given that we predict $\mathbf x$ is +
* what's the probability that the decision is correct
* we estimate precision as $P = \cfrac{\text{# TP}}{\text{# predicted positives}} = \cfrac{\text{# TP}}{\text{# TP} + \text{# FP}}$


Interpretation
* Out of all the people we thought have cancer, how many actually had it? 
* High precision is good
* we don't tell many people that they have cancer when they actually don't 



=== Recall ===
Recall
* $\rho = P\big(h_{\theta}(\mathbf x) = C_+ \, \big| \, f(\mathbf x) = C_+ \big)$
* given a positive instance $\mathbf x$ 
* what's the probability that we predict correctly
* we estimate recall as $R = \cfrac{\text{# TP}}{\text{# actual positives}} = \cfrac{\text{# TP}}{\text{# TP + # FN}}$


Interpretation
* Out of all the people that do actually have cancer, how much we identified? 
* The higher the better:
* We don't fail to spot many people that actually have cancer


* For a classifier that always returns zero (i.e. $h_{\theta}(x) = 0$) the Recall would be zero
* That gives us more useful evaluation metric
* And we're much more sure 


== F Measure ==
$P$ and $R$ don't make sense in the isolation from each other
* higher level of $\rho$ may be obtained by lowering $\pi$ and vice versa


Suppose we have a ranking classifier that produces some score for $\mathbf x$ 
* we decide whether to classify it as $C_+$ or $C_-$ based on some threshold parameter $\tau$
* by varying $\tau$ we will get different precision and recall 
* improving recall will lead to worse precision
* improving precision will lead to worse recall 
* how to pick the threshold? 
* combine $P$ and $R$ into one measure (also see [[ROC Analysis]])


$F_\beta = \cfrac{(\beta^2 + 1) P\, R}{\beta^2 \, P + R}$
* $\beta$ is the tradeoff between $P$ and $R$
* if $\beta$ is close to 0, then we give more importance to $P$
** $F_0 = P$
* if $\beta$ is closer to $+ \infty$, we give more importance to $R$


When $\beta = 1$ we have $F_1$ score:
* The $F_1$-score is a single measure of performance of the test. 
* it's the harmonic mean of precision $P$ and recall $R$ 
* $F_1 = 2 \cfrac{P \, R}{P + R}$


=== Motivation: [[Precision and Recall]] ===
Let's say we trained a [[Logistic Regression]] classifier 
* we predict 1 if $h_{\theta}(x) \geqslant 0.5$
* we predict 0 if $h_{\theta}(x) &lt; 0.5$

Suppose we want to predict y = 1 (i.e. people have cancer) only if we're very confident 
* we may change the threshold to 0.7
** we predict 1 if $h_{\theta}(x) \geqslant 0.7$
** we predict 0 if $h_{\theta}(x) &lt; 0.7$
* We'll have higher precision in this case (all for who we predicted y = 1 are more likely to actually have it)
* But lower recall (we'll miss more patients that actually have cancer, but we failed to spot them)

Let's consider the opposite 
* Suppose we want to avoid missing too many cases of y=1 (i.e. we want to avoid false negatives)
* So we may change the threshold to 0.3
** we predict 1 if $h_{\theta}(x) \geqslant 0.3$
** we predict 0 if $h_{\theta}(x) &lt; 0.3$
* That leads to 
* Higher recall (we'll correctly flag higher fraction of patients with cancer)
* Lower precision (and higher fraction will turn out to actually have no cancer)


Questions
* Is there a way to automatically choose the threshold for us? 
* How to compare precision and recall numbers and decide which algorithm is better?
* at the beginning we had a single number (error ratio) - but now have two and need to choose which one to prefer 
* $F_1$ score helps to decide since it's just one number


=== Example ===
Suppose we have 3 algorithms $A_1$, $A_2$, $A_3$, and we captured the following metrics: 


{| border=&quot;1&quot; class=&quot;wikitable&quot;
|
! $P$ !! $R$ !! $\text{Avg}$ !! $F_1$
|
|-
! $A_1$
| 0.5 || 0.4 || 0.45 || 0.444 || $\leftarrow$ our choice
|-
! $A_2$
| 0.7 || 0.1 || 0.4 || 0.175 ||
|-
! $A_3$
| 0.02 || 1.0 || 0.54 || 0.0392 ||
|}


Here's the best is $A_1$ because it has the highest $F_1$-score


== Precision and Recall for Clustering ==
Can use precision and recall to evaluate the result of clustering 

Correct decisions:
* '''TP''' = decision to assign two similar documents to the same cluster
* '''TN''' = assign two dissimilar documents to different clusters 

Errors:
* '''FP''': assign two dissimilar documents to the same cluster
* '''FN''': assign two similar documents to different clusters 


So the confusion matrix is:

{|  class=&quot;wikitable&quot;
|
! same  !! different 
|-
! same
| TP || FN
|-
! different
| FP || TN 
|-
|}


=== Example ===
Consider the following example (from the IR book [http://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-clustering-1.html])
* http://nlp.stanford.edu/IR-book/html/htmledition/img1393.png
* there are $\cfrac{n \, (n - 1)}{2} = 136$ pairs of documents
* $\text{TP} + \text{FP} = {6 \choose 2}  + {6 \choose 2}  + {5 \choose 2}  = 40$
* $\text{TP} = {5 \choose 2}  + {4 \choose 2}  + {3 \choose 2}  + {2 \choose 2}  = 20$
* etc

So have the following contingency table:

{|  class=&quot;wikitable&quot;
|
! same !! different 
|-
! same
| $\text{TP} = 20$ || $\text{FN} = 24$
|-
! different
| $\text{FP} = 20$ || $\text{TN} = 72$ 
|-
|}


Thus, 
* $P = 20/40 = 0.5$ and $R = 20/44 \approx 0.455$
* $F_1$ score is $F_1 \approx 0.48$


== Multi-Class Problems ==
How do we adapt precision and recall to multi-class problems?
* let $f(\cdot)$ be the target unknown function and $h_\theta(\cdot)$ the model
* let $C_1, \ ... , C_K$ be labels we want to predict ($K$ labels)


Precision w.r.t class $C_i$ is 
* $P\big(f(\mathbf x) = C_i \ \big| \ h_\theta(\mathbf x) = C_i \big)$
* probability that given that we classified $\mathbf x$ as $C_i$
* the decision is indeed correct


Recall w.r.t. class $C_i$ is 
* $P\big(h_\theta(\mathbf x) = C_i \ \big| \ f(\mathbf x) = C_i \big)$
* given an instance $\mathbf x$ belongs to $C_i$
* what's the probability that we predict correctly


We estimate these probabilities using a contingency table w.r.t each class $C_i$

Idea similar to the [[One-vs-All Classification]] technique


Contingency Table for $C_i$:
* let $C_+$ be $C_i$ and 
* let $C_-$ be all other classes except for $C_i$, i.e. $C_- = \{ C_j \} - C_i$ (all classes except for $i$)
* then we create a contingency table 
* and calculate $\text{TP}_i, \text{FP}_i, \text{FN}_i, \text{TN}_i$ for them
* http://habrastorage.org/files/468/b51/be7/468b51be729a42ff8195b6fc05292508.png


Now estimate precision and recall for class $C_i$
* $P_i = \cfrac{\text{TP}_i}{\text{TP}_i + \text{FP}_i}$
* $R_i = \cfrac{\text{TP}_i}{\text{TP}_i + \text{FN}_i}$


=== Averaging ===
* These precision and recall are calculated for each class separately
* how to combine them? 


'''Micro-averaging''' 
* calculate TP, ... etc globally and then average
* let 
** $\text{TP} = \sum_i \text{TP}_i$ 
** $\text{FP} = \sum_i \text{FP}_i$ 
** $\text{FN} = \sum_i \text{FN}_i$ 
** $\text{TN} = \sum_i \text{TN}_i$ 
* and then calculate precision and recall as
** $P^\mu = \cfrac{\text{TP}}{\text{TP} + \text{FP}}$
** $R^\mu = \cfrac{\text{TP}}{\text{TP} + \text{FN}}$



'''Macro-averaging'''
* calculate $P_i$ and $R_i$ &quot;locally&quot; for each $C_i$
* and then let $P^M = \cfrac{1}{K} \sum_i P_i$ and $R^M = \cfrac{1}{K} \sum_i R_i$


Micro and macro averaging behave quite differently and may give different results 
* the ability to behave well on categories with low generality (fewer training examples) will be less emphasized by macroaveraging
* which one to use? depends on application


This way is often used in [[Document Classification]]



== Sources ==
* [[Machine Learning (coursera)]]
* Sebastiani, Fabrizio. &quot;Machine learning in automated text categorization.&quot; (2002). [http://arxiv.org/pdf/cs/0110053.pdf]
* Zhai, ChengXiang. &quot;Statistical language models for information retrieval.&quot; 2008.
* [[Information Retrieval (UFRT)]]
* Manning, Christopher D., Prabhakar Raghavan, and Hinrich Schütze. &quot;Introduction to information retrieval.&quot; 2008. [http://informationretrieval.org/]


[[Category:Machine Learning]]
[[Category:Classifiers]]
[[Category:Information Retrieval]]
[[Category:Model Performance Evaluation]]</text>
      <sha1>g815z77o9ppxqjg6amdv5xnbupooe5c</sha1>
    </revision>
    <revision>
      <id>744</id>
      <parentid>586</parentid>
      <timestamp>2015-12-22T13:38:23Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <comment>/* Multi-Class Problems */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12088">== Precision and Recall ==
Precision and Recall are quality metrics used across many domains:
* originally it's from [[Information Retrieval]]
* also used in [[Machine Learning]]



== Precision and Recall for [[Information Retrieval]] ==
IR system has to be:
* precise: all returned document should be relevant 
* efficient: all relevant document should be returned


Given a test collection, the quality of an IR system is evaluated with:
* ''Precision'': % of relevant documents in the result
* ''Recall'': % of retrieved relevant documents


More formally, 
* given a collection of documents $C$ 
* If $X \subseteq C$ is the output of the IR system  and $Y \subseteq C$ is the list of all relevant documents then define
* ''precision'' as $P = \cfrac{|X \cup Y|}{| X|}$ and ''recall'' as $R = \cfrac{|X \cup Y|}{| Y |}$
* both $P$ and $R$ are defined w.r.t a set of retrieved documents 



=== Precision/Recall Curves ===
* If we retrieve more document, we improve recall (if return all docs, $R = 1$)
* if we retrieve fewer documents, we improve precision, but reduce recall
* so there's a trade-off between them


Let $k$ be the number of retrieved documents 
* then by varying $k$ from $0$ to $N = |C|$ we can draw $P$ vs $R$ and obtain the Precision/recall curve:
* https://habrastorage.org/files/26b/c1e/a38/26bc1ea381424262b9d966c63f418661.png source: [http://www.searchtechnologies.com/precision-recall]
* the closer the curve to the $(1, 1)$ point - the better the IR system performance
* https://habrastorage.org/files/010/ded/77e/010ded77e8d0454b99f0cafd3d962613.png source: [[Information Retrieval (UFRT)]] lecture 2


Area under P/R Curve:
* Analogously to [[ROC Analysis|ROC Curves]] we can calculate the area under the P/R Curve
* the closer AUPR to 1 the better 



=== Average Precision ===
Top-$k$-precision is insensitive to change of ranks of relevant documents among top $k$ 

how to measure overall performance of an IR system? 

$\text{avg P} = \cfrac{1}{K} \sum_{k = 1}^K \cfrac{k}{r_k}$ 
* where $r_i$ is the rank of $k$th relevant document in the result 

Since in a test collection we usually have a set of queries, we calcuate the average over them 
and get Mean Average Precision: MAP



== Precision and Recall for [[Classification]] ==
The precision and recall metrics can also be applied to [[Machine Learning]]: to binary classifiers


{| class=&quot;wikitable&quot; align=&quot;center&quot; style=&quot;text-align:center; border:none; background:transparent;&quot;
|+ Diagnostic Testing Measures  [http://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram]
| colspan=&quot;2&quot; rowspan=&quot;2&quot; style=&quot;border:none;&quot;|
! colspan=&quot;2&quot; | Actual Class $y$
|-
| Positive
| Negative
|-
! rowspan=&quot;2&quot; | $h_{\theta}(x)$ &lt;br/&gt; Test&lt;br /&gt;outcome
| Test&lt;br /&gt;outcome&lt;br /&gt;positive
|style=&quot;background:#ccffcc;&quot;| '''True positive'''&lt;br/&gt; ($\text{TP}$)
|style=&quot;background:#eedddd;&quot;| '''False positive'''&lt;br /&gt;($\text{FP}$, Type I error)
| Precision =&lt;br /&gt; $\cfrac{\# \text{TP}}{\# \text{TP} + \# \text{FP}}$
|-
| Test&lt;br /&gt;outcome&lt;br /&gt;negative
|style=&quot;background:#eedddd;&quot;| '''False negative'''&lt;br /&gt;($\text{FN}$, Type II error)
|style=&quot;background:#ccffcc;&quot;| '''True negative'''&lt;br /&gt; ($\text{TN}$)
| Negative predictive value =&lt;br /&gt; $\cfrac{\# \text{TN}}{\# \text{FN} + \# \text{TN}}$
|-
|colspan=&quot;2&quot; style=&quot;border:none;&quot; |
| Sensitivity =&lt;br /&gt; $\cfrac{\# \text{TP}}{\# \text{TP} + \# \text{FN}}$
| Specificity =&lt;br /&gt; $\cfrac{\# \text{TN}}{\# \text{FP} + \# \text{TN}}$
| Accuracy =&lt;br /&gt; $\cfrac{\# \text{TP} + \# \text{TN}}{\# \text{TOTAL}}$
|}


Main values of this matrix:
* '''True Positive''' - we predicted &quot;+&quot; and the true class is &quot;+&quot;
* '''True Negative''' - we predicted &quot;-&quot; and the true class is &quot;-&quot;
* '''False Positive''' - we predicted &quot;+&quot; and the true class is &quot;-&quot; (Type I error)
* '''False Negative''' - we predicted &quot;-&quot; and the true class is &quot;+&quot; (Type II error)


Two Classes: $C_+$ and $C_-$


=== Precision ===
Precision
* $\pi = P\big(f(\mathbf x) = C_+ \, \big| \, h_{\theta}(\mathbf x) =  C_+ \big)$
* given that we predict $\mathbf x$ is +
* what's the probability that the decision is correct
* we estimate precision as $P = \cfrac{\text{# TP}}{\text{# predicted positives}} = \cfrac{\text{# TP}}{\text{# TP} + \text{# FP}}$


Interpretation
* Out of all the people we thought have cancer, how many actually had it? 
* High precision is good
* we don't tell many people that they have cancer when they actually don't 



=== Recall ===
Recall
* $\rho = P\big(h_{\theta}(\mathbf x) = C_+ \, \big| \, f(\mathbf x) = C_+ \big)$
* given a positive instance $\mathbf x$ 
* what's the probability that we predict correctly
* we estimate recall as $R = \cfrac{\text{# TP}}{\text{# actual positives}} = \cfrac{\text{# TP}}{\text{# TP + # FN}}$


Interpretation
* Out of all the people that do actually have cancer, how much we identified? 
* The higher the better:
* We don't fail to spot many people that actually have cancer


* For a classifier that always returns zero (i.e. $h_{\theta}(x) = 0$) the Recall would be zero
* That gives us more useful evaluation metric
* And we're much more sure 


== F Measure ==
$P$ and $R$ don't make sense in the isolation from each other
* higher level of $\rho$ may be obtained by lowering $\pi$ and vice versa


Suppose we have a ranking classifier that produces some score for $\mathbf x$ 
* we decide whether to classify it as $C_+$ or $C_-$ based on some threshold parameter $\tau$
* by varying $\tau$ we will get different precision and recall 
* improving recall will lead to worse precision
* improving precision will lead to worse recall 
* how to pick the threshold? 
* combine $P$ and $R$ into one measure (also see [[ROC Analysis]])


$F_\beta = \cfrac{(\beta^2 + 1) P\, R}{\beta^2 \, P + R}$
* $\beta$ is the tradeoff between $P$ and $R$
* if $\beta$ is close to 0, then we give more importance to $P$
** $F_0 = P$
* if $\beta$ is closer to $+ \infty$, we give more importance to $R$


When $\beta = 1$ we have $F_1$ score:
* The $F_1$-score is a single measure of performance of the test. 
* it's the harmonic mean of precision $P$ and recall $R$ 
* $F_1 = 2 \cfrac{P \, R}{P + R}$


=== Motivation: [[Precision and Recall]] ===
Let's say we trained a [[Logistic Regression]] classifier 
* we predict 1 if $h_{\theta}(x) \geqslant 0.5$
* we predict 0 if $h_{\theta}(x) &lt; 0.5$

Suppose we want to predict y = 1 (i.e. people have cancer) only if we're very confident 
* we may change the threshold to 0.7
** we predict 1 if $h_{\theta}(x) \geqslant 0.7$
** we predict 0 if $h_{\theta}(x) &lt; 0.7$
* We'll have higher precision in this case (all for who we predicted y = 1 are more likely to actually have it)
* But lower recall (we'll miss more patients that actually have cancer, but we failed to spot them)

Let's consider the opposite 
* Suppose we want to avoid missing too many cases of y=1 (i.e. we want to avoid false negatives)
* So we may change the threshold to 0.3
** we predict 1 if $h_{\theta}(x) \geqslant 0.3$
** we predict 0 if $h_{\theta}(x) &lt; 0.3$
* That leads to 
* Higher recall (we'll correctly flag higher fraction of patients with cancer)
* Lower precision (and higher fraction will turn out to actually have no cancer)


Questions
* Is there a way to automatically choose the threshold for us? 
* How to compare precision and recall numbers and decide which algorithm is better?
* at the beginning we had a single number (error ratio) - but now have two and need to choose which one to prefer 
* $F_1$ score helps to decide since it's just one number


=== Example ===
Suppose we have 3 algorithms $A_1$, $A_2$, $A_3$, and we captured the following metrics: 


{| border=&quot;1&quot; class=&quot;wikitable&quot;
|
! $P$ !! $R$ !! $\text{Avg}$ !! $F_1$
|
|-
! $A_1$
| 0.5 || 0.4 || 0.45 || 0.444 || $\leftarrow$ our choice
|-
! $A_2$
| 0.7 || 0.1 || 0.4 || 0.175 ||
|-
! $A_3$
| 0.02 || 1.0 || 0.54 || 0.0392 ||
|}


Here's the best is $A_1$ because it has the highest $F_1$-score


== Precision and Recall for Clustering ==
Can use precision and recall to evaluate the result of clustering 

Correct decisions:
* '''TP''' = decision to assign two similar documents to the same cluster
* '''TN''' = assign two dissimilar documents to different clusters 

Errors:
* '''FP''': assign two dissimilar documents to the same cluster
* '''FN''': assign two similar documents to different clusters 


So the confusion matrix is:

{|  class=&quot;wikitable&quot;
|
! same  !! different 
|-
! same
| TP || FN
|-
! different
| FP || TN 
|-
|}


=== Example ===
Consider the following example (from the IR book [http://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-clustering-1.html])
* http://nlp.stanford.edu/IR-book/html/htmledition/img1393.png
* there are $\cfrac{n \, (n - 1)}{2} = 136$ pairs of documents
* $\text{TP} + \text{FP} = {6 \choose 2}  + {6 \choose 2}  + {5 \choose 2}  = 40$
* $\text{TP} = {5 \choose 2}  + {4 \choose 2}  + {3 \choose 2}  + {2 \choose 2}  = 20$
* etc

So have the following contingency table:

{|  class=&quot;wikitable&quot;
|
! same !! different 
|-
! same
| $\text{TP} = 20$ || $\text{FN} = 24$
|-
! different
| $\text{FP} = 20$ || $\text{TN} = 72$ 
|-
|}


Thus, 
* $P = 20/40 = 0.5$ and $R = 20/44 \approx 0.455$
* $F_1$ score is $F_1 \approx 0.48$


== Multi-Class Problems ==
How do we adapt precision and recall to multi-class problems?
* let $f(\cdot)$ be the target unknown function and $h_\theta(\cdot)$ the model
* let $C_1, \ ... , C_K$ be labels we want to predict ($K$ labels)


Precision w.r.t class $C_i$ is 
* $P\big(f(\mathbf x) = C_i \ \big| \ h_\theta(\mathbf x) = C_i \big)$
* probability that given that we classified $\mathbf x$ as $C_i$
* the decision is indeed correct


Recall w.r.t. class $C_i$ is 
* $P\big(h_\theta(\mathbf x) = C_i \ \big| \ f(\mathbf x) = C_i \big)$
* given an instance $\mathbf x$ belongs to $C_i$
* what's the probability that we predict correctly


We estimate these probabilities using a contingency table w.r.t each class $C_i$


Contingency Table for $C_i$:
* let $C_+$ be $C_i$ and 
* let $C_-$ be all other classes except for $C_i$, i.e. $C_- = \{ C_j \} - C_i$ (all classes except for $i$)
* then we create a contingency table 
* and calculate $\text{TP}_i, \text{FP}_i, \text{FN}_i, \text{TN}_i$ for them
* http://habrastorage.org/files/468/b51/be7/468b51be729a42ff8195b6fc05292508.png


Now estimate precision and recall for class $C_i$
* $P_i = \cfrac{\text{TP}_i}{\text{TP}_i + \text{FP}_i}$
* $R_i = \cfrac{\text{TP}_i}{\text{TP}_i + \text{FN}_i}$


=== Averaging ===
* These precision and recall are calculated for each class separately
* how to combine them? 


'''Micro-averaging''' 
* calculate TP, ... etc globally and then average
* let 
** $\text{TP} = \sum_i \text{TP}_i$ 
** $\text{FP} = \sum_i \text{FP}_i$ 
** $\text{FN} = \sum_i \text{FN}_i$ 
** $\text{TN} = \sum_i \text{TN}_i$ 
* and then calculate precision and recall as
** $P^\mu = \cfrac{\text{TP}}{\text{TP} + \text{FP}}$
** $R^\mu = \cfrac{\text{TP}}{\text{TP} + \text{FN}}$



'''Macro-averaging'''
* similar to the [[One-vs-All Classification]] technique
* calculate $P_i$ and $R_i$ &quot;locally&quot; for each $C_i$
* and then let $P^M = \cfrac{1}{K} \sum_i P_i$ and $R^M = \cfrac{1}{K} \sum_i R_i$


Micro and macro averaging behave quite differently and may give different results 
* the ability to behave well on categories with low generality (fewer training examples) will be less emphasized by macroaveraging
* which one to use? depends on application


This way is often used in [[Document Classification]]

== Sources ==
* [[Machine Learning (coursera)]]
* Sebastiani, Fabrizio. &quot;Machine learning in automated text categorization.&quot; (2002). [http://arxiv.org/pdf/cs/0110053.pdf]
* Zhai, ChengXiang. &quot;Statistical language models for information retrieval.&quot; 2008.
* [[Information Retrieval (UFRT)]]
* Manning, Christopher D., Prabhakar Raghavan, and Hinrich Schütze. &quot;Introduction to information retrieval.&quot; 2008. [http://informationretrieval.org/]


[[Category:Machine Learning]]
[[Category:Classifiers]]
[[Category:Information Retrieval]]
[[Category:Model Performance Evaluation]]</text>
      <sha1>1mwwcekrvlh0752bejjjvxi2zgtfyky</sha1>
    </revision>
    <revision>
      <id>745</id>
      <parentid>744</parentid>
      <timestamp>2015-12-22T13:39:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <comment>/* Averaging */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12111">== Precision and Recall ==
Precision and Recall are quality metrics used across many domains:
* originally it's from [[Information Retrieval]]
* also used in [[Machine Learning]]



== Precision and Recall for [[Information Retrieval]] ==
IR system has to be:
* precise: all returned document should be relevant 
* efficient: all relevant document should be returned


Given a test collection, the quality of an IR system is evaluated with:
* ''Precision'': % of relevant documents in the result
* ''Recall'': % of retrieved relevant documents


More formally, 
* given a collection of documents $C$ 
* If $X \subseteq C$ is the output of the IR system  and $Y \subseteq C$ is the list of all relevant documents then define
* ''precision'' as $P = \cfrac{|X \cup Y|}{| X|}$ and ''recall'' as $R = \cfrac{|X \cup Y|}{| Y |}$
* both $P$ and $R$ are defined w.r.t a set of retrieved documents 



=== Precision/Recall Curves ===
* If we retrieve more document, we improve recall (if return all docs, $R = 1$)
* if we retrieve fewer documents, we improve precision, but reduce recall
* so there's a trade-off between them


Let $k$ be the number of retrieved documents 
* then by varying $k$ from $0$ to $N = |C|$ we can draw $P$ vs $R$ and obtain the Precision/recall curve:
* https://habrastorage.org/files/26b/c1e/a38/26bc1ea381424262b9d966c63f418661.png source: [http://www.searchtechnologies.com/precision-recall]
* the closer the curve to the $(1, 1)$ point - the better the IR system performance
* https://habrastorage.org/files/010/ded/77e/010ded77e8d0454b99f0cafd3d962613.png source: [[Information Retrieval (UFRT)]] lecture 2


Area under P/R Curve:
* Analogously to [[ROC Analysis|ROC Curves]] we can calculate the area under the P/R Curve
* the closer AUPR to 1 the better 



=== Average Precision ===
Top-$k$-precision is insensitive to change of ranks of relevant documents among top $k$ 

how to measure overall performance of an IR system? 

$\text{avg P} = \cfrac{1}{K} \sum_{k = 1}^K \cfrac{k}{r_k}$ 
* where $r_i$ is the rank of $k$th relevant document in the result 

Since in a test collection we usually have a set of queries, we calcuate the average over them 
and get Mean Average Precision: MAP



== Precision and Recall for [[Classification]] ==
The precision and recall metrics can also be applied to [[Machine Learning]]: to binary classifiers


{| class=&quot;wikitable&quot; align=&quot;center&quot; style=&quot;text-align:center; border:none; background:transparent;&quot;
|+ Diagnostic Testing Measures  [http://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram]
| colspan=&quot;2&quot; rowspan=&quot;2&quot; style=&quot;border:none;&quot;|
! colspan=&quot;2&quot; | Actual Class $y$
|-
| Positive
| Negative
|-
! rowspan=&quot;2&quot; | $h_{\theta}(x)$ &lt;br/&gt; Test&lt;br /&gt;outcome
| Test&lt;br /&gt;outcome&lt;br /&gt;positive
|style=&quot;background:#ccffcc;&quot;| '''True positive'''&lt;br/&gt; ($\text{TP}$)
|style=&quot;background:#eedddd;&quot;| '''False positive'''&lt;br /&gt;($\text{FP}$, Type I error)
| Precision =&lt;br /&gt; $\cfrac{\# \text{TP}}{\# \text{TP} + \# \text{FP}}$
|-
| Test&lt;br /&gt;outcome&lt;br /&gt;negative
|style=&quot;background:#eedddd;&quot;| '''False negative'''&lt;br /&gt;($\text{FN}$, Type II error)
|style=&quot;background:#ccffcc;&quot;| '''True negative'''&lt;br /&gt; ($\text{TN}$)
| Negative predictive value =&lt;br /&gt; $\cfrac{\# \text{TN}}{\# \text{FN} + \# \text{TN}}$
|-
|colspan=&quot;2&quot; style=&quot;border:none;&quot; |
| Sensitivity =&lt;br /&gt; $\cfrac{\# \text{TP}}{\# \text{TP} + \# \text{FN}}$
| Specificity =&lt;br /&gt; $\cfrac{\# \text{TN}}{\# \text{FP} + \# \text{TN}}$
| Accuracy =&lt;br /&gt; $\cfrac{\# \text{TP} + \# \text{TN}}{\# \text{TOTAL}}$
|}


Main values of this matrix:
* '''True Positive''' - we predicted &quot;+&quot; and the true class is &quot;+&quot;
* '''True Negative''' - we predicted &quot;-&quot; and the true class is &quot;-&quot;
* '''False Positive''' - we predicted &quot;+&quot; and the true class is &quot;-&quot; (Type I error)
* '''False Negative''' - we predicted &quot;-&quot; and the true class is &quot;+&quot; (Type II error)


Two Classes: $C_+$ and $C_-$


=== Precision ===
Precision
* $\pi = P\big(f(\mathbf x) = C_+ \, \big| \, h_{\theta}(\mathbf x) =  C_+ \big)$
* given that we predict $\mathbf x$ is +
* what's the probability that the decision is correct
* we estimate precision as $P = \cfrac{\text{# TP}}{\text{# predicted positives}} = \cfrac{\text{# TP}}{\text{# TP} + \text{# FP}}$


Interpretation
* Out of all the people we thought have cancer, how many actually had it? 
* High precision is good
* we don't tell many people that they have cancer when they actually don't 



=== Recall ===
Recall
* $\rho = P\big(h_{\theta}(\mathbf x) = C_+ \, \big| \, f(\mathbf x) = C_+ \big)$
* given a positive instance $\mathbf x$ 
* what's the probability that we predict correctly
* we estimate recall as $R = \cfrac{\text{# TP}}{\text{# actual positives}} = \cfrac{\text{# TP}}{\text{# TP + # FN}}$


Interpretation
* Out of all the people that do actually have cancer, how much we identified? 
* The higher the better:
* We don't fail to spot many people that actually have cancer


* For a classifier that always returns zero (i.e. $h_{\theta}(x) = 0$) the Recall would be zero
* That gives us more useful evaluation metric
* And we're much more sure 


== F Measure ==
$P$ and $R$ don't make sense in the isolation from each other
* higher level of $\rho$ may be obtained by lowering $\pi$ and vice versa


Suppose we have a ranking classifier that produces some score for $\mathbf x$ 
* we decide whether to classify it as $C_+$ or $C_-$ based on some threshold parameter $\tau$
* by varying $\tau$ we will get different precision and recall 
* improving recall will lead to worse precision
* improving precision will lead to worse recall 
* how to pick the threshold? 
* combine $P$ and $R$ into one measure (also see [[ROC Analysis]])


$F_\beta = \cfrac{(\beta^2 + 1) P\, R}{\beta^2 \, P + R}$
* $\beta$ is the tradeoff between $P$ and $R$
* if $\beta$ is close to 0, then we give more importance to $P$
** $F_0 = P$
* if $\beta$ is closer to $+ \infty$, we give more importance to $R$


When $\beta = 1$ we have $F_1$ score:
* The $F_1$-score is a single measure of performance of the test. 
* it's the harmonic mean of precision $P$ and recall $R$ 
* $F_1 = 2 \cfrac{P \, R}{P + R}$


=== Motivation: [[Precision and Recall]] ===
Let's say we trained a [[Logistic Regression]] classifier 
* we predict 1 if $h_{\theta}(x) \geqslant 0.5$
* we predict 0 if $h_{\theta}(x) &lt; 0.5$

Suppose we want to predict y = 1 (i.e. people have cancer) only if we're very confident 
* we may change the threshold to 0.7
** we predict 1 if $h_{\theta}(x) \geqslant 0.7$
** we predict 0 if $h_{\theta}(x) &lt; 0.7$
* We'll have higher precision in this case (all for who we predicted y = 1 are more likely to actually have it)
* But lower recall (we'll miss more patients that actually have cancer, but we failed to spot them)

Let's consider the opposite 
* Suppose we want to avoid missing too many cases of y=1 (i.e. we want to avoid false negatives)
* So we may change the threshold to 0.3
** we predict 1 if $h_{\theta}(x) \geqslant 0.3$
** we predict 0 if $h_{\theta}(x) &lt; 0.3$
* That leads to 
* Higher recall (we'll correctly flag higher fraction of patients with cancer)
* Lower precision (and higher fraction will turn out to actually have no cancer)


Questions
* Is there a way to automatically choose the threshold for us? 
* How to compare precision and recall numbers and decide which algorithm is better?
* at the beginning we had a single number (error ratio) - but now have two and need to choose which one to prefer 
* $F_1$ score helps to decide since it's just one number


=== Example ===
Suppose we have 3 algorithms $A_1$, $A_2$, $A_3$, and we captured the following metrics: 


{| border=&quot;1&quot; class=&quot;wikitable&quot;
|
! $P$ !! $R$ !! $\text{Avg}$ !! $F_1$
|
|-
! $A_1$
| 0.5 || 0.4 || 0.45 || 0.444 || $\leftarrow$ our choice
|-
! $A_2$
| 0.7 || 0.1 || 0.4 || 0.175 ||
|-
! $A_3$
| 0.02 || 1.0 || 0.54 || 0.0392 ||
|}


Here's the best is $A_1$ because it has the highest $F_1$-score


== Precision and Recall for Clustering ==
Can use precision and recall to evaluate the result of clustering 

Correct decisions:
* '''TP''' = decision to assign two similar documents to the same cluster
* '''TN''' = assign two dissimilar documents to different clusters 

Errors:
* '''FP''': assign two dissimilar documents to the same cluster
* '''FN''': assign two similar documents to different clusters 


So the confusion matrix is:

{|  class=&quot;wikitable&quot;
|
! same  !! different 
|-
! same
| TP || FN
|-
! different
| FP || TN 
|-
|}


=== Example ===
Consider the following example (from the IR book [http://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-clustering-1.html])
* http://nlp.stanford.edu/IR-book/html/htmledition/img1393.png
* there are $\cfrac{n \, (n - 1)}{2} = 136$ pairs of documents
* $\text{TP} + \text{FP} = {6 \choose 2}  + {6 \choose 2}  + {5 \choose 2}  = 40$
* $\text{TP} = {5 \choose 2}  + {4 \choose 2}  + {3 \choose 2}  + {2 \choose 2}  = 20$
* etc

So have the following contingency table:

{|  class=&quot;wikitable&quot;
|
! same !! different 
|-
! same
| $\text{TP} = 20$ || $\text{FN} = 24$
|-
! different
| $\text{FP} = 20$ || $\text{TN} = 72$ 
|-
|}


Thus, 
* $P = 20/40 = 0.5$ and $R = 20/44 \approx 0.455$
* $F_1$ score is $F_1 \approx 0.48$


== Multi-Class Problems ==
How do we adapt precision and recall to multi-class problems?
* let $f(\cdot)$ be the target unknown function and $h_\theta(\cdot)$ the model
* let $C_1, \ ... , C_K$ be labels we want to predict ($K$ labels)


Precision w.r.t class $C_i$ is 
* $P\big(f(\mathbf x) = C_i \ \big| \ h_\theta(\mathbf x) = C_i \big)$
* probability that given that we classified $\mathbf x$ as $C_i$
* the decision is indeed correct


Recall w.r.t. class $C_i$ is 
* $P\big(h_\theta(\mathbf x) = C_i \ \big| \ f(\mathbf x) = C_i \big)$
* given an instance $\mathbf x$ belongs to $C_i$
* what's the probability that we predict correctly


We estimate these probabilities using a contingency table w.r.t each class $C_i$


Contingency Table for $C_i$:
* let $C_+$ be $C_i$ and 
* let $C_-$ be all other classes except for $C_i$, i.e. $C_- = \{ C_j \} - C_i$ (all classes except for $i$)
* then we create a contingency table 
* and calculate $\text{TP}_i, \text{FP}_i, \text{FN}_i, \text{TN}_i$ for them
* http://habrastorage.org/files/468/b51/be7/468b51be729a42ff8195b6fc05292508.png


Now estimate precision and recall for class $C_i$
* $P_i = \cfrac{\text{TP}_i}{\text{TP}_i + \text{FP}_i}$
* $R_i = \cfrac{\text{TP}_i}{\text{TP}_i + \text{FN}_i}$


=== Averaging ===
* These precision and recall are calculated for each class separately
* how to combine them? 


'''Micro-averaging''' 
* calculate TP, ... etc globally and then calculate Precision and Recall
* let 
** $\text{TP} = \sum_i \text{TP}_i$ 
** $\text{FP} = \sum_i \text{FP}_i$ 
** $\text{FN} = \sum_i \text{FN}_i$ 
** $\text{TN} = \sum_i \text{TN}_i$ 
* and then calculate precision and recall as
** $P^\mu = \cfrac{\text{TP}}{\text{TP} + \text{FP}}$
** $R^\mu = \cfrac{\text{TP}}{\text{TP} + \text{FN}}$



'''Macro-averaging'''
* similar to the [[One-vs-All Classification]] technique
* calculate $P_i$ and $R_i$ &quot;locally&quot; for each $C_i$
* and then let $P^M = \cfrac{1}{K} \sum_i P_i$ and $R^M = \cfrac{1}{K} \sum_i R_i$


Micro and macro averaging behave quite differently and may give different results 
* the ability to behave well on categories with low generality (fewer training examples) will be less emphasized by macroaveraging
* which one to use? depends on application


This way is often used in [[Document Classification]]

== Sources ==
* [[Machine Learning (coursera)]]
* Sebastiani, Fabrizio. &quot;Machine learning in automated text categorization.&quot; (2002). [http://arxiv.org/pdf/cs/0110053.pdf]
* Zhai, ChengXiang. &quot;Statistical language models for information retrieval.&quot; 2008.
* [[Information Retrieval (UFRT)]]
* Manning, Christopher D., Prabhakar Raghavan, and Hinrich Schütze. &quot;Introduction to information retrieval.&quot; 2008. [http://informationretrieval.org/]


[[Category:Machine Learning]]
[[Category:Classifiers]]
[[Category:Information Retrieval]]
[[Category:Model Performance Evaluation]]</text>
      <sha1>rdmorn1od1crkrebbbsn8ojgma0bk8l</sha1>
    </revision>
  </page>
  <page>
    <title>F Measure</title>
    <ns>0</ns>
    <id>584</id>
    <redirect title="Precision and Recall" />
    <revision>
      <id>587</id>
      <timestamp>2015-04-28T20:45:37Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="44">#REDIRECT [[Precision and Recall#F Measure]]</text>
      <sha1>mkdovo1rg4b7qaos9zn9g07yf6zxvid</sha1>
    </revision>
  </page>
  <page>
    <title>PCA</title>
    <ns>0</ns>
    <id>585</id>
    <redirect title="Principal Component Analysis" />
    <revision>
      <id>588</id>
      <timestamp>2015-05-01T19:40:27Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="42">#REDIRECT [[Principal Component Analysis]]</text>
      <sha1>b7hp3ed8rz6235h2l4zxfgaz8ggf2vr</sha1>
    </revision>
  </page>
  <page>
    <title>Document Clustering</title>
    <ns>0</ns>
    <id>586</id>
    <revision>
      <id>589</id>
      <timestamp>2015-05-01T19:43:32Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8418">== Document Clustering ==
The goal of text clustering is
* to assign documents to different topics or topic hierarchies
* i.e. when the topics/hierarchies are not known in advance
* as opposed to [[Document Classification]] when labels are known
* It's a [[Cluster Analysis]] task: [[Unsupervised Learning]] applied to textual data


Objects to be clustered are 
* documents, paragraphs, sentences
* or terms ([[Term Clustering]])


Applications:
* [[Cluster Analysis]] is also useful in [[Text Mining]] 
* E.g. organizing documents for better [[Information Retrieval]]
* Organizing documents intro hierarhical clusters  Cutting1992
* see Anick1997, Cutting1993 ([[Scatter/Gather]])
* Corpus Summarization 
* Improving [[Document Classification]] - see Baker1998 and Bekkerman2001



== Preprocessing ==
Usual [[Natural Language Processing|NLP]]/[[Information Retrieval|IR]]


=== Document Representation ===
The most commonly used document representation is [[Vector Space Model]]:
* extract a list of unique terms and weight them
* weighted with TF or [[TF-IDF]]

Alternative representation:
* terms as a [[Probability Distribution]]: [[Language Models]]
* then we can measure (dis)similarity with a symmetric variation of [[KL Divergence]] 


=== [[Feature Selection]] ===
Concept of distance and similarity may be not meaningful in high-dimensional space 
* so may need to reduce dimensionality

In text mining usually referred as &quot;Term Selection&quot;:
* [[Stop Words|Remove stop words]]
* use document frequency to cut away infrequent and very frequent words. such words usually don't contribute much (or anything) to similarity computation
* [[Subset Selection]] and [[Feature Filtering]] won't work because we don't have labels 


=== [[Dimensionality Reduction]] ===
* [[Term Clustering]]: find clusters of terms and replace the terms by their centroids
* [[PCA]] gives the basis for [[Latent Semantic Analysis]]
* [[Non-Negative Matrix Factorization]]



== Clustering ==
* [[Hierarchical Clustering]]: good for Document clustering because it creates a tree structure
* Partitioning Clustering Algorithms
** [[K-Means]]
** [[Scatter/Gather]]
* Parametric Modeling Methods like [[Expectation Maximization]]




=== Distances and Similarity ===
Popular choice: 
* [[Euclidean Distance]] is not very good for high-dimensional data
* [[Jaccard Coefficient]] or [[Cosine Similarity]] are better


If not [[Vector Space Models]]:
* [[Language Models]]: symmetric variant [[KL Divergence]]
* Keep documents as strings: [[Edit Distance]] (but it'll most likely be extremely slow)


Papers:
* Strehl2000: Survey on distances for documents
* Sahami2006: When text segments are too short (e.g. tweets or sentences)


Direct similarity measures are not always reliable for high-dimensional clustering (see Guha1999)
* high dimensional data is sparse and therefore on average similarity is low 
* also see [[Curse of Dimensionality]]
* SNN Distance solves it: Shared Nearest Neighbors Distance, # of [[KNN]]s two documents share (as used in [[SNN Clustering]])


== Algorithms ==
=== [[K-Means]] ===
* centroids = weighed average of all docs in the cluster 
* to compare a document with a cluster, calculate cosine between document and cluster

A variation of K-Means: 
* Bisecting K-Means: gives good performance for document clusters
* [[K-Medoids]] for non-Euclidean distances, using medoid ($\approx$ median) instead of mean for selecting a centroid
* [[Scatter/Gather]]: 
** smart seed selection
** centroid = concatenation of all docs in the cluster
** Split and Join refinement operations


=== [[Two-Phase Document Clustering]] ===
Main idea:
* use [[Mutual Information]] to find best term clustering
* and then use mutual information to find best document clustering


=== [[Co-Clustering]] ===
Clustering terms and documents at the same time 
* clustering of terms and clustering of documents are dual problems
* take advantage of that
* also can use [[Non-Negative Matrix Factorization]] $A \approx UV^T$ where $U$ are clusters of docs and $V$ are clusters of terms 


=== [[Latent Semantic Analysis]] ===
Using [[PCA]] define new features from terms 
* it creates a new semantic space where problems like symomymy or polysemy are solved 
* term-document matrix is decomposed using [[SVD]]


Not only SVD is good:
* can also use [[Non-Negative Matrix Factorization]] techniques 
* this way it's easy to interpret and [[Fuzzy Clustering|clusters can be fuzzy]]


=== [[Topic Models]] ===
* define some probabilistic generative models for text documents
* in some way it's similar to LSA, but it's probabilistic
* see [[Probabilistic LSA]] or [[Latent Dirichlet Allocation]]


=== [[Semi-Supervised Clustering]] ===
Use prior knowledge to help clustering 
* e.g. if you know some of the labels, do better seed selection for [[K-Means]]



== Performance ==
Issues
* Text data usually has very high dimensionality
* especially important for large corpus - it will be very slow, especially for hierarchical algorithms


=== [[Inverted Index]] ===
Idea:
* usually a document contains only a small portion of terms 
* so document vectors are very sparse
* typical distance is cosine similarity - it ignores zeros. for cosine to be non-zero, two docs need to share at least one term
* $D^T$ is the inverted index of the term-document matrix $D$


this, to find docs similar to $d$:
* for each $w_i \in d$
* let $D_i = \{ d_i \} - d = \text{index}[w_i]$ be a set of documents that also contain $w_i$
* then take the union of all $D_i$ 
* calculate similarity only with documents from this union


=== Term Selection ===
Idea:
* Only top high-weighted terms contribute substantially to the norm 
* so keep only those weights that contribute 90% of the norm
* and set the rest to 0


It can reduce the number of documents to consider but without losing much information


== References ==
* Anick, Peter G., and Shivakumar Vaithyanathan. &quot;Exploiting clustering and phrases for context-based information retrieval.&quot;  1997. 
* Cutting, Douglass R., et al. &quot;Scatter/gather: A cluster-based approach to browsing large document collections.&quot; 1992. [http://courses.washington.edu/info320/au11/readings/Week4.Cutting.et.al.1992.Scatter-Gather.pdf]
* Cutting, Douglass R., David R. Karger, and Jan O. Pedersen. &quot;Constant interaction-time scatter/gather browsing of very large document collections.&quot; 1993.
* Baker, L. Douglas, and Andrew Kachites McCallum. &quot;Distributional clustering of words for text classification.&quot; 1998. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.7488&amp;rep=rep1&amp;type=pdf]
* Bekkerman, Ron, et al. &quot;On feature distributional clustering for text categorization.&quot; 2001. [http://scholar.google.com/scholar?cluster=1445350076343942781&amp;hl=ru&amp;as_sdt=0,5] 
* Sahami, Mehran, and Timothy D. Heilman. &quot;A web-based kernel function for measuring the similarity of short text snippets.&quot; 2006. [http://research.google.com/intl/en/pubs/archive/32.pdf]
* Strehl, Alexander, Joydeep Ghosh, and Raymond Mooney. &quot;Impact of similarity measures on web-page clustering.&quot; 2000. [http://strehl.com/download/strehl-aaai00.pdf]
* Guha, Sudipto, Rajeev Rastogi, and Kyuseok Shim. &quot;ROCK: A robust clustering algorithm for categorical attributes.&quot; 1999. [http://www.cacs.louisiana.edu/~jyoon/grad/adb/References/clustering/ROCK-clus99icde.pdf]

== Sources ==
* Steinbach, Michael, George Karypis, and Vipin Kumar. &quot;A comparison of document clustering techniques.&quot; 2000. ([https://wwws.cs.umn.edu/tech_reports_upload/tr2000/00-034.ps])
* Larsen, Bjornar, and Chinatsu Aone. &quot;Fast and effective text mining using linear-time document clustering.&quot; 1999. ([http://comminfo.rutgers.edu/~muresan/IR/Docs/Articles/sigkddLarsen1999.pdf])
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. Springer US, 2012. [http://ir.nmu.org.ua/bitstream/handle/123456789/144935/d1784ebed3eab2708026b202b2b65309.pdf?sequence=1#page=90]
* Jing, Liping. &quot;Survey of text clustering.&quot; (2008). [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.3476&amp;rep=rep1&amp;type=pdf]
* Ertöz, Levent, Michael Steinbach, and Vipin Kumar. &quot;Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data.&quot; 2003. [http://static.msi.umn.edu/rreports/2003/73.pdf]

[[Category:Document Clustering]]
[[Category:Unsupervised Learning]]
[[Category:Cluster Analysis]]
[[Category:Thesis]]</text>
      <sha1>d9d9hgqtipiai05uky96mmy4vyyizqy</sha1>
    </revision>
    <revision>
      <id>764</id>
      <parentid>589</parentid>
      <timestamp>2017-04-26T20:59:06Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8624">== Document Clustering ==
The goal of text clustering is
* to assign documents to different topics or topic hierarchies
* i.e. when the topics/hierarchies are not known in advance
* as opposed to [[Document Classification]] when labels are known
* It's a [[Cluster Analysis]] task: [[Unsupervised Learning]] applied to textual data


Objects to be clustered are 
* documents, paragraphs, sentences
* or terms ([[Term Clustering]])


Applications:
* [[Cluster Analysis]] is also useful in [[Text Mining]] 
* E.g. organizing documents for better [[Information Retrieval]]
* Organizing documents intro hierarhical clusters  Cutting1992
* see Anick1997, Cutting1993 ([[Scatter/Gather]])
* Corpus Summarization 
* Improving [[Document Classification]] - see Baker1998 and Bekkerman2001



== Preprocessing ==
Usual [[Natural Language Processing|NLP]]/[[Information Retrieval|IR]]


=== Document Representation ===
The most commonly used document representation is [[Vector Space Model]]:
* extract a list of unique terms and weight them
* weighted with TF or [[TF-IDF]]

Alternative representation:
* terms as a [[Probability Distribution]]: [[Language Models]]
* then we can measure (dis)similarity with a symmetric variation of [[KL Divergence]] 


=== [[Feature Selection]] ===
Concept of distance and similarity may be not meaningful in high-dimensional space 
* so may need to reduce dimensionality

In text mining usually referred as &quot;Term Selection&quot;:
* [[Stop Words|Remove stop words]]
* use document frequency to cut away infrequent and very frequent words. such words usually don't contribute much (or anything) to similarity computation
* [[Subset Selection]] and [[Feature Filtering]] won't work because we don't have labels 


=== [[Dimensionality Reduction]] ===
* [[Term Clustering]]: find clusters of terms and replace the terms by their centroids
* [[PCA]] gives the basis for [[Latent Semantic Analysis]]
* [[Non-Negative Matrix Factorization]]



== Clustering ==
* [[Hierarchical Clustering]]: good for Document clustering because it creates a tree structure
* Partitioning Clustering Algorithms
** [[K-Means]]
** [[Scatter/Gather]]
* Parametric Modeling Methods like [[Expectation Maximization]]




=== Distances and Similarity ===
Popular choice: 
* [[Euclidean Distance]] is not very good for high-dimensional data
* [[Jaccard Coefficient]] or [[Cosine Similarity]] are better


If not [[Vector Space Models]]:
* [[Language Models]]: symmetric variant [[KL Divergence]]
* Keep documents as strings: [[Edit Distance]] (but it'll most likely be extremely slow)


Papers:
* Strehl2000: Survey on distances for documents
* Sahami2006: When text segments are too short (e.g. tweets or sentences)


Direct similarity measures are not always reliable for high-dimensional clustering (see Guha1999)
* high dimensional data is sparse and therefore on average similarity is low 
* also see [[Curse of Dimensionality]]
* SNN Distance solves it: Shared Nearest Neighbors Distance, # of [[KNN]]s two documents share (as used in [[SNN Clustering]])


== Algorithms ==
=== [[K-Means]] ===
* centroids = weighed average of all docs in the cluster 
* to compare a document with a cluster, calculate cosine between document and cluster

A variation of K-Means: 
* Bisecting K-Means: gives good performance for document clusters
* [[K-Medoids]] for non-Euclidean distances, using medoid ($\approx$ median) instead of mean for selecting a centroid
* [[Scatter/Gather]]: 
** smart seed selection
** centroid = concatenation of all docs in the cluster
** Split and Join refinement operations


=== [[Two-Phase Document Clustering]] ===
Main idea:
* use [[Mutual Information]] to find best term clustering
* and then use mutual information to find best document clustering


=== [[Co-Clustering]] ===
Clustering terms and documents at the same time 
* clustering of terms and clustering of documents are dual problems
* take advantage of that
* also can use [[Non-Negative Matrix Factorization]] $A \approx UV^T$ where $U$ are clusters of docs and $V$ are clusters of terms 


=== [[Latent Semantic Analysis]] ===
Using [[PCA]] define new features from terms 
* it creates a new semantic space where problems like symomymy or polysemy are solved 
* term-document matrix is decomposed using [[SVD]]


Not only SVD is good:
* can also use [[Non-Negative Matrix Factorization]] techniques 
* this way it's easy to interpret and [[Fuzzy Clustering|clusters can be fuzzy]]


=== [[Topic Models]] ===
* define some probabilistic generative models for text documents
* in some way it's similar to LSA, but it's probabilistic
* see [[Probabilistic LSA]] or [[Latent Dirichlet Allocation]]


=== [[Semi-Supervised Clustering]] ===
Use prior knowledge to help clustering 
* e.g. if you know some of the labels, do better seed selection for [[K-Means]]



== Performance ==
Issues
* Text data usually has very high dimensionality
* especially important for large corpus - it will be very slow, especially for hierarchical algorithms


=== [[Inverted Index]] ===
Idea:
* usually a document contains only a small portion of terms 
* so document vectors are very sparse
* typical distance is cosine similarity - it ignores zeros. for cosine to be non-zero, two docs need to share at least one term
* $D^T$ is the inverted index of the term-document matrix $D$


this, to find docs similar to $d$:
* for each $w_i \in d$
* let $D_i = \{ d_i \} - d = \text{index}[w_i]$ be a set of documents that also contain $w_i$
* then take the union of all $D_i$ 
* calculate similarity only with documents from this union




=== Term Selection ===
Idea:
* Only top high-weighted terms contribute substantially to the norm 
* so keep only those weights that contribute 90% of the norm
* and set the rest to 0


It can reduce the number of documents to consider but without losing much information



=== [[Locality Sensitive Hashing]] ===
The approach with inverted index is also called &quot;self-join&quot;, and this doesn't scale well for large databases 
* LSH allows to circumvent the self-join bottleneck


== References ==
* Anick, Peter G., and Shivakumar Vaithyanathan. &quot;Exploiting clustering and phrases for context-based information retrieval.&quot;  1997. 
* Cutting, Douglass R., et al. &quot;Scatter/gather: A cluster-based approach to browsing large document collections.&quot; 1992. [http://courses.washington.edu/info320/au11/readings/Week4.Cutting.et.al.1992.Scatter-Gather.pdf]
* Cutting, Douglass R., David R. Karger, and Jan O. Pedersen. &quot;Constant interaction-time scatter/gather browsing of very large document collections.&quot; 1993.
* Baker, L. Douglas, and Andrew Kachites McCallum. &quot;Distributional clustering of words for text classification.&quot; 1998. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.7488&amp;rep=rep1&amp;type=pdf]
* Bekkerman, Ron, et al. &quot;On feature distributional clustering for text categorization.&quot; 2001. [http://scholar.google.com/scholar?cluster=1445350076343942781&amp;hl=ru&amp;as_sdt=0,5] 
* Sahami, Mehran, and Timothy D. Heilman. &quot;A web-based kernel function for measuring the similarity of short text snippets.&quot; 2006. [http://research.google.com/intl/en/pubs/archive/32.pdf]
* Strehl, Alexander, Joydeep Ghosh, and Raymond Mooney. &quot;Impact of similarity measures on web-page clustering.&quot; 2000. [http://strehl.com/download/strehl-aaai00.pdf]
* Guha, Sudipto, Rajeev Rastogi, and Kyuseok Shim. &quot;ROCK: A robust clustering algorithm for categorical attributes.&quot; 1999. [http://www.cacs.louisiana.edu/~jyoon/grad/adb/References/clustering/ROCK-clus99icde.pdf]

== Sources ==
* Steinbach, Michael, George Karypis, and Vipin Kumar. &quot;A comparison of document clustering techniques.&quot; 2000. ([https://wwws.cs.umn.edu/tech_reports_upload/tr2000/00-034.ps])
* Larsen, Bjornar, and Chinatsu Aone. &quot;Fast and effective text mining using linear-time document clustering.&quot; 1999. ([http://comminfo.rutgers.edu/~muresan/IR/Docs/Articles/sigkddLarsen1999.pdf])
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. Springer US, 2012. [http://ir.nmu.org.ua/bitstream/handle/123456789/144935/d1784ebed3eab2708026b202b2b65309.pdf?sequence=1#page=90]
* Jing, Liping. &quot;Survey of text clustering.&quot; (2008). [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.3476&amp;rep=rep1&amp;type=pdf]
* Ertöz, Levent, Michael Steinbach, and Vipin Kumar. &quot;Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data.&quot; 2003. [http://static.msi.umn.edu/rreports/2003/73.pdf]

[[Category:Document Clustering]]
[[Category:Unsupervised Learning]]
[[Category:Cluster Analysis]]
[[Category:Thesis]]</text>
      <sha1>7nydf5umi82e5uv4ru7v8nksj72r745</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Document Clustering</title>
    <ns>14</ns>
    <id>587</id>
    <revision>
      <id>590</id>
      <timestamp>2015-05-01T19:44:07Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="64">[[Category:Cluster Analysis]]
[[Category:Unsupervised Learning]]</text>
      <sha1>8i7f1zfnpwenfjips1ands8n9pq2yyw</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Cluster Analysis</title>
    <ns>14</ns>
    <id>588</id>
    <revision>
      <id>591</id>
      <timestamp>2015-05-01T19:44:20Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="64">[[Category:Unsupervised Learning]]
[[Category:Machine Learning]]</text>
      <sha1>3l0jnx98auyl6bges0lt58ez9f2vw0u</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Unsupervised Learning</title>
    <ns>14</ns>
    <id>589</id>
    <revision>
      <id>592</id>
      <timestamp>2015-05-01T19:44:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="29">[[Category:Machine Learning]]</text>
      <sha1>n8w88wwx02oq4b7xpy1nt4zqyteghjs</sha1>
    </revision>
  </page>
  <page>
    <title>Term Clustering</title>
    <ns>0</ns>
    <id>590</id>
    <revision>
      <id>593</id>
      <timestamp>2015-05-01T19:47:14Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2066">== Term Clustering ==
Term clustering is a dual problem of [[Document Clustering]]
* it's also unsupervised [[Text Mining]] technique, but applied to terms instead of documents
* term clustering may be good technique for [[Dimensionality Reduction]]



Duality:
* when we use [[Vector Space Models]], e.g. Bag of Words, then we have a term-document matrix $D$
* rows of $D$ are documents, columns of $D$ are terms
* can cluster columns instead of rows!
* clustering rows and clustering columns are very related problems 


Term Clustering groups words with a high degree of semantic relatedness 
* so we can use clusters (centroids of terms) to represent terms 


Li Jain 1998 
* view semantic relatedness between words in terms of their co-occurrence and co-absence in the corpus


== Clustering of Terms ==
How to do this?
* try applying usual row clustering techniques on $D^T$


=== Frequent Termset === 
Apply [[Local Pattern Discovery]] and [[Frequent Patterns Mining]] techniques for terms:
* can see a document as a transaction and words like items 
* we want to find frequent itemsets of words in these documents 
* it's called [[Frequent Word Patterns]]


=== [[Two-Phase Document Clustering]] ===
Main idea:
* use [[Mutual Information]] to find best term clustering
* and then use mutual information to find best document clustering



== Simultaneous Term/Document Clustering ==
Simultaneous clustering of rows and columns is called [[Co-Clustering]]
* simplest way is to use [[Non-Negative Matrix Factorization]]


== References ==
* Slonim, Noam, and Naftali Tishby. &quot;Document clustering using word clusters via the information bottleneck method.&quot; 2000. [http://lsa3.colorado.edu/LexicalSemantics/slonim00document.pdf]


== Sources ==
* Li, Yong H., and Anil K. Jain. &quot;Classification of text documents.&quot; (1998) [http://julio.staff.ipb.ac.id/files/2014/09/LiJ98.pdf]
* Sebastiani, Fabrizio. &quot;Machine learning in automated text categorization.&quot; (2002). [http://arxiv.org/pdf/cs/0110053.pdf]

[[Category:Cluster Analysis]]
[[Category:Document Clustering]]</text>
      <sha1>7dgvd6ujf7v2d9vd5ahi5632iuf3pr2</sha1>
    </revision>
  </page>
  <page>
    <title>Frequent Word Patterns</title>
    <ns>0</ns>
    <id>591</id>
    <revision>
      <id>594</id>
      <timestamp>2015-05-01T19:47:52Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1690">{{stub}}

== Frequent Word Patterns ==
Frequent word patters is a technique of [[Local Pattern Discovery]] applied to documents
* we can see a document as a transaction and words like items 
* then want to find frequent itemsets of words in these documents - like in [[Frequent Patterns Mining]] with [[Apriori]] or [[Eclat]]
* frequent itemset $\equiv$ frequent wordset



== [[Document Clustering]] ==
We can use [[Frequent Pattern Mining|FPM]] for [[Term Clustering]]
* cluster = all documents that contain a certain frequent term set 
* so frequent term sets describe clusters 
* note that here clustering is not strict (it's [[Fuzzy Clustering]]): it allows some overlap between clusters
* which is sometimes natural in text documents


Problem formalization
* let $R$ be set of chosen frequent term sets (FTS)
* $f_i$ be the # of FTSs from $R$ contained in document $d_i$
* we put a constraint on $f_i$: it must be at least one to ensure complete coverage (there should be no documents without category)
* we want: minimize the average value of $f_i - 1$


Algorithm:
* at each iteration
* pick FTS with minimal overlap with other clusters
* see more in the reference




== References ==
* Beil, Florian, Martin Ester, and Xiaowei Xu. &quot;Frequent term-based text clustering.&quot; 2002. [http://www.cs.sfu.ca/~ester/papers/KDD02.Clustering.final.pdf]

== Sources ==
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. Springer US, 2012. [http://ir.nmu.org.ua/bitstream/handle/123456789/144935/d1784ebed3eab2708026b202b2b65309.pdf?sequence=1#page=90]


[[Category:Rule Mining]]
[[Category:Cluster Analysis]]
[[Category:Document Clustering]]</text>
      <sha1>jvtg6u4v3f8aayi58b4uygqo9e9crbe</sha1>
    </revision>
  </page>
  <page>
    <title>Two-Phase Document Clustering</title>
    <ns>0</ns>
    <id>592</id>
    <revision>
      <id>595</id>
      <timestamp>2015-05-01T19:48:50Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2261">== Two-Phase Document Clustering ==
How can we use [[Term Clustering]] for [[Document Clustering]]?


Two Phases
* term clustering
* document clustering


=== Notation ===
* let $D$ be term-document matrix: rows are documents and columns are terms 
* $X = \{ \mathbf x_1 , \ ... \ , \mathbf x_n \}$ - random vectors: rows of $D$
* $Y = \{ \mathbf y_1 , \ ... \ , \mathbf y_d \}$ - random vectors: columnts of $D$


We want to partition:
* $Y$ into $l$ clusters $\hat Y = \{ \hat Y_1 , \ ... \ , \hat Y_l \}$
* $X$ into $k$ clusters $\hat X = \{ \hat X_1 , \ ... \ , \hat X_k \}$


=== Problem Statement ===
Formally, we want to find mappings:
* $C_Y : Y \to \hat Y$ or  $\mathbf y_1 , \ ... \ , \mathbf y_d \to \hat Y_1, \ ... \ , \hat Y_l $
* $C_X : X \to \hat X$, or $\mathbf x_1 , \ ... \ , \mathbf x_n \to \hat X_1, \ ... \ , \hat X_k $



=== Phase One: Term Clustering ===
Find word clustering s.t. 
* most of [[Mutual Information]] between words and documents is preserved 
* when we go from representing docs in terms of words to representing docs in terms of word clusters


Cluster:
* find clustering of $Y$ into $\hat Y$ s.t. information from $I(X; Y)$ is preserved in $I(X; \hat Y)$ as good as possible


How?
* $P(X, Y)$ always has more information than $P(X, \hat Y)$, so $I(X; \hat Y) \leqslant I(X; Y)$
* thus find such mapping $C_Y$ that minimizes $I(X; Y) - I(X; \hat Y)$
* this loss function is called &quot;Mutual information loss&quot;



=== Phase Two: Document Clustering ===
Using term clusters:
* perform document clustering 
* cluster $X$ into $\hat X$ s.t. we preserve as much of $I(X; \hat Y)$ as possible in $I(\hat X ; \hat Y)$


Same here:
* minimize  $I(X; \hat Y) - I(\hat X; \hat Y)$


For details, see Slonim2000



== References ==
* Slonim, Noam, and Naftali Tishby. &quot;Document clustering using word clusters via the information bottleneck method.&quot; 2000. [http://lsa3.colorado.edu/LexicalSemantics/slonim00document.pdf]

== Sources ==
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. Springer US, 2012. [http://ir.nmu.org.ua/bitstream/handle/123456789/144935/d1784ebed3eab2708026b202b2b65309.pdf?sequence=1#page=90]

[[Category:Information Theory]]
[[Category:Document Clustering]]</text>
      <sha1>dld98vu738jv7syeei80g20663ffq4b</sha1>
    </revision>
  </page>
  <page>
    <title>Co-Clustering</title>
    <ns>0</ns>
    <id>593</id>
    <revision>
      <id>596</id>
      <timestamp>2015-05-31T16:08:02Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2128">{{stub}}

== Co-Clustering ==
Co-clustering is a set of techniques in [[Cluster Analysis]]
* given some matrix $A$ we want to cluster rows of $A$ and columns of $A$ simultaneously 
* this is a common task for ''dyadic'' data matrices such as [[Vector Space Models|term-document matrices]] or [[Collaborative Filtering|user-item matrices]]


Co-clustering is also called bi-clustering 
* let $A$ be  $m \times n$ matrix, 
* goal is to generate biclusters/co-clusters: a subset of rows which exhibit similar behavior across a subset of columns, or vice versa.



Co-clustering is defined as two map functions:
* rows -&gt; row cluster indexes
* columns -&gt; column cluster indexes 
* these map functions are learned simultaneously
* Unlike [[Two-Phase Document Clustering]] where we first cluster columns and then we use this to cluster rows


=== [[Subspace Clustering]] ===
Can use subspace clustering for co-clustering
* subspace clustering $\approx$ local feature selection



== [[Non-Negative Matrix Factorization]] ==
One way of doing Co-Clustering is via NMF:
* let $A = UV^T$ where $U$ is $m \times k$ and $V$ is $n \times k$
* then rows of $U$ may correspond to clusters of rows, and rows of $V$ to clusters of columns



== References ==
* Dhillon, Inderjit S. &quot;Co-clustering documents and words using bipartite spectral graph partitioning.&quot; 2001. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.9634&amp;rep=rep1&amp;type=pdf]
* Dhillon, Inderjit S., Subramanyam Mallela, and Dharmendra S. Modha. &quot;Information-theoretic co-clustering.&quot; 2003. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.6173&amp;rep=rep1&amp;type=pdf]
* Li, Tao, Sheng Ma, and Mitsunori Ogihara. &quot;Document clustering via adaptive subspace iteration.&quot;  2004. [http://users.cs.fiu.edu/~taoli/pub/sigir04-p218-li.pdf]

== Sources ==
* http://en.wikipedia.org/wiki/Biclustering
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. Springer US, 2012. [http://ir.nmu.org.ua/bitstream/handle/123456789/144935/d1784ebed3eab2708026b202b2b65309.pdf?sequence=1#page=90]


[[Category:Document Clustering]]</text>
      <sha1>1i40jot1pv2e9d2gbv8n0wviq2yr4y9</sha1>
    </revision>
  </page>
  <page>
    <title>Subspace Clustering</title>
    <ns>0</ns>
    <id>594</id>
    <revision>
      <id>597</id>
      <timestamp>2015-05-01T19:50:58Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3970">{{stub}}

== Subspace Clustering ==
Textual data (esp in [[Vector Space Models]]) suffers from the [[Curse of Dimensionality]]
* so need to use [[Dimensionality Reduction]]


But often we can use the following idea:
* correlation in high-dimensional data is usually local (esp. in [[Text Mining|text data]])
* for some data items features are correlated, but for some the same features are not


Subspace clustering:
* it's the task of detecting all clusters  in all subspaces 
* a data point may belong to many different clusters - with each cluster in some subspace 



Survey paper:
* Parsons, Lance, Ehtesham Haque, and Huan Liu. &quot;Subspace clustering for high dimensional data: a review.&quot; (2004). [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.85.8962&amp;rep=rep1&amp;type=pdf]
* Domeniconi, Carlotta, et al. &quot;Subspace Clustering of High Dimensional Data.&quot; SDM. Vol. 73. 2004. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.8676&amp;rep=rep1&amp;type=pdf]


There are two types of subspace clustering
* based on how they determine a measure of locality for evaluating subspaces
* bottom-up subspace search 
* top-down search


=== Bottom-up Subspace Search ===
Use downward closure property for density to reduce the search space ([[Apriori]]-style)


CLIQUE:
* Agrawal, Rakesh, et al. Automatic subspace clustering of high dimensional data for data mining applications.1998. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.407.4066&amp;rep=rep1&amp;type=pdf]

ENCLUS
* Cheng, Chun-Hung, Ada Waichee Fu, and Yi Zhang. &quot;Entropy-based subspace clustering for mining numerical data.&quot; 1999. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.1465&amp;rep=rep1&amp;type=pdf]

MAFIA 
* Goil, Sanjay, Harsha Nagesh, and Alok Choudhary. &quot;MAFIA: Efficient and scalable subspace clustering for very large data sets.&quot; 1999. [http://www.cs.upc.edu/~bejar/amlt/material_art/DM%20clustering%20goil99mafia.pdf]

CBF
* Chang, Jae-Woo, and Du-Seok Jin. &quot;A new cell-based clustering method for large, high-dimensional data in data mining applications.&quot;, 2002. [http://www.researchgate.net/profile/Jae-Woo_Chang2/publication/221001126_A_new_cell-based_clustering_method_for_large_high-dimensional_data_in_data_mining_applications/links/02e7e519c25a68e567000000.pdf]

CLTree
* clustering via decision trees 

DOC
* Procopiuc, Cecilia M., et al. &quot;A Monte Carlo algorithm for fast projective clustering.&quot; 2002. [http://www.cs.duke.edu/~pankaj/publications/papers/proj-cluster-sample.pdf]


=== Iterative Top-Down Subspace Search ===
PROCLUS 
* Aggarwal, Charu C., et al. &quot;Fast algorithms for projected clustering.&quot; 1999. [http://dbs.informatik.uni-halle.de/Lehre/Aktiv_2000/Paper/aggarwal_sigmod99.pdf]

ORCLUS
* Aggarwal, Charu C., and Philip S. Yu. Finding generalized projected clusters in high dimensional spaces. 2000. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.23.5160&amp;rep=rep1&amp;type=pdf]

FINDIT 
* Woo, Kyoung-Gu, et al. &quot;FINDIT: a fast and intelligent subspace clustering algorithm using dimension voting.&quot; (2004). [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.5164&amp;rep=rep1&amp;type=pdf]

$\beta$-Clusters 
* Yang, Jiong, et al. &quot;δ-clusters: Capturing subspace correlation in a large data set.&quot; 2002. [http://ftp.it.murdoch.edu.au/units/ICT219/Papers%20for%20transfer/papers%20on%20Clustering/delta%20clusers.pdf]

COSA
* Friedman, Jerome H., and Jacqueline J. Meulman. &quot;Clustering objects on subsets of attributes (with discussion).&quot; (2004). [http://www.datatheory.nl/pages/Friedman%26Meulman.pdf]



== Document Subspace Clustering  ==
Text data is very high-dimensional 
* creates problems for [[Document Clustering]]


Adaptive subspace iteration:
* reduce data
* identify subspaces


== Sources ==
* Jing, Liping. &quot;Survey of text clustering.&quot; (2008). [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.3476&amp;rep=rep1&amp;type=pdf]
* http://en.wikipedia.org/wiki/Clustering_high-dimensional_data

[[Category:Cluster Analysis]]</text>
      <sha1>2mt57s206mvcysx024j1i4up1k52d6p</sha1>
    </revision>
  </page>
  <page>
    <title>Non-Negative Matrix Factorization</title>
    <ns>0</ns>
    <id>595</id>
    <revision>
      <id>598</id>
      <timestamp>2015-07-05T09:36:36Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9141">== Non-Negative Matrix Factorization ==
Non-Negative Matrix Factorization (NMF) is a [[Matrix Decomposition]] technique that is especially good for [[Cluster Analysis]]



== Algorithms for Computing NMF ==
See Lee2001
* Norm Minimization (NMF-ED)
* [[KL Divergence]] Minimization (NMF-KL)


=== Norm Minimization Algorithm ===
Let $A$ be an $m \times n$ matrix 
* we want to find $k$-rank approximation of $A$ (or, in other words, create $k$ clusters)


to do this, we want to find matrices $U$ and $V$ s.t. 
* $J = \cfrac{1}{2} \| A - U V^T \|_F$ where the norm is the [[Frobenius Norm]]
* $U$ is $m \times k$ matrix
* $V$ is $n \times k$ matrix 
* columns of $V$ are the basis 

* as we minimize $J$ we get $UV^T \approx A$
* if $\mathbf a$ is a row of $A$, then $\mathbf a \approx \mathbf u V^T$ where $u$ is a corresponding row of $U$
* so $\mathbf a$ is rewritten using the basis from the columns of $V$ 


This can be solved analytically
* for any matrix $Q$, $\| Q \|_F = \text{tr}(QQ^T)$, where $\text{tr}(QQ^T)$ is the [[Trace (Matrix)|Trace]] of $QQ^T$ (see properties of [[Frobenius Norm]])
* so $J = 0.5 \text{tr}\Big( (A - UV^T)^T \, (A - UV^T) \Big) = \text{tr}\Big( AA^T - 2 A U V^T + U V^T V U^T \Big) = \frac{1}{2} \, \text{tr} (AA^T) - \text{tr}(A U V^T) + 0.5 \text{tr}(U V^T V U^T)$
* additionally, we have constraints $u_{ij} \geqslant 0$, $v_{ij} \geqslant 0$: use [[Lagrange Multipliers]] for this
* let $\boldsymbol \alpha$ be a matrix of $\alpha_{ij}$ of the same dimension as $U$ and $\boldsymbol \beta$ be a batrix of $\beta_{ij}$ of the same dimension as $V$ 
* note that $\text{tr}(\boldsymbol \alpha \, U^T) = \sum_{ij} \alpha_{ij} u_{ij}$ and $\text{tr}(\boldsymbol \alpha \, U^T) = \sum_{ij} \alpha_{ij} u_{ij}$ - so we'll use them as lagrangian constraints


Let's solve it:
* $L = J + \text{tr}(\boldsymbol \alpha U^T) + \text{tr}(\boldsymbol \beta V^T)$
* $\cfrac{\partial L}{\partial U} = -AV + U V^T V + \boldsymbol \alpha = 0$
* $\cfrac{\partial L}{\partial V} = -A^T V + V U^T U + \boldsymbol \beta = 0$


The [[KTT Condition]] $\alpha_{ij} \, u_{ij} = 0$ and $\beta_{ij} \, v_{ij} = 0$:
* $(AV)_{ij} \cdot u_{ij} - (U V^T V)_{ij} \cdot u_{ij} = 0$
* $(A^T U)_{ij} \cdot v_{ij} - (V U^T U)_{ij} \cdot v_{ij} = 0$
* these are independent of $\boldsymbol \alpha$ and $\boldsymbol \beta$


So we have the following update rule:
* $u_{ij} = \cfrac{(AV)_{ij} \cdot u_{ij}}{(U V^T V)_{ij}}$
* $v_{ij} = \cfrac{(A^T U)_{ij} \cdot v_{ij}}{(V U^T U)_{ij}}$


== [[SVD]] vs NMF ==
* SVD: basis is orthonormal, NMF is not
* components of NMF are always non-negative
* vectors in the basis of NMF directly correspond to clusters 
* we can learn cluster membership by taking the largest component of the vector (in the new representation)




== Applications ==
=== [[Latent Semantic Analysis]] ===
Why SVD is bad for LSA?
* if want to apply [[Cluster Analysis]] to cluster documents in the semantic space produced by SVD, need to use an external algorithm, e.g. [[K-Means]]
* negative values are hard to interpret
* objective of SVD is to find the orthogonal basis, which doesn't always result in a good basis for the Semantic Space:
* http://i.stack.imgur.com/PMhBY.png (source: Xu2003)


Can use NMF instead of [[SVD]] to reveal the latent structure and find the Semantic Space
* if $k$ is small (compared to original $n$), then NMF is bound to discover latent structure (i.e. &quot;topics&quot;) in data
* non-negativity is good for interpretability:
* it ensures that documents can be interpreted as non-negative combination of the key concepts (topics/clusters)
* it can find clusters for both terms and documents: columns of $V$ are basis for docs, columns of $U$ are basis for terms




=== [[Document Clustering]] ===
Assumptions:
* there are clusters of documents that correspond to coherent topics
* suppose we have a [[Vector Space Model|document-term matrix]] $D$ 
* and want to project documents (rows of $D$) to a $k$-dimensional semantic space 
* i.e. we want to represent each document as a linear (non-negative) combination of $k$ topics 


Result of NMF can be interpreted as clustering directly:
* decide on cluster membership by finding the base topic with greatest projection value
* can also be [[Fuzzy Clustering|fuzzy]]: e.g. take all topics larger than some projection value



== Local NMF ==
It's a variant of NMF (Li2001)
* in usual NMF vectors are not orthogonal and may be more similar to each other than desired
* LNMF addresses this issue


3 additional constants on $U$ and $V$ that aim to find the local features in the original matrix
* max sparsity in $V$: want to have as many 0's as possible
* expressiveness of $U$: retain only those components of $U$ that carry most information about the matrix
* max orthogonality of $U$ 


Results reported by Osinski2006:
* slow convergence 
* not good for [[Information Retrieval]] clustering because of sparsity 


== Implementation ==
=== NMF-ED in Python/Numpy ===
NMF-ED = Euclidean distance minimization 
* Algorithm from Lee1999

&lt;pre&gt;
import numpy as np

def seung_objective(V, W, H):
    ''' calculated the non-negative matrix factorization objective
        
    Usage:
        W, H = seung_update(V, W, H)
    Parameters:
        V: a (d x n)-array containing n observations in the columns
        W: (d x k)-array of non-negative basis images (components)
        H: (k x n)-array of weights, one column for each of the n observations
    Returns:
        F: a scalar objective
    '''    
    d, n = V.shape
    WH = np.dot(W, H)

    F = (V * np.log(WH) - WH).sum() / (d * n)
    return F


def seung_updateW(V, W, H):
    ''' performs the multiplicative non-negative matrix factorization updates for W
        
    Usage:
        W, H = seung_update(V, W, H)
    Parameters:
        V: a (d x n)-array containing n observations in the columns
        W: (d x k)-array of non-negative basis images (components)
        H: (k x n)-array of weights, one column for each of the n observations
    Returns:
        W: (d x k)-array of updated non-negative basis images (components)
    '''
    
    WH = np.dot(W, H)
    W_new = W * np.dot(V / WH, H.T)
    W_new = W_new / np.sum(W_new, axis=0, keepdims=True)    
    return W_new

def seung_updateH(V, W, H):
    ''' performs the multiplicative non-negative matrix factorization updates
        
    Usage:
        W, H = seung_update(V, W, H)
    Parameters:
        V: a (d x n)-array containing n observations in the columns
        W: (d x k)-array of non-negative basis images (components)
        H: (k x n)-array of weights, one column for each of the n observations
    Returns:
        H: (k x n)-array of updated weights, one column for each of the n observations
    '''
    
    WH = np.dot(W, H)
    H_new = H * np.dot((V / WH).T, W).T
    return H_new


def seung_nmf(V, k, threshold=1e-5, maxiter=500):
    ''' decomposes X into r components by non-negative matrix factorization
        
    Usage:
        W, H = seung_nmf(X, r)
    Parameters:
        V: a (d x n)-array containing n observations in the columns
        k: number of components to extract
        threshold: relative error threshold of the iteration
        maxiter: maximum number of iterations
    Returns:
        W: (d x k)-array of non-negative basis images (components)
        H: (k x n)-array of weights, one column for each of the n observations
    '''
    
    d, n = V.shape
    W = np.random.rand(d, k)
    H = np.random.rand(k, n)
    F = seung_objective(V, W, H)
    
    it_no = 0
    converged = False

    while (not converged) and it_no &lt;= maxiter:
        W_new = seung_updateW(V, W, H)
        H_new = seung_updateH(V, W_new, H)    
        F_new = seung_objective(V, W_new, H_new)

        converged = np.abs(F_new - F) &lt;= threshold 
        W, H = W_new, H_new
        it_no = it_no + 1
    
    return W, H
&lt;/pre&gt;


== References ==
* Lee, Daniel D., and H. Sebastian Seung. &quot;Learning the parts of objects by non-negative matrix factorization.&quot; 1999. [http://john.cs.olemiss.edu/~ychen/courses/CSCI582S07/seung-nonneg-matrix.pdf]
* Lee, Daniel D., and H. Sebastian Seung. &quot;Algorithms for non-negative matrix factorization.&quot; 2001. [http://papers.nips.cc/paper/1861-alg]
* Li, Stan Z., et al. &quot;Learning spatially localized, parts-based representation.&quot; 2001. [http://cvl.ice.cycu.edu.tw/meeting/2008.12.02.pdf]

== Sources ==
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. Springer US, 2012. [http://ir.nmu.org.ua/bitstream/handle/123456789/144935/d1784ebed3eab2708026b202b2b65309.pdf?sequence=1#page=90]
* Xu, Wei, Xin Liu, and Yihong Gong. &quot;Document clustering based on non-negative matrix factorization.&quot; 2003. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.2293&amp;rep=rep1&amp;type=pdf]
* Osinski, Stanislaw. &quot;Improving quality of search results clustering with approximate matrix factorisations.&quot; 2006. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.74&amp;rep=rep1&amp;type=pdf]
* [[Python for Machine Learning (TUB)]]

[[Category:Linear Algebra]]
[[Category:Matrix Decomposition]] 
[[Category:Python]]</text>
      <sha1>1gy4z3jx2i54mq1usr42g80t6r7idzt</sha1>
    </revision>
  </page>
  <page>
    <title>Python for Machine Learning (TUB)</title>
    <ns>0</ns>
    <id>596</id>
    <revision>
      <id>599</id>
      <timestamp>2015-05-01T20:04:18Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="358">* Taken in Wintersemester 2014 at TU Berlin
* Taught by Daniel Bartz


== Course Content ==
Prelimilaries:
* numpy, scipy and matplotlib
* loading graphics and data


Algorithms:
* [[K-Means]]
* [[Principal Component Analysis]]
* [[Non-Negative Matrix Factorization]]



[[Category:Machine Learning]]
[[Category:IT4BI]]
[[Category:Python]]
[[Category:Notes]]</text>
      <sha1>g622wq1mj8cg9j1l7ee9aycahxkeni5</sha1>
    </revision>
  </page>
  <page>
    <title>Topic Modeling</title>
    <ns>0</ns>
    <id>597</id>
    <redirect title="Topic Models" />
    <revision>
      <id>600</id>
      <timestamp>2015-05-01T20:05:51Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="26">#REDIRECT [[Topic Models]]</text>
      <sha1>bc9g10ykttnwj6ovidkopcvl1stezmb</sha1>
    </revision>
  </page>
  <page>
    <title>Topic Models</title>
    <ns>0</ns>
    <id>598</id>
    <revision>
      <id>601</id>
      <timestamp>2015-05-01T20:06:39Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1402">{{stub}}

== Topic Models ==
Topic models is a probabilistic approach to [[Document Clustering]]:
* create a probabilistic generative model for text documents
* represent corpus as a function of hidden variables 


Notation and problem:
* $D_1, \ ... \ , D_n$ are documents
* $T_1, \ ... \ , T_k$ are topics (sort of &quot;clusters&quot;)
* each document may belong to several topics - so these &quot;clusters&quot; are [[Fuzzy Clustering|Fuzzy]]
* probability of $D_i$ belonging to $T_j$ is $P(T_j \mid D_i)$
* but cluster membership is secondary in this problem
* the main problem is to find latent topics that generated documents - which is why it's called Topic Modeling 
* let $t_1, \ ... \ , t_d$ be $d$ terms from the lexicon
* then the probability that $t_l$ occurs in $T_j$ is $P(t_l \mid T_j)$


Thus, we need to estimate the following probabilities:
* $P(T_j \mid D_i)$ and $P(t_l \mid T_j)$
* usually parameters are learned via maximum likelihood methods like [[Expectation Maximization]]


There are two types of Topic Modeling techniques:
* [[Probabilistic LSA]]
* [[Latent Dirichlet Allocation]]


== Sources ==
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. Springer US, 2012. [http://ir.nmu.org.ua/bitstream/handle/123456789/144935/d1784ebed3eab2708026b202b2b65309.pdf?sequence=1#page=90]


[[Category:Topic Models]]
[[Category:Document Clustering]]</text>
      <sha1>tvlub95zj2wda9hu3yxtco73anug7gw</sha1>
    </revision>
  </page>
  <page>
    <title>Probabilistic LSA</title>
    <ns>0</ns>
    <id>599</id>
    <revision>
      <id>602</id>
      <timestamp>2015-05-01T20:07:25Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2372">{{stub}}

== Probabilistic LSA ==
This is a probabilistic extension to [[Latent Semantic Analysis]]
* it's a part of [[Topic Models]]


=== Problem ===
Notation and problem:
* $D_1, \ ... \ , D_n$ are documents
* $T_1, \ ... \ , T_k$ are topics (sort of &quot;clusters&quot;)
* each document may belong to several topics - so these &quot;clusters&quot; are [[Fuzzy Clustering|Fuzzy]]
* probability of $D_i$ belonging to $T_j$ is $P(T_j \mid D_i)$
* but cluster membership is secondary in this problem
* the main problem is to find latent topics that generated documents - which is why it's called Topic Modeling 
* let $t_1, \ ... \ , t_d$ be $d$ terms from the lexicon
* then the probability that $t_l$ occurs in $T_j$ is $P(t_l \mid T_j)$


=== Learning ===
Thus, we need to estimate the following probabilities:
* $P(T_j \mid D_i)$ and $P(t_l \mid T_j)$
* usually parameters are learned via maximum likelihood methods like [[Expectation Maximization]]


We need to learn $P(T_j \mid D_i)$ and $P(t_l \mid T_j)$
* $P(t_l \mid D_i)$ can be expressed via them:
* $P(t_l \mid D_i) = \sum\limits_{j=1}^k p(t_l \mid T_i) \, P(T_j \mid D_i)$
* thus, for each $t_l$ and $D_i$ we can generate $n \times d$ matrix of probabilities 
* these probabilities are learned from term-document matrix $X$: $X_{il}$ is # of times $t_l$ occurred in $D_i$ 
* so we can use [[Maximum Likelihood Estimator]] to maximize the product of probabilities of terms we observed 


Optimization:
* we will optimize the log likelihood $\sum_{i,l} X_{il} \cdot \log P(t_l, D_i)$
* s.t. $\sum_l P(t_l \mid T_j) = 1$ for all $T_j$ and $\sum_j P(T_j \mid D_i) = 1$ for all $D_i$
* can use [[Lagrange Multipliers]] for this


== [[Latent Dirichlet Allocation]] ==
is an extension of Probabilistic LSA
* model term-topic probabilities and topic-document probabilities with [[Dirichlet Distribution]]
* so LDA is a Bayesian version of PLSA
* but LSA overfits less than PLSA because it has less parameters to fit


== References ==
* Hofmann, Thomas. &quot;Probabilistic latent semantic analysis.&quot; 1999. [http://arxiv.org/ftp/arxiv/papers/1301/1301.6705.pdf]

== Sources ==
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. Springer US, 2012. [http://ir.nmu.org.ua/bitstream/handle/123456789/144935/d1784ebed3eab2708026b202b2b65309.pdf?sequence=1#page=90]


[[Category:Topic Models]]</text>
      <sha1>iusrs70ciu468yxb6fc2n5opffva5n7</sha1>
    </revision>
  </page>
  <page>
    <title>Euclidean Distance</title>
    <ns>0</ns>
    <id>600</id>
    <revision>
      <id>603</id>
      <timestamp>2015-07-08T17:07:02Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2635">== Euclidean Distance ==
Euclidean distance is a geometric [[Distance]] between two datapoints
* distance between $\mathbf x_1$ and $\mathbf x_2$ is 
* length of the line that connects these two points:
* $\| \mathbf x_1 - \mathbf x_2 \| = \sqrt{ (\mathbf x_1 - \mathbf x_2)^T (\mathbf x_1 - \mathbf x_2) } = \sqrt{\sum_i (x_{1i} - x_{2i})^2}$


It's the most common distance metric, also called $L_2$ norm


=== Properties ===
The Euclidean distance is translation invariant
* let $\mathbf a$ be some vector
* then consider the distance in the translated space :
* $\| (\mathbf x_1 - \mathbf a) - (\mathbf x_2 - \mathbf a) \| = \| \mathbf x_1 - \mathbf a - \mathbf x_2 + \mathbf a \| = \| \mathbf x_1 - \mathbf x_2 \|$
* so the distance in the translated space is the same as in the original space




== High Dimensionality ==
Euclidean distance is not always meaningful for high dimensional data

Consider this example:

{| class=&quot;wikitable&quot;
|-
! || $A_1$ ||  $A_2$ ||  $A_3$ || $A_4$ || $A_5$ || $A_6$ || $A_7$ || $A_8$ || $A_9$ || $A_{10}$
|-
| $\mathbf p_1$ || 3 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || 0
|-
| $\mathbf p_2$ || 0 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || 4
|-
| $\mathbf p_3$ || 3 || 2 || 4 || 0 || 1 || 2 || 3 || 1 || 2 || 0
|-
| $\mathbf p_4$ || 0 || 2 || 4 || 0 || 1 || 2 || 3 || 1 || 2 || 4
|}


* distance between $\mathbf p_1$ and $\mathbf p_2$ is $\| \mathbf p_1 - \mathbf p_2\| = 5$
* distance between $\mathbf p_3$ and $\mathbf p_4$ is $\| \mathbf p_3 - \mathbf p_4\| = 5$
* so Euclidean distance between these two vectors is the same!
* but suppose these vectors correspond to documents and words ([[Vector Space Models]])
*  $\mathbf p_3$ and $\mathbf p_4$ must be more similar to each other than $\mathbf p_1$ and $\mathbf p_2$: $\mathbf p_3$ and $\mathbf p_4$ have 7 words in common whereas $\mathbf p_1$ and $\mathbf p_2$ have none


When the data is sparse it's better to use different measure of distance/similarity
* we need to ignore records where both vectors have 0 
* for example:
* [[Dot Product]] and [[Cosine Similarity]]
* [[Jaccard Coefficient]]




== Sources ==
* http://en.wikipedia.org/wiki/Euclidean_distance
* Ertöz, Levent, Michael Steinbach, and Vipin Kumar. &quot;Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data.&quot; 2003. [http://static.msi.umn.edu/rreports/2003/73.pdf]
* Korenius, Tuomo, Jorma Laurikkala, and Martti Juhola. &quot;On principal component analysis, cosine and Euclidean measures in information retrieval.&quot; 2007. [http://www.sciencedirect.com/science/article/pii/S0020025507002630] 


[[Category:Distances]]
[[Category:Norms]]</text>
      <sha1>bzmenw6r7ka2bptcpjt69cv2t7tjp9s</sha1>
    </revision>
  </page>
  <page>
    <title>Scatter/Gather</title>
    <ns>0</ns>
    <id>601</id>
    <revision>
      <id>604</id>
      <timestamp>2015-05-01T20:39:47Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3443">== Scatter/Gather ==
This is 
* use [[Hierarchical Clustering]] for seed selection, 
* k-means for clustering

Scatter/Gather is a variation of [[K-Means]] used for [[Document Clustering]] with
* special seed selection
* usual k-means
* then several cluster refinement operations


Idea:
* use some hierarchical clustering algorithm on a sample to find good initial seeds
* use K-Means afterwards 


Notation:
* Let $k$ be the number of clusters we want to select and 
* $n$ the number of observations we want to cluster



== Seed Selection ==
=== Buckshot ===
* sample $\sqrt{k \cdot n}$ observations
* use hierarchical clustering to get $k$ seeds from them 


=== Fractionation ===
* break dataset into $n / m$ buckets of size $m &gt; k$ each
* apply hierarchical clustering to each bucket and obtain $v$ clusters inside each bucket
* then merge all observations in these clusters (within each bucket) into one
* repeat till we have $k$ seeds 


Can do better than randomly grouping observations into buckets
* for document clustering: 
* try to group documents in such a way that documents inside buckets have common words
* e.g. sort docs by index of $j$th most common word in them, $j \approx 3$ corresponds to medium frequent word in a doc


== K-Means Step ==
After we did the seed selecting, we apply the usual k-means
* but, with a difference: the centroid is not a &quot;mean&quot; document
* centroid is a concatenation of words from all the documents in the cluster



== Cluster Refinement ==
After selecting seeds just do usual K-Means 
* but do some additional operations to improve quality for document clustering


Cluster refinement hypothesis:
* documents that belong to the same cluster in finer granularity will also occur in the same cluster in coarser granularity


=== Split Operations ===
The main idea is to continue splitting after K-Means has finished
* sometimes clusters as not as granular as we'd like
* continue splitting them to refine clusters 
* don't need to apply it to all clusters - only to non-coherent ones
* it will help create more coherent clusters


Algo: 
* select a cluster to split
* apply buckshot with $k=2$ on this cluster
* re-cluster around these centers 


How to measure &quot;coherence&quot;?
* compute self-similarity of a cluster:
* similarity of documents to the centroid cluster
* or average pairwise similarity within the cluster
* apply split only to clusters with low self-similarity


=== Join Operation ===
The idea:
* after K-means has finished,
* join very similar clusters into one 


How?
* compute typical words of each cluster: 
* i.e. examine most frequent words on the centroid
* two clusters are similar if there's significant overlap between words of these clusters 


== Challenges ==
* if there are many documents, the centroid will contain many word =&gt; leads to slowdown 
* solution: use [[Projection onto Subspaces|projection]] techniques like [[PCA]] 


== Sources ==
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. Springer US, 2012. [http://ir.nmu.org.ua/bitstream/handle/123456789/144935/d1784ebed3eab2708026b202b2b65309.pdf?sequence=1#page=90]
* Cutting, Douglass R., et al. &quot;Scatter/gather: A cluster-based approach to browsing large document collections.&quot; 1992. [http://courses.washington.edu/info320/au11/readings/Week4.Cutting.et.al.1992.Scatter-Gather.pdf]


[[Category:Document Clustering]]
[[Category:Cluster Analysis]]</text>
      <sha1>2lsonnx3wq28sy2xmgg4my18ia96607</sha1>
    </revision>
  </page>
  <page>
    <title>Hierarchical Clustering</title>
    <ns>0</ns>
    <id>602</id>
    <revision>
      <id>605</id>
      <timestamp>2015-05-01T20:40:42Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="672">== Hierarchical Clustering ==
This is a part of [[Cluster Analysis]]: we want to build a hierarchy of clusters 

Two major approaches:
* [[Agglomerative Clustering]]: This is a &quot;bottom up&quot; approach: each observation starts in its own cluster, and pairs of clusters are merged as one moves up the hierarchy.
* [[Divisive Clustering]]: This is a &quot;top down&quot; approach: all observations start in one cluster, and splits are performed recursively as one moves down the hierarchy.


== Links ==
* http://www.cs.princeton.edu/courses/archive/spr08/cos424/slides/clustering-2.pdf

== Sources ==
* http://en.wikipedia.org/wiki/Hierarchical_clustering


[[Category:Cluster Analysis]]</text>
      <sha1>mn0vj3ao6bt6nerij4ubx6vv2c33cdo</sha1>
    </revision>
  </page>
  <page>
    <title>Agglomerative Clustering</title>
    <ns>0</ns>
    <id>603</id>
    <revision>
      <id>606</id>
      <timestamp>2015-07-05T18:58:21Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3859">{{ stub }}

== Agglomerative Clustering ==
General concept: merge items into clusters based on distance/similarity 
* usually based on best pairwise similarity

Typical steps:
* at the beginning each document is a cluster on its own
* then we compute similarity between all pairs of clusters and store the results in a similarity matrix 
* merge two most similar clusters 
* update the similarity matrix 
* repeat until everything belongs to the same cluster 



== Linkage Types ==
How to join two clusters?
* Single Linkage (SLINK)
* Complete Linkage (CLINK)
* Group-Average Linkage


Suppose we have clusters $A, B, C, ...$ that we want to merge 

{{ TODO | need more mathematical definitions }}


=== Single Linkage ===
Merge two groups $A$ and $B$ based on their closest pair 


Implementation:
* compute all similarity pairs
* sort them in order of decrease
* process pairs in this order


advantage: 
* efficient to implement 
* equivalent to a Spanning Tree algo on the complete graph of pair-wise distances {{ TODO | Link to Algo 2 from Coursera! }}
* can use Prim's Spanning Tree algo


Drawbacks 
* encourages chaining
** similarity is usually not transitive: 
** i.e. if $A$ is similar to $B$, and $B$ is similar to $C$, it doesn't mean that $A$ must be similar to $C$
** but single linkage encourages grouping through transitivity chains


References:
* Sibson, Robin. &quot;SLINK: an optimally efficient algorithm for the single-link cluster method.&quot; 1973. [http://www.cs.ucsb.edu/~veronika/MAE/SLINK_sibson.pdf]



=== Complete Linkage ===
Worst-case similarity:
* avoids chaining altogether
* but it's very expensive computationally


References:
* Defays, Daniel. &quot;An efficient algorithm for a complete link method.&quot; 1977. [http://comjnl.oxfordjournals.org/content/20/4/364.short]


=== Group-Average Linkage ===
similarity between groups $A$ and $B$ are calculated as average similarity between each $a \in A$ and $b \in B$


* It's way slower than single linkage,
* but it's more robust: it doesn't show the chaining behavior


Speeding up:
* can approximate it by using the distance between centroids: mean doc in $A$ and mean doc in $B$ 



=== Ward's Method ===
Merge the pair of clusters that minimizes the total within-group error (sum of squares) between each document and centroid 


Result:
* spherical tightly bound clusters 
* less sensitive to outliers

References:
* El-Hamdouchi, Abdelmoula, and Peter Willett. &quot;Hierarchic document classification using Ward's clustering method.&quot; 1986. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.91.7722&amp;rep=rep1&amp;type=pdf]



=== Pros and Cons ===
* Single-link algorithms are best for capturing clusters of different sizes and shapes 
* but it's also sensitive to noise 
* complete link and group average are not affected by noise, but have a bias towards finding global patterns

Computational complexity:
* only Single-Link is computationally possible for large datasets, but it doesn't give good results because uses too little information



== References ==
* Rasmussen, Edie M. &quot;Clustering Algorithms.&quot; Information retrieval: data structures &amp; algorithms 1992. [http://orion.lcg.ufrj.br/Dr.Dobbs/books/book5/chap16.htm]
* Voorhees, Ellen M. &quot;Implementing agglomerative hierarchic clustering algorithms for use in document retrieval.&quot; 1986. [https://ecommons.library.cornell.edu/handle/1813/6605]


== Sources ==
* Ertöz, Levent, Michael Steinbach, and Vipin Kumar. &quot;Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data.&quot; 2003. [http://static.msi.umn.edu/rreports/2003/73.pdf]
* Oikonomakou, Nora, and Michalis Vazirgiannis. &quot;A review of web document clustering approaches.&quot; Data mining and knowledge discovery handbook. 2010. [https://scholar.google.com/scholar?cluster=1261203777431390097&amp;hl=ru&amp;as_sdt=0,5]

[[Category:Cluster Analysis]]</text>
      <sha1>76e0siblm40xsqazms6gd05f3g73scu</sha1>
    </revision>
  </page>
  <page>
    <title>K-Medoids</title>
    <ns>0</ns>
    <id>604</id>
    <revision>
      <id>607</id>
      <timestamp>2015-05-01T20:42:34Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1029">== K-Medoids ==
K-Medoids is a variation of [[K-Means]] clustering algorithm 


Algorithm:
* use a set of points from the original data set as anchors (&quot;medoids&quot;)
* then build clusters around them 
* each item is assigned to its closest representation from the data set 
* iterative approach 


Objective 
* $J$: average similarity of each item to its centroid


Disadvantages 
* require many iterations to converge
* so it's slow: it's slow to compute $J$
* doesn't always work well for sparse data
** e.g. for text, not many docs have lots of terms in common
** so similarities between such pairs are small and noisy
** a single medoid may not contain all needed information to build a cluster around it



== Sources ==
* http://en.wikipedia.org/wiki/K-medoids
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. Springer US, 2012. [http://ir.nmu.org.ua/bitstream/handle/123456789/144935/d1784ebed3eab2708026b202b2b65309.pdf?sequence=1#page=90]

[[Category:Cluster Analysis]]</text>
      <sha1>sedox3fwp7u920ltbd384n92ik4r6vh</sha1>
    </revision>
  </page>
  <page>
    <title>Semi-Supervised Clustering</title>
    <ns>0</ns>
    <id>605</id>
    <revision>
      <id>608</id>
      <timestamp>2015-05-01T20:43:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2152">{{stub}}

== Semi-Supervised Clustering ==
Semi-supervised clustering is a bridge between [[Supervised Learning]] and [[Cluster Analysis]]
* it's about learning with both labeled and unlabeled data:
* sometimes we have some prior knowledge about clusters, e.g. we could have some label information 
* such knowledge can be useful in creating clusters - especially when the number of examples is very big


Where these labels come from?
* you can sample your data and manually label it 
* or try to extract the label e.g. from the unstructured data if you have at least some prior knowledge


== Approaches ==
=== Seeded Approach ===
Use labeled data to help initialize clusters 
* it will bias clustering towards a good region in the search space


Papers 
* Basu, Sugato, Arindam Banerjee, and Raymond Mooney. &quot;Semi-supervised clustering by seeding.&quot; 2002.


=== Constrained Approach ===
Force to keep the grouping of labels unchanged 


=== Feedback-Based Approach ===
* First run regular clustering 
* then adjust clusters based on labeled data 
* account for user feedback


=== Probabilistic frameworks ===
Papers
* Basu, Sugato, Mikhail Bilenko, and Raymond J. Mooney. &quot;A probabilistic framework for semi-supervised clustering.&quot; 2004. 


== [[Document Classification]] ==
It's also useful for document classification

Papers:
* Nigam, Kamal, et al. &quot;Learning to classify text from labeled and unlabeled documents.&quot; (1998). [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.6837&amp;rep=rep1&amp;type=pdf]
* Nigam, Kamal, et al. &quot;Text classification from labeled and unlabeled documents using EM.&quot; (2000). [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.154.3651&amp;rep=rep1&amp;type=pdf]



== Sources ==
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. Springer US, 2012. [http://ir.nmu.org.ua/bitstream/handle/123456789/144935/d1784ebed3eab2708026b202b2b65309.pdf?sequence=1#page=90]
* Jing, Liping. &quot;Survey of text clustering.&quot; (2008). [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.3476&amp;rep=rep1&amp;type=pdf]


[[Category:Cluster Analysis]]
[[Category:Machine Learning]]</text>
      <sha1>m2u4nfcpbu2zvxd1iyvmfbnbbbiptxp</sha1>
    </revision>
  </page>
  <page>
    <title>Cluster Analysis</title>
    <ns>0</ns>
    <id>606</id>
    <revision>
      <id>609</id>
      <timestamp>2015-07-05T18:49:52Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5115">== Cluster Analysis ==
Clustering is about finding groups of similar objects in the data

How do we define similar? 
* we measure with some similarity/distance function 


Application of Clustering
* Customer Segmentation
* Clustering for Classification
* Collaborative Filtering
* Visualization
* Document organization and indexing 



[[Similarity Functions|Similarity measures]] and [[Distance Functions|Distances]]:
* [[Euclidean Distance]]
* [[Jaccard Coefficient]]
* [[Dot Product]]
* [[Cosine Similarity]]



== One-Sided Clustering ==
=== Partitioning Clustering ===
Idea: 
* decompose dataset into $k$ disjoint classes 
* s.t. each item belongs to exactly one class 


Algorithms:
* [[K-Means]] and variants like [[K-Medoids]]
* [[CURE Clustering]]


=== [[Hierarchical Clustering]] ===
Idea:
* build a tree

Main approaches:
* [[Agglomerative Clustering]]
** at the beginning everything is a cluster on its own
** merge till have one big cluster
* [[Divisive Clustering]]
** at the beginning everything belongs to one big cluster
** split clusters until everything is a cluster on its own


Others:
* [[Chameleon Clustering]]


=== Density-Based ===
Cluster neighborhood groups based on some density conditions
* [[DBSCAN]]
* [[SNN Clustering]] extension of DBSCAN with notion of similarity based on [[KNN|$k$-nearest neighbors]]


=== Grid-Based ===
Partition space into finite number of cells and perform clustering there



== Other Types ==
=== Graph-Based Clustering ===
apply [[Graph Partitioning]] Algorithms: 
* identify clusters by cutting edges from the graph 
* s.t. the sum of cuts is minimal 
* for example, [[Minimal Cut Algorithm]]

Algorithms:
* [[Chameleon Clustering]]


[[Spectral Clustering]]
* apply [[Graph Partitioning]] but in some high-dimensional space
* usually involves computing [[SVD|Singular Values and Vectors]] / [[Eigenvalues and Eigenvectors]] of the graph affinity matrix
* usually has global optimum
* criteria: Average Cut, Average Association, Normalized Cut, Min-Max Cut
* when applied to [[Document Clustering|documents]], under certain conditions resulting eigenspaces are equivalent to semantic spaces found by [[Latent Semantic Analysis]] 
* but also like in LSA, usually found directions don't correspond to clusters directly, need to do additional clustering afterwards (e.g. by [[K-Means]])


Link-Based Clustering
* can use Web-graph techniques 
* [[PageRang]] and [[HITS]] are used for Ranking
* see Oikonomakou2010


=== [[Neural Networks]] Based ===
Called [[Self-Organized Maps]]

Build a Neural Network with 2 layers:
* input layers: $n$ input nodes 
* output: $k$ nodes: decision regions


Objective we want to maximize:
* within-region similarities of items 


References:
* https://en.wikipedia.org/wiki/Self-organizing_map



=== [[Fuzzy Clustering]] ===
sometimes also called &quot;Soft Clustering&quot;
* Usually clustering is &quot;exclusive&quot;: the clustering algorithms assigns each object strictly to cluster
* but we can remove this restriction and modify the membership function s.t. an object can belong to several clusters
* so In this type of clustering a data point may belong to several clusters


Membership function
* computes for each object and for each cluster returns the degree of membership
* modification of K-Means: [[Fuzzy C-Means]]
* degree of membership to the cluster in C-Means depends on the distance from the document to the cluster centroid


Others:
* clustering via [[Non-Negative Matrix Factorization]] can be fuzzy
* also, Looney, Carl G. &quot;A fuzzy clustering and fuzzy merging algorithm.&quot; 1999. [https://www.researchgate.net/publication/2467319_A_Fuzzy_Clustering_and_Fuzzy_Merging_Algorithm]



=== [[Probabilistic Clustering]] ===
Membership function outputs probabilities of an item belonging to a cluster


Algorithms:
* [[Finite Mixture Modeling]]
* [[Expectation Maximization]] (with [[Gaussian Mixture Models]])



=== [[Co-Clustering]] ===
One-sided clustering is clustering only rows of data matrix $D$
* co-clustering: clustering both rows and columns at the same time


Algorithms
* clustering via [[Non-Negative Matrix Factorization]] can be viewed as clustering both columns and rows


=== [[Subspace Clustering]] ===
Subspace clustering:
* it's the task of detecting all clusters  in all subspaces 
* a data point may belong to many different clusters - with each cluster in some subspace 



== Sources ==
* http://en.wikipedia.org/wiki/Cluster_analysis
* Jing, Liping. &quot;Survey of text clustering.&quot; (2008). [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.3476&amp;rep=rep1&amp;type=pdf]
* Oikonomakou, Nora, and Michalis Vazirgiannis. &quot;A review of web document clustering approaches.&quot; Data mining and knowledge discovery handbook. 2010. [https://scholar.google.com/scholar?cluster=1261203777431390097&amp;hl=ru&amp;as_sdt=0,5]
* Xu, Wei, Xin Liu, and Yihong Gong. &quot;Document clustering based on non-negative matrix factorization.&quot; 2003. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.2293&amp;rep=rep1&amp;type=pdf]

[[Category:Unsupervised Learning]]
[[Category:Cluster Analysis]]
[[Category:Machine Learning]]</text>
      <sha1>ew9qqazpaor3lrnfz6mp1sijuupxzny</sha1>
    </revision>
  </page>
  <page>
    <title>CURE Clustering</title>
    <ns>0</ns>
    <id>607</id>
    <revision>
      <id>610</id>
      <timestamp>2015-05-01T20:57:05Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1132">{{ stub }}

== CURE Algorithm for Clustering ==
Use a set of representative points to find non-global clusters 
* these points capture the geometry and shape of clusters 

{{ TODO | see [[Scalable Data Analytics and Data Mining AIM3 (TUB)]] lectures }}


Choose points
* 2 farthest away points
* 3 and so on - furthest away from previous ones
* this procedure guarantees that the points are well distributed 

Then shrink the points towards the centroids by factor of $\alpha$ 


CURE eliminates outliers by discarding small slowly growing clusters 
* but it has a notion of center - not all shapes has natural center


== References == 
* Guha, Sudipto, Rajeev Rastogi, and Kyuseok Shim. &quot;Cure: an efficient clustering algorithm for large databases.&quot; (2001) [http://www.cs.sfu.ca/CourseCentral/459/han/papers/guha98.pdf]

== Sources ==
* Ertöz, Levent, Michael Steinbach, and Vipin Kumar. &quot;Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data.&quot; 2003. [http://static.msi.umn.edu/rreports/2003/73.pdf]
* http://en.wikipedia.org/wiki/CURE_data_clustering_algorithm

[[Category:Cluster Analysis]]</text>
      <sha1>0lwpw80psfwuuw7lcmbkr17zj7d616z</sha1>
    </revision>
  </page>
  <page>
    <title>Chameleon Clustering</title>
    <ns>0</ns>
    <id>608</id>
    <revision>
      <id>611</id>
      <timestamp>2015-05-01T20:57:58Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1663">{{ stub }}

== Chameleon Clustering ==
Combines initial partition of data with hierarchical clustering techniques 
it modifies clusters dynamically

Step1: 
* Generate a [[KNN]] graph
* because it's local, it reduces influence of noise and outliers
* provides automatic adjustment for densities


Step2:
* use METIS: a graph partitioning algorithm 
* get equally-sized groups of well-connected vertices 
* this produces &quot;sub-clusters&quot; - something that is a part of true clusters


Step3:
* recombine sub-clusters 
* combine two clusters if
** they are relatively close
** they are relatively interconnected 
* so they are merged only if the new cluster will be similar to the original ones 
* i.e. when &quot;self-similarity&quot; is preserved (similar to the join operation in [[Scatter/Gather]])


But 
* [[Curse of Dimensionality]] makes similarity functions behave poorly
* distances become more uniform as dimensionality grows
* and this makes clustering difficult 

Similarity between two point of high dimensionality can be misleading
* often points may be similar even though they should belong to different clusters 


Solutions:
* [[ROCK Clustering]]
* [[SNN Clustering]]: also use [[KNN]]


== References == 
* Karypis, George, Eui-Hong Han, and Vipin Kumar. &quot;Chameleon: Hierarchical clustering using dynamic modeling.&quot; (1999). [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.44.5847&amp;rep=rep1&amp;type=pdf]

== Sources ==
* Ertöz, Levent, Michael Steinbach, and Vipin Kumar. &quot;Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data.&quot; 2003. [http://static.msi.umn.edu/rreports/2003/73.pdf]


[[Category:Cluster Analysis]]</text>
      <sha1>syugtysx7tghox7f5bw2ej4ps4fmal2</sha1>
    </revision>
  </page>
  <page>
    <title>SNN Clustering</title>
    <ns>0</ns>
    <id>609</id>
    <revision>
      <id>612</id>
      <timestamp>2015-07-28T06:58:45Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4458">== SNN Clustering ==
The goal:
* find clusters of different shapes, sizes and densities in high-dimensional data
* [[DBSCAN]] is good for finding clusters of different shapes and sizes, but it fails to find clusters with different densities 
* it will find only one cluster:
* http://habrastorage.org/files/ff4/b40/6fc/ff4b406fc5d948d7bf3b2d4e3c18a71d.png
* (figure source: Ertöz2003)


Distance:
* [[Euclidean Distance]] is not good for high-dimensional data 
* use different similarity measure in terms of [[KNN]]s - &quot;Shared Nearest Neighbors&quot;
* then define density in terms of this similarity


=== Jarvis-Patrick Algorithm ===
&quot;Jarvis-Patrick&quot; algorithm, as in Jarvis1973


Step 1: SNN sparsification:
* construct an SSN [[Graph]] from data matrix as follows
* if $p$ and $q$ have each others in the KNN list
* then create a link between them 


Step 2: Weighting
* weight the links with $\text{sim}(p, q) = \big| \, \text{NN}(p) \ \cup \ \text{NN}(q) \, \big|$
* where $\text{NN(p)}$ and $\text{NN(q)}$ are $k$ neighbors of $p$ and $q$ resp.


Step 3: Filtering
* then filter the edges: 
* remove all edges with weight less than some threshold


Step 4: Clusters
* let all connected components be clusters


Illustration
* http://habrastorage.org/files/b2b/174/cd8/b2b174cd84e3488a8d1dad51687bf194.png
* (figure source: Ertöz2003)
* note that this procedure removed the noise
* and clusters are of uniform density: it breaks the links in the transition regions


=== Density ===
Usual density is not good:
* In the Euclidean space, the density is the number of points per unit volume 
* but as dimensionality increases, the volume increases rapidly
* so unless the number of points increases exponentially with dimensionality, the density tends to 0
* Density-based algorithms (e.g. [[DBSCAN]]) will not work properly 


Need different intuition of density
* can use a related concept from 
* if $k$th nearest neighbor is close, then the region is most likely of high density
* so the distance to $k$th neighbor gives a measure of density of a point
* because of the [[Curse of Dimensionality]], the approach is not good for [[Euclidean Distance]], [[Cosine Similarity]] or others
* but we can use the SNN-Similarity to define density


SSN-based measures of density:
* sum of SSN similarities over all KNNs 
** why sum an not just $k$th?
** to reduce random variation - which happens when we look only at one point
** to be consistent with the graph-based view of the problem
* of it can be the number of points within some radius - specified in terms of SNN distance
** like in [[DBSCAN]], but with SSN distance


=== SSN Clustering Algorithm ===
SNN Clustering algorithm is a combination of 
* Jarvis-Patrick algorithm and
* DBSCAN with SSN Similarity and SSN Density


Parameters
* $k$ 
* $\epsilon$
* $\text{min_pts} &lt; k$


Steps:
* compute the similarity matrix 
* sparsify the matrix by keeping only $k$ most similar neighbors for each data point
* construct the SSN graph (use the Jarvis-Patrick algo)
* find SSN density of each point $p$:
** in the KNN list of $p$ count $q$ s.t. $\text{sim}(p, q) \geqslant \epsilon$
* find the core points
** all points with SSN density greater than $\text{min_pts}$ are the core ones
* form clusters from the core points 
** all non-core points not within $\epsilon$ from the core ones are discarded as noise
* align non-noise non-core points to clusters


Parameter tuning:
* $k$ controls granularity of clusters
* if $k$ is small, then it will find small and very tight clusters
* if $k$ is large, it'll find big and well-separated clusters


=== Complexity ===
* The algorithm runs in $O(n^2)$ time
* can speed up with [[Kd-Trees]] or [[R-Tree]]s
* alternatively, can use [[Canopy Clustering|canopies]]


== References ==
* Jarvis, Raymond A., and Edward A. Patrick. &quot;Clustering using a similarity measure based on shared near neighbors.&quot; (1973). [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.474.2388&amp;rep=rep1&amp;type=pdf]
* See also: Houle, Michael E., et al. &quot;Can shared-neighbor distances defeat the curse of dimensionality?.&quot; 2010. [http://www.dbs.ifi.lmu.de/~zimek/publications/SSDBM2010/SNN-SSDBM2010-preprint.pdf]


== Sources ==
* Ertöz, Levent, Michael Steinbach, and Vipin Kumar. &quot;Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data.&quot; 2003. [http://static.msi.umn.edu/rreports/2003/73.pdf]

[[Category:Cluster Analysis]]
[[Category:Distances]]</text>
      <sha1>oy4l0m5it0munrr1atwc5le4c7qiv2c</sha1>
    </revision>
  </page>
  <page>
    <title>DBSCAN</title>
    <ns>0</ns>
    <id>610</id>
    <revision>
      <id>613</id>
      <timestamp>2015-05-01T21:02:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1172">{{ stub  }}

== DBSCAN ==
It's a density-based clustering algorithm


Density associated with a point is obtained by counting the number of points in a region of specified radius $\epsilon$ around each point 
* points with density $\geqslant \text{min_pts}$ are considered as &quot;core points&quot;
* noise and non-core points are discarded 
* clusters are formed around the core points 
* if two core points are within a radius $\epsilon$, then they belong to the same cluster



Disadvantages
* can find clusters of different shapes, but can't find clusters of different densities


== Extensions ==
=== [[SNN Clustering]] ===
* an extension of DBSCAN that words better for high-dimensional data
* also can find clusters of different density


== References ==
* Ester, Martin, et al. &quot;A density-based algorithm for discovering clusters in large spatial databases with noise.&quot; 1996. [http://www.aaai.org/Papers/KDD/1996/KDD96-037]

== Sources ==
* Ertöz, Levent, Michael Steinbach, and Vipin Kumar. &quot;Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data.&quot; 2003. [http://static.msi.umn.edu/rreports/2003/73.pdf]

[[Category:Cluster Analysis]]</text>
      <sha1>kph5esfh87dld4ym8bjc9smkswi7yrn</sha1>
    </revision>
  </page>
  <page>
    <title>Canopy Clustering</title>
    <ns>0</ns>
    <id>611</id>
    <revision>
      <id>614</id>
      <timestamp>2015-05-01T21:04:23Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="619">{{ stub }}
{{ TODO | see [[Scalable Data Analytics and Data Mining AIM3 (TUB)]] lectures }}


== Canopy Clustering ==

repeat
* sample a point
* form a group around this point 
** other points that are within some similarity threshold
* remove closest points 


result
* set of (potentially overlapping) groups
* they are much smaller than the original dataset 


canopies reduce the computation time:
* for [[Cluster Analysis]]
* in general, for [[KNN]] queries


== Links ==
* http://en.wikipedia.org/wiki/Canopy_clustering_algorithm
* http://www.kamalnigam.com/papers/canopy-kdd00.pdf


[[Category:Cluster Analysis]]</text>
      <sha1>ekxp2xk9et1wnfftv4czy4urve3k9ok</sha1>
    </revision>
  </page>
  <page>
    <title>Term Strength</title>
    <ns>0</ns>
    <id>612</id>
    <revision>
      <id>615</id>
      <timestamp>2015-07-05T11:13:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2163">== Term Strength ==
Term Strength is a technique for [[Feature Selection]] in [[Text Mining]]
* it doesn't need a pre-defined list of [[Stop Words]] - it discovers them automatically
* so it's a technique for vocabulary reduction in text retrieval 
* this method estimates term importance based on how often a term appears in &quot;related&quot; documents

 
''Strength'' of a term $t$ 
* measures how informative a word is for identifying two related documents
* $s(t) = P(t \in y \mid t \in x)$
* for two related documents $x, y$ what's the probability that $t$ belongs to $y$ given it belongs to $x$?
* estimate $s(t)$ on training data using [[Maximum Likelihood Estimation]]


What does it mean &quot;related&quot;?
* if we know the labels of these documents, then related are those that belong to the same category
* what about [[Unsupervised Learning]]?



== [[Document Clustering]] ==
Can we use this for unsupervised learning?

How to find such $x$ and $y$?
* manual or with user feedback - not practical

Can we automate it?

Yes (Wilbur1992):
* use [[Cosine Similarity]] to find most related documents 
* set some threshold $t$ and let all pairs with cosine $&gt; t$ be related 

Then we can estimate $s(t)$ using [[Maximum Likelihood Estimation]] for [[Multinomial Distribution]]
$$\hat s(t) = \cfrac{\text{# of pairs where $t$ occurs both in $x$ and $y$}}{\text{# of pairs where $t$ occurs in $x$}}$$



== Pruning ==
Let expected strength be $z = \mathbb E_t [s(t)]$ 
* we estimate $z$ as $\hat z = \cfrac{1}{| V |} \sum\limits_{t \in V} s(t)$ 
* let $\sigma = \text{sd}\big( s(t) \big)$ - how much $s(t)$ varies
* we prune term $t$ if $s(t) \leqslant 2 \sigma \, z$



== Sources ==
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. Springer US, 2012. [http://ir.nmu.org.ua/bitstream/handle/123456789/144935/d1784ebed3eab2708026b202b2b65309.pdf?sequence=1#page=90]
* Wilbur, W. John, and Karl Sirotkin. &quot;The automatic identification of stop words.&quot; 1992. [https://www.researchgate.net/publication/247786801_The_automatic_identification_of_stop_words]


[[Category:Feature Selection]]
[[Category:Information Retrieval]]</text>
      <sha1>dgq52x1qynjxgprq6lf0zrbd8607jcb</sha1>
    </revision>
  </page>
  <page>
    <title>Term Contribution</title>
    <ns>0</ns>
    <id>613</id>
    <revision>
      <id>616</id>
      <timestamp>2015-05-01T21:09:22Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1191">== Term Contribution ==
Idea: result of clustering highly depends on how similar are documents

so contribution of a term $t$ is how much it contributes to similarity of two documents

Text clustering is highly dependent on the documents similarity.
* Suppose use a [[Dot Product]] based similarity:
* $\text{similarity}(d_i, d_j) =  \sum_{t \in V} f(t, d_i) \times f(t, d_j)$
** where $f(t, d)$ represents the weight of term $t$ in document $d$


The contribution of each term is the overall contribution to documents’ similarities and shown by the following equation:

* $\text{TC}(t) = \sum_{i,j} f(t, d_i) \times f(t, d_j)$


It's slow - $O(n^2)$
* sample to speed it up



== Sources ==
* Liu, Tao, et al. &quot;An evaluation on feature selection for text clustering.&quot; ICML. Vol. 3. 2003. [http://www.aaai.org/Papers/ICML/2003/ICML03-065.pdf]
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. Springer US, 2012. [http://ir.nmu.org.ua/bitstream/handle/123456789/144935/d1784ebed3eab2708026b202b2b65309.pdf?sequence=1#page=90]
* http://cs.gmu.edu/~carlotta/teaching/INFS-795-s05/readings/INFS795_MCayci.ppt

[[Category:Feature Selection]]</text>
      <sha1>4ys1ejsp5imyuvfqz7113plt7q1xq0x</sha1>
    </revision>
  </page>
  <page>
    <title>Concept Decomposition</title>
    <ns>0</ns>
    <id>614</id>
    <revision>
      <id>617</id>
      <timestamp>2015-05-02T06:09:18Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1011">{{ stub }}

== Concept Decomposition ==
We can use clustering for [[Dimensionality Reduction]] of text data
* both [[Term Clustering]] and [[Document Clustering]] technique at the same time


do clustering 
* most frequent terms in the centroids are the basis
* they are almost orthogonal - they shouldn't appear a lot in other clusters
* then represent each document in terms of this basis 



== References ==
* Dhillon, Inderjit S., and Dharmendra S. Modha. &quot;Concept decompositions for large sparse text data using clustering.&quot; (2001). [http://www.cs.utexas.edu/users/inderjit/public_papers/concept_mlj.pdf]
* https://www.google.ru/?q=Concept+Decomposition

== Sources ==
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. Springer US, 2012. [http://ir.nmu.org.ua/bitstream/handle/123456789/144935/d1784ebed3eab2708026b202b2b65309.pdf?sequence=1#page=90]

[[Category:Cluster Analysis]]
[[Category:Document Clustering]]
[[Category:Dimensionality Reduction]]</text>
      <sha1>2ajr30p6md7uqgqi7f0c9ezzk3v8zan</sha1>
    </revision>
  </page>
  <page>
    <title>Feature Filtering</title>
    <ns>0</ns>
    <id>615</id>
    <revision>
      <id>618</id>
      <timestamp>2015-05-02T06:12:20Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1198">{{ stub }}

== Feature Filtering ==
Given $D$ features $f_1, \ ... \ , f_D$ and outcome $Y$
* rank these features according to some criterion of &quot;importance&quot;
* keep only important ones

Important? 
* top $d$
* ones with scores above some threshold


Criteria of usefulness :
* [[Information Theory]] measures ([[Shannon's Information Measures]]))
* [[Entropy-Based Ranking]]
* [[Information Gain]]
* [[Mutual Information]]
* [[Odds Ratio]]
* [[Chi-Squared Ranking]]


* All these functions capture the intuition that the best features for predicting the outcome $Y$ is ones that distribute very differently given values of $Y$
* Usually these functions measure (in)dependence between $f_i$ and $Y$ 
* the more dependent the feature is, the better it is for classification


E.g. $\chi^2$ measures how the results of an observation differs from the result expected according to the null hypothesis 
* lower values indicate less dependency 
* so for $\chi^2$ we want to take biggest values 


== Sources ==
* Sebastiani, Fabrizio. &quot;Machine learning in automated text categorization.&quot; (2002). [http://arxiv.org/pdf/cs/0110053.pdf]


[[Category:Dimensionality Reduction]]
[[Category:Feature Filtering]]</text>
      <sha1>12o8msmkstnnhy5020ov1ddk4n49xun</sha1>
    </revision>
  </page>
  <page>
    <title>Entropy-Based Ranking</title>
    <ns>0</ns>
    <id>616</id>
    <revision>
      <id>619</id>
      <timestamp>2015-05-02T06:14:44Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1868">== Entropy-Based Ranking ==


== Unsupervised Learning ==
Consider feature $F_i$ as  a Random Variable with a value $f_i$ 

Entropy is
* $H(F_1, \ ... \ , F_M) = - \sum_{f_1}  \ ... \ \sum_{f_M} p(f_1, \ ... \ , f_M) \log p(f_1, \ ... \ , f_M)$

When the data has well-formed clusters, the uncertainty is low so is the entropy.  
* In the real-world data, there are few cases that the clusters are well-formed.
* Two points belonging to the same cluster or 2 different clusters will contribute to the total entropy less that if they were uniformly separated. 
* Similarity $S_{ij}$ between two instances $X_i$ and $X_j$ is high if the 2 instance are very close and $S_{ij}$ is low if the 2 are far away. Entropy $H_{ij}$ will be low if $S_{ij}$ is either high or low, and $H_{ij}$ will be low otherwise.


We can measure the quality of a term $t$ by amount of [[Entropy]] it removes when we prune $t$ 

$$H(t) = \sum_{i = 1}^n \sum_{j = 1}^n \Big[  S_{ij} \log S_{ij} + (1 - S_{ij}) \log (1 - S_{ij}) \Big] $$

where $S_{ij}$ is similarity between documents $i$ and $j$ when feature $f$ is removed 

$$S_{ij} = 2^{-\frac{\text{dist}(i, j)}{\text{avg.dist}}}$$

* $\text{dist}(i, j)$ distance between $i$ and $j$ when $t$ is removed 
* $\text{avg.dist}$ - average distance when 


But it's very slow: $O(n^2)$ for each $t$



== References ==
* Dash, Manoranjan, and Huan Liu. &quot;Feature selection for clustering.&quot; 2000. [http://blog.finsternis.me/attachment/fk12.pdf]

== Sources ==
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. Springer US, 2012. [http://ir.nmu.org.ua/bitstream/handle/123456789/144935/d1784ebed3eab2708026b202b2b65309.pdf?sequence=1#page=90]
* http://cs.gmu.edu/~carlotta/teaching/INFS-795-s05/readings/INFS795_MCayci.ppt


[[Category:Dimensionality Reduction]]
[[Category:Document Clustering]]</text>
      <sha1>6c5lrwmkdxt8y8v7yk5mu4ps5kinnmv</sha1>
    </revision>
  </page>
  <page>
    <title>Chi-Squared Ranking</title>
    <ns>0</ns>
    <id>617</id>
    <revision>
      <id>620</id>
      <timestamp>2015-05-02T06:30:30Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="538">{{ stub }}

== Chi-Squared Ranking ==
[[Chi-Squared Test of Independence]]


The $\chi^2$ statistics measures the lack of independence between $f$ and $y$ and can be compared to $\chi^2$ with one degree of freedom

it's zero when $f$ and $y$ are independent

$\chi^2$ measures how the results of an observation differs from the result expected according to the null hypothesis 
* lower values indicate less dependency 
* so for $\chi^2$ we want to take biggest values


[[Category:Feature Filtering]]
[[Category:Dimensionality Reduction]]</text>
      <sha1>sr4balbi3ly3mbi3cfje0as7b0702fy</sha1>
    </revision>
  </page>
  <page>
    <title>Curse of Dimensionality</title>
    <ns>0</ns>
    <id>618</id>
    <revision>
      <id>621</id>
      <timestamp>2015-05-02T06:32:06Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1440">== Curse of Dimensionality ==
In high dimensional space distances (esp. [[Euclidean Distance]]) become less meaningful
* distance between each pair of point is almost the same 
* for many data distributions and distances  


$$\lim_{d \to \infty} \frac{\text{dist}_\max - \text{dist}_\min}{\text{dist}_\min} = 0$$


* [[Curse of Dimensionality]] makes similarity functions behave poorly
* [[KNN]] makes less sense
* distances become more uniform as dimensionality grows
* and this makes clustering difficult 

Similarity between two point of high dimensionality can be misleading
* often points may be similar even though they should belong to different clusters 


How to deal?
* [[Dimensionality Reduction]]
* [[Subspace Clustering]]


== Paper ==
* Beyer, Kevin, et al. &quot;When is “nearest neighbor” meaningful?.&quot; 1999. [http://www.loria.fr/~berger/Enseignement/Master2/Exposes/beyer.pdf]
* Kriegel, Hans-Peter, Peer Kröger, and Arthur Zimek. &quot;Clustering high-dimensional data: A survey on subspace clustering, pattern-based clustering, and correlation clustering.&quot; (2009) 

== Sources ==
* http://en.wikipedia.org/wiki/Curse_of_dimensionality
* http://en.wikipedia.org/wiki/Clustering_high-dimensional_data
* Ertöz, Levent, Michael Steinbach, and Vipin Kumar. &quot;Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data.&quot; 2003. [http://static.msi.umn.edu/rreports/2003/73.pdf]

[[Category:Distances]]</text>
      <sha1>gpp2ctm6fvj2kaciuq8ftd73xcalbvm</sha1>
    </revision>
    <revision>
      <id>769</id>
      <parentid>621</parentid>
      <timestamp>2017-04-27T20:13:16Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2054">
== Curse of Dimensionality ==
In high dimensional space distances (esp. [[Euclidean Distance]]) become less meaningful
* distance between each pair of point is almost the same 
* for many data distributions and distances  


$$\lim_{d \to \infty} \frac{\text{dist}_\max - \text{dist}_\min}{\text{dist}_\min} = 0$$


* [[Curse of Dimensionality]] makes similarity functions behave poorly
* [[KNN]] makes less sense
* distances become more uniform as dimensionality grows
* and this makes clustering difficult 

Similarity between two point of high dimensionality can be misleading
* often points may be similar even though they should belong to different clusters 


How to deal?
* [[Dimensionality Reduction]]
* [[Subspace Clustering]]

==  NLP and Embeddings ==
* Suppose we want to make a [[Language Model]]
* How to model the [[Joint Distribution]] between many [[Discrete Random Variables]]?
** e.g. words in a sentence
** 10 constitutive words in a language with vocabulary 100k - then there are $100\, 000^10 -1 = 10^{50} - 1$ free parameters 

solution: [[Word Embeddings]]
* embed the words into some dense low-dimensional space 
* express the join distribution in terms of these embeddings


== Papers ==
* Beyer, Kevin, et al. &quot;When is “nearest neighbor” meaningful?.&quot; 1999. [http://www.loria.fr/~berger/Enseignement/Master2/Exposes/beyer.pdf]
* Kriegel, Hans-Peter, Peer Kröger, and Arthur Zimek. &quot;Clustering high-dimensional data: A survey on subspace clustering, pattern-based clustering, and correlation clustering.&quot; (2009) 


== Sources ==
* http://en.wikipedia.org/wiki/Curse_of_dimensionality
* http://en.wikipedia.org/wiki/Clustering_high-dimensional_data
* Ertöz, Levent, Michael Steinbach, and Vipin Kumar. &quot;Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data.&quot; 2003. [http://static.msi.umn.edu/rreports/2003/73.pdf]
* Bengio, Yoshua. &quot;A neural probabilistic language model.&quot;. 2003. [http://www.iro.umontreal.ca/~lisa/publications2/index.php/attachments/single/74]

[[Category:Distances]]</text>
      <sha1>9l5vx2q4930l1xlil4fjx7s496wbz3y</sha1>
    </revision>
  </page>
  <page>
    <title>Semantic Domains in Computational Linguistics (book)</title>
    <ns>0</ns>
    <id>619</id>
    <revision>
      <id>622</id>
      <timestamp>2015-05-07T15:42:13Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="430">== Semantic Domains in Computational Linguistics ==

http://ecx.images-amazon.com/images/I/41R5wnsvR4L._SY344_BO1,204,203,200_.jpg


* 2009
* by Alfio Gliozzo, Carlo Strapparava 
* Downloadable from Springer Link [http://link.springer.com/book/10.1007%2F978-3-540-68158-8]



=== Content ===
* [[Computational Linguistics]]
* [[Vector Space Models]]
* [[Semantic Domains]]



[[Category:Books]]
[[Category:Notes]]
[[Category:NLP]]</text>
      <sha1>qgfacu2j2vd90jc3zujq6ewohr6rzo2</sha1>
    </revision>
  </page>
  <page>
    <title>Computational Linguistics</title>
    <ns>0</ns>
    <id>620</id>
    <revision>
      <id>623</id>
      <timestamp>2015-05-07T15:45:41Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1079">== Computational Linguistics ==
Computational linguistics (CL) is a discipline between linguistics and computer science which is concerned with the computational aspects of the human language faculty. 
* It belongs to the cognitive sciences and overlaps with the field of [[Artificial intelligence]]
* Computational linguistics has applied and theoretical components.


What's the difference between [[NLP]] and Computational Linguistics?

CL:
* using computers for linguistic theory
* CL is a branch of Linguistics


NLP
* engineering a text processing application to solve particular task for particular reason
* NLP is a branch of [[Machine Learning]], [[Statistics]] and engineering
* usually follows empirical approaches: collecting and analyzing lots of text data
* usually they are Shallow Models (see [[Linguistic Models]])



== Sources ==
* http://www.coli.uni-saarland.de/~hansu/what_is_cl.html
* http://en.wikipedia.org/wiki/Computational_linguistics
* [[Semantic Domains in Computational Linguistics (book)]]


[[Category:NLP]]
[[Category:Computational Linguistics]]</text>
      <sha1>nuxfpswu1n03ny1rtod7j5n3fmck6qj</sha1>
    </revision>
  </page>
  <page>
    <title>Linguistic Models</title>
    <ns>0</ns>
    <id>621</id>
    <revision>
      <id>624</id>
      <timestamp>2015-05-07T15:46:55Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="866">== Linguistic Models ==
A natural language consists of two parts:
* lexicon: vocabulary of the language
* grammar: set of rules to combine words from the lexicon in a meaningful way


=== Shallow Model ===
[[Machine Learning]] techniques in [[NLP]] are usually shallow
* don't care much about grammar


Shallow Parsing:
* JMLR Special Issue on Shallow Parsing [http://www.jmlr.org/papers/special/shallow_parsing02.html]
* Machine Learning Approaches to Shallow Parsing [http://www.jmlr.org/papers/v2/hammerton02a.html]


=== Deep Model ===
* Deep linguistic processing is a natural language processing framework which draws on theoretical and descriptive linguistics. 
* It models language predominantly by way of theoretical syntactic/semantic theory


== Sources ==
* http://en.wikipedia.org/wiki/Deep_linguistic_processing


[[Category:Computational Linguistics]]</text>
      <sha1>2khxyh0yqnlr6bamuniaaqgs0e0pj3z</sha1>
    </revision>
  </page>
  <page>
    <title>Gram Matrices</title>
    <ns>0</ns>
    <id>622</id>
    <revision>
      <id>625</id>
      <timestamp>2015-05-08T18:48:51Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4326">== Gram Matrices ==
A Gram matrix of vectors $\mathbf a_1 , \ ... \ , \mathbf a_n$ is a matrix $G$ 
* s.t. $G = \langle \mathbf a_i, \mathbf a_j \rangle$ for all $i,j$
* if vectors $\mathbf a_1 , \ ... \ , \mathbf a_n$ are columns of a matrix $A$, then 
* $G = A^T A$ 
* a Gram matrix is  [[Positive-Definite Matrices|Positive Definite]] and [[Symmetric Matrices|Symmetric]] 
* if vectors $\mathbf a_1 , \ ... \ , \mathbf a_n$ are the rows of $A$ ($A$ would be so-called &quot;Data Matrix&quot;), then $G = A A^T$, and it's called left Gram matrix


=== Notation ===
* let $C(A)$ be the [[Column Space]] and $R(A)$ the [[Row Space]]


== [[Symmetric Matrices]] ==
Let's consider a rectangular $m \times n$ matrix $A$
* $A^T A$ is always symmetric:
* $(A^T A)^T = A^T (A^T)^T = A^T A$
* $A A^T$ is also symmetric
* $(A A^T)^T = (A^T)^T A^T = A A^T$

This is used for [[Singular Value Decomposition]]


== [[Four Fundamental Subspaces]] ==
=== [[Nullspace]] ===
Let $A$ be any matrix. Let's show that $N(A^T A) = N(A)$
* we will show that $\forall \mathbf x: \mathbf x \in N(A) \iff \mathbf x \in N(A^T A)$


$\mathbf x \in N(A) \Rightarrow \mathbf x \in N(A^T A)$ case
* if $\mathbf x \in N(A)$ $\Rightarrow$ 
* $A \mathbf x = \mathbf 0$ multiply by $A^T$: 
* $(A^T A) \mathbf x = \mathbf 0$
* so $\mathbf x \in N(A^T A)$ as well


$\mathbf x \in N(A^T A) \Rightarrow \mathbf x \in N(A)$ case
* $A^T A \mathbf x = \mathbf 0$, want to show that $A \mathbf x = \mathbf 0$
* can't multiply by $(A^T)^{-1}$ - it doesn't exist
* multiply by $\mathbf x^T$ instead:
* $\mathbf x^T A^T A \mathbf x = \mathbf x^T \mathbf 0 = 0$
* $(A \mathbf x)^T A \mathbf x = 0$
* $\| A \mathbf x \|^2 = 0$
* so the length of vector $A \mathbf x$ is 0 - it's true only when $A \mathbf x = \mathbf 0$


So $N(A) = N(A^T A)$

$\square$



=== Row Space and Column Space ===
* we know that $C(A^T A) \subseteq C(A^T) = R(A)$ (see [[Matrix Multiplication#Properties]])
* and $R(A^T A) \subseteq R(A)$
* $\text{rank}(A^T A) = \text{rank}(A)$ (see below)
* so $C(A^T A) = R(A^T A) = R(A)$


The same reasoning can be applied to $A A^T$:
* $C(A A^T) = R(A A^T) = C(A)$



== Other Properties ==
=== [[Rank (Matrix)|Rank]] ===
Consequence: 
* by the [[Rank-Nullity Theorem]], we know that for $m \times n$ matrix $A$, $\text{rank }A + \text{dim } N(A) = n$
* $A^T A$ is an $n \times n$ matrix, so $\text{rank } A^T A + \text{dim } N(A^T A) = \text{rank } A^T A + \text{dim } N(A) = n$
* so $\text{rank }A = \text{rank }A^T A = n - \text{dim } N(A)$



=== Invertability ===
Theorem: $A^T A$ is invertible if and only if $A$ has linearly independent columns
* $A$ is invertible when $A$ has independent columns
* i.e. $N(A) = \{ \mathbf 0 \}$
* so if $N(A) = \{ \mathbf 0 \}$, then $A^T A$ is square, symmetric and invertible


=== [[Positive-Definite Matrices|Semi-Positive Definiteness]] ===
Check: Let $R$ be an $n \times m$ matrix
* let $A = R^T R$, it's square and symmetric
* $A$ is PDM:
* $\mathbf v^T A \mathbf v = \mathbf v^T R^T R \, \mathbf v = (R \, \mathbf v)^T R \, \mathbf v = \| R \, \mathbf v \|^2 &gt; 0$ 
* if $\mathbf v \ne \mathbf 0$ - and it's the case when columns of $R$ are linearly independent 
* see the theorem in [[Projection onto Subspaces#Theorem:_.24A.5ET_A.24_is_Invertible|Projection onto Subspaces]]
* If some columns of $R$ are linearly dependent, then still $R^T R$ is semi-positive, with some eigenvalues equal to 0


Let's check $R R^T$:
* $\mathbf v^T R R^T \mathbf v = \| R^T \mathbf v \|^2$
* it's always non negative


Also can see that both $R^T R$ and $R R^T$ have non-negative eigenvalues:
* let $\mathbf v$ be eigenvector of $R^T R$ with eigenvalue $\lambda$
* then $\| R \mathbf v \|^2 = (R \mathbf v)^2 R \mathbf v = \mathbf v^T \underbrace{R^T R \mathbf v}_{\lambda \mathbf v} = \lambda \mathbf v^T \mathbf v = \lambda \| \mathbf v \|^2$
* so $\| R \mathbf v \|^2 = \lambda \| \mathbf v \|^2$. Lengths are always positive, so $\lambda$ must be non-negative
* can see the same for $RR^T$: if $\mathbf u$ is its eigenvector and $\lambda$ is eigenvalue, then
* $\| R^T \mathbf u \|^2 = \lambda \| \mathbf u \|^2$



== Sources ==
* other inner-wiki pages
* http://en.wikipedia.org/wiki/Gramian_matrix
* http://en.wikipedia.org/wiki/Rank%E2%80%93nullity_theorem
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>erg5jcb4wrjywhtma3tujqp0nieir0g</sha1>
    </revision>
  </page>
  <page>
    <title>Power Iteration</title>
    <ns>0</ns>
    <id>623</id>
    <revision>
      <id>626</id>
      <timestamp>2015-05-08T19:20:36Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2629">== Power Iteration ==
This is a linear algebra method for computing [[Eigenvalues and Eigenvectors]]


== Symmetric Matrices ==
Suppose $A$ is symmetric
* then [[Eigendecomposition]] of $A$ is $A = Q \Lambda Q^T$ 
* and $A^k = Q \Lambda^k Q^T$
* let $\mathbf q_i$ be the columns of $Q$

When $k \to \infty$
* suppose $\lambda_1 &gt; \lambda_2$, 
* then, as $k$ increases, $\lambda_1^k / \lambda_i^k \to 0$ for $i \geqslant 2$ 
* so $A^k \to \lambda_1^k \mathbf q_1 \mathbf q_1^T$
* so we can find $\lambda_1$ by powering $A$ 


Performance:
* computing $A \cdot A^{k-1}$ is costly
* instead, can compute $A \, A^{k-1} \mathbf x$ where $\mathbf x$ is some random unit vector
* $A^k \mathbf x \approx \lambda_1^k \, \mathbf q_1 \, (\mathbf q_1^T \mathbf x) = \alpha \cdot \mathbf q_1$
* so it's some scalar times a unit vector $\mathbf q_1$
* thus, to recover $\mathbf q_i$, use $A^k \mathbf x / \| A^k \mathbf x \| = \mathbf q_i$


== Finding Other Eigenvectors ==
* $A = Q \Lambda Q^T$, so $A = \sum_{i = 1}^n \lambda_i \mathbf q_i \mathbf q_i^T$
* use power iteration to find $\mathbf q_1$ and $\lambda_1$
* then let $A_2 \leftarrow A - \lambda_1 \mathbf q_1 \mathbf q_1^T$ 
* repeat power iteration on $A_2$ to find $\mathbf q_2$ and $\lambda_2$
* continue like this for $\lambda_3, \ ... \ , \lambda_n$



== Issues ==
* if $\lambda_1 - \lambda_2 \gg 0$, then it's fine, but if $\lambda_1 - \lambda_2$ is small, it will take a lot of time to converge


== Implementation ==
=== NumPy ===
&lt;pre&gt;
def eigenvalue(S, w):
    return w.T.dot(S).dot(w)

def power_iteration(X, debug=True):
    n, d = X.shape
    converged = False

    S = X.T.dot(X)
    w = np.ones(d) / np.sqrt(d)
    error = eigenvalue(S, w)

    while not converged:
        Sw = S.dot(w)
        w_new = Sw / np.linalg.norm(Sw)

        error_new = eigenvalue(S, w_new)
        converged = np.abs(error - error_new) &lt; 0.01
    
        w = w_new
        error = error_new

    return w
&lt;/pre&gt;


=== Mahout Samsara ===
&lt;pre&gt;
var x: Vector = 1 to dim map (_ =&gt; 1.0 / Math.sqrt(dim))
var converged = false

while (!converged) {
  val Ax = A %*% x
  var x_new = Ax.collect(::, 0)
  x_new = x_new / x_new.norm(2)

  val diff = (x_new - x).norm(2)
  converged = diff &lt; 1e-6
  x = x_new
}
&lt;/pre&gt;


== Applications ==
* [[Principal Component Analysis]]
* [[Stochastic Matrices]] and [[PageRank]]


== Sources ==
* Hopcroft, John, and Ravindran Kannan. &quot;Foundations of Data Science1.&quot; (2014) [http://research.microsoft.com/en-US/people/kannan/book-mar-30-2014.pdf]
* [[Machine Learning 1 (TUB)]]

[[Category:Linear Algebra]]
[[Category:Python]]
[[Category:Machine Learning]]</text>
      <sha1>7g750j8qt9m9boxufx4gic4k3b5w9ka</sha1>
    </revision>
    <revision>
      <id>779</id>
      <parentid>626</parentid>
      <timestamp>2017-06-22T14:46:32Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6746">== Power Iteration ==
Power Iteration is a [[Linear Algebra]] method for approximating the dominant [[Eigenvalues and Eigenvectors]] of a matrix 

Suppose $A$ is symmetric
* then [[Eigendecomposition]] of $A$ is $A = Q \Lambda Q^T$ 
* and $A^k = Q \Lambda^k Q^T$
* let $\mathbf q_i$ be the columns of $Q$

Dominant eigenvalues and eigenvectors
* $\lambda_1$ is the dominant eigenvalue of $A$ if $|\lambda_1| &gt; |\lambda_i|$ for all $i = 2, ...$
* The corresponding eigenvector $\mathbf q_1$ is also called dominant


=== The Power Method ===
Algorithm
* initial approximation - random unit vector $x_0$
* $x_1 = A x_0$
* $x_2 = A A x_0 = A^2 x_0$
* $x_3 = A A A x_0 = A^3 x_0$
* ...
* until converges

For large powers of $k$, we will obrain a good approximation of the dominant eigenvector


Finding the eigenvalue:
* if $v$ is an eigenvector of $A$, then its eigenvalue is 
* $\lambda = \cfrac{v^T A^T v}{v^T v} = \cfrac{(A v)^T v}{v^T v}$
* This is called [[Rayleigh Quotent]] 
* proof: suppose $\lambda$ is eigenvalue of $A$ and $v$ is its eigenvector
* $\cfrac{(A v)^T v}{v^T v} = \cfrac{\lambda \, v^T v}{v^T v} = \lambda$


Performance:
* computing $A \cdot A^{k-1}$ is costly
* go the other direction: 
* use recurrent relation $x_{k} = A x_{k-1}$


if the power method generates a good approximation of the eigenvector, the approximation of the eigenvalue is also good


=== Normalization ===
The values produced by the power method are quite large:
* better if we scale them down 
* should scale the values at each iteartion
* for example, can find the largest component of $x_k$ and divide by it
* more commonly, we just unit-normalize it


=== Implementation ===
Python with Numpy:

 def eigenvalue(A, v):
     Av = A.dot(v)
     return v.dot(Av)
 
 def power_iteration(A):
     n, d = A.shape
 
     v = np.ones(d) / np.sqrt(d)
     ev = eigenvalue(A, v)
 
     while True:
         Av = A.dot(v)
         v_new = Av / np.linalg.norm(Av)
 
         ev_new = eigenvalue(A, v_new)
         if np.abs(ev - ev_new) &lt; 0.01:
             break
 
         v = v_new
         ev = ev_new
 
    return ev_new, v_new


=== Convergence of the Power Method ===
Theorem:
* if $A$ is diagonalizable and has dominant eigenvalue, 
* then power iteration sequence $Ax, A^2 x, A^3 x, ...$ converges to the dominant eigenvector (scaled)

Proof:
* since $A$ is diagonalizable, it has $n$ linearly independent eigenvectors $v_1, ..., v_n$ and corresponding eigenvalues $\lambda_1, ..., \lambda_n$. 
* let $v_1$ and $\lambda_1$ be dominant. 
* because the eigenvectors are independent, they form a basis
** so any vector $x_0$ can be represented as $x_0 = c_1 v_1 + ... + c_n v_n$
** and $c_1$ must be non zero - otherwise $x_0$ is not a good choice, and we need to choose another initial vector
* let's multiply both sides by $A$:
** $A x_0 = c_1 A v_1 + ... + c_n A v_n = c_1 \lambda_1 v_1 + ... + c_n \lambda_n v_n$
* repeat that $k$ times:
** $A^k x_0 = c_1 \lambda_1^k v_1 + ... + c_n \lambda_n^k v_n$
** or $A^k x_0 =  \lambda_1^k \left[ c_1 v_1 + c_2 \left(\cfrac{\lambda_2}{\lambda_1} \right)^k v_2 ... + c_n \left(\cfrac{\lambda_n}{\lambda_1} \right)^k v_n \right]$
* since $\lambda_1$ is dominating, the ratios $\left(\cfrac{\lambda_i}{\lambda_1} \right)^k \to 0$ as $k \to \infty$ for all $i$ 
* so $A^k x_0 =  \lambda_1^k c_1 v_1$ and it gets better as $k$ grows

$\square$


From the proof we can also see that if the ratio $\lambda_2 / \lambda_1$ is small, it will converge quickly, but if it's not - it will take many iterations

Examples:
* &lt;code&gt;A = [4 5; 6 5]&lt;/code&gt; - needs only 6 steps, ratio is 0.1
* &lt;code&gt;A = [-4 10; 7 5]&lt;/code&gt; - needs 68 steps, ratio is 0.9


== Inverse Iteration ==
Inverse iteration - to find the smallest eigenvalue 
http://ranger.uta.edu/~huber/cse4345/Notes/Eigenvalues.pdf


== Finding Other Eigenvectors ==
=== Naive Method ===
We can just remove the dominant direction from the matrix and repeat

So:
* $A = Q \Lambda Q^T$, so $A = \sum_{i = 1}^n \lambda_i \mathbf q_i \mathbf q_i^T$
* use power iteration to find $\mathbf q_1$ and $\lambda_1$
* then let $A_2 \leftarrow A - \lambda_1 \mathbf q_1 \mathbf q_1^T$ 
* repeat power iteration on $A_2$ to find $\mathbf q_2$ and $\lambda_2$
* continue like this for $\lambda_3, \ ... \ , \lambda_n$


=== Orthogonal Iteration ===
Orthogonal Iteration is a block version of the Power Method, also sometimes called &quot;Simultaneous (Power) Interation&quot;
* Instead of multiplying $A$ by just one vector, we multiply by multiple vectors $\{ q_1, ... q_r \}$, which we put in a matrix $Q$.
* At each step we re-normalize the vectors, e.g. with [[QR Decomposition]]

Algorithm:

* choose $Q_0$ such that $Q_0^T Q_0 = I$
* for $k = 1, 2, ...$:
** $Z_k = A Q_{k-1}$
** $Q_k R_k = Z_k$ (QR decomposition)


Let's look at the sequence of $\{ R_k \}$:
* $R_k = Q_k^T Z_k = Q_k^T A Q_{k - 1}$
* if $\{ Q_k \}$ converges to some $Q$ then $Q^T A Q = R$ is upper triangular 
* This is a [[Schur Decomposition]] of $A$
* Thus, the eigenvalues of $A$ are located on the main diagonal of $R$ 
* And the columns of $Q$ are the eigenvectors


=== Implementation ===

 def simultaneous_power_iteration(A, k):
     n, m = A.shape
     Q = np.random.rand(n, k)
     Q, _ = np.linalg.qr(Q)
     Q_prev = Q
  
    for i in range(1000):
         Z = A.dot(Q)
         Q, R = np.linalg.qr(Z)
 
         err = ((Q - Q_prev) ** 2).sum()
         if i % 10 == 0:
             print(i, err)
 
         Q_prev = Q
         if err &lt; 1e-3:
             break
 
     ev = np.diag(R)
     # or: ev = (A.dot(Q) * Q).sum(axis=0)
     return ev, Q


=== Deflation ===
TODO: 
Power method can be modified to approximate other eigenvalues using &quot;deflation&quot;. 
Deflation - by performing a [[Householder Tranformation]]


== Algorithms based on Power Iteration ==
=== Applications ===
* [[Principal Component Analysis]]
* [[Stochastic Matrices]] and [[PageRank]]

=== [[QR Algorithm]] ===
Simultaneous Iteration typically takes a while to converge 
* Another, better way to do it is QR algorithm.

=== [[Lanczos Algorithm]] ===
Lanczos algorithm is used for tridiagonalization of a matrix $A$
* It's based on the power iteration algorithm 
* And can be used to find eigenvalues and eigenvectors


== Sources ==
* [[Machine Learning 1 (TUB)]]
* Hopcroft, John, and Ravindran Kannan. &quot;Foundations of Data Science1.&quot; (2014) [http://research.microsoft.com/en-US/people/kannan/book-mar-30-2014.pdf]
* https://www2.math.ethz.ch/education/bachelor/seminars/fs2008/nas/grasic.pdf
* http://college.cengage.com/mathematics/larson/elementary_linear/5e/students/ch08-10/chap_10_3.pdf
* http://www.math.usm.edu/lambers/mat610/sum10/lecture14.pdf

[[Category:Linear Algebra]]
[[Category:Python]]
[[Category:Machine Learning]]</text>
      <sha1>egj0td7ixfdafy561nmkutni4xukx4m</sha1>
    </revision>
    <revision>
      <id>784</id>
      <parentid>779</parentid>
      <timestamp>2017-06-26T15:26:31Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7910">== Power Iteration ==
Power Iteration is a [[Linear Algebra]] method for approximating the dominant [[Eigenvalues and Eigenvectors]] of a matrix 

Suppose $A$ is symmetric
* then [[Eigendecomposition]] of $A$ is $A = Q \Lambda Q^T$ 
* and $A^k = Q \Lambda^k Q^T$
* let $\mathbf q_i$ be the columns of $Q$

Dominant eigenvalues and eigenvectors
* $\lambda_1$ is the dominant eigenvalue of $A$ if $|\lambda_1| &gt; |\lambda_i|$ for all $i = 2, ...$
* The corresponding eigenvector $\mathbf q_1$ is also called dominant


=== The Power Method ===
Algorithm
* initial approximation - random unit vector $x_0$
* $x_1 = A x_0$
* $x_2 = A A x_0 = A^2 x_0$
* $x_3 = A A A x_0 = A^3 x_0$
* ...
* until converges

For large powers of $k$, we will obrain a good approximation of the dominant eigenvector


Finding the eigenvalue:
* if $v$ is an eigenvector of $A$, then its eigenvalue is 
* $\lambda = \cfrac{v^T A^T v}{v^T v} = \cfrac{(A v)^T v}{v^T v}$
* This is called [[Rayleigh Quotent]] 
* proof: suppose $\lambda$ is eigenvalue of $A$ and $v$ is its eigenvector
* $\cfrac{(A v)^T v}{v^T v} = \cfrac{\lambda \, v^T v}{v^T v} = \lambda$


Performance:
* computing $A \cdot A^{k-1}$ is costly
* go the other direction: 
* use recurrent relation $x_{k} = A x_{k-1}$


if the power method generates a good approximation of the eigenvector, the approximation of the eigenvalue is also good


=== Normalization ===
The values produced by the power method are quite large:
* better if we scale them down 
* should scale the values at each iteartion
* for example, can find the largest component of $x_k$ and divide by it
* more commonly, we just unit-normalize it


=== Implementation ===
Python with Numpy:

 def eigenvalue(A, v):
     Av = A.dot(v)
     return v.dot(Av)
 
 def power_iteration(A):
     n, d = A.shape
 
     v = np.ones(d) / np.sqrt(d)
     ev = eigenvalue(A, v)
 
     while True:
         Av = A.dot(v)
         v_new = Av / np.linalg.norm(Av)
 
         ev_new = eigenvalue(A, v_new)
         if np.abs(ev - ev_new) &lt; 0.01:
             break
 
         v = v_new
         ev = ev_new
 
    return ev_new, v_new


=== Convergence of the Power Method ===
Theorem:
* if $A$ is diagonalizable and has dominant eigenvalue, 
* then power iteration sequence $Ax, A^2 x, A^3 x, ...$ converges to the dominant eigenvector (scaled)

Proof:
* since $A$ is diagonalizable, it has $n$ linearly independent eigenvectors $v_1, ..., v_n$ and corresponding eigenvalues $\lambda_1, ..., \lambda_n$. 
* let $v_1$ and $\lambda_1$ be dominant. 
* because the eigenvectors are independent, they form a basis
** so any vector $x_0$ can be represented as $x_0 = c_1 v_1 + ... + c_n v_n$
** and $c_1$ must be non zero - otherwise $x_0$ is not a good choice, and we need to choose another initial vector
* let's multiply both sides by $A$:
** $A x_0 = c_1 A v_1 + ... + c_n A v_n = c_1 \lambda_1 v_1 + ... + c_n \lambda_n v_n$
* repeat that $k$ times:
** $A^k x_0 = c_1 \lambda_1^k v_1 + ... + c_n \lambda_n^k v_n$
** or $A^k x_0 =  \lambda_1^k \left[ c_1 v_1 + c_2 \left(\cfrac{\lambda_2}{\lambda_1} \right)^k v_2 ... + c_n \left(\cfrac{\lambda_n}{\lambda_1} \right)^k v_n \right]$
* since $\lambda_1$ is dominating, the ratios $\left(\cfrac{\lambda_i}{\lambda_1} \right)^k \to 0$ as $k \to \infty$ for all $i$ 
* so $A^k x_0 =  \lambda_1^k c_1 v_1$ and it gets better as $k$ grows

$\square$


From the proof we can also see that if the ratio $\lambda_2 / \lambda_1$ is small, it will converge quickly, but if it's not - it will take many iterations

Examples:
* &lt;code&gt;A = [4 5; 6 5]&lt;/code&gt; - needs only 6 steps, ratio is 0.1
* &lt;code&gt;A = [-4 10; 7 5]&lt;/code&gt; - needs 68 steps, ratio is 0.9


== Finding Other Eigenvectors ==
=== Naive Method ===
We can just remove the dominant direction from the matrix and repeat

So:
* $A = Q \Lambda Q^T$, so $A = \sum_{i = 1}^n \lambda_i \mathbf q_i \mathbf q_i^T$
* use power iteration to find $\mathbf q_1$ and $\lambda_1$
* then let $A_2 \leftarrow A - \lambda_1 \mathbf q_1 \mathbf q_1^T$ 
* repeat power iteration on $A_2$ to find $\mathbf q_2$ and $\lambda_2$
* continue like this for $\lambda_3, \ ... \ , \lambda_n$


=== Inverse Iteration ===
Inverse iteration - to find the smallest eigenvalue 
http://ranger.uta.edu/~huber/cse4345/Notes/Eigenvalues.pdf


=== Shifts ===
We can focus at any other eigenvalue by shifting our matrix
* ''Shifting'' is the procedure of adding some value $s$ to the main diagonal: $A + s I$
* let $\mu$ be the smallest ev of the shifted $A$
** i.e. $(A + s I) \mathbf x = \mu \mathbf x$
** or $(A + s I) \mathbf x - \mu \mathbf x = (A + s I - \mu I) \mathbf x = 0$
** and the matrix $A + s I - \mu I$ is singular
* since $A + s I - \mu I$ is singular, $\lambda = \mu - s$ is the eigenvalue of $A$ and it's the value closest to $s$ 
* So shifting allows to focus on eigenvalues closest to any particular value 


Eigenvectors are not affected by shifts:
* suppose $A \mathbf x = \lambda \mathbf x$
* let's shift by $m$: $(A + m I) \mathbf x = A \mathbf x + m \mathbf x = \lambda \mathbf x + m \mathbf x = (\lambda + m) \mathbf x$
* for the shifted $A$, the eigenvalue is $\lambda + m$, and the eigenvector stays the same



=== Orthogonal Iteration ===
Idea:
* we know that other eigenvectors are orthogonal to the dominant one
* so we can use the power method, and force that the second vector is orthogonal to the first one 
* this way we guarante that they will converge to two different eigenvectors
* we can do this for many vectors, not just two
* this is called &quot;Orthogonal Iteration&quot;

Orthogonal Iteration
* Orthogonal Iteration is a block version of the Power Method, also sometimes called &quot;Simultaneous (Power) Interation&quot;
* Instead of multiplying $A$ by just one vector, we multiply by multiple vectors $\{ q_1, ... q_r \}$, which we put in a matrix $Q$.
* At each step we re-normalize the vectors, e.g. with [[QR Decomposition]]


Algorithm:
* choose $Q_0$ such that $Q_0^T Q_0 = I$
* for $k = 1, 2, ...$:
** $Z_k = A Q_{k-1}$
** $Q_k R_k = Z_k$ (QR decomposition)


Let's look at the sequence of $\{ R_k \}$:
* $R_k = Q_k^T Z_k = Q_k^T A Q_{k - 1}$
* if $\{ Q_k \}$ converges to some $Q$ then $Q^T A Q = R$ is upper triangular 
* This is a [[Schur Decomposition]] of $A$
* Thus, the eigenvalues of $A$ are located on the main diagonal of $R$ 
* And the columns of $Q$ are the eigenvectors


=== Implementation ===
Python with numpy:

 def simultaneous_power_iteration(A, k):
     n, m = A.shape
     Q = np.random.rand(n, k)
     Q, _ = np.linalg.qr(Q)
     Q_prev = Q
  
     for i in range(1000):
         Z = A.dot(Q)
         Q, R = np.linalg.qr(Z)
 
         # can use other stopping criteria as well 
         err = ((Q - Q_prev) ** 2).sum()
         if i % 10 == 0:
             print(i, err)
 
         Q_prev = Q
         if err &lt; 1e-3:
             break
 
     return np.diag(R), Q



== Algorithms based on Power Iteration ==
=== [[QR Algorithm]] ===
Simultaneous Iteration typically takes a while to converge 
* Another, better way to do it is QR algorithm.
* It's based on Simultaneous Iteration algorithm 


=== [[Lanczos Algorithm]] ===
Lanczos algorithm is used for tridiagonalization of a matrix $A$
* It's based on the power iteration algorithm 
* And can be used to find eigenvalues and eigenvectors


=== Applications ===
* [[Principal Component Analysis]]
* [[Stochastic Matrices]] and [[PageRank]]



== Sources ==
* [[Machine Learning 1 (TUB)]]
* Hopcroft, John, and Ravindran Kannan. &quot;Foundations of Data Science1.&quot; (2014) [http://research.microsoft.com/en-US/people/kannan/book-mar-30-2014.pdf]
* https://www2.math.ethz.ch/education/bachelor/seminars/fs2008/nas/grasic.pdf
* http://college.cengage.com/mathematics/larson/elementary_linear/5e/students/ch08-10/chap_10_3.pdf
* http://www.math.usm.edu/lambers/mat610/sum10/lecture14.pdf

[[Category:Linear Algebra]]
[[Category:Python]]
[[Category:Machine Learning]]</text>
      <sha1>84i5cxympm3x8qrvhiabmbjilfh6fh7</sha1>
    </revision>
  </page>
  <page>
    <title>Matrix-Vector Multiplication</title>
    <ns>0</ns>
    <id>624</id>
    <revision>
      <id>627</id>
      <timestamp>2015-05-08T19:58:20Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2537">== Matrix-Vector Multiplication ==
Suppose we have an $m \times n$ matrix $A$ and $n$-vector $\mathbf b$
* How to calculate $\mathbf x = A \mathbf b$?
* note that $\mathbf x \in \mathbb R^m$ 

There are two equivalent ways to do it:
* Row at a time
* Column at a time 


=== Row at a Time ===
See $A$ as $m$ vectors along rows:

$A = \begin{bmatrix}
— \mathbf a_1 \,— \\ 
— \mathbf a_2 \,— \\ 
 ...   \\ 
— \mathbf a_m \,— 
\end{bmatrix}$

And then multiply (using [[Dot Product]]) each row $(\mathbf a_i)^T$ with the vector $\bf x$:
* $x_i = (\mathbf a_i)^T \mathbf b$
* $\mathbf x = \begin{bmatrix}
— (\mathbf a_1)^T \mathbf b \,— \\ 
— (\mathbf a_2)^T \mathbf b \,— \\ 
 ...   \\ 
— (\mathbf a_m)^T \mathbf b \,— 
\end{bmatrix}$
* Where dot product is $\mathbf a^T \mathbf b = \sum\limits_{i=1}^m a_i b_i$


=== Column at a Time ===
Another way to see $A$ is as $n$ vectors along columns:

$A = \begin{bmatrix}
\mathop{a_1}\limits_|^| \ \mathop{a_2}\limits_|^| \ \cdots \  \mathop{a_n}\limits_|^| 
\end{bmatrix}$

When we multiply $A$ on a vector $\mathbf b$, it produces a [[Linear Combination]] of these column vectors: 

$A \mathbf b = \begin{bmatrix}
\mathop{a_1}\limits_|^| \ \mathop{a_2}\limits_|^| \ \cdots \ \mathop{a_n}\limits_|^| 
\end{bmatrix} \mathbf b = 
  b_1 \begin{bmatrix} \mathop{a_1}\limits_|^| \end{bmatrix} 
+ b_2 \begin{bmatrix} \mathop{a_2}\limits_|^| \end{bmatrix} + \cdots	
+ \ b_n \begin{bmatrix} \mathop{a_n}\limits_|^| \end{bmatrix}$


=== Example ===
$\begin{bmatrix}
2 &amp; 5\\ 
1 &amp; 3
\end{bmatrix} \cdot \begin{bmatrix}
1 \\
2
\end{bmatrix} $


Row at a time: 
* $[2 \ 5] \begin{bmatrix}
1 \\
2
\end{bmatrix} = 2 \cdot 1 + 5 \cdot 2 = 12$
* $[1 \ 3] \begin{bmatrix}
1 \\
2
\end{bmatrix} = 1 \cdot 1 + 3 \cdot 2 = 7$
* so $\begin{bmatrix}
2 &amp; 5\\ 
1 &amp; 3
\end{bmatrix} \cdot \begin{bmatrix}
1 \\
2
\end{bmatrix} = \begin{bmatrix}
12 \\
7
\end{bmatrix}$


Column at a time
* $1 \begin{bmatrix}
2 \\
1
\end{bmatrix} + 2 \begin{bmatrix}
5 \\
3
\end{bmatrix} = \begin{bmatrix}
12 \\
7
\end{bmatrix}$


=== Left Vector Multiplication ===
A vector may be on the left of the matrix as well
* in such case $\mathbf b$ is a row vector, and thus the result $\mathbf x$ is as well a row vector
* let $\mathbf b \in \mathbb R^{m}$ and $A \in \mathbb{R}^{m \times n}$
* $\mathbf b^T A = \mathbf x^T$
* Can transpose both parts and get $A^T \mathbf b  = \mathbf x$
* and we're back to the normal column-vector case 



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>smctobe6gfy44ti6obj2i04ws4hbc6p</sha1>
    </revision>
    <revision>
      <id>825</id>
      <parentid>627</parentid>
      <timestamp>2020-01-24T10:14:00Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2612">== Matrix-Vector Multiplication ==
Suppose we have an $m \times n$ matrix $A$ and $n$-vector $\mathbf b$
* How to calculate $\mathbf x = A \mathbf b$?
* note that $\mathbf x \in \mathbb R^m$ 

There are two equivalent ways to do it:
* Row at a time
* Column at a time 


=== Row at a Time ===
See $A$ as $m$ vectors along rows:

&lt;math&gt;A = \begin{bmatrix}
— \mathbf a_1 \,— \\ 
— \mathbf a_2 \,— \\ 
 ...   \\ 
— \mathbf a_m \,— 
\end{bmatrix}&lt;/math&gt;

And then multiply (using [[Dot Product]]) each row $(\mathbf a_i)^T$ with the vector $\bf x$:
* $x_i = (\mathbf a_i)^T \mathbf b$
* &lt;math&gt;\mathbf x = \begin{bmatrix}
— (\mathbf a_1)^T \mathbf b \,— \\ 
— (\mathbf a_2)^T \mathbf b \,— \\ 
 ...   \\ 
— (\mathbf a_m)^T \mathbf b \,— 
\end{bmatrix}&lt;/math&gt;
* Where dot product is $\mathbf a^T \mathbf b = \sum\limits_{i=1}^m a_i b_i$


=== Column at a Time ===
Another way to see $A$ is as $n$ vectors along columns:

&lt;math&gt;A = \begin{bmatrix}
\mathop{a_1}\limits_|^| \ \mathop{a_2}\limits_|^| \ \cdots \  \mathop{a_n}\limits_|^| 
\end{bmatrix}&lt;/math&gt;

When we multiply $A$ on a vector $\mathbf b$, it produces a [[Linear Combination]] of these column vectors: 

&lt;math&gt;A \mathbf b = \begin{bmatrix}
\mathop{a_1}\limits_|^| \ \mathop{a_2}\limits_|^| \ \cdots \ \mathop{a_n}\limits_|^| 
\end{bmatrix} \mathbf b = 
  b_1 \begin{bmatrix} \mathop{a_1}\limits_|^| \end{bmatrix} 
+ b_2 \begin{bmatrix} \mathop{a_2}\limits_|^| \end{bmatrix} + \cdots	
+ \ b_n \begin{bmatrix} \mathop{a_n}\limits_|^| \end{bmatrix}&lt;/math&gt;


=== Example ===
&lt;math&gt;\begin{bmatrix}
2 &amp; 5\\ 
1 &amp; 3
\end{bmatrix} \cdot \begin{bmatrix}
1 \\
2
\end{bmatrix}&lt;/math&gt;

Row at a time: 
* &lt;math&gt;[2 \ 5] \begin{bmatrix}
1 \\
2
\end{bmatrix} = 2 \cdot 1 + 5 \cdot 2 = 12$
* $[1 \ 3] \begin{bmatrix}
1 \\
2
\end{bmatrix} = 1 \cdot 1 + 3 \cdot 2 = 7$
* so $\begin{bmatrix}
2 &amp; 5\\ 
1 &amp; 3
\end{bmatrix} \cdot \begin{bmatrix}
1 \\
2
\end{bmatrix} = \begin{bmatrix}
12 \\
7
\end{bmatrix}&lt;/math&gt;


Column at a time
* &lt;math&gt;1 \begin{bmatrix}
2 \\
1
\end{bmatrix} + 2 \begin{bmatrix}
5 \\
3
\end{bmatrix} = \begin{bmatrix}
12 \\
7
\end{bmatrix}&lt;/math&gt;


=== Left Vector Multiplication ===
A vector may be on the left of the matrix as well
* in such case $\mathbf b$ is a row vector, and thus the result $\mathbf x$ is as well a row vector
* let $\mathbf b \in \mathbb R^{m}$ and $A \in \mathbb{R}^{m \times n}$
* $\mathbf b^T A = \mathbf x^T$
* Can transpose both parts and get $A^T \mathbf b  = \mathbf x$
* and we're back to the normal column-vector case 



== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]

[[Category:Linear Algebra]]</text>
      <sha1>jdz0xba2qrqp3rzkelox3ruswc6sg4h</sha1>
    </revision>
  </page>
  <page>
    <title>Matrix-Matrix Multiplication</title>
    <ns>0</ns>
    <id>625</id>
    <revision>
      <id>628</id>
      <timestamp>2015-05-08T20:05:18Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5382">== Matrix-Matrix Multiplication ==
Suppose we want to multiply $m \times n$ matrix $A$ on $n \times p$ matrix $B$, we get an $m \times p$ matrix $C$


== [[Linear Transformation]] ==
What is matrix-matrix multiplication in terms of Linear Transformations?
* Let $A$ be an $m \times n$ matrix, 
* then there's a linear transformation $T_A \ : \ \mathbb R^n \to \mathbb R^m$: $T_A(\mathbf x) = A \mathbf x$ where $A \mathbf x$ is [[Matrix-Vector Multiplication]]
* now let $B$ be an $n \times k$ matrix, then $T_B \ : \ \mathbb R^m \to \mathbb R^k$: $T_B(\mathbf y) = B \mathbf x$
* what is $T_A \circ T_B$? It's $T_A \circ T_B \ : \ \mathbb R^k \to \mathbb R^m $
* $(T_A \circ T_B)(\mathbf x) = T_A \big( T_B(\mathbf x) \big) = T_A \big( B \mathbf x \big) = A \, B \, \mathbf x$
* $AB$ is matrix-matrix multiplication


== Multiplication ==
We can see matrix by matrix multiplication from 5 different positions:
* row by column multiplication
* column at a time
* row at a time
* as sum of outer products
* block multiplication

All of them are equivalent and lead to the same result


=== Row By Columns ===
This is usual dot product multiplication: 
* for each row of matrix $A$ we calculate a dot product with each column of matrix $B$
* http://habrastorage.org/files/bad/3a8/b38/bad3a8b38db64a918543146979adcea0.png
* $c_{ij} = (\text{row $i$ of $A$})^T \times (\text{col $j$ of $B$}) = \sum\limits_{k=1}^{m} c_{ik} b_{kj}$


=== Column at a Time ===
For each column $\mathbf{b}_j$ of $B$ 
* we multiply each column of $A$ with $\mathbf{b}_j$ - like in column at a time for matrix by vector
* http://habrastorage.org/files/fe8/ffb/fb9/fe8ffbfb9ede4ad18a868024f8e791a1.png
* $\mathbf{c}_j = \begin{bmatrix}
\mathop{a_1}\limits_|^| \ \mathop{a_2}\limits_|^| \ \cdots \  \mathop{a_n}\limits_|^| 
\end{bmatrix} \times \mathbf{b}_j$
* so each $\mathbf{c}_j$ is a combination of columns of $A$


=== Row at a Time ===
For each row $\mathbf{a}^T_i$ of $A$
* multiply $\mathbf{a}^T_i$ with each rows of $B$ - like for left vector multiplication
* http://habrastorage.org/files/9ac/c1a/b9d/9acc1ab9d7784a96b3e42f72fe4f1882.png
* $\mathbf{c}^T_i = \mathbf{a}^T_i \times B$
* Note that we can see this as Column at a Time case, but transposed:
** row at a time in $A\times B = C$ is the same as column at a time in $B^T \times A^T = C^T$


=== Sum of [[Outer Product]]s ===
For $i$ from 1 to $n$, 
* multiply column of $A$ $\mathbf{a}_i$ by row of $B$ $\mathbf{b}^T_i$
* it gives us a rank-1 matrix - an outer product
* then sum over all $i$
* http://habrastorage.org/files/c8c/6b7/90c/c8c6b790cafc4240b41015c484fdb4f2.png
* $C = AB = \sum\limits_{i=1}^n \mathbf{a}_i \mathbf{b}^T_i$


=== Block Multiplication ===
$AB = \left[ \begin{array}{c|c}
A_1 &amp; A_2 \\
\hline
A_3 &amp; A_4
\end{array} \right] \times 
\left[ \begin{array}{c|c}
B_1 &amp; B_2 \\
\hline
B_3 &amp; B_4
\end{array} \right] = 
\left[ \begin{array}{c|c}
A_1B_1 + A_2B_3 &amp; A_3B_1 + A_4B_3 \\
\hline
A_1B2 + A_2B_1 &amp; A_3B_1 + A_4B_3
\end{array} \right] = C$



== Properties ==
=== Transposition ===
* $(AB)^T = B^T A^T$
* $(A_1 \cdot \ ... \ \cdot A_n)^T = A_n^T \cdot \ ... \ \cdot A_1^T$


=== Inverse Matrices ===
$(AB)^{-1} = B^{-1} A^{-1}$ 
* [[Inverse Matrices|inverse]] of product is product of inverses in the reversed order 
* check: 
** $AB \times B^{-1} A^{-1} = A \times (B  B^{-1}) \times A^{-1} = A \times I \times A^{-1} A \times A^{-1} = I$
** $B^{-1} A^{-1} \times AB = B^{-1} \times (A^{-1} A) \times B = B^{-1} \times B = I$


=== Row Space and Column Space ===
Let's show the following:
* $C(A\, B) \subseteq C(A)$
* $R(A \, B) \subseteq R(B)$
* where $C(\cdot)$ is [[Column Space]] and $R(\cdot)$ is [[Row Space]]


Image of linear transformation
* first, let's consider a linear transformation of an $m \times n$ matrix $A$
* $T_A \ : \ \mathbb R^n \to \mathbb R^m$ : $T_A(\mathbf x) = A \mathbf x$
* Column Space of $A$ is the image of $T_A$ in $\mathbb R^m$ 


$C(A\, B) \subseteq C(A)$
* let $A$ be an $m \times n$ matrix and $B$ be an $k \times n$
* $A \, B$ corresponds to linear transformation $T_A \circ T_B$
* so need to show that $\text{image}(T_A \circ T_B) \subseteq \text{image}(T_A)$
* http://habrastorage.org/files/693/fc9/9de/693fc99de6f7493d97e571e0a3b3e0c8.png &lt;!-- etc\alg\matrix-mult-image.png --&gt;


What about $R(A \, B) \subseteq R(B)$?
* $R(A \, B) = C(B^T A^T) \subseteq C(B^T) = R(B)$



== Implementation ==
=== SQL ===
Sparse matrix multiplication
&lt;pre&gt;
select a.row_num, b.col_num, sum(a.value * b.value)
  from A a, B b
 where a.col_num = b.row_num
group by a.row_num, b.col_num;
&lt;/pre&gt;


=== [[MapReduce]] ===
* It's easy to implement the SQL expression above in terms of MapReduce
* Link [https://code.google.com/p/stolzen/source/browse/trunk/courses/coursera/Introduction%20to%20Data%20Science/assignment3/p6_matrixmult.py]


E.g. Apache Flink:

&lt;pre&gt;
matrixA.join(matrixB).where(1).equalTo(0)
       .map(new ProjectJoinResultMapper()).groupBy(0, 1).sum(2)
&lt;/pre&gt;


Full code of Matrix Multiplication in Flink: [https://github.com/alexeygrigorev/aim3/blob/master/src/main/java/de/tuberlin/dima/aim3/assignment3/MatrixMultiplication.java]




== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Курош А.Г. Курс Высшей Алгебры
* [[Introduction to Data Science (coursera)]]
* [[Scalable Data Analytics and Data Mining AIM3 (TUB)]]

[[Category:Linear Algebra]]</text>
      <sha1>atpwzlsmb0jgado142hvdc1ujcxihlg</sha1>
    </revision>
    <revision>
      <id>667</id>
      <parentid>628</parentid>
      <timestamp>2015-11-14T13:00:54Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>/* Column at a Time */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5392">== Matrix-Matrix Multiplication ==
Suppose we want to multiply $m \times n$ matrix $A$ on $n \times p$ matrix $B$, we get an $m \times p$ matrix $C$


== [[Linear Transformation]] ==
What is matrix-matrix multiplication in terms of Linear Transformations?
* Let $A$ be an $m \times n$ matrix, 
* then there's a linear transformation $T_A \ : \ \mathbb R^n \to \mathbb R^m$: $T_A(\mathbf x) = A \mathbf x$ where $A \mathbf x$ is [[Matrix-Vector Multiplication]]
* now let $B$ be an $n \times k$ matrix, then $T_B \ : \ \mathbb R^m \to \mathbb R^k$: $T_B(\mathbf y) = B \mathbf x$
* what is $T_A \circ T_B$? It's $T_A \circ T_B \ : \ \mathbb R^k \to \mathbb R^m $
* $(T_A \circ T_B)(\mathbf x) = T_A \big( T_B(\mathbf x) \big) = T_A \big( B \mathbf x \big) = A \, B \, \mathbf x$
* $AB$ is matrix-matrix multiplication


== Multiplication ==
We can see matrix by matrix multiplication from 5 different positions:
* row by column multiplication
* column at a time
* row at a time
* as sum of outer products
* block multiplication

All of them are equivalent and lead to the same result


=== Row By Columns ===
This is usual dot product multiplication: 
* for each row of matrix $A$ we calculate a dot product with each column of matrix $B$
* http://habrastorage.org/files/bad/3a8/b38/bad3a8b38db64a918543146979adcea0.png
* $c_{ij} = (\text{row $i$ of $A$})^T \times (\text{col $j$ of $B$}) = \sum\limits_{k=1}^{m} c_{ik} b_{kj}$


=== Column at a Time ===
For each column $\mathbf{b}_j$ of $B$ 
* we multiply each column of $A$ with $\mathbf{b}_j$ - like in column at a time for matrix by vector
* http://habrastorage.org/files/fe8/ffb/fb9/fe8ffbfb9ede4ad18a868024f8e791a1.png
* &lt;math&gt;\mathbf{c}_j = \begin{bmatrix}
\mathop{a_1}\limits_|^| \ \mathop{a_2}\limits_|^| \ \cdots \  \mathop{a_n}\limits_|^| 
\end{bmatrix} \times \mathbf{b}_j&lt;/math&gt;
* so each $\mathbf{c}_j$ is a combination of columns of $A$

=== Row at a Time ===
For each row $\mathbf{a}^T_i$ of $A$
* multiply $\mathbf{a}^T_i$ with each rows of $B$ - like for left vector multiplication
* http://habrastorage.org/files/9ac/c1a/b9d/9acc1ab9d7784a96b3e42f72fe4f1882.png
* $\mathbf{c}^T_i = \mathbf{a}^T_i \times B$
* Note that we can see this as Column at a Time case, but transposed:
** row at a time in $A\times B = C$ is the same as column at a time in $B^T \times A^T = C^T$


=== Sum of [[Outer Product]]s ===
For $i$ from 1 to $n$, 
* multiply column of $A$ $\mathbf{a}_i$ by row of $B$ $\mathbf{b}^T_i$
* it gives us a rank-1 matrix - an outer product
* then sum over all $i$
* http://habrastorage.org/files/c8c/6b7/90c/c8c6b790cafc4240b41015c484fdb4f2.png
* $C = AB = \sum\limits_{i=1}^n \mathbf{a}_i \mathbf{b}^T_i$


=== Block Multiplication ===
$AB = \left[ \begin{array}{c|c}
A_1 &amp; A_2 \\
\hline
A_3 &amp; A_4
\end{array} \right] \times 
\left[ \begin{array}{c|c}
B_1 &amp; B_2 \\
\hline
B_3 &amp; B_4
\end{array} \right] = 
\left[ \begin{array}{c|c}
A_1B_1 + A_2B_3 &amp; A_3B_1 + A_4B_3 \\
\hline
A_1B2 + A_2B_1 &amp; A_3B_1 + A_4B_3
\end{array} \right] = C$



== Properties ==
=== Transposition ===
* $(AB)^T = B^T A^T$
* $(A_1 \cdot \ ... \ \cdot A_n)^T = A_n^T \cdot \ ... \ \cdot A_1^T$


=== Inverse Matrices ===
$(AB)^{-1} = B^{-1} A^{-1}$ 
* [[Inverse Matrices|inverse]] of product is product of inverses in the reversed order 
* check: 
** $AB \times B^{-1} A^{-1} = A \times (B  B^{-1}) \times A^{-1} = A \times I \times A^{-1} A \times A^{-1} = I$
** $B^{-1} A^{-1} \times AB = B^{-1} \times (A^{-1} A) \times B = B^{-1} \times B = I$


=== Row Space and Column Space ===
Let's show the following:
* $C(A\, B) \subseteq C(A)$
* $R(A \, B) \subseteq R(B)$
* where $C(\cdot)$ is [[Column Space]] and $R(\cdot)$ is [[Row Space]]


Image of linear transformation
* first, let's consider a linear transformation of an $m \times n$ matrix $A$
* $T_A \ : \ \mathbb R^n \to \mathbb R^m$ : $T_A(\mathbf x) = A \mathbf x$
* Column Space of $A$ is the image of $T_A$ in $\mathbb R^m$ 


$C(A\, B) \subseteq C(A)$
* let $A$ be an $m \times n$ matrix and $B$ be an $k \times n$
* $A \, B$ corresponds to linear transformation $T_A \circ T_B$
* so need to show that $\text{image}(T_A \circ T_B) \subseteq \text{image}(T_A)$
* http://habrastorage.org/files/693/fc9/9de/693fc99de6f7493d97e571e0a3b3e0c8.png &lt;!-- etc\alg\matrix-mult-image.png --&gt;


What about $R(A \, B) \subseteq R(B)$?
* $R(A \, B) = C(B^T A^T) \subseteq C(B^T) = R(B)$



== Implementation ==
=== SQL ===
Sparse matrix multiplication
&lt;pre&gt;
select a.row_num, b.col_num, sum(a.value * b.value)
  from A a, B b
 where a.col_num = b.row_num
group by a.row_num, b.col_num;
&lt;/pre&gt;


=== [[MapReduce]] ===
* It's easy to implement the SQL expression above in terms of MapReduce
* Link [https://code.google.com/p/stolzen/source/browse/trunk/courses/coursera/Introduction%20to%20Data%20Science/assignment3/p6_matrixmult.py]


E.g. Apache Flink:

&lt;pre&gt;
matrixA.join(matrixB).where(1).equalTo(0)
       .map(new ProjectJoinResultMapper()).groupBy(0, 1).sum(2)
&lt;/pre&gt;


Full code of Matrix Multiplication in Flink: [https://github.com/alexeygrigorev/aim3/blob/master/src/main/java/de/tuberlin/dima/aim3/assignment3/MatrixMultiplication.java]




== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Курош А.Г. Курс Высшей Алгебры
* [[Introduction to Data Science (coursera)]]
* [[Scalable Data Analytics and Data Mining AIM3 (TUB)]]

[[Category:Linear Algebra]]</text>
      <sha1>hpr2m07pszghhsi2t41ply81w3mpxdb</sha1>
    </revision>
    <revision>
      <id>785</id>
      <parentid>667</parentid>
      <timestamp>2017-06-27T09:58:59Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7177">== Matrix-Matrix Multiplication ==
Suppose we want to multiply $m \times n$ matrix $A$ on $n \times p$ matrix $B$, we get an $m \times p$ matrix $C$


== [[Linear Transformation]] ==
What is matrix-matrix multiplication in terms of Linear Transformations?
* Let $A$ be an $m \times n$ matrix, 
* then there's a linear transformation $T_A \ : \ \mathbb R^n \to \mathbb R^m$: $T_A(\mathbf x) = A \mathbf x$ where $A \mathbf x$ is [[Matrix-Vector Multiplication]]
* now let $B$ be an $n \times k$ matrix, then $T_B \ : \ \mathbb R^m \to \mathbb R^k$: $T_B(\mathbf y) = B \mathbf x$
* what is $T_A \circ T_B$? It's $T_A \circ T_B \ : \ \mathbb R^k \to \mathbb R^m $
* $(T_A \circ T_B)(\mathbf x) = T_A \big( T_B(\mathbf x) \big) = T_A \big( B \mathbf x \big) = A \, B \, \mathbf x$
* $AB$ is matrix-matrix multiplication


== Multiplication ==
We can see matrix by matrix multiplication from 5 different positions:
* row by column multiplication
* column at a time
* row at a time
* as sum of outer products
* block multiplication

All of them are equivalent and lead to the same result


=== Row By Columns ===
This is usual dot product multiplication: 
* for each row of matrix $A$ we calculate a dot product with each column of matrix $B$
* http://habrastorage.org/files/bad/3a8/b38/bad3a8b38db64a918543146979adcea0.png
* $c_{ij} = (\text{row $i$ of $A$})^T \times (\text{col $j$ of $B$}) = \sum\limits_{k=1}^{m} c_{ik} b_{kj}$


=== Column at a Time ===
For each column $\mathbf{b}_j$ of $B$ 
* we multiply each column of $A$ with $\mathbf{b}_j$ - like in column at a time for matrix by vector
* http://habrastorage.org/files/fe8/ffb/fb9/fe8ffbfb9ede4ad18a868024f8e791a1.png
* &lt;math&gt;\mathbf{c}_j = \begin{bmatrix}
\mathop{a_1}\limits_|^| \ \mathop{a_2}\limits_|^| \ \cdots \  \mathop{a_n}\limits_|^| 
\end{bmatrix} \times \mathbf{b}_j&lt;/math&gt;
* so each $\mathbf{c}_j$ is a combination of columns of $A$

=== Row at a Time ===
For each row $\mathbf{a}^T_i$ of $A$
* multiply $\mathbf{a}^T_i$ with each rows of $B$ - like for left vector multiplication
* http://habrastorage.org/files/9ac/c1a/b9d/9acc1ab9d7784a96b3e42f72fe4f1882.png
* $\mathbf{c}^T_i = \mathbf{a}^T_i \times B$
* Note that we can see this as Column at a Time case, but transposed:
** row at a time in $A\times B = C$ is the same as column at a time in $B^T \times A^T = C^T$


=== Sum of [[Outer Product]]s ===
For $i$ from 1 to $n$, 
* multiply column of $A$ $\mathbf{a}_i$ by row of $B$ $\mathbf{b}^T_i$
* it gives us a rank-1 matrix - an outer product
* then sum over all $i$
* http://habrastorage.org/files/c8c/6b7/90c/c8c6b790cafc4240b41015c484fdb4f2.png
* $C = AB = \sum\limits_{i=1}^n \mathbf{a}_i \mathbf{b}^T_i$


=== Block Multiplication ===
$AB = \left[ \begin{array}{c|c}
A_1 &amp; A_2 \\
\hline
A_3 &amp; A_4
\end{array} \right] \times 
\left[ \begin{array}{c|c}
B_1 &amp; B_2 \\
\hline
B_3 &amp; B_4
\end{array} \right] = 
\left[ \begin{array}{c|c}
A_1B_1 + A_2B_3 &amp; A_3B_1 + A_4B_3 \\
\hline
A_1B2 + A_2B_1 &amp; A_3B_1 + A_4B_3
\end{array} \right] = C$



== Properties ==
=== Transposition ===
* $(AB)^T = B^T A^T$
* $(A_1 \cdot \ ... \ \cdot A_n)^T = A_n^T \cdot \ ... \ \cdot A_1^T$


=== Inverse Matrices ===
$(AB)^{-1} = B^{-1} A^{-1}$ 
* [[Inverse Matrices|inverse]] of product is product of inverses in the reversed order 
* check: 
** $AB \times B^{-1} A^{-1} = A \times (B  B^{-1}) \times A^{-1} = A \times I \times A^{-1} A \times A^{-1} = I$
** $B^{-1} A^{-1} \times AB = B^{-1} \times (A^{-1} A) \times B = B^{-1} \times B = I$


=== Row Space and Column Space ===
Let's show the following:
* $C(A\, B) \subseteq C(A)$
* $R(A \, B) \subseteq R(B)$
* where $C(\cdot)$ is [[Column Space]] and $R(\cdot)$ is [[Row Space]]


Image of linear transformation
* first, let's consider a linear transformation of an $m \times n$ matrix $A$
* $T_A \ : \ \mathbb R^n \to \mathbb R^m$ : $T_A(\mathbf x) = A \mathbf x$
* Column Space of $A$ is the image of $T_A$ in $\mathbb R^m$ 


$C(A\, B) \subseteq C(A)$
* let $A$ be an $m \times n$ matrix and $B$ be an $k \times n$
* $A \, B$ corresponds to linear transformation $T_A \circ T_B$
* so need to show that $\text{image}(T_A \circ T_B) \subseteq \text{image}(T_A)$
* http://habrastorage.org/files/693/fc9/9de/693fc99de6f7493d97e571e0a3b3e0c8.png &lt;!-- etc\alg\matrix-mult-image.png --&gt;


What about $R(A \, B) \subseteq R(B)$?
* $R(A \, B) = C(B^T A^T) \subseteq C(B^T) = R(B)$



== Implementation ==
=== Possible Ways to Implement ===
Suppose we want to implement the update $C = C + AB$:
* let $A$ be $m \times r$ matrix and $B$ be $r \times n$
* then $C$ is $m \times n$ matrix
* $C$ can be initialized as an array filled with zeros - then $C$ will contain the results of $AB$

 for (int i = 0; i &lt; m; i++) {
     for (int j = 0; i &lt; n; j++) {
         for (int k = 0; k &lt; r; k++) {
             C[i, j] = C[i, j] + A[i, k] * B[k, j]
         }
     }
 }


Note that here it is not important in which order we do the loop: 
* it can be &lt;code&gt;ijk&lt;/code&gt;, &lt;code&gt;ikj&lt;/code&gt;, etc, with $3! = 6$ possible ways

{| class=&quot;wikitable&quot; 
!Order||Inner Loop||Outer Loops||Inner Loop Access
|-
|&lt;code&gt;ijk&lt;/code&gt;|| &lt;code&gt;dot&lt;/code&gt; || Vector-Matrix Mult || $A$ row, $B$ col
|-
|&lt;code&gt;jik&lt;/code&gt;|| &lt;code&gt;dot&lt;/code&gt; || Matrix-Vector Mult || $A$ row, $B$ col
|-
|&lt;code&gt;ikj&lt;/code&gt;|| &lt;code&gt;saxpy&lt;/code&gt; || Row &lt;code&gt;gaxpy&lt;/code&gt; || $B$ row, $C$ row
|-
|&lt;code&gt;jki&lt;/code&gt;|| &lt;code&gt;saxpy&lt;/code&gt; || Col &lt;code&gt;gaxpy&lt;/code&gt; || $A$ col, $C$ col
|-
|&lt;code&gt;kij&lt;/code&gt;|| &lt;code&gt;saxpy&lt;/code&gt; || row outer product || $A$ row, $C$ row
|-
|&lt;code&gt;kji&lt;/code&gt;|| &lt;code&gt;saxpy&lt;/code&gt; || col outer product || $A$ col, $C$ col
|}


Some details:
* The way inner loop accesses the data is important for storing the data to make it faster - data should be contiguos in memory 
* &lt;code&gt;dot&lt;/code&gt; is usual Vector-Vector multiplication
* &lt;code&gt;saxpy&lt;/code&gt; (scalar $a$ times $x$ plus $y$): $y \leftarrow ax + y$
* &lt;code&gt;gaxpy&lt;/code&gt; (generalized &lt;code&gt;axpy&lt;/code&gt;): $y \leftarrow y + Ax$
* outer product update: $A \leftarrow A + xy^T$



=== SQL and [[MapReduce]] ===
Suppose we have two sparce matrices $A$ and $B$
* we store these matrices as &lt;code&gt;(row_num, col_num, value)&lt;/code&gt; triples
* it is easy to use SQL for this multiplication


Sparse matrix multiplication with SQL 

 select a.row_num, b.col_num, sum(a.value * b.value)
   from A a, B b
  where a.col_num = b.row_num
 group by a.row_num, b.col_num;


[[MapReduce]]
* We can translate this SQL expression into MapReduce
* Link [https://code.google.com/p/stolzen/source/browse/trunk/courses/coursera/Introduction%20to%20Data%20Science/assignment3/p6_matrixmult.py]


E.g. Apache Flink:

 matrixA.join(matrixB).where(1).equalTo(0)
        .map(new ProjectJoinResultMapper()).groupBy(0, 1).sum(2)


Full code of Matrix Multiplication in Flink: [https://github.com/alexeygrigorev/aim3/blob/master/src/main/java/de/tuberlin/dima/aim3/assignment3/MatrixMultiplication.java]




== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* Курош А.Г. Курс Высшей Алгебры
* [[Introduction to Data Science (coursera)]]
* [[Scalable Data Analytics and Data Mining AIM3 (TUB)]]
* [[Matrix Computations (book)]]

[[Category:Linear Algebra]]</text>
      <sha1>jcirt9f599yx3rg50mwjlsz99ny31qp</sha1>
    </revision>
  </page>
  <page>
    <title>Semantic Domains</title>
    <ns>0</ns>
    <id>626</id>
    <revision>
      <id>629</id>
      <timestamp>2015-05-09T18:58:45Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16504">== Semantic Domains ==
* A ''semantic field'' corresponds to words grouped by their meaning
* it consists of words from some domain
* e.g. in English the field &quot;Rain&quot; may include words like &quot;rain&quot;, &quot;drizzle&quot;, &quot;downpour&quot;, &quot;raindrop&quot;, &quot;puddle&quot;, all of these words can be used to talk about rain


Words within one domain are related by lexical relations
* there are two kinds of lexical relations:
* term lexical relations: relations between words, typically about words that collocate (frequently used together: e.g. words &quot;bird&quot; and &quot;fly&quot;)
* paradigm form: synonyms, antonyms, etc. E.g. words &quot;big&quot; and &quot;large&quot;


Forming lexical relations:
* we learn lexical relations to speak correctly 
* each of us has a big mental dictionary organized into a big network of lexical relations
* there are clusters in this network: ''semantic field''


Semantic Domains:
* In [[Computational Linguistics]] and [[NLP]] Semantic Domains is a computational model for [[Lexical Semantics]]
* Semantic domains are a way of finding Semantic Fields 



== The Theory of Semantic Fields ==
Lexicon (words of a natural language) is structured into Semantic Fields
* Semantic Fields: &quot;clusters&quot; of semantically related terms
* relations among concepts that belong to the same Semantic Field are very dense
* and concept from different Semantic Field are typically unrelated 
* Theory of Semantic Fields: it claims that words are structured into a set of semantic fields 



Structural Semantics models relations between words, like in [[WordNet]]
* The Theory of Semantic Fields goes further by introducing an additional aggregation level
* Semantic Fields form higher-level abstractions
* relations between them are much more stable than between words
* even if word senses change over time, the field still stays the same 
* so, Semantic Fields are usually consistent across languages, cultures and time
* there's a strong connection between Semantic Fields of different Languages: such connections don't exist among the terms themselves



Limitation of this theory:
* it doesn't provide any objective criteria for identifying Semantic Fields in the language
* solution to this problem: Semantic Domains, it's a computational approach for finding Semantic Fields
* use the lexical coherence assumption: words from the same field should co-occur in texts



== Semantic Domains ==
''Semantic Domains'' are Semantic Fields that are characterized by set of ''domain words'' which often occur in texts about corresponding domain
* words belonging to the same lexical field are called &quot;domain words&quot;
* usually large potion of the language terminology is characterized by domain words 


=== Lexical Coherence Assumption ===
Basic hypothesis: 
* a great percentage of the concepts expressed in the same text belongs to the same domain 
* it's a basic property of any natural language: domain-specific words co-occur with each other in the same text, this property is called &quot;lexical coherence&quot;
* There are common areas of human knowledge such as Economics, Politics, Law, Science, etc. All these areas demonstrate lexical coherence


So, what about Semantic Fields?
* Semantic Fields are lexically coherent: words in one SF tend to co-occur in texts 
* We call these fields &quot;Semantic Domains&quot;: they are Semantic Fields characterized by lexically coherent words


Lexical coherence assumption:
* We assume that real-world documents are lexically coherent
* this guarantees the existence of Semantic Domains
* it's also proven by experiments: in real texts if you count the percentage of words that belong to the same domain, you'll see that the most belong to one domain 


There are 3 types of words 
* '''Text-Related Domain words''': words that have at least one sense that contributes to determining the domain of the whore text 
** e.g. word &quot;bank&quot; in a text about economy
* '''Text-Unrelated Domain words''': words that are from some non-generic domain, but don't contribute to the domain of the text
** e.g. word &quot;church&quot; in a text about economy
* '''Text-Unrelated Generic words''': don't bring any relevant domain information 
** e.g. &quot;to be&quot;


Let's put the lexical coherence assumption more formally:
* &quot;One domain per discourse&quot; ($\approx$ text, document) assumption
* if a word is used in one sense in some discourse
* then other occurrences of this word should also have the same sense
* smart way of putting it: &quot;multiple occurrences of a word in coherent portions of texts tend to share the same domain&quot;


The lexical coherence assumption allows us to represent Semantic Domains by the set of domain-specific texts


=== Role of Semantic Domains ===
Characterizing word senses (i.e. lexical concepts)
* typically by assigning domain labels to words in a lexicon
* e.g. Crane has senses in Zoology and Construction
* WordNet Domains - extension of [[WordNet]] that adds the information about domain


Characterizing texts
* can use Semantic Domains for text categorization
* at the textual level, semantic domains are [[Document Clustering|clusters of texts]] on similar topics
* so can see Semantic Domains as a collection of domain-specific texts 


practical points of view: Semantic Domains are lists of related terms that describe a particular subject/area



== Representation ==
=== Domain Sets ===
* domain relations: two words are domain-related if they belong to the same domain
* domain set is used to describe semantic classes of texts 
* semantic classes of strongly related lexical concepts are domain concepts
* so a domain set should relate each word to one or more domain sets


Requirements of an &quot;ideal&quot; domain set:
* completeness: all possible texts should be assigned to at least one domain
* balancement: number of texts belonging to each domain should be uniform
* separability: the same text/concept can't be assigned to more than one domain


Usually not achievable: 
* it's quite difficult to define a complete domain set, general enough to represent all possible aspects of human knowledge
* and it's also not possible to collect a corpus that contains all the human knowledge
* a certain degree of overlapping is unavoidable (e.g. math/physics)



=== Domain Model ===
We can easily obtain term-based representation of documents e.g. by using [[Vector Space Models]] 
* but VSMs have lexical ambiguity problem
* domain terms are typically highly correlated within texts: they tend to co-occur inside the same types of text
* this is justified by the lexical coherence property of natural languages (Leacock96)


Domain model is a computational model for Semantic Domains to represent domain information 
* it describes relations at the term level
* it does that by defining a set of term clusters (see also [[Term Clustering]])
* each cluster represent a semantic domain: set of terms that often co-occur in texts with similar topics 
* it's a way to represent domain information at the textual level


Domain Model:
* is a matrix that describes the degree of association between terms in the vocabulary and Semantic Domains
* rows are indexed by words
* columns are the corresponding domains 


Domain Model is a [[Linguistic Models|shallow model]] for lexical semantics, but it capture ambiguity and variability


DM is represented by a $n \times k$ rectangular matrix $D$ 
* $D$ contains the domain relevance for each term w.r.t each domain 


E.g. 

{| class=&quot;wikitable&quot;
! || Medicine || CS
|-
| HIV || 1 || 0
|-
| AIDS || 1 || 0
|-
| virus || 0.5 || 0.5
|-
| laptop || 0 || 1
|}


Formally, 
* let $\mathcal D = \{ D_1 , \ ... \ , D_k \}$ be a set of domains 
* and we have $n$ words $V = \{ w_1, \ ... \ , w_n \}$  ($n$ - vocabulary size)
* then $D$ is a $n \times k$ matrix, where $D_{iz}$ is domain relevance of term $w_i$ w.r.t. domain $D_z$

* let $R(D_z, o)$ denote domain relevance of domain $D_z$ w.r.t. some linguistic object $o$ (text, term, concept)
* it gives a measure of association between $D_z$ and $o$ 
* typically higher values indicate higher association and often the value ranges from 0 to 1


DMs can describe ambiguity and variability:
* ambiguity: by associating one term to several domains 
* variability: by associating different terms to the same domain 


A domain Model defines a Domain Space 



=== Obtaining Domain Models ===
Obtaining Domain Models
* Domain Models can be obtained from unsupervised learning or manual annotation
* can use WordNet Domain 
* or by performing [[Term Clustering]]


domain relations among terms can be detected by analyzing co-occurrence in the corpus
* motivated by the lexical coherence assumption
* co-occurring terms have a good chance to show domain relations


=== WordNet Based Domain Model ===
WordNet Domains is an extension of [[WordNet]]: 
* each synset here is annotated with one or more domain labels
* it has ~ 200 domain labels


Using WordNet Domain for building a domain model:
* if $\mathcal D = \{ D_1 , \ ... \ , D_k \}$ are domains of the word net domains 
* and $\mathcal C = \{ c_1 , \ ... \ , c_s \}$ are concepts (synsets) from WordNet
* then let $\text{senses}(w)$ be a set of all synsets that contain $w$: $\text{senses}(w) = \{c  \mid  c \in \mathcal C, \text{$c$ is a sense of $w$} \}$
* let $R_s: \mathcal D \times \mathcal C \to \mathbb R$ be a domain relevance function for concepts
* $\text{dom}(c)$ is a domain assignment function, $\text{dom}(c) \subseteq \mathcal D$: returns a set of domains associated with a synset $c$ 
* $R_s(D, c) = \begin{cases}
1 / |\text{dom}(c)| &amp; \text{ if } D \in \text{dom}(c) \\ 
1 / k &amp; \text{ if } \text{dom}(c) \equiv \{ \text{Factotum} \} \\ 
0 &amp; \text{ otherwise } \\ 
\end{cases}$
* Factotum = generic concept for all non-domain words
* $k$ - cardinality of $\mathcal D$
* $R_s(D, c) \approx$ estimated prior probability of the domain given the concept 


This is for synsets, not words
* now let $V = \{ w_1 , \ ... \ , w_n \}$ the vocabulary
* then domain relevance of a word is a function $R: \mathcal D \times V \to \mathbb R$ 
* define $R$ as $$R(D_z, w_i) = \cfrac{1}{| \text{senses}(w_i) |} \sum\limits_{c \in \text{senses}(w_i)} R(D_z, c)$$
* so it's average relevance of all $w_i$'s senses
* if $w$ has only one sense, then $R(D_z, w) = R_s(D_z, c)$
* a word with several senses (&quot;polysemous&quot;) will be less relevant than a word with few senses 
* words with just one sense are (&quot;monosemic&quot;) - they will be the most relevant: they provide more information about the domain


This is consistent with the phenomenon that less frequent words are more informative: because they have fewer senses


The domain model $D$ is defined as $D_{ij} = R(D_j, w_i)$


Limitations: 
* $\mathcal D$ is fixed because WordNet Domains is fixed
* WordNet Domains is limited: not complete
* and lexicon in WordNet Domains is also limited



=== Corpus-Based Acquisition of Domain Models ===
We want automatically extract domain models from corpus:
* to avoid subjectivity
* to find more flexible models 


[[Term Clustering]] techniques are usually used for this
* usually need soft clustering techniques for this: want one term to be in several clusters 
* there are several ways: 
* [[Fuzzy C-Means]], Information bottleneck method, etc
* we'll use [[Latent Semantic Analysis]]


LSA is done by projecting TermVSM and TextVSM to a common LSA space using some linear transformations
* first-order (shallow) relations between terms: their co-occurrence in texts
* it takes into account both second-order relations: their semantics, established by co-occurrence


DO [[SVD]]:
* $T = W \Sigma P^T$ 
* $W$ (for '''W'''ords) are orthogonal eigenvectors of $T T^T$: word vectors
* $P$ (for '''P'''assages) are orthogonal eigenvectors of $T^T T$: document vectors
* Truncated SVD: use $\Sigma_k$: first $k$ singular values and the rest set to 0
* $T_k = W \Sigma_k P^T \approx T$ the best approximation 


Now let's define the domain matrix 
* $D = I^{\text{N}} W \sqrt{\Sigma}$
* $I^{\text{N}}$ is a diagonal matrix s.t. $I^{\text{N}}_{ii} = \cfrac{1}{\| w_i \|}$
* $w_i$ is $i$th column of $W \sqrt{\Sigma}$ - principal components ($W \sqrt{\Sigma}$ are loadings for words)




=== Domain Space ===
Domain Models define the Domain Space

Once a DM is determined, we can define a Domain Space 
* it's a geometric space where terms and documents can be represented as vectors 
* it's a [[Vector Space Models|Vector Space Model]]


There are some problems of VSMs:
* TextVSM can't deal with lexical ambiguity and variability
* e.g.: &quot;he's affected by AIDS&quot; and &quot;HIV is a virus&quot; don't have any words in common
* so in the TextVSM the similarity is 0: these vectors are orthogonal even though the concepts are related 
* on the other hand, similarity between &quot;the laptop has a virus&quot; and &quot;HIV is a virus&quot; is not 0: due to the ambiguity of &quot;virus&quot;


Term VSM: 
* feature sparseness 
* if we want to model domain relations, we're mostly interested in domain-specific words 
* such words are quite infrequent compared to non-domain words, so vectors for these words are very sparse, esp in large corpus 
* so similarity between domain words would tend to 0
* and the results overall will not be very meaningful and interesting


Domain Spaces ftw


so a '''Domain Space''' is a cluster-based representation for estimating term and text meaning 
* it's a vector space where both terms and texts can be compared 
* once a domain space is defined by a matrix $D$, can represent both terms and texts by domain vectors
* domain vectors - vectors that represent relevance among linguistic objects and each domain


Domain space is 
* it's an instance of Generalized Vector Space Model
* for text $t_i$ in the [[Vector Space Models|Text VSM]]
* $t_i' = t_i (I^{\text{idf}} D)$ ({{ TODO | why left multiplication? }})
* where $I^{\text{idf}}$ is a diagonal matrix s.t. $I^{\text{idf}}_{ii} = \text{idf}(w_i)$ - it's inverse document frequency of word $w_i$ (see [[TF-IDF]])
* so we define a mapping function and thus have a generalized VSM

In the domain space the vector representation of terms and documents is &quot;augmented&quot; by domain relations represented by the domain model 


Geometrically: 
* http://habrastorage.org/files/0fe/98c/f82/0fe98cf82f2b4e369c5043c522b283a6.png
* source: [[Semantic Domains in Computational Linguistics (book)]], Fig 3.2
* both terms and texts are represented in common vector space 
* so comparison between terms and texts are possible
* also, the dimensionality of Domain Space is generally lower 


Domain Space allows to reduce the impact of ambiguity and variability: 
* by introducing non-sparse space 


So advantages of DS:
* lower dimensionality
* sparseness is avoided 
* duality: allows direct and uniform similarity between texts and terms 


=== Domain Kernel ===
Domain Kernel is a similarity function for terms and documents in the domain space. Domain Kernel is a Mercer [[Kernel]], so it can be used in any kernel-based algorithm.

This kernel is represented by a DOmain Model matrix $D$ 
* $K : \mathbb R^n \cup V \to \mathbb R^k$ 
* maps texts $t \in \mathbb R^n$  and terms $w \in V$ into Domain Space: $t' \in \mathbb R^k$ and $w' \in \mathbb R^k$


$K$ is defined as 
* $K(w) = w_i'$ if $w = w_i \in V$ 
* $K(w) = \cfrac{\sum_{t \in T} \text{tf}(w, t) \cdot t'} {\| \sum_{t \in T} \text{tf}(w, t) \cdot t' \|}$ if $w \not \in V$ 
* $K(t) = t (I^{text{idf}} D) = t'$ for documents
* $\text{tf}(w, t)$ is a term frequency of $w$ in text $t$ 
* $I^{\text{idf}}$ is a diagonal matrix with IDFs: $I^{\text{idf}}_{ii} = \cfrac{1}{| \{ t \in T \mid \text{tf}(w_i, t) &gt; 0\} |}$


Can compute the similarity using cosine 

$K$ is defined for any term and text
* $K$ is a mercer kernel by construction: it's a dot product, but unlike many other kernels, it reduces the dimensionality instead of increasing it



== Usage ==
* after that we can use Domain Models for many NLP task
* can use domain model to estimate topic similarity


Domain Kernels can be used for any instance-based algorithm in many NLP applications:
* [[Document Classification]]
* [[Document Clustering]]
* [[Term Clustering]]
* can use any [[Machine Learning]] algorithm with this kernel, e.g. [[SVM]]




== References ==
* Leacock, Claudia, et al. &quot;Towards building contextual representations of word senses using statistical models.&quot; (1996). [http://anthology.aclweb.org/W/W93/W93-0102.pdf]


== Sources ==
* http://www.semdom.org/description
* [[Semantic Domains in Computational Linguistics (book)]]

[[Category:Natural Language Processing]]
[[Category:Thesis]]</text>
      <sha1>2u9gl6eet7ku6l05c3nyx6cxx0w5ozf</sha1>
    </revision>
  </page>
  <page>
    <title>Sources Index</title>
    <ns>0</ns>
    <id>627</id>
    <revision>
      <id>630</id>
      <timestamp>2015-07-05T11:26:35Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8300">== Sources Index ==
Only papers I read and used as sources (or small books that don't deserve a separate wiki page)
* ordered by first author
* ABCDEFGHIJKLMNOPQRSTUVWXYZ


=== A ===
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. 2012. [[Document Clustering]], [[K-Means]], [[K-Medoids]], [[Co-Clustering]], [[Two-Phase Document Clustering]], [[Non-Negative Matrix Factorization]], [[Semi-Supervised Clustering]], [[Topic Models]], [[Probabilistic LSA]], [[Term Strength]], [[Term Contribution]], [[Stop Words]]

=== B ===
=== C ===
* Cristianini, Nello, John Shawe-Taylor, and Huma Lodhi. &quot;Latent semantic kernels.&quot; 2002. [http://eprints.soton.ac.uk/259781/1/LatentSemanticKernals_JIIS_18.pdf] [[Kernel Methods]] [[Latent Semantic Kernels]]
* Cutting, et al. &quot;Scatter/gather: A cluster-based approach to browsing large document collections.&quot; 1992. [http://courses.washington.edu/info320/au11/readings/Week4.Cutting.et.al.1992.Scatter-Gather.pdf] [[Scatter/Gather]]

=== D ===
* Datar, Mayur, et al. &quot;Locality-sensitive hashing scheme based on p-stable distributions.&quot; 2004. [http://www.cs.princeton.edu/courses/archive/spring05/cos598E/bib/p253-datar.pdf] [[Locality Sensitive Hashing]], [[Euclidean LSH]]
* De Smet, Yves. &quot;An introduction to multicriteria decision aid: The PROMETHEE and GAIA methods.&quot; [[PROMETHEE]]
* Deerwester, Scott C., et al. &quot;Indexing by latent semantic analysis.&quot; 1990. [http://www.cob.unt.edu/itds/faculty/evangelopoulos/dsci5910/LSA_Deerwester1990.pdf] [[Latent Semantic Analysis]]
* Domingos, Pedro. &quot;A few useful things to know about machine learning.&quot; 2012. [https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf] [[Overfitting]]

=== E ===
* Elsayed, Tamer, Jimmy Lin, and Douglas W. Oard. &quot;Pairwise document similarity in large collections with MapReduce.&quot; 2008. [http://www.ece.umd.edu/~oard/pdf/acl08elsayed2.pdf] [[Inverted Index]]
* Ertöz, Levent et al. &quot;Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data.&quot; 2003. [http://static.msi.umn.edu/rreports/2003/73.pdf] [[Document Clustering]], [[DBSCAN]], [[SNN Clustering]], [[Euclidean Distance]], [[Curse of Dimensionality]], [[Chameleon Clustering]], [[CURE Clustering]], [[ROCK Clustering]]

=== F ===
=== G ===
* Gionis, Aristides, Piotr Indyk, and Rajeev Motwani. &quot;Similarity search in high dimensions via hashing.&quot; 1999. [http://www.cs.princeton.edu/courses/archive/spring13/cos598C/Gionis.pdf] [[Locality Sensitive Hashing]], [[Bit Sampling LSH]]

=== H ===
* Hopcroft, John, and Ravindran Kannan. &quot;Foundations of Data Science1.&quot; 2014. [[Power Iteration]]

=== I ===
=== J ===
* Jauregui, Jeff. &quot;Principal component analysis with linear algebra.&quot; 2012. [http://www.math.union.edu/~jaureguj/PCA.pdf] [[SVD]], [[Principal Component Analysis]]
* Jing, Liping. &quot;Survey of text clustering.&quot; 2008. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.3476&amp;rep=rep1&amp;type=pdf] [[Vector Space Model]], [[Document Clustering]], [[Cluster Analysis]], [[Subspace Clustering]], [[Semi-Supervised Clustering]]


=== K ===
* Kalman, Dan. &quot;A singularly valuable decomposition: the SVD of a matrix.&quot; 1996. [http://www.math.washington.edu/~morrow/498_13/svd.pdf] [[SVD]]
* Koll, Matthew B. &quot;WEIRD: An approach to concept-based information retrieval.&quot; 1979. [[Latent Semantic Analysis]]
* Korenius, Tuomo, Jorma Laurikkala, and Martti Juhola. &quot;On principal component analysis, cosine and Euclidean measures in information retrieval.&quot; 2007. [http://www.sciencedirect.com/science/article/pii/S0020025507002630] [[Principal Component Analysis]], [[Latent Semantic Analysis]], [[Distance Functions]], [[Cosine Similarity]], [[Euclidean Distance]]
* Kristianto, et al. &quot;Extracting definitions of mathematical expressions in scientific papers.&quot; 2012. [https://kaigi.org/jsai/webprogram/2012/pdf/719.pdf] [[Mathematical Definition Extraction]], [[Math-Aware POS Tagging]]
* Kristianto, et al. &quot;Extracting Textual Descriptions of Mathematical Expressions in Scientific Papers.&quot; 2014. [http://www.dlib.org/dlib/november14/kristianto/11kristianto.html] [[Mathematical Definition Extraction]]

=== L ===
* Landauer, T. et al. &quot;An introduction to latent semantic analysis.&quot; 1998. [http://tottdp.googlecode.com/files/LandauerFoltz-Laham1998.pdf] [[Latent Semantic Analysis]]
* Larsen, Bjornar et al. &quot;Fast and effective text mining using linear-time document clustering.&quot; 1999. [http://comminfo.rutgers.edu/~muresan/IR/Docs/Articles/sigkddLarsen1999.pdf] [[Document Clustering]]
* Li, Yong H., et al. &quot;Classification of text documents.&quot; 1998. [http://julio.staff.ipb.ac.id/files/2014/09/LiJ98.pdf] [[Term Clustering]]
* Liu, Tao, et al. &quot;An evaluation on feature selection for text clustering.&quot; 2003. [http://www.aaai.org/Papers/ICML/2003/ICML03-065.pdf] [[Term Contribution]]


=== M ===
=== N ===
=== O ===
* Oikonomakou, Nora, and Michalis Vazirgiannis. &quot;A review of web document clustering approaches.&quot; Data mining and knowledge discovery handbook. 2010. [https://scholar.google.com/scholar?cluster=1261203777431390097&amp;hl=ru&amp;as_sdt=0,5] [[Cluster Analysis]] [[Agglomerative Clustering]] [[K-Means]]
* Osinski, Stanislaw. &quot;Improving quality of search results clustering with approximate matrix factorisations.&quot; 2006. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.74&amp;rep=rep1&amp;type=pdf] [[Non-Negative Matrix Factorization]]

=== P ===
* Pagael, Rober, and Moritz Schubotz. &quot;Mathematical Language Processing Project.&quot; 2014. [http://arxiv.org/abs/1407.0167] [[Mathematical Definition Extraction]] [[Math-Aware POS Tagging]]
* Paulevé, Loïc, et al. &quot;Locality sensitive hashing: A comparison of hash function types and querying mechanisms.&quot; 2010. [https://hal.inria.fr/inria-00567191/document] [[Locality Sensitive Hashing]], [[K-Means LSH]]


=== Q ===
=== R ===
=== S ===
* Salton, et al. &quot;A vector space model for automatic indexing.&quot; 1975. [http://cgis.cs.umd.edu/class/fall2009/cmsc828r/PAPERS/VSM_salton-2.pdf] [[Vector Space Model]]
* Salton, Buckley. &quot;Term-weighting approaches in automatic text retrieval.&quot; 1988. [http://www.cs.odu.edu/~jbollen/spring03_IR/readings/article1-29-03.pdf] [[TF-IDF]]
* Schelter, Sebastian, et al. &quot;Efficient Sample Generation for Scalable Meta Learning.&quot; [http://ssc.io/wp-content/uploads/2014/11/ICDE15_research_150.pdf]. 2014. [[Meta Learning]]
* Schöneberg et al. &quot;POS Tagging and its Applications for Mathematics.&quot; 2014. [[Math-Aware POS Tagging]]
* Sculley, David. &quot;Web-scale k-means clustering.&quot; 2010. [http://www.ra.ethz.ch/CDstore/www2010/www/p1177.pdf] [[K-Means]]
* Sebastiani, Fabrizio. &quot;Machine learning in automated text categorization.&quot; 2002. [http://arxiv.org/pdf/cs/0110053.pdf] [[Document Classification]], [[Term Clustering]]
* Slaney, Malcolm, and Michael Casey. &quot;Locality-sensitive hashing for finding nearest neighbors [lecture notes].&quot; 2008. [http://web.iitd.ac.in/~sumeet/Slaney2008-LSHTutorial.pdf] [[Locality Sensitive Hashing]], [[Euclidean LSH]]
* Steinbach, Michael, et al. &quot;A comparison of document clustering techniques.&quot; 2000. [[Document Clustering]], [[K-Means]]
* Strang, Gilbert. &quot;The fundamental theorem of linear algebra.&quot; 1993. [http://www.engineering.iastate.edu/~julied/classes/CE570/Notes/strangpaper.pdf] [[SVD]]


=== T ===
=== U ===
=== V ===
=== W ===
* Wilbur, W. John, &quot;The automatic identification of stop words.&quot; 1992. [http://www.researchgate.net/publication/247786801_The_automatic_identification_of_stop_words] [[Stop Words]], [[Term Strength]]

=== X ===
* Xu, Wei, Xin Liu, and Yihong Gong. &quot;Document clustering based on non-negative matrix factorization.&quot; 2003. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.2293&amp;rep=rep1&amp;type=pdf] [[Cluster Analysis]], [[Non-Negative Matrix Factorization]]

=== Y ===

=== Z ===
* Zhai, ChengXiang. &quot;Statistical language models for information retrieval.&quot; (Book) 2008. [[Information Retrieval]], [[Statistical Language Models]], [[Multinomial Distribution]], [[Smoothing for Language Models]], [[TF-IDF]], [[Probabilistic Retrieval Model]]
* Zhukov, Leonid, and David Gleich. &quot;Topic identification in soft clustering using PCA and ICA&quot;. 2004. [http://leonidzhukov.ru/papers/soft-clustering-pca-ica.pdf] [[Latent Semantic Analysis]]

[[Category:Papers]]
[[Category:Notes]]</text>
      <sha1>d2swficn31jfmvfq4ftht0zi94u4dfn</sha1>
    </revision>
    <revision>
      <id>758</id>
      <parentid>630</parentid>
      <timestamp>2017-04-25T20:50:54Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9029">== Sources Index ==
Only papers I read and used as sources (or small books that don't deserve a separate wiki page)
* ordered by first author
* ABCDEFGHIJKLMNOPQRSTUVWXYZ


=== A ===
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. 2012. [[Document Clustering]], [[K-Means]], [[K-Medoids]], [[Co-Clustering]], [[Two-Phase Document Clustering]], [[Non-Negative Matrix Factorization]], [[Semi-Supervised Clustering]], [[Topic Models]], [[Probabilistic LSA]], [[Term Strength]], [[Term Contribution]], [[Stop Words]]

=== B ===
=== C ===
* Cristianini, Nello, John Shawe-Taylor, and Huma Lodhi. &quot;Latent semantic kernels.&quot; 2002. [http://eprints.soton.ac.uk/259781/1/LatentSemanticKernals_JIIS_18.pdf] [[Kernel Methods]] [[Latent Semantic Kernels]]
* Cutting, et al. &quot;Scatter/gather: A cluster-based approach to browsing large document collections.&quot; 1992. [http://courses.washington.edu/info320/au11/readings/Week4.Cutting.et.al.1992.Scatter-Gather.pdf] [[Scatter/Gather]]

=== D ===
* Datar, Mayur, et al. &quot;Locality-sensitive hashing scheme based on p-stable distributions.&quot; 2004. [http://www.cs.princeton.edu/courses/archive/spring05/cos598E/bib/p253-datar.pdf] [[Locality Sensitive Hashing]], [[Euclidean LSH]]
* De Kok D., Brouwer H. &quot;Natural language processing for the working programmer&quot;, 2011. [[Collocation Extraction]]
* De Smet, Yves. &quot;An introduction to multicriteria decision aid: The PROMETHEE and GAIA methods.&quot; [[PROMETHEE]]
* Deerwester, Scott C., et al. &quot;Indexing by latent semantic analysis.&quot; 1990. [http://www.cob.unt.edu/itds/faculty/evangelopoulos/dsci5910/LSA_Deerwester1990.pdf] [[Latent Semantic Analysis]]
* Domingos, Pedro. &quot;A few useful things to know about machine learning.&quot; 2012. [https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf] [[Overfitting]]

=== E ===
* Elsayed, Tamer, Jimmy Lin, and Douglas W. Oard. &quot;Pairwise document similarity in large collections with MapReduce.&quot; 2008. [http://www.ece.umd.edu/~oard/pdf/acl08elsayed2.pdf] [[Inverted Index]]
* Ertöz, Levent et al. &quot;Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data.&quot; 2003. [http://static.msi.umn.edu/rreports/2003/73.pdf] [[Document Clustering]], [[DBSCAN]], [[SNN Clustering]], [[Euclidean Distance]], [[Curse of Dimensionality]], [[Chameleon Clustering]], [[CURE Clustering]], [[ROCK Clustering]]

=== F ===
=== G ===
* Gionis, Aristides, Piotr Indyk, and Rajeev Motwani. &quot;Similarity search in high dimensions via hashing.&quot; 1999. [http://www.cs.princeton.edu/courses/archive/spring13/cos598C/Gionis.pdf] [[Locality Sensitive Hashing]], [[Bit Sampling LSH]]

=== H ===
* Hopcroft, John, and Ravindran Kannan. &quot;Foundations of Data Science1.&quot; 2014. [[Power Iteration]]

=== I ===
=== J ===
* Jauregui, Jeff. &quot;Principal component analysis with linear algebra.&quot; 2012. [http://www.math.union.edu/~jaureguj/PCA.pdf] [[SVD]], [[Principal Component Analysis]]
* Jing, Liping. &quot;Survey of text clustering.&quot; 2008. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.3476&amp;rep=rep1&amp;type=pdf] [[Vector Space Model]], [[Document Clustering]], [[Cluster Analysis]], [[Subspace Clustering]], [[Semi-Supervised Clustering]]


=== K ===
* Kalman, Dan. &quot;A singularly valuable decomposition: the SVD of a matrix.&quot; 1996. [http://www.math.washington.edu/~morrow/498_13/svd.pdf] [[SVD]]
* Koll, Matthew B. &quot;WEIRD: An approach to concept-based information retrieval.&quot; 1979. [[Latent Semantic Analysis]]
* Korenius, Tuomo, Jorma Laurikkala, and Martti Juhola. &quot;On principal component analysis, cosine and Euclidean measures in information retrieval.&quot; 2007. [http://www.sciencedirect.com/science/article/pii/S0020025507002630] [[Principal Component Analysis]], [[Latent Semantic Analysis]], [[Distance Functions]], [[Cosine Similarity]], [[Euclidean Distance]]
* Kristianto, et al. &quot;Extracting definitions of mathematical expressions in scientific papers.&quot; 2012. [https://kaigi.org/jsai/webprogram/2012/pdf/719.pdf] [[Mathematical Definition Extraction]], [[Math-Aware POS Tagging]]
* Kristianto, et al. &quot;Extracting Textual Descriptions of Mathematical Expressions in Scientific Papers.&quot; 2014. [http://www.dlib.org/dlib/november14/kristianto/11kristianto.html] [[Mathematical Definition Extraction]]

=== L ===
* Landauer, T. et al. &quot;An introduction to latent semantic analysis.&quot; 1998. [http://tottdp.googlecode.com/files/LandauerFoltz-Laham1998.pdf] [[Latent Semantic Analysis]]
* Larsen, Bjornar et al. &quot;Fast and effective text mining using linear-time document clustering.&quot; 1999. [http://comminfo.rutgers.edu/~muresan/IR/Docs/Articles/sigkddLarsen1999.pdf] [[Document Clustering]]
* Lee, K., Lee, Y. et al &quot;Parallel data processing with MapReduce: a survey&quot; 2012. [http://www.cs.arizona.edu/~bkmoon/papers/sigmodrec11.pdf] [[Hadoop]], [[MapReduce]], [[Hadoop MapReduce]]
* Li, Yong H., et al. &quot;Classification of text documents.&quot; 1998. [http://julio.staff.ipb.ac.id/files/2014/09/LiJ98.pdf] [[Term Clustering]]
* Liu, Tao, et al. &quot;An evaluation on feature selection for text clustering.&quot; 2003. [http://www.aaai.org/Papers/ICML/2003/ICML03-065.pdf] [[Term Contribution]]


=== M ===
Manning C., Schütze H. &quot;Foundations of statistical natural language processing&quot;, 1999. [[Collocation Extraction]]

=== N ===
=== O ===
* Oikonomakou, N, Vazirgiannis, M. &quot;A review of web document clustering approaches.&quot; Data mining and knowledge discovery handbook. 2010. [https://scholar.google.com/scholar?cluster=1261203777431390097&amp;hl=ru&amp;as_sdt=0,5] [[Cluster Analysis]] [[Agglomerative Clustering]] [[K-Means]]
* Osinski, S. &quot;Improving quality of search results clustering with approximate matrix factorisations.&quot; 2006. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.74&amp;rep=rep1&amp;type=pdf] [[Non-Negative Matrix Factorization]]
* Ordonez, C, et al, &quot;Relational versus non-relational database systems for data warehousing.&quot; 2010. [http://www2.cs.uh.edu/~ordonez/w-2010-DOLAP-relnonrel.pdf] [[Hadoop]], [[Hadoop MapReduce]]

=== P ===
* Pagael R, Schubotz M. &quot;Mathematical Language Processing Project.&quot; 2014. [http://arxiv.org/abs/1407.0167] [[Mathematical Definition Extraction]] [[Math-Aware POS Tagging]]
* Paulevé, L. et al. &quot;Locality sensitive hashing: A comparison of hash function types and querying mechanisms.&quot; 2010. [https://hal.inria.fr/inria-00567191/document] [[Locality Sensitive Hashing]], [[K-Means LSH]]
* Petrović S. et al. &quot;Comparison of collocation extraction measures for document indexing&quot;, 2006. [http://bib.irb.hr/datoteka/251298.110-4-157-203.pdf]


=== Q ===
=== R ===
=== S ===
* Salton, et al. &quot;A vector space model for automatic indexing.&quot; 1975. [http://cgis.cs.umd.edu/class/fall2009/cmsc828r/PAPERS/VSM_salton-2.pdf] [[Vector Space Model]]
* Salton, Buckley. &quot;Term-weighting approaches in automatic text retrieval.&quot; 1988. [http://www.cs.odu.edu/~jbollen/spring03_IR/readings/article1-29-03.pdf] [[TF-IDF]]
* Schelter, Sebastian, et al. &quot;Efficient Sample Generation for Scalable Meta Learning.&quot; [http://ssc.io/wp-content/uploads/2014/11/ICDE15_research_150.pdf]. 2014. [[Meta Learning]]
* Schöneberg et al. &quot;POS Tagging and its Applications for Mathematics.&quot; 2014. [[Math-Aware POS Tagging]]
* Sculley, David. &quot;Web-scale k-means clustering.&quot; 2010. [http://www.ra.ethz.ch/CDstore/www2010/www/p1177.pdf] [[K-Means]]
* Sebastiani, Fabrizio. &quot;Machine learning in automated text categorization.&quot; 2002. [http://arxiv.org/pdf/cs/0110053.pdf] [[Document Classification]], [[Term Clustering]]
* Slaney, Malcolm, and Michael Casey. &quot;Locality-sensitive hashing for finding nearest neighbors [lecture notes].&quot; 2008. [http://web.iitd.ac.in/~sumeet/Slaney2008-LSHTutorial.pdf] [[Locality Sensitive Hashing]], [[Euclidean LSH]]
* Steinbach, Michael, et al. &quot;A comparison of document clustering techniques.&quot; 2000. [[Document Clustering]], [[K-Means]]
* Strang, Gilbert. &quot;The fundamental theorem of linear algebra.&quot; 1993. [http://www.engineering.iastate.edu/~julied/classes/CE570/Notes/strangpaper.pdf] [[SVD]]


=== T ===
=== U ===
=== V ===
=== W ===
* Wilbur, W. John, &quot;The automatic identification of stop words.&quot; 1992. [http://www.researchgate.net/publication/247786801_The_automatic_identification_of_stop_words] [[Stop Words]], [[Term Strength]]

=== X ===
* Xu, Wei, Xin Liu, and Yihong Gong. &quot;Document clustering based on non-negative matrix factorization.&quot; 2003. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.2293&amp;rep=rep1&amp;type=pdf] [[Cluster Analysis]], [[Non-Negative Matrix Factorization]]

=== Y ===

=== Z ===
* Zhai, ChengXiang. &quot;Statistical language models for information retrieval.&quot; (Book) 2008. [[Information Retrieval]], [[Statistical Language Models]], [[Multinomial Distribution]], [[Smoothing for Language Models]], [[TF-IDF]], [[Probabilistic Retrieval Model]]
* Zhukov, Leonid, and David Gleich. &quot;Topic identification in soft clustering using PCA and ICA&quot;. 2004. [http://leonidzhukov.ru/papers/soft-clustering-pca-ica.pdf] [[Latent Semantic Analysis]]

[[Category:Papers]]
[[Category:Notes]]</text>
      <sha1>ewjfcvkyu2ywzzihxv4nt2v5qwmr2dr</sha1>
    </revision>
    <revision>
      <id>821</id>
      <parentid>758</parentid>
      <timestamp>2018-05-21T20:29:21Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9198">== Sources Index ==
Only papers I read and used as sources (or small books that don't deserve a separate wiki page)
* ordered by first author
* ABCDEFGHIJKLMNOPQRSTUVWXYZ


=== A ===
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. 2012. [[Document Clustering]], [[K-Means]], [[K-Medoids]], [[Co-Clustering]], [[Two-Phase Document Clustering]], [[Non-Negative Matrix Factorization]], [[Semi-Supervised Clustering]], [[Topic Models]], [[Probabilistic LSA]], [[Term Strength]], [[Term Contribution]], [[Stop Words]]

=== B ===
=== C ===
* Cristianini, Nello, John Shawe-Taylor, and Huma Lodhi. &quot;Latent semantic kernels.&quot; 2002. [http://eprints.soton.ac.uk/259781/1/LatentSemanticKernals_JIIS_18.pdf] [[Kernel Methods]] [[Latent Semantic Kernels]]
* Cutting, et al. &quot;Scatter/gather: A cluster-based approach to browsing large document collections.&quot; 1992. [http://courses.washington.edu/info320/au11/readings/Week4.Cutting.et.al.1992.Scatter-Gather.pdf] [[Scatter/Gather]]

=== D ===
* Datar, Mayur, et al. &quot;Locality-sensitive hashing scheme based on p-stable distributions.&quot; 2004. [http://www.cs.princeton.edu/courses/archive/spring05/cos598E/bib/p253-datar.pdf] [[Locality Sensitive Hashing]], [[Euclidean LSH]]
* De Kok D., Brouwer H. &quot;Natural language processing for the working programmer&quot;, 2011. [[Collocation Extraction]]
* De Smet, Yves. &quot;An introduction to multicriteria decision aid: The PROMETHEE and GAIA methods.&quot; [[PROMETHEE]]
* Deerwester, Scott C., et al. &quot;Indexing by latent semantic analysis.&quot; 1990. [http://www.cob.unt.edu/itds/faculty/evangelopoulos/dsci5910/LSA_Deerwester1990.pdf] [[Latent Semantic Analysis]]
* Domingos, Pedro. &quot;A few useful things to know about machine learning.&quot; 2012. [https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf] [[Overfitting]]

=== E ===
* Elsayed, Tamer, Jimmy Lin, and Douglas W. Oard. &quot;Pairwise document similarity in large collections with MapReduce.&quot; 2008. [http://www.ece.umd.edu/~oard/pdf/acl08elsayed2.pdf] [[Inverted Index]]
* Ertöz, Levent et al. &quot;Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data.&quot; 2003. [http://static.msi.umn.edu/rreports/2003/73.pdf] [[Document Clustering]], [[DBSCAN]], [[SNN Clustering]], [[Euclidean Distance]], [[Curse of Dimensionality]], [[Chameleon Clustering]], [[CURE Clustering]], [[ROCK Clustering]]

=== F ===
=== G ===
* Gionis, Aristides, Piotr Indyk, and Rajeev Motwani. &quot;Similarity search in high dimensions via hashing.&quot; 1999. [http://www.cs.princeton.edu/courses/archive/spring13/cos598C/Gionis.pdf] [[Locality Sensitive Hashing]], [[Bit Sampling LSH]]

=== H ===
* Hopcroft, John, and Ravindran Kannan. &quot;Foundations of Data Science1.&quot; 2014. [[Power Iteration]]

=== I ===
=== J ===
* Jauregui, Jeff. &quot;Principal component analysis with linear algebra.&quot; 2012. [http://www.math.union.edu/~jaureguj/PCA.pdf] [[SVD]], [[Principal Component Analysis]]
* Jing, Liping. &quot;Survey of text clustering.&quot; 2008. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.3476&amp;rep=rep1&amp;type=pdf] [[Vector Space Model]], [[Document Clustering]], [[Cluster Analysis]], [[Subspace Clustering]], [[Semi-Supervised Clustering]]


=== K ===
* Kalman, Dan. &quot;A singularly valuable decomposition: the SVD of a matrix.&quot; 1996. [http://www.math.washington.edu/~morrow/498_13/svd.pdf] [[SVD]]
* Koll, Matthew B. &quot;WEIRD: An approach to concept-based information retrieval.&quot; 1979. [[Latent Semantic Analysis]]
* Korenius, Tuomo, Jorma Laurikkala, and Martti Juhola. &quot;On principal component analysis, cosine and Euclidean measures in information retrieval.&quot; 2007. [http://www.sciencedirect.com/science/article/pii/S0020025507002630] [[Principal Component Analysis]], [[Latent Semantic Analysis]], [[Distance Functions]], [[Cosine Similarity]], [[Euclidean Distance]]
* Kristianto, et al. &quot;Extracting definitions of mathematical expressions in scientific papers.&quot; 2012. [https://kaigi.org/jsai/webprogram/2012/pdf/719.pdf] [[Mathematical Definition Extraction]], [[Math-Aware POS Tagging]]
* Kristianto, et al. &quot;Extracting Textual Descriptions of Mathematical Expressions in Scientific Papers.&quot; 2014. [http://www.dlib.org/dlib/november14/kristianto/11kristianto.html] [[Mathematical Definition Extraction]]

=== L ===
* Landauer, T. et al. &quot;An introduction to latent semantic analysis.&quot; 1998. [http://tottdp.googlecode.com/files/LandauerFoltz-Laham1998.pdf] [[Latent Semantic Analysis]]
* Larsen, Bjornar et al. &quot;Fast and effective text mining using linear-time document clustering.&quot; 1999. [http://comminfo.rutgers.edu/~muresan/IR/Docs/Articles/sigkddLarsen1999.pdf] [[Document Clustering]]
* Lee, K., Lee, Y. et al &quot;Parallel data processing with MapReduce: a survey&quot; 2012. [http://www.cs.arizona.edu/~bkmoon/papers/sigmodrec11.pdf] [[Hadoop]], [[MapReduce]], [[Hadoop MapReduce]]
* Lee K., Jalali A., Dasdan A. &quot;Real time bid optimization with smooth budget delivery in online advertising&quot;, 2013. [https://arxiv.org/abs/1305.3011] [[Budget Pacing]]
* Li, Yong H., et al. &quot;Classification of text documents.&quot; 1998. [http://julio.staff.ipb.ac.id/files/2014/09/LiJ98.pdf] [[Term Clustering]]
* Liu, Tao, et al. &quot;An evaluation on feature selection for text clustering.&quot; 2003. [http://www.aaai.org/Papers/ICML/2003/ICML03-065.pdf] [[Term Contribution]]


=== M ===
Manning C., Schütze H. &quot;Foundations of statistical natural language processing&quot;, 1999. [[Collocation Extraction]]

=== N ===
=== O ===
* Oikonomakou, N, Vazirgiannis, M. &quot;A review of web document clustering approaches.&quot; Data mining and knowledge discovery handbook. 2010. [https://scholar.google.com/scholar?cluster=1261203777431390097&amp;hl=ru&amp;as_sdt=0,5] [[Cluster Analysis]] [[Agglomerative Clustering]] [[K-Means]]
* Osinski, S. &quot;Improving quality of search results clustering with approximate matrix factorisations.&quot; 2006. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.74&amp;rep=rep1&amp;type=pdf] [[Non-Negative Matrix Factorization]]
* Ordonez, C, et al, &quot;Relational versus non-relational database systems for data warehousing.&quot; 2010. [http://www2.cs.uh.edu/~ordonez/w-2010-DOLAP-relnonrel.pdf] [[Hadoop]], [[Hadoop MapReduce]]

=== P ===
* Pagael R, Schubotz M. &quot;Mathematical Language Processing Project.&quot; 2014. [http://arxiv.org/abs/1407.0167] [[Mathematical Definition Extraction]] [[Math-Aware POS Tagging]]
* Paulevé, L. et al. &quot;Locality sensitive hashing: A comparison of hash function types and querying mechanisms.&quot; 2010. [https://hal.inria.fr/inria-00567191/document] [[Locality Sensitive Hashing]], [[K-Means LSH]]
* Petrović S. et al. &quot;Comparison of collocation extraction measures for document indexing&quot;, 2006. [http://bib.irb.hr/datoteka/251298.110-4-157-203.pdf]


=== Q ===
=== R ===
=== S ===
* Salton, et al. &quot;A vector space model for automatic indexing.&quot; 1975. [http://cgis.cs.umd.edu/class/fall2009/cmsc828r/PAPERS/VSM_salton-2.pdf] [[Vector Space Model]]
* Salton, Buckley. &quot;Term-weighting approaches in automatic text retrieval.&quot; 1988. [http://www.cs.odu.edu/~jbollen/spring03_IR/readings/article1-29-03.pdf] [[TF-IDF]]
* Schelter, Sebastian, et al. &quot;Efficient Sample Generation for Scalable Meta Learning.&quot; [http://ssc.io/wp-content/uploads/2014/11/ICDE15_research_150.pdf]. 2014. [[Meta Learning]]
* Schöneberg et al. &quot;POS Tagging and its Applications for Mathematics.&quot; 2014. [[Math-Aware POS Tagging]]
* Sculley, David. &quot;Web-scale k-means clustering.&quot; 2010. [http://www.ra.ethz.ch/CDstore/www2010/www/p1177.pdf] [[K-Means]]
* Sebastiani, Fabrizio. &quot;Machine learning in automated text categorization.&quot; 2002. [http://arxiv.org/pdf/cs/0110053.pdf] [[Document Classification]], [[Term Clustering]]
* Slaney, Malcolm, and Michael Casey. &quot;Locality-sensitive hashing for finding nearest neighbors [lecture notes].&quot; 2008. [http://web.iitd.ac.in/~sumeet/Slaney2008-LSHTutorial.pdf] [[Locality Sensitive Hashing]], [[Euclidean LSH]]
* Steinbach, Michael, et al. &quot;A comparison of document clustering techniques.&quot; 2000. [[Document Clustering]], [[K-Means]]
* Strang, Gilbert. &quot;The fundamental theorem of linear algebra.&quot; 1993. [http://www.engineering.iastate.edu/~julied/classes/CE570/Notes/strangpaper.pdf] [[SVD]]


=== T ===
=== U ===
=== V ===
=== W ===
* Wilbur, W. John, &quot;The automatic identification of stop words.&quot; 1992. [http://www.researchgate.net/publication/247786801_The_automatic_identification_of_stop_words] [[Stop Words]], [[Term Strength]]

=== X ===
* Xu, Wei, Xin Liu, and Yihong Gong. &quot;Document clustering based on non-negative matrix factorization.&quot; 2003. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.2293&amp;rep=rep1&amp;type=pdf] [[Cluster Analysis]], [[Non-Negative Matrix Factorization]]

=== Y ===

=== Z ===
* Zhai, ChengXiang. &quot;Statistical language models for information retrieval.&quot; (Book) 2008. [[Information Retrieval]], [[Statistical Language Models]], [[Multinomial Distribution]], [[Smoothing for Language Models]], [[TF-IDF]], [[Probabilistic Retrieval Model]]
* Zhukov, Leonid, and David Gleich. &quot;Topic identification in soft clustering using PCA and ICA&quot;. 2004. [http://leonidzhukov.ru/papers/soft-clustering-pca-ica.pdf] [[Latent Semantic Analysis]]

[[Category:Papers]]
[[Category:Notes]]</text>
      <sha1>m4huw80fr1o00v30nqxyf024y0z8slb</sha1>
    </revision>
  </page>
  <page>
    <title>Types of Data</title>
    <ns>0</ns>
    <id>628</id>
    <revision>
      <id>631</id>
      <timestamp>2015-06-24T20:15:34Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="862">== Types of Data ==
There are two types of data:
* with data model: structured, know what to expect
* without data model: structured, have to impose some structure, harder to know what to expect


== With [[Data Model]] ==
=== Structured ===
* Relations in a [[Relational Databases]]
* [[Relational Databases#Relational Data Model|Relational Data Model]]


=== Semi-structured ===
* [[XML]], HTML, [[JSON]]
* Also have some [[Data Model]]: [[Semi-Structured Data Model]]
* Data Model can be expressed via constrains with schemas: [[DTD]] or [[XML Schema]]


== No [[Data Model]] ==
=== Unstructured ===
* Free text: need [[Text Mining]] and [[NLP]] techniques
* Audio, Video
* Use [[Information Retrieval]] to index and structure unstructured data - especially text


=== Machine-generated data ===
* Sensors, 
* [[Internet of Things]]


[[Category:Data Models]]</text>
      <sha1>psezxwnjuhxnb4eolu1y29mdaof51kn</sha1>
    </revision>
  </page>
  <page>
    <title>Information Retrieval (UFRT)</title>
    <ns>0</ns>
    <id>629</id>
    <revision>
      <id>632</id>
      <timestamp>2015-06-26T08:14:14Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1320">== Information Retrieval (UFRT) ==
Course taken in the winter semester of the 2013-2014 year at UFRT. 

Taught by 
* Veronika Peralta
* Patrick Marcel
* Agata Savary
* Jean-Yves Antoine
* Anaïs Lefeuvre


== Course Content ==
=== Introduction ===
* [[Information Retrieval]]
* [[NLP Pipeline]]
** [[Tokenization]]
** [[Stop Words|Stop Words Removal]]
** [[Text Normalization]]
** [[Stemming]] or [[Lemmatization]]
** [[Spelling Correction]]
** [[Phonetic Normalization]] (e.g. with [[Soundex]]) 
* [[Vector Space Model]], [[TF-IDF]]
* [[Inverted Index]]
* other [[Information Retrieval Models]]


=== Ranking and Rating ===
* Preferences, Query Expansion, Recommendations
* [[PageRank]]: Markov ranking in Web search


=== [[Natural Language Processing]] in IR ===
* General introduction: applications of NLP and linguistic level of description
* Morphology: linguistic modeling (compound words), [[Stemming]], [[Lemmatization]]
* Terminology: motivation and applications
* Morphology and syntax: [[POS Tagging]], [[Named Entities Recognition]]
* Syntax: parsing


=== Semantic Analysis ===
* (Mentioned in the course description, but wasn't taught)
* Semantic processing for information retrieval: [[Latent Semantic Analysis]]


[[Category:IT4BI]]
[[Category:Notes]]
[[Category:Information Retrieval]]
[[Category:NLP]]</text>
      <sha1>d4a7t5yswtw7pyw43ektejwch93haxe</sha1>
    </revision>
  </page>
  <page>
    <title>Category:IT4BI</title>
    <ns>14</ns>
    <id>630</id>
    <revision>
      <id>633</id>
      <timestamp>2015-06-26T08:23:31Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="41">[[Category:Education]]
[[Category:Notes]]</text>
      <sha1>8tzctm5nmhq82optodjifecvzctcgzn</sha1>
    </revision>
  </page>
  <page>
    <title>Category:EdX</title>
    <ns>14</ns>
    <id>631</id>
    <revision>
      <id>634</id>
      <timestamp>2015-06-26T08:23:41Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="41">[[Category:Education]]
[[Category:Notes]]</text>
      <sha1>8tzctm5nmhq82optodjifecvzctcgzn</sha1>
    </revision>
  </page>
  <page>
    <title>Distance Functions</title>
    <ns>0</ns>
    <id>632</id>
    <revision>
      <id>635</id>
      <timestamp>2015-07-04T15:28:57Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="965">{{stub}}

== Distance ==
A metric function (or distance) is a generalization of geometric distance (i.e. [[Euclidean Distance]])


Direct similarity measures are not always reliable for high-dimensional clustering (see Guha1999)
* [[Euclidean Distance]]
* [[Edit Distance]]


Similarity is the opposite of distance
* usually can be turned to distance 
* [[Cosine Similarity]] and [[Dot Product]]
* [[Jaccard Coefficient]]


Non-metric
* [[KL Divergence]]


== Resources ==
* Strehl, Alexander, Joydeep Ghosh, and Raymond Mooney. &quot;Impact of similarity measures on web-page clustering.&quot; 2000. [http://strehl.com/download/strehl-aaai00.pdf]
* Guha, Sudipto, Rajeev Rastogi, and Kyuseok Shim. &quot;ROCK: A robust clustering algorithm for categorical attributes.&quot; 1999. [http://www.cacs.louisiana.edu/~jyoon/grad/adb/References/clustering/ROCK-clus99icde.pdf]


== Source ==
* http://en.wikipedia.org/wiki/Metric_%28mathematics%29


[[Category:Distances]]
[[Category:Norms]]</text>
      <sha1>14zh4n0ejbbsrwswgjnzmmu9ivpc6kc</sha1>
    </revision>
  </page>
  <page>
    <title>Mathematical Definition Extraction</title>
    <ns>0</ns>
    <id>633</id>
    <revision>
      <id>636</id>
      <timestamp>2015-06-27T10:21:59Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9551">== Mathematical Definition Extraction ==
Mathematical expressions are hard to understand without the natural language description, so
we want to find identifiers in the mathematical expressions and extract their definition from the surrounding text

Example: 
* The precision $P$ is defined as $P = \cfrac{w}{w + y}$ where $w$ is the number of correctly labeled pairs and $y$ is the number of incorrectly labeled pairs
** want to extract:
** ($P$, &quot;precision&quot;)
** ($w$, &quot;the number of correctly labeled pairs&quot;)
** ($y$, &quot;the number of incorrectly labeled pairs&quot;)
* Let $e$ be the base of natural logarithm 
** ($e$, &quot;the base of natural logarithm&quot;)


=== Definition ===
A phrase that defines a mathematical expression consists of three parts: (Kristianto 12)
* definiendum (math expression/identifier - term to be defined) The term—word or phrase—defined in a definition. 
* definiens (definition): The word or phrase that defines the definiendum in a definition. 
* definitor (relator verb)

We are interested only in parts 1 and 2, and we will call them ''relations''

An identifier is a mathematical 

=== Automatic Definition Extraction ===
The definitions of mathematical expressions and identifiers can be found from 
the natural text description around the expression. 

Assumption: the definitions of mathematical expressions are always noun phrases

A noun phrase can be 
* just a noun
* compound noun
* compound noun with a clause, prepositional phrase, etc

We have an identifier and want to find what it stands for. 


== Preprocessing ==
The typical pipeline is the following:
* Latex documents / Wiki Documents
* =&gt; [[MathML]] 
* =&gt; Extract identifiers from MathML
* =&gt; Replace formulas with tags
* =&gt; Annotate ([[Math-Aware POS Tagging]])
* =&gt; Find relations in text


For example:

* http://habrastorage.org/files/025/1f5/4fa/0251f54fa7a248faa6718839ee060b53.png
* http://habrastorage.org/files/99a/bff/9f0/99abff9f0b81438bac258c9c286d9950.png
* add MLP flow


== Extraction Methods ==
=== Nearest Noun Method ===
Definition is a combination of adjectives and nouns (also sometimes determinants) in the text before the identifier

This way it only can be compound nouns without additional phrases. 


E.g:
* &quot;In other words, the bijection $\sigma$ normalizes $G$ in ...&quot;
* It will extract relations ($\sigma$, &quot;bijection&quot;)


Papers:
* Grigore, Mihai, Magdalena Wolska, and Michael Kohlhase. &quot;Towards context-based disambiguation of mathematical expressions.&quot; The Joint Conference of ASCM. 2009. ([https://svn.kwarc.info/repos/www/people/mgrigore/publications/ASCMtalk.pdf pdf])
* Yokoi, Keisuke, et al. &quot;Contextual analysis of mathematical expressions for advanced mathematical search.&quot; Prof. of 12th International Conference on Intelligent Text Processing and Comptational Linguistics (CICLing 2011), Tokyo, Japan, February. 2011. ([http://www.scielo.org.mx/pdf/poli/n43/n43a11.pdf pdf])


=== Pattern Matching Methods ===
Use patterns to extract definitions

For example, 

* DESC IDENTIFIER (this is actually the same as nearest noun method)
* let|set IDENTIFIER denote|denotes|be DESC
* DESC is|are denoted|defined|given as|by IDENTIFIER
* IDENTIFIER denotes|dentore|stand|stands as|by IDENTIFIER
* IDENTIFIER is|are DESC
* DESC is|are IDENTIFIER
* others 

Patterns taken from
* Trzeciak, Jerzy. Writing mathematical papers in English: a practical guide. European Mathematical Society, 1995.
* frequent sentence patterns from Graphs and Combinatorics papers from Springer


Papers: 
* Quoc, Minh Nghiem, et al. &quot;Mining coreference relations between formulas and text using Wikipedia.&quot; 23rd International Conference on Computational Linguistics. 2010. ([http://lexitron.nectec.or.th/public/COLING-2010_Beijing_China/NLPIX/NLPIX-2010.pdf#page=77 pdf]) 
* in other papers usually is used as the baseline to compare with

Tools:
* [https://github.com/alexeygrigorev/rseq rseq] is a convenient tool for Java for doing this


=== Machine Learning Based Methods ===
Formulates definition extraction as a binary classification problem 

* find candidate pairs (identifier, candidate definition)
* candidates are nouns and noun phrases from the same sentence as the expression


Features: 
* sentence patterns (true if one of the patterns can capture this relation - could be separate feature for each pattern)
* if there's a colon/comma between candidate and identifier
* if there's another math expression between
* if candidate is inside parentheses and identifier is outside 
* word-distance between candidate and identifier 
* position of candidate relative to identifier
* text and POS tag of one/two/three preceding and following tokens around the candidate
* unigram/bigram/trigram of previous features
* text of first verb between candidate and identifier
* hop-distance in the dependency tree between the candidate and identifier
* ...

Classifiers: 
* [[SVM]] (linear kernel) (Kristianto14, Yokoi11)
* [[Conditional Random Fields]] (Kristianto12)


Papers 
* Yokoi, Keisuke, et al. &quot;Contextual analysis of mathematical expressions for advanced mathematical search.&quot; 2011. ([http://www.scielo.org.mx/pdf/poli/n43/n43a11.pdf pdf])
* Kristianto, Giovanni Yoko, et al. &quot;Extracting definitions of mathematical expressions in scientific papers.&quot; 2012. ([https://kaigi.org/jsai/webprogram/2012/pdf/719.pdf pdf])
* Kristianto, Giovanni Yoko, and Akiko Aizawa. &quot;Extracting Textual Descriptions of Mathematical Expressions in Scientific Papers.&quot; D-Lib Magazine 20.11 (2014) ([http://www.dlib.org/dlib/november14/kristianto/11kristianto.html html])


=== Probabilistic Approaches ===
Mathematical Language Processing (MLP) Approach: 

Rank candidate definitions by probablity and design an information extraction system that shots the most relevant (i.e. probable) definition to the reader to facilitate reading scientific texts with mathematics. 


Statistical definition discovery

The idea: the definitions occur very closely to identifiers in sentences.

* extract identifiers from MathML
* 

Two assumptions
* indentifier and its definition occur in the same sentence, so the candidates are taken only from the same sentences (as in the ML approach)
* definitions are likely occur earlier in the document when authors introduce the meaning of an identifier, in subsequent uses the definition is typically not repeated


Ranking:

* each candidate is ranked with the following weighed sum:
* $R(n, \Delta, t, d) = \cfrac{\alpha \, R_{\sigma_d}(\Delta) + \beta \, R_{\sigma_s}(n) + \gamma \, \text{tf}(t, s)}{\alpha + \beta + \gamma}$
* where
* $t$ is the candidate term
* $s$ set of sentences in the document
* $\Delta$ is the distance (the amount of word tokens) between identifier and the candidate term $t$
* $n$ ?

Gaussian: 
* $R_{\sigma}(\Delta) = \exp \left( -\cfrac{1}{2} \cdot {\Delta^2 - 1}{\sigma_2} \right)$
* we don't take the raw distance, but instead use a Gaussian of this distance 
* assume that the probability to find a relation at $\Delta = 1$ is maximal 

Parameters $\sigma_d$ and $\sigma_s$
* $\sigma_d$ - the standard deviation of Gaussian that models the distance to definition candidate 
** manual evaluation showed that $R_{\sigma_d}(1) \approx R_{\sigma_d}(5)$
** i.e. it's two times more likely to find the real definition at distance $\Delta=1$ than at distance $\Delta=5$
** thus $\sigma_d = \sqrt{\cfrac{12}{\ln 2}}$
* $\sigma_s$
** $\sigma_s = 2 \sqrt{\cfrac{1}{\ln 2}}$
* weights $\alpha, \beta, \gamma$
** $\alpha = \beta = 1$
** $\gamma = 0.1$ because some valid definitions may occur more often than other valid definitions, e.g. &quot;length&quot; vs &quot;Hamiltonian&quot;


Papers:
* Pagael, Schubotz. &quot;Mathematical Language Processing Project.&quot; arXiv preprint arXiv:1407.0167 (2014). ([http://arxiv.org/abs/1407.0167 abstract])


=== Other Ideas ===
Translation of mathematical formulas to English using machine-translation techniques
* Nghiem, Minh-Quoc, et al. &quot;Towards Mathematical Expression Understanding.&quot; ([http://inftyreader.org/06deims12_submission_7.pdf pdf])

Concept Description Formula: 
* relate entire formula to natural language description, e.g. 
* $a^2 + b^2 = c^2$ is Pythagorean theorem 


== Performance Measures ==

* Precision: 
** no of math expresssion with correctly extracted definitions / no of extracted definitions
* recall 
** no of math expresssion with correctly extracted definitions / no of expressions with definitions
* F1 = 2PR / (P + R)


== Applications ==
=== Semantic Search for Mathematical Formulas ===
Main challenges

* mathematical notation is context-dependent
* same identifier can stand for different mathematical objects
* same mathematical object can be referred to by different identifiers

So same problems as in NLP: a lot of ambiguity and variability


=== Others ===
* Mathematical search
* math knowledge bases: Interlinking scientific documents based on content of the formulas


== Sources ==
* Kristianto, Giovanni Yoko, et al. &quot;Extracting definitions of mathematical expressions in scientific papers.&quot; Proc. of the 26th Annual Conference of JSAI. 2012. ([https://kaigi.org/jsai/webprogram/2012/pdf/719.pdf pdf])
* Kristianto, Giovanni Yoko, and Akiko Aizawa. &quot;Extracting Textual Descriptions of Mathematical Expressions in Scientific Papers.&quot; D-Lib Magazine 20.11 (2014) ([http://www.dlib.org/dlib/november14/kristianto/11kristianto.html html])
* Pagael, Rober, and Moritz Schubotz. &quot;Mathematical Language Processing Project.&quot; arXiv preprint arXiv:1407.0167 (2014). ([http://arxiv.org/abs/1407.0167 abstract])

[[Category:NLP]]
[[Category:Thesis]]</text>
      <sha1>buhkfgqgkft3lxmuf5si1u64ceh9bus</sha1>
    </revision>
  </page>
  <page>
    <title>Math-Aware POS Tagging</title>
    <ns>0</ns>
    <id>634</id>
    <revision>
      <id>637</id>
      <timestamp>2015-06-27T10:32:23Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2109">== Math-Aware POS Tagging ==
[[POS Tagging]] is one of the [[NLP]]  task, but what about scientific documents with math expressions? 
* can adjust traditional POS Tagging methods to handle formulas 


=== Classification ===
[[Penn Treebank POS Scheme]] doesn't have special classes for mathematics.
What we can do is to add other math-related classes:

* '''ID''' for identifiers (e.g. &quot;... where $E$ stands for energy&quot;, $E$ should be tagged as ID)
* '''MATH''' for formulas (e.g. &quot;$E = mc^2$ is the mass-energy equivalence formula&quot;, &quot;$E = mc^2$ should be tagged as '''MATH''')


=== Text Preprocessing ===
Mathematical expressions are usually contained within special tags, e.g. inside tag &lt;code&gt;&amp;lt;math&amp;gt;&amp;lt;/math&amp;gt;&lt;/code&gt; for wikipedia, or inside &lt;code&gt;$$&lt;/code&gt; for latex documents. 

* We find all such mathematical expressions and replace each with a unique single token &quot;'''MATH_mathID'''&quot;
* the mathID could be a randomly generated string or result of some hash function applied to the content of formula. The latter approach is preferred when we want to have consistent strings across several runs. 
* Then we apply traditional [[POS Tagging]] techniques to the textual data. They typically will annotate such &quot;'''MATH_mathID'''&quot; tokens as nouns
* after that we may want to re-annotate all math tokens: if it contains only one identifier, we label it as '''ID''', if several - as '''MATH'''. But in some cases we want to keep original annotation
* after that we can bring the mathematical content back to the document


=== Usage ===
* Can be used in Mathematical NLP
* e.g. in [[Mathematical Definition Extraction]]


== Sources ==
* Kristianto, Giovanni Yoko, et al. &quot;Extracting definitions of mathematical expressions in scientific papers.&quot; 2012. [https://kaigi.org/jsai/webprogram/2012/pdf/719.pdf]
* Pagael, Robert, and Moritz Schubotz. &quot;Mathematical Language Processing Project.&quot; 2014. [http://arxiv.org/pdf/1407.0167]
* Schöneberg, Ulf, and Wolfram Sperber. &quot;POS Tagging and its Applications for Mathematics.&quot; 2014. [http://arxiv.org/pdf/1406.2880]


[[Category:NLP]]
[[Category:Thesis]]</text>
      <sha1>he5e8vk988583z3qtrg71jbaqhd6bq4</sha1>
    </revision>
  </page>
  <page>
    <title>Multiple Comparisons Tests</title>
    <ns>0</ns>
    <id>635</id>
    <revision>
      <id>638</id>
      <timestamp>2015-06-27T10:34:50Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="917">== Multiple Comparisons Tests ==

{{stub}}


== Family-Wise Error Rate ==
=== Controlling FWER ===
* suppose we run many tests at the same time 
* we perform a [[Pairwise t-test]] and want to compare 10 samples
* thus we need to make about $\sum_{i=1}^{10} i = 45$ comparisons
* the chances hight that among the 45 tests a couple of them will incorrectly reject $H_0$ - i.e. they will make Type 1 Error about 5% of the time at $\alpha = 0.05%$
* the solution: to modify the significance level - run the tests at significance level $\alpha^* &lt; \alpha$


== Corrections ==
=== Bonferroni Correction ===
use $\alpha^* = \alpha \cdot \cfrac{1}{K}$
* where $K$ is the number of tests to run 
* in a pairwise test of $k$ samples,  $K= \cfrac{k \cdot (k - 1)}{2}$



== Sources ==
* [[OpenIntro Statistics (book)]]
* http://en.wikipedia.org/wiki/Familywise_error_rate


[[Category:Statistics]]
[[Category:Statistical Tests]]</text>
      <sha1>ox13yx7sgzx3w2uapfnr0r0fpyngt2n</sha1>
    </revision>
  </page>
  <page>
    <title>Phonetic Normalization</title>
    <ns>0</ns>
    <id>636</id>
    <revision>
      <id>639</id>
      <timestamp>2015-06-27T10:35:15Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1265">== Phonetic Normalization ==
Phonetic normalization is a form of [[Text Normalization]] done for [[Information Retrieval]] applications

Problem:
* in English (and many other languages) words that are pronounced the same way can be spelled differently
* some IR applications need to account for that 
* use phonetic normalization to reduce similar-sounding words to the same token


So, phonetic normalization algorithm should:
* facilitate the retrieval of words with similar sound.


== Soundex ==
Soundex is a phonetic normalization algorithm 
* encodes words according to their pronunciation 
* each word is compressed into a 4 characters code: Soundex code.

Algorithm:
* keep the first letter of the name 
* drop all a, e, i, o, u, y, h, w.
* replace similar-sounding (&quot;phonetically clone&quot;) consonants with digits:
** bfpv -&gt; 1;
** cgjkqsxz -&gt; 2; 
** dt -&gt; 3;
** l -&gt; 4; 
** mn -&gt; 5; 
** r -&gt; 6;
* now remove all consequent occurrences of the same digit 
* keep only first four characters of the resulting string (append with zeros if needed)


Examples:
* Herman -&gt; H655
* Veronika, Veronique -&gt; V652

=== Usage ===
Useful for
* First and last names
* Street names 
* etc


== Sources ==
* [[Information Retrieval (UFRT)]]

[[Category:Information Retrieval]]</text>
      <sha1>jvrmyi1i24p34403rq0ww6ryy0pv04t</sha1>
    </revision>
  </page>
  <page>
    <title>Probabilistic Retrieval Model</title>
    <ns>0</ns>
    <id>637</id>
    <revision>
      <id>640</id>
      <timestamp>2015-06-27T10:40:08Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6925">== Probabilistic Retrieval Model ==
=== Probabilistic Ranking Principle ===
Due to Robertson 1977
* relevance = &quot;what is the probability that document $D$ is relevant to the query $Q$?&quot;


=== Assumptions ===
* '''ranking assumption''': usefulness of a relevant document depends on the number of relevant documents the user has already seen
** the more documents we see - the less useful they are 
* '''independence assumption''': relevance of $D_i$ to $Q$ is independent to other documents $D_j$ from the collection
** therefore we can apply it for each document separately



== Relevance Function ==
* $R = \{ r, \lnot r \}$ a binary random variable that indicates relevance
* let $r$ represent the event that $D$ is relevant 
* $\lnot r$ represent the event that $D$ is not relevant 


We need estimate the probability of relevance of a document $D$ w.r.t a query $Q$ 
* Need to find:
* $P(R = r \mid D, Q)$ - prob that $D$ is relevant to $Q$
* $P(R = \lnot r \mid D, Q)$ - prob that $D$ is not relevant to $Q$
* So we need to estimate (learn) $P(R \mid D, Q)$



=== [[Descriptive Models|Descriptive Model]] Approach ===
Sometimes referred as a &quot;[[Machine Learning]]&quot; approach

It then becomes a Classification Problem:
* can learn $P(R \mid D, Q)$ with a [[Descriptive Models|Descriptive Model]]
* $R$ depends on features that characterize the relationships between $D$ and $Q$ 
* for example, # of matched terms

Suppose 
* we have $k$ features $F_i(Q, D)$
* $f$ is a function with parameter $\Lambda$ s.t. $f(F_1, \ ... \ , F_k, \Lambda) = P(R \mid D, Q)$ 
* then can fit $f$ with some ML algorithm e.g. [[OLS Regression]], [[Logistic Regression]] or [[Kernel Ridge Regression]]


Comments:
* will have to spend a lot of time engineering good features
* also model has to learn to rank rather than just classify
* but sometimes it will work even better than [[Vector Space Model]]s
* such models can use scores from other IR techniques and combine them + use some extra ones


Literature:
* Joachims, Thorsten, et al. &quot;Learning to rank for information retrieval.&quot; 2007. [http://www.sigir.org/files/forum/2007D/2007d_sigirforum_joachims.pdf]
* Liu, Tie-Yan. &quot;Learning to rank for information retrieval.&quot; 2009. [http://didawikinf.di.unipi.it/lib/exe/fetch.php/magistraleinformatica/ir/ir13/1_-_learning_to_rank.pdf]



=== [[Generative Models]] Approach ===
Can use the [[Bayes Rule]] to infer the probabilities
* $P(R = r \mid D, Q) = \cfrac{P(D, Q \mid R = r) \, P(R = r)}{P(D, Q)}$
* $P(R = \lnot r \mid D, Q) = \cfrac{P(D, Q \mid R = \lnot r) \, P(R = \lnot r)}{P(D, Q)}$
* and then compare $P(R = r \mid D, Q)$ and $P(R = \lnot r \mid D, Q)$

Interpretation:
* $P(D, Q \mid R = r)$ probability that if we know that a relevant document is retrieved, it's $D$
* $P(R = r)$ probability of retrieving a relevant document
* $P(D, Q)$ probability of retrieving $D$ and issuing $Q$


Log [[Odds Ratio]]:
* it's the same as using Odds ratio:
* if $\cfrac{P(R = r \mid D, Q)}{P(R = \lnot  \mid D, Q)} &gt; 1$ or $\log \cfrac{P(R = r \mid D, Q)}{P(R = \lnot \mid D, Q)} &gt; 0$ then $D$ is relevant w.r.t $Q$ 
* so again the formulated the problem as two-category [[Document Classification]]
* but we're more interested in the scores rather than class outcome




== Binary Independence Retrieval Model ==
BIR Model: 
* classical probabilistic IR Model 
* assumes that terms are independent: it's a &quot;[[Naive Bayes Classifier]]&quot; for IR


Documents are represented by binary vectors 
* if a term is present in a document, it's 1, otherwise it's 0
* $T = \{T_i \}$ with $T_i = 1$ if $w_i$ is present in the document $D$ 


=== Ranking ===
Can rank using log odds:
* use $s(Q, D) = \log \cfrac{P(R = r \mid D, Q)}{P(R = \lnot r \mid D, Q)} = \log \cfrac{P(D, Q \mid R = r) \, P(R = r)}{P(D, Q \mid R = \lnot r) \, P(R = \lnot r)}$
* $P(R = r)$ and $P(R = \lnot r)$ are just constants and will not change relative positions of documents in the rating, so let's remove them:
* $s(Q, D) = \log \cfrac{P(D, Q \mid R = r)}{P(D, Q \mid R = \lnot r)}$
* by independence have:
* $s(Q, D) = \log \cfrac{\prod P(T_i \mid Q, R = r)}{\prod P(T_i \mid Q, R = \lnot r)} = \log \prod \cfrac{P(T_i \mid Q, R = r)}{P(T_i \mid Q, R = \lnot r)} = \sum \log \cfrac{P(T_i \mid Q, R = r)}{P(T_i \mid Q, R = \lnot r)}$
* can sum only over words present in the query:
* $s(Q, D) = \sum\limits_{i \in Q} \log \cfrac{P(T_i \mid Q, R = r)}{P(T_i \mid Q, R = \lnot r)}$
* now let $p_i = P(T_1 = 1 \mid Q, R = r)$ and $q_i = P(T_1 = 1 \mid Q, R = \lnot r)$. then 
* $s(Q, D) = \sum\limits_{i \in Q \cap D} \log \cfrac{p_i \, (1 - q_i)}{(1 - p_i) \, q_i}$
* let $c_i = \log \cfrac{p_i \, (1 - q_i)}{(1 - p_i) \, q_i}$, so we have 
* $s(Q, D) = \sum\limits_{i \in Q \cap D} c_i$



Comments:
* here we take into account only presence/absence of words 
* we don't care about frequency 
* we assume a [[Binomial Distribution|Multiple Bernoulli Event Model]]: $P(T_i = 1 \mid Q, R) + P(T_i = 0 \mid Q, R) = 0$


=== Estimation of Probabilities ===
How to estimate $p_i$ and $q_i$? 

Robertson / Sparck Jones Formula
* based on the training IR test corpus 
* and also can be account relevance feedback


Notation
* given a query $Q$ and a corpus $C$ 
* let $N$ be the number of documents in the corpus
* let $R$ be the number of documents relevant to $Q$ 
* $n_i$ # of docs that have term $w_i$
* $r_i$ # of relevant docs that have term $w_i$ 


Then:
* $p_i = \cfrac{r_i + \lambda}{R + 2 \lambda}$ 
* $q_i = \cfrac{n_i - r_i + \lambda}{N - R + 2 \lambda}$
* here we add some distortion value $\lambda$ (can be e.g. $\lambda = 0.5$) to avoid getting logs with 0
* It's [[Laplace Smoothing]]



== BM25 Retrieval Function ==
{{ Stub }}

Use 2-Poisson Mixture Model with a Term Frequency formula

BM25:
* $\text{tf}(t, D)$ - how many times $t$ occurs in document $D$
* $\text{df}(t \mid C)$ - how many documents in the corpus $C$ contain $t$ 
* $$\text{bm25}(Q, D \mid C) = \sum_{t \in Q, D} \ln \cfrac{|C| - \text{df}(t \mid C) + 0.5}{\text{df}(t \mid C) + 0.5} \cdot \cfrac{(k_1 + 1) \, \text{tf}(t, D)}{k_1 \Big( (1 - b) + b \, | D| / | \bar D | \Big) + \text{tf}(t, D)} \cdot \cfrac{(k_3 + 1) \, \text{tf}(t, Q)}{k_3 + \text{tf}(t, Q)}$$
* where $| D |$ the length of $D$ and $| \bar D |$ is the average length of a document in $C$ 
* params: $t_1 \in [1, 2]$, $b = 0.75$ and $k_3 \in [0, 1000]$
* Note that BM25 formula is very similar to [[TF-IDF]]s


See 
* Robertson, Stephen E., and Steve Walker. &quot;Some simple effective approximations to the 2-poisson model for probabilistic weighted retrieval.&quot; 1994. [http://nclt.computing.dcu.ie/~gjones/Teaching/CA437/p232.pdf]



== Other Probabilistic Models ==
* [[Statistical Language Models]]
* [[Bayesian Networks]]


== Sources ==
* [[Information Retrieval (UFRT)]]
* Zhai, ChengXiang. &quot;Statistical language models for information retrieval.&quot; 2008.

[[Category:Information Retrieval]]
[[Category:Probabilistic Models]]</text>
      <sha1>4obxc2x89iqvt1e151u1s8kg9r2255s</sha1>
    </revision>
  </page>
  <page>
    <title>ROCK Clustering</title>
    <ns>0</ns>
    <id>638</id>
    <revision>
      <id>641</id>
      <timestamp>2015-06-27T10:41:55Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="575">{{stub}}

== ROCK Clustering ==
ROCK $\approx$ group average in [[Agglomerative Clustering]]


== References ==
* Guha, Sudipto, Rajeev Rastogi, and Kyuseok Shim. &quot;ROCK: A robust clustering algorithm for categorical attributes.&quot; 1999. [http://www.cacs.louisiana.edu/~jyoon/grad/adb/References/clustering/ROCK-clus99icde.pdf]


== Sources ==
* Ertöz, Levent, Michael Steinbach, and Vipin Kumar. &quot;Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data.&quot; 2003. [http://static.msi.umn.edu/rreports/2003/73.pdf]


[[Category:Cluster Analysis]]</text>
      <sha1>gs1jdofqnk7i2tt8nl905ldpt8lb3vu</sha1>
    </revision>
  </page>
  <page>
    <title>Statistical Language Models</title>
    <ns>0</ns>
    <id>639</id>
    <revision>
      <id>642</id>
      <timestamp>2015-06-27T10:45:03Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5402">== Statistical Language Models ==
A statistical language model (Language Model for short) is a probability distribution over sequences of words (i.e. over sentences)

It assigns any sentence a probability
it's a probability of seeing a sentence according to the LM 

Language Models can be context dependent


For example: 
* $p_1 = P(\text{&quot;Today is Wednesday&quot;}) = 0.001$
* $p_2 = P(\text{&quot;The equation has a solution&quot;}) = 0.00001$

Although both sentences are valid, sentence 1 is more likely: for example, because the LM can model some general conversations rather than conversations on a math conference


=== [[Generative Models]] ===
Language models are generative models for text: 
* given a LM we can sample sentences according to the distribution and obtain a text sample
* so we can &quot;generate&quot; text 


=== Usage ===
LMs: 
* provide a way to quantify the uncertainly associated with natural languages
* allow to answer [[Information Retrieval]] related questions e.g.
** how likely would a user use a query with word &quot;baseball&quot; if he wants to find about sport



== Building Language Models ==
Can't enumerate all possible sentences, so need to make some assumptions to simplify the model

Notation:
* $V = \{w_1, \ ... \ , w_N\}$ is the vocabulary, $|V| = N$



== Unigrams ==
This is the simplest LM 
* a word sequence is generated by sampling each word independently 
* Assumption: for a sequence $[w_1, \ ... \ , w_n]$, $P(w_1, \ ... \ , w_n) = \prod_{i} P(w_i)$


Let $\theta$ be a Unigram LM 
* there are $|V|$ params in $\theta$ 
* condition: $\sum p(w_i \mid \theta) = 1$
* so unigram LM specifies a [[Multinomial Distribution]] over words
* according to unigram models, sentences with high-probability words have higher probability

High probability words also can indicate topics
* e.g. $\theta_1$ about Text Mining
* $\theta_2$ about food
* if a document $D$ is a text mining paper, than we expect $P(D \mid \theta_1) &gt; P(D \mid \theta_2)$


=== Inference ===
Suppose we have $D$ generated by some unigram model $\theta$
* and we want to learn that are the parameters of $\theta$: estimate $P(w \mid \theta)$ for each $w \in D$
* this is a [[Parameter Estimation Problem]]
* [[Maximum Likelihood Estimation]] (MLE) is a possible solution: $\hat \theta = \operatorname{arg max}_{\theta} P(D \mid \theta)$
* since unigrams is a multinomial probability distribution, MLE is:
* $P(w \mid \hat \theta) = \cfrac{c(w, D)}{|D|}$ where $c(w, D)$ is the count of word $w$ in document $D$ and $|D|$ is the total number of words in the document



How this formula is derived?
* consider log likelihood function: $\log P(D \mid \theta) = \sum_{w \in V} c(w, D) \, \log P(w \mid \theta)$ 
* we want to maximize it s.t. $P(w \mid \theta)$ is a [[Probability Distribution]] i.e. $\sum_{w \in V} P(w \mid \theta) = 1$
* use [[Lagrange Multipliers]] to convert this constrained optimization problem into an unconstrained one
* so let $L(\theta, \lambda) = \log P(D \mid \theta) + \lambda \left(1 - \sum P(w \mid \theta) \right) = \sum_{w \in V} c(w, D) \, \log P(w \mid \theta) + \lambda \left(1 - \sum P(w \mid \theta) \right)$ 
* by solving it, we get $P(w \mid \hat \theta) = \cfrac{c(w, D)}{|D|}$


[[Smoothing for Language Models]]
* MLE may [[Overfitting|overfit]] the data: it will assign 0 probabilities to words it hasn't seen 
* What to do with it? 
* [[Bayesian Parameter Estimation]] can both maximize the data likelihood and incorporate the prior belief to &quot;smooth&quot; the estimate
* use MAP: [[Maximum A Posteriori Estimation]]:
* $\hat \theta = \operatorname{arg max}_{\theta} P(\theta \mid D) = \operatorname{arg max}_{\theta} P(D \mid \theta) \, P(\theta)$
* so we can define some prior $P(\theta)$, and depending on the choice of prior, we'd have different estimators
* if the prior prefers models that don't assign 0 probability to any $w$, then at the end we won't have 0 entries 
* adjusting MLE to avoid 0 probability is called &quot;smoothing&quot; - it's a form of regularization


=== Usage ===
* Popular choice in [[Information Retrieval]]


== N-grams ==
Unigrams make unrealistic assumptions about word occurrence: 
* generally word order matters 

Bigram models: 
* Have the [[Markov Property]]:
* $P(w_1, \ ... \ , w_n) = P(w_1) \cdot \prod_i P(w_i \mid w_{i-1})$
* can capture local dependency between two adjacent words 



Usage: 
* better than unigrams in complex NLP tasks such as [[Machine Translation]], [[Speech Recognition]], etc
* not much used in IR: the IR task is relatively easy and these models usually don't give much performance gain over unigrams


== Evaluation of Language Models ==
=== Indirect Way ===
Evaluate not the LM itself, but the application where LM is used 
* if the LM is used in an IR system, evaluate the performance of this IR system using different LMs (e.g. with [[Precision and Recall]])
* 

=== Direct Way ===
Standalone evaluation of LM 


== Structured Models ==
There are also models that take into account the structure of natural languages 
* for example Probabilistic Context-Free Grammars allow to capture remote dependencies
* these models are complex and require a lot of data to estimate the parameters
* usually simpler models work just as good


== Sources ==
* [[Information Retrieval (UFRT)]]
* Zhai, ChengXiang. &quot;Statistical language models for information retrieval.&quot; 2008.

[[Category:Information Retrieval]]
[[Category:NLP]]</text>
      <sha1>8polr8ipx61xzpa1gj8hcj6zw3bkzqf</sha1>
    </revision>
  </page>
  <page>
    <title>Language Models</title>
    <ns>0</ns>
    <id>640</id>
    <redirect title="Statistical Language Models" />
    <revision>
      <id>643</id>
      <timestamp>2015-06-27T10:45:26Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="41">#REDIRECT [[Statistical Language Models]]</text>
      <sha1>ehzd0q45545t94vcs285cdubpb2w53r</sha1>
    </revision>
  </page>
  <page>
    <title>Tokenization</title>
    <ns>0</ns>
    <id>641</id>
    <revision>
      <id>644</id>
      <timestamp>2015-06-27T10:47:54Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1253">== Tokenization ==
Tokenization is a part of [[NLP Pipeline]] and it's common in almost any [[NLP]] or [[Information Retrieval]] task


Tokenization can be of two types:
* Decompose text into sentences 
* Decompose sentences into tokens


== Word Split ==
Usual tokenization is given a text, split it s.t. individual words can be accessed 

For example
* &quot;The quick brown fox jumps over the lazy dog&quot; -&gt; 
* ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']

Need to be careful with special cases:
* Numbers
* Los Angeles - may be one token, not two
* Punctuation is important:
* email@gmail.com - dot inside email
* U.S.A. - watch out for dots inside the token 
* Mr. Durand - one person
* see also [[Text Normalization]]


In some languages it's difficult
* e.g. German, Chinese 


== Sentence Split ==
Main challenge: distinguish between full stop dot and dot in abbreviations



== [[NLP Pipeline]] ==
* Tokenization is usually the very first step in NLP and IR applications 
* Then it can be followed by 
* [[Stop Words|Stop Word Removal]]
* [[Lemmatization]]
* building a [[Vector Space Model]] or [[Inverted Index]]
* etc


== Sources ==
* [[Information Retrieval (UFRT)]]

[[Category:Information Retrieval]]
[[Category:NLP]]</text>
      <sha1>r1prksi2ra97ar1ckra9ewyf61mrwm1</sha1>
    </revision>
  </page>
  <page>
    <title>Smoothing for Language Models</title>
    <ns>0</ns>
    <id>642</id>
    <revision>
      <id>645</id>
      <timestamp>2015-06-27T10:52:26Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9769">== Smoothing for Language Models ==
It's a form of [[Regularization]] for [[Statistical Language Models]]


== Parameter Estimation ==
Suppose $\theta$ is a Unigram [[Statistical Language Model]]
* so $\theta$ follows [[Multinomial Distribution]]
* $D$ is a document consisting of words: $D = \{w_1, \ ... \ , w_m \}$
* $V$ is the vocabulary of the model: $V = \{ w_1, \ ... \ , w_M \}$
* By the unigram model, each word is independent, so
* $P(D \mid \theta) = \prod_i P(w_i \mid \theta) = \prod_{w \in V} P(w \mid \theta)^{c(w, D)}$
* where $c(w, D)$ is the term frequency: how many times $w$ occurs in $D$ (see also [[TF-IDF]])
* how do we estimate $P(w \mid \theta)$?

With MLE, we have:

$\hat p_\text{ML} (w \mid \theta) = \cfrac{c(w, D)}{\sum_{w \in V} c(w, D)} = \cfrac{c(w, D)}{| D |}$

No smoothing



[[Smoothing]]
* MLE may [[Overfitting|overfit]] the data: it will assign 0 probabilities to words it hasn't seen 
* What to do with it? 
* [[Bayesian Parameter Estimation]] can both maximize the data likelihood and incorporate the prior belief to &quot;smooth&quot; the estimate
* use MAP: [[Maximum A Posteriori Estimation]]:
* $\hat \theta = \operatorname{arg max}_{\theta} P(\theta \mid D) = \operatorname{arg max}_{\theta} P(D \mid \theta) \, P(\theta)$
* so we can define some prior $P(\theta)$, and depending on the choice of prior, we'd have different estimators
* if the prior prefers models that don't assign 0 probability to any $w$, then at the end we won't have 0 entries 
* adjusting MLE to avoid 0 probability is called &quot;smoothing&quot; - it's a form of regularization



== Interpolation Smoothing ==
Discount some probability mass of seen words 
* then discounted probability is shared between all words: seen and unseen
* so it's some sort of interpolation between LME probabilities and prior/collection model


=== Additive Smoothing === 
[[Laplace Smoothing]] (or Additive Smoothing):
* $\hat p_\lambda (w \mid \theta) = \cfrac{c(w, D) + \lambda}{\sum_{w \in V} c(w, D)} = \cfrac{c(w, D)}{| D | + \lambda \, | V | }$
* so it gives the same probability mass $\cfrac{\lambda}{|D| + \lambda \, |V|}$ to all unseen words

If $\lambda = 1$ then we have &quot;+1 Smoothing&quot;


=== Collection Smoothing ===
* Additive smoothing gives the same probability mass $\cfrac{\lambda}{|D| + \lambda \, |V|}$ to all unseen words
* it may not be what we want: maybe we want to give more or less weight to certain words
* so the idea is to have some reference language model 
* if we have a corpus, then we can use this corpus to learn the LM on the entire corpus
* such corpus LM is called &quot;Collection LM&quot; or &quot;Background LM&quot;


==== Collection LM ====
There are two ways of building the Collection LM:
* let $P(w \mid C)$ denote the collection LM


1) Each word contributes equally
* $P(w \mid C) = \cfrac{\sum_{D \in C} c(w, D)}{ \sum_{D \in C} |D|}$
* it's the same as if we concatenated all documents in $C$ into one
* &quot;Macro-averaging&quot;


2) Each document contribute equally
* $P(w \mid C) = \cfrac{1}{N} \sum_{D \in C} \cfrac{c(w, D)}{ |D|}$
* average contribution of each doc
* &quot;Micro-averaging&quot;

Approach (1) is more popular than (2)


==== Smoothing with Collection LM ====
Once we learned the Collection LM, we can use it to smooth the probabilities:

$$P(w \mid \hat \theta) = \begin{cases}
P_{\lambda} (w \mid \theta) &amp; \text{ if } w \in D\\ 
\alpha \cdot P(w \mid C) &amp; \text{ else }
\end{cases}$$


Where
* $P_{\lambda} (w \mid \theta)$ smoothed probabilities (with Laplace Smoothing)
* $\alpha$ coefficient that controls how much prob. mass is assigned to unseen words
* One way: $\alpha = \cfrac{1 - \sum_{w : \ c(w, D) &gt; 0} P_{\lambda}(w \mid \theta) }{1 - \sum_{w : \ c(w, D) &gt; 0} P(w \mid \theta)}$
* When we're doing Laplace smoothing, we take some probability mass from each seen words and re-distribute it evenly 
* here we distribute it according to Collection LM


=== Jelinek-Mercer Smoothing ===
Or &quot;Fixed Coefficient Interpolation&quot;

Interpolate MLE with the collection LM
* use some coefficient of interpolation $\beta$ 
* $P_\beta(w \mid \hat \theta) = (1 - \beta) \, \cfrac{c(w, D)}{|D|} + \beta \, P(w \mid C)$


=== Dirichlet Prior Smoothing ===
It's a Bayesian Smoothing with special prior: [[Dirichlet Distribution]]
* $\text{Dir}(\theta \mid \boldsymbol \alpha) = \cfrac{\Gamma \left( \sum_{i} \alpha_i \right)}{\prod_i  \Gamma(\alpha_1)} \cdot \prod_i \theta_{i}^{\alpha_i - 1}$
* params: $\boldsymbol \alpha = (\alpha_1, \ ... \ , \alpha_{|V|})$
* let $\alpha_i = \mu \cdot P(w_i \mid C)$, $\mu$ - param, $P(w_i \mid C)$


Dirichlet is a [[Conjugate Prior]] for [[Multinomial Distribution]]
* it means that the prior has the same functional form as the likelihood


Posterior:
* $P(\theta \mid D) \propto \prod_{w \in V} P(w \mid \theta)^{c(w, D) + \mu \, P(w \mid C) - 1}$ 
* posterior is also Dirichlet distribution with $\alpha_i = c(w_i, D) + \mu \, P(w \mid C)$


Dirichlet Smoothing:
* $P_\mu(w \mid \hat \theta) = \cfrac{c(w, D) + \mu \, P(w \mid C)}{|D| + \mu} = \cfrac{|D|}{|D| + \mu} \cdot \cfrac{c(w, D)}{|D|} + \cfrac{\mu}{\mu + |D|} \cdot P(w \mid C)$
* Compare with Jelinek-Mercer: same if $\beta = \cfrac{\mu}{\mu + |D|}$


&quot;Eventually, data overrides the prior&quot;:
* for a fixed $\mu$ longer documents will get less smoothing
* as $|D| \to \infty$, smoothing $\to 0$


Notes: 
* the smoothing adds a pseudo count $\mu P(w \mid C)$ to each word
* thus Additive Smoothing is a special case of Dirichlet smoothing with uniform Collection LM


=== Absolute Discounting Smoothing ===
* $P_\delta (w \mid \hat \theta) = \cfrac{\max \big( c(w, D) - \delta, 0 \big) }{\sum_{w' \in V} c(w', D)} + \sigma \, P(w \mid C)$
* $\delta \in [0, 1]$ discounting factor
* $\sigma = \delta \cfrac{|D|_U}{|D|}$ where $|D|_U$ is number of unique terms in $D$ and $|D|$ is total word count



== Backoff ==
Interpolation:
* discount some probability mass from seen words, reassing it to both seen and unseen
* problem with this approach: some words may end up with counts even higher than the original
* for example, if a word is frequent in the collection LM 


Alternative Strategy: ''Back Off''
* trust MLE for high count words
* but discount and redistribute probability mass for less common terms
* popular in [[Speech Recognition]], but less popular in [[Information Retrieval]]


== Other Smoothing Methods ==
=== Good-Turing  Smoothing ===
Idea:
* # of unseen events = # of &quot;singletons&quot;: words that occur only once 
* let $\hat{c}(w, D)$ be the adjusted count of $w$ 
* then $P(w \mid \hat \theta) = \cfrac{\hat{c}(w, D)}{|D|}$


What is  $\hat{c}(w, D)$?
* let $n_r$ denote # of words that occur $r$ times in $D$ 
* then the adjusted is done via:
* $\hat{c}(w, D) \, n_{c(w, D)} = \big(c(w, D) + 1\big) \, n_{c(w, D) + 1}$


Intuition
* let's pretend that none of the singletones were observed 
* use this to estimate the total # of unseen words


Improvements:
* Gale, William, and Geoffrey Sampson. &quot;Good-Turing smoothing without tears.&quot; 1995. [https://faculty.cs.byu.edu/~ringger/CS479/papers/Gale-SimpleGoodTuring.pdf]



== Smoothing vs [[TF-IDF]] ==
Smoothing and TF-IDF are connected
* also see probabilistic justification for TF-IDF in 
** Hiemstra, Djoerd. &quot;A probabilistic justification for using tf× idf term weighting in information retrieval.&quot; 2000. [http://doc.utwente.nl/66959/1/ijodl.pdf]



Let's derive a query retrieval function using the smoothed log likelihood:
* $Q$ is a query
* assuming the general smoothing scheme: (comparing $Q$ with each $D$)
* $\log P(Q \mid \theta) = \sum_{w \in V} c(w, Q) \, \log P(w \mid \theta) = \sum_{w \in D} c(w, Q) \, \log P_S(w \mid \theta) + \sum_{w \not \in D} c(w, Q) \, \alpha \log P(w \mid \theta)$
* $\sum_{w \not \in D} c(w, Q) \, \alpha \log P(w \mid \theta) = \sum_{w \in V} c(w, Q) \, \alpha \log P(w \mid \theta) - \sum_{w \in D} c(w, Q) \, \alpha \log P(w \mid \theta)$: 
** words that are not in the document = all words - words that are in the document
* let's regroup it:
* $\log P(Q \mid \theta) = \sum_{w \in D} c(w, Q) \, \log \cfrac{P_S (w \mid \theta) }{\alpha \, P(w \mid C)} + |Q| \, \log \alpha + \sum_{w \in V} c(w, Q) \, \alpha \log P(w \mid \theta) = \ ...$
* can ignore the last term $\sum_{w \in V} c(w, Q) \, \alpha \log P(w \mid \theta)$ because it will not affect the ranking 
* thus we're left with 
* $\log P(Q \mid \theta) \mathop{=}\limits^{\text{rank}} \sum_{w \in D} c(w, Q) \, \log \cfrac{P_S (w \mid \theta) }{\alpha \, P(w \mid C)} + |Q| \, \log \alpha$  


Observe:
* form of this smoothed retrieval function is similar to TF-IDF:
* first term: $\sum_{w \in D} c(w, Q) \, \log \cfrac{P_S (w \mid \theta) }{\alpha \, P(w \mid C)}$
* it sums over all matched terms - ones with $c(w, Q) &gt; 0$ 
* $P_S (w \mid \theta)$ would be larger for words with high TF ($\approx$ TF heuristic)
* frequent items in collection would have high $P(w \mid C)$ and thus smaller overall weight ($\approx$ IDF heuristic)


== Other Smoothing Ideas ==
=== Clustering / KNN Smoothing ===
Smoothing all documents from $C$ with the same collection LM may be not the most optimal approach
* maybe need to try more &quot;individual&quot; approaches


Can try:
* cluster all documents prior indexing, build a cluster LM for each cluster, and then smooth documents using their associated cluster LM
* find [[KNN]] docs, and then smooth using them 




== References ==
* Chen, Stanley F., and Joshua Goodman. &quot;An empirical study of smoothing techniques for language modeling.&quot; 1996 [http://arxiv.org/pdf/cmp-lg/9606011.pdf] and 1999 [http://u.cs.biu.ac.il/~yogo/courses/mt2013/papers/chen-goodman-99.pdf].


== Sources ==
* Zhai, ChengXiang. &quot;Statistical language models for information retrieval.&quot; 2008.


[[Category:NLP]]
[[Category:Information Retrieval]]
[[Category:Regularization]]</text>
      <sha1>mz913gjaht6e0onr44qvfjkfz5irj38</sha1>
    </revision>
  </page>
  <page>
    <title>Statistical Language Model</title>
    <ns>0</ns>
    <id>643</id>
    <redirect title="Statistical Language Models" />
    <revision>
      <id>646</id>
      <timestamp>2015-06-27T11:12:35Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="41">#REDIRECT [[Statistical Language Models]]</text>
      <sha1>ehzd0q45545t94vcs285cdubpb2w53r</sha1>
    </revision>
  </page>
  <page>
    <title>Stemming</title>
    <ns>0</ns>
    <id>644</id>
    <revision>
      <id>647</id>
      <timestamp>2015-06-27T11:16:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1650">== Stemming ==
Stemming is a part of [[NLP Pipeline]] useful in [[Text Mining]] and [[Information Retrieval]]
* ''stemming'' is an algorithm that extract the morphological root of a word 


Usage:
* it's a part of [[Text Normalization]] step: 
* it helps reducing the size of [[Inverted Index]] and the dimensionality of [[Vector Space Model]]
* it can be seen as a [[Dimensionality Reduction]] technique for textual data



== Algorithms ==
Need to reduce words to a stem (root) form
* use language-dependent rules
* usually they are in a form of [[Deterministic Finite Automate|Automaton]] that gradually reduces a token to its stem
* for example, there's a Porter Algorithm and Snowball Stemmer
 

=== Porter Stemmer ===
It's a bunch of rules for reducing a word:
* sses -&gt; es
* ies -&gt; i
* ational -&gt; ate
* tional -&gt; tion
* s -&gt; $\varnothing$
* when conflicts, the longest rule wins

Example
* economy, economic, economical, economically, economics, economize =&gt; econom
* automates, automatic, automation =&gt; automat


=== Snowball Stemmer ===
Better stemmer than Porter


== Programming ==
=== Python / NLTK ===
&lt;pre&gt;
from nltk.stem import SnowballStemmer
snowball_stemmer = SnowballStemmer('english')
stem = snowball_stemmer.stem(unigram)
&lt;/pre&gt;


== Downsides ==
* often does wrong replacement and bad reduction
* e.g. universe -&gt; univers, university -&gt; univers: different words, same stem
* in applications where it's important to distinguish between these words, use [[Lemmatization]] instead (although it's more computationally expensive)


== Sources ==
* [[Information Retrieval (UFRT)]]

[[Category:Information Retrieval]]
[[Category:NLP]]</text>
      <sha1>e9d9tw48h3gi2sqqps7tefd2t669fiv</sha1>
    </revision>
  </page>
  <page>
    <title>Stop Words</title>
    <ns>0</ns>
    <id>645</id>
    <revision>
      <id>648</id>
      <timestamp>2015-07-05T11:15:36Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2696">== Stop Words ==
Stop words are ''function words'':
* stop words are useful syntactically and grammatically, but don't tell anything about the document content 
* and they are topic-neutral: stop words have the same likelihood of occurring in both relevant and non-relevant documents - so not very useful for [[Information Retrieval]]  
* they are present everywhere: usually most frequent words are stop words
* for example, &quot;the&quot;, &quot;a&quot;, &quot;an&quot;, ...


== Stop Words Removal ==
In many cases stop words are not needed:
* for example, in [[Information Retrieval]] or [[NLP]]
* they don't have enough descriptive power to distinguish between relevant and not relevant documents: all documents have them!
* so, before [[Inverted Index|indexing]] they are often removed
* it also makes the index much smaller
* it can be seen as a [[Dimensionality Reduction]] technique for text data


=== [[NLP Pipeline]] ===
Stop words removal is a part of the [[NLP Pipeline]]
* for building [[Inverted Index]]
* for building [[Vector Space Model]]


=== Implementing ===
* English: http://www.ranks.nl/stopwords
* http://www.textfixer.com/resources/common-english-words.txt

Stop words removal in NLTK [http://stackoverflow.com/questions/19130512/stopword-removal-with-nltk]:

&lt;pre&gt;
&gt;&gt;&gt; from nltk.corpus import stopwords
&gt;&gt;&gt; stop = stopwords.words('english')
&gt;&gt;&gt; sentence = &quot;this is a foo bar sentence&quot;
&gt;&gt;&gt; print [i for i in sentence.split() if i not in stop]
['foo', 'bar', 'sentence']
&lt;/pre&gt;


== Stop Words Usage ==
There are cases when stop words are not removed, and even used 

Examples:
* author identification (&quot;the little words give authors away&quot;)
* language detection: languages have very distinctive set of stop words, so they can be used to detect the language of a text (see e.g. here [http://blog.alejandronolla.com/2013/05/15/detecting-text-language-with-python-and-nltk/])


== Stop Words Learning ==
* Stop words can be learned from the text, usually by looking at top words and manually selecting them 
* But this process can be automated (Wilbur1992):
* use [[Term Strength]] for automatically discovering stop words
* Term Strength: given a pair of documents, what's the probability that when a term occurs in one document of the pair, it also occurs in another?  



== Sources ==
* [[Information Retrieval (UFRT)]]
* Aggarwal, Charu C., and ChengXiang Zhai. &quot;A survey of text clustering algorithms.&quot; Mining Text Data. 2012.
* Wilbur, W. John, &quot;The automatic identification of stop words.&quot; 1992. [http://www.researchgate.net/publication/247786801_The_automatic_identification_of_stop_words]

[[Category:Feature Selection]]
[[Category:NLP]]
[[Category:Information Retrieval]]
[[Category:Python]]</text>
      <sha1>h6p3aueeycdh4r4az9vorzdjw8knm4f</sha1>
    </revision>
  </page>
  <page>
    <title>Text Normalization</title>
    <ns>0</ns>
    <id>646</id>
    <revision>
      <id>649</id>
      <timestamp>2015-06-27T11:20:23Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2659">== Text Normalization ==
It's a part of [[NLP Pipeline]] for preprocessing text data 
* normalization = applying some linguistic models to [[Tokenization|tokens]] of text
* text tokens often have some minor difference in spelling, but refer to same thing
* need to recognize such tokens and reduce them to the same common form


[[Information Retrieval]]
* it's important to do text normalization for IR:
* it reduces the dimensionality of [[Vector Space Models]] and the size of the [[Inverted Index|Index]]


== Types ==
=== Word Form Normalization ===
Forms can have many inclinations, but more often they are not important and we need to know only the base form of the word

Can be done by
* [[Stemming]]: keeping only the root of the word (usually just deleting suffixes)
** economy, economic, economical, economically, economics, economize =&gt; econom
* [[Lemmatization]]: keeping only the lemma
* produce, produces, product, production =&gt; produce



=== [[Phonetic Normalization]] ===
In English words that are pronounced the same way can be spelled differently
* in some IR applications need to account for that 
* use phonetic normalization to reduce similar-sounding words to the same token


=== Acronyms ===
Countries
* the US -&gt; USA
* U.S.A. -&gt; USA

Organizations
* UN -&gt; United Nations


=== Accents / Umlauts ===
* naïve -&gt; naive
* météo -&gt; meteo
* or can be the other way around - depending on application



=== Capital Letters ===
In many cases capital letter aren't needed
* Product -&gt; product
* usually the way to handle it is to lovercase all the letters


Careful: sometimes capitalization is needed
* e.g. for [[Named Entity Recognition]], some features that models use are capital letters
* 


=== Values ===
Sometimes we want to enforce some specific format on some values of some types
* e.g:
* phones (+7 (800) 123 1231, 8-800-123-1231 =&gt; 0078001231231)
* dates, times (e.g. 25 June 2015, 25.06.15 =&gt; 2015.06.25)
* currency (\$400 =&gt; 400 dollars)
* addresses


Often we don't care about specific value, only what this value mean, so we can do the following normalization:
* \$400 =&gt; MONEY
* email@gmail.com =&gt; EMAIL
* 25 June 2015 =&gt; DATE
* +7 (800) 123 1231 =&gt; PHONE
* etc



=== [[Spelling Correction]] ===
Also in Natural Languages there are spelling mistakes
* In many applications it's useful to correct them
* e.g. infromation -&gt; information



== Applications ==
Often text normalization can be seen as a set [[Dimensionality Reduction]] techniques applied to term-document matrices


== Sources ==
* [[Information Retrieval (UFRT)]]

[[Category:Dimensionality Reduction]]
[[Category:Information Retrieval]]
[[Category:NLP]]</text>
      <sha1>jxoay6bjsq909uiocxlr1p03pjayu64</sha1>
    </revision>
  </page>
  <page>
    <title>Inverted Index</title>
    <ns>0</ns>
    <id>647</id>
    <revision>
      <id>650</id>
      <timestamp>2015-06-27T12:14:16Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1970">== Inverted Index ==
=== Indexing for [[Information Retrieval]] ===
In [[Databases]], [[Indexing (databases)|indexing]] is needed to speed up queries
* want to avoid full table scan 
* same is true for [[Information Retrieval]] and other [[Text Mining]]/[[NLP]] tasks
* Inverted index is a way of achieving this, and it can be generalized to other forms of input, not just text


For IR
* index is a partial representation of a document that contains the most important information about the document
* usually want to find terms to index automatically 




== Inverted Index for Similarity Search ==
=== General Idea ===
Idea:
* usually a document contains only a small portion of terms 
* so document vectors are very sparse
* typical distance is cosine similarity - it ignores zeros. for cosine to be non-zero, two docs need to share at least one term
* $D^T$ is the inverted index of the term-document matrix $D$


This, to find docs similar to $d$:
* for each $w_i \in d$
** let $D_i = \text{index}[w_i] - d$ be a set of documents that contain $w_i$ (except for $d$ itself)
* then take the union of all $D_i$
* calculate similarity only with documents from this union


Can be used in [[Document Clustering]] to speed up similarity computation


== Implementation ==
=== Posting List ===
Build a dictionary: a &quot;posting&quot; list
* for each word we store ids of documents that have this word
* document are sorted by ids
* &lt;img src=&quot;http://slidewiki.org/upload/media/images/29/509.png?filter=Resize-width-550&quot; /&gt;
* source of picture: [http://slidewiki.org/print/deck/339]
* sorting - because it's easier to take union: just merge the posting list 



== Sources == 
* [[Information Retrieval (UFRT)]]
* Ertöz, Levent, Michael Steinbach, and Vipin Kumar. &quot;Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data.&quot; 2003. [http://static.msi.umn.edu/rreports/2003/73.pdf]


[[Category:Information Retrieval]]
[[Category:Database Indexes]]</text>
      <sha1>6oep7vd76zjcxck27rwtgngqtknu6aj</sha1>
    </revision>
    <revision>
      <id>765</id>
      <parentid>650</parentid>
      <timestamp>2017-04-26T20:59:52Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3608">== Inverted Index ==
=== Indexing for [[Information Retrieval]] ===
In [[Databases]], [[Indexing (databases)|indexing]] is needed to speed up queries
* want to avoid full table scan 
* same is true for [[Information Retrieval]] and other [[Text Mining]]/[[NLP]] tasks
* Inverted index is a way of achieving this, and it can be generalized to other forms of input, not just text


For IR
* index is a partial representation of a document that contains the most important information about the document
* usually want to find terms to index automatically 




== Inverted Index for Similarity Search ==
=== General Idea ===
Idea:
* usually a document contains only a small portion of terms 
* so document vectors are very sparse
* typical distance is cosine similarity - it ignores zeros. for cosine to be non-zero, two docs need to share at least one term
* $D^T$ is the inverted index of the term-document matrix $D$


This, to find docs similar to $d$:
* for each $w_i \in d$
** let $D_i = \text{index}[w_i] - d$ be a set of documents that contain $w_i$ (except for $d$ itself)
* then take the union of all $D_i$
* calculate similarity only with documents from this union


Can be used in [[Document Clustering]] to speed up similarity computation


== Implementation ==
=== Posting List ===
Build a dictionary: a &quot;posting&quot; list
* for each word we store ids of documents that have this word
* document are sorted by ids
* &lt;img src=&quot;http://slidewiki.org/upload/media/images/29/509.png?filter=Resize-width-550&quot; /&gt;
* source of picture: [http://slidewiki.org/print/deck/339]
* sorting - because it's easier to take union: just merge the posting list 



== Pairwise Similarity in Document Collection ==
=== [[Relation Database]] ===
Suppose we have a table Documents(doc_id, &lt;u&gt;word&lt;/u&gt;, weight)
* we index it on word: an have an inverted index
* then document-document similarity would be a self-join of Document with itself 


=== [[MapReduce]] ===
How do we use it to efficiently compute pair-wise similarity between each document 
* given two documents $\mathbf d_1$, $\mathbf d_2$:
* $\text{sim}(\mathbf d_1, \mathbf d_2) = \sum_{t \in V} = w_{t, \mathbf d_i} \cdot w_{t, \mathbf d_j} = \sum_{t \in \mathbf d_i \cup \mathbf d_j} = w_{t, \mathbf d_i} \cdot w_{t, \mathbf d_j} $ 
* so we need to take into account only terms that both documents share 


If we compute similarity for all documents:
* if a term $t$ appears only in documents $\mathbf x, \mathbf y, \mathbf z$, then it contributes only to the similarity scores between $(\mathbf x, \mathbf y), (\mathbf x, \mathbf z)$ and $(\mathbf y, \mathbf z)$



Algorithm:
* let $\text{posting}(t)$ be a function that returns all documents that contain $t$ 
* set $\text{sim}[i, j] = 0$ be the similarity matrix
* for $t \in V$ do:
** $p_t = \text{posting}(t)$
** for all pairs $(\mathbf d_i, \mathbf d_j) \in (p_t \times p_t)$ (s.t. $i &gt; j$)
** $\text{sim}[i, j] = \text{sim}[i, j] + w_{t, \mathbf d_i} \cdot w_{t, \mathbf d_j}$


It can easily be implemented in [[MapReduce]]
* first MR job: build the index
* second MR job: compute pair-wise similarity



== Sources == 
* [[Information Retrieval (UFRT)]]
* Ertöz, Levent, Michael Steinbach, and Vipin Kumar. &quot;Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data.&quot; 2003. [http://static.msi.umn.edu/rreports/2003/73.pdf]
* Elsayed, Tamer, Jimmy Lin, and Douglas W. Oard. &quot;Pairwise document similarity in large collections with MapReduce.&quot; 2008. [[http://www.ece.umd.edu/~oard/pdf/acl08elsayed2.pdf]]

[[Category:Information Retrieval]]
[[Category:Database Indexes]]</text>
      <sha1>dby7nylgfy6e30apgnqoyk4zygodacn</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Information Retrieval</title>
    <ns>14</ns>
    <id>648</id>
    <revision>
      <id>651</id>
      <timestamp>2015-06-27T12:14:34Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="39">[[Category:Databases]]
[[Category:NLP]]</text>
      <sha1>nyv9qg4np5ao1n6dgs7gyzuzifzjpq4</sha1>
    </revision>
  </page>
  <page>
    <title>Gram Matrix</title>
    <ns>0</ns>
    <id>649</id>
    <redirect title="Gram Matrices" />
    <revision>
      <id>652</id>
      <timestamp>2015-07-03T10:40:33Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27">#REDIRECT [[Gram Matrices]]</text>
      <sha1>o1ccqbq9nzifzjjnzm3ah9pv9414qfn</sha1>
    </revision>
  </page>
  <page>
    <title>Category:NLP</title>
    <ns>14</ns>
    <id>650</id>
    <revision>
      <id>653</id>
      <timestamp>2015-07-03T10:43:28Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="50">Natural Language Processing. Main Article: [[NLP]]</text>
      <sha1>72bpz5gkyxtkf3j0m209j1rpv22mv8p</sha1>
    </revision>
  </page>
  <page>
    <title>Distance</title>
    <ns>0</ns>
    <id>651</id>
    <revision>
      <id>654</id>
      <timestamp>2015-07-04T15:28:59Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="54">#перенаправление [[Distance Functions]]</text>
      <sha1>8kv6dprpm8bf2t71wlr56gqjospkpkk</sha1>
    </revision>
  </page>
  <page>
    <title>Vector Space Models</title>
    <ns>0</ns>
    <id>652</id>
    <revision>
      <id>655</id>
      <timestamp>2015-07-05T16:50:06Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11865">== Vector Space Model ==
Vector space model is a statistical model for representing text information for [[Information Retrieval]], [[NLP]], [[Text Mining]]
* Representing documents in VSM is called &quot;vectorizing text&quot;
* contains the following information: how many documents contain a term, and what are important terms each document has 



=== From Text to Vectors: [[NLP Pipeline]] ===
How do we represent a free text in terms of queries? 
* to do we need some preprocessing steps, often called &quot;NLP Pipeline&quot;
* the pipeline may include the following:
* [[Tokenization]] - most important step, extracts individual words - &quot;tokens&quot;
* [[Stop Words|Stop Words Removal]] - removes functional words
* [[Stemming]] or [[Lemmatization]] - reduces words to some common form
* or other [[Text Normalization]] techniques
* building a VSM model is usually one of the lasts steps of the pipeline
* for IR we also usually build an [[Inverted Index]] to speed up querying


=== Bag of Words Assumption ===
The main assumptions we're making about text data:
* word order is not important, only word counts
* Bag of Words = unordered list of terms 
* good enough for topic similarity 


=== Independence Assumption ===
We treat all words as independent 
* i.e. the basis vector of the term space (see below) is orthogonal



== Document-Term Matrix ==
Document-Term Matrix - representation of a document for text analysis 
* each row of the matrix - is a ''document vector'' 
* each component of the document vectors is a concept, a key word, or a term, but usually it's terms 
* documents don't contain many distinct words, so the matrix is sparse



=== Term Weighting ===
For each documents words are weighed

Weights can be:
* binary: 1 if term is present and 0 if not
* term frequency (TF): frequency of each word in a document
* sublinear TF: $\log \text{TF}$: sometimes a word is used too often so we want to reduce its influence compared to other less frequently used words 
* document frequency: words that are used more in the collections have more weight
* inverse document frequency (IDF): words that are rare across the document collections may be more relevant than frequent words.
* [[TF-IDF]]: combination of sublinear TF and IDF


=== Document-Term vs Term-Document ===
So texts are represented by feature vectors with frequency of each term in a lexicon 


Notation:
* let $\mathcal D = \{d_1, \ ... \ , d_m \}$ be a set of $m$ documents 
* and let $V = \{w_1, \ ... \ , w_n \}$ be a set of $n$ words (the vocabulary)
* let $D$ be the matrix 


'''Term-Document Matrix'''
* if $D$ is $n \times m$ matrix 
* rows of $D$ are indexed by terms $w_i$ and columns are indexed by documents $d_j$
* then $D$ is a Term-Document Matrix and $D_{ij}$ is a weight of $w_i$ in document $d_j$


'''Document-Term Matrix'''
* if $D$ is $m \times n$ matrix 
* rows of $D$ are indexed by terms $w_j$ and columns are indexed by documents $d_i$
* then $D$ is a Document-Term Matrix and $D_{ji}$ is a weight of $w_j$ in document $d_i$


Notes:
* if $D$ is a Term-Document matrix, then $D^T$ is a Document-Term
* in IR literature Term-Document matrices are used more commonly
* in some applications it's more convenient to use document-term matrix, 
* Document-Term matrices are more often used in software packages, e.g. in scikit-learn
* Document-Term are especially nice especially for large scale processing it's more convenient to operate rows that are documents



=== Properties of VSM Matrices ===
Properties of textual data:
* dimensionality is very large, but vectors are very sparse
** e.g. vocabulary size $| V | = 10^5$, but documents may contain only 500 distinct words
** or even less - when we consider sentences or tweets
* lexicon of document may be large, but words are typically correlated with each other 
** so number of concepts (&quot;principal components&quot; (see [[PCA]])) is $\ll | V |$
** may want to account for that 
* number of words across different documents may wary a lot
** so need to normalize


Since data is high dimensional, we may need special pre-processing and representation


=== [[Dimensionality Reduction]] ===
Usually done via [[Feature Selection]] (called &quot;Term Selection&quot;)
* discard infrequent and very frequent terms 


not all terms have the same descriptiveness power w.r.t. domain/topic e.g frequent words like &quot;a&quot;, &quot;the&quot;
* we often eliminate such words from the representation of the text

many infrequent words are eliminated as well
* they are called &quot;hapax logomena&quot;: &quot;said only once&quot; and they are usually spelling errors or neologisms that have not yet been lexicalized (i.e. not a part of the vocabulary) 


== Geometrical View ==
A geometrical way to express BoW features is the Vector Space Model 
* let $D$ be a document-term matrix 


'''TextVSM''': Document Vector Space Model - it's the [[Row Space]] of $D$
* each document $d_i$ is $i$th row of the matrix 
* dimensions are words and vectors are documents
* https://habrastorage.org/files/ace/015/d08/ace015d080da420d98b4228dfaeeb0d0.png
* source: [[Semantic Domains in Computational Linguistics (book)]], Fig 3.1
* similarity between two documents: [[Inner Product|dot product]] or [[Cosine Similarity|cosine]]


'''TermVSM''': Term Vector Space model - it's the [[Column Space]] of $D$
* Can do the same for the terms:
* dimensions are documents and vector are terms
* https://habrastorage.org/files/e86/a64/ab6/e86a64ab6f904b9180ff7874495a445f.png
* source: [[Semantic Domains in Computational Linguistics (book)]], Fig 3.1
* terms are expressed by documents in which they occur
* similarity between two terms: [[Inner Product|dot product]] or [[Cosine Similarity|cosine]]



TextVSM and TermVSM appear to be very similar, but in reality they are a bit different
* e.g. Words in the vocabulary of a corpus follow the [[Zip's Law]]: the size of the vocabulary becomes stable when corpus size increases 
* it means that the dimensionality of Text VSM is bounded to the number of terms in the language
* not true for the Term VSM: the number of documents can grow forever
* also, the [[Curse of Dimensionality]]: paradox: the larger the corpus size is, the worse the similarity estimation in this space becomes 


another difference: 
* can do feature selection in the Text VSM easily
* but can't really discard dimensions in the Term VSM: can't remove one documents and keep others 


finally these spaces are disjoint: they don't hare any common dimensions
* so we can't measure similarity between a text and a document


== Similarities ==
=== Common Similarity Measures ===
Suppose we have two document vectors $d_1, d_2$. Then we can define the following measures of similarity:
* [[Inner Product]]: $d_1^T d_2$
* [[Cosine Similarity]]: $\cfrac{d_1^T d_2}{\| d_1 \| \cdot \| d_2 \|}$
* [[Dice Coefficient]]: $\cfrac{d_1^T d_2}{\|d_1\|^2 + \| d_2\|^2}$
* [[Jaccard Coefficient]]: $\cfrac{d_1^T d_2}{\|d_1\|^2 + \| d_2\|^2 - d_1^T d_2}$
* most efficient: normalize $d_1$ and $d_2$ and compute the dot product to get cosine 


=== Document-Document Similarity ===
With that matrix you can compute the similarity of two documents 
* multiply the matrix with its own transpose 
* $S = D \cdot D^T$
* The result is a square document - document matrix where each cell represents similarity 
* and you have (unnormalized) measure of similarity
* if $D$ is row-normalized, then $S$ contains ''cosine scores'' between each document
* [[Cosine Similarity]] - is a measure of the angle between the two document vectors, normalized by magnitude 
* computing $D \, D^T$ may be the first step for [[Document Clustering]]


=== Term-Term Similarity ===
In some cases term-term similarity can be useful
* e.g. for [[Term Clustering]]
* compute $D^T D$ to get pair-wise term similarity
* to get cosine, you need to unit-normalize columns of $D$
* note that if rows of $D$ should not be normalized


=== [[Information Retrieval]] Ranking ===
In IR a query is also represented in TextVSM
* in such a case the query is called &quot;pseudo-document&quot; $q$
* so ranking is done by computing cosine between the query and all the documents
* it can be done by matrix multiplication: if $q$ and $D$'s rows are unit normalized
* then [[Matrix-Vector Multiplication]] $D \, q$ is the cosine score between each doc and the query


[[Inverted Index]]
* computing $D \, q$ may be computationally expensive when there are many documents in the corpus
* so usually the documents are indexed and we compute the similarity only to whose documents that share at least one word with the query



== Advantages and Disadvantages ==
VSM is the most popular model in IR


=== Advantages ===
* Query language is simple
* Ranking - reduces to a dot product


=== Problems ===
problems of VSMs: 
* Text VSM can't deal with lexical ambiguity and variability
* e.g.: &quot;he's affected by AIDS&quot; and &quot;HIV is a virus&quot; don't have any words in common
* so in the TextVSM the similarity is 0: these vectors are orthogonal even though the concepts are related 
* on the other hand, similarity between &quot;the laptop has a virus&quot; and &quot;HIV is a virus&quot; is not 0: due to the ambiguity of &quot;virus&quot;


Term VSM: 
* feature sparseness 
* if we want to model domain relations, we're mostly interested in domain-specific words 
* such words are quite infrequent compared to non-domain words, so vectors for these words are very sparse, esp in large corpus 
* so similarity between domain words would tend to 0
* and the results overall will not be very meaningful and interesting


Solutions: 
* Generalized Vector Space Models: Relaxes the Term Independence assumption and uses term co-occurrence information
* Distributed Clusters (Bekkerman et al. Distributional word clusters vs. words for text categorization. 2002)
* Concept-Based Representation (Gonzalo et al. Indexing with WordNet synsets can improve text retrieval. 1998)
* [[Latent Semantic Analysis]]
* [[Semantic Domains#Domain Spaces|Domain Spaces]]



== Decomposition of Term-Document Matrix ==
We can decompose the matrix $D$ 
* using [[SVD]] and we'll get [[Latent Semantic Analysis]]
* LSA can also be done with [[Non-Negative Matrix Factorization]]


== VSM as an IR/NLP Framework ==
A VMS is more a (retrieval) framework 

VSM has several components:
* term space for representing documents and queries
* document space for representing terms
* similarity/distance measure 

Framework:
* The exact vector representation and similarity is not specified 
* therefore it's up to the user to define them 
* this flexibility allows to incorporate many advanced indexing techniques and solve problems of VSMs  (mentioned earlier) while staying within the framework


=== [[Latent Semantic Analysis]] ===
For example, consider LSA:
* if we apply [[SVD]] to the document-term matrix, we'll have LSA
* this way we'll reduce the dimensionality of data and capture some semantic closeness between terms
* by doing this we changed the way documents and terms are represented 
* also the similarity is changed slightly
* but overall the framework stays the same 


=== Generalized Vector Space Models ===
Don't assume that words are independent

Reference:
* Wong, SK Michael, Wojciech Ziarko, and Patrick CN Wong. &quot;Generalized vector spaces model in information retrieval.&quot; 1985. [http://dl.acm.org/citation.cfm?id=253506])



== Sources ==
* Salton, Gerard, Anita Wong, and Chung-Shu Yang. &quot;A vector space model for automatic indexing.&quot; (1975). [http://cgis.cs.umd.edu/class/fall2009/cmsc828r/PAPERS/VSM_salton-2.pdf]
* Jing, Liping. &quot;Survey of text clustering.&quot; 2008. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.3476&amp;rep=rep1&amp;type=pdf]
* [[Semantic Domains in Computational Linguistics (book)]]
* [[Information Retrieval (UFRT)]]
* Zhai, ChengXiang. &quot;Statistical language models for information retrieval.&quot; 2008.


[[Category:Information Retrieval]]
[[Category:NLP]]</text>
      <sha1>7ysmobsumxoz544yquzcgkq5993izht</sha1>
    </revision>
  </page>
  <page>
    <title>Information Retrieval</title>
    <ns>0</ns>
    <id>653</id>
    <revision>
      <id>656</id>
      <timestamp>2015-07-05T18:31:31Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5090">== Information Retrieval ==
Information Retrieval is about quickly finding materials in a large collection of [[Types of Data|unstructured data]]
* IR is theories, principles and algorithms to find relevant information for a collection of unstructured data - usually text data


=== Information Retrieval System ===
IR system:
* A user of an Information Retrieval system has some information need which he wants to satisfy by sending it a query
* The system returns a list of results ranked by relevance
* https://habrastorage.org/files/ed7/5b0/353/ed75b03538e34051afb9a998ee5b4567.png


So, 
* general goal of IR systems: rank relevant items much higher than non-relevant
* to do it, the items must be scored, and it's done with a retrieval function


=== IR Problem ===
Problem: 
* we have a large data collection of unstructured data
* user interacts with the collection by sending a query
* we find some results, but in what order should they be presented? 

The ''central problem'' of IR is ranking  elements of the collection according to relevance for a user query


Text IR:
* Most common usecase for IR systems is finding something in textual data
* the '''goal''' of textual IR system is to retrieve most relevant documents for the user


Basic formulation:
* Given a collection $C = \{d_1, d_2, \ ... \ , d_N \}$ and a query $q \in Q$ 
* IR system given $q$ returns a ranked list of ''relevant'' documents from $C$ 
* documents are ''relevant'' when they contain information that the user looks for 
e.g. they contain the answer to the query 



=== Relevancy ===
''Retrieval function'' is a scoring function that's used to rank documents 
* retrieval function is based on a [[Information Retrieval Models|retrieval model]]
* Retrieval Model defines the notion of relevance and makes it possible to rank the documents 


[[Information Retrieval Models]]:
* the model should be able to represent both objects in the collection and the queries 
* for documents the most popular one is [[Vector Space Model]]
* but there are other [[Information Retrieval Models]]: e.g. [[Probabilistic Retrieval Model]]



Given the model we define a retrieval function $s$ 
* $s: Q \times C \to \mathbb R$ 
* it takes a query and and a document form $C$ and returns a rank value: some real number
* we can apply $s$ to all documents in $C$ to rank them 


Which documents are relevant?
* in the [[Vector Space Model]]
* assumption: relevance of a document $d$ w.r.t. to a query $q$ correlated with similarity between query and document:
* So can use some [[Similarity Functions|similarity function]] $\text{similarity}(d, q)$ to find if  a document is relevant
* so the retrieval function can be a similarity function, and you'll just need to sort all documents in $C$ by their similarity to $q$





== Retrieval Process ==
https://habrastorage.org/files/4b9/a9b/1a6/4b9a9b1a60d041b2b4dfeca4b7989586.png
* source: [[Information Retrieval (UFRT)]]  L01-introduction.pdf


The retrieval consists of several phases:
* offline:
** collection preparation
** parse documents
** build [[Inverted Index]]: index the documents so they can be retrieved faster
* online:
** query preparation (parse the query)
** find relevant documents and rand them according to the relevance score


Plus, the ranking may account user's preferences: 
* To make the results better
* To personalize the output 
* Also we may want to account for user feedback


=== Evaluation ===
How to evaluate an IR system? 
* use an IR test collection which consists of:
* documents 
* queries 
* and know relevance of each query for each document


Given a test collection, the quality of an IR system is evaluated with:
* [[Precision and Recall]]
* Precision: % of relevant documents in the result
* Recall: % of retrieved relevant documents

Definitions:
* If $X \subseteq C$ is the output of the IR system and $Y \subseteq C$ is the list of all relevant documents
* then $P = \cfrac{|X \cup Y|}{| X|}$ and $R = \cfrac{|X \cup Y|}{| Y |}$


== [[Document Clustering]] for IR ==
Ranked list is not the only way of presenting the retrieval results to the user
* the results can also be clustered 
* so we want to present internal relationships between documents to IR user when outputting the result
* [[Scatter/Gather]], a variant of [[K-Means]] for documents - first popular IR clustering technique, used for clustering web search results


There are two ways to cluster the results:
* search-result clustering (post-retrieval document clustering)
* pre-retrieval document clustering 


Pre-retrieval 
* Lingo: use [[Matrix Decomposition]] techniques to produce low-dimensional basis for the document space
* these base vectors can be interpreted as semantic vectors of the space 
* find clustering using [[SVD]] or [[Non-Negative Matrix Factorization]]



== Sources ==
* [[Information Retrieval (UFRT)]]
* Zhai, ChengXiang. &quot;Statistical language models for information retrieval.&quot; 2008.
* http://datascience.stackexchange.com/questions/1106/how-to-build-a-textual-search-engine


[[Category:Information Retrieval]]
[[Category:NLP]]</text>
      <sha1>drcsxdx1tx4141leeuv3w710rem2yg6</sha1>
    </revision>
  </page>
  <page>
    <title>Information Retrieval Models</title>
    <ns>0</ns>
    <id>654</id>
    <revision>
      <id>657</id>
      <timestamp>2015-07-05T18:33:11Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2884">== Information Retrieval Models ==
General goal of an [[Information Retrieval]] systems: rank relevant items much higher than non-relevant
* to do it, the items must be scored 


''Retrieval function'' is a scoring function that's used to rank documents 
* retrieval function is based on a [[Information Retrieval Models|retrieval model]]
* Retrieval Model defines the notion of relevance and makes it possible to rank the documents 


There are 5 categories of IR models
* they define the retrieval function in different ways 
* they also different in how they define/measure relevance


== Similarity-Based Models ==
* main assumption: relevance of a query $Q$ to the document $D$ is correlated with $\text{similarity}(Q, D)$
* i.e. the more similar a document $D$ to the query $Q$, the more relevant $Q$ to $D$ is 
* potentially can use any similarity function 


=== Algebraic Model === 
[[Vector Space Model]]s are most well-known 
* use Bag-of-Word to build a vector space
* both documents and the query are represented as vectors in this space
* each term is assigned some weight that reflects the importance of this term
* and then we use [[Cosine Similarity]] or [[Inner Product]] to rank queries

It's a framework that defines:
* Term VSM: how documents and queries are represented (by terms they have)
* Similarity measure defined on this vector space
* also it has Document VSM: how terms are represented (terms are represented by documents where they are used) - but it's not very relevant for IR


=== Set-Based ===
* [[Boolean Model]]: only exact match
* satisfies all the conditions of the query 
* hard to rank
* [[Extended Boolean Model]]: more flexible



== Probabilistic Relevance Models ==
[[Probabilistic Retrieval Model]]
* relevance = &quot;what is the probability that document $D$ is relevant to the query $Q$?&quot;
* Binary Independence Retrieval - classical probabilistic IR model, assumes term independence 
* it's sort of &quot;[[Naive Bayes Classifier]]&quot; for IR
* BM25 Ranking Function is comparable with [[TF-IDF]] weighting performance



== Probabilistic Inference Models ==
=== [[Decision Theory|Decision-Theoretic]] Retrieval Framework ===
* from [[Bayesian Decision Theory]]
* general risk miminization framework for IR


=== Query Likelihood Retrieval Model ===
Query Likelihood scoring method
* use [[Statistical Language Models]] for [[NLP]]
* Ponte, Jay M., and W. Bruce Croft. &quot;A language modeling approach to information retrieval.&quot; 1998. [http://www.cs.unibo.it/~montesi/CBD/Articoli/LanguageModelApproachIR.pdf]




== Links ==
* http://comminfo.rutgers.edu/~aspoerri/InfoCrystal/Ch_2.html
* http://wwwhome.cs.utwente.nl/~hiemstra/papers/IRModelsTutorial-draft.pdf


== Sources ==
* [[Information Retrieval (UFRT)]]
* Zhai, ChengXiang. &quot;Statistical language models for information retrieval.&quot; 2008.


[[Category:Information Retrieval]]
[[Category:NLP]]</text>
      <sha1>f3exdwnph2ot6ddwjtkq8vtt82sx55o</sha1>
    </revision>
  </page>
  <page>
    <title>Vector Space Model</title>
    <ns>0</ns>
    <id>655</id>
    <redirect title="Vector Space Models" />
    <revision>
      <id>658</id>
      <timestamp>2015-07-05T18:35:20Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="33">#REDIRECT [[Vector Space Models]]</text>
      <sha1>khb0d5alqpiw328zg72klslzsa4dwrg</sha1>
    </revision>
  </page>
  <page>
    <title>TF-IDF</title>
    <ns>0</ns>
    <id>656</id>
    <revision>
      <id>659</id>
      <timestamp>2015-07-05T18:41:16Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6888">== TF-IDF ==
It's a family of weighting schemes for the [[Vector Space Model]] in [[Information Retrieval]] and [[Text Mining]]


=== [[Vector Space Model]] ===
Suppose we have 
* a collection of documents $\mathcal D = \{ d_1, \ ... \ , d_N \}$ with $N$ documents
* the vocabulary $V = \{ w_1, \ ... \ , w_M \}$ consisting of $M$ words
* then each document is represented by $d = (x_1, x_2, \ ... \ , x_M)$ where $x_i$ is the weight assigned to the word $w_i$ in the document $d \in \mathcal D$
* let $D$ be a matrix with rows indexed by documents and columns indexed by words. $D$ is called a Document-Term matrix



== Term Weighing Systems ==
Weights can be:
* binary: 1 if term is present and 0 if not
* term frequency (TF): frequency of each word in a document
* document frequency (DF): words that are used more in the collections have more weight
* TF-IDF: combination of sublinear TF and inverse document frequency


=== Term Frequency ===
Term Frequency (TF)
* local frequency of a word in the document
* i.e. the word is weighed by how many times it occurs in the document
* $\text{tf}(w, d) = \big| \{ w' \in d  \ : \ w' = w \} \big|$ where $w$ is a word and $d = \{ w_1, \ ... \ , w_m \}$ is a document 


Sublinear TF:
* sometimes a word is used too often so we want to reduce its influence compared to other less frequently used words
* for that we can use some sublinear function, e.g. 
* $\log \text{tf}(w, d)$ or $\sqrt{\text{tf}(w, d)}$



=== Document Frequency ===
Document Frequency (DF)
* global frequency of a word in the document collection
* it's the number of documents that contain the word:
* $\text{df}(w, \mathcal D) = \big| \{ d \in \mathcal D \ : \  w \in d \} \big|$ where $w$ is a word and $\mathcal D = \{ d_1, \ ... \ , d_N \}$ is the document corpus


Inverse Document Frequency (IDF)
* more often we're interested in words that are rare across the document collections
* they tend to be domain specific and are usually more relevant for retrieving this document
* so we should give them more weight than to high-frequency words 
* thus, $\text{idf}(w, \mathcal D) = \log \cfrac{ |\mathcal D| + 1 }{\text{df}(w, \mathcal D)}$ 
* also can be some [[Entropy]]-based measure


=== Good Weighting System ===
The main function of a weighting scheme is to enhance IR effectiveness 
* want to retrieve items relevant to the users 
* and non-relevant items should be rejected


Effectiveness of an IR system is measures via [[Precision and Recall]]
* precision $P$: % of retrieved items that are relevant
* recall $R$: % of relevant items retrieved 
* want both $P$ and $R$ be good 
* $R$ is best served by broad high-frequency items: such terms are frequent and are likely to contain relevant documents
* $P$ best served by narrow and specific terms: the ones with &quot;discriminating power&quot;
* we can't achieve both, so need to compromise: use terms broad enough to get good $R$, but without producing very low $P$ 


Suggestions:
* TF should be good for getting high frequency words
* but using just TF is not good: if high frequency words are contained in many documents, all of them will be retrieved, thus affecting precision
* thus need a collection dependent factor that favors terms that are contained in fewer documents: IDF
* IDF varies inversely with the # of documents and the number of documents containing them


'''Term discrimination''' considerations:
* best terms are the ones that can distinguish individual documents from the test 
* so best terms should have high TF but low IDF =&gt; so we can combine them and use TF $\times$ IDF



=== TF-IDF Scheme ===
When weighting we want to get:
* domain specific words
* words that are frequent in the document 
* this can be done by combining TF and IDF:
* use sub-linear TF to avoid the dominating effect of words that occur very frequently 
* use IDF to reduce weights of terms that occur more frequently to ensure that document matching is done with more discriminative words 
* as the result, terms appearing too rarely or too frequently are ranked low


Intuition:
* the more often a term occurs in a document, the more representative it is of this document
* the more documents contain a term, the lest discriminating it becomes


So, we can combine then my multiplying:
* $\text{tf-idf}(w, d \mid \mathcal D) = (1 + \log \text{tf}(w, d)) \cdot \log \cfrac{|\mathcal D|}{\text{df}(w, \mathcal D)}$
* this is often used in [[Text Mining]], but in [[Information Retrieval]] there can be other components in the TF-IDF


=== Normalization ===
In systems where vectors have very different lengths a third component of a weight can be useful: 
* Term normalization component


Why? 
* if we have a short document $d$, then for corresponding vector $d$, $\| d \|$ is small
* if we have a large doc with many words, then $\| d \|$ is big
* so for larger documents the chances of matching are higher =&gt; so larger documents have higher chances of being retrieved just because they are larger


Normalization Factor
* Thus, we need to incorporate the normalization factor $\cfrac{d}{\| d \|}$
* It's also called &quot;Cosine Normalization&quot;: we normalize weights s.t. they have a unit length
* then for a document vector $d$ and a query vector $q$, $\| d \| = 1$ and $\| q \| = 1$
* if we do this, the [[Inner Product]] is the same as [[Cosine Similarity]]: $d^T q = \text{cosine}(d, q)$ 



=== Pivoted Length Normalization Function ===
In Information Retrieval more involved variants of TF-IDF give better performance
* they account for TF, IDF and also document length
* but it's still a TF-IDF variation


for example,
* $$\text{tf-idf}(d, q \mid \mathcal D) = \sum_{w \in q, d} = \cfrac{1 + \ln \big(1 + \ln \text{tf}(w, d) \big)}{(1 - s) + s \cdot \| d \| / \| \bar d \|} \cdot \text{tf}(w, q) \cdot \ln \cfrac{\| \mathcal D\| + 1}{\text{df}(w, \mathcal D)}$$
* where $s$ - some parameter
* $\| d \|$ is the length of document $d$, i.e. how many words are in $d$
* $\| \bar d \|$ is the average document length



== Critique ==
* TF-IDF is just a bunch of heuristics
* they don't have sound theoretical properties (in contrast to [[Probabilistic Retrieval Model]]s)


== [[Smoothing for Language Models|Smoothing]] vs TF-IDF ==
Smoothing and TF-IDF are connected
* also see probabilistic justification for TF-IDF in 
* Hiemstra, Djoerd. &quot;A probabilistic justification for using tf×idf term weighting in information retrieval.&quot; 2000. [http://doc.utwente.nl/66959/1/ijodl.pdf]
* see [[Smoothing for Language Models#Smoothing vs TF-IDF]]



== Sources ==
* [[Information Retrieval (UFRT)]]
* Zhai, ChengXiang. &quot;Statistical language models for information retrieval.&quot; 2008.
* Salton, Gerard, and Christopher Buckley. &quot;Term-weighting approaches in automatic text retrieval.&quot; 1988. [http://www.cs.odu.edu/~jbollen/spring03_IR/readings/article1-29-03.pdf]


[[Category:Information Retrieval]]
[[Category:NLP]]</text>
      <sha1>04z70m91ylzdfz6zj5hnmu1f73wpnv9</sha1>
    </revision>
  </page>
  <page>
    <title>Cosine Similarity</title>
    <ns>0</ns>
    <id>657</id>
    <revision>
      <id>660</id>
      <timestamp>2015-07-05T18:46:33Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4702">== Cosine Similarity ==
Cosine similarity is a [[Similarity Function]] that is often used in [[Information Retrieval]]
* it measures the angle between two vectors,  and in case of IR - the angle between two documents


=== Derivation ===
* recall the definition of the [[Dot Product]]: $\mathbf v \cdot \mathbf w = \| \mathbf v \| \cdot \| \mathbf w \| \cdot \cos \theta$
* or, by rearranging get $\cos \theta = \cfrac{\mathbf v \cdot \mathbf w}{\| \mathbf v \| \cdot \| \mathbf w \|}$
* so, let's define the cosine similarity function as $\text{cosine}(\mathbf d_1, \mathbf d_2) = \cfrac{\mathbf d_1^T \mathbf d_2}{\| \mathbf d_1 \| \cdot \| \mathbf d_2 \|}$
* cosine is usually $[-1, 1]$, but document vectors (see [[Vector Space Model]]) are usually non-negative, so the angle between two documents can never be greater than 90 degrees, and for document vectors $\text{cosine}(\mathbf d_1, \mathbf d_2) \in [0, 1]$
** min cosine is 0 (max angle: the documents are orthogonal) 
** max cosine is 1 (min angle: the documents are the same)


=== Cosine Normalization ===
If documents have unit length, then cosine similarity is the same as [[Dot Product]]
* $\text{cosine}(\mathbf d_1, \mathbf d_2) = \cfrac{\mathbf d_1^T \mathbf d_2}{\| \mathbf d_1 \| \cdot \| \mathbf d_2 \|} = \mathbf d_1^T \mathbf d_2$
* thus we can &quot;unit-normalize&quot; document vectors $\mathbf d' = \cfrac{\mathbf d}{\| \mathbf d \|}$ and then compute dot product on them and get cosine 
* this &quot;unit-length normalization&quot; is often called &quot;cosine normalization&quot; in IR



== Cosine Distance == 
* for documents $\text{cosine}(\mathbf d_1, \mathbf d_2) \in [0, 1]$
* it is max when two documents are the same
* how to define a distance? distance function should become larger as elements become less similar
* since maximal value of cosine is 1, we can define '''cosine distance''' as 
* $d_c(\mathbf d_1, \mathbf d_2) = 1 - \text{cosine}(\mathbf d_1, \mathbf d_2) = 1 -  \cfrac{\mathbf d_1^T \mathbf d_2}{\| \mathbf d_1 \| \cdot \| \mathbf d_2 \|}$


=== [[Distance Functions|Metricity]] ===
Let's check if cosine distance is a proper metric, i.e. it satisfies all the requirements
* Let $D$ be the document space and $\mathbf d_1, \mathbf d_2 \in D$
* $d_c(\mathbf d_1, \mathbf d_2) \geqslant 0$: checks - 0 is minimum
* $d_c(\mathbf d_1, \mathbf d_1) = 0$ checks - $1 - \cos 0 = 0$
* $d_c(\mathbf d_1, \mathbf d_2) = d_c(\mathbf d_2, \mathbf d_1)$: checks - angle is the same


What about the triangle inequality?
* under certain conditions is doesn't hold (Korenius2007) - so it's not a proper metric



== Cosine and [[Euclidean Distance]] ==
Euclidean distance $\| \mathbf d_1 - \mathbf d_2 \| = \sqrt{(\mathbf d_1 - \mathbf d_2)^T (\mathbf d_1 - \mathbf d_2)}$
* ED is a proper metric 

There's a connection between Cosine Distance end Euclidean Distance
* consider two unit-normalized vectors $\mathbf x_1 = \mathbf d_1 / \| \mathbf d_1 \|$ and $\mathbf x_2 = \mathbf d_1 / \| \mathbf d_1 \|$
* $\| \mathbf x_1 - \mathbf x_2 \|^2 = (\mathbf x_1 - \mathbf x_2)^T (\mathbf x_1 - \mathbf x_2) = \mathbf x_1^T \mathbf x_1 - 2 \, \mathbf x_1^T \mathbf x_2 + \mathbf x_2^T \mathbf x_2 = \| \mathbf x_1 \|^2 - 2 \, \mathbf x_1^T \mathbf x_2 + \| \mathbf x_2 \|^2 = 2 - 2 \, \mathbf x_1^T \mathbf x_2$
* if vectors are unit-normalized, cosine = dot product, so we have 
* $\| \mathbf x_1 - \mathbf x_2 \|^2 = 2 \, (1 -  \mathbf x_1^T \mathbf x_2) = 2 \, \big(1 - \text{cosine}(x_1, x_2)\big) = 2 \, d_c(x_1, x_2)$


It can also make some sense visually: 
* https://habrastorage.org/files/f73/289/979/f732899792f246358649e89765cd88da.png
* recall the [[Cosine Theorem]]: $a^2 = b^2 + c^2 - 2 bc \cos \theta$
* $b = c = 1$, so we have $a^2 = 2 \, (1 - \cos \theta)$


Thus we can use Euclidean distance and interpret it as Cosine distance


== Other Properties ==
=== Translation Non-Invariant ===
For [[PCA]] we usually do mean-correction
* but mean-correction affects the angle between documents
* can show that visually: the angle between two vectors are not translation-resistant
* https://habrastorage.org/files/60e/825/3b3/60e8253b34ba496da20ed47df2e21bf2.png
* i.e. if we have two vectors $\mathbf x_1$ and $\mathbf x_2$ and with $\theta$ being the angle between them, when we translate the space by $m$, we get a new angle $\theta'$ s.t. $\theta \ne \theta'$ 
* also note that when we translate, some elements may become negative!




== Sources ==
* Korenius, Tuomo, Jorma Laurikkala, and Martti Juhola. &quot;On principal component analysis, cosine and Euclidean measures in information retrieval.&quot; 2007. [http://www.sciencedirect.com/science/article/pii/S0020025507002630] 

[[Category:Similarity Functions]]
[[Category:Distances]]</text>
      <sha1>t73ltl4sg520ntrg39kjnuy8uu160jy</sha1>
    </revision>
  </page>
  <page>
    <title>Data Science Interview Questions</title>
    <ns>0</ns>
    <id>658</id>
    <revision>
      <id>661</id>
      <timestamp>2015-10-19T20:00:40Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="28006">The result: http://www.itshared.org/2015/10/data-science-interview-questions.html


== Data Science Interview Questions ==
The term &quot;Data Science&quot; is not yet well establish, so interviews for Data Science jobs might include a very broad range of questions - depending on the interpretation of the term by a particular company. This post is an attempt to organize Data Science interview questions in some usable form, but it might also be biased by how I see Data Science myself. I hope you also can find it useful.

The sources of the questions are: 
* my own data science interviews (being on the interviewee side)
* links that I discovered on the Internet, mostly from Quora and Reddit (see the links at the bottom of the post). 


== Background Questions ==
=== Careers ===
For background questions be ready to talk about a summary of your career. 
* Summarize your experience 
* What companies you worked at? What was your role?
* Do you have a project portfolio? What projects you implemented? Discuss some of them in details 


Preparation: 
* Review presentation of your projects or the code
* Try to explain the goal of these projects to yourself or your friend
* Prepare technical and non-technical summary of the projects. You'll need the non-technical summary if you're asked to explain the project in &quot;layman's terms&quot;
* Be ready to explain why a particular tool/algorithm was used and what other options you had


=== General Questions ===
There also be some questions not directly related to the projects you did. For example:
* What is the latest paper you read? Why did you read it and what did you learn? 
* What data science blogs do you follow? 


Other general questions:
* What have you done to improve your data analytics knowledge in the past year?
* What are your career goals?
* For aspiring data scientists: Why do you want a career in data science?



== Process ==
All Machine Learning, Data Mining and Data Science projects should follow some process, so there can be questions about it. 

Data Mining process questions:
* Can you outline the steps in an analytics project?
* Have you heard of [[CRISP-DM]] (Cross Industry Standard Process for Data Mining)?


CRISP-DM defines the following steps:
* Problem Definition 
* Data Exploration
* Data Preparation
* Modeling 
* Evaluation
* Deployment (for the production)


So next you may discuss each of these steps in details
* What is the goal of each step? 
* What are possible activities at each step?




== Background Mathematics ==
=== Linear Algebra ===
Basic Linear Algebra questions might include:
* What is $A \mathbf x = \mathbf b$? How to solve it?
* How do we multiply matrices? 
* What is an Eigenvalue? And what is an Eigenvector? What is Eigenvalue Decomposition or The Spectral Theorem?
* What is [[Singular Value Decomposition]]? 
* You can expect tons of LA questions in the Machine Learning part of the interview


=== Other Areas ===
* Analysis, Discrete Mathematics and Logics are not that important for Data Science 
* Probability and Statistics are core skills and discussed in the next section
* Optimization is usually discussed in the Machine Learning and usually when talking about a particular algorithm


== Probability and Statistics ==
Probability and Statistics is an important part of an interview, because it's the basics for Machine Learning. It is also useful if the company is doing some marketing or website optimization, so they could ask about A/B tests. 


=== Basic Probability ===
You can have a couple of simple questions to check your understanding of probability. 

For example:
* Given two fair dices, what is the probability of getting scores that sum to 4? to 8?
* A simple questions on Bayes rule: Imagine a test with a true positive rate of 100% and false positive rate of 5%. Imagine a population with a 1/1000 rate of having the condition the test identifies. Given a positive test, what is the probability of having that condition?


=== Distributions ===
You can expect questions about probability distributions:
* What is the normal distribution? Give an example of some variable that follows this distribution
* What about log-normal?
* Explain what a long tailed distribution is and provide three examples of relevant phenomena that have long tails. Why are they important in classification and prediction problems?
* How to check if a distribution is close to Normal? Why would you want to check it? What is QQ Plot? 
* Give examples of data that does not have a Gaussian distribution, or log-normal. 
* Do you know what the exponential family is?
* Do you know the Dirichlet distribution? the multinomial distribution?


=== Basic Statistics ===
* What is the Laws of Large Numbers? Central Limit Theorem?
* Why are they important for Statistics?
* What summary statistics do you know?


=== Experiment Design === 
Sampling and Randomization
* Why do we need to sample and how? 
* Why is randomization important in experimental design?
* Some 3rd party organization randomly assigned people to control and experiment groups. How can you verify that the assignment truly was random?
* How do you calculate needed sample size? 
* Power analysis


Biases
* When you sample, what bias are you inflicting?
* How do you control for biases?
* What are some of the first things that come to mind when I do X in terms of biasing your data?


Other questions
* What are confounding variables? 


=== Point Estimates ===
Confidence intervals
* What is a point estimate? What is a confidence interval for it?
* How they are constructed?
* Why you standardize?
* How to interpret confidence intervals?


=== Testing ===
Hypothesis tests
* Why do we need hypothesis testing? What is P-Value?
* What is the null hypothesis? How do we state it? 
* Do you know what type-I (type-II) error is?
* What is t-Test/F-Test/ANOVA? When to use it? 
* How would you test if two populations have the same mean? What if you have 3 or 4 populations?
* You applied ANOVA and it says that the mean is different. How do you identify the populations where the means are different? 
* What are the distributions / is the distribution of p-value's, in general?


=== A/B Tests === 
* What is A/B testing? How is it different from usual Hypothesis testing? 
* How can you prove that one improvement you've brought to an algorithm is really an improvement over not doing anything? How familiar are you with A/B testing? 
* How can we tell whether our website is improving?
* What are the metrics to evaluate a website? A search engine? 
* What kind of metrics would you track for you music streaming website?
* Common metrics: Engagement / retention rate, conversion, similar products / duplicates matching, how to measure them.
* Real-life numbers and intuition: Expected user behavior, reasonable ranges for user signup / retention rate, session length / count, registered / unregistered users, deep / top-level engagement, spam rate, complaint rate, ads efficiency.


=== Bayesian Statistics ===
In my interviews I didn't have any questions about Bayesian Stats, not did I found a lot of questions on the Internet. But here are some: 
* Have you ever seen Bayes Theorem?
* Do you know what a conjugate-prior is?

You might also get questions about Bayesian non-parametric models, but I'm not sure if it's common. 


=== Time Series === 
* What is a time series? 
* What is the difference between data for usual statistical analysis and time series data? 
* Have you used time series models? Cross-correlations with time lags? Correlograms? Spectral analysis? Signal processing and filtering techniques? In which context?
* Have you used any of the following: Time series models, Cross-correlations with time lags, Correlograms, Spectral analysis, Signal processing and filtering techniques? If yes, in which context?
* In time series modeling how can we deal with multiple types of seasonality like weekly and yearly seasonality?


=== Advanced ===
Resampling 
* Explain what resampling methods are and why they are useful. Also explain their limitations.
* Bootstrapping - how and why it is used? 
* How to use resampling for hypothesis testing? Have you heard of Permutation Tests? 
* How would you apply resampling to time series data? 



== Machine Learning ==
In my experience the Machine Learning part is usually the largest part of the interview. It may be a few basic questions, but it's helpful to be prepared to more in-depth ML questions, especially if you claim to have worked with ML on your CV. 


=== General ML Questions ===
The ML part may start with something quite simple, like: 
* What is the difference between supervised and unsupervised learning? Which algorithms are supervised learning and which are not? Why? 
* What is your favorite ML algorithm and why? 


=== Regression ===
* Describe the regression problem. Is it supervised learning? Why? 
* What is linear regression? Why is it called linear? 
* Discuss the bias-variance tradeoff.


Linear Regression:
* What is Ordinary Least Squares Regression? How it can be learned? 
* Can you derive the OLS Regression formula? (For one-step solution)
* Is model $Y = X_1 + X_2 + X_1 \, X_2 + \varepsilon$ still linear? Why? 
* Do we always need the intercept term? When do we need it and when do we not? 
* What is collinearity and what to do with it? How to remove multicollinearity? 
* What if the design matrix is not full rank? 
* What is overfitting a regression model? What are ways to avoid it?
* What is Ridge Regression? How is it different from OLS Regression? Why do we need it? 
* What is Lasso regression? How is it different from OLS and Ridge? 


Linear Regression assumptions:
* What are the assumptions required for linear regression? (see [[Multivariate Linear Regression]])
* What if some of these assumptions are violated? 


Significant features in Regression
* You would like to find significant features. How would you do that? 
* You fit a multiple regression to examine the effect of a particular feature. The feature comes back insignificant, but you believe it is significant. Why can it happen? 
* Your model considers the feature $X$ significant, and $Z$ is not, but you expected the opposite result. Why can it happen?


Evaluation
* How to check is the regression model fits the data well? 


Other algorithms for regression
* Decision trees for regression
* KNN for regression
* Do you know others? E.g. Splines? LOESS/LOWESS? 


=== Classification ===
Basic:
* Can you describe what is the classification problem? 
* What is the simplest classification algorithm?
* What classification algorithms do you know? Which one you like the most? 


Decision trees:
* What is a decision tree? 
* What are some business reasons you might want to use a decision tree model?
* How do you build it? 
* What impurity measures do you know? 
* Describe some of the different splitting rules used by different decision tree algorithms.
* Is a big brushy tree always good? Why would you want to prune it? 
* Is it a good idea to combine multiple trees? 
* What is Random Forest? Why is it good? [https://medium.com/@D33B/the-unreasonable-effectiveness-of-random-forests-f33c3ce28883]



Logistic regression:
* What is logistic regression? 
* How do we train a logistic regression model?
* How do we interpret its coefficients?



Support Vector Machines
* What is the maximal margin classifier? How this margin can be achieved and why is it beneficial?
* How do we train SVM? What about hard SVM and soft SVM?
* What is a kernel? Explain the Kernel trick
* Which kernels do you know? How to choose a kernel? 


Neural Networks
* What is an Artificial Neural Network?
* How to train an ANN? What is back propagation? 
* How does a neural network with one layer and one input and output compare to a logistic regression?
* What is deep learning? What is CNN or RNN? 


Other models: 
* What other models do you know? 
* How can we use Naive Bayes classifier for categorical features? What if some features are numerical? 
* Tradeoffs between different types of classification models. How to choose the best one? 
* Compare logistic regression with decision trees and neural networks.


=== Regularization ===
* What is Regularization? 
* Which problem does Regularization try to solve? 
* What does it mean (practically) for a design matrix to be &quot;ill-conditioned&quot;?
* When might you want to use ridge regression instead of traditional linear regression?
* What is the difference between the $L_1$ and $L_2$ regularization?
* Why (geometrically) does LASSO produce solutions with zero-valued coefficients (as opposed to LASSO ridge)?
* Let us go through the derivation of OLS or Logistic Regression. What happens when we add $L_2$ regularization? How do the derivations change? What if we replace $L_2$ regularization with $L_1$ regularization?



=== Dimensionality Reduction ===
Basics:
* What is the purpose of dimensionality reduction and why do we need it? 
* What ways of reducing dimensionality do you know? 
* Is feature selection a dimensionality reduction technique? 
* What is the difference between feature selection and feature extraction? 


PCA:
* Is it beneficial to perform dimensionality reduction before fitting an SVM? Why or why not?
* Are dimensionality reduction techniques supervised or not? Are all of them are (un)supervised? 
* What is Principal Component Analysis (PCA)? What is the problem it solves? How is it related to eigenvalue decomposition (EVD)? 
* What's the relationship between PCA and SVD? When SVD is better than EVD for PCA?
* Under what conditions is PCA effective?
* Why do we need to center data for PCA and what can happed if we don't do it? Do we need to scale data for PCA? 
* Is PCA a linear model or not? Why? 


Other DR techniques:
* Do you know other DR techniques? 
* What is Independent Component Analysis (ICA)? What's the difference between ICA and PCA? 
* Suppose you have a very sparse matrix where rows are highly dimensional. You project these rows on a random vector of relatively small dimensionality. Is it a valid dimensionality reduction technique or not? 
* Have you heard of Kernel PCA or other non-linear dimensionality reduction techniques? What about LLE (Locally Linear Embedding) or t-SNE (t-distributed Stochastic Neighbor Embedding)
* What is Fisher Discriminant Analysis? How it is different from PCA? Is it supervised or not? 



=== Cluster Analysis ===
* What is the cluster analysis problem?
* Which cluster analysis methods you know? 
* Describe K-Means. What is the objective of K-Means? Can you describe the Lloyd algorithm? 
* How do you select K for K-Means? 
* How can you modify k-means to produce soft class assignments?
* How to assess the quality of clustering? 
* Describe any other cluster analysis method. E.g. DBSCAN.


=== Optimization ===
You may have some basic questions about optimization:
* What is the difference between a convex function and non-convex? 
* What is Gradient Descent Method?
* Will Gradient Descent methods always converge to the same point?
* What is a local optimum? 
* Is it always bad to have local optima?
* What the Newton's method is?
* What kind of problems are well suited for Newton's method? Simplex? BFGS? SGD?
* What are &quot;slack variables&quot;?
* Describe a constrained optimization problem and how you would tackle it.



=== Recommendation ===
* What is a recommendation engine? How does it work?
* How would you approach the Netflix Prize?
* How to do customer recommendation?
* What is Collaborative filtering?
* How would you generate related searches for a search engine?
* How would you suggest followers on Twitter?


=== Feature Engineering ===
* How to apply machine learning to audio data, images, texts, graphs, etc? 
* What is feature engineering? Can you give an example? Why do we need it? 
* How to go from categorical variables to numerical? 



=== Natural Language Processing ===
If the company deals with text data, you can expect some questions on NLP and Information Retrieval:
* What is NLP? How is it related to Machine Learning? 
* How would you turn unstructured text data into structured data usable for ML models?
* What is the Vector Space Model?
* What is TF-IDF?
* Which distances and similarity measures can we use to compare documents? What is cosine similarity? 
* Why do we remove stop words? When do we not remove them?
* Language Models. What is N-Grams? 


=== Meta Learning ===
Feature selection
* Are all features equally good? 
* What are the downfalls of using too many or too few variables?
* What is Feature Selection and why do we need it? 
* How many features should you use? How do you select the best features? Describe several feature selection methods. Are these methods depend on the model or not?


Model selection
* You have built several different models. How would you select the best one? 
* You have one model and want to find the best set of parameters for this model. How would you do that? 
* How would you look for the best parameters? Do you know something else apart from grid search? 
* What is Cross-Validation? 
* What is 10-Fold CV?
* What is the difference between holding out a validation set and doing 10-Fold CV.


Model evaluation
* How do you know if your model overfits? 
* How do you assess the results of a logistic regression?
* Which evaluation metrics you know? Something apart from accuracy?
* Which is better: Too many false positives or too many false negatives?
* What precision and recall are?
* What is a ROC curve? What is AU ROC (AUC)? How to interpret ROC and AU ROC? 
* Do you know about Concordance or Lift? 



Discussion Questions:
* You have a marketing campaign and you want to send emails to users. You developed a model for predicting if a user will reply or not. How can you evaluate this model? Is there a chart you can use?



=== Miscellanea ===
Curse of Dimensionality
* What is Curse of Dimensionality? How does it affect distance and similarity measures? 
* What are the problems of large feature space? How does it affect different models, e.g. OLS? What about computational complexity? 
* What dimensionality reductions can be used for preprocessing the data?
* What is the difference between density-sparse data and dimensionally-sparse data? 



You are training an image classifier with limited data. What are some ways you can augment your dataset?

=== LA for ML ===

How does the &quot;power method&quot; work?
How are sparse matrices special/useful?
Why is the QR factorization often used to solve OLS regression problems instead of the better known matrix form of the normal equations?


== Computer Science ==
Knowledge in Computer Science is as important for Data Science as knowledge in Machine Learning. So you may get the same type of questions as for any software developer position, but possible with lower expectations on your answers.

I was a Java developer for quite some time, so here is a list of questions I asked (and often was asked) for job interviews. This list can also be helpful for preparing to a Data Science interview [[Java interview questions]].


=== Libraries and Tools ===
You can be asked about libraries:
* Which libraries for Analytics/DS you are familiar in Python/R/Java?
* Have you used numpy, scipy, pandas, sklearn?
* What are some features of the sklearn api that differentiate it from fitting models in R?
* What are some features of pandas/scipy that you like? Hate? Same questions for R.
* Why is &quot;vectorization&quot; such a powerful method for optimizing numerical code? What is going on that makes the code faster relative to alternatives like nested for loops?
* When is it better to write your own code than using a data science software package?
* State any 3 positive and negative aspects about your favorite statistical software.
* Describe a difficult bug you've encountered and how you resolved it.
* How does floating point affect precision of calculations? Equality tests?
* What is BLAS? LAPACK?



=== Algorithms ===
And also some algorithm related questions, like
* What is big O? 
* What sorting algorithm do you know? 
* How to HashMap is implemented? 
* What are hash table collisions? How is it avoided? How frequently does it happen?


Implementation
* implement some simple model, e.g. OLS regression or logistic regression 


Data generation:
* Given an unfair coin with the probability of heads not equal to 0.5. What algorithm could you use to create a list of random 1s and 0s?
* Given a set of $n$ objects, write an algorithm to select a random subset of size $k$ (where $k \leqslant n$) without replacement.


Other questions:
* What is probabilistic merging (AKA fuzzy merging)? Is it easier to handle with SQL or other languages?
* Which languages would you choose for semi-structured text data reconciliation?


=== Databases ===
* Have you been involved in database design and data modeling?
* SQL-Related questions: e.g. what's group by? 
* Or given some DB schema you may be asked to write a simple SQL query.

Describe different NoSQL technologies you're familiar with, what they are good at, and what they are bad at.

What is a &quot;star schema&quot;?


=== Distributed Systems and Big Data ===
Basic &quot;Big Data&quot; questions:
* What is the biggest data set that you have processed and how did you process it? What was the result?
* Do you know about Apache Hadoop, Apache Spark, Apache Flink? Have you used Apache Mahout?



MapReduce
* What are the advantages/disadvantages of &quot;shared-nothing&quot; architecture?
* What is MapReduce? Why is it &quot;shared-nothing&quot; architecture?
* Can you implement word count in MapReduce? What about something a bit more complex like TF-IDF? Naive Bayes? 
* What is load balance? How to make sure a mapreduce application has good load balance? 
* Can you give examples where MapReduce does not work? 
* What are examples of &quot;embarassingly parallelizable&quot; algorithms?


Implementation questions
* How do you optimize a web crawler to run much faster, extract better information and summarize data to produce cleaner databases?
* How would you estimate the median of a dataset that is too big to hold in your computer memory?




== Hands-On ==

=== Problem to Solve ===
Quite often you are given some problem description and asked how would you approach it. 

For example:

Assume that you are asked to lead a project on churn detection, and have dataset of known users who stopped using the service and ones who are still using. This data includes demographics and other features.

Do the following:
# Describe the methodology and model that you will chose to identify churn, and describe your thought process.
# Think how would you communicate the results to the CEO? 
# Suppose in the dataset only 0.025 of users churned. How would you make it more balanced? 

Also:
* How would you implement it if you had one day? One month? One year? 
* How would your approach scale? 


Other problems: 
* How would you approach identifying plagiarism? 
* How to detect individual paid accounts shared by multiple users?
* How to detect bogus reviews, or bogus Facebook accounts used for bad purposes?
* Usually the domain of the problem is related to what the company is doing. If they're doing marketing, it will most likely be marketing related. 


Additionally, you may be asked: 
* How would you approach collecting the data if you didn't have the dataset? 


=== Problem Solving Coding ===
* Sometimes you even may be presented a small dataset and ask to do a particular task with any tool. For example, write a script to extract features, then do some exploratory data analysis and finally apply some ML algorithm to this dataset. Or just the last two, with a ready to use dataset in tabular form. 


Anyway, the right way to conduct a data science interview is to create a dataset (i.e. from a Kaggle, etc) that resembles the problem you want to solve, and have the 'scientist' work through the different steps from start to finish of what they would do:

* What data would they choose?
* How would they clean the data?
* What types of features? How could features be enhanced with domain knowledge?
* What model would they use? why / why not?
* What evaluation metrics? (f1 / recall / precision, etc)
* What are other papers saying about this? What is the academic benchmark for a problem like this?
* Who in academia has presented papers on this type of problem?
* etc.


=== Papers ===
It's also possible that you'll be asked to read some ML paper and share your thoughts on it, and then discuss the proposed algorithm, it's time complexity, how it can be implemented and improved. I wasn't asked to do it myself, but based on my experience working as a ML developer, I believe that reading papers and being able to understand them is an important skill, so don't be surprised if somebody tries to check this ability.




== Sources ==
* My own interviews
* http://www.quora.com/What-is-a-typical-data-scientist-interview-like
* http://www.quora.com/What-are-the-interview-questions-on-regression-modeling
* http://www.quora.com/How-should-I-prepare-for-statistics-questions-for-a-data-science-interview
* http://www.quora.com/A-B-Testing/What-kind-of-A-B-testing-questions-should-I-expect-in-a-data-scientist-interview-and-how-should-I-prepare-for-such-questions
* http://www.quora.com/What-are-20-questions-to-detect-fake-data-scientists
* http://www.quora.com/What-are-some-common-Machine-Learning-interview-questions
* http://www.quora.com/What-are-the-best-interview-questions-to-evaluate-a-machine-learning-researcher
* https://www.quora.com/Are-CS-questions-part-of-a-data-scientist-interview-at-Facebook
* http://www.quora.com/Data-Science/How-should-I-prepare-for-statistics-questions-for-a-data-science-interview
* http://stats.stackexchange.com/questions/5465/statistics-interview-questions
* http://www.reddit.com/r/datascience/comments/2nhb4k/what_interview_questions_have_you_been_asked/
* http://www.reddit.com/r/statistics/comments/310h76/i_have_an_interview_for_a_parttime_data_analyst/
* https://www.reddit.com/r/datascience/comments/3fsz54/my_top10_technical_questions_for_job_candidates/
* https://www.reddit.com/r/datascience/comments/3kzf69/data_scientist_interview_questions_on_pca_svm/
* http://www.reddit.com/r/MachineLearning/comments/392nwy/interview_questions_for_data_scientist_positions/
* http://blog.udacity.com/2015/04/data-science-interview-questions.html
* http://alyaabbott.wordpress.com/2014/10/01/how-to-ace-a-data-science-interview/
* http://www.marketingdistillery.com/2014/09/03/how-to-successfully-recruit-a-data-scientist/ 
* http://www.edureka.co/blog/frequently-asked-data-science-interview-questions
* http://www.galvanize.it/blog/how-to-nail-a-data-science-interview
* http://analyticsindiamag.com/common-analytics-interview-questions/
* http://www.datasciencecentral.com/profiles/blogs/66-job-interview-questions-for-data-scientists



== Useful Links ==
* http://www2.udacity.com/rs/udacity/images/Ultimate%20Skills%20Checklist%20For%20Your%20First%20Data%20Analyst%20Job.pdf
* http://www.quora.com/What-are-some-important-questions-to-ask-a-recruiter-when-interviewing-for-a-data-science-job
* http://www.quora.com/In-a-data-scientist-interview-should-I-use-Python-or-C++-for-algorithm-data-structure-questions
* http://www.quora.com/How-do-I-prepare-for-a-data-scientist-interview
* http://datascienceinterview.quora.com/Data-Science-Interview-Preparation
* http://datascienceinterview.quora.com/Answers-1
* https://github.com/gkamradt/Lessons-Learned-Data-Science-Interviews
* http://mathewanalytics.com/2015/08/18/homework-during-the-hiring-process-no-thanks/
* https://medium.com/@D33B/interview-questions-for-data-scientist-positions-5ad3c5d5b8bd
* https://medium.com/@D33B/interview-questions-for-data-scientist-positions-part-ii-ac294c2c7241
* http://www.jasq.org/just-another-scala-quant/new-agey-interviews-at-the-grocery-startup


[[Category:Interview Questions]]
[[Category:Interviews]]
[[Category:Machine Learning]]
[[Category:Statistics]]</text>
      <sha1>rjtp9tu8nytklw0xwfafrjt89canze8</sha1>
    </revision>
  </page>
  <page>
    <title>Redis</title>
    <ns>0</ns>
    <id>659</id>
    <revision>
      <id>668</id>
      <timestamp>2015-11-16T10:32:59Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Redis == [http://redis.io/ Redis] is an in-memory database, good to be used as  * a cache * a message queue   == Installation == === Ubuntu === Installing Redis on ubuntu...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5154">== Redis ==
[http://redis.io/ Redis] is an in-memory database, good to be used as 
* a cache
* a message queue


== Installation ==
=== Ubuntu ===
Installing Redis on ubuntu

* &lt;code&gt;sudo apt-get install redis-tools&lt;/code&gt;
* default port is 6379
* Use &lt;code&gt;redis-cli&lt;/code&gt; to enter redis commands 
* if you need redis instance be outside, do &lt;code&gt;nano /etc/redis/redis.conf&lt;/code&gt;  and replace &lt;code&gt;bind 127.0.0.1&lt;/code&gt; to &lt;code&gt;bind 0.0.0.0&lt;/code&gt;
* restart the server &lt;code&gt;service redis-server restart&lt;/code&gt;
* to check if you can connect to redis from another server, do &lt;code&gt;redis-cli -h 192.168.x.x ping&lt;/code&gt;, should get &lt;code&gt;PONG&lt;/code&gt; in return


=== Python ===
Python library: 

* &lt;code&gt;sudo pip install redis&lt;/code&gt; or
* &lt;code&gt;sudo easy_install install redis&lt;/code&gt; or


== Building Blocks ==
=== Databases ===
* Each redis server can have several databases
* they are indexed by integers: 0, 1, 2, ...
* 0 is the default db
* to choose the 1st db, use &lt;code&gt;select 1&lt;/code&gt;
* redis keeps all the data in memory, but by default, redis also snapshots DB to disk after each $X$ changes 
* there's also append-only mode


=== Key/Value Pairs ===
String key/values
* key can be anything, e.g. &lt;code&gt;users:ololo&lt;/code&gt;, &lt;code&gt;:&lt;/code&gt; doesn't have any specific meaning, but can be used to separate &quot;table name&quot; and &quot;key name&quot;
* command &lt;code&gt;set users:ololo '{&quot;name&quot;:&quot;ololo&quot;, ...}'&lt;/code&gt; - the content can be any string, not necessarily JSON
* to get the value, use &lt;code&gt;get users:ololo&lt;/code&gt;
* you can query only by key, never by value 


String functions:
* &lt;code&gt;strlen key&lt;/code&gt; returns the lenth of the value associated with key &lt;code&gt;key&lt;/code&gt;
* &lt;code&gt;getrange key 0 10&lt;/code&gt; returns the substring from 0 to 10 of the value stored by &lt;code&gt;key&lt;/code&gt;
* &lt;code&gt;append key value2&lt;/code&gt; appends 'value2' to the current value stored by &lt;code&gt;key&lt;/code&gt;


=== Counters ===
* You can store counters in redis 
* &lt;code&gt;incr key&lt;/code&gt; increment the integer value stored in &lt;code&gt;key&lt;/code&gt;, or create a new key with value 1
* &lt;code&gt;decr key&lt;/code&gt; decrement the value
* &lt;code&gt;incrby&lt;/code&gt; and &lt;code&gt;decrby&lt;/code&gt; are used to increase/decrease the values by some number


=== Bitmaps ===
* you can store byte arrays in redis and set/get their specific bits
* commands: &lt;code&gt;setbit&lt;/code&gt; and &lt;code&gt;getbit&lt;/code&gt;
* this can be used for implementing [[Sketching Algorithms]], e.g. [[Bloom Filters]]


=== Hashes ===
* hashes in redis are [[Hash Tables|associative arrays]]
* to store a hash, not a string, use &lt;code&gt;hset&lt;/code&gt; and &lt;code&gt;hget&lt;/code&gt;
* &lt;code&gt;hset hashname field 30&lt;/code&gt; is approximately equal to &lt;code&gt;hashname[field] = 30&lt;/code&gt;
* if hash &lt;code&gt;hashname&lt;/code&gt; doesn't exist, it will be created. If exists, but &lt;code&gt;field&lt;/code&gt; doesn't, &lt;code&gt;field&lt;/code&gt; will be created
* &lt;code&gt;hgetall hashname&lt;/code&gt; returns all fields of the hash &lt;code&gt;hashname&lt;/code&gt;
* &lt;code&gt;hdel hashname field&lt;/code&gt; removes &lt;code&gt;field&lt;/code&gt; from &lt;code&gt;hashname&lt;/code&gt;


=== Lists ===
* lists keep an array of values associated with a specific key
* &lt;code&gt;lpush listname new_value&lt;/code&gt; adds the new value to the front of &lt;code&gt;listname&lt;/code&gt;
* &lt;code&gt;ltrim listname 0 49&lt;/code&gt; removes first 50 values from the list
* &lt;code&gt;lrange listname 0 9&lt;/code&gt; returns first 10 values


=== Sets ===
Unordered sets
* &lt;code&gt;sadd set1 val1 val2 val3&lt;/code&gt; adds values &quot;val1&quot; &quot;val2&quot; &quot;val3&quot; to set &lt;code&gt;setkey&lt;/code&gt;
* &lt;code&gt;smember set1 val1&lt;/code&gt;
* &lt;code&gt;sinter set1 set2&lt;/code&gt; intersection of two sets &lt;code&gt;set1&lt;/code&gt; and &lt;code&gt;set2&lt;/code&gt;
* &lt;code&gt;sinterstore set1 set2 new_set&lt;/code&gt; store instersection of two sets in a new set &lt;code&gt;new_set&lt;/code&gt;


Ordered sets
* the same commands, but they start with &quot;z&quot;:
* &lt;code&gt;zadd&lt;/code&gt;, &lt;code&gt;zmember&lt;/code&gt;, ...


== Usage Patterns ==
* in redis it's fine to issue several requests (&quot;round trips&quot; to db) - because it's so fast 


=== Avoiding Duplication ===
* suppose users can log in using their ids or emails - so you have two keys for the same user
* how can you avoid storing the same user twice? 
* first, keep the user data at &lt;code&gt;user:id&lt;/code&gt;, e.g. &lt;code&gt;users:9001&lt;/code&gt;
* use hash to lookup the id for email: &lt;code&gt;hget user:emails ololo@mlwiki.org&lt;/code&gt;


=== Expiration ===
* you can set time to live of a key 
* &lt;code&gt;expire key 30&lt;/code&gt; where 30 is the time to live in seconds 
* &lt;code&gt;expireat key unix_timestamp&lt;/code&gt;
* &lt;code&gt;ttl key&lt;/code&gt; to see how much time the &lt;code&gt;key&lt;/code&gt; has left to live


=== Publish/Subscribe ===
* it's easy to implement the [[Publish-Subscribe Model]] in redis - which makes it a lightweight message queue
* &lt;code&gt;blpop&lt;/code&gt; and &lt;code&gt;brpop&lt;/code&gt; - return and remove first (last) element of a list - or blocks until something is avialable 
* can use it to implement a [[Queue]]
* also can use &lt;code&gt;subscribe q_id&lt;/code&gt; and &lt;code&gt;publish q_it message&lt;/code&gt;


A P/S model implemented in Scala: https://gist.github.com/debasishg/7056696



=== Lua Scripting ===
* finally, it's possible to write stored procedures in Lua 


== Sources ==
* Little Redis Book: https://github.com/karlseguin/the-little-redis-book

[[Category:Databases]]</text>
      <sha1>5uljz4ckg0j9wc90w1ehdvmw7aexzyr</sha1>
    </revision>
  </page>
  <page>
    <title>Template:Void</title>
    <ns>10</ns>
    <id>660</id>
    <revision>
      <id>671</id>
      <timestamp>2015-11-16T16:22:51Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;&lt;noinclude&gt;Does nothing&lt;/noinclude&gt;&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="35">&lt;noinclude&gt;Does nothing&lt;/noinclude&gt;</text>
      <sha1>i7mt4crte7u4c7k2dh4tkgx6rzkmz36</sha1>
    </revision>
  </page>
  <page>
    <title>Hadoop Pseudo Distributed Mode</title>
    <ns>0</ns>
    <id>661</id>
    <revision>
      <id>672</id>
      <timestamp>2015-11-17T16:17:03Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Hadoop Pseudo Distributed Mode == [[Hadoop]] cluster can be emulated with &quot;pseudo-distributed mode&quot; * all Hadoop demons run, and applications feel like tHey are being execu...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4324">== Hadoop Pseudo Distributed Mode ==
[[Hadoop]] cluster can be emulated with &quot;pseudo-distributed mode&quot;
* all Hadoop demons run, and applications feel like tHey are being executed on a real cluster 
* good for testing [[Hadoop MapReduce]] jobs before running them on a fully distributed cluster


== Setting Up Locally ==
=== Preparation ===
* install Hadoop from binaries, put e.g. to &lt;code&gt;~/soft/hadoop-2.6.0/&lt;/code&gt;
* point &lt;code&gt;HADOOP_CONF_DIR&lt;/code&gt; to some directory with config, e.g. &lt;code&gt;~/conf/hadoop-local&lt;/code&gt;

You need to export the following env variables:

 #!/bin/bash
 
 export HADOOP_HOME=~/soft/hadoop-2.6.0
 export HADOOP_BIN=$HADOOP_HOME/bin
 
 export HADOOP_CONF_DIR=~/conf/hadoop-cluster
 export YARN_CONF_DIR=$HADOOP_CONF_DIR
 
 export PATH=$HADOOP_BIN:$HADOOP_HOME/sbin:$PATH


Also, if you don't have a java on your PATH, you need to create &lt;code&gt;hadoop-env.sh&lt;/code&gt; in &lt;code&gt;HADOOP_CONF_DIR&lt;/code&gt; and add (replace)

 export JAVA_HOME=/home/user/soft/jdk1.8.0_60/
 export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-&quot;/etc/hadoop&quot;}


=== Properties ===

Hadoop in &quot;Pseudo-distributed mode&quot; should have properties similar to these:

 cat core-site.xml
 &lt;?xml version=&quot;1.0&quot;?&gt;
 &lt;configuration&gt;
   &lt;property&gt;
     &lt;name&gt;fs.defaultFS&lt;/name&gt;
     &lt;value&gt;hdfs://localhost/&lt;/value&gt;
   &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
     &lt;value&gt;/home/agrigorev/tmp/hadoop/&lt;/value&gt;
   &lt;/property&gt;
 &lt;/configuration&gt;

 cat hdfs-site.xml 
 &lt;?xml version=&quot;1.0&quot;?&gt;
 &lt;configuration&gt;
   &lt;property&gt;
     &lt;name&gt;dfs.replication&lt;/name&gt;
     &lt;value&gt;1&lt;/value&gt;
   &lt;/property&gt;
 &lt;/configuration&gt;

 cat mapred-site.xml 
 &lt;?xml version=&quot;1.0&quot;?&gt;
 &lt;configuration&gt;
   &lt;property&gt;
     &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
     &lt;value&gt;yarn&lt;/value&gt;
   &lt;/property&gt;
 &lt;/configuration&gt;

 cat yarn-site.xml 
 &lt;?xml version=&quot;1.0&quot;?&gt;
 &lt;configuration&gt;
   &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
     &lt;value&gt;localhost&lt;/value&gt;
   &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
     &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
   &lt;/property&gt;
 &lt;/configuration&gt;


=== File System ===
* Once the configuration is set, format the filesystem
* &lt;code&gt;hdfs namenode -format&lt;/code&gt;
* if &lt;code&gt;hadoop.tmp.dir&lt;/code&gt; is not specified, it'll use &lt;code&gt;/tmp/hadoop-${user.name}&lt;/code&gt;, which is cleaned after each reboot 


=== Setting SSH Access ===
* Application master and workers on the cluster communicate via ssh 
* it's the same for pseudodistributed mode - except that the master and all the workers are located on the same machine
* but they still need to use ssh for that 
* so make sure you can do &lt;code&gt;ssh localhost&lt;/code&gt;
* if not - check if ssh service and &lt;code&gt;ssh-agent&lt;/code&gt; are running 


=== Starting Daemons ===
To start, use

 start-dfs.sh
 start-yarn.sh
 mr-jobhistory-daemon.sh start historyserver


make sure namenode started:

 telnet localhost 8020


If namenode doesn't start in local mode, do [http://stackoverflow.com/questions/8076439/namenode-not-getting-started]: 
* delete all contents from the hadoop temporary folder: &lt;code&gt;rm -Rf tmp_dir&lt;/code&gt;
* format the namenode: &lt;code&gt;hadoop namenode -format&lt;/code&gt;
* start the namenode again: &lt;code&gt;start-dfs.sh&lt;/code&gt;

Starting datanodes
* &lt;code&gt;hadoop-daemon.sh start datanode&lt;/code&gt;
* to check if it works:

 hadoop fs -put somefile /home/username/
 hadoop fs -ls /home/username/ 


Troubleshooting:
* if datanode doesn't start [http://stackoverflow.com/questions/16725804/]
* if yarn resourcemanager doesn't start 
** &quot;Queue configuration missing child queue names for root&quot; [http://stackoverflow.com/questions/28357130/unable-to-start-resourcemanager-capacity-scheduler-xml-not-found-hadoop-2-6-0]
** copy [http://svn.apache.org/viewvc/hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/resources/capacity-scheduler.xml?view=co&amp;revision=1495684&amp;content-type=text%2Fplain capacity-scheduler.xml] to &lt;code&gt;HADOOP_CONF_DIR&lt;/code&gt;

=== Jobs Monitoring ===

 yarn application -list
 yarn application -kill application_1445857836386_0002



== Links ==
* [https://www.evernote.com/shard/s344/sh/21cdb658-ed50-40e7-809c-4a6418d3c10b/1912d438d4abb05617d31caa7609ffdd note on Evernote]

== Sources ==
* [[Hadoop: The Definitive Guide (book)]]

[[Category:Hadoop]]
[[Category:MapReduce]]</text>
      <sha1>13zqzsfs77ajdjvskkgt1zhpjuehtok</sha1>
    </revision>
  </page>
  <page>
    <title>Oozie</title>
    <ns>0</ns>
    <id>662</id>
    <revision>
      <id>674</id>
      <timestamp>2015-11-19T13:21:40Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Apache Oozie == [[Oozie|Apache Oozie]] is a workflow manager, designed especially for running [[Hadoop MapReduce]] jobs  It contains 2 parts: * workflow engine: runs workfl...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1130">== Apache Oozie ==
[[Oozie|Apache Oozie]] is a workflow manager, designed especially for running [[Hadoop MapReduce]] jobs

It contains 2 parts:
* workflow engine: runs workflow jobs (MR, Pig, Hive)
* coordinator engine: coordinates the execution


It's a service:
* Oozie is a service that runs on the cluster 
* the client submits only workflow definitions
* so, unlike hadoop &lt;code&gt;JobControl&lt;/code&gt;, it doesn't submit the tasks itself


=== Workflow ===
A ''workflow'' is a [[Graphs#Directed Acyclic Graph|DAG]]  of ''action nodes''
and ''control-flow nodes''

Action Nodes 
* perform workflow tasks 
* e.g. running [[Hadoop MapReduce]], [[Pig]] or [[Hive]] jobs
* can also be an arbitrary shell script or a Java program


Control Flow Nodes
* Conditional logic (if, else, etc)
* Parallel execution 

The Oozie workflow is written in [[XML]] using Hadoop Process Definition language

== Editors ==
Hue has Oozie Workflow editor - so it is possible to design workflows manually
* see http://gethue.com/new-apache-oozie-workflow-coordinator-bundle-editors/


[[Category:Hadoop]]
[[Category:Workflow Management]]
[[Category:ETL]]</text>
      <sha1>0llezzgsqudsfxkuhiuwpq4x1cg6q7f</sha1>
    </revision>
    <revision>
      <id>677</id>
      <parentid>674</parentid>
      <timestamp>2015-11-23T10:37:40Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1188">== Apache Oozie ==
[[Oozie|Apache Oozie]] is a workflow manager, designed especially for running [[Hadoop MapReduce]] jobs

It contains 2 parts:
* workflow engine: runs workflow jobs (MR, Pig, Hive)
* coordinator engine: coordinates the execution


It's a service:
* Oozie is a service that runs on the cluster 
* the client submits only workflow definitions
* so, unlike hadoop &lt;code&gt;JobControl&lt;/code&gt;, it doesn't submit the tasks itself


=== Workflow ===
A ''workflow'' is a [[Graphs#Directed Acyclic Graph|DAG]]  of ''action nodes''
and ''control-flow nodes''

Action Nodes 
* perform workflow tasks 
* e.g. running [[Hadoop MapReduce]], [[Pig]] or [[Hive]] jobs
* can also be an arbitrary shell script or a Java program


Control Flow Nodes
* Conditional logic (if, else, etc)
* Parallel execution 

The Oozie workflow is written in [[XML]] using Hadoop Process Definition language


== Editors ==
Hue has Oozie Workflow editor - so it is possible to design workflows manually
* see http://gethue.com/new-apache-oozie-workflow-coordinator-bundle-editors/


== Sources ==
* [[Hadoop: The Definitive Guide (book)]]

[[Category:Hadoop]]
[[Category:Workflow Management]]
[[Category:ETL]]</text>
      <sha1>shfkbk6gd74i8yj410jnys97xb6hdbq</sha1>
    </revision>
  </page>
  <page>
    <title>MapReduce/MRUnit</title>
    <ns>0</ns>
    <id>663</id>
    <revision>
      <id>675</id>
      <timestamp>2015-11-20T16:42:35Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== MapReduce MRUnit == MR Unit is a library for unit-testing [[Hadoop MapReduce]] jobs * https://mrunit.apache.org/   == Example == === Maven Dependency === For Hadoop2:    &lt;d...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1975">== MapReduce MRUnit ==
MR Unit is a library for unit-testing [[Hadoop MapReduce]] jobs
* https://mrunit.apache.org/


== Example ==
=== Maven Dependency ===
For Hadoop2: 

 &lt;dependency&gt;
   &lt;groupId&gt;org.apache.mrunit&lt;/groupId&gt;
   &lt;artifactId&gt;mrunit&lt;/artifactId&gt;
   &lt;version&gt;1.1.0&lt;/version&gt;
   &lt;classifier&gt;hadoop2&lt;/classifier&gt; 
   &lt;scope&gt;test&lt;/scope&gt;
 &lt;/dependency&gt;

Use classifier &lt;code&gt;hadoop1&lt;/code&gt; for Hadoop1 

This version works well with Hadoop &lt;code&gt;2.6.0-cdh5.4.7&lt;/code&gt;


=== Mapper Test ===
Steps:
* You wrap your mapper in &lt;code&gt;MapDriver.newMapDriver&lt;/code&gt;
* Feed some input data
* Provide expected output 
* Run

 mapper = MapDriver.newMapDriver(new YourMapper());
 
 // input
 mapper.addInput(key1, value1);
 mapper.addInput(key2, value2);
 mapper.addInput(key3, value3);
 
 // expected output
 mapper.addOutput(outKey1, outValue1);
 mapper.addOutput(outKey2, outValue2);
 mapper.addOutput(outKey3, outValue3);
 
 mapper.runTest();

=== Reducer Test ===
Same as for Mapper:
* Wrap your reducer in &lt;code&gt;ReduceDriver.newReduceDriver&lt;/code&gt;
* Provide input and expected output 
* Run

 reducer = ReduceDriver.newReduceDriver(new YourReducer());
 
 reducer.addInput(key1, value1);
 reducer.addInput(key2, value2);
 
 reducer.addOutput(outKey1, outValue1);
 reducer.addOutput(outKey2, outValue2);
 
 reducer.runTest();


=== Configuration ===
Changing some configuration parameters is easy
* use &lt;code&gt;driver.getConfiguration()&lt;/code&gt;

E.g.:

 reducer.getConfiguration().setInt(&quot;app.name.param1&quot;, 4);


=== Distributed Cache ===
Faking a file from &quot;Distribute Cache&quot;:

 URL resource = this.getClass().getResource(&quot;test-resource-file.txt&quot;);
 Path link = Paths.get(&quot;symlink&quot;);
 Path target = Paths.get(resource.toURI());
 if (link.toFile().exists()) {
     link.toFile().delete();
 }
 
 Files.createSymbolicLink(link, target);
 
 try {
     // test goes here
 } finally {
     link.toFile().delete();
 }



[[Category:Hadoop]]
[[Category:Java]]
[[Category:Snippets]]</text>
      <sha1>dd4xdn4lp7wntflf85oqi6ga38h3ybz</sha1>
    </revision>
  </page>
  <page>
    <title>Hadoop: The Definitive Guide (book)</title>
    <ns>0</ns>
    <id>664</id>
    <revision>
      <id>676</id>
      <timestamp>2015-11-23T10:35:18Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;This is a book by T. White published by O'Reilly Media, Inc. * notes are based on the 4th edition (2015) from Safari books [https://www.safaribooksonline.com/library/view/hado...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1249">This is a book by T. White published by O'Reilly Media, Inc.
* notes are based on the 4th edition (2015) from Safari books [https://www.safaribooksonline.com/library/view/hadoop-the-definitive/9781491901687/]

http://akamaicovers.oreilly.com/images/0636920033448/cat.gif


== Table of Contents ==
=== [[Hadoop]] Fundamentals ===
* Meet Hadoop
* [[MapReduce]]
* The [[Hadoop Distributed File System]]
* [[YARN]]
* Hadoop I/O

=== [[Hadoop MapReduce]] ===
* Developing a MapReduce Application
** Writing a Unit Test with [[MapReduce/MRUnit|MRUnit]]
** Running Locally on Test Data
** [[Hadoop Pseudo Distributed Mode]]
** MapReduce Workflows: [[Oozie|Apache Oozie]]
* How MapReduce Works (see [[YARN]])
* MapReduce Types and Formats
* MapReduce Features
** [[MapReduce/Secondary Sort]]
** [[MapReduce/Joins]]

=== Hadoop Operations ===
* Setting Up a Hadoop Cluster
* Administering Hadoop

=== Related Projects ===
* [[Avro]]
* [[Parquet]]
* [[Flume]]
* [[Sqoop]]
* [[Pig]]
* [[Hive]]
* [[Crunch]]
* [[Spark]]
* [[HBase]]
* [[ZooKeeper]]

=== Case Studies ===
* Composable Data at Cerner
* Biological Data Science: Saving Lives with Software
* [[Cascading]]



[[Category:Books]]
[[Category:Notes]]
[[Category:Hadoop]]
[[Category:Distributed Systems]]</text>
      <sha1>g2q1t22c7a14049130wss66z8qunsrp</sha1>
    </revision>
  </page>
  <page>
    <title>Hadoop MapReduce</title>
    <ns>0</ns>
    <id>665</id>
    <revision>
      <id>679</id>
      <timestamp>2015-11-23T11:41:28Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Hadoop MapReduce == This is a [[Hadoop]] data processing tool on top of [[HDFS]] * it's a batch query processing tool that goes over '''all''' available data * best for off...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15602">== Hadoop MapReduce ==
This is a [[Hadoop]] data processing tool on top of [[HDFS]]
* it's a batch query processing tool that goes over '''all''' available data
* best for off-line use
* it's a part of [[Hadoop]]


== [[MapReduce]] Jobs ==
=== Jobs ===
''Job'' is a specification that should be run on the cluster by [[Hadoop]]/[[YARN]]
* it's a unit of work
* contains: paths to input data, the MapReduce program (Map and Reduce UDFs) and configuration
* a job can have several input paths, and one output path

Job packaging: 
* when we run the code on a cluster, we package it to a set of jar files 
* we need to tell the cluster which is our jar 
* done via &lt;code&gt;job.setJarByClass(MyJob.class)&lt;/code&gt;, so Hadoop can figure out which jar to use
* job is submitted via &lt;code&gt;job.waitForCompletion(true)&lt;/code&gt;


=== Data Locality Principle ===
* programs don't pull data from storage 
* instead, programs (jobs and tasks) are sent as close to data as possible 


=== Tasks ===
Each job consists of tasks:
* there are two types of tasks: '''map tasks''' and '''reduce tasks'''
* tasks are scheduled by [[YARN]] and run on different nodes 
* if a task fails, it's rescheduled on a different node

Map tasks:
* the input files are split into fixed-size pieces - ''input splits''
* then Hadoop creates a map task for each input split
* and then the task applies the map function to each record of that split
* map tasks write their results to local disks, not HDFS - their output is intermediate results and can be thrown away, when reducers are done 

Reducer tasks:
* we specify the number of reducers for the job
* reducers cannot use the data locality principle, because input of Reducers is the output from all the mappers
* output of reducer is typically stored on hdfs
* it's possible to have 0 reducers, then such a job is called &quot;Map Only&quot; and writes the output directly to HDFS 


Users can set mappers, reducers and combiners

 job.setMapperClass(MyMapper.class);
 job.setCombinerClass(MyCombiner.class);
 job.setReducerClass(MyReducer.class);

Map only tasks

 job.setMapperClass(MyMapper.class);
 job.setNumReduceTasks(0);



== MapReduce Job Execution ==
General flow:
* input files are split into input splits
* '''map phase''': master picks some idle workers and assigns them a map task
* mappers write their results to their disks
* '''reduce phase''': once they finish, reducers take the results and process

https://raw.github.com/alexeygrigorev/ulb-adb-project-couchbd/master/report/images/map-reduce2.png


'''map phase'''
* each input split is assigned to a map worker
* it applies the [[MapReduce#Map Function|map function]] to each record
* results are written to $R$ partitions, where $R$ is the number of reducers
* wait until '''all''' map tasks are completed


'''shuffle phase''' (sorting)
* the master assigns reduce task to workers
* the intermediate results are shuffled and assigned to reducers
* if there's a combiner function, it is applied to each partition
* each reduces pulls its partition from mappers' disks
* each record is assigned to only one reduces


https://habrastorage.org/files/29b/802/f87/29b802f87a734694b9e5fcf16fd016e9.png {{void|map-to-reduce.png}} 

'''reduce phase'''
* Reducers ask the Application Master where the mappers are located
* and then they start pulling files from mappers as soon as mappers complete
* now apply the [[MapReduce#Reduce Function|reduce function]] to each group
* output is typically stored on [[HDFS]]


Hadoop in one picture: 

https://raw.github.com/alexeygrigorev/ulb-adb-project-couchbd/master/report/images/hadoop.png

(Figure source: Huy Vo, NYU Poly and [http://escience.washington.edu/get-help-now/what-hadoop])


=== Shuffling Details ===
* Hadoop is often referred as &quot;Big [[External Merge Sort|Distributed Merge Sort]]&quot;
* Hadoop guarantees that the that the input to reducers is sorted by key 
* ''Shuffle'' is the process of sorting and transferring map output to the reducers
* The output of mappers is not just written to disk, Hadoop does some pre-sorting 

https://habrastorage.org/files/9f3/a16/024/9f3a16024acb42d98c8aeb320b370d1e.png {{void|shuffling.png}}


For tuning MapReduce jobs, it may be useful to know how the shuffling is performed
* Each mapper has ~100 mb buffer (buffer size is configured in &lt;code&gt;mapreduce.task.io.sort.mb&lt;/code&gt;)
* when it's 80% full (set in &lt;code&gt;mapreduce.map.sort.spill.percent&lt;/code&gt;), a background thread starts to ''spill'' the content on disk (while the buffers are still being populated)
* it's written to disk in the [[Round Robin]] fashion to &lt;code&gt;mapreduce.cluster.local.dir&lt;/code&gt; directory into a job-specific subdirectory 
* before writing to disk, the output is subdivided into partitions, and within each partition records are sorted by key
* if there's a combiner function, it's applied 
* then all spills are merged 
* if there are multiple spills (at least 3, specified in &lt;code&gt;mapreduce.map.combine.minspills&lt;/code&gt;), then combiner is run again
* by default the output of mapper is not compressed, but you can turn it on with &lt;code&gt;mapreduce.map.output.compress=true&lt;/code&gt; and the compression library is set with &lt;code&gt;mapreduce.map.output.compress.codec&lt;/code&gt;
* then each reducer can download its partition


Sorting at the Reducer side
* as soon as mappers complete, reducers start pulling the data from their local disks
* each reducer gets its own partitions and merge-sort them 
* also, reducer is fed data at the last merge phase to save one iteration of merge sort


=== Runtime Scheduling Scheme ===
* see [[YARN]] for details how it's scheduled
* For job execution MapReduce component doesn't build any execution plan beforehand
* Result: no communication costs
* MR tasks are done without communication between tasks

=== Failures and Fault-Tolerance ===
There are different types of failures:
* Task Failure (e.g. task JVM crushed). 
** It a task attempt fails, it's rescheduled on a different node
** If the attempt fails 4 times (configured in &lt;code&gt;mapreduce.map|reduce.maxattempts&lt;/code&gt;), it's not rescheduled
* Application Master failure 
* Cluster Failure (not recoverable)


Fault tolerance is achieved naturally in this execution scheme
* detect failures and re-assigns tasks of failed nodes to others in the cluster
* also leads to (some) load balancing 


== Execution ==
=== The Tool Interface ===
&lt;code&gt;Tool&lt;/code&gt; is a helper class for executing Hadoop MR jobs 
* so you can implement the &lt;code&gt;Tool&lt;/code&gt; interface and run it with the &lt;code&gt;ToolRunner&lt;/code&gt; 
* it knows where to look for config files and already parses some parameter
* e.g. if you pass &lt;code&gt;-conf&lt;/code&gt; parameter, it knows that it needs to load &lt;code&gt;Configuration&lt;/code&gt; from there
* Usually you have something like YouJob extends Configured implements Tool {


=== Unit Testing ===
[[MapReduce/MRUnit]]
* MRUnit is a library for testing MapReduce jobs
* uses a mock job runner, collect the output and compares it with the expected output



=== Running Locally ===
* You can also run your files locally for testing, before submitting the job to a real cluster
* the default mode is local, and MR jobs are run with &lt;code&gt;LocalJobRunner&lt;/code&gt;
* it runs on a single JVM and can be run from IDE 
* The local mode is the default one: &lt;code&gt;mapreduce.framework.name=local&lt;/code&gt; by default 
* You can also have a local YARN cluster - see &lt;code&gt;MiniYARNCluster&lt;/code&gt;


=== Running on Cluster ===
Jobs must be packaged to jar files 
* easiest way: &lt;code&gt;mvn clean package &lt;/code&gt;
* or &lt;code&gt;mvn clean package -DskipTests&lt;/code&gt;

''client'' - the driver class that submits the job, usually it implements the &lt;code&gt;Tool&lt;/code&gt; interface

Client classpath:
* job jar
* jar files in the &lt;code&gt;lib/&lt;/code&gt; directory inside the jar
* classpath defined by &lt;code&gt;HADOOP_CLASSPATH&lt;/code&gt;

Task classpath
* it runs on a separate JVM, not on the same as the client!
* not controlled by &lt;code&gt;HADOOP_CLASSPATH&lt;/code&gt; - it's only for the client
* the job jar and its &lt;code&gt;lib/&lt;/code&gt; directory
* files in the distributed cache (submitted via &lt;code&gt;-libjars&lt;/code&gt;)

Task classpath precedence 
* for client: &lt;code&gt;HADOOP_USER_CLASSPATH_FIRST=true&lt;/code&gt;
* for configuration: &lt;code&gt;mapreduce.job.user.classpath.first=true&lt;/code&gt;

Results: 
* &lt;code&gt;part-r-0001&lt;/code&gt; (or &lt;code&gt;part-m-0001&lt;/code&gt; if job is map only)
* you can merge the result 
* just merge - see snippets 
* order - see [[MapReduce Patters]]


=== Problem Decomposition ===
* Problems rarely can be expressed with a single MapReduce job
* usually need a few of them 

Hadoop solution: &lt;code&gt;JobControl&lt;/code&gt; class
* linear chain of jobs:

 JobClient.runJob(conf1);
 JobClient.runJob(conf2);

* the job control creates a graph of jobs to be run on the cluster 
* the jobs are submitted to the cluster specified in configuration 
* but the &lt;code&gt;JobClient&lt;/code&gt; class is run on the client machine 


Other tools for running worflows
* [[Oozie|Apache Oozie]] - for running workflows 
* [[Luigi]]



== Hadoop MapReduce Features ==
=== Compression ===
Output of reducers (and mappers) can be compressed 

For example, to use [[GZip]] compression, use

 TextOutputFormat.setCompressOutput(job, true);
 TextOutputFormat.setOutputCompressorClass(job, GzipCodec.class);

Hadoop can recognize gzipped files automatically when reading


=== Writables ===
Objects in Hadoop should implement the &lt;code&gt;Writable&lt;/code&gt; interface
* by implementing it, you're telling Hadoop how the files should be de-serialized
* the Java default serialization mechanism is not effective to be used in Hadoop

&lt;code&gt;Writable&lt;/code&gt; interface has two methods:
* &lt;code&gt;void write(DataOutput out)&lt;/code&gt;
* &lt;code&gt;void readFields(DataInput in)&lt;/code&gt;

Implementation is usually easy:

 @Override
 public void write(DataOutput out) throws IOException {
     Text.writeString(out, language);
     Text.writeString(out, token);
     out.writeLong(hash);
 }
 
 @Override
 public void readFields(DataInput in) throws IOException {
     language = Text.readString(in);
     token = Text.readString(in);
     hash = in.readLong();
 }

&lt;code&gt;WritableComparator&lt;/code&gt; 
* is another interface to be used for keys 
* it's a &lt;code&gt;Writable&lt;/code&gt; and &lt;code&gt;Comparable&lt;/code&gt;
* so there's &lt;code&gt;int compareTo()&lt;/code&gt; method


&lt;code&gt;RawComparator&lt;/code&gt;
* We also can have a raw comparator - to compare directly on bytes without depersonalization 
* it's very good for speed because it avoids serialization/de-serialization
* the method to implement is &lt;code&gt;int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2)&lt;/code&gt;
* &lt;code&gt;WritableComparator&lt;/code&gt; already implements this method



=== Counters ===
Counters is a good way to count things
* for example, to count how many records are processed 
* how mane records are processed with exceptions

Usage:

 try {
     process(record, context);
     context.getCounter(Counters.DOCUMENTS).increment(1);
 } catch (Exception ex) {
     LOGGER.error(&quot;Caught Exception&quot;, ex);
     context.getCounter(Counters.EXCEPTIONS).increment(1);
 }


=== Secondary Sort ===
* Typically the output of mappers is sorted by key only - there's no specific order for values 
* Sometimes we need to make sure that the values are also sorted
* to do it, we create a custom &lt;code&gt;Writable&lt;/code&gt; that is composed of both key and value 
* and use &lt;code&gt;NullWritable&lt;/code&gt; to output the value 
* See [[MapReduce/Secondary Sort]]


=== Distributed Cache ===
Distributed cache is a service for copying files to task nodes 

&lt;code&gt;Tool&lt;/code&gt; interface:
* If you implement the &lt;code&gt;Tool&lt;/code&gt; interface, can specify files with the &lt;code&gt;-files&lt;/code&gt; option
* e.g. &lt;code&gt;-files some/path/to/file.txt&lt;/code&gt;
* and then you can read this file from the working directory just with &lt;code&gt;new File(&quot;file.txt&quot;)&lt;/code&gt;
* use the &lt;code&gt;setup&lt;/code&gt; method in mapper or reducer for this
* these files are first copied to HDFS, and then pulled to local machines before the task is executed

In Java API you'd use this: 

 Job job = Job.getInstance(getConf());
 job.addCacheFile(new URI(path.toUri() + &quot;#symlink-name&quot;));

* you can also specify a symlink name by appending &lt;code&gt;&quot;#symlink-name&quot;&lt;/code&gt;
* then you can read the file with 

 FileUtils.openInputStream(new File(&quot;./symlink-name&quot;));



== MapReduce vs RDBMS ==
[[Relational Databases|RDBMS]] 
* Declarative query language
* Schemas
* [[Indexing (databases)|Indexing]] 
* [[Logical Query Plan Optimization]] 
* [[Caching]]
* [[View Materialization]] 
* [[ACID]] and transactions 

MapReduce
* High Scalability 
* Fault-tolerance


== Advantages ==
[[MapReduce]] is simple and expressive
* computing aggregation is easy
* flexible
** no dependency on [[Data Model]] or schema
** especially good for unstructured data
** cannot do that in [[Database]]s
* can write in any programming language
* fault-tolerance: detect failures and re-assigns tasks of failed nodes to others in the cluster
* high scalability
* even though not in the most efficient way
* cheap: runs on commodity hardware
* open source


== Disadvantages ==
=== No Query Language ===
No high-level declarative language as SQL
* [[MapReduce]] is very low level - need to know programming languages 
* programs are expensive to write and to maintain
* programmers that can do that are expensive
* for [[Data Warehousing]]: [[OLAP]] is not that good in MapReduce

Possible solutions: 
* [[Pig]], [[Hive]], [[Tez]], [[Impala]], [[Spark]], [[Flink]]


=== Performance ===
Performance issues:
* no schema, no index, need to parse each input
** may cause performance degradation
* not tuned for multidimensional queries
* possible solutions: [[HBase]], [[Hive]]
* because of fault-tolerance and scalability - it's not always optimized for I/O cost
** all intermediate results are materialized (no [[Pipelining]])
** triple replication
* low latency
** big overhead for small queries (job start time + jvm start time)


Map and Reduce are Blocking
* a transition from Map phase to Reduce phase cannot be made while Map tasks are still running
** reason for it is that relies on [[External Merge Sort]] for grouping intermediate results
** [[Pipelining]] is not possible
* latency problems from this blocking processing nature
* causes performance degradation - bad for [[OLAP|on-line processing]]


Solutions for I/O optimization
* [[HBase]]
** [[Column-Oriented Databases|Column-Oriented Database]] that has index structures
** data compression (easier for Column-Oriented Databases)
* Hadoop++ [https://infosys.uni-saarland.de/projects/hadoop.php]
** HAIL (Hadoop Aggressive Indexing Library) as an enhancement for HDFS 
** structured file format
** 20x improvement in Hadoop performance
* [[Spark]] and [[Flink]] can do pipelining
* Incremental MapReduce (like in [[CouchDB]] [http://stackoverflow.com/questions/11236676/why-is-mapreduce-in-couchdb-called-incremental] [http://eagain.net/articles/incremental-mapreduce/])


== Sources ==
* Lee et al, Parallel Data Processing with MapReduce: A Survey [http://www.cs.arizona.edu/~bkmoon/papers/sigmodrec11.pdf]
* Ordonez et al, Relational versus non-relational database systems for data warehousing [http://www2.cs.uh.edu/~ordonez/w-2010-DOLAP-relnonrel.pdf]
* Paper by Cloudera and Teradata, Awadallah and Graham, Hadoop and the Data Warehouse: When to Use Which. [http://www.teradata.com/white-papers/Hadoop-and-the-Data-Warehouse-When-to-Use-Which/]
* [[Introduction to Data Science (coursera)]]
* [[Hadoop: The Definitive Guide (book)]]

[[Category:Hadoop]]
[[Category:Distributed Systems]]
[[Category:MapReduce]]
[[Category:Improve Images]]</text>
      <sha1>fown21vuqs9qd0ug8r4kesc318h1tl3</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Improve Images</title>
    <ns>14</ns>
    <id>666</id>
    <revision>
      <id>680</id>
      <timestamp>2015-11-23T11:42:35Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;[[Category:Special]] [[Category:TODO]]&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="38">[[Category:Special]]
[[Category:TODO]]</text>
      <sha1>d649wqpbr0sdfehcj55sco7jkd3ax5m</sha1>
    </revision>
  </page>
  <page>
    <title>YARN</title>
    <ns>0</ns>
    <id>667</id>
    <revision>
      <id>682</id>
      <timestamp>2015-11-23T12:08:37Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== YARN == YARN stands for &quot;Yet another resource negotiator&quot; * it's a [[Hadoop]] cluster resource manager system  * it's not restricted to [[Hadoop MapReduce]] and can run any...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4595">== YARN ==
YARN stands for &quot;Yet another resource negotiator&quot;
* it's a [[Hadoop]] cluster resource manager system 
* it's not restricted to [[Hadoop MapReduce]] and can run any systems, e.g. [[Flink]]
* it's an alternative to Hadoop TaskTracker - which is referred as &quot;Hadoop1&quot;
* YARN is &quot;Hadoop2&quot;


YARN
* so YARN is API for requesting and working with cluster resources 
* it's for frameworks, not for users


=== Components ===
https://habrastorage.org/files/0b8/698/e0c/0b8698e0c74b46c58f8ec81ac1e8ed5d.png {{void|yarn.png}}

It has: 
* Resource Manager: one per cluster
* Node Managers: per each node 

Roles of components:
* node managers launch and monitor containers (which are unix processes)
* a client contacts the RM and asks to run a ''master process''
* if the requirements can be satisfied, YARN finds a node manager that can run it 
* then the application master can request more containers for its processes

a resource request in YARN is a set of constraints that include: 
* memory constrain: how much memory should a container have
* CPU: how much cores
* locality constant: container should be as close to data as possible


== Job Execution ==
How a Job is Executed
* Let us consider how YARN executes a Hadoop MapReduce job
* https://habrastorage.org/files/de8/b3c/41e/de8b3c41e9834c6681569c30ddc72ad4.png {{void|yarn-jobexecution.png}}

There are 5 entities 
* client - submits the job
* YARN Resource Manager - coordinates allocation of resources
* YARN Node Manager - launches and monitors containers on the machines of the cluster 
* MR Application Master - coordinates the tasks that run the MR job 
** MR tasks and the Application Master run the container scheduled by the Resource anager 
** it is managed by the Node Manager
* [[HDFS]] for sharing job files


=== Job Submission ===
The client submits the job
* typically done via &lt;code&gt;job.waitForCompletion(true)&lt;/code&gt;
* the client also pulls the job's execution status and progress each second and reports to the user


Job Submission:
* asks the Resource Manager for a new application id - it will used as the MR Job id
* checks out the specification of the job
* computes the input splits 
* copies the job resources: jars, config, computed input split
* submits the job


=== Job Initialization ===
* when the Resource Manager get a call to its &lt;code&gt;submit&lt;/code&gt;, it passes it to YARN Scheduler
* The Scheduler allocates a container that satisfies the requirements
* the Resource Manager launches the Application Master process there
* For MapReduce, the Application Master is &lt;code&gt;MRAppMaster&lt;/code&gt; class - it creates some bookkeeping classes to monitor the progress
* Then it retrieves the input splits from HDFS
* and creates map tasks for each split and reducer tasks (set with &lt;code&gt;setNumReduceTasks()&lt;/code&gt;)
* each task is assigned an ID


=== Task Assignment ===
* the Application Master request containers for all map and reduce tasks from the Resource Manager
* first, the requests are made for the map tasks
* requests for reducers aren't made until at least 5% of all map tasks are finished


Request constraints that Resource Manager has to satisfy:
* Locality constraint. Optimal case when the task is ''data local'', or at least ''rack local''
* Memory and CPU requirements. By default, each task is allocated 1024 MB and 1 CPU 


These values are configurable on per-job basis:
* &lt;code&gt;mapreduce.map.memory.mb&lt;/code&gt;
* &lt;code&gt;mapreduce.reduce.memry.mb&lt;/code&gt;
* &lt;code&gt;mapreduce.map.cpu.vcores&lt;/code&gt;
* &lt;code&gt;mapreduce.reduce.cpu.vcores&lt;/code&gt;
* they are subject to min/max constraints specified in the YARN config ({{TODO|describe them as well}})


=== Task Execution ===
* a task is assigned to a container on a particular node by the Resource Manager's Scheduler
* the Application Manager starts the container by contacting the node manager 
* the task is executed by a java class &lt;code&gt;YarnChild&lt;/code&gt;
* before running, it get all needed files (e.g. config, job jars, etc) from the distributed cache
* finally, it runs the tasks: first, map tasks, then - reduce tasks
* &lt;code&gt;YarnChild&lt;/code&gt; runs on a separate JVM so it doesn't affect anything else 


=== Job Completion ===
* When the last Job task is complete, the Application Master changes its status to &quot;SUCCESSFUL&quot;
* then &lt;code&gt;job.waitForCompletion(true)&lt;/code&gt; finishes and returns &lt;code&gt;true&lt;/code&gt;
* if there was an error, it returns &lt;code&gt;false&lt;/code&gt;

== Source ==
* [[Hadoop: The Definitive Guide (book)]]

[[Category:Distributed Systems]]
[[Category:Hadoop]]
[[Category:Resource Management]]
[[Category:Improve Images]]</text>
      <sha1>ap4gutexeazi9ohw4qftbcgg64hs6gm</sha1>
    </revision>
  </page>
  <page>
    <title>Web Data Management (book)</title>
    <ns>0</ns>
    <id>668</id>
    <revision>
      <id>685</id>
      <timestamp>2015-11-23T12:30:46Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;https://habrastorage.org/files/dcc/17a/111/dcc17a11149a435292b4984fdd2b69fa.jpg  == Web Data Management (book) == * A book by Serge Abiteboul, Ioana Manolescu, Philippe Rigaux...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="816">https://habrastorage.org/files/dcc/17a/111/dcc17a11149a435292b4984fdd2b69fa.jpg

== Web Data Management (book) ==
* A book by Serge Abiteboul, Ioana Manolescu, Philippe Rigaux, Marie-Christine Rousset, Pierre Senellart; 
* Published by Cambridge University Press 2011.

The book is available online:
* http://webdam.inria.fr/Jorge/?action=chapters


Notes taken from the book:
* [[Conjunctive Query]]
** [[Skolem Function]]
* [[Ontologies]]
** [[Semantic Web Application Architecture]]
** [[Ontology Based Data Access]] 
* [[Data Integration]]
** [[Mediator (Data Integration)]]
** [[GAV Mediation]]
** [[LAV Mediation]]
** [[Bucket Algorithm (Data Integration)]]
** [[Minicon Algorithm]]
** [[Inverse-Rules Algorithm]] 


[[Category:Notes]]
[[Category:Books]]
[[Category:Semantic Web]]
[[Category:Data Integration]]</text>
      <sha1>09kb54lbbpj73322we2nkwvlbo3cpy4</sha1>
    </revision>
  </page>
  <page>
    <title>OBDA</title>
    <ns>0</ns>
    <id>669</id>
    <redirect title="Ontology Based Data Access" />
    <revision>
      <id>693</id>
      <timestamp>2015-11-23T12:46:13Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Redirected page to [[Ontology Based Data Access]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="40">#REDIRECT [[Ontology Based Data Access]]</text>
      <sha1>8cm38o8sns0m27rzr73ur56x2i0cymd</sha1>
    </revision>
  </page>
  <page>
    <title>Data Normalization</title>
    <ns>0</ns>
    <id>670</id>
    <redirect title="Feature Normalization" />
    <revision>
      <id>703</id>
      <timestamp>2015-11-23T13:33:00Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Alexey moved page [[Data Normalization]] to [[Feature Normalization]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="35">#REDIRECT [[Feature Normalization]]</text>
      <sha1>hjvibnq48frsh31oounip1warbupgmd</sha1>
    </revision>
  </page>
  <page>
    <title>Template:MainPage Menu</title>
    <ns>10</ns>
    <id>671</id>
    <revision>
      <id>705</id>
      <timestamp>2015-11-23T14:38:16Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;* [[Courses]] * [[Books]] * [[Sources Index]]&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="45">* [[Courses]]
* [[Books]]
* [[Sources Index]]</text>
      <sha1>lbwprz6lqpe0xbf2cbp1lp7yr7nricf</sha1>
    </revision>
    <revision>
      <id>708</id>
      <parentid>705</parentid>
      <timestamp>2015-11-23T14:41:37Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="67">Here I keep my notes:
* [[Courses]]
* [[Books]]
* [[Sources Index]]</text>
      <sha1>niov42a1es8lq8p2p59qged67sdtgkc</sha1>
    </revision>
    <revision>
      <id>719</id>
      <parentid>708</parentid>
      <timestamp>2015-11-23T16:04:29Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="95">My notes:
* [[Courses]]
* [[Books]]
* [[Sources Index]]

Need attention
* [[:Category:Special]]</text>
      <sha1>1zfgh7vr4jvpjkapzpb2vtk5cnbe6sh</sha1>
    </revision>
  </page>
  <page>
    <title>Template:MainPage Featured</title>
    <ns>10</ns>
    <id>672</id>
    <revision>
      <id>706</id>
      <timestamp>2015-11-23T14:38:38Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;* Featured pages&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16">* Featured pages</text>
      <sha1>saj38fvgaw18fuyj87hiszvz1w39jo4</sha1>
    </revision>
  </page>
  <page>
    <title>T-test</title>
    <ns>0</ns>
    <id>673</id>
    <redirect title="T-tests" />
    <revision>
      <id>711</id>
      <timestamp>2015-11-23T15:37:01Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Redirected page to [[T-tests]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21">#REDIRECT [[T-tests]]</text>
      <sha1>mrvvcrole5ciu0r4sc8izuez8lyiabd</sha1>
    </revision>
  </page>
  <page>
    <title>One-Sample t-test</title>
    <ns>0</ns>
    <id>674</id>
    <revision>
      <id>712</id>
      <timestamp>2015-11-23T15:37:40Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== [[One-Sample t-test|One-Sample $t$-test]] == This is a [[t-test]] for one variable * it can be used to calculate a [[Confidence Intervals|Confidence Interval]] for the true...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2194">== [[One-Sample t-test|One-Sample $t$-test]] ==
This is a [[t-test]] for one variable
* it can be used to calculate a [[Confidence Intervals|Confidence Interval]] for the true mean $\mu$ 
* the null value for $H_0$ might come from other research or from your knowledge 

Parameters:
* $\text{df} = n - 1$, where $n$ is the sample size 



== Examples ==
=== Example 1 ===
* Sample: $n = 60, \bar{X} = 7.177, s = 2.948$
* True mean $\mu$ is unknown 

Let's run a test:
* $H_0: \mu = 0, H_A: \mu &gt; 0$ (this is one-sided test)
* Under $H_0$, we know that $\cfrac{\bar{X} - \mu}{\sqrt{s^2 / n}} \approx t_{n - 1}$
* Observed: $\bar{X} - \mu = 7.177 - 0 = 7.177$
* How plausible is the observed value under $H_0$? 


The probability of observing this value is 
* $P(\bar{X} - \mu \geqslant 7.177) = $
** $P\left(\cfrac{\bar{X} - \mu}{\sqrt{s^2 / n}} \geqslant \cfrac{7.177}{\sqrt{s^2 / n}}\right) \approx$
** $P\left(t_{59} \geqslant \cfrac{7.177}{\sqrt{2.948^2 / 60}}\right) \approx$
** $P(t_{59} \geqslant 18.86) \approx 1 / 10^{26}$

Extremely small! So we reject $H_0$ and conclude that $\mu &gt; 0$



=== Example 2 ===
* Sample $n = 400, \bar{X} = -14.15, s = 14.13$
* Test: $H_0: \mu = 0$  vs $H_A: \mu \neq 0$ (this is a 2-sided)

We know that
* $\cfrac{\bar{X} - \mu}{\sqrt{s^2 / n}} \approx t_{n - 1} = t_{399}$


$p$-value:
* $P( | \bar{X} - \mu | \geqslant | -14.15 - 0 |) = $
** $P\left( \left| \cfrac{\bar{X} - \mu}{\sqrt{s^2 / n}} \right| \geqslant \cfrac{14.15}{\sqrt{14.13^2 / 400}}\right) \approx $
** $P( | t_{399} | \geqslant 20.03 ) =$
** $2 \cdot P( t_{399} \leqslant -20.03) \approx$
** $1 / 3.5 \cdot 10^{64}$


Extremely small! Reject the $H_0$ and conclude that $\mu \neq 0$


=== R code ===
Our test statistic is $T = \cfrac{\bar{X} - \mu}{\sqrt{s^2 / n}}$.

&lt;pre&gt;
xbar = mean(ch)
s2 = var(ch)
n = length(ch)
mu = 0

t = (xbar - mu) / sqrt(s2 / n) // 18.856
pt(t, df=n-1, lower.tail=F) // 5.84E-24
// so we reject
&lt;/pre&gt;


== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[OpenIntro Statistics (book)]]
* http://projectile.sv.cmu.edu/research/public/talks/t-test.htm

[[Category:T-Test]]
[[Category:Statistics]]
[[Category:Statistical Tests]]
[[Category:R]]</text>
      <sha1>noxwn58hdzeik3rw84twpv9t1j9ladr</sha1>
    </revision>
  </page>
  <page>
    <title>Two-Sample t-test</title>
    <ns>0</ns>
    <id>675</id>
    <revision>
      <id>713</id>
      <timestamp>2015-11-23T15:40:52Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Two-Sample t-test == This type of [[t-test|$t$-test]] is used when we want to compare the means of two different samples * suppose that we have two samples $a$ and $b$ of s...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3713">== Two-Sample t-test ==
This type of [[t-test|$t$-test]] is used when we want to compare the means of two different samples
* suppose that we have two samples $a$ and $b$ of sizes $n_a$ and $n_b$ resp.
* we're interested in inferring something about $\mu_a - \mu_b$ 
* [[Point Estimate]] in this case is $\bar{X}_a - \bar{X}_b$
* [[Standard Error]] is $\text{SE}_{\bar{X}_a - \bar{X}_b} = \sqrt{\text{SE}_a + \text{SE}_b } = \sqrt{ s^2_a / n_a + s^2_b / n_b}$
** because $\text{SE}^2_{\bar{X}_a - \bar{X}_b} = \text{var}[\bar{X}_a - \bar{X}_b] = \text{var}[x_a] + \text{var}[x_b] = \text{SE}^2_a + \text{SE}^2_b$


The test is of the following form
* $H_0: \mu_a = \mu_b$, or $H_0: \mu_a - \mu_b = 0$
* $H_A: \mu_a \neq \mu_b$ or $H_A: \mu_a - \mu_b \neq 0$ (two-sided, can also be $&lt;$ or $&gt;$)


So, test statistics:
* $T = \cfrac{(\bar{X}_1 - \bar{X}_2) - (\mu_1 - \mu_2)}{\sqrt{s_1^2 / n_1 + s_2^2 / n_2}}$
* $T \approx t_{\text{df}}$
* $\text{df}$ depends on a few things, discussed below


=== Welch-Satterthwaite Approximation ===
What is $\text{df}$ there?
* Welch-Satterthwaite Approximation for df is
* $\text{df} = \cfrac{( s_1^2 / n_1 + s_2^2 / n_2 )^2 }{ \frac{(s_1^2 / n_1)^2 }{n_1 - 1} + \frac{(s_2^2 / n_2)^2 }{n_2 - 1} }$

This can be a non-integer value, but that's fine


=== Pooled Variance Estimation ===
* Can we &quot;pool&quot; the samples?
* Yes, but only under assumption that $\sigma_1^2 = \sigma_2^2$ (in other words, we assume that the variances are equal)

We can replace $s_1^2$ and $s_2^2$ by the ''pooled variance'':
* $s^2 = \cfrac{(n_1 - 1) s_1^2 + (n_2 - 1) s_2^2 }{ (n_1 - 1) + (n_2 - 1)}$
* and $\text{df} = (n_1 - 1) + (n_2 - 1) = n_1 + n_2 - 2$


== Example ==
=== Example 1 ===
* males: $n_1 = 281 $
* females: $n_2 = 199$
* $\bar{X}_1 = -12.9, s_1^2 = 181.5$
* $\bar{X}_2 = -17.1, s_2^2 = 231.5$
* $\bar{X}_1 - \bar{X}_2 = -12.9 + 17.1 = 4.2$

We then calculate
* $\text{df} = 200.09$
* so $T_{0.025, 200.09} = 1.97$


We have the following test
* $H_0: \mu_1 = \mu_2, H_A: \mu_1 \neq \mu_2$
* and $\bar{X}_1 - \bar{X}_2 = 4.2$


$p$-value:
* $P(| \bar{X}_1 - \bar{X}_2 |  \geqslant  4.2 ) = $
* $P \left( \left| \cfrac{(\bar{X}_1 - \bar{X}_2) - (\mu_1 - \mu_2)}{\sqrt{s_1^2 / n_1 + s_2^2 / n_2}} \right|  \geqslant  \cfrac{4.2}{\sqrt{s_1^2 / n_1 + s_2^2 / n_2}} \right) \approx $
* $P\left( |t_\text{df} |  \geqslant \cfrac{4.2}{\sqrt{181.5 / 281 + 231 / 119}} \right) = 0.0097$

pretty small, so we reject the $H_0$.


=== Example 2 ===
Life expectancy in E.Asia and Pacific vs S.Asia
* EA&amp;P: $n_1: 30, \bar{X}_1 = 73.1, s_1^2 = 38.7$
* SA: $n_2: 8, \bar{X} = 67.0, s_2^2 = 72.5$
* $\bar{X}_1 - \bar{X}_2 = 73.1 - 67.0 = 6.1$


We then calculate
* $\text{df} = 9.09$ by Welch-Satterthwaite Approximation
* $T_{0.025, 0.09} = 2.26$


Our test:
* $H_0: \mu_0 = \mu_1, H_A: \mu_0 \neq \mu_1$

$p$-value:
* $P(| \bar{X}_1 - \bar{X}_2 |  \geqslant  6.1 ) = $
* $P \left( \left| \cfrac{(\bar{X}_1 - \bar{X}_2) - (\mu_1 - \mu_2)}{\sqrt{s_1^2 / n_1 + s_2^2 / n_2}} \right|  \geqslant  \cfrac{6.1}{\sqrt{s_1^2 / n_1 + s_2^2 / n_2}} \right) \approx $
* $P ( |t_\text{df} |  \geqslant 1.90 ) \approx 0.09$

Not so small - we can't reject the $H_0$, it might be true that $\mu_0 = \mu_1$

== R code ==
=== R (Means) ===
&lt;pre&gt;
male = skeletons[sex == '1', 6]
female = skeletons[sex == '2', 6]

# critical value
qt(0.025, df=200.9, lower.tail=F)
&lt;/pre&gt;

or 

&lt;pre&gt;
t.test(male, female, mu=0, conf.level=0.95, alternative='two.sided')
&lt;/pre&gt;


== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[OpenIntro Statistics (book)]]
* http://projectile.sv.cmu.edu/research/public/talks/t-test.htm

[[Category:T-Test]]
[[Category:Statistics]]
[[Category:Statistical Tests]]
[[Category:R]]</text>
      <sha1>pkgluv0wcm73l8psaz0fqolzyivafxb</sha1>
    </revision>
  </page>
  <page>
    <title>Paired t-test</title>
    <ns>0</ns>
    <id>676</id>
    <revision>
      <id>714</id>
      <timestamp>2015-11-23T15:45:00Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Paired t-test == This variation of [[t-test]] is used for Paired Data  === Paired Data === Two set of observations are ''paired'' if each observation in one set has exactly...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2317">== Paired t-test ==
This variation of [[t-test]] is used for Paired Data

=== Paired Data ===
Two set of observations are ''paired'' if each observation in one set has exactly one corresponding observation is another set. 


Examples:
* pre- and post-test scores on the same person
* measures in pairs at the same time or place 
* outcome with or without a treatment - on same subject (cross-over study)


=== Using in [[R]] ===
&lt;pre&gt;
library(openintro)
data(textbooks)
t.test(textbooks$diff, mu=x.bar.nul, alternative='two.sided')
&lt;/pre&gt;

or 

&lt;pre&gt;
t.test(textbooks$uclaNew, textbooks$amazNew, paired=T, alternative='two.sided')
&lt;/pre&gt;


== Examples ==
=== Example: Bookstore vs Amazon ===
* two samples: local bookshop and amazon 
* $\mu_\text{dif} = \mu_l - \mu_a$ - the mean of difference in the price

Test
* $H_0: \mu_\text{dif} = 0$ - there's no difference in the price
* $H_A: \mu_\text{dif} \ne 0$ - there's some difference 

Calculations
* $\bar{X}_\text{dif} = 12.76$
* [[Standard Error]]: $\text{SE}_{\bar{X}_\text{dif}} = \cfrac{s_\text{dif}}{\sqrt{n_\text{dif}}} = 1.67$
* $T = \cfrac{\bar{X}_\text{dif}}{\text{SE}_{\bar{X}_\text{dif}}} = \cfrac{12.76}{1.67} = 7.59$
* $p = 6 \cdot 10^{-11}$, less than $\alpha = 0.05$, so we reject $H_0$


&lt;pre&gt;
library(openintro)
data(textbooks)

hist(textbooks$diff, col='yellow')

n = length(textbooks$diff)
s = sd(textbooks$diff)
se = s / sqrt(n)

x.bar.nul = 0
x.bar.dif = mean(textbooks$diff)

t = (x.bar.dif - x.bar.nul) / se
t
p = pt(t, df=n-1, lower.tail=F) * 2
p
&lt;/pre&gt;

or 

&lt;pre&gt;
t.test(textbooks$diff, mu=x.bar.nul, alternative='two.sided')
&lt;/pre&gt;


=== Example 2 ===
Let $\mu_d = \mu_0 - \mu_1$ be the difference between two methods

Our test:
* $H_0: \mu_d = 0, H_A: \mu_d \neq 0$

Say, we have:
* $\bar{X}_d = 6.854$
* $s_d = 11.056$
* $n = 398$

Test statistics:
* $\cfrac{\bar{X}_d - 0}{s_d / \sqrt{n}} = \cfrac{6.854}{11.056 / \sqrt{398}} \approx 12.37$

Then we compare it with $t_{397}$
* $p$-value is $2.9 \cdot 10^{29}$

And we conclude that the difference between the two methods is not 0


== Sources ==
* [[Statistics: Making Sense of Data (coursera)]]
* [[OpenIntro Statistics (book)]]
* http://projectile.sv.cmu.edu/research/public/talks/t-test.htm

[[Category:T-Test]]
[[Category:Statistics]]
[[Category:Statistical Tests]]
[[Category:R]]</text>
      <sha1>3kbmeuc2a9147a506g4usocyh3lu9fk</sha1>
    </revision>
  </page>
  <page>
    <title>Chi-Squared Test</title>
    <ns>0</ns>
    <id>677</id>
    <redirect title="Chi-Squared Tests" />
    <revision>
      <id>715</id>
      <timestamp>2015-11-23T15:45:47Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Redirected page to [[Chi-Squared Tests]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="31">#REDIRECT [[Chi-Squared Tests]]</text>
      <sha1>h2m3t9lg27zqb1591heauegcgmamrz4</sha1>
    </revision>
  </page>
  <page>
    <title>Calculus: Single Variable (coursera)</title>
    <ns>0</ns>
    <id>678</id>
    <revision>
      <id>721</id>
      <timestamp>2015-12-06T19:40:16Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;Summer 2015  == Calculus: Single Variable (coursera) == === Functions === * [[Function]] ** [[Exponential Function]], [[Polynomial Functions]] ** [[Trigonometric Functions]],...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3582">Summer 2015

== Calculus: Single Variable (coursera) ==
=== Functions ===
* [[Function]]
** [[Exponential Function]], [[Polynomial Functions]]
** [[Trigonometric Functions]], [[Hyperbolic Trigonometric Functions]]
* [[Taylor Series]]
* [[Limits]]
** [[L'Hopital's Rule]]
** [[Orders of Growth]]

=== Differentiation ===
* Derivatives -Definition and interpretations of the derivative
* Differentiation rules -Rules for differentiating combinations of functions
* Linearization - First order Taylor approximations
* Higher derivatives -Definition and interpretation of higher derivatives
* Optimization -Classifying critical points and finding extrema
* Differentials -Implicit differentiation and related rates
* Differentiation as an operator -Using operators to compute other derivatives 

=== Integration ===
* Antidifferentiation -The indefinite integral and separable differential equations
* Exponential growth examples -More examples of exponential growth and decay
* More differential equations -Linear first order differential equations
* ODE Linearization -Solving harder differential equations
* Integration by Substitution -Substitution as an integration technique
* Integration by parts -Using the product rule as an integration technique
* Trigonometric substitution -Integration using trigonometric substitutions
* Partial fractions -Integration of rational functions using algebra
* Definite integrals -Definition and interpretation of the definite integral
* Fundamental Theorem of Integral Calculus -Connecting definite and indefinite integrals
* Improper integrals -Computing definite integrals when FTIC does not apply
* Trigonometric integrals -Products and powers of trigonometric functions
* Tables and computers -Using tables of integrals and mathematics software 

=== Applications ===
* Simple Areas -Finding the area of regions in the plane
* Complex Areas -Areas of more complex regions in the plane
* Volumes -Using the volume element to compute volume
* Volumes of revolution -Volumes from revolving a region about an axis
* Volumes in arbitrary dimension -Fourth dimension and beyond
* Arclength -Finding the length along a curve
* Surface area -Surface area of a solid of revolution
* Work -Computing work with integration
* Elements -Pressure, force, and other applications
* Averages -The average value of a function over an interval
* Centroids and centers of mass -Finding centroid and center of mass with integration
* Moments and gyrations -Moment of inertia and radius of gyration
* Fair probability -Uniform distribution
* Probability densities -Using the density function to compute probabilities
* Expectation and variance -Properties and interpretations of probability distributions 

=== Discretization ===
* Sequences -Discrete-input functions
* Differences -Derivatives of sequences
* Discrete Calculus -How to integrate discrete functions
* Numerical ODEs -Using sequences to solve ODEs
* Numerical integration -Using sequences to solve definite integrals
* Series -Infinite series as improper discrete integrals
* Convergence Tests -Comparison-type tests
* Convergence tests 2 -Geometric series-type tests
* Absolute Convergence and Conditional Convergence -Two types of series convergence
* Power Series -Interval and radius of convergence
* Taylor series redux -Details about Taylor series convergence
* Approximation and error -How to estimate an infinite series


== Links ==
* https://www.coursera.org/course/calcsing
* Course wiki: http://calculus.seas.upenn.edu/


[[Category:Coursera]]
[[Category:Notes]]
[[Category:Calculus]]</text>
      <sha1>qemfldjayvo5cfzyjh1vkcywk219632</sha1>
    </revision>
    <revision>
      <id>724</id>
      <parentid>721</parentid>
      <timestamp>2015-12-06T19:59:35Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <comment>Alexey moved page [[Calculus Single Variable (coursera)]] to [[Calculus: Single Variable (coursera)]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3582">Summer 2015

== Calculus: Single Variable (coursera) ==
=== Functions ===
* [[Function]]
** [[Exponential Function]], [[Polynomial Functions]]
** [[Trigonometric Functions]], [[Hyperbolic Trigonometric Functions]]
* [[Taylor Series]]
* [[Limits]]
** [[L'Hopital's Rule]]
** [[Orders of Growth]]

=== Differentiation ===
* Derivatives -Definition and interpretations of the derivative
* Differentiation rules -Rules for differentiating combinations of functions
* Linearization - First order Taylor approximations
* Higher derivatives -Definition and interpretation of higher derivatives
* Optimization -Classifying critical points and finding extrema
* Differentials -Implicit differentiation and related rates
* Differentiation as an operator -Using operators to compute other derivatives 

=== Integration ===
* Antidifferentiation -The indefinite integral and separable differential equations
* Exponential growth examples -More examples of exponential growth and decay
* More differential equations -Linear first order differential equations
* ODE Linearization -Solving harder differential equations
* Integration by Substitution -Substitution as an integration technique
* Integration by parts -Using the product rule as an integration technique
* Trigonometric substitution -Integration using trigonometric substitutions
* Partial fractions -Integration of rational functions using algebra
* Definite integrals -Definition and interpretation of the definite integral
* Fundamental Theorem of Integral Calculus -Connecting definite and indefinite integrals
* Improper integrals -Computing definite integrals when FTIC does not apply
* Trigonometric integrals -Products and powers of trigonometric functions
* Tables and computers -Using tables of integrals and mathematics software 

=== Applications ===
* Simple Areas -Finding the area of regions in the plane
* Complex Areas -Areas of more complex regions in the plane
* Volumes -Using the volume element to compute volume
* Volumes of revolution -Volumes from revolving a region about an axis
* Volumes in arbitrary dimension -Fourth dimension and beyond
* Arclength -Finding the length along a curve
* Surface area -Surface area of a solid of revolution
* Work -Computing work with integration
* Elements -Pressure, force, and other applications
* Averages -The average value of a function over an interval
* Centroids and centers of mass -Finding centroid and center of mass with integration
* Moments and gyrations -Moment of inertia and radius of gyration
* Fair probability -Uniform distribution
* Probability densities -Using the density function to compute probabilities
* Expectation and variance -Properties and interpretations of probability distributions 

=== Discretization ===
* Sequences -Discrete-input functions
* Differences -Derivatives of sequences
* Discrete Calculus -How to integrate discrete functions
* Numerical ODEs -Using sequences to solve ODEs
* Numerical integration -Using sequences to solve definite integrals
* Series -Infinite series as improper discrete integrals
* Convergence Tests -Comparison-type tests
* Convergence tests 2 -Geometric series-type tests
* Absolute Convergence and Conditional Convergence -Two types of series convergence
* Power Series -Interval and radius of convergence
* Taylor series redux -Details about Taylor series convergence
* Approximation and error -How to estimate an infinite series


== Links ==
* https://www.coursera.org/course/calcsing
* Course wiki: http://calculus.seas.upenn.edu/


[[Category:Coursera]]
[[Category:Notes]]
[[Category:Calculus]]</text>
      <sha1>qemfldjayvo5cfzyjh1vkcywk219632</sha1>
    </revision>
  </page>
  <page>
    <title>Function</title>
    <ns>0</ns>
    <id>679</id>
    <revision>
      <id>723</id>
      <timestamp>2015-12-06T19:58:50Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Function == In mathematics, a function $f(\cdot)$ is a set of pairs $x, f(x)$, where * $x$ is input, $f(x)$ is output  * all possible inputs $x$ that a function can take is...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2030">== Function ==
In mathematics, a function $f(\cdot)$ is a set of pairs $x, f(x)$, where
* $x$ is input, $f(x)$ is output 
* all possible inputs $x$ that a function can take is the ''domain'' of $f$
* all possible outputs $f(x)$ of a function $f(\cdot)$ is the ''range'' of $f$

&lt;img src=&quot;http://alexeygrigorev.com/wiki-figures/crs/calc/function.svg&quot;/&gt;

== Operations on Functions ==
=== Composition ===
For two functions $f$ and $g$, composition is $f \circ g$
* $(f \circ g) (x) = f(g(x))$
* $g$ is applied first, then $f$ 

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/composite.png


For example, 
* $\sqrt{1 - x^2}$
* $g = x^2$, it's inside
* $f(t) = \sqrt{1 - t}$, it's outsize


=== Inverse ===
For $f$ its inverse is $f^{-1}$
* $x = f^{-1}(x)$  if $f(f^{-1}(x)) = x$
* $f^{-1}(\cdot)$ is a function that &quot;undoes&quot; $f(\cdot)$



== Single Variable Functions ==
That's the simplest type of functions: they have one input and one output

=== Important Function Classes ===
* [[Polynomial Functions]]: $P(x) = C_0 + C_1 x + \ ... \ + C_n x^n = \sum_{k=0}^n C_k x^k$, $n$ is degree of $P(\cdot)$
* Rational Functions: $\cfrac{P(x)}{Q(x)}$, s.t. $Q(x) \ne 0$. e.g. $\cfrac{3x - 1}{x^2 - x - 6}$
* [[Trigonometric Functions]]: $\sin x$, $\cos x$, $\tan x$, etc
* [[Exponential Function]] and [[Logarithm]]

=== [[Continuous Functions]] ===
* Functions are [[Continuous Functions|continuous]] is their [[Limits]] always exist
* otherwise functions are discontinuous 
* these are important functions in Calculus


== Multi Variable Functions ==
These functions are more complex:
* they can have multiple inputs and multiple outputs
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/function-multi.png

== [[Function Spaces]] ==
Functions, like [[Vectors]], can form [[Vector Spaces]]
* they are called [[Function Spaces]] for functions


== Sources ==
* [[Calculus: Single Variable (coursera)]]

[[Category:Calculus]]
[[Category:Linear Algebra]]
[[Category:Mathematics]]</text>
      <sha1>5gh4zk6bnjpxo4doo5w89ij6m8al2nc</sha1>
    </revision>
    <revision>
      <id>727</id>
      <parentid>723</parentid>
      <timestamp>2015-12-06T20:03:56Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2053">== Function ==
In mathematics, a function $f(\cdot)$ is a set of pairs $x, f(x)$, where
* $x$ is input, $f(x)$ is output 
* all possible inputs $x$ that a function can take is the ''domain'' of $f$
* all possible outputs $f(x)$ of a function $f(\cdot)$ is the ''range'' of $f$

&lt;img src=&quot;http://alexeygrigorev.com/wiki-figures/crs/calc/function.svg&quot;/&gt;

== Operations on Functions ==
=== Composition ===
For two functions $f$ and $g$, composition is $f \circ g$
* $(f \circ g) (x) = f(g(x))$
* $g$ is applied first, then $f$ 

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/composite.png


For example, 
* $\sqrt{1 - x^2}$
* $g = x^2$, it's inside
* $f(t) = \sqrt{1 - t}$, it's outsize


=== Inverse ===
For $f$ its inverse is $f^{-1}$
* $x = f^{-1}(x)$  if $f(f^{-1}(x)) = x$
* $f^{-1}(\cdot)$ is a function that &quot;undoes&quot; $f(\cdot)$



== Single Variable Functions ==
That's the simplest type of functions: they have one input and one output

=== Important Function Classes ===
* [[Polynomial Functions]]: $P(x) = C_0 + C_1 x + \ ... \ + C_n x^n = \sum_{k=0}^n C_k x^k$, $n$ is degree of $P(\cdot)$
* Rational Functions: $\cfrac{P(x)}{Q(x)}$, s.t. $Q(x) \ne 0$. e.g. $\cfrac{3x - 1}{x^2 - x - 6}$
* [[Trigonometric Functions]]: $\sin x$, $\cos x$, $\tan x$, etc
* [[Exponential Function]] and [[Logarithm]]

=== [[Continuous Functions]] ===
* Functions are [[Continuous Functions|continuous]] is their [[Limits]] always exist
* otherwise functions are discontinuous 
* these are important functions in Calculus


== Multi Variable Functions ==
These functions are more complex:
* they can have multiple inputs and multiple outputs
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/function-multi.png

== [[Function Spaces]] ==
Functions, like [[Vectors]], can form [[Vector Spaces]]
* they are called [[Function Spaces]] for functions


== Sources ==
* [[Calculus: Single Variable (coursera)]]

[[Category:Calculus]]
[[Category:Linear Algebra]]
[[Category:Mathematics]]
[[Category:Functions]]</text>
      <sha1>dd1tm1plixqnvapzewpxmoknlapfvpr</sha1>
    </revision>
  </page>
  <page>
    <title>Calculus Single Variable (coursera)</title>
    <ns>0</ns>
    <id>680</id>
    <redirect title="Calculus: Single Variable (coursera)" />
    <revision>
      <id>725</id>
      <timestamp>2015-12-06T19:59:35Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Alexey moved page [[Calculus Single Variable (coursera)]] to [[Calculus: Single Variable (coursera)]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="50">#REDIRECT [[Calculus: Single Variable (coursera)]]</text>
      <sha1>0icng1rygb5y3wx44ixl1isjuir28h4</sha1>
    </revision>
  </page>
  <page>
    <title>Exponential Function</title>
    <ns>0</ns>
    <id>681</id>
    <revision>
      <id>728</id>
      <timestamp>2015-12-06T20:07:04Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;{{stub}}  == Exponential Functions == * $e^x$, or $\exp x$ is the exponential function * [[Logarithm]] is inverse of exponent * https://raw.githubusercontent.com/alexeygrigore...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="890">{{stub}}

== Exponential Functions ==
* $e^x$, or $\exp x$ is the exponential function
* [[Logarithm]] is inverse of exponent
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/exp-log.png


Base
* &quot;Natural&quot; base is $e = 2.718281828...$, where $e$ is the Euler's Number
* can be any other base: $a^x$


Algebraic Properties 
* $e^x e^y = e^{x + y}$
* $(e^x)^y = e^{xy}$
* $\cfrac{d}{dx} e^x = e^x$
* $\int e^x\, dx = e^x + C$


[[Euler's Formula]]:
* relates Exponential Function and [[Trigonometric Functions]]
* $e^{ix} = \cos x + i \sin x$ where $i = \sqrt {-1}$


== [[Taylor Series|Taylor Expansion]] ==
Can expand $e^x = 1 + x + \cfrac{1}{2!}\, x^2 + \cfrac{1}{3!}\, x^3 + \cfrac{1}{4!}\, x^4 + \ ... \ = \sum\limits_{k=0}^{\infty} \cfrac{1}{k!} x^k$


== Sources ==
* [[Calculus: Single Variable (coursera)]]

[[Category:Functions]]
[[Category:Calculus]]</text>
      <sha1>3jijpu6et56ionrcxog3t0vf55vu2aa</sha1>
    </revision>
  </page>
  <page>
    <title>Polynomial Functions</title>
    <ns>0</ns>
    <id>682</id>
    <revision>
      <id>729</id>
      <timestamp>2015-12-06T20:08:22Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;{{stub}}  == Polynomial Functions == * $\cfrac{d}{dx} x^k = k\, x^{k-1}$ * $\int x^k\, dx = \cfrac{1}{k+1} x^{k+1} + C$, $k \ne -1$  A [[Taylor Series|Taylor Expansion]] of a...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="259">{{stub}}

== Polynomial Functions ==
* $\cfrac{d}{dx} x^k = k\, x^{k-1}$
* $\int x^k\, dx = \cfrac{1}{k+1} x^{k+1} + C$, $k \ne -1$

A [[Taylor Series|Taylor Expansion]] of a polynomial is polynomial 


== Sources ==
* [[Calculus: Single Variable (coursera)]]</text>
      <sha1>sicqe306feis7u1omfaqrsy4m5ttqkc</sha1>
    </revision>
    <revision>
      <id>734</id>
      <parentid>729</parentid>
      <timestamp>2015-12-06T20:22:10Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="283">{{stub}}

== Polynomial Functions ==
* $\cfrac{d}{dx} x^k = k\, x^{k-1}$
* $\int x^k\, dx = \cfrac{1}{k+1} x^{k+1} + C$, $k \ne -1$

A [[Taylor Series|Taylor Expansion]] of a polynomial is polynomial 


== Sources ==
* [[Calculus: Single Variable (coursera)]]

[[Category:Functions]]</text>
      <sha1>odv83k6fvf8chjlykhswwhxmoa4clk3</sha1>
    </revision>
  </page>
  <page>
    <title>Functions</title>
    <ns>0</ns>
    <id>683</id>
    <redirect title="Function" />
    <revision>
      <id>730</id>
      <timestamp>2015-12-06T20:13:54Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Redirected page to [[Function]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22">#REDIRECT [[Function]]</text>
      <sha1>8bscsdc04uec2qsp66ehazaenf8i421</sha1>
    </revision>
  </page>
  <page>
    <title>Trigonometric Functions</title>
    <ns>0</ns>
    <id>684</id>
    <revision>
      <id>731</id>
      <timestamp>2015-12-06T20:18:44Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Trigonometric Functions == The Trigonometric [[Functions]] are functions of angles * they relate angles of a triangle to the length of its sides   https://raw.githubusercon...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6112">== Trigonometric Functions ==
The Trigonometric [[Functions]] are functions of angles
* they relate angles of a triangle to the length of its sides 

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/trig-pythag.png

* $\sin \theta$ = length of edge, opposite to $\theta$
* $\cos \theta$ = length of edge, adjacent to $\theta$
* when the hypotenuse is 1, by [[Pythagoras Theorem]], we get $\cos^2 \alpha + \sin^2 \alpha = 1$

Unit circle:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/trig-circle.png


Other trigonometric functions are derives from sine and cosine:
* tangent: $\tan \alpha = \cfrac{\sin \alpha}{\cos \alpha}$
* cotangent: $\cot \alpha = \cfrac{\cos \alpha}{\sin \alpha}$
* secant: $\sec \alpha = \cfrac{1}{\cos \alpha}$
* co-secant: $\csc \alpha = \cfrac{1}{\sin \alpha}$


https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/trig-finctions.jpg


Inverse Trigonometric functions:
* arcsin: $\arcsin \alpha = \sin^{-1} \alpha$
* arccos: $\arccos \alpha = \cos^{-1} \alpha$
* both have restricted domain $[-1, 1]$ because $\cos$ and $\sin$ can output only $[-1, 1]$


https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Mplwp_arcsin_arccos_arctan_piaxis.svg/320px-Mplwp_arcsin_arccos_arctan_piaxis.svg.png
(Source: [https://commons.wikimedia.org/wiki/File:Mplwp_arcsin_arccos_arctan_piaxis.svg])



== [[Taylor Series|Taylor Expansion]] ==
* $\cos x = \sum\limits_{k=0}^\infty (-1)^k \cfrac{x^{2k}}{(2k)!}$
* $\sin x = \sum\limits_{k=0}^\infty (-1)^k \cfrac{x^{2k + 1}}{(2k + 1)!}$


[[Euler's Formula]]:
* relates Exponential Function and [[Trigonometric Functions]]
* $e^{ix} = \cos x + i \sin x$ where $i = \sqrt {-1}$

With Taylor Expansions, we can pretend that $\sin x$, $\cos x$ and [[Exponential]] are long [[Polynomial Functions]]



== Trigonometric Identities ==
* $\alpha$ radians = $180\, \alpha\, /\, \pi$ degrees
* $\beta$ degrees = $\pi\, \beta\, /\, 180$ radians

=== Fundamental ===
* $\sin (-\alpha) = -\sin \alpha$
* $\cos (-\alpha) =  \cos \alpha$
* $\sin \left(\pi/2 - \alpha\right) = \cos \alpha$
* $\cos \left(\cfrac{\pi}{2} - \alpha \right) = \sin \alpha$
* $\sin^2 \alpha + \cos^2 \alpha = 1$
* $\tan \alpha = \cfrac{\sin \alpha}{\cos \alpha}$
* $\cot \alpha = \cfrac{\cos \alpha}{\sin \alpha} = \cfrac{1}{\tan \alpha}$

=== Double angles ===
* $\sin 2\alpha = 2\, \sin \alpha \, \cos \alpha $
* $\cos 2\alpha = 2\, \cos^2 \alpha  - 1 = 1 - 2\, \sin^2 \alpha  = \cos^2 \alpha  - sin^2 \alpha $
* $\tan 2\alpha = \cfrac{2\, \tan \alpha}{1 - \tan^2 \alpha}$

=== Sums ===
* $\sin \alpha + \sin \beta = 2\, \sin\cfrac{\alpha +\beta}{2}\, \cos\cfrac{\alpha - \beta}{2}$
* $\sin \alpha - \sin \beta = 2\, \cos\cfrac{\alpha +\beta}{2}\, \sin\cfrac{\alpha - \beta}{2}$
* $\cos \alpha + \cos \beta = 2\, \cos\cfrac{\alpha +\beta}{2}\, \cos\cfrac{\alpha - \beta}{2}$
* $\cos \alpha - \cos \beta = 2\, \sin\cfrac{\alpha +\beta}{2}\, \sin\cfrac{\beta - \alpha}{2}$

=== Products ===
* $2\, \sin \alpha\, \sin \beta = \cos (\alpha - \beta) - \cos (\alpha + \beta)$
* $2\, \cos \alpha\, \cos \beta = \cos (\alpha - \beta) + \cos (\alpha + \beta)$
* $2\, \sin \alpha\, \cos \beta = \sin (\alpha + \beta) + \sin (\alpha - \beta)$

=== Sums Inside Trigs ===
* $\sin (\alpha \pm \beta) = \sin \alpha\, \cos \beta \pm \sin \beta\, \cos \alpha$
* $\cos (\alpha \pm \beta) = \cos \alpha\, \cos \beta \mp \sin \alpha\, \sin \beta$
* $\tan (\alpha \pm \beta) = \cfrac{\tan \alpha \pm \tan\beta}{1 \mp \tan \alpha\, \tan \beta}$

=== Secs and Cosecs ===
* $\sec \alpha = \cfrac{1}{\cos \alpha}$
* $\csc \alpha = \cfrac{1}{\sin \alpha}$
* $1 + \tan^2 \alpha = \sec^2 \alpha$
* $\tan \left(\cfrac{\pi}{2} - \alpha \right) = \cot \alpha$

=== Inverse Trigs ===
* $\sin (\arcsin \alpha) = \alpha$
* $\cos (\arccos \alpha) = \alpha$
* $\tan (\arctan \alpha) = \alpha$
* $\arcsin (\sin \alpha) = \alpha$
* $\arccos (\cos \alpha) = \alpha$
* $\arctan (\tan \alpha) = \alpha$

=== Tangents ===
* $\tan^2 \alpha  = \cfrac{1 - \cos \alpha}{1 + \cos \alpha}$
* $\tan \cfrac{2}{\alpha} = \cfrac{2\, \tan \alpha}{1 - \tan^2 \alpha}$
* $\tan \cfrac{\alpha}{2} = \cfrac{\sin \alpha}{1 + \cos \alpha} = \cfrac{1 - \cos \alpha}{\sin \alpha}$
* $\tan \cfrac{\alpha + \beta}{2} = \cfrac{\sin \alpha + \sin \beta}{\cos \alpha + \cos \beta}$
* $\tan \left(\cfrac{\alpha}{2} + \cfrac{\pi}{4}\right) = \tan \alpha + \sec \alpha = \cfrac{1 + \sin \alpha}{\cos \alpha}$
* $\tan 3\alpha = \cfrac{3\, \tan \alpha - \tan^3 \alpha}{1 - 3\, \tan^3 \alpha}$



== Derivatives and Integrals ==
=== [[Derivatives]] ===
https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/trigs-derivs.png

* $\sin' x =  \cos x$
* $\cos' x = -\sin x$
* $\tan' x =  \sec^2 x$
* $\big(\sin^2 x \big)' =  2\, \sin x\, \cos x =  \sin 2x$
* $\big(\cos^2 x \big)' = -2\, \cos x\, \sin x = -\sin 2x$
* $\big(\tan^2 x \big)' = 2\, \tan x + 2\, \tan^3 x$
* $\csc' x = -\cot x\, \csc x$
* $\sec' x =  \tan x\, \sec x$
* $\cot' x = -\csc^2 x$


=== [[Integrals]] ===
Basic Integrals:
* $\int \sin x\, dx = -\cos x + C$
* $\int \cos x\, dx = \sin x + C$
* $\int \tan x\, dx = -\ln | \cos x | + C$
* $\int \sec x\, dx = \ln | \tan x + \sec x | + C$
* $\int \csc x\, dx = -\ln | \cot x + \csc x | + C$
* $\int \cot x\, dx = \ln | \sin x | + C$
* $\int \sin^2 x\, dx = \cfrac{x}{2} - \cfrac{\sin 2x}{4} + C$
* $\int \cos^2 x\, dx = \cfrac{x}{2} + \cfrac{\sin 2x}{4} + C$
* $\int \sin x\, \cos x\, dx = -\cfrac{1}{2}\, \cos^2 x + C$


Harder Integrals:
* $\int x\, \sin x\, dx = \sin x - x\, \cos x + C$
* $\int x\, \cos x\, dx = \cos x + x\, \sin x + C$
* $\int \cfrac{1}{1 + \sin x}\, dx = \tan \left( \cfrac{x}{2} - \cfrac{\pi}{4} \right) + C$
* $\int \cfrac{1}{1 + \cos x} dx = \tan \left( \cfrac{x}{2} \right) + C$


== Sources ==
* [[Calculus: Single Variable (coursera)]]
* http://calculus-geometry.hubpages.com/hub/Trig-Identities-Derivatives-Antiderivatives-sin-cos-tan-Formulas
* https://en.wikipedia.org/wiki/Trigonometric_functions

[[Category:Calculus]]
[[Category:Derivatives]]
[[Category:Integrals]]
[[Category:Cheat Sheets]]</text>
      <sha1>7u88drad93su8t59dceurne04xsyw3f</sha1>
    </revision>
    <revision>
      <id>733</id>
      <parentid>731</parentid>
      <timestamp>2015-12-06T20:21:50Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>/* Sources */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6135">== Trigonometric Functions ==
The Trigonometric [[Functions]] are functions of angles
* they relate angles of a triangle to the length of its sides 

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/trig-pythag.png

* $\sin \theta$ = length of edge, opposite to $\theta$
* $\cos \theta$ = length of edge, adjacent to $\theta$
* when the hypotenuse is 1, by [[Pythagoras Theorem]], we get $\cos^2 \alpha + \sin^2 \alpha = 1$

Unit circle:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/trig-circle.png


Other trigonometric functions are derives from sine and cosine:
* tangent: $\tan \alpha = \cfrac{\sin \alpha}{\cos \alpha}$
* cotangent: $\cot \alpha = \cfrac{\cos \alpha}{\sin \alpha}$
* secant: $\sec \alpha = \cfrac{1}{\cos \alpha}$
* co-secant: $\csc \alpha = \cfrac{1}{\sin \alpha}$


https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/trig-finctions.jpg


Inverse Trigonometric functions:
* arcsin: $\arcsin \alpha = \sin^{-1} \alpha$
* arccos: $\arccos \alpha = \cos^{-1} \alpha$
* both have restricted domain $[-1, 1]$ because $\cos$ and $\sin$ can output only $[-1, 1]$


https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Mplwp_arcsin_arccos_arctan_piaxis.svg/320px-Mplwp_arcsin_arccos_arctan_piaxis.svg.png
(Source: [https://commons.wikimedia.org/wiki/File:Mplwp_arcsin_arccos_arctan_piaxis.svg])



== [[Taylor Series|Taylor Expansion]] ==
* $\cos x = \sum\limits_{k=0}^\infty (-1)^k \cfrac{x^{2k}}{(2k)!}$
* $\sin x = \sum\limits_{k=0}^\infty (-1)^k \cfrac{x^{2k + 1}}{(2k + 1)!}$


[[Euler's Formula]]:
* relates Exponential Function and [[Trigonometric Functions]]
* $e^{ix} = \cos x + i \sin x$ where $i = \sqrt {-1}$

With Taylor Expansions, we can pretend that $\sin x$, $\cos x$ and [[Exponential]] are long [[Polynomial Functions]]



== Trigonometric Identities ==
* $\alpha$ radians = $180\, \alpha\, /\, \pi$ degrees
* $\beta$ degrees = $\pi\, \beta\, /\, 180$ radians

=== Fundamental ===
* $\sin (-\alpha) = -\sin \alpha$
* $\cos (-\alpha) =  \cos \alpha$
* $\sin \left(\pi/2 - \alpha\right) = \cos \alpha$
* $\cos \left(\cfrac{\pi}{2} - \alpha \right) = \sin \alpha$
* $\sin^2 \alpha + \cos^2 \alpha = 1$
* $\tan \alpha = \cfrac{\sin \alpha}{\cos \alpha}$
* $\cot \alpha = \cfrac{\cos \alpha}{\sin \alpha} = \cfrac{1}{\tan \alpha}$

=== Double angles ===
* $\sin 2\alpha = 2\, \sin \alpha \, \cos \alpha $
* $\cos 2\alpha = 2\, \cos^2 \alpha  - 1 = 1 - 2\, \sin^2 \alpha  = \cos^2 \alpha  - sin^2 \alpha $
* $\tan 2\alpha = \cfrac{2\, \tan \alpha}{1 - \tan^2 \alpha}$

=== Sums ===
* $\sin \alpha + \sin \beta = 2\, \sin\cfrac{\alpha +\beta}{2}\, \cos\cfrac{\alpha - \beta}{2}$
* $\sin \alpha - \sin \beta = 2\, \cos\cfrac{\alpha +\beta}{2}\, \sin\cfrac{\alpha - \beta}{2}$
* $\cos \alpha + \cos \beta = 2\, \cos\cfrac{\alpha +\beta}{2}\, \cos\cfrac{\alpha - \beta}{2}$
* $\cos \alpha - \cos \beta = 2\, \sin\cfrac{\alpha +\beta}{2}\, \sin\cfrac{\beta - \alpha}{2}$

=== Products ===
* $2\, \sin \alpha\, \sin \beta = \cos (\alpha - \beta) - \cos (\alpha + \beta)$
* $2\, \cos \alpha\, \cos \beta = \cos (\alpha - \beta) + \cos (\alpha + \beta)$
* $2\, \sin \alpha\, \cos \beta = \sin (\alpha + \beta) + \sin (\alpha - \beta)$

=== Sums Inside Trigs ===
* $\sin (\alpha \pm \beta) = \sin \alpha\, \cos \beta \pm \sin \beta\, \cos \alpha$
* $\cos (\alpha \pm \beta) = \cos \alpha\, \cos \beta \mp \sin \alpha\, \sin \beta$
* $\tan (\alpha \pm \beta) = \cfrac{\tan \alpha \pm \tan\beta}{1 \mp \tan \alpha\, \tan \beta}$

=== Secs and Cosecs ===
* $\sec \alpha = \cfrac{1}{\cos \alpha}$
* $\csc \alpha = \cfrac{1}{\sin \alpha}$
* $1 + \tan^2 \alpha = \sec^2 \alpha$
* $\tan \left(\cfrac{\pi}{2} - \alpha \right) = \cot \alpha$

=== Inverse Trigs ===
* $\sin (\arcsin \alpha) = \alpha$
* $\cos (\arccos \alpha) = \alpha$
* $\tan (\arctan \alpha) = \alpha$
* $\arcsin (\sin \alpha) = \alpha$
* $\arccos (\cos \alpha) = \alpha$
* $\arctan (\tan \alpha) = \alpha$

=== Tangents ===
* $\tan^2 \alpha  = \cfrac{1 - \cos \alpha}{1 + \cos \alpha}$
* $\tan \cfrac{2}{\alpha} = \cfrac{2\, \tan \alpha}{1 - \tan^2 \alpha}$
* $\tan \cfrac{\alpha}{2} = \cfrac{\sin \alpha}{1 + \cos \alpha} = \cfrac{1 - \cos \alpha}{\sin \alpha}$
* $\tan \cfrac{\alpha + \beta}{2} = \cfrac{\sin \alpha + \sin \beta}{\cos \alpha + \cos \beta}$
* $\tan \left(\cfrac{\alpha}{2} + \cfrac{\pi}{4}\right) = \tan \alpha + \sec \alpha = \cfrac{1 + \sin \alpha}{\cos \alpha}$
* $\tan 3\alpha = \cfrac{3\, \tan \alpha - \tan^3 \alpha}{1 - 3\, \tan^3 \alpha}$



== Derivatives and Integrals ==
=== [[Derivatives]] ===
https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/trigs-derivs.png

* $\sin' x =  \cos x$
* $\cos' x = -\sin x$
* $\tan' x =  \sec^2 x$
* $\big(\sin^2 x \big)' =  2\, \sin x\, \cos x =  \sin 2x$
* $\big(\cos^2 x \big)' = -2\, \cos x\, \sin x = -\sin 2x$
* $\big(\tan^2 x \big)' = 2\, \tan x + 2\, \tan^3 x$
* $\csc' x = -\cot x\, \csc x$
* $\sec' x =  \tan x\, \sec x$
* $\cot' x = -\csc^2 x$


=== [[Integrals]] ===
Basic Integrals:
* $\int \sin x\, dx = -\cos x + C$
* $\int \cos x\, dx = \sin x + C$
* $\int \tan x\, dx = -\ln | \cos x | + C$
* $\int \sec x\, dx = \ln | \tan x + \sec x | + C$
* $\int \csc x\, dx = -\ln | \cot x + \csc x | + C$
* $\int \cot x\, dx = \ln | \sin x | + C$
* $\int \sin^2 x\, dx = \cfrac{x}{2} - \cfrac{\sin 2x}{4} + C$
* $\int \cos^2 x\, dx = \cfrac{x}{2} + \cfrac{\sin 2x}{4} + C$
* $\int \sin x\, \cos x\, dx = -\cfrac{1}{2}\, \cos^2 x + C$


Harder Integrals:
* $\int x\, \sin x\, dx = \sin x - x\, \cos x + C$
* $\int x\, \cos x\, dx = \cos x + x\, \sin x + C$
* $\int \cfrac{1}{1 + \sin x}\, dx = \tan \left( \cfrac{x}{2} - \cfrac{\pi}{4} \right) + C$
* $\int \cfrac{1}{1 + \cos x} dx = \tan \left( \cfrac{x}{2} \right) + C$


== Sources ==
* [[Calculus: Single Variable (coursera)]]
* http://calculus-geometry.hubpages.com/hub/Trig-Identities-Derivatives-Antiderivatives-sin-cos-tan-Formulas
* https://en.wikipedia.org/wiki/Trigonometric_functions

[[Category:Functions]]
[[Category:Calculus]]
[[Category:Derivatives]]
[[Category:Integrals]]
[[Category:Cheat Sheets]]</text>
      <sha1>pd78120g5d5981jtr3cwr5ql3525eln</sha1>
    </revision>
  </page>
  <page>
    <title>Hyperbolic Trigonometric Functions</title>
    <ns>0</ns>
    <id>685</id>
    <revision>
      <id>732</id>
      <timestamp>2015-12-06T20:21:14Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;{{stub}}  == Hyperbolic Trigonometric Functions ==  Hyperbolic trigs are analogs of usual [[Trigonometric Functions]]  * $\cosh x = \cfrac{e^x + e^{-x}}{2}$ * $\sinh x = \cfra...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1818">{{stub}}

== Hyperbolic Trigonometric Functions == 
Hyperbolic trigs are analogs of usual [[Trigonometric Functions]] 
* $\cosh x = \cfrac{e^x + e^{-x}}{2}$
* $\sinh x = \cfrac{e^x - e^{-x}}{2}$
* $\tanh x = \cfrac{\sinh x}{\cosh x} = \cfrac{e^x - e^{-x}}{e^x + e^{-x}}$

http://calculus.seas.upenn.edu/uploads/Main/Hyperbolic.png (source: [http://calculus.seas.upenn.edu/?n=Main.ComputingTaylorSeries])

* $\cosh^2 x - \sinh^2 x = 1$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/hyptrigs-vs-trigs.png


Taylor Expansion:
* $\cosh x = \cfrac{e^x + e^{-x}}{2} = \cfrac{1}{2}\, e^x + \cfrac{1}{2}\, e^{-x} = \ ...$
** $... \ = \cfrac{1}{2}\, \left(1 + x + \cfrac{1}{2!}\, x^2 + \cfrac{1}{3!}\, x^3 + \ ... \ \right) + \cfrac{1}{2}\, \left(1 - x + \cfrac{1}{2!}\, x^2 - \cfrac{1}{3!}\, x^3 + \ ... \ \right) = \ ...$
** odd degree terms cancel out
** $... \ = 1 + \cfrac{1}{2!}\, x^2 + + \cfrac{1}{4!}\, x^4 + \ ... \  = \sum\limits_{k=0}^\infty \cfrac{x^2}{(2k)!}$
** co we have even powers, like for $\cos x$, just without $(-1)^k$ term
* same for $\sinh x = \cfrac{1}{2}\, e^x - \cfrac{1}{2}\, e^{-x} = \sum\limits_{k=0}^\infty \cfrac{x^{2k + 1}}{(2k+1)!}$
** if we Taylor expand $e^x$, even powers cancel out, and we're left only with odd powers
** just like usual $\sin x$, but without alternating sing 


== Derivatives ==
* $\cfrac{d}{dx}\, \sinh x = \cosh x$
* $\cfrac{d}{dx}\, \cosh x = \sinh x$

Can show that with Taylor expansions:
* $\cfrac{d}{dx}\, \sinh x = \cfrac{d}{dx} \sum\limits_{k=0}^\infty \cfrac{x^{2k + 1}}{(2k+1)!} = \sum\limits_{k=0}^\infty (2k+1)\, \cfrac{x^{2k}}{(2k+1)!} = \sum\limits_{k=0}^\infty \cfrac{x^{2k}}{(2k)!} = \cosh x$
* same with $\cosh x$


== Sources ==
* [[Calculus: Single Variable (coursera)]]

[[Category:Calculus]]
[[Category:Functions]]</text>
      <sha1>5bkopze7ugfofdbkaa4y2kkubj2hcrj</sha1>
    </revision>
  </page>
  <page>
    <title>Continuous Functions</title>
    <ns>0</ns>
    <id>686</id>
    <revision>
      <id>735</id>
      <timestamp>2015-12-06T20:23:55Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;{{stub}}  == Continuous Functions == A [[Function]] $f(x)$ is continuous if the [[Limit]] of this function always exists otherwise the function is discontinuous   * $f(x)$ is...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="945">{{stub}}

== Continuous Functions ==
A [[Function]] $f(x)$ is continuous if the [[Limit]] of this function always exists
otherwise the function is discontinuous


* $f(x)$ is continuous at $x = a$ if $\lim\limits_{x \to a} f(x) = f(a)$ 
* $f(x)$ is continuous everywhere if its continuous for all $a$ in the '''domain''' of $f(x)$


Many functions are continuous, for example: 
* [[Polynomial Functions]]
* [[Rational Functions]]
* [[Trigonometric Functions]]
* [[Exponential Functions]] and [[Logarithms]]


Careful!
* some functions might look discontinuous, but they may be continuous
* this is the case when the discontinuously-looking points are not in the domain 
* but if the function is defined in this point, then it's discontinuous 

Discontinuous: 

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/limit-discontinuity.png


== Sources ==
* [[Calculus: Single Variable (coursera)]]

[[Category:Functions]]</text>
      <sha1>1okrdetkifskeexx359w46v0su10dn9</sha1>
    </revision>
  </page>
  <page>
    <title>Taylor Series</title>
    <ns>0</ns>
    <id>687</id>
    <revision>
      <id>736</id>
      <timestamp>2015-12-06T20:42:03Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Taylor Series == The idea behind Taylor Series is that any well-behaving [[Function]] (e.g. [[Continuous Functions]]) can be represented as a sum of Polynomial Functions|...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9665">== Taylor Series ==
The idea behind Taylor Series is that any well-behaving [[Function]] (e.g. [[Continuous Functions]]) can be represented as a sum of [[Polynomial Functions|Polynomials]]


=== Taylor and Maclaurin Series ===
A Taylor Series of $f(x)$ at $x=0$ is 
* $f(x) = \sum\limits_{k=0}^\infty \cfrac{f^{(k)}(0)}{k!}\, x^k$
* where $f^{(k)}(0)$ is $k$th [[Derivative]] of $f$ evaluated at $x=0$
* this kind of Taylor Series about $x = 0$ is sometimes called ''Maclaurin Series''


Taylor Series of $f(x)$ at $x = a$ is 
* $f(x) = \sum\limits_{k=0}^\infty \cfrac{f^{(k)}(a)}{k!}\, (x - a)^k$
* this is the general form


=== Expansion as an Operator ===
Taylor Expansion is the process of turning a function to a Taylor Series
* can think of it as an operator that takes a function and returns a Series
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/taylor-expansion.png


=== Examples ===
Famous expansions: 
* [[Exponential Function]]: $e^x = \sum\limits_{k=0}^{\infty} \frac{1}{k!} x^k$ of [[Exponential Function]]
* [[Trigonometric Functions]]:
** $\cos x = \sum\limits_{k=0}^\infty (-1)^k \cfrac{x^{2k}}{(2k)!}$ of Cosine 
** $\sin x = \sum\limits_{k=0}^\infty (-1)^k \cfrac{x^{2k + 1}}{(2k + 1)!}$ of Sine
* it allows us to deal with these functions as with long sums of polynomials 


== Approximation ==
Taylor Series are used for approximations

Exponential
* as we add more terms, we are closer and closer to the function
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/taylor-exp.png (source: [http://www.wolframalpha.com/input/?i=e%5Ex+series])
* order $n$ approximation is shown with $n$ dots


Trigonometric Functions:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/taylor-cos.png (source: [http://www.wolframalpha.com/input/?i=cos+x+series])
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/taylor-sin.png (source: [http://www.wolframalpha.com/input/?i=sin+x+series])
* by taking only polynomials of odd (even) powers, we get cosines or sines 

Approximation near the expansion point 0:
* Note that these approximations work best near 0
* It's clear from the sin/cos graphs - the more away from 0, need more terms 


== Computing Taylor Series ==
How to compute Taylor Series? 
There are several ways of doing it

=== [[Derivatives]] ===
* This is the straightforward way:
* use the definitions and compute all the Derivatives
* if a function is complex, it may be hard 

=== Substitution ===
Example: $\cfrac{1}{x}\, \sin (x^2)$
* hard to take derivatives
* but we know the expansion of $\sin x$, so
* $\cfrac{1}{x}\, \sin (x^2) = \cfrac{1}{x}\, \left( (x^2) - \cfrac{1}{3!}\, (x^2)^3 + \cfrac{1}{5!}\, (x^2)^5 -\ ...  \right) =\ ...$
** $... \ = x - \cfrac{1}{3!}\, x^5 + \cfrac{1}{5!}\, x^9 -\ ... = \sum\limits_{k=0}^\infty (-1)^k \cfrac{x^{4k + 1}}{(2k + 1)!}$


=== Combination ===
$\cos^2 x = \cos x \cdot \cos x$
* expand each one separately 
* $\cos x \cdot \cos x = \left(1 - \cfrac{1}{2!}\, x^2 + \cfrac{1}{4!}\, x^4 -\ ... \right)\, \left( 1 - \cfrac{1}{2!}\, x^2 + \cfrac{1}{4!}\, x^4 -\ ... \right) = \ ...$
** $... \ = 1\cdot 1 + 1\, \left(-\cfrac{1}{2!}\, x^2\right) + 1\, \left(\cfrac{1}{4!}\, x^4\right) + \ ... \ - \cfrac{1}{2}\, x^2 \cdot 1 - \cfrac{1}{2}\, x^2 \left(-\cfrac{1}{2!}\, x^2\right) - \cfrac{1}{2}\, x^2 \left(\cfrac{1}{4!}\, x^4\right) - \ ... \ = \ ...$
** $... \ = 1- x^2 +\cfrac{1}{3}\, x^4 - \cfrac{2}{45}\, x^6 + \ ... $
* since $\cos^2 x = 1 - \sin^2 x$, we also obtained the expansion of $\sin^2 x$!


== Higher Order Terms ==
Instead of writing &quot;...&quot; can just say &quot;HOT&quot; meaning &quot;Higher order terms&quot;:
* $e^x = 1 + x + \cfrac{1}{2}\, x^2 + \cfrac{1}{3!}\, x^3 + \text{HOT}$
* we mean that we don't care what terms are there - it's fine to consider just leading terms for some purposes
* it can simplify our calculations


For example:
* $f(x) = 1 - 2x\, e^{\sin (x^2)}$
* How can we Taylor Expand it?
* $\sin (x^2) = x^2 - \cfrac{1}{3!}\, (x^2)^3 + \text{HOT} = x^2 - \cfrac{1}{3!}\, x^6 + \text{HOT}$
* $e^{\sin (x^2)} = 1 + \left( x^2 - \cfrac{1}{3!}\, x^6 + \text{HOT} \right) + \cfrac{1}{2!}\, \left( x^2 - \cfrac{1}{3!}\, x^6 + \text{HOT} \right)^2 + \cfrac{1}{3!}\, \left( x^2 + \text{HOT} \right)^3 + \text{HOT} = 1 + x^2 + \cfrac{1}{2}\, x^4 + \text{HOT}$
* so $f(x) = 1 - 2x\, e^{sin (x^2)} = 1 - 2x\, \left(1 + x^2 + \cfrac{1}{2}\, x^4 + \text{HOT} \right)$


To show what behavior HOTs have, we use [[Orders of Growth]]: the Big-O notation:
* $e^x\, \cfrac{1}{1-x} = \big(1 + x + O(x^2)\big) \cdot \big(1 + x + O(x^2)\big) = \ ...$
** $... \ = (1 + x)^2 + 2\, (1 + x)\, O(x) + \big( O(x^2)\big)^2 = 1 + 2x + O(x^2) + O(x^3) + O(x^4) = 1 + 2x + O(x^2)$


== [[Series Convergence|Convergence]] ==
[[Series]] = adding an infinite number of terms 
* it can be dangerous 
* Problem: not all functions can be expressed as sum of [[Polynomial Functions]], i.e. as $f(x) = \sum c_k x^k$ 

for example, natural [[Logarithm]]:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/log.png
* $\ln x$ is not even defined at $x=0$
* polynomials are too simple to capture all the complexity of $\ln x$ 


=== [[Convergence Domain]] ===
Taylor Series has a ''convergence domain'' on which the series is well behaved 
* for many functions, e.g. $e^x$, $\sin x$, $\cos x$, $\sinh x$, etc, the domain is $\mathbb R = (-\infty, \infty)$

Within the domain of convergence you can do with series whatever you want: 
* rearrange terms 
* differentiate/integrate 
* combine 

For example, $\ln (1 + x)$
* $\ln (1 + x) = \int \cfrac{1}{1 + x}\, dx$ 
** $\cfrac{1}{1 + x}$ is [[Geometric Series]], so
* $\ln (1 + x) = \int \left(\sum\limits_{k=0}^\infty (-x)^k \right)\, dx = \ ...$
** can rearrange integral and sum:
** $... \ = \sum\limits_{k=0}^\infty \left( \int (-x)^k \, dx \right) = \ ...$
** $... \ = \sum\limits_{k=0}^\infty (-1)^k \cfrac{x^{k+1}}{k+ 1} + C = \ ...$
* $C = 0$ because $\ln 1 = 0$, so we have 
** $\ln (1 + x) = \sum\limits_{k=1}^\infty (-1)^{k+1}\, \cfrac{x^k}{k} = x - \cfrac{1}{2}\, x^2 + \cfrac{1}{3}\, x^3 - \cfrac{1}{4}\, x^4 + \ ...$
* no factorials involved! 


'''Convergence domain''':
* we used [[Geometric Series]] here, so we must be in the domain of convergence of this series 
* which is $|x| &lt; 1$
* Taylor Series approximates well only on the domain of convergence 
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/log-domain-of-conv.png
* outside of the domain, we don't get better approximation when we add more terms!


Another example: $\arctan x$
* $\arctan x = \int \cfrac{1}{1 + x^2}\, dx$
** we also have a Geometric Series here, with $-x^2$, so 
* $\arctan x = \int \cfrac{1}{1 + x^2}\, dx = \int \sum\limits_{k=0}^\infty (-x^2)^k \, dx = \ ...$
** $... \ = \int \sum\limits_{k=0}^\infty (-1)^k x^{2k} \, dx = \sum\limits_{k=0}^\infty \left( \int (-1)^k x^{2k} \, dx \right) = \ ...$
** $... \ = \sum\limits_{k=0}^\infty \cfrac{(-1)^k}{2k + 1}\, x^{2k + 1} + C$
* $C = 0$ because $\arctan 0 = 0$
** so $\arctan x = x - \cfrac{1}{3}\, x^3 + \cfrac{1}{5}\, x^5 - \cfrac{1}{7}\, x^7 + \ ...$
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/arctan-domain-of-conv.png
* the domain of convergence is also $|x| &lt; 1$



== Expansion Points ==
* Maclaurin Series give good approximation at points near 0. 
* But what if we want to have good approximations at some other points? 
* In many applications 0 is not the most interesting point

Taylor Series of $f(x)$ at $x = a$ is 
* $f(x) = \sum\limits_{k=0}^\infty \cfrac{f^{(k)}(a)}{k!}\, (x - a)^k = f(a) + \cfrac{df}{dx}|_{a} (x - a) + \cfrac{1}{2!}\, \cfrac{d^2f}{dx^2}|_{a} (x - a)^2 + \cfrac{1}{3!}\, \cfrac{d^3f}{dx^3}|_{a} (x - a)^3 + \ ...$
* this is polynomial in $(x - a)$ instead of just $x$

=== Approximation ===
https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/taylor-approx.png
* The bigger $|a - x|$ is, the more high-order terms we need to have good approximation
* Taylor Series converge only within the domain of convergence - so need to stay within the domain


Example:
* estimate $\sqrt{10}$
* $\sqrt{x}$ expanded at $x = a$ is $\sqrt{x} = \sqrt{a} + \cfrac{1}{2\, \sqrt{a}}\, (x - a) - \cfrac{1}{8\, \sqrt{a^3}}\, (x - a)^2 + \text{HOT}$
* let's approximate it at $a = 1$: 
** $\sqrt{x} = 1 + \cfrac{1}{2}\, (x - 1) - \cfrac{1}{8}\, (x - 1)^2 + \text{HOT}$
** for $x = 10$, we get $\approx -4.122$
** bad approximation! $a = 1$ is far from $x = 10$, so need more derivatives to approximate better
* let's consider $a = 9$ ($\sqrt{9} = 3$)
** $\sqrt{x} = 3 + \cfrac{1}{6}\, (x - 9) - \cfrac{1}{216}\, (x - 9)^2 \approx -4.122$
** for $x = 10$ we get $3 + 1/6 - 1/216 \approx 3.1620$ (real is $3.1623$)
** quite close!
* so it's important to select $a$ which is close to the value $x$ where you want to approximate $f(x)$


=== Taylor Expansion via Decomposition ===
Be careful with expansion points when doing Taylor Expansion via decomposition
Expand about the correct value!

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/taylor-expansion-composition.png

For example, compute expansion for $e^{\cos x}$ about $x = 0$
* we have: $0 \to \cos (\cdot) \to e^{(\cdot)} \to$
* first, we expand about 0
* but for $e$, we don't expand about 0 - we expand about $\cos 0 = 1$!
* $\cos x = 1 - \cfrac{1}{2!}\, x^2 + \cfrac{1}{4!}\, x^4 - \ ...$
* $e^u = e + e\, (u - 1) + \cfrac{1}{2!}\, e\, (u - 1)^2 + \ ...$


== Sources ==
* [[Calculus: Single Variable (coursera)]]

[[Category:Calculus]]
[[Category:Functions]]
[[Category:Series]]</text>
      <sha1>1d1r4z0oxfgvbqm7uri5b81r9nbrqjh</sha1>
    </revision>
  </page>
  <page>
    <title>Limits</title>
    <ns>0</ns>
    <id>688</id>
    <revision>
      <id>737</id>
      <timestamp>2015-12-06T20:46:36Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Limits == $\lim\limits_{x \to a} f(x) = L$    === Definition === the limit of $f(x)$ as $x \to a$ is $L$: * if $\forall \varepsilon &gt; 0 \ \ \exists\, \delta &gt; 0$ s.t. $x \n...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3903">== Limits ==
$\lim\limits_{x \to a} f(x) = L$ 


=== Definition ===
the limit of $f(x)$ as $x \to a$ is $L$:
* if $\forall \varepsilon &gt; 0 \ \ \exists\, \delta &gt; 0$ s.t. $x \ne a$ is within $\delta$ of $a$
* then $f(x)$ is within $\varepsilon$ of $L$ 

=== Interpretation ===
Interpretation: 
* if as $x$ gets closer to $a$, $f(x)$ gets closer to $L$
* then $L$ is the limit of $f(x)$ 

or
* choose some ''output tolerance'' $\varepsilon$ 
* then there exists some ''input tolerance'' $\delta$ such that $L$ lies within $\varepsilon$ of $f(x)$
* if you change $\varepsilon$, you need to be able to update $\delta$ - this has to be true for any $\varepsilon$

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/limit-def.png


=== $x \to \infty$ ===
* $a = \infty$ then 
* $\lim\limits_{x \to \infty} f(x) = L$ 

What does it mean? Can think if it as of the &quot;end&quot; of the real line

Definition:
* the definition needs to be slightly adapted 
* if $\forall \varepsilon &gt; 0 \ \ \exists\, M &gt; 0$ s.t. $|f(x) - L| &lt; \varepsilon$ when $x &gt; M$
* if there's no such $M$, then the limit does not exist


Interpretation:
* instead of input tolerance $\infty \pm \delta, we mean some very large $M$:
* we always can find some large $M$ after which $f(x)$ is always within $\varepsilon$ of $L$ 

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/limit-def-infty.png

as $\varepsilon$ becomes tighter, we still should be able to find larger $M$ for which the function lies within $\varepsilon$


== Non-Existent Limits ==
Some functions are not well-behaved, so things can go wrong

=== Discontinuity ===
The limit does not exist because the limit from the left and the limit from the right are not equal.

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/limit-discontinuity.png


=== Blow-Up ===
The function has a vertical asymptote:
* functions gets to $\infty$ as $x \to a$ 

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/limit-blowup.png


=== Oscillation ===
The function oscillates up and down as the input approaches some value

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/limit-oscillation.png


== Rules ==
Rules for limits

Suppose $\lim\limits_{x \to a} f(x)$ and $\lim\limits_{x \to a} g(x)$ exist. Then
* '''Sum Rule''': $\lim \big(f(x) + g(x) \big) = \lim f(x) + \lim g(x)$
* '''Product Rule''': $\lim \big(f(x) \cdot g(x) \big) = \left[\lim f(x)\right] \cdot \left[ \lim g(x) \right]$
* '''Quotient Rule''': $\lim \cfrac{f(x)}{g(x)} = \cfrac{\lim f(x)}{\lim g(x)}$ (when $\lim g(x) \ne 0$)
* '''Chain Rule''' (or '''Composition Rule'''): $\lim f \big(g(x) \big) = f \big(\lim g(x) \big)$ if $f$ is continuous 


== [[L'Hopital's Rule]] ==
$$\lim_{x \to a} \cfrac{f(x)}{g(x)} = \lim_{x \to a} \cfrac{f'(x)}{g'(x)}$$

Gives a way to solve ambiguous limits:
* $\lim \cfrac{0}{0}$
* $\lim \cfrac{\infty}{\infty}$
* $\lim \infty \cdot 0$
* $\lim (\infty - \infty)$
* $\lim \infty^0$



== Some Important Limits ==
=== $\lim\limits_{x \to 0} \cfrac{\sin x}{x}$ ===
What is $\lim\limits_{x \to 0} \cfrac{\sin x}{x}$?
* cannot apply the Quotient Rule because $x \to 0$ 
* let's [[Taylor Series|Taylor Expand]] $\sin x$ 
*  $\lim\limits_{x \to 0} \cfrac{\sin x}{x} = \lim\limits_{x \to 0} \cfrac{x - \frac{1}{3!}\, x^3 + \frac{1}{5!}\, x^5 - \ ...}{x} = \ ...$
** $... \ = \lim\limits_{x \to 0} \cfrac{x\, \left(1 - \frac{1}{3!}\, x^2 + \frac{1}{5!}\, x^4 - \ ... \ \right)}{x} = \ ...$
** $... \ = \lim\limits_{x \to 0} \left(1 - \frac{1}{3!}\, x^2 + \frac{1}{5!}\, x^4 + \ ... \ \right) = 1$


Can also show this using the [[L'Hopital's Rule]]
* $\lim\limits_{x \to 0} \cfrac{\sin x}{x} = \lim\limits_{x \to 0} \cfrac{\cos x}{1} = 1$

== Sources ==
* [[Calculus: Single Variable (coursera)]]

[[Category:Calculus]]
[[Category:Functions]]
[[Category:Limits]]</text>
      <sha1>bkkf9qyo5tydnly1snchal2ew9pi8d7</sha1>
    </revision>
  </page>
  <page>
    <title>L'Hopital's Rule</title>
    <ns>0</ns>
    <id>689</id>
    <revision>
      <id>738</id>
      <timestamp>2015-12-06T20:48:39Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== L'Hôpital's Rule == The rule has this form: $$\lim_{x \to a} \cfrac{f(x)}{g(x)} = \lim_{x \to a} \cfrac{f'(x)}{g'(x)}$$   === $0/0$ case === * suppose $\lim\limits_{x \to...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2043">== L'Hôpital's Rule ==
The rule has this form:
$$\lim_{x \to a} \cfrac{f(x)}{g(x)} = \lim_{x \to a} \cfrac{f'(x)}{g'(x)}$$


=== $0/0$ case ===
* suppose $\lim\limits_{x \to a} \cfrac{f(x)}{g(x)} = \cfrac{0}{0}$
* i.e. $f(a) = 0$ and $g(a) = 0$
* if $f(x)$ and $g(x)$ are continuous 
* then the rule is $$\lim_{x \to a} \cfrac{f(x)}{g(x)} = \lim_{x \to a} \cfrac{f'(x)}{g'(x)}$$


Can show this using [[Taylor Expansion]] about $x = a$:
* $\lim\limits_{x \to a} \cfrac{f(x)}{g(x)} = \lim\limits_{x \to a} \cfrac{f(a) + f'(a)\, (x - a) + \ ...}{g(a) + g'(a)\, (x - a) + \ ...}$
** know that $f(a) = g(a) = 0$, so have 
* $\lim\limits_{x \to a} \cfrac{f(x)}{g(x)} = \lim\limits_{x \to a} \cfrac{f'(a)\, (x - a) + \ ...}{g'(a)\, (x - a) + \ ...}$
* can factor $(x - a)$ out, so we have: 
* $\lim\limits_{x \to a} \cfrac{f(x)}{g(x)} = \lim\limits_{x \to a} \cfrac{f'(a) + \ ...}{g'(a) + \ ...}$
* the leading order terms are $f'(a)$ and $g'(a)$, and the rest vanish under the limit


Examples:
* $\lim\limits_{x \to 0} \cfrac{\sin x}{x} = \lim\limits_{x \to 0} \cfrac{\cos x}{1} = 1$
* $\lim\limits_{x \to 0} \cfrac{1 - \cos x}{x} = \lim\limits_{x \to 0} \cfrac{\sin x}{1} = 0$


=== $\infty / \infty$ case ===
* suppose $\lim\limits_{x \to a} \cfrac{f(x)}{g(x)} = \cfrac{\infty}{\infty}$
* i.e. $f(a) = \infty$ and $g(a) = \infty$
* if $f(x)$ and $g(x)$ are continuous 
* then the rule is $$\lim_{x \to a} \cfrac{f(x)}{g(x)} = \lim_{x \to a} \cfrac{f'(x)}{g'(x)}$$


Example: 
* $\lim\limits_{x \to \infty} \cfrac{\ln x}{\sqrt{x}}$
* both go to $\infty$, but the rate at which they approach $\infty$ is different 
* by taking the derivative, we can see which one grows faster 
* is this case, $\sqrt{x}$ dominates $\ln x$: it grows much faster
* so the limit is 0

To say that one function grows faster than other, we can use the [[Order of Growth|Big-O notation]]


=== Other Cases ===
See http://calculus.seas.upenn.edu/?n=Main.LHopitalsRule


== Sources ==
* [[Calculus: Single Variable (coursera)]]

[[Category:Calculus]]
[[Category:Limits]]</text>
      <sha1>s0c90k93rfva00p5wkrp9ldli1ap8t5</sha1>
    </revision>
    <revision>
      <id>743</id>
      <parentid>738</parentid>
      <timestamp>2015-12-07T06:26:02Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2048">== L'Hôpital's Rule ==
The rule has this form:
$$\lim_{x \to a} \cfrac{f(x)}{g(x)} = \lim_{x \to a} \cfrac{f'(x)}{g'(x)}$$


=== $0/0$ case ===
* suppose $\lim\limits_{x \to a} \cfrac{f(x)}{g(x)} = \cfrac{0}{0}$
* i.e. $f(a) = 0$ and $g(a) = 0$
* if $f(x)$ and $g(x)$ are continuous 
* then the rule is $$\lim_{x \to a} \cfrac{f(x)}{g(x)} = \lim_{x \to a} \cfrac{f'(x)}{g'(x)}$$


Can show this using [[Taylor Expansion]] about $x = a$:
* $\lim\limits_{x \to a} \cfrac{f(x)}{g(x)} = \lim\limits_{x \to a} \cfrac{f(a) + f'(a)\, (x - a) + \ ...}{g(a) + g'(a)\, (x - a) + \ ...}$
** know that $f(a) = g(a) = 0$, so have 
* $\lim\limits_{x \to a} \cfrac{f(x)}{g(x)} = \lim\limits_{x \to a} \cfrac{f'(a)\, (x - a) + \ ...}{g'(a)\, (x - a) + \ ...}$
* can factor $(x - a)$ out, so now we have: 
* $\lim\limits_{x \to a} \cfrac{f(x)}{g(x)} = \lim\limits_{x \to a} \cfrac{f'(a) + \ ...}{g'(a) + \ ...}$
* the leading order terms are $f'(a)$ and $g'(a)$, and the rest vanish under the limit


Examples:
* $\lim\limits_{x \to 0} \cfrac{\sin x}{x} = \lim\limits_{x \to 0} \cfrac{\cos x}{1} = 1$
* $\lim\limits_{x \to 0} \cfrac{1 - \cos x}{x} = \lim\limits_{x \to 0} \cfrac{\sin x}{1} = 0$


=== $\infty / \infty$ case ===
* suppose $\lim\limits_{x \to a} \cfrac{f(x)}{g(x)} = \cfrac{\infty}{\infty}$
* i.e. $f(a) = \infty$ and $g(a) = \infty$
* if $f(x)$ and $g(x)$ are continuous 
* then the rule is $$\lim_{x \to a} \cfrac{f(x)}{g(x)} = \lim_{x \to a} \cfrac{f'(x)}{g'(x)}$$


Example: 
* $\lim\limits_{x \to \infty} \cfrac{\ln x}{\sqrt{x}}$
* both go to $\infty$, but the rate at which they approach $\infty$ is different 
* by taking the derivative, we can see which one grows faster 
* is this case, $\sqrt{x}$ dominates $\ln x$: it grows much faster
* so the limit is 0

To say that one function grows faster than other, we can use the [[Orders of Growth|Big-O notation]]


=== Other Cases ===
See http://calculus.seas.upenn.edu/?n=Main.LHopitalsRule


== Sources ==
* [[Calculus: Single Variable (coursera)]]

[[Category:Calculus]]
[[Category:Limits]]</text>
      <sha1>pxuf59ftma5eu3gi1jv4yn2cmc5to92</sha1>
    </revision>
    <revision>
      <id>749</id>
      <parentid>743</parentid>
      <timestamp>2016-01-02T11:05:42Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <minor/>
      <comment>/* Other Cases */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2148">== L'Hôpital's Rule ==
The rule has this form:
$$\lim_{x \to a} \cfrac{f(x)}{g(x)} = \lim_{x \to a} \cfrac{f'(x)}{g'(x)}$$


=== $0/0$ case ===
* suppose $\lim\limits_{x \to a} \cfrac{f(x)}{g(x)} = \cfrac{0}{0}$
* i.e. $f(a) = 0$ and $g(a) = 0$
* if $f(x)$ and $g(x)$ are continuous 
* then the rule is $$\lim_{x \to a} \cfrac{f(x)}{g(x)} = \lim_{x \to a} \cfrac{f'(x)}{g'(x)}$$


Can show this using [[Taylor Expansion]] about $x = a$:
* $\lim\limits_{x \to a} \cfrac{f(x)}{g(x)} = \lim\limits_{x \to a} \cfrac{f(a) + f'(a)\, (x - a) + \ ...}{g(a) + g'(a)\, (x - a) + \ ...}$
** know that $f(a) = g(a) = 0$, so have 
* $\lim\limits_{x \to a} \cfrac{f(x)}{g(x)} = \lim\limits_{x \to a} \cfrac{f'(a)\, (x - a) + \ ...}{g'(a)\, (x - a) + \ ...}$
* can factor $(x - a)$ out, so now we have: 
* $\lim\limits_{x \to a} \cfrac{f(x)}{g(x)} = \lim\limits_{x \to a} \cfrac{f'(a) + \ ...}{g'(a) + \ ...}$
* the leading order terms are $f'(a)$ and $g'(a)$, and the rest vanish under the limit


Examples:
* $\lim\limits_{x \to 0} \cfrac{\sin x}{x} = \lim\limits_{x \to 0} \cfrac{\cos x}{1} = 1$
* $\lim\limits_{x \to 0} \cfrac{1 - \cos x}{x} = \lim\limits_{x \to 0} \cfrac{\sin x}{1} = 0$


=== $\infty / \infty$ case ===
* suppose $\lim\limits_{x \to a} \cfrac{f(x)}{g(x)} = \cfrac{\infty}{\infty}$
* i.e. $f(a) = \infty$ and $g(a) = \infty$
* if $f(x)$ and $g(x)$ are continuous 
* then the rule is $$\lim_{x \to a} \cfrac{f(x)}{g(x)} = \lim_{x \to a} \cfrac{f'(x)}{g'(x)}$$


Example: 
* $\lim\limits_{x \to \infty} \cfrac{\ln x}{\sqrt{x}}$
* both go to $\infty$, but the rate at which they approach $\infty$ is different 
* by taking the derivative, we can see which one grows faster 
* is this case, $\sqrt{x}$ dominates $\ln x$: it grows much faster
* so the limit is 0

To say that one function grows faster than other, we can use the [[Orders of Growth|Big-O notation]]


=== Other Cases ===
* See http://calculus.seas.upenn.edu/?n=Main.LHopitalsRule

== Links ==
* http://math.stackexchange.com/questions/584889/the-intuition-behind-lhopitals-rule/

== Sources ==
* [[Calculus: Single Variable (coursera)]]

[[Category:Calculus]]
[[Category:Limits]]</text>
      <sha1>52zji29r2xgwxt2mtj8udids9mbt4n4</sha1>
    </revision>
  </page>
  <page>
    <title>Limit</title>
    <ns>0</ns>
    <id>690</id>
    <redirect title="Limits" />
    <revision>
      <id>739</id>
      <timestamp>2015-12-06T20:50:51Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Redirected page to [[Limits]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20">#REDIRECT [[Limits]]</text>
      <sha1>4iue59bcf4twxyyyanjmfl9h6ycspfu</sha1>
    </revision>
  </page>
  <page>
    <title>Polynomial Function</title>
    <ns>0</ns>
    <id>691</id>
    <redirect title="Polynomial Functions" />
    <revision>
      <id>740</id>
      <timestamp>2015-12-06T20:51:20Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Redirected page to [[Polynomial Functions]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="34">#REDIRECT [[Polynomial Functions]]</text>
      <sha1>ellaz2p0dl1rbajlirvah59qx667g5v</sha1>
    </revision>
  </page>
  <page>
    <title>Orders of Growth</title>
    <ns>0</ns>
    <id>692</id>
    <revision>
      <id>741</id>
      <timestamp>2015-12-06T20:58:33Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Orders of Growth == Asymptotic notation: &quot;Big-O&quot; * Big-O notation gives a way to talk about the rate at which functions grow/decrease * it allows us to study asymptotic beh...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5009">== Orders of Growth ==
Asymptotic notation: &quot;Big-O&quot;
* Big-O notation gives a way to talk about the rate at which functions grow/decrease
* it allows us to study asymptotic behavior of a function

Big-O can answer: 
* what happens when a function becomes very very small? 
* very very large? 
* how fast the function approaches 0? $\infty$?



== Hierarchy of Growth/Decrease ==
=== $x \to \infty$ ===
Consider a [[Limit]] $\lim\limits_{x \to \infty} \cfrac{x^n}{e^x}$
* who &quot;wins&quot;? 
* can apply [[L'Hopital's Rule]] several times:
* $\lim\limits_{x \to \infty} \cfrac{x^n}{e^x} = \lim\limits_{x \to \infty} \cfrac{n\, x^{n-1}}{e^x} = \ ... \ = \lim\limits_{x \to \infty} \cfrac{n!}{e^x}$
* $n!$ is a constant (even though it might be big - but it's still a constant)
* so $e^x$ grows faster than any Monomial Function (and any [[Polynomial Function]] as well) 


We have the following hierarchy of growth:
* [[Factorial]]
* [[Exponential Function]]
* [[Polynomial Functions]] (also, $x^{n+1} &gt; x^n$)
* [[Logarithm]]
* Constant 


Let's illustrate it on some monomials:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/orders-of-growth.png
* so we see that higher order monomials grow faster than lower order monomials

Example:
* $\lim\limits_{x \to \infty}\cfrac{3\, x^2 - 2\, x + 1}{6\, x^2 - 5\, x + 4} = \lim\limits_{x \to \infty}\cfrac{x^2\, (3 + \text{smth small})}{x^2\, (6 + \text{smth small})} = \cfrac{3}{6} = \cfrac{1}{2}$


Factorial Growth beats Exponential Growth
* let's show why:
* $\cfrac{x!}{e^x} = \cfrac{x\, (x - 1)\ ... \ 3\, 2\, 1}{e\, e \ ... \ e\, e\, e}$
* almost all terms at the numerator are greater than $e$, only 2 and 1 are smaller 


=== $x \to 0$ ===
It's the opposite for $x \to 0$
* let's consider $x &lt; 1$:
* https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/orders-of-growth-0.png
* linear function is biggest here!
* so as $x \to 0$, $x^{n+1} &lt; x^n$ - opposite of $x \to \infty$


The hierarchy reverses 
* Constant 
* [[Logarithm]]
* [[Polynomial Functions]] ($x^{n+1} &lt; x^n$)
* [[Exponential Function]]
* [[Factorial]]

Example:
* $\lim\limits_{x \to 0} \cfrac{1 -2x + 3x^2}{4 - 5x + 6x^2} = \cfrac{1}{4}$
* lowest order terms dominate any higher order terms 


=== Summary ===
* $x \to \infty$: high order terms dominate 
* $x \to 0$: low order terms dominate 


== Big-O Notation ==
This gives a language for describing the growth 
* it has two forms 
* one for $x \to \infty$
* another for $x \to 0$

Definition: 
* A [[Function]] $f$ is in $O(x^n)$ if $|f(x)| &lt; C\, |x^n|$ for some constant $C$ 
* more generally: $f \in O \big( g(x) \big)$ if $|f(x)| &lt; C\, |g(x)|$ for some $C$


Interpretation:
* we care only about the upper border: &quot;how bad can it be?&quot; 



&lt;table&gt;
&lt;tr&gt;
&lt;th&gt;$x \to 0$&lt;/th&gt;&lt;th&gt;$x \to \infty$&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$O(x^n)$ consists of all functions $f$ that approach 0 '''at least as fast as''' $x^n$&lt;/td&gt;
&lt;td&gt;$O(x^n)$ consists of all functions $f$ that approach \infty '''no faster than''' $x^n$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
* $\sqrt x \in O(\sqrt x)$ 
* $x \in O(\sqrt x)$ 
* $x^2 \in O(\sqrt x)$ 
&lt;/td&gt;
&lt;td&gt;
* $\sqrt x \in O(x^2)$ 
* $x \in O(x^2)$ 
* $x^2 \in O(x^2)$ &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
$\arctan x = x - O(x^3) = x - \cfrac{x^3}{3} + O(x^5)$ 
&lt;/td&gt;
&lt;td&gt;
$x\, \sqrt{x^2 + 3\, x + 5} = x^2 + O(x) = x^2 + \cfrac{3}{2}\, x + O(1)$ 
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/crs/calc/orders-of-growth-ex.png

== Examples ==
=== Case $x \to 0$ ===
* $3\, x^2 + 5\, x \in O(x)$, but $\not \in O(x^2)$
* $\sin x \in O(x)$, $\not \in O(x^2)$
* $\ln (1 - x) - x \in O(x^2)$, $\not \in O(x^3)$
* $1 - \cos x^2 \in O(x^4)$, $\not \in O(x^5)$
* $\sqrt{n} \not \in O(x^n) \ \forall n \geqslant 1$ - it goes to zero faster than any other polynomial
* $e^{- 1/x^2} \in O(x^n) \ \forall n$ 

=== Case $x \to \infty$ ===
* $\arctan x \in O(1), O(n) \ \forall n \geqslant 1$
* $x\, \sqrt{1 + x^2} \in O(x^2), \ \not \in O(x^{3/2})$
* $\ln (\sinh x) \in O(x), \ \not \in O(\ln x)$: $\ln (\sinh x)$ grows too fast for $\ln x$
* $\cosh x \in O(e^x), \ \not \in O(x^n) \forall n \geqslant 0$
* $\ln x^5 \in O(\ln x), O(x^n) \ \forall n$



== Rules of Asymptotic Analysis ==
* $O(x^m) \cdot O(x^n) = O(x^{m + n})$
* $O(x^m) + O(x^n) = O(x^{\min m, n})$ for $x \to 0$
* $O(x^m) + O(x^n) = O(x^{\max m, n})$ for $x \to \infty$

=== Examples ===
Example 1:
* $\cfrac{e^x}{1 - x}$ as $x \to 0$
* $\cfrac{e^x}{1 - x} = e^x\, \cfrac{1}{1-x}$
* have an exponent and a [[Geometric Series]], can [[Taylor Series|Taylor Expand]] both:
*  $e^x\, \cfrac{1}{1-x} = \big(1 + x + O(x^2)\big) \cdot \big(1 + x + O(x^2)\big) = \ ...$
** $... \ = (1 + x)^2 + 2\, (1 + x)\, O(x) + \big( O(x^2)\big)^2 = 1 + 2x + O(x^2) + O(x^3) + O(x^4) = 1 + 2x + O(x^2)$


== Applications ==
* Algorithms: Computational Complexity, [[Big O]]
* Error Analysis
* Stirling Formula (see [[Factorial]])

== Sources ==
* [[Calculus: Single Variable (coursera)]]

[[Category:Calculus]]
[[Category:Limits]]</text>
      <sha1>hxht28rkagan30l6na043i1sl9dmn4n</sha1>
    </revision>
  </page>
  <page>
    <title>Taylor Expansion</title>
    <ns>0</ns>
    <id>693</id>
    <redirect title="Taylor Series" />
    <revision>
      <id>742</id>
      <timestamp>2015-12-07T06:23:19Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Redirected page to [[Taylor Series]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27">#REDIRECT [[Taylor Series]]</text>
      <sha1>mel4yps9j4o9xc1pag49pem9ve7sf9y</sha1>
    </revision>
  </page>
  <page>
    <title>MapReduce/Joins</title>
    <ns>0</ns>
    <id>694</id>
    <revision>
      <id>748</id>
      <timestamp>2015-12-30T15:19:12Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== MapReduce/Joins == How to implement a Join from [[Relational Algebra]] using [[MapReduce]]?  There are several types of joins: * broadcast join * reduce-side join   == Broa...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3094">== MapReduce/Joins ==
How to implement a Join from [[Relational Algebra]] using [[MapReduce]]?

There are several types of joins:
* broadcast join
* reduce-side join


== Broadcast-Join ==
* when one table is small enough to fit into memory
* small one is broadcasted to each mapper and kept in memory there
* go through blocks of other one and do the join


=== [[Hadoop MapReduce]] Implementation ===
* use [[Hadoop MapReduce#Distributed Cache|Distributed Cache]] for sending the same data to all the nodes
* [https://github.com/alexeygrigorev/aim3/blob/master/src/main/java/de/tuberlin/dima/aim3/assignment1/BookAndAuthorBroadcastJoin.java BookAndAuthorBroadcastJoin.java] 




== Reduce-Side Join ==
* preparation step
** each mapper tags each record to identify which entity it is
* mapper outputs (id, record) for each record
** same keys will be copied to same reducer during shuffling
* each reducer does the join based on equal kets
* similar to [[Physical Operators (databases)#(Partition) Hash Join|Hash Join]] in DBMS

note
* it may lead to massive data re-distribution 
* when input is huge
* even though data may be on one node it may be moved to others
* need to take the cost of communication into account


=== Example ===
Suppose we have the following schema: 
* Employee(name, SSN)
* Department(emplSSN, depName)

We want to have the following join: 
* $\text{Employee} \Join_\text{SSN = emplSSN} \text{Department}$

Our tagged dataset 
{| class=&quot;wikitable&quot;
|-
| Emp || Sue || 999
|-
| Emp || Tony || 777
|-
| Dep || 999 || Accounts 
|-
| Dep || 777 || Sales
|-
| Dep || 777 || Marketing
|}


After applying map we get
{| class=&quot;wikitable&quot;
|-
| 999 || (Emp, Sue, 999)
|-
| 777 || (Emp, Tony, 777)
|-
| 999 || (Dep, 999, Accounts)
|-
| 777 || (Dep, 777, Sales)
|-
| 777 || (Dep, 777, Marketing)
|}


And finally after the reduce stage we get 

{| class=&quot;wikitable&quot;
|-
| key=999 || [(Emp, Sue, 999), (Dep, 999, Accounts)]
|-
| key=777 || [(Emp, Tony, 777), (Dep, 777, Sales), (Dep, 777, Marketing)]
|}



=== Python Implementation ===
Source: [http://code.google.com/p/stolzen/source/browse/trunk/courses/coursera/Introduction%20to%20Data%20Science/assignment3/p2_join.py]

 def mapper(record):
   id = record[1]
   emit(id, record)
 
 def reducer(key, list_of_values):
   grouped = itertools.groupby(list_of_values, operator.itemgetter(0))
   g = {k: list(v) for (k, v) in grouped}
   order = g['order'][0]
 
   for line_item in g['line_item']:
     emit(order + line_item)


=== Hadoop MapReduce Implementation ===
From [[Scalable Data Analytics and Data Mining AIM3 (TUB)|AIM3]]:
* [https://github.com/alexeygrigorev/aim3/blob/master/src/main/java/de/tuberlin/dima/aim3/assignment1/BookAndAuthorReduceSideJoin.java BookAndAuthorReduceSideJoin.java]


== High Level APIs ==
* High level APIs such as [[Pig]]/[[Hive]] or [[Flink]]/[[Spark]] already provide join abstractions
* so there's no need to implement them 

== Sources ==
* [[Introduction to Data Science (coursera)]]
* [[Scalable Data Analytics and Data Mining AIM3 (TUB)]]

[[Category:MapReduce]]
[[Category:Hadoop]]</text>
      <sha1>k4mcc2br1blg7nitgd8gwo2kbr1hcb3</sha1>
    </revision>
  </page>
  <page>
    <title>Collocation Extraction</title>
    <ns>0</ns>
    <id>695</id>
    <revision>
      <id>756</id>
      <timestamp>2017-04-25T20:47:53Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Collocation Extraction == There's no commonly accepted definition of &quot;collocation&quot;, but it's usually a multiple-word token (i.e. an $n$-gram) where * the words of the ngram...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9157">== Collocation Extraction ==
There's no commonly accepted definition of &quot;collocation&quot;, but it's usually a multiple-word token (i.e. an $n$-gram) where
* the words of the ngram co-occur together more often than by chance alone
* usually they mean something collectively, something different from what each word means alone

Other names for collocations:
* compound terms 
* multi-word terms
* $n$-grams

=== Types of Collocations ===
There are two types of collocations:
* Open Compounds 
* Compositional Collocation 

Open Compounds 
* uninterrupted sequences of words that generally function as a single &quot;word&quot; in the text 
* e.g. &quot;stock market&quot;, &quot;foreign exchange&quot;

Compositional Collocation 
* a sequence interrupted by preposition or a conjunction 
* e.g. &quot;cure for cancer&quot;, &quot;guns and ammunitions&quot;

=== Applications ===
There are following applications for Collocation Extraction 
* [[Inverted Index|Indexing]], [[Information Retrieval]]
* [[Language Generation]]
* [[Word Sense Disambiguation]]
* [[Document Classification]]
* and many others 

[[Information Retrieval]]
* in IR these words may represent documents better than unigram tokens
* some tri-grams and higher order $n$-grams may be good for IR, even though they aren't compound term - in the sense of the definitions above. 


=== Identification of Collocations ===
How to find and extract collocations? 
* by &quot;co-occur more often than by chance&quot; we can mean independence 
* so we can test if the words in the collocation are independent or not
* if they aren't - then maybe it's a collocation
* we also can use some measures than quantify the dependence between words - and the higher the measure, the more likely the words form a collocation


== Two Word Collocations ==
Let us start by considering the bigram collocation case
* suppose the collocation candidate is $(w_1, w_2)$ 
* if both $w_1$ and $w_2$ are frequent, they may co-locate just by chance, even if they don't form a collocation
* we want to test if this collocation occurs significantly more often than by chance
* for that we can compare how often $w_1$ and $w_2$ occur independently, and how often they occur together
* can do [[Hypothesis Testing]] for that

General framework:
* under the Independence hypothesis ($H_0$) we assume that there is no association between $w_1$ and $w_2$, i.e. they are independent 
* let $P(w_1)$ and $P(w_2)$ are probabilities that a random token in a text is $w_1$ and $w_2$ resp.
* and $P(w_1, w_2)$ is the probability that $(w_1, w_2)$ occur together in the text (i.e. one follows another) 
* so under $H_0$, $P(w_1, w_2) = P(w_1)\, P(w_2)$
* we can compute the observed probability of $P(w_1, w_2)$ and compare it with the probability under $H_0$  
* if these probabilities are significantly different from each other, then $(w_1, w_2)$ is a collocation


Ranking candidates 
* if we can measure the degree of dependence, we can rank the candidate collocation
* usually tests have some test statistics which we can use for ranking candidates
* often it is more interesting to look at the top ranking candidates rather than at all of them


Ways to test/rank:
* [[T-test|$T$-test]]
* Odds Ratio
* [[Point-Wise Mutual Information]]
* [[Chi-Squared Test]]
* The [[Dice Coefficient]] $\text{DICE}(w_1, w_2) = \cfrac{2 \, c(w_1, w_2)}{c(w_1)\, c(w_2)}$
* [[Log Likelihood Ratio]] ([[Entropy]] version): $G^2 = \sum_{ij} O_{ij} \log \cfrac{O_{ij}}{E_{ij}}$
* and others 
* these measures are usually based on frequencies obtained from some corpus


=== [[T-test|$T$-tests]] ===
$t$-test can also be used for collocation discovery
* it looks at the mean and variance 
* can use $t$-test for proportions: $t = \cfrac{\bar x - \mu}{\sqrt{s^2 / N}}$

The idea:
* The probability of generating a bigram $(w_1, w_2)$ is a [[Bernoulli Random Variable]] with $p= P(w_1, w_2)$ 
* for Bernoulli, $\mu = p$ and $\sigma^2 = p\, (1-p)$
* because $p$ is typically quite small, $\sigma^2 \approx p$ for most bigrams
* then we can calculate the $t$-value and the corresponding critical value ($N$ = number of unigrams)
* and if $t$ is large enough, reject $H_0$ 
* but in this case, it's more useful to rank values by their $t$ rather than just know if a bigram passes a test or not


=== Other Tests ===
Other tests can also be used 
* e.g. [[Chi-Squared Test]] (see [[Chi-Squared Test of Independence]])
* it's a good alternative for t-test

it's applied to 2-by-2 table 
* in essence, it compares observed frequencies to expected frequencies 
* if the difference is large - reject $H_0$ 
* $X^2 = \sum_{ij} \cfrac{(O_{ij} - E_{ij})^2}{E_{ij}}$
* $X^2$ is distributed as $\chi^2$


=== [[Odds Ratio Test]] ===
To compare $P(w_1, w_2)$ with $P(w_1) \, P(w_2)$ we can use the Odds Ratio:
* [[Odds Ratio]] is $\cfrac{P(w_1, w_2)}{P(w_1) \, P(w_2)}$
* collocations should have scores higher than 1
* the higher the ratio, the more likely a bigram is a collocation


=== [[Point-Wise Mutual Information]] ===
[[Mutual Information]]:
* it's a measure on how much one word tells about the other 
* In [[Information Theory]], Mutual Information is defined between Random Variables, not words (values of RVs)
* which is why we use PMI

Point-Wise Mutual Information (PMI):
* instead of Odds Ratio, can use [[Log Odds]]:
* $\log \cfrac{P(w_1, w_2)}{P(w_1) \, P(w_2)}$
* then it becomes [[Point-Wise Mutual Information]]
* $\text{PMI}(w_1, w_2) = \log \cfrac{P(w_1, w_2)}{P(w_1)\, P(w_2)} = \log \cfrac{P(w_1) \, P(w_2 \mid w_1)}{P(w_1)\, P(w_2)} = \log \cfrac{P(w_2 \mid w_1)}{P(w_2)}$


PMI is the amount of information we get when 
* a word $w_1$ occurs at position $i$ 
* and it's followed by $w_2$ at position $i+1$


PMI can generalize to any $n$-grams
* suppose $\mathbf x$ and $\mathbf y$ are vectors (not necessarily of the same dimensions)
* then $\text{PMI}(\mathbf x, \mathbf y) = \log \cfrac{P(\mathbf x, \mathbf y)}{P(\mathbf x)\, P(\mathbf y)}$
* also see the [[#$n$-Gram Collocations]] section


== Estimates ==

=== [[Maximum Likelihood Estimator]] ===
Estimation of $P(w_1)$, $P(w_2)$ and $P(w_1, w_2)$:
* these probabilities are estimated from a corpus 
* typically using [[Maximum Likelihood Estimator]]
* No [[Smoothing for Language Models|Smoothing]] is typically needed because we don't need to generalize to unseen words
* We want to extract collocations from a given corpus, not to build a [[Statistical Language Model]]

[[MLE]] of $P(w_1)$ and $P(w_2)$: 
* $\hat P(w) = \cfrac{c(w)}{N}$, where 
* $c(w)$ is the number of times $w_1$ appeared in the corpus, and 
* $N$ is the total number of tokens


[[MLE]] of $P(w_1, w_2)$
* $P(w_1, w_2) = P(w_1) \, P(w_2 \mid w_1)$, so 
* $\hat P(w_1, w_2) = \hat P(w_1) \, \hat P(w_2 \mid w_1) = \cfrac{c(w_1)}{N} \cdot \cfrac{c(w_1, w_2)}{c(w_1)} = \cfrac{c(w_1, w_2)}{N}$


so MLE estimate of PMI is 
* $\text{PMI}(w_1, w_2) = \log \cfrac{\hat P(w_2 \mid w_1)}{\hat P(w_2)} = \log \left( \cfrac{c(w_1, w_2)}{c(w_1)} \cdot \cfrac{N}{c(w_2)} \right)$


== $n$-Gram Collocations ==
For 3-grams:
* treat $(w_1, w_2)$ as a single var
* $\text{PMI}\Big((w_1, w_2), w_3 \Big) = \log \cfrac{P\big((w_1, w_2), w_3\big)}{P(w_1, w_2)\, P(w_3)} = \log \cfrac{P\big(w_1, w_2, w_3\big)}{P(w_1, w_2)\, P(w_3)}$
** $P(w_1, w_2, w_3) = P(w_1) \, P(w_2 \mid w_1) \, P(w_3 \mid w_1, w_2)$
** $\hat P(w_1, w_2, w_3) = \cfrac{c(w_1)}{N} \cdot \cfrac{c(w_1, w_2)}{c(w_1)} \cdot \cfrac{c(w_1, w_2, w_3)}{c(w_1, w_2)} = \cfrac{c(w_1, w_2, w_3)}{N}$
* So estimate of $\text{PMI}\big((w_1, w_2), w_3\big)$ is 
** $\text{PMI}\big((w_1, w_2), w_3\big) = \log \left( \cfrac{c(w_1, w_2, w_3)}{N} \cdot \cfrac{N}{c(w_1, w_2)} \cdot \cfrac{N}{c(w_3)} \right) = \log \cfrac{N \cdot c(w_1, w_2, w_3)}{c(w_1, w_2) \, c(w_3)}$


For $n$-grams:
* $\text{PMI}\big((w_1, \, ... \, , w_n), w_{n+1} \big) = \log \cfrac{P(w_1, \ ... \ , w_{n+1})}{P(w_1, \ ... \ , w_n)\, P(w_{n+1})}$
* Estimate:
* $\text{PMI}\big((w_1, \, ... \, , w_n), w_{n+1} \big) = \log \cfrac{N \cdot c(w_1, \ ... \ , w_{n+1})}{c(w_1, \ ... \ , w_n) \, w(n_{n+1})}$




== References ==
* McInnes B. T. &quot;Extending the log likelihood measure to improve collocation identification&quot;, 2004.
* Boulis C. &quot;Clustering of Cepstrum Coefficients Using Pairwise Mutual Information&quot;, 2002.
* Tadić M., Šojat K. &quot;Finding multiword term candidates in Croatian&quot;, 2003.
* Gerlof Bouma, &quot;Normalized (Pointwise) Mutual Information in Collocation Extraction&quot; [https://svn.spraakdata.gu.se/repos/gerlof/pub/www/Docs/npmi-pfd.pdf]

== Sources ==
* De Kok D., Brouwer H. &quot;Natural language processing for the working programmer&quot;. 2011. Chapter 3 [http://nlpwp.org/book/chap-ngrams.xhtml] [https://web.archive.org/web/20151026194211/http://nlpwp.org/book/chap-ngrams.xhtml archived version version], [https://scholar.google.com/scholar?cluster=12545221866517295405&amp;as_sdt=0,5 google scholar]
* Manning C. D., Schütze H. &quot;Foundations of statistical natural language processing&quot;, 1999. Chapter 5 [http://nlp.stanford.edu/fsnlp/promo/colloc.pdf]
* Petrović S. et al. &quot;Comparison of collocation extraction measures for document indexing&quot;, 2006. [http://bib.irb.hr/datoteka/251298.110-4-157-203.pdf]

[[Category:Text Mining]]
[[Category:NLP]]</text>
      <sha1>3wc0sms6529wkcnh17n7brak48i7zjk</sha1>
    </revision>
  </page>
  <page>
    <title>Locality Sensitive Hashing</title>
    <ns>0</ns>
    <id>696</id>
    <revision>
      <id>759</id>
      <timestamp>2017-04-25T21:05:48Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Locality Sensitive Hashing == In large databases it's not possible to use brute force search: there's too much data * one way of speeding search up is using Indexing (dat...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11883">== Locality Sensitive Hashing ==
In large databases it's not possible to use brute force search: there's too much data
* one way of speeding search up is using [[Indexing (databases)|Indexing]]: in particular, most interesting indexes are [[Multi-Dimensional Indexes]]
* but many of these &quot;classical&quot; indexing schemes don't work for high dimensional data
* '''Locality-Sensitive Hashing''' algorithms address this problem:
* it's a family of probabilistic/approximate indexing techniques that return the true KNNs most of the time correctly  



LSH algorithms:
* used for quick search of similar entires in larges DBs
* used for Nearest Neighbor (1-NN) queries as well as in [[KNN]] queries 
* these algorithms are ''randomized'': they don't guarantee the exact answer, but rather give a high probability to find the correct answer or a close approximation

* Good similarity/distance function should rank relevant answers much closer to the query than irrelevant 
* if it's the case, approximate answer should also give good result
* Outcome: by allowing some small error and storage overhead, can considerably improve the query time


Basic idea
* hash points s.t. probability of collision is high for similar objects


=== Applications ===
* Finding duplicates and near-duplicates 
* Audio, video, image search
* Pattern Classification
* Cluster Analysis


== Problem Definition ==
=== Nearest Neighbor Search Problem  ===
Notation:
* $\| \mathbf x \|_p = \left( \sum_i |x_i|^p \right)^{1/p}$
* let $d_p(\mathbf p, \mathbf q) = \| \mathbf p - \mathbf q \|_p$
* and let $d_H(\mathbf p, \mathbf q)$ be the [[Hamming Distance]]: # of bits in which $\mathbf p$ and $\mathbf q$ are different


NN Search problem: 
* Given set $P$ of $n$ objects preprocess $P$ s.t. it's effective to find $\mathbf p \in P$ closest to a query object $\mathbf q$ 
* KNN: return top $k$ closest objects $\{ \mathbf p_1 , \ ... \  , \mathbf p_k \}, \mathbf p_i \in P$


$\varepsilon$-NNS problem: 
* approximate version of NNS
* $\mathbf p \in P$ closest to a query object $\mathbf q$  s.t. $d(\mathbf p, \mathbf q) \leqslant (1 + \varepsilon) \cdot d(\mathbf p^*, \mathbf q)$ where $\mathbf p^*$ is the true NN
* can generalize to KNN as well:
* find $\mathbf p_1 , \ ... \  , \mathbf p_k \in P$ s.t. distance $d(\mathbf p_i, \mathbf q)$ is at most $(1 + \varepsilon)$ to the true $i$th closest $\mathbf p^*_i$



=== Most Similar Item Problem ===
* Given a query point $q$ and a database $D$ 
* find $q' \in D$ s.t. $q'$ is the most similar object to $q$ 


Brute force solution:
* try each object in the database and return the closest
* the complexity of executing this query grows linearly with $N = |D|$: number of items in the database


Trees
* e.g. [[kd-Trees]], [[Quad Trees]], [[R-Tree]]s
* the complexity is $O(\log N)$
* problem: when dimensionality is big, they break down, and we end up testing all the nodes - which brings the complexity back to $O(N)$


[[Hash Function|Hashes]]
* A [[Hash Tables|hash table]] is a structure that allows to map between some symbol and some value
* a well-designed hash function should separate two close symbols into different buckets of a hash table
* so hashes are good for &lt;u&gt;exact&lt;/u&gt; matches, but we need to get NN match 

Cryptographic hashes like [[MD5]] or [[SHA1]]:
* change one bit - get a completely different hash 
* but we want to same same hash for close objects
* Solution: Use LSH


=== LSH Problem ===
* given $q$ find closest $q' \in D$ 
* with probability $(1 - \delta)$ we return the true NN


Basic idea:
* use LSH: a special hash function that would put points that are close together to the same point
* if two points are close together in high-dimensional space, then they should remain close together after some projection to a lower-dimensional space 


Illustration:
* suppose we have a 3D sphere with points on it
* if we project the sphere on 2D, then close points should still remain close - no matter how we rotate the sphere
* if points are far apart, usually in the projection they are also far apart, but sometimes they become close
* https://habrastorage.org/files/047/fee/e74/047feee74b6c45bab8525323d579d6c6.png
* (Source: fig1 of Slaney2008)



Formalization:
* let $D(\cdot, \cdot)$ be a distance function of elements from $P$
* then for each $\mathbf p \in P$ let $B(\mathbf p, r)$ be a set of elements within distance $r$ from $\mathbf p$


A family of hash functions $\mathcal H$ is $(r_1, r_2, p_1, p_2)$-sensitive if 
* for all $\mathbf p, \mathbf q$
* if $\mathbf p \in B(\mathbf q, r_1)$ then $P_{\mathcal H} \Big[ h(\mathbf q) = h(\mathbf p)  \Big] \geqslant p_1$
* if $\mathbf p \not \in B(\mathbf q, r_2)$ then $P_{\mathcal H} \Big[ h(\mathbf q) = h(\mathbf p)  \Big] \leqslant p_2$


LSH:
* A LSH family is useful when $p_1 &gt; p_2$ and $r_1 &lt; r_2$
* The algorithin solves $(r, \varepsilon)$-NN problem if
* if there exists a $\mathbf p^* \in B(\mathbf q, r_1)$ then $g_j(\mathbf p^*) = g_j(\mathbf q)$ for at least one $j$ 


Common for almost all LSH families. Outline:
* input space $P$ 
* define a family $\mathcal H = \{ h \, P \to \mathbb R \}$ that maps original datapoint to some real value: $h(\mathbf v) \in \mathbb R$
* next define a family of hash functions $\mathcal G = \{ g: P \to \mathbb R^k \}$ s.t. a $g$ takes $k$ different $h_i \in \mathcal H$ functions: 
* $g(\mathbf v) = \[ h_1(\mathbf v), h(\mathbf v), \ ... \ , h_k(\mathbf v) \] \in \mathbb R^k$
* then take $L$ such $g$ functions from $\mathcal G$: $g_1, g_2, \ ... \ , g_L$ 


Preprocessing: 
* store each $\mathbf v \in P$ in bucket $g_j(\mathbf v)$ for all $j = 1 \ .. \ L$
* (can do second hashing to put $g_j(\mathbf v) \in \mathbb R^k$ to a usual [[Hash Table]])

Querying:
* given query $\mathbf q$ 
* search all buckets $g_1(\mathbf q), g_2(\mathbf q), \ ... \ ,g_L(\mathbf q)$
* optional: if number of possible candidates is too large - interrupt after some time, e.g. after first $3L$ items (including duplicates)
* then use linear search to find $k$NN


$k$ and $L$ are parameters chosen s.t.:
* if there exists some $\mathbf v^* \in B(\mathbf q, r_1)$ then $g_j(\mathbf v^*) = g_j(\mathbf q)$ for at least one $g_j$
* total number of collisions on $\mathbf q$ with points from outside $B(\mathbf q, r_1)$ is less than $3L$


A hash function family is ''locality-sensitive'' if 
* &quot;similar&quot; $\mathbf v_1, \mathbf v_2$ - e.g. big $\text{sim}(\mathbf v_1, \mathbf v_2)$ for some [[Similarity Measure]] or small $d(\mathbf v_1, \mathbf v_2)$ for some distance measure 
* they should collide: have same hash value with high probability



== LSH Families ==
=== Hamming LSH ===
* Or [[Bit Sampling LSH]] or &quot;the&quot; LSH (Gionis99)
* Approximated distance: Hamming Distance

=== E2 LSH ===
* Or p-stable LSH or random projection/quantization LSH
* [[Euclidean LSH]] often called E2LSH in the literature
* Approximated Distance: Euclidean Distance 

=== [[MinHash]]  ===
* aka Min-Wise independent permutations
* Approximated similarity: Jaccard

=== [[SimHash]] ===
* http://matpalm.com/resemblance/simhash/

=== [[Random Binary Projection]] ===
* Approximated similarity: Cosine
* Approximated Distance: Cosine Distance (1 - cosine)
* http://stackoverflow.com/questions/12952729/how-to-understand-locality-sensitive-hashing
* http://www.cs.jhu.edu/~vandurme/papers/VanDurmeLallACL10-slides.pdf

=== [[K-Means LSH]] ===
* uses the structure of underlying data to find the best hash functions 
* &quot;learns&quot; the hash functions via [[K-Means]]

=== Bayesian LSH ===
* Satuluri, V., Parthasarathy, S. &quot;Bayesian locality sensitive hashing for fast similarity search.&quot; 2012. [http://arxiv.org/abs/1110.1328]


== Fewer Hash Tables ==
Ways to improve LSH
* usually applicable to different LSH Families

Drawback of conventional LSH schemes:
* to guarantee a good quality need to have many hash tables
* it's a large space requirement for index
* also, in distributed settings it leads to large network load: each hash bucket lookup requires a communication over the network

Hash tables reducing techniques: 
* the hash tables occupy a lot of space
* can we have fewer tables but still maintain the same level of performance?  

Space requirements:
* each hash table has the same size as the entire dataset (i.e. if dataset has $N$ entries, then the hash index also has $N$ entries)


=== Entropy LSH ===
Reduces the number of hash tables 
* the indexing (hashing) stage stays the same, but $L$ is smaller than usual

uses different procedure for querying:
* hashes $\mathbf q$ as usual LSH
* but also hashes the query offsets - and sees where the offsets map to

Idea: 
* close objects are likely to be in the same bucket as the query - but also in the buckets nearby
* generate query offsets to hit the nearby buckets as well 
* this reduces the number of hash tables 

But:
* it doesn't help with network efficiency: 
* all $\mathbf q$ + offsets each require a network call
* number of query offsets required by Entropy LSH is larger than the number of hashtables in the original scheme: it's even less network efficient than usual LSHs


Panigrahy, Rina. &quot;Entropy based nearest neighbor search in high dimensions.&quot; 2006. [http://arxiv.org/abs/cs/0510019]


=== Multi-Probe LSH ===
How to increase the quality of LSH? 

Probe multiple times 
* it increases the scope of search and gives better [[Precision and Recall]]
* idea: try to look for hash buckets nearby

Lv, Qin, et al. &quot;Multi-probe LSH: efficient indexing for high-dimensional similarity search.&quot; 2007.


=== Distributed Layered LSH ===
Layered LSH
* carefully designed implementation of Entropy LSH

idea: 
* distribute hash buckets in such a way that near points are likely to be on the same machine (so get network efficiency)
* while fair away points are likely to be on different machines (so get load balance)


Achieved by rehashing 
* rehash the bucket IDs for both data and query via additional layer of LSH 
* and then use the hashed buckets as keys


Reference:
* Bahmani, Bahman, Ashish Goel, and Rajendra Shinde. &quot;Efficient distributed locality sensitive hashing.&quot; 2012. [http://arxiv.org/abs/1210.7057]
* there's a MapReduce implementation and Storm implementation in the paper



== Other Meta LSHs ==
=== Query-Adaptive LSH ===
This method adapts its behavior: 
* it picks those hash functions that are most likely to return the NN

Usual Query-Adaptive LSH:
* define a pool of $L$ hash functions (with $L$ larger than in usual LSHs)
* compute relevance criteria $\lambda_i$ for each $g_i$: this criteria identifies the hash functions that are more likely to return the NNs 
* relevance could be: distance between the query and the center of the cell 


Jégou, Hervé, et al. &quot;Query adaptative locality sensitive hashing.&quot; 2008. [[https://hal.inria.fr/inria-00318614/document]]


== Comparisons ==
* http://arxiv.org/abs/1206.2082
* minhash vs simhash: Henzinger, Monika (2006), &quot;Finding near-duplicate web pages: a large-scale evaluation of algorithms&quot; [http://infoscience.epfl.ch/record/99373/files/Henzinger06.pdf]



== Sources ==
* Slaney, Malcolm, and Michael Casey. &quot;Locality-sensitive hashing for finding nearest neighbors [lecture notes].&quot; 2008. [http://web.iitd.ac.in/~sumeet/Slaney2008-LSHTutorial.pdf]
* Gionis, Aristides, Piotr Indyk, and Rajeev Motwani. &quot;Similarity search in high dimensions via hashing.&quot; 1999. [http://www.cs.princeton.edu/courses/archive/spring13/cos598C/Gionis.pdf]
* Datar, Mayur, et al. &quot;Locality-sensitive hashing scheme based on p-stable distributions.&quot; 2004. [http://www.cs.princeton.edu/courses/archive/spring05/cos598E/bib/p253-datar.pdf]
* Paulevé, Loïc, et al. &quot;Locality sensitive hashing: A comparison of hash function types and querying mechanisms.&quot; 2010. [https://hal.inria.fr/inria-00567191/document]



[[Category:Hashing]]
[[Category:LSH]]
[[Category:Database Indexes]]
[[Category:Information Retrieval]]</text>
      <sha1>e56uqfibun569qubmv9n23idrbenut4</sha1>
    </revision>
  </page>
  <page>
    <title>Bit Sampling LSH</title>
    <ns>0</ns>
    <id>697</id>
    <revision>
      <id>760</id>
      <timestamp>2017-04-26T20:05:17Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Bit Sampling LSH == * LSH for the [[Hamming Distance]] * can convert [[Manhattan Distance|$L_1$]] to Hamming distance * NNs are usually the same for $L_1$ and Euclidean D...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5281">== Bit Sampling LSH ==
* LSH for the [[Hamming Distance]]
* can convert [[Manhattan Distance|$L_1$]] to Hamming distance
* NNs are usually the same for $L_1$ and [[Euclidean Distance|$L_2$]] 
** see Figiel et al. &quot;The dimension of almost spherical sections of convex bodies.&quot; 1977. [http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.308.2113]
* so it can be (&quot;sort of&quot;) used for Euclidean spaces


=== Hamming LSH ===
Suppose we have $P = \{ \mathbf p_i \}$ where $\mathbf p_i \in H^{d} = \{0, 1\}^{d}$ - i.t. points are in the (binary) [[Hamming Space]] of dimensionality $d$ (or $Cd$, in $C$ chunks of size $d$)


Hash Functions
* sample $L$ subsets $I_1, \ ... \ , I_L$ of size $k$ uniformly (with replacement) from \{1 \ ... \ d \}$
* let $g_j(\mathbf p)$ be the projection of $\mathbf p$ on $I_j$: it selects coordinate positions per $I_j$ and concatenates bits on these positions


=== Indexing ===
Preprocessing (indexing):
* store each $\mathbf p \in P$ in the bucket $g_j(\mathbf p)$ for all $j = 1 \, .. \, L$
* total number of resulting buckets may be large ($g_j(\mathbf p)$'s are sparse), so reduce the desparsify and reduce dimensionality using usual hashing


So have two levels of hashing:
* LSH Hash to map $\mathbf p$ to bucket $g_j(\mathbf p)$
* standard hash function to map $g_j(\mathbf p)$ to a hash table of size $M$ 


Pseudocode:
* Input: database $P$, number of hash tables $L$
* Output: $L$ hash tables $\tau_j$
* generate $L$ random hash functions $g_j(\cdot)$  - for each $\tau_j$
* for each $\mathbf p_i \in P$ and for each $(g_j, \tau_j)$:
* $\tau_j\big[ g_j(\mathbf p_i) \big] = \mathbf p_i$



=== Querying ===
Querying: 
* given $\mathbf q$ 
* search all buckets $g_j(\mathbf q)$ until:
* either encounter $c \cdot L$ points ($c$ to be specified)
* or checked all $L$ indexes
* then for all candidates keep only $K$ closest


Pseudocode:
* input: 
** a query point $\mathbf q$, 
** number of nearest neighbors $K$,
** $L$ tables $\tau_i$ 
* output: $K$ (or less) NNs
* let $S \leftarrow \varnothing$ be a candidate list
* for each  $(g_j, \tau_j)$
** $S \leftarrow S \cup \tau_j \big[ g_j(\mathbf q) \big]$
* return $K$NNs from $S$ (can be found using linear search)


=== Parameters ===
* $L$: number of subsets $I_j$'s and hence the # of hash functions
* $k$: size of $I_j$'s: $k$ is chosen s.t. 
** it maximizes the probability that if $\mathbf p$ is close to $\mathbf q$, then they must end up in the same bucket
** it minimizes the prob that if $\mathbf p$ and $\mathbf q$ ending up in the same bucket when $\mathbf p$ is not close to $\mathbf q$
** $k \approx 700$ is a good value for $d \approx 64$ 


=== Embedding $L_1$ to Hamming ===
For converting from $L_1$ to Hamming:
* All $\mathbf p \in P$ are positive integers 
* coordinates may be made all-positive by translating the origin


Let $C$ be the largest coordinate in all points in $P$
* then we can embed $P$ into a Hamming cube $\{0, 1\}^{Cd}$ where $d$ is the dimensionality of the original space

* transform each $\mathbf p = (p_1, \ ... \ , p_d$ into a binary vector:
* let $v(\mathbf p) = \big( \text{unary}_C(p_1), \ ... \ , \text{unary}_C(p_d) \big)$
* $\text{unary}_C(p)$ denotes the binary representation of $p$: a sequence of $p$ ones followed by $C - p$ zeros
* e.g. for $C = 10$ and $p = 4$, we'd have $\text{unary}_{10}(4) = 11110 \, 00000$
* for a vector $\mathbf p = (3, 4, 5)$ we would have $v(\mathbf p) = ( 11100 \, 00000 \, 11110 \, 00000 \, 11111 \, 00000 )$


Now, 
* if $\mathbf p, \mathbf q \in \{1 \, .. \, C \}$ 
* then $d_1 \big(\mathbf p, \mathbf q \big) = d_H \big(v(\mathbf p), v(\mathbf q) \big)$
* i.e. this embedding preserves the $L_1$ distance between points



Mapping $\mathbf p \in \mathbb R^d$ to $\mathbf p' \in H^{Cd}$: (effective hashing calculation)
* choose $I$: a $k$-vector of indexes sampled from $\{0, \, .. \, C \}$
* we need to compute a projection on $I$
* for each component $p_i$ of $\mathbf p$ do:
** let $I^{(i)}$ denote coordinates of $I$ that correspond to $p_i$ 
*** these are some of the $C$ coordinates of $p_i$ in the Hamming embedding that got selected in $I$
** order indexes inside $I^{(i)}$
** when we project $\mathbf p$ on $I^{(i)}$, the result is a monotone sequence of bits: there are 1's followed by 0's 
** let $o_i$ be the number of 1's of $p_i$
** let $\mathbf p'_i$ denote the part of $\mathbf p'$ that corresponds to coordinate $p_i$
** so, to represent $\mathbf p'_i$ it's enough to know only $o_i$ 
* thus $\mathbf p'$ can be represented by $\{o_1, o_2, \ ... \ , o_d \}$


Computing $o_i$ fast:
* there's a way to compute $o_i$ fast
* finding $o_i$ is equivalent to finding the number of elements in sorted array $I^{(i)}$ which are smaller than $p_i$
* can be done via Binary Search in $O(\log C)$
* or even in constant time if we use a precomputed array of $C$ bits 


Total projection time
* then total time to project $\mathbf p$ to $\mathbf p'$ is 
* $O(d \, \log C)$ for Binary Search or
* $O(d)$ for precomputed arrays



== Sources ==
* Gionis, Aristides, Piotr Indyk, and Rajeev Motwani. &quot;Similarity search in high dimensions via hashing.&quot; 1999. [http://www.cs.princeton.edu/courses/archive/spring13/cos598C/Gionis.pdf]

[[Category:Hashing]]
[[Category:LSH]]
[[Category:Database Indexes]]</text>
      <sha1>keetxppd1wy9f6ywiyrm7rx97bwz36l</sha1>
    </revision>
  </page>
  <page>
    <title>LSH</title>
    <ns>0</ns>
    <id>698</id>
    <redirect title="Locality Sensitive Hashing" />
    <revision>
      <id>761</id>
      <timestamp>2017-04-26T20:08:38Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Redirected page to [[Locality Sensitive Hashing]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="40">#REDIRECT [[Locality Sensitive Hashing]]</text>
      <sha1>jskfbjvighys1to46ney749nn8mn1ts</sha1>
    </revision>
  </page>
  <page>
    <title>Euclidean LSH</title>
    <ns>0</ns>
    <id>699</id>
    <revision>
      <id>762</id>
      <timestamp>2017-04-26T20:11:05Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Euclidean LSH == Euclidean LSH - [[LSH]] for the [[Euclidean Distance|Euclidean Space]] * Also called E2LSH or $p$-stable LSH * Unlike [[Bit Sampling LSH]] this LSH Family...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7210">== Euclidean LSH ==
Euclidean LSH - [[LSH]] for the [[Euclidean Distance|Euclidean Space]]
* Also called E2LSH or $p$-stable LSH
* Unlike [[Bit Sampling LSH]] this LSH Family words directly on $L_p$ without embedding it into [[Hamming Distance|Hamming Space]]


== $p$-Stable Distributions ==
A family of hash functions $\mathcal H$ is $(r_1, r_2, p_1, p_2)$-sensitive if 
* for all $\mathbf p, \mathbf q$
* if $\mathbf p \in B(\mathbf q, r_1)$ then $P_{\mathcal H} \Big[ h(\mathbf q) = h(\mathbf p)  \Big] \geqslant p_1$
* if $\mathbf p \not \in B(\mathbf q, r_2)$ then $P_{\mathcal H} \Big[ h(\mathbf q) = h(\mathbf p)  \Big] \leqslant p_2$

Here: choose $r_1 = R$ and $r_2 = c \cdot R$


A [[Probability Distribution]] $D$ over $\mathbb R$ is $p$-stable 
* if there exists $p \geqslant 0$ s.t. for any $n$ real numbers $v_1, ..., v_n$
* and iid samples from distribution $D$: $\ X_1, X_2, \ ... \ , X_n \sim D$
* the [[Random Variable]] $\sum v_i \, X_i$ follows the same distribution as $\left( \sum |v_i|^p \right)^{1/p} \cdot X = \| \mathbf v \| \cdot X$ where $X \sim D$


Known $p$-stable Distribution:
* [[Cauchy Distribution]] for $p = 1$
* [[Gaussian Distribution]] for $p = 2$ 

In CS $p$-stable distributions are useful for [[Sketching]]
* can be used to estimate $\| \mathbf v \|_p$


Papers:
* Nolan, J. &quot;Stable distributions.&quot; 2009. [http://academic2.american.edu/~jpnolan/stable/stable.html] [http://academic2.american.edu/~jpnolan/stable/chap1.pdf]
* Indyk, Piotr. &quot;Stable distributions, pseudorandom generators, embeddings, and data stream computation.&quot; 2006. [http://old-madalgo.au.dk/img/SumSchoo2007_Lecture%20slides/Bibliography/p3-Indyk_JACM_06.pdf]


== E2 LSH ==
A hash function family is ''locality-sensitive'' if 
* &quot;similar&quot; $\mathbf v_1, \mathbf v_2$ - i.e. have small $\| \mathbf v_1 - \mathbf v_2 \|_p$ 
* they should collide: have same hash value with high probability


Consider $\mathbf a \cdot \mathbf v$ - it's a projection of $\mathbf v$ to a real line 
* it follows from the $p$-stability that for two $\mathbf v_1, \mathbf v_2$ distance between the projections $\mathbf a \cdot \mathbf v_1 - \mathbf a \cdot \mathbf v_2$ is distributed as $\| \mathbf v_1 - \mathbf v_2 \|_p \cdot X$ 
* so if we chop the real line into equi-width segments of $w$, then the hash functions should be locality-preserving


=== Random Projections ===
The [[Dot Product]] is a projection 
* this is at the core of LSH
* let $\mathbf v$ be the query and $\mathbf x$ some random vector with each $x_i \sim N(0, 1)$ (components of $\mathbf x$ are sampled from the [[Normal Distribution]]) 
* the hash function is then defined as $h(\mathbf v) = \mathbf v \cdot \mathbf x$

Quantization:
* then we quantize $h(\mathbf v)$ into a set of hash buckets - hoping that nearby items will fall into the same bin
* i.e. we get the following hash function:
* $h_{\mathbf x, b}(\mathbf v) = \left\lfloor \cfrac{\mathbf v \cdot \mathbf x + b}{w} \right\rfloor$
* where $w$ is the length of each quantization bucket
* and $b$ is a [[Random Variable]] sampled from the [[Uniform Distribution]]: $b \sim \text{unif}[0, w]$
* $w$ - quantization step


Requirements for the projection operator
* let $\mathcal H$ be a family of LSH functions
* for any $\mathbf p, \mathbf q \in \mathbb R^d$ that are close to each other, i.e. for $\|\mathbf p - \mathbf q \| \leqslant R_1$
* probability that they end up in the same bucket should be high, i.e. $P_{\mathcal H} \Big[ h(\mathbf p) = h(\mathbf q) \Big] \geqslant p_1$ 
* if $\mathbf p, \mathbf q$ are far apart, i.e. $\|\mathbf p - \mathbf q \| \geqslant R_2$
* probability that they end up in the same bucket is low, i.e. $P_{\mathcal H} \Big[ h(\mathbf p) = h(\mathbf q) \Big] \leqslant p_2$


I.e. $\| h(\mathbf p) - h(\mathbf q) \| \sim \| \mathbf p - \mathbf q \|$ ($\sim$ = &quot;distributed proportionally to&quot;)



=== $L$ Random Projections ===
Can magnify the difference between $P_1$ and $P_2$ by performing projection on $K$ random directions in parallel

$\left( \cfrac{p_1}{p_2} \right)^K &gt; \cfrac{p_1}{p_2}$


* So given a query $\mathbf v$ apply $K$ individual dot products
* and obtain $K$ real numbers $h_i (\mathbf v) \in \mathbb R$ (all quantified - i.e. put into buckets - separately)
* so $H(\mathbf v) = \Big[ h_1(\mathbf v), h_2(\mathbf v), \ ... \ , h_K(\mathbf v) \Big] \in \mathbb R^K$


Now we say that $\mathbf u$ is a NN candidate for $\mathbf v$ if they end up in the same bucket, i.e. $H(\mathbf u) = H(\mathbf v)$ (for all $h_i(\cdot)$)


Note that for $K$ dot products the probability of having the same bucket is $p_1^K$ - which decreases as we increase $K$
* to reduce this effect form $L$ independent projections - i.e. we'll have $L$ hash functions $H_1, \ ... \ , H_L$
* then $\mathbf u$ is a candidate if it ends up in the same bucket as $\mathbf v$ for at least one projection $H_i$
* it's very unlikely that the true NN will be absent in all $L$ bins


=== Hash Implementation ===
(E2 LSH)

$\{ H_i \}$ put each data point into a hash bucket described by $K$-vector 
* this $K$-dim space is very sparse - can densify it 
* use exact hashes - i.e. &quot;classical&quot; [[Hash Tables]] for this
* so let $T_1(\mathbf v) = \mathbf w_2^T H(\mathbf v)  \ \mod P_1$ for some random weight vector $\mathbf w$ and a big prime number $P_1$ (which is also the size of the hash table)


Unrelated points may collide to the same bucket 
* how to handle it? 
* have another function $T_2$ with different weights $\mathbf w_2$ and $P_2$
* let $T_2(\mathbf v)$ be the &quot;fingerprint&quot; of $\mathbf v$ 
* we store the fingerprint of $\mathbf v$ in the bin chosen by $T_1$
* then during retrieval we can find the true match by comparing fingerprints: they are short and their comparison is fast
* chances that both $T_1$ and $T_2$ collide are very small


Accuracy 
* accuracy is determined by the probability it will find the true NN


=== $p$-Stable Distributions ===
A distribution is $p$-stable if 
* for iid sample $X_1, \ ... \ , X_n \sim D$
* for any $v_1, \ ... \ , v_n \in \mathbb R$ 
* $\sum v_i \, X_i$ follows the same distribution as the random variable $\left( \sum_i \|v_i \big \|_p \right)^{1 / p} \cdot X$
* where $\| \, \cdot \, \|_p$ is $L_p$ norm
* and $X \sim D$
* [[Probability Density Function|PDF]] of this RV is $f_p$


For $p=2$ Gaussian is $p$-stable

What it means:
* $\mathbf u = \| \mathbf p - \mathbf q \|$ will always be small if $\mathbf p$ and $\mathbf q$ are close 
* but because of quantization they may end up in different buckets 


Probability of getting to the same bucket: 
* $P_{\mathbf a, b} = P \Big [ h_{\mathbf a, b}(\mathbf p) = h_{\mathbf a, b}(\mathbf q)  \Big] = \int\limits_{0}^{w} \frac{1}{\mathbf u} \cdot f_p(\frac{t}{\mathbf u}) \, (1 - \frac{t}{w}) , \text{d}t$


== Sources ==
* Slaney, Malcolm, and Michael Casey. &quot;Locality-sensitive hashing for finding nearest neighbors [lecture notes].&quot; 2008. [http://web.iitd.ac.in/~sumeet/Slaney2008-LSHTutorial.pdf]
* Datar, Mayur, et al. &quot;Locality-sensitive hashing scheme based on p-stable distributions.&quot; 2004. [http://www.cs.princeton.edu/courses/archive/spring05/cos598E/bib/p253-datar.pdf]

[[Category:Hashing]]
[[Category:LSH]]
[[Category:Database Indexes]]</text>
      <sha1>5x76awt8h0bqq2l4a2t7wzm76zx83ft</sha1>
    </revision>
    <revision>
      <id>763</id>
      <parentid>762</parentid>
      <timestamp>2017-04-26T20:13:29Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7174">== Euclidean LSH ==
Euclidean LSH - [[LSH]] for the [[Euclidean Space]]
* Also called E2LSH or $p$-stable LSH
* Unlike [[Bit Sampling LSH]] this LSH Family words directly on $L_p$ without embedding it into [[Hamming Space]]


== $p$-Stable Distributions ==
A family of hash functions $\mathcal H$ is $(r_1, r_2, p_1, p_2)$-sensitive if 
* for all $\mathbf p, \mathbf q$
* if $\mathbf p \in B(\mathbf q, r_1)$ then $P_{\mathcal H} \Big[ h(\mathbf q) = h(\mathbf p)  \Big] \geqslant p_1$
* if $\mathbf p \not \in B(\mathbf q, r_2)$ then $P_{\mathcal H} \Big[ h(\mathbf q) = h(\mathbf p)  \Big] \leqslant p_2$

Here: choose $r_1 = R$ and $r_2 = c \cdot R$


A [[Probability Distribution]] $D$ over $\mathbb R$ is $p$-stable 
* if there exists $p \geqslant 0$ s.t. for any $n$ real numbers $v_1, ..., v_n$
* and iid samples from distribution $D$: $\ X_1, X_2, \ ... \ , X_n \sim D$
* the [[Random Variable]] $\sum v_i \, X_i$ follows the same distribution as $\left( \sum |v_i|^p \right)^{1/p} \cdot X = \| \mathbf v \| \cdot X$ where $X \sim D$


Known $p$-stable Distribution:
* [[Cauchy Distribution]] for $p = 1$
* [[Gaussian Distribution]] for $p = 2$ 

In CS $p$-stable distributions are useful for [[Sketching]]
* can be used to estimate $\| \mathbf v \|_p$


Papers:
* Nolan, J. &quot;Stable distributions.&quot; 2009. [http://academic2.american.edu/~jpnolan/stable/stable.html] [http://academic2.american.edu/~jpnolan/stable/chap1.pdf]
* Indyk, Piotr. &quot;Stable distributions, pseudorandom generators, embeddings, and data stream computation.&quot; 2006. [http://old-madalgo.au.dk/img/SumSchoo2007_Lecture%20slides/Bibliography/p3-Indyk_JACM_06.pdf]


== E2 LSH ==
A hash function family is ''locality-sensitive'' if 
* &quot;similar&quot; $\mathbf v_1, \mathbf v_2$ - i.e. have small $\| \mathbf v_1 - \mathbf v_2 \|_p$ 
* they should collide: have same hash value with high probability


Consider $\mathbf a \cdot \mathbf v$ - it's a projection of $\mathbf v$ to a real line 
* it follows from the $p$-stability that for two $\mathbf v_1, \mathbf v_2$ distance between the projections $\mathbf a \cdot \mathbf v_1 - \mathbf a \cdot \mathbf v_2$ is distributed as $\| \mathbf v_1 - \mathbf v_2 \|_p \cdot X$ 
* so if we chop the real line into equi-width segments of $w$, then the hash functions should be locality-preserving


=== Random Projections ===
The [[Dot Product]] is a projection 
* this is at the core of LSH
* let $\mathbf v$ be the query and $\mathbf x$ some random vector with each $x_i \sim N(0, 1)$ (components of $\mathbf x$ are sampled from the [[Normal Distribution]]) 
* the hash function is then defined as $h(\mathbf v) = \mathbf v \cdot \mathbf x$

Quantization:
* then we quantize $h(\mathbf v)$ into a set of hash buckets - hoping that nearby items will fall into the same bin
* i.e. we get the following hash function:
* $h_{\mathbf x, b}(\mathbf v) = \left\lfloor \cfrac{\mathbf v \cdot \mathbf x + b}{w} \right\rfloor$
* where $w$ is the length of each quantization bucket
* and $b$ is a [[Random Variable]] sampled from the [[Uniform Distribution]]: $b \sim \text{unif}[0, w]$
* $w$ - quantization step


Requirements for the projection operator
* let $\mathcal H$ be a family of LSH functions
* for any $\mathbf p, \mathbf q \in \mathbb R^d$ that are close to each other, i.e. for $\|\mathbf p - \mathbf q \| \leqslant R_1$
* probability that they end up in the same bucket should be high, i.e. $P_{\mathcal H} \Big[ h(\mathbf p) = h(\mathbf q) \Big] \geqslant p_1$ 
* if $\mathbf p, \mathbf q$ are far apart, i.e. $\|\mathbf p - \mathbf q \| \geqslant R_2$
* probability that they end up in the same bucket is low, i.e. $P_{\mathcal H} \Big[ h(\mathbf p) = h(\mathbf q) \Big] \leqslant p_2$


I.e. $\| h(\mathbf p) - h(\mathbf q) \| \sim \| \mathbf p - \mathbf q \|$ ($\sim$ = &quot;distributed proportionally to&quot;)



=== $L$ Random Projections ===
Can magnify the difference between $P_1$ and $P_2$ by performing projection on $K$ random directions in parallel

$\left( \cfrac{p_1}{p_2} \right)^K &gt; \cfrac{p_1}{p_2}$


* So given a query $\mathbf v$ apply $K$ individual dot products
* and obtain $K$ real numbers $h_i (\mathbf v) \in \mathbb R$ (all quantified - i.e. put into buckets - separately)
* so $H(\mathbf v) = \Big[ h_1(\mathbf v), h_2(\mathbf v), \ ... \ , h_K(\mathbf v) \Big] \in \mathbb R^K$


Now we say that $\mathbf u$ is a NN candidate for $\mathbf v$ if they end up in the same bucket, i.e. $H(\mathbf u) = H(\mathbf v)$ (for all $h_i(\cdot)$)


Note that for $K$ dot products the probability of having the same bucket is $p_1^K$ - which decreases as we increase $K$
* to reduce this effect form $L$ independent projections - i.e. we'll have $L$ hash functions $H_1, \ ... \ , H_L$
* then $\mathbf u$ is a candidate if it ends up in the same bucket as $\mathbf v$ for at least one projection $H_i$
* it's very unlikely that the true NN will be absent in all $L$ bins


=== Hash Implementation ===
(E2 LSH)

$\{ H_i \}$ put each data point into a hash bucket described by $K$-vector 
* this $K$-dim space is very sparse - can densify it 
* use exact hashes - i.e. &quot;classical&quot; [[Hash Tables]] for this
* so let $T_1(\mathbf v) = \mathbf w_2^T H(\mathbf v)  \ \mod P_1$ for some random weight vector $\mathbf w$ and a big prime number $P_1$ (which is also the size of the hash table)


Unrelated points may collide to the same bucket 
* how to handle it? 
* have another function $T_2$ with different weights $\mathbf w_2$ and $P_2$
* let $T_2(\mathbf v)$ be the &quot;fingerprint&quot; of $\mathbf v$ 
* we store the fingerprint of $\mathbf v$ in the bin chosen by $T_1$
* then during retrieval we can find the true match by comparing fingerprints: they are short and their comparison is fast
* chances that both $T_1$ and $T_2$ collide are very small


Accuracy 
* accuracy is determined by the probability it will find the true NN


=== $p$-Stable Distributions ===
A distribution is $p$-stable if 
* for iid sample $X_1, \ ... \ , X_n \sim D$
* for any $v_1, \ ... \ , v_n \in \mathbb R$ 
* $\sum v_i \, X_i$ follows the same distribution as the random variable $\left( \sum_i \|v_i \big \|_p \right)^{1 / p} \cdot X$
* where $\| \, \cdot \, \|_p$ is $L_p$ norm
* and $X \sim D$
* [[Probability Density Function|PDF]] of this RV is $f_p$


For $p=2$ Gaussian is $p$-stable

What it means:
* $\mathbf u = \| \mathbf p - \mathbf q \|$ will always be small if $\mathbf p$ and $\mathbf q$ are close 
* but because of quantization they may end up in different buckets 


Probability of getting to the same bucket: 
* $P_{\mathbf a, b} = P \Big [ h_{\mathbf a, b}(\mathbf p) = h_{\mathbf a, b}(\mathbf q)  \Big] = \int\limits_{0}^{w} \frac{1}{\mathbf u} \cdot f_p(\frac{t}{\mathbf u}) \, (1 - \frac{t}{w}) , \text{d}t$


== Sources ==
* Slaney, Malcolm, and Michael Casey. &quot;Locality-sensitive hashing for finding nearest neighbors [lecture notes].&quot; 2008. [http://web.iitd.ac.in/~sumeet/Slaney2008-LSHTutorial.pdf]
* Datar, Mayur, et al. &quot;Locality-sensitive hashing scheme based on p-stable distributions.&quot; 2004. [http://www.cs.princeton.edu/courses/archive/spring05/cos598E/bib/p253-datar.pdf]

[[Category:Hashing]]
[[Category:LSH]]
[[Category:Database Indexes]]</text>
      <sha1>4b5qucxl9rxftvnxlw92sf8nb98x417</sha1>
    </revision>
  </page>
  <page>
    <title>K-Means LSH</title>
    <ns>0</ns>
    <id>700</id>
    <revision>
      <id>766</id>
      <timestamp>2017-04-26T21:03:13Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== K-Means LSH == Many of [[Locality Sensitive Hashing|LSH families]] are structured quantizers: they don't take into account underlying statistics * for example, Euclidean...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3726">== K-Means LSH ==
Many of [[Locality Sensitive Hashing|LSH families]] are structured quantizers: they don't take into account underlying statistics
* for example, [[Euclidean LSH|E2LSH]] is structured:
* we choose only quantization step $w$ and offset $b$ and have little influence on the density of individual cells
* but can address this issue by learning a [[Vector Quantizer]] - such as [[K-Means]]: this way we can adapt the cell size to the density of the space in the cell


=== Learning Density with K-Means ===
Unstructured [[Vector Quantizer|VQ]]: 
* let $\mathcal R \to [ \, 1, 2, \ ... \ , k \, ]$
* and $\mathbf x \to g(\mathbf x) = \mathop{arg min}\limits_{i = 1..k} L_2(\mathbf x, \boldsymbol \mu_i)$ 
* it maps each vector to a cell indexed by $g(\mathbf x)$
* $k$ is # of possible values of $g(\cdot)$
* $\boldsymbol \mu_i$ are centroids - they define the quantizer 
* often learned with [[K-Means]]



Illustration:
* https://habrastorage.org/files/6ec/d01/8e3/6ecd018e30b74a4ea977186ec9809bd3.png
* Euclidean LSH (Random Projection LSH) vs K-Means
* K-Means adapts to data while others don't
* source: Paulevé2010 figure 3



== KLSH: K-Means LSH ==
=== Preprocessing ===
How to use K-Means to build a LSH?
* generate $L$ different clusterings on the same data by using different seeds
* after this we have $L$ codebooks (sets of centroids) $\{\mathbf c_{j1}, \ ... \ , \mathbf c_{jk}\}$, where $\mathbf c_{ji}$ is $i$th centroid of $j$'s clustering
* each centroid is an $h$ and codebooks is an $g$ in LSH

Indexing:
* a vector to index is assigned to the closest centroid found in a codebook
* use $L$ codebooks to have $L$ cluster assignments 


=== Querying ===
Search time: 
* first nearest centroid for each codebook
* then keep only vectors that are assignment to the same centroids


query($\mathbf q$)
* $\text{res} = \varnothing$
* for $j = 1$ to $L$ do
** $i^* = \operatorname{arg\, mix}\limits_{i = 1 .. k} \| \mathbf q, \mathbf c_{ji} \|$
** $\text{res} = \text{res} \cup \big\{  \text{cluster}(\mathbf c_{ji^*}) \big\}$
* return $\text{res}$


== Improvements ==
=== Multi-Probing ===
[[Multi-Probe LSH|Multi-Probing]] for K-Means LSH:
* fix $m_p$ the number of buckets we want to retrieve 
* for each $L$ hash functions 
** select $m_p$ closets centroids 
** then return all vectors from these $m_p$ centroids 


=== Query-Adaptive K-Means LSH ===
Idea: 
* a variation of [[Query-Adaptive LSH]] for K-Means LSH
* instead of a single k-means per hash maintain a pool of independent clustering results 
* at the query time select the best one from the pool


Usual Query-Adaptive LSH:
* define a pool of $L$ hash functions (with $L$ larger than in usual LSHs)
* compute relevance criteria $\lambda_j$ for each $g_j$: this criteria identifies the hash functions that are more likely to return the NNs 
* relevance could be: distance between the query and the center of the cell 


Query-Adaptive K-Means LSH:
* $\lambda_j(\mathbf q) = \min_{i = 1..k} \| \mathbf q, \mathbf c_{ji} \|$
* and $\lambda_j(\mathbf q)$ is actually a by-product of finding the nearest centroid
* so rank $g_j(\mathbf q)$ by $\lambda_j(\mathbf q)$ then pick $p$ best and use them 


Notes:
* for this to be useful need $L$ larger than usual
* it gives better performance, but it becomes more computationally expensive - may be not very critical as it's done offline 


=== Speeding K-Means Up ===
Can use [[Approximate K-Means]] or [[Mini-Batch K-Means]]


== Sources ==
* Paulevé, Loïc, et al. &quot;Locality sensitive hashing: A comparison of hash function types and querying mechanisms.&quot; 2010. [https://hal.inria.fr/inria-00567191/document]


[[Category:Cluster Analysis]]
[[Category:LSH]]
[[Category:Database Indexes]]</text>
      <sha1>njheripemcptsq6m6kgkf2oeaf6e1qv</sha1>
    </revision>
  </page>
  <page>
    <title>Latent Semantic Kernels</title>
    <ns>0</ns>
    <id>701</id>
    <revision>
      <id>767</id>
      <timestamp>2017-04-26T21:07:24Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;$\require{cancel}$  == Latent Semantic Kernels == In [[Information Retrieval]] via [[Vector Space Model]], retrieval is based on inner product as well * so can also use Kern...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5357">$\require{cancel}$

== Latent Semantic Kernels ==
In [[Information Retrieval]] via [[Vector Space Model]], retrieval is based on inner product as well
* so can also use [[Kernels]]
* You can already use [[SVM]] for text data and get very good performance 
* but also can incorporate additional information by using a kernel
* In traditional [[Vector Space Model]] semantic relationships are not taken into account 
* Goal: design a &quot;Semantic Kernel&quot;: a kernel which creates a map that captures semantic information


Building the Kernel:
* Use Semantic Network (e.g. [[WordNet]]) to capture similarity between words and encode this information into kernel
* use [[Latent Semantic Analysis]] to learn the semantic space and a mapping function that brings input space to the semantic spaces
* in semantic space documents that don't share any terms still can be close if they terms are semantically related 
* this semantic similarity is inferred by analyzing co-occurrence patterns: terms that co-occur often in the same documents are considered related 
* this statistical co-occurrence is extracted via [[SVD]]


== [[Vector Space Model]] == 
Suppose we have a term-document matrix $D$
* then $G = D^T D$ is a doc-by-doc matrix and $T = D D^T$ matrix
* can define a base kernel as $k(\mathbf d_1, \mathbf d_2) = \mathbf d_1^T \mathbf d_2$
* suppose we apply some [[Linear Transformation]] $\phi$: to documents: $\phi(\mathbf d) = P \, \mathbf d$
* (usual VSM: $P = I$)
* then kernel becomes $k(\mathbf d_1, \mathbf d_2) = \mathbf d_1^T P^T P \mathbf d_2$ and the kernel matrix $K = D^T P^T \, P \, D$
* now can build a new kernel $k'$ using the base kernel $k$ (e.g. polynomial or gaussian) - to increase the expressive power of the VSM model




== Semantic Kernels ==
But in reality usual VSM models have problems with synonymy and polysemy - these kernels can't handle that 

how to enrich kernels with semantic information? 
* document expansion: add all synonyms to the document
* or replace words by concepts (can be taken from a semantic network or learned)
* use information about term-term correlation! 

So $K = D^T P^T \, P \, D$ 
* let  $P_{ij}$ denote semantic proximity between terms $i$ and $j$
* then is a square symmetric matrix
* so have  $k(\mathbf d_1, \mathbf d_2) = \mathbf d_1^T P^T P \mathbf d_2 = \mathbf d_1^T P^2 \, \mathbf d_2$
* also note that $\| P\, \mathbf d_1 - P\, \mathbf d_2 \|^2 = \| P \, (\mathbf d_1 - \mathbf d_2) \|^2 = (\mathbf d_1 - \mathbf d_2)^T P^2 \, (\mathbf d_1 - \mathbf d_2)$: can use this to apply Gaussian Kernel

$P$ can also be concept-term similarity matrix, but then $P$ will not be symmetric


=== LSI Kernel ===
[[Latent Semantic Analysis|LSI]]: document feature vector $\mathbf d$ is projected onto the subspace spanned by first $k$ singular vectors if the feature space 
* apply [[SVD]] to $D$: $D = U \Sigma V^T$ where $U$ contains the singular vectors of the feature space
* the projection on $k$ first singular values gives $U_k$, so let $P = U_k^T$ 
* $U_k$ identifies terms that co-occur most often 
* this have $k(\mathbf d_1, \mathbf d_2) = (U_k^T \mathbf d_1)^T U_k^T \mathbf d_2 = \mathbf d_1^T U_k \, U_k^T \mathbf d_2$ 


Suppose we have our kernel classifier 
* $f(\mathbf d) = \sum_{i = 1}^{n} \alpha_i \, k(\mathbf d_i, \mathbf d)$
* then by using this kernel, we have
* $f(\mathbf d) = \sum_{i = 1}^{n} \alpha_i \, \big( \mathbf d_i^T U_k \, U_k^T \mathbf d \big)$
* now consider a vector $\boldsymbol \alpha = (\alpha_1, \ ... \ , \alpha_n)$ 
* we can replace $\big( \mathbf d_i^T U_k \, U_k^T \mathbf d \big)$ with a vector $D^T U_k \, U_k^T \mathbf d$ where $D$ has documents $\mathbf d_1, \, ... \, \mathbf d_n$ as columns
* so $f(\mathbf d) = \boldsymbol \alpha^T D^T U_k \, U_k^T \mathbf d = \ ...$ let's replace $D$ with its SVD
** $... \ = \boldsymbol \alpha^T V \, \Sigma U^T U_k \, U_k^T \mathbf d = \ ...$ replace $U_k = U \, I_k$
** $... \ = \boldsymbol \alpha^T V \, \Sigma \cancel{U^T U} I_k \, U_k^T \mathbf d = \ ...$ 
** $... \ = \boldsymbol \alpha^T V \, \Sigma \, I_k \, U_k^T \mathbf d = \ ...$ note that $\Sigma \, I_k = \Sigma_k$
** $... \ = \boldsymbol \alpha^T V \, \Sigma_k \, U_k^T \mathbf d = \ ...$ 


Can we avoid working on the feature space? We still have $\Sigma_k$ and $U_k$
* $\Sigma_k \, U_k^T \mathbf d$ - need to express in terms of the input space
* $\Sigma_k \, U_k^T \mathbf d = I_k \Sigma \, U^T \mathbf d = \ ...$ 
** $... \ = \Sigma_k \, U_k^T \mathbf d = I_k \underbrace{V^T V}_{I} \Sigma \, U^T \mathbf d = \ ...$
** $... \ = \Sigma_k \, U_k^T \mathbf d = I_k V^T \underbrace{V \Sigma \, U^T}_{D^T} \mathbf d = \ ...$ 
** $... \ = \Sigma_k \, U_k^T \mathbf d = I_k V^T D^T \mathbf d$ 
* let's plug it to $f(\mathbf d)$:
** $f(\mathbf d) = \boldsymbol \alpha^T V \, I_k V^T D^T \mathbf d$
* so we avoid working on the feature space directly: 
* $V$ can be computed by [[Eigendecomposition]] of the kernel matrix $K$ 


Bottleneck: 
* decomposing $K$ 
* approximate: Smola, Alex J., and Bernhard Schölkopf. &quot;Sparse greedy matrix approximation for machine learning.&quot; 2000. [http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.43.3153]



== Sources ==
* Cristianini, Nello, John Shawe-Taylor, and Huma Lodhi. &quot;Latent semantic kernels.&quot; 2002. [http://eprints.soton.ac.uk/259781/1/LatentSemanticKernals_JIIS_18.pdf]

[[Category:Kernels]]</text>
      <sha1>pv3ksentpnvbqng9v6cipr90l92j238</sha1>
    </revision>
  </page>
  <page>
    <title>Metric Trees</title>
    <ns>0</ns>
    <id>702</id>
    <revision>
      <id>768</id>
      <timestamp>2017-04-27T19:58:32Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Metric Trees == Metric tree in an [[Indexing (databases)|indexing]] structure that allows for efficient [[KNN]] search  Metric tree organizes a set of points hierarchically...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6184">== Metric Trees ==
Metric tree in an [[Indexing (databases)|indexing]] structure that allows for efficient [[KNN]] search

Metric tree organizes a set of points hierarchically
* It's a [[Binary Search Trees|binary tree]]: nodes = sets of points, root = all points
* sets across siblings (nodes on the same level) are all disjoint
* at each internal node all points are partitioned into 2 disjoint sets


Notation:
* let $N(v)$ be all points at node $v$ 
* $\text{left}(v), \text{right}(v)$ - left and right children of $v$


Splitting a node:
* choose two pivot points $p_l$ and $p_r$ from $N(v)$ 
* ideally these points should be selected s.t. the distance between them is largest:
** $(p_l, p_r) = \operatorname{arg max}\limits_{p_1, p_2 \in N(v)} \| p_1 - p_2 \|$
** but it takes $O(n^2)$ (where $n = |N(v)|$) to find optimal $p_l, p_r$
* heuristic: 
** pick a random point $p \in N(v)$
** then let $p_l$ be point farthest from $p$
** and then let $p_r$ be point farthest from $p_l$ 
* once we have $(p_l, p_r)$ we can partition:
** project all points onto a line $u = p_r - p_l$
** find the median point $A$ along the line $u$
** all points on the left of $A$ got to $\text{left}(v)$, on the right of $A$ - to $\text{right}(v)$
** by using the median we ensure that the depth of the tree is $O(\log N)$ where $N$ is the total number of data points
** however finding the median is expensive
* heuristic:
** can use the mean point as well, i.e. $A = (p_l + p_r) / 2$
* let $L$ be a $d - 1$ dimensional plane orthogonal to $u$ that goes through $A$ 
** this $L$ is a ''decision boundary'' - we will use it for querying 


After metric tree is constructed at each node we have:
* the decision boundary $L$ 
* a sphere $\mathbb B$ s.t. all points in $N(v)$ are in this sphere
** let $\text{center}(v)$ be the center of $\mathbb B$ and $r(v)$ be the radius
** so $N(v) \subseteq \mathbb B\big(\text{center}(v), r(v)\big)$



'''MT-DFS'''($q$) - the search algorithm
* search in a Metric Tree is a guided [[Depth-First Search]]
* the decision boundary $L$ at each node $n$ is used to decide whether to go left or right
** if $q$ is in the left, then go to  $\text{left}(v)$, otherwise - to $\text{right}(v)$
** (or can project the query point to $u$, and then check if $q &lt; A$ or not)
* all the time we maintain $x$: nearest neighbor found so far
* let $d = \| x - q \|$ - distance from best $x$ so far to the query
* we can use $d$ to prune nodes: we can check if a node is good or no point can better than $x$ 
** no point is better than $x$ if $\| \text{center}(r) - q \| - r(v) \geqslant d$


This algorithm is very efficient when dimensionality is $\leqslant 30$ 
* but slows down when it increases 


Observation:
* MT often finds the NN very quickly and then spends 95% of the time verifying that this is the true NN
* can reduce this time with Spill-Trees


== Spill-Trees ==
A Spill-Tree is a variant of Metric Tree 
* in which children of a node can &quot;spill over&quot; onto each other 
* i.e. $\text{left}(v)$ and $\text{right}(v)$ are no longer required to be disjoint


Partitioning
* the decision boundary $L$ still goes though $A$ 
* but we define two additional separate planes $L_L$ and $L_R$ 
* let $\tau$ be the area that both left and right children of $v$ can share
* $L_L = L - \tau$ and $L_R = L + \tau$
** $\tau$ is the size of overlap
* then $\text{left}(v)$ contains all points on the left of $L_R$ and $\text{right}(v)$ contains all the points on the right of $L_L$
* illustration:
** https://habrastorage.org/files/0ef/d0e/d70/0efd0ed70d0a4d6fb377d0f88b65d101.png


Why allowing overlap?
* find the answer approximately, not exactly


'''SP-Search'''($q$)
* don't backtrack at all - just do a tree descent, not DFS
* consider a case when $q$ is close to $L$: it's true that the true NN might be on the other side of $L$ 
* so by allowing overlap we hope to catch the true NN on the over side 
* and by varying $\tau$ we can reduce the probability of a mistake



=== Hybrid Spill-Trees ===
Problems with Spill-Trees: depth varies a lot with $\tau$ 

Construction
* let $\rho &lt; 1$ be the balance threshold (usually $\rho = 0.7$)
* Similar to SP-Trees, but 
** if either of $v$'s children contains more than $\rho \cdot | N(v) |$ elements 
** then don't do overlapping nodes - use usual MT split and mark the node as &quot;non-overlapping&quot;
* this way we still can maintain the logarithmic depth


Search:
* also hybrid of both
* if non-overlapping: do backtracking
* if overlapping: don't backtrack


== [[Random Projections]]: [[Dimensionality Reduction]] ==
Both SP and MT aren't very efficient for $D \geqslant 30$ 
* but by Johnson-Lidenstrauss Lemma (see Achlioptas2003) know that 
** we can always embed $N$ points into a subspace with dimensionality $\log N$
** with little distortion on pair-wise distances. 
* so let's do a very simple embedding: [[Random Projections]]
* pick up a random subspace $S$ and project all data on $S$ 


So, 
* do Random Projection as a preprocessing step: project all data points on $S$ and build the tree on the low dimensional representation
* by doing projection we'll lose some accuracy
* can fix that by doing multiple different random projections and do a hybrid search for each resulting tree separately
* if probability of failing to find the true NN is $\delta$, then do doing $L$ different projections we reduce this probability to $\delta^L$ 



== References ==
* Uhlmann, Jeffrey K. &quot;Metric trees.&quot; 1991. [http://trac.astrometry.net/export/20934/trunk/documents/papers/dstn-review/papers/uhlmann1991b.pdf]
* Omohundro, Stephen M. &quot;Bumptrees for efficient function, constraint, and classification learning.&quot; 1991. [http://www1.icsi.berkeley.edu/ftp/pub/techreports/1991/tr-91-009.pdf]
* Achlioptas, Dimitris. &quot;Database-friendly random projections: Johnson-Lindenstrauss with binary coins.&quot; 2003. [http://www.sciencedirect.com/science/article/pii/S0022000003000254]



== Sources ==
* Liu, Ting, et al. &quot;An investigation of practical approximate nearest neighbor algorithms.&quot; 2004. [http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2005_187.pdf]


[[Category:Database Indexing]]
[[Category:Information Retrieval]]</text>
      <sha1>h038aabc3bzu5lwxyyoul1mzc7g7682</sha1>
    </revision>
  </page>
  <page>
    <title>Kernel Methods</title>
    <ns>0</ns>
    <id>703</id>
    <revision>
      <id>770</id>
      <timestamp>2017-04-27T20:22:18Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;{{draft}} {{stub}}  == Kernel Methods ==  [[Support Vector Machines]]    [[Kernel]] is a generalized dot product  * [[Latent Semantic Analysis]] captures semantic relations be...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3195">{{draft}} {{stub}}

== Kernel Methods ==

[[Support Vector Machines]]



[[Kernel]] is a generalized dot product 
* [[Latent Semantic Analysis]] captures semantic relations between terms 
* drawback: computationally expensive

[[Kernel Methods]]
* data items are mapped into some high-dimensional space where we use [[Inner Product]] for constructing models
* kernel acts as an &quot;interface&quot; between the model and the high-dimensional space
* by defining (often implicitly) a mapping function that transform the input space to some (possibly very high dimensional) feature space

Just dot product is enough for many algorithms:
* [[Perceptron]]
* [[Principal Component Analysis]] -&gt; [[Kernel PCA]]
* [[Ridge Regression]] -&gt; [[Kernel Ridge Regression]]





== Use of Kernels ==
=== [[Classification]] ===
[[Support Vector Machines]]

=== [[Text Mining]] ===
[[Latent Semantic Kernels]]: Use [[Latent Semantic Analysis]]

=== [[Clustering Analysis]] ===


=== [[Regression]] ===
Support Vector Regression
* Smola, Alex J., and Bernhard Schölkopf. &quot;A tutorial on support vector regression.&quot; 2004. [http://lasa.epfl.ch/teaching/lectures/ML_Phd/Notes/nu-SVM-SVR.pdf]


=== [[Anomaly Detection]] ===

=== [[Gaussian Processes]] ===

=== [[Kernel Density Estimation]] ===


== Kernels ==
=== Data Span Solution ===
Choosing a kernel $\equiv$ choosing a feature space 
* $k(\mathbf x, \mathbf z) = \langle \varphi(\mathbf x), \varphi(\mathbf z) \rangle$
* given a dataset, apply $k$ to each pair and get a Kernel Matrix (also called [[Gram Matrix]])

$$K = \begin{bmatrix}
k(\mathbf x_1, \mathbf x_1) &amp; k(\mathbf x_1, \mathbf x_2) &amp; \cdots &amp; k(\mathbf x_1, \mathbf x_n) \\ 
k(\mathbf x_2, \mathbf x_1) &amp; k(\mathbf x_2, \mathbf x_2) &amp; \cdots &amp; k(\mathbf x_2, \mathbf x_n) \\ 
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\ 
k(\mathbf x_n, \mathbf x_1) &amp; k(\mathbf x_n, \mathbf x_2) &amp; \cdots &amp; k(\mathbf x_n, \mathbf x_n) \\ 
\end{bmatrix}$$


If we have a linear learning machine with parameters $\mathbf w$, 
* then the function we try to learn is modeled by $f(\mathbf x) = \mathbf w^T \varphi(\mathbf x)$
* we can express $\mathbf w$ as a combination of training points: $\mathbf w = \sum_{i = 1}^{n} \alpha_i \, \varphi(\mathbf x_i)$ (i.e. the solution lies in the span of the data)
* then $f(\mathbf x) = \sum_{i = 1}^{n} \alpha_i \, k(\mathbf x_i, \mathbf x)$


=== Mercer Kernels ===


=== Types ===
We can combine Kernels: 
* given base kernel $k(\mathbf x, \mathbf z)$ (can be a dot product $k(\mathbf x, \mathbf z) = \langle \mathbf x, \mathbf z \rangle)$)
* Polynomial Kernel: $k'(\mathbf x, \mathbf z) = \big( k(\mathbf x, \mathbf z) + D \big)^p$
* Gaussian Kernel: $k'(\mathbf x, \mathbf z) = \exp \left( \cfrac{k(\mathbf x, \mathbf x) - 2 \, k(\mathbf x, \mathbf z) + k(\mathbf z, \mathbf z)}{\sigma^2} \right)$


== References ==
* Hofmann, Thomas, Bernhard Schölkopf, and Alexander J. Smola. &quot;Kernel methods in machine learning.&quot; 2008. [http://www.kernel-machines.org/publications/pdfs/0701907.pdf]


== Sources ==
* Cristianini, Nello, John Shawe-Taylor, and Huma Lodhi. &quot;Latent semantic kernels.&quot; 2002. [http://eprints.soton.ac.uk/259781/1/LatentSemanticKernals_JIIS_18.pdf]

[[Category:Kernels]]</text>
      <sha1>qgrfqd9411wxdjadz00yswp96ccqza3</sha1>
    </revision>
  </page>
  <page>
    <title>KNN</title>
    <ns>0</ns>
    <id>704</id>
    <revision>
      <id>771</id>
      <timestamp>2017-04-27T20:24:56Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;{{stub}} {{draft}}  == $K$ Nearest Neighbors ==   KNN Graph a graph that contains links only between $k$ closest neighborhoods  used in    == [[Machine Learning]] and Statis...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2853">{{stub}} {{draft}}

== $K$ Nearest Neighbors ==


KNN Graph
a graph that contains links only between $k$ closest neighborhoods 
used in 


== [[Machine Learning]] and [[Statistics]] ==
Simple and popular method for many areas of machine learning, statistics and beyond


=== [[Regression Problem]] ===



=== [[Classification Problem]] ===



=== [[Cluster Analysis]] ===
KNN approach is used in [[SNN Clustering]]
* can use the number of shared neighbors as a similarity measure



=== [[Probability Density Estimation]] ===
* If $k$th nearest neighbor is close, then the region is most likely of high density
* so the distance to $k$th neighbor gives a measure of density of a point
* can use it with [[Euclidean Distance]], [[Cosine Similarity]] or SNN Similarity (see [[SNN Clustering]])



== [[Curse of Dimensionality]] ==
Also note that for high dimensional data many distance/similarity measures become less meaningful 
* especially [[Euclidean Distance]]
* can use special functions that can handle high dimensional data: SNN Similarity (see [[SNN Clustering]])


== Indexing for KNN Queries ==
Brute force search for $k$NN takes $O(N)$ where $N$ is the size of the database
* need to use [[Multi-Dimensional Indexes]], for example, trees: [[Kd-Trees]] or [[R-Tree]]s
* however for high dimensional data tree performance degrades from $O(\log N)$ to $O(N)$
* see Weber98: all indexing techniques degrade to linear search for large dimensionality
* also can't use classical hash-based indexes (like [[Linear Hashing]] or [[Extensible Hashing]]): they aim at exact match and don't handle KNN queries

Trees
* [[Metric Trees]]
* [[Spill-Trees]] gives approximate answer to KNN
* both don't work well in high dimensions, but can apply [[Random Projections]] to make them work


Hashes:


=== Dealing with High Dimensionality ===
How to deal with the [[Curse of Dimensionality]]?

Pre-aggregating data:
* can use [[Locality Sensitive Hashing]]: probabilistic/approximate indexing techniques that return the true KNNs most of the time correctly  
* it would put data items into hash buckets, and when we look for KNN of $q$, we look into buckets where $q$ landed
* alternatively, can use [[Canopy Clustering|canopies]]




== References ==
* Weber, Roger, Hans-Jörg Schek, and Stephen Blott. &quot;A quantitative analysis and performance study for similarity-search methods in high-dimensional spaces.&quot; 1998. [http://www.vldb.org/conf/1998/p194.pdf]
* Nearest-Neighbor Methods in Learning and Vision: Theory and Practice [http://people.csail.mit.edu/gregory/annbook/book.html]

== Sources ==
* Ertöz, Levent, Michael Steinbach, and Vipin Kumar. &quot;Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data.&quot; 2003. [http://static.msi.umn.edu/rreports/2003/73.pdf]


[[Categories:Machine Learning]]
[[Categories:Statistics]]</text>
      <sha1>23lgx0jlmvle19ntkdgfvn1ghureqcy</sha1>
    </revision>
  </page>
  <page>
    <title>Multinomial Distribution</title>
    <ns>0</ns>
    <id>705</id>
    <revision>
      <id>773</id>
      <timestamp>2017-04-27T20:28:14Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;{{stub}}  == Multinomial Distribution == It's an extension of [[Binomial Distribution]]   == [[Maximum Likelihood Estimator]] == * consider log likelihood function: $\log P(D...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="875">{{stub}}

== Multinomial Distribution ==
It's an extension of [[Binomial Distribution]]


== [[Maximum Likelihood Estimator]] ==
* consider log likelihood function: $\log P(D \mid \theta) = \sum_{w \in V} c(w, D) \, \log P(w \mid \theta)$ 
* we want to maximize it s.t. $P(w \mid \theta)$ is a [[Probability Distribution]] i.e. $\sum_{w \in V} P(w \mid \theta) = 1$
* use [[Lagrange Multipliers]] to convert this constrained optimization problem into an unconstrained one
* so let $L(\theta, \lambda) = \log P(D \mid \theta) + \lambda \left(1 - \sum P(w \mid \theta) \right) = \sum_{w \in V} c(w, D) \, \log P(w \mid \theta) + \lambda \left(1 - \sum P(w \mid \theta) \right)$ 
* by solving it, we get $P(w \mid \hat \theta) = \cfrac{c(w, D)}{|D|}$


== Sources ==
* Zhai, ChengXiang. &quot;Statistical language models for information retrieval.&quot; 2008.


[[Category:Distributions]]</text>
      <sha1>f7mopc0q29l65skiaygton99w44972l</sha1>
    </revision>
  </page>
  <page>
    <title>NLP Pipeline</title>
    <ns>0</ns>
    <id>706</id>
    <revision>
      <id>774</id>
      <timestamp>2017-04-27T20:29:09Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== NLP Pipeline ==   === NLP Applications === * [[Tokenization]] * [[Stop Words|Stop Words Removal]] * [[Text Normalization]] (e.g. U.S.A. -&gt; USA) ** [[Spelling Correction]] *...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="902">== NLP Pipeline ==


=== NLP Applications ===
* [[Tokenization]]
* [[Stop Words|Stop Words Removal]]
* [[Text Normalization]] (e.g. U.S.A. -&gt; USA)
** [[Spelling Correction]]
** [[Lemmatization]] (or sometimes [[Stemming]])
** find equivalence classes (using thesauri, e.g. [[WordNet]]) (semantic stuff)
* [[POS Tagging]]
* [[Named Entity Recognition]]
* building [[Statistical Language Models]]


=== [[Information Retrieval]] ===
* [[Tokenization]]
* [[Stop Words|Stop Words Removal]]
* [[Text Normalization]]
** [[Stemming]] or [[Lemmatization]]
** [[Spelling Correction]]
** [[Phonetic Normalization]] (e.g. with [[Soundex]])
** find equivalence classes (using thesauri, e.g. [[WordNet]]) (semantic stuff)
* [[Named Entity Recognition]]
* building [[Inverted Index]] and [[Vector Space Model]]




== Sources ==
* [[Information Retrieval (UFRT)]]

[[Category:Information Retrieval]]
[[Category:NLP]]</text>
      <sha1>ab18eb7s3xe02i2k2ric8adnwd6ifkz</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Matrix Decomposition</title>
    <ns>14</ns>
    <id>707</id>
    <revision>
      <id>780</id>
      <timestamp>2017-06-22T15:25:52Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;[[Category:Linear Algebra]]&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27">[[Category:Linear Algebra]]</text>
      <sha1>1o0hp9w6lazhtrq9wq68p3anq0bhkp4</sha1>
    </revision>
  </page>
  <page>
    <title>Ordinary Least Squares</title>
    <ns>0</ns>
    <id>709</id>
    <redirect title="Normal Equation" />
    <revision>
      <id>797</id>
      <timestamp>2017-06-27T12:16:42Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Alexey moved page [[Ordinary Least Squares]] to [[OLS Regression]] over redirect</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="28">#REDIRECT [[OLS Regression]]</text>
      <sha1>0zehvaalxjknu3651znxj41qwwqxjxc</sha1>
    </revision>
    <revision>
      <id>798</id>
      <parentid>797</parentid>
      <timestamp>2017-06-27T12:17:14Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Redirected page to [[Normal Equation]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="29">#REDIRECT [[Normal Equation]]</text>
      <sha1>84lm7cy878qen621t4qsjscg1zlcrqz</sha1>
    </revision>
  </page>
  <page>
    <title>Diagonalization</title>
    <ns>0</ns>
    <id>710</id>
    <revision>
      <id>804</id>
      <timestamp>2017-06-28T13:52:54Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Redirected page to [[Eigendecomposition]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="32">#REDIRECT [[Eigendecomposition]]</text>
      <sha1>1q9wojhkyxnia28xbwcjjn0norkijo3</sha1>
    </revision>
    <revision>
      <id>805</id>
      <parentid>804</parentid>
      <timestamp>2017-06-28T13:55:10Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1047">== Diagonalization ==
Diagonalization is the process of tranforming a square matrix $A$ to the diagonal form

Diagonal Form
* $T$ is the ''diagonal form'' of $A$ if
* $T$ is Diagonal and
* there exists $X$ such that $T = X^{-1} A X$
* $A$ and $T$ are [[Similar Matrices|similar]]
* so $A$ and $T$ share the same [[Eigenvalues and Eigenvectors|eigenvalues]]


Non-defectiveness
* $A$ is ''non defective'' $\iff$ there exists non singular $X$ s.t.
* $X^{-1} A X = \text{diag}(\lambda_1, ..., \lambda_n)$
* i.e. there exists a similarity tranformation $X$ such that the results is a diagonal matrix with eigenvalues on the diagonal


== [[Eigendecomposition]] ==
Eigendecomposition decomposes a symmetric matric $A$ as 
* $\Lambda = S^{T} A S$
* where $\Lambda = \text{diag}(\lambda_1, ..., \lambda_n)$
* and $S$ has eigenvectors on the diagonal 
* so the similarity transformation matrix $S$ here is [[Orthogonal Matrices|orthogonal]]


== Sources ==
* [[Linear Algebra MIT 18.06 (OCW)]]
* [[Matrix Computations (book)]]

[[Category:Linear Algebra]]</text>
      <sha1>7tow69d5r91ptf2zb4c9ja0tahoje01</sha1>
    </revision>
  </page>
  <page>
    <title>Householder Transformation</title>
    <ns>0</ns>
    <id>711</id>
    <revision>
      <id>809</id>
      <timestamp>2017-08-06T19:29:49Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Householder Transformation == Householder Transformation (also &quot;Householder Reflection&quot;) is an orthogonal reflection transformation: * it reflex the vectors in the columns...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4631">== Householder Transformation ==
Householder Transformation (also &quot;Householder Reflection&quot;) is an orthogonal reflection transformation:
* it reflex the vectors in the columns of the matrix such that
* the first vector has all zeros except the first element 


=== The Transformation Matrix ===
Reflection transformation:
* Reflection across the plane orthogonal to some unit-vector $v$ is specified by the following transformation:
* $P = I - 2 v v^T$
* So this is just rank-1 update of the identity matrix 
* such $P$ is called &quot;Householder transformation&quot; (also: Householder Reflection or Householder Matrix)
* and $v$ is the &quot;Householder vector&quot;
* when we multiply $P x$, $x$ is reflected around $\text{span}(v)^{\bot}$
* if $v$ is not unit vector, we need to normalize it
* let $\beta = 2 / \| v \|^2$, so we can simply write $P = I - \beta v v^T$


=== Properties ===
Householder matrices are [[Symmetric Matrices|symmetric]] and [[Orthogonal Matrices|orthogonal]]: they are reflection matrices


=== Derivation ===
So we have $P = I - 2vv^T$:
* this is reflection across the plane orthogonal to $v$
* suppose we have some vector $x$ and want to reflect it such that it becomes parallel to some unit vector $y$
* https://habrastorage.org/web/c24/6e0/3ba/c246e03bace34da19bf1a18b832f2f23.png https://habrastorage.org/web/668/dca/ac3/668dcaac3b5f4581abb7a7beca03430d.png
* here we want to reflect around the place that is between $y$ and $x$ - that bisects the angle between them
* the vector orthogonal to this place is $x - \| x \| y$
* so let $u = x - \| x \| y$ and $v = u / \| u \|$
* $\| u \|^2 = (x - \| x \| y)^T (x - \| x \| y) = \ ...$
** $... \ = \|x\|^2 - 2 \| x \| x^T y + \| x \|^2 \| y \|^2 = \ ...$ 
** $... \ = \|x\|^2 - 2 \| x \| x^T y + \| x \|^2  = \ ...$ (since $y$ is unit vector)
** $... \ = 2 \|x\|^2 - 2 \| x \| x^T y$
* $Px = (I - 2 v v^T) x = x - 2 \cfrac{u u^T x}{\| u \|^2} = \ ...$
** $... \ = x - 2 \cfrac{(x - \| x \| y) (x - \| x \| y)^T x}{2 \|x\|^2 - 2 \| x \| x^T y} = \ ...$
** $... \ = x - 2 \cfrac{(x - \| x \| y) (x^T - \| x \| x^T y)}{2 \|x\|^2 - 2 \| x \| x^T y} = \ ...$
** $... \ = x - (x - \| x \| y) = \| x \| y$
* so when we apply $P$ to some $x$, we get $\| x \| y$


We use such transformations for zeroing elements
* we want to zero all elements of $x$ except the first one, so we need $P x = \pm \alpha e_1$
* we know that if $P x = \pm \alpha e_1$ and $P$ is Householder reflection with $y = e_1$, then $P x =\pm \alpha e_1 = \| x \| e_1$, so $\alpha = \pm \| x \| = \rho \| x \|$ where $\rho = \pm 1$ 
* let $z = x - \alpha e_1$ and $u = z / \| z \|$
* so &lt;math&gt;z = x - \alpha e_1 = x - \rho \| x \| e_1 = \begin{bmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n 
\end{bmatrix} - \rho \| x \| \begin{bmatrix}
1 \\
0 \\
\vdots \\
0 \\
\end{bmatrix} = 
\begin{bmatrix}
x_1 - \rho \| x \| \\
x_2 \\
\vdots \\
x_n 
\end{bmatrix}
&lt;/math&gt;
* we can choose any $\rho$, but often it's $\rho = -\text{sign}(x_1)$ - this is better for round-off errors




== [[QR Decomposition]] ==
Like in case of [[LU Decomposition]], where we applied a series of Gauss Transformation changes, we can do the same and perform a series of Householder Transformations
* so if we select $y = \pm e_1$ (where $e_1$ is the matrix with 1 on position 1 and rest are zeros)
* then it will zero all elements of $x$ except the first one 
* thus by the appropriate choice of $H$ we can take $A$ and zero all the sub-diagonal elements
* can do that multiple times for each column of $A$

https://habrastorage.org/web/f97/c9d/02e/f97c9d02e5a34d52b0763a544aa742bc.png


This way we can perform [[QR Decomposition]]:


 def qr_householder(A):
     m, n = A.shape
     Q = np.eye(m) # Orthogonal transform so far
     R = A.copy() # Transformed matrix so far
 
     for j in range(n):
         # Find H = I - beta*u*u' to put zeros below R[j,j]
         x = R[j:, j]
         normx = np.linalg.norm(x)
         rho = -np.sign(x[0])
         u1 = x[0] - rho * normx
         u = x / u1
         u[0] = 1
         beta = -rho * u1 / normx
 
         R[j:, :] = R[j:, :] - beta * np.outer(u, u).dot(R[j:, :])
         Q[:, j:] = Q[:, j:] - beta * Q[:, j:].dot(np.outer(u, u))
         
     return Q, R

== [[Hessenberg Decomposition]] ==
Instead of using it for reducting the matrix to Triangular, we can use Householder Transformation to reduce a matrix to Hessenberg Matrix 



== Sources ==
* http://www.cs.cornell.edu/~bindel/class/cs6210-f12/notes/lec16.pdf
* [[Matrix Computations (book)]]
* https://math.dartmouth.edu/~m116w17/Householder.pdf

[[Category:Linear Algebra]]
[[Category:Matrix Decomposition]]
[[Category:Python]]</text>
      <sha1>5l1h0ma92gnlw9r4onx1ggviytd89f6</sha1>
    </revision>
  </page>
  <page>
    <title>Matrix Computations (book)</title>
    <ns>0</ns>
    <id>712</id>
    <revision>
      <id>811</id>
      <timestamp>2017-08-06T19:33:08Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Matrix Computations ==  http://cv02.twirpx.net/1459/1459090.jpg  Book by Golub and Van Loan, 4th Edition * official page: https://www.cs.cornell.edu/cv/GVL4/golubandvanloan...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="904">== Matrix Computations ==

http://cv02.twirpx.net/1459/1459090.jpg

Book by Golub and Van Loan, 4th Edition
* official page: https://www.cs.cornell.edu/cv/GVL4/golubandvanloan.htm

== Table of Contents ==
TOC in PDF [https://www.cs.cornell.edu/cv/GVL4/TableOfContents.pdf]


Basics
* [[Matrix-Matrix Multiplication]]
* [[Vector Spaces]]
* [[Linear Independence]]
* [[System of Linear Equations]]
* [[LU Decomposition]]
* [[Triangular Matrices]]
* [[Similar Matrices]]
* [[Diagonalization]]

[[Orthogonalization]] and [[Ordinary Least Squares|Least Squares]]
* [[Orthogonalization]] and [[QR Decomposition]]
* [[Householder Transformation]]
* [[Givens Transformation]]
* [[Gram-Schmidt Process]]
* [[Ordinary Least Squares]]

[[Eigenvalues and Eigenvectors|Eigenvalue Problems]]
* [[Power Iteration]]
* [[Hessenberg Transformation]]
* [[QR Algorithm]]
* [[Tridiagonalization]] and [[Tridiagonal Matrices]]</text>
      <sha1>l2bv1f31dvmxdrcer5fzikfew15j15g</sha1>
    </revision>
  </page>
  <page>
    <title>Budget Pacing</title>
    <ns>0</ns>
    <id>713</id>
    <revision>
      <id>820</id>
      <timestamp>2018-05-21T20:26:03Z</timestamp>
      <contributor>
        <username>Alexey</username>
        <id>1</id>
      </contributor>
      <comment>Created page with &quot;== Budget Pacing == Budget pacing control: * take the daily budget as input * calculate the delivery schedule * based on the schedule, DSP tries to spread the actions througho...&quot;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5589">== Budget Pacing ==
Budget pacing control:
* take the daily budget as input
* calculate the delivery schedule
* based on the schedule, DSP tries to spread the actions throughout the day

Notation:
* $n$ ad requests 
* $x_i = \{0, 1\}$, decision whether to bid on $i$ or not
* $v_i$ - value if we win on $i$ and show it to user
* $c_i$ - cost of showing $i$ 
* $\hat{c}_i$ - how much we are willing to bid
** for second price option, $\hat{c}_i = c_i + \epsilon_i$, and $\epsilon_i$ is unknown to the bidder at bid time
* $B$ total budget, allocated in $T$ slots $b_t$ s.t. $\sum b_t = B$

Goal:
* maximize $\sum v_i x_i$
* s.t. $\sum_j c_j x_j \leqslant b_t$ for all $j$ of $b_t$ 


== Optimization ==
Metrics: 
* eCPC or eCPA, want to minimize them 

More notation:
* let  $s(t) = \sum c_j x_j$ - how much we actually spent during $t$ 
* want $\sum s(t)$ be as close to $B$ as possible
* and $s(t)$ to be close to $b_t$ 


Assumption: 
* $s(t)$ is proportional to the number of impressions served at the time
* it means that the price of individual impressions are approximately the same during this time slot
* the length of the time slot can be chosen s.t. this assumption is not violated

=== Setting Bid Rate ===

For each ad spot for time $t$ we assign a bid rate (pacing rate): 
* $s(t)$ is proportional to number of impressions served
* $\text{requests}(t)$: # of received bid requests
* $\text{bids}(t)$: # of times we decided to bid
* $\text{imps}(t)$: # of shown impressions at $t$
* $\text{bid_rate}(t)$: rate at which we decide to bid on the request
** $\text{bid_rate}(t) = \text{bids}(t) \, / \, \text{requests}(t)$
* $\text{win_rate}(t)$: rate at which we win the bid
** $\text{win_rate}(t) = \text{imps}(t) \, / \, \text{bids}(t)$
* $s(t) \sim \text{request}(t) \cdot \text{bid_rate}(t) \cdot \text{win_rate}(t)$

So we can control $s(t)$ by changing our $\text{bid_rate}(t)$

Changing bid_rate:

Adjusting bid rate for slot $t+1$:
* take feedback from slot $t$ 
* use this for $t+1$ 

we can control $\text{bid_rate}(t+1)$


=== Budget Schedule ===
Selecting $b_t$
* uniform - not the best one
* traffic is different during each hour
* should allocate more budget for periods with better quality traffic
* i.e. to the time where the target audience is more active

History-based:
* for each $b_t$ calculate $p_t$ 
* $p_t$ is probability of success (click or conversion)
* $\sum p_t = 1$ 

so, ideal spending for the next time slot can be calculated as 

$$\left(B - \sum_{m=1}^{t} s(m) \right) \cdot \cfrac{p_{t+1}}{\sum_{m=t+1}^{T} p_m}$$

two parts
* remaining budget: how much money we still have
* how good is the next slot compared to all other remaining slots

note that if $p_t = 0$ for some $t$, the system will never explore this time slots, so should always give it some chance 

Once we calculate the desired bid rate, we can 
* select top quality ad requests to bid on
* choose the price we are willing to bid for these requests 


=== Selecting Good Quality Ad Requests ===
for each impression $i$ we can choose the price to bid with

construct bidding histogram $c^*$
* this is historical average of costs $c_i$ in $b_t$ 
* now we know which $b_t$ is cheapest
* take base price and scale it up/down considering bid rate 

=== Bid Price ===
bid_rate vs bid_price:
* bid_rate controls the frequency of bidding 
* but bid price is important
* if it's not high enough, we don't win the impression
* if it's too high, CPA rises


bid price adjustments
* split requests into 3 groups based on bid rate:
* define $\beta_1$, $\beta_2$ s.t. $0 &lt; \beta_1 &lt; \beta_2 &lt; 1$

bid_rate can be in one of these 3 groups:
* safe: $0 &lt; br \leqslant \beta_1$, no delivery issues
* critical: $\beta_1 &lt; br \leqslant \beta_2$, normal delivery
* danger: $\beta_2 &lt; br \leqslant 1$ and cannot win enough impressions

Let $u_i$ be the base bid price however set based on CTR/AR model
* (AR - action rate or conversion rate)


Safe region: learning $\hat{c}_i$ 
* look at submitted bid price $\hat{c}_i$ and actual price $c_i$ 
* let $\theta_i = c_i \, / \, \hat{c}_i$
* build a histogram of $\theta_i$, choose $\theta^*$ as the bottom 1-2 percentile
* submit $\hat{c}_i = \theta^* \cdot u_i$

Critical region:
* bid $\hat{c}_i = u_i$ 

Danger region:
* Reasons for being in this region:
* audience is too specific, not enough bid requests that satisfy all the criteria 
* bid price is too low to win impressions 
* Can increase the bid price by some coefficient $\rho \geqslant 1$


== Models ==
=== Estimation of CTR/AR ===
Why estimate AR?
* to predict the quality of an ad request
* to set the bid price: e.g. AR * CPA goal 

Ways to do it:
* [[Hierarchical Bandits]]
* [[Logistic Regression]]
* [[Factorization Machines]]


== Problems ==
=== Cold Start Problem ===
Ideas:
* use content features for models to estimate CTR/AR
* epsilon-greedy strategy for online bid optimization


=== Overspending ===
Because of unusual unexpected activity spikes we might spend all the budget earlier than expected 

solution:
* monitor total spend and stop the campaign when we spend more than B
* monitor spend at $t$ and allow to spend no more than $b_t + \delta$, and pause until $t+1$ if the limit is exceeded 


=== System ===

 Ad request -&gt; check bid rate -&gt; evaluate CTR/AR -&gt; bid -&gt; ...
 ... -&gt; SSP -&gt; ...
 ... -&gt; bid log with win -&gt; save to db
 db &lt;-&gt; train CTR/AR models
    &lt;-&gt; compute good bid rate


== Sources ==
*  Real Time Bid Optimization with Smooth Budget Delivery in Online Advertising: https://arxiv.org/abs/1305.3011


[[Category:Adtech]]
[[Category:Machine Learning]]</text>
      <sha1>rqoru6kr8kflv5osj79pg5hi6vt0jfr</sha1>
    </revision>
  </page>
</mediawiki>
